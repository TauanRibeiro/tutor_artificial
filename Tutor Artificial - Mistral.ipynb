{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948e72cc-9b7b-4418-830d-560b2e9e35e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import gradio as gr \n",
    "\n",
    "from textwrap import fill\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
    "\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# subaze\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "# opcode\n",
    "#os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "\n",
    "import openai\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deb029eb-6fbc-4e41-aa14-8d94df82ab48",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No GPU found. A GPU is needed for quantization.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL_NAME, use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n\u001b[1;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m GenerationConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL_NAME)\n\u001b[0;32m     22\u001b[0m generation_config\u001b[38;5;241m.\u001b[39mmax_new_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\tauan\\anaconda3\\envs\\tutor_artificial\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tauan\\anaconda3\\envs\\tutor_artificial\\Lib\\site-packages\\transformers\\modeling_utils.py:2864\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_8bit \u001b[38;5;129;01mor\u001b[39;00m load_in_4bit:\n\u001b[0;32m   2863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m-> 2864\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo GPU found. A GPU is needed for quantization.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2865\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[0;32m   2866\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2867\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2868\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2869\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `pip install bitsandbytes`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2870\u001b[0m         )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No GPU found. A GPU is needed for quantization."
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    "    load_in_4bit=True\n",
    ")\n",
    "\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "generation_config.max_new_tokens = 1024\n",
    "generation_config.temperature = 0.0001\n",
    "generation_config.top_p = 0.95\n",
    "generation_config.do_sample = True\n",
    "generation_config.repetition_penalty = 1.15\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    generation_config=generation_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb4a2b6-1743-4b10-ae64-dfc13cb79138",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HuggingFacePipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFacePipeline\u001b[49m(\n\u001b[0;32m      2\u001b[0m     pipeline\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[0;32m      3\u001b[0m     )\n\u001b[0;32m      5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(\n\u001b[0;32m      6\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthenlper/gte-large\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      8\u001b[0m     encode_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'HuggingFacePipeline' is not defined"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline(\n",
    "    pipeline=pipeline,\n",
    "    )\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"thenlper/gte-large\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3791678-a82e-422f-b74f-4696f49c3197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62587854-25ae-489f-8cd6-ac70ab07846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(\"repositorio/\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30ac161b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\nAvailable online 9 April 2022\\n2666-920X/© 2022 The Author. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-\\nnc-nd/4.0/ ).Personalized education and Artificial Intelligence in the United States, \\nChina, and India: A systematic review using a Human-In-The-Loop model☆ \\nAditi Bhutoriaa,b,c,1,* \\naIndian Institute of Management Calcutta, Diamond Harbour Road, Kolkata, 700104, India \\nbEdTech Hub, United Kingdom \\ncEducation and Training Evaluation Commission, King Khalid Bin Abdulaziz Road, Al-Nakheel Al-Gharbi District, Riyadh, 11683, Saudi Arabia   \\nARTICLE INFO  \\nKeywords: \\nPersonalized education \\nArtificial intelligence \\nBig data \\nUSA \\nChina \\nIndia ABSTRACT  \\nThe traditional “one size fits all” education system has been largely criticized in recent years on the ground of its \\nlacking the capacity to meet individual student needs. Global education systems are leaning towards a more \\npersonalized, student-centered approach. Innovations like Big Data, Machine Learning, and Artificial Intelligence \\n(AI) have given the modern-day technology to accommodate the distinctive features of human beings - smart \\nmachines and computers have been built to understand individual-specific needs. This opens an avenue for \\n“personalization ” in the education sector. From, mushrooming of Education Technology (EdTech) start-ups to \\ngovernment funding in AI research, it is evident that the next generation educational reforms would take a \\nquantum leap forward piloted by Big Data analysis and AI. The objective of this paper is to organize the vast \\nliterature on the use of AI for personalization of education and to shed light on the key themes by which an AI- \\ndriven approach makes structural modifications to the existing education system. To this effect, the paper \\nemployed a systematic review using a Human-In-The-Loop natural language processing model of past two years ’ \\nliterature (2019 –2021) in English language from IEEE Xplore on countries China, India and the USA. This process \\nyielded more than 2000 search results at first and these were eventually shortlisted to 353 relevant papers for in- \\ndepth analysis. Being the pioneers in EdTech innovations, insights from research done in these three countries \\nprovides valuable input for the development of global education systems and research. The findings bring for-\\nward AI’s success in catering to specific learning requirements, learning habits, and learning abilities of students \\nand guiding them into optimized learning paths across all three countries. Not just that, it is also evident from the \\nliterature that AI augments educational content, customizes it for any individual according to their needs, and \\nraises the flag of caution for anticipated learning difficulties. This recalibrates the role of instructors as well as \\noptimizes the teaching-learning environment for a better learning experience. The upward trajectory of educa -\\ntional development with AI opens a new horizon of personalized education for the future generation, but also \\ncomes with its challenges. Data privacy issues, availability of digital resources, and affordability constraints have \\nbeen reported in the recent literature as impediments in the way of promoting such technologies for day-to-day \\npractice.   \\n1.Introduction \\nA key goal of education is to foster the talents of students and to \\nprovide them with a holistic learning experience. Hence, it is imperative \\nto teach in line with each individual ’s ability, which could not be provided by the conventional paradigm of one-size-fits-all in traditional \\neducation systems. The idea of personalized education paves the way for \\na more nuanced teaching technique. The concept of personalized edu-\\ncation comes from the idea of “precision medicine ”, where data to \\nidentify patterns relevant to specific patients are analyzed so that pre-', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 0}),\n",
       " Document(page_content='cation comes from the idea of “precision medicine ”, where data to \\nidentify patterns relevant to specific patients are analyzed so that pre-\\nvention and treatment can be customized. This is why such \\n☆I would like to thank the Asian Century Foundation for the China-India Visiting Fellowship, constant support and funding for this paper. I am immensely grateful \\nfor the collaboration with Prof. Hongtao Sun (Beijing Normal University) and his useful suggestions on the paper. I would also like to thank Rohit Kumar Nag and \\nSoumita Mitra for exceptional research assistance. \\n*Indian Institute of Management Calcutta, Diamond Harbour Road, Joka, Kolkata, 700104, West Bengal, India. \\nE-mail address: abhutoria@iimcal.ac.in .   \\n1 https://edtechhub.org/ \\nContents lists available at ScienceDirect \\nComputers and Education: Artificial Intelligence \\njournal homepag e: www.sci encedirect. com/journa l/computers-a nd-educati on-artificial -intelligence \\nhttps://doi.org/10.1016/j.caeai.2022.100068 \\nReceived 3 January 2022; Received in revised form 5 April 2022; Accepted 6 April 2022', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 0}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n2transformation of the education system toward a more personalized \\nstructure is called “precision education”, although this term has been \\nincreasingly replaced by terms like “personalized teaching and learning” \\nin the recent academic literature. Personalized education involves pre-\\ndicting students’ performance and providing them feedback to optimize \\nlearning after analysis of student learning profiles and retention pat-\\nterns. Overall, personalized education attempts to improve the diag-\\nnosis, prediction, and treatment of learning outcomes alongside the \\nprevention of learning losses. \\nThe advent of computer-aided teaching and learning has played a \\nvery important role in the propagation and development of personalized \\neducation. Computer-Based Instruction (CBI) came into the limelight in \\nthe 1950s, especially in developed nations like the United States. \\nHowever, education technologists across the globe started developing \\nprograms to assist tutors and test students around the early 1960s. The \\nteaching machines that were introduced at this time were predomi -\\nnantly contributions from the field of behavioral psychology. Skinner \\n(1958) mentioned key characteristics of teaching machines and pro-\\ngrammed instruction as the arrangement of materials so that the student \\ncould make correct responses and receive reinforcement when correct \\nresponses were made. With the advent of the internet, CBI transitioned \\ninto the broader header of Information and Communication Technology \\n(ICT) which included computer, internet, and electronic delivery sys-\\ntems (Fu, 2013). Flourishing growth of the ICT sector over time has \\nrequired up-to-date and reliable data, and this is where use and analysis \\nof large datasets comes into play. \\nBig Data and Artificial Intelligence (AI) applications have great po-\\ntential to help produce meaningful insights from the datasets to under -\\nstand learning trajectories of students so as to enhance the efficacy of \\neducational systems. From creating customized study material for a \\nparticular student as per their specific learning requirements, to creating \\ncustomized tests and evaluating them; from cautioning an instructor \\nabout potential learning hindrances to answering a student’s questions \\nby simulating a human conversation, the application of data has pene-\\ntrated deep enough into the education system to significantly modify its \\nshape and structure. \\nThis paper aims to assimilate recent research trends on the incor -\\nporation of technology for personalized education in the three top \\nEdTech hubs of the world: the United States, China, and India. This study \\nfocuses on applications of AI and has used a systematic review meth -\\nodology as the first attempt at exploring, curating, and documenting \\nobservational and causal research on the topic across the three coun-\\ntries. The rationale behind using a systematic review is precisely to get \\nrid of technical or semantic digressions caused by the abundance of \\npapers available in the field, and get on board with the thematic changes \\nand work on them for better implementation. Put differently, the major \\nthemes that emerge from this review are intended to guide future re-\\nsearchers both in terms of technological innovations as well as policy \\ndesign, and in turn aim to help in effective implementation of AI- \\npowered personalized education systems. 2.Personalizing education with the emergence of data-driven \\nEdTech \\nPersonalizing education can be considered as an evidence-based \\napproach in educational practice. A personalized system of education \\nis designed to recognize and analyze the individual-specific learning \\nabilities, learning requirements, and study goals so as to customize the \\ncontent delivered accordingly. This customization can be comprised of \\nrevision, reorientation and even reconstruction of an otherwise unified', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 1}),\n",
       " Document(page_content='content delivered accordingly. This customization can be comprised of \\nrevision, reorientation and even reconstruction of an otherwise unified \\ncurriculum. An individual-specific focus can also help to eliminate \\nlearning difficulties of marginalized learners for a subsequent \\nenhancement in teaching and learning productivity (Yonezawa et al., \\n2012). In fact, personalization is not a new concept in the education \\nsector. Terms such as personalizing, matching, or tailoring of educa -\\ntional content have been used interchangeably over time to recognize \\nand better understand the heterogeneity among learners with specific \\nproblems so as to prescribe remedial interventions more precisely. In \\nfact, problem analysis to examine student’s needs is the first constituent \\nof personalized education (Cook et al., 2018). Based on problem iden-\\ntification and diagnosis, solutions can be designed to match students’ \\nlearning requirements and preferences. Here, the application of Educa -\\ntion Technology (EdTech) has given a tactile medium to the education \\nsector for personalization through data. \\nIn the latter half of 1990s and even in the early years of 21st century, \\nEdTech was primarily focused on the receiving end, i.e. to supplement \\nstudent learning through the existing formats of offline teaching (Liu \\net al., 2017). However, recent innovations in data analytics have \\nrendered a feedback system to the teaching-learning process. It means \\nthat the collected learner data provides a much in-depth comprehensive \\nunderstanding of what works best as the most optimal learning envi-\\nronment. This approach has generated the basic idea of using data \\nmining, Big Data, and related technologies in order to personalize ed-\\nucation. Two areas of research should be mentioned here as the building \\nblocks of personalization in the education sector, one is Educational \\nData Mining (EDM), and another is learning analytics. \\nEDM primarily deals with formulating algorithms to have a better \\nunderstanding of the learning environment and make better predictions \\nregarding that. On the other hand, learning analytics mostly caters to the \\nproblem of how to use those algorithms efficiently (Liu et al., 2017). In \\nrecent years, considerable success has been achieved by using learning \\nanalytics where data of students’ responses to certain teaching tech-\\nniques, contents, and learning resources are recorded in vast quantity. \\nThis data is then analyzed for pattern recognition and for building \\npredictive models to prescribe suitable learning choices according to \\ntheir learning characteristics of students. The structural shift towards \\nusing Big Data, EDM, and learning analytics in education has led to \\nimmense possibilities of using AI in the sector (Zhang and Aslan, 2021). \\nInstances of using AI in education include creating interactive \\nPersonalized Learning Spaces (PLS) with a primarily virtual operating \\nmedium that have been found to provide massified access by eliminating \\nthe geographic hurdles to learning. Using such systems anyone can learn \\nfrom any location according to their own convenience. Besides, such \\nsystems can also recommend learning plans based on AI-driven adaptive \\niterations (Xu, D., & Wang, H., 2006). Similarly, an AI-based Intelligent \\nTutoring System (ITS) in the US that personalized educational content \\naccording to the extra-curricular interests of the student showed that \\nsuch an approach in instruction could yield more effective learning \\n(Walkington and Bernacki, 2019). In extension to this, AI-enabled ed-\\nucation has also achieved considerable success in language studies. An \\nempirical exercise conducted on students in Hong Kong (Fryer et al., \\n2017) revealed that AI companions, in comparison with human com-\\npanions are claimed to enhance learning experience in language studies. \\nFurthermore, AI-powered education systems also contribute to \\nimproving pedagogical planning. As an example, a study conducted in', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 1}),\n",
       " Document(page_content='Furthermore, AI-powered education systems also contribute to \\nimproving pedagogical planning. As an example, a study conducted in \\nTaiwan in 2020 can be considered that found AI-driven educational \\nsystems helped reduce learning anxiety among learners by using Abbreviations \\nAI Artificial Intelligence \\nCBI Computer-Based Instruction \\nEdTech Education Technology \\nEDM Educational Data Mining \\nHITL Human-In-The-Loop \\nICT Information and Communication Technology \\nITS Intelligent Tutoring System \\nLDA Latent Dirichlet Allocation \\nNLP Natural Language Processing \\nPLS Personalized Learning Space  A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 1}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n3cognitive performance analysis and deriving a positive feedback loop \\n(Hwang et al., 2020). The key aspect to be noted here is that AI-driven \\nsystems offer a feedback mechanism which intakes data and conducts \\npredictive analysis using predetermined algorithms. \\nMoving forward, learning management systems, learning compan -\\nions, virtual reality, intelligent tutors – are all potential and new-age \\ntools built on the very essence of AI. The interactive nature of AI- \\nenabled learning systems helps to receive feedback and understand \\nthe requirements of the learners on the basis of that and lastly, prescribe \\nsuitable learning choices for the learner depending on predictive algo-\\nrithms. So far, the above discussion gives the reader a glimpse of the \\nexisting literature about application of AI in the education sector. The \\nupcoming sections of this paper will discuss the more up-to-the-minute \\nadditions to the use of AI in education from the standpoint of person -\\nalizing education. It is important to note here that the existing literature \\nhas explicitly acknowledged the requirement of AI EdTech to be more \\nconnected to the mainstream pedagogical structure of the education \\nsystem across the globe. Lack of an education-specific perspective to AI \\nresearch has been clearly mentioned as a limitation in many previous \\nsystematic reviews of literature (Zhang and Aslan, 2021). Keeping that \\nin mind, the main discussion of this review is organized from the \\nstandpoint of how AI infusion is shifting the educational paradigm and \\nshepherding it toward the pedagogical objective of personalization \\nacross the three biggest EdTech hubs: USA, China, and India. \\n2.1. EdTech in USA, China, and India \\nAI is transforming the global landscape and is expected to touch all \\nimportant aspects of human life in the time to come. Building data- \\ndriven intelligent machines to understand, analyze and even simulate \\nhuman behavior is what makes AI the game changer in all the sectors \\nincluding the education industry. Naturally, some of the world’s biggest \\neconomic powers are chasing the crown of leadership and supremacy in \\nEdTech by experimenting with newer techniques to integrate AI into the \\neducation system. Judging by the global EdTech scenario in recent \\nyears, the United States, China and India dominate the competition in \\nthe world to become global EdTech leaders (HolonIQ). Whether it is \\nabout growing EdTech startups or about innovating and developing \\nbetter and more compact AI-driven EdTech; these three countries secure \\nthe top of the leaderboard. \\nThe United States secures the position of being a longstanding and \\nmature incumbent in the global EdTech scenario, with companies like \\nCoursera, Udemy and Masterclass providing service to learners world -\\nwide. China and India - the two booming powerhouses - have also \\nproven themselves to be worthy competitors in the recent years. These \\ntwo countries spend a considerable proportion of their GDP (around 4 \\npercent) on educational development and innovation. As a result, in \\n2019 India and China together represented more than 70 percent of the \\nglobal EdTech capital. Since January 2020, forty-two EdTech companies \\nin China itself secured a combined USD 10 billion equity funding from \\ninvestors as reported by HolonIQ. Yuanfudao, VIPKid, Knowbox are the \\nnotable Chinese EdTech startups in the list of global unicorns. The In-\\ndian learning app ByJu’s is valued at $21 billion as per Holon (2022) \\nwhich is the highest valuation given to any EdTech startup in the world \\nright as of now. Apart from this, five other EdTech companies from India \\nhave secured the position of global EdTech unicorns between August \\n2021 and January 2022, namely: Unacademy, Emeritus, upGrad, Lead \\nSchool and Vedantu. This signifies the importance of India in the context \\nof EdTech research in upcoming years. Overall, the EdTech products', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 2}),\n",
       " Document(page_content='School and Vedantu. This signifies the importance of India in the context \\nof EdTech research in upcoming years. Overall, the EdTech products \\nacross the US, China, and India are all catering to the personalization \\nagenda. However, it is to be noted that although India and China are \\nshelling out a fortune for AI development and smarter educational op-\\ntions, the US still holds a position where EdTech is more inclusive when \\nit comes to on-the-ground proliferation. For instance, American startups \\ncater to a wider variety of needs of the consumers, starting from online \\ncurriculum, career planning, corporate learning, amongst others, while the ones operating in China and India are mostly focused on tutoring, \\ntest preparation and language studies (Horn & Staker, 2016). \\nCoupled with these market-based developments, both Indian and \\nChinese governments have actively participated in this journey. The \\n“New Generation Artificial Intelligence Development Plan” published by \\nthe State Council of China, which released in July 2017, presents an \\noutline of strategies to build a USD 150 billion AI industry with a vision \\nto make China a leader in Artificial Intelligence by the year 2030. Pari \\npassu with these initiatives in China, the central government of India has \\nalso launched a program called “AI for All” as a part of their new Na-\\ntional Education Policy 2020 - which is a self-paced 4-h inclusive \\nlearning program that explains the crux of AI to the common populace. \\nWhile these Asian EdTech giants are taking their leaps forward to \\ncompete with the incumbent, the US government is definitely not \\nlurking behind. Congress and the White House has also documented its \\ndesire to boost AI R&D funding yearly from about USD 5 billion in un-\\nclassified spending in 2020 to USD 25 billion by 2025. Rasser report \\n(2019) also documented that “investment in AI would be around 19 \\npercent of the total federal R&D spending in the budget for the 2020 \\nfiscal year and this investment would be a small price to pay for a key \\ndriver of long-term economic growth”. \\nWith this brief outline on the use and successes of EdTech, especially \\nAI, for personalization our paper explores the recent academic literature \\non the topic and the diversity across US, China, and India using a sys-\\ntematic literature review and natural language processing. The motto is \\nto understand the intent and the forthcoming direction of EdTech \\nresearch in the field of personalizing education in these three countries. \\nTo this effect, we undertake screening, collation, and review of new \\nresearch to understand which trends have continued and what are the \\nareas for future research for personalized education and AI. These steps \\nhave been detailed in the following section. \\n3.Research methodology \\nRecent research has made the role of Big Data and AI very prominent \\nin the education sector. A more individualized learning and assessment \\nsystem powered by Big Data analysis is being massively discoursed. To \\nevaluate where the literature stands on personalized education, Big Data \\nanalysis, and AI in the current context, this study explores:  \\na. The recent status of research on AI and personalized education in the \\ntop three global EdTech leaders: US, China, and India  \\nb. The main areas where AI has been incorporated for personalizing \\neducation  \\nc. The present limitations in the field of AI-enabled education \\n3.1. Systematic review using a Human-In-The-Loop (HITL) model \\nThis study follows a Systematic Review (SR) methodology that in-\\nvolves search, collation, and appraisal of all relevant mainstream and \\nsupplementary AI and Personalized Education (PE) literature for the \\nUnited States, China, and India. An English database - IEEE Xplore is \\nused for this purpose with a time-reference period of 2 years \\n(2019–2021). \\nAn SR is defined as “a review of the evidence on a formulated \\nquestion that uses systematic and explicit methods to identify, select,', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 2}),\n",
       " Document(page_content='(2019–2021). \\nAn SR is defined as “a review of the evidence on a formulated \\nquestion that uses systematic and explicit methods to identify, select, \\nand critically evaluate relevant primary research, and to extract and \\nanalyze data from the studies that are included in the review” (Booth \\net al., 2016). It is different from the traditional narrative reviews in \\nseveral ways. Narrative reviews are mainly descriptive and do not \\ninvolve a systematic search of the literature. They also often focus on a \\nsubset of studies in an area chosen based on the availability or author \\nselection. Narrative reviews are mainly informative and create the \\nproblem of selection bias. Systematic reviews typically involve a \\ndetailed and comprehensive plan and search strategy derived a priori, A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 2}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n4intending to reduce bias by identifying, appraising, and synthesizing all \\nrelevant studies on a particular topic (Popay et al., 2006). \\nThe steps that were followed to undertake the systematic review for \\nthis study are listed below and also illustrated briefly through Figure A1 \\nin Appendix.  \\ni. The first stage was to formulate the review questions and a review \\ntitle - aspects that are discussed earlier in this paper.  \\nii. The second stage was to define exclusion and inclusion criteria. Such \\ncriteria that we used in our study are mentioned below: \\nInclusion Criteria (IC):  \\n⁃ Papers published in listed academic journals including conference \\npapers  \\n⁃ Papers that were mainly focused on personalized teaching and \\nlearning \\n⁃Papers talking about various applications of AI and Big Data Ana-\\nlytics in education sector  \\n⁃ Papers mentioning challenges of integrating AI in the education \\nsystem \\nExclusion Criteria (EC):  \\n⁃ Papers that were published in magazines, books \\n⁃Papers that were focused on secondary studies like survey, re-\\nviews, posters, tutorials etc.  \\n⁃ Papers that were included and focused on topics like “medical \\neducation”, “robotics education”, which are based on technical \\ndisciplinary knowledge  \\n⁃ Papers that were more focused on computer sciences theories \\nonly including deep learning and other methods and applications \\nof AI.  \\niii. The third stage was to develop search strategies that focused on \\nthe list of relevant keywords. For example, in this study across all \\nthree selected countries, articles were selected based on key-\\nwords such as: education, learning, teaching, and artificial \\nintelligence.  \\niv. The fourth stage was to select the subset of relevant studies. After \\nsearching articles or papers with the help of the keywords, \\nretrieval and review of a detailed list of abstracts and studies were \\nperformed. After obtaining the papers for each of the countries \\nand minimizing duplication, an ML-based text mining technique \\nwas used to remove punctuation marks and “stop” words to clean \\nthe abstracts. Here, a Lemmatization process was also used where \\nwords in third person were changed to first person and verbs in \\npast and future tenses were changed into present.  \\nv. The fifth stage involved running the Latent Dirichlet Allocation \\n(LDA) process, a commonly used ML technique for topic model -\\nling. This process helped to create multiple groups of “bags of \\nwords” each of which form a topic. We limited our study to 10 \\ntopics. \\nvi.The sixth stage included exploring the different LDA character -\\nistics like “number of topics”, “number of words per topic”, \\n“coherence value” etc. to ensure that we are able to identify the \\nmost relevant topics for our study. This process also helped us to \\nreject the papers that were evidently a part of the areas under our \\nexclusion criteria or those out of scope for this study.  \\nvii. The seventh stage included selecting the main relevant topics for \\nthis study. Three main topics focusing on “student” and “teach -\\ners” and “use of technology” (yielding a total of 999 papers) were \\nused for further analysis in this study. A second stage LDA was \\napplied to these 999 papers to develop a list of 25 sub-topics. Of \\nthese the main sub-topic (353 papers) that covered the maximum \\nnumber of papers and also focused on “student”, “teacher”, “education”, “use of AI”, and “personalization” were selected for \\nfurther consideration and analysis.  \\nviii. The last stage included an analysis of these selected papers \\nincluded reading the abstracts/key words of all the selected pa-\\npers i.e. 353 papers and identifying broad themes from these \\npapers. Of these, the papers that were fully read are listed in the \\nAppendix in Table A1, out of 353 papers, 336 were read, 17 were \\nnot found to be relevant to the paper’s research topic and were \\nleft out of analysis. Papers that explicitly discussed “application', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 3}),\n",
       " Document(page_content='Appendix in Table A1, out of 353 papers, 336 were read, 17 were \\nnot found to be relevant to the paper’s research topic and were \\nleft out of analysis. Papers that explicitly discussed “application \\nof AI in education” were read in full. The writing process involved \\nsummarization of the key observations from the literature, indi-\\ncating the recent research trends in AI-enabled personalized ed-\\nucation. The writing exercise also included identifying and \\nsummarizing the limitations of the literature thus providing \\nfuture research opportunities.2 \\nKey procedures followed under Steps (iii)-(viii) are discussed in \\ndetail in the section below. \\n4.Analysis \\n4.1. Search process and data extraction \\nFor this review, the papers were collected from IEEE Xplore and it \\nwas last searched on June 11th, 2021.3 As the initial stage of the search \\nprocess, the keywords relevant to the present exercise were used in the \\nsearch string for extracting relevant papers. Those keywords are stated \\nbelow: \\n“Education” AND “Learning” AND “Teaching” AND “Artificial In-\\ntelligence” AND “China” (or “USA” or “India”). \\nMainly journal articles alongside conference and early-access papers, \\nwhich were published from January 2019 to June 2021, were collected \\nfor this exercise. Web Scrapping was employed for extracting and \\nexporting the data. This allowed the citation information to be collected, \\nincluding aspects like: Title of the paper; Authors’ names; Abstract of \\npaper; Publication year; Publishing place; and Publisher name. \\nA total of 2067 journal articles covering literature from United \\nStates, China, and India were collected. Out of these, 600, 1133, and 336 \\npapers were extracted using the search terms: the United States of \\nAmerica, China, and India respectively and these were appended \\ntogether into a single database. Following this, exact duplicate entries \\nwere identified and removed. This left 1709 papers for further \\nexploration. \\n4.2. Topic modelling \\nIn order sieve out the key themes emerging across the abstract of \\n1709 papers, a text-mining approach using Natural Language Processing \\n(NLP) known as “topic modelling” was used. Topic models are “proba -\\nbilistic models for uncovering the underlying semantic structure of a \\ndocument collection based on a hierarchical Bayesian analysis of the \\noriginal texts” (Blei and Lafferty, 2009). The core idea of the topic \\nmodelling step is to identify keywords and groups of keywords that \\ndescribe the content of the set of publications returned from the paper’s \\nsearch query. Topic modelling identifies the groups of words that are \\nlikely to occur together and represent a specific topic. The most \\ncommonly used topic modelling method for modelling the document \\ncollection (corpus) is the LDA, which is an unsupervised generative \\nprobabilistic method. \\n2 As a next step to this paper, a sub-topic selection using the 999 papers \\nwould be undertaken for developing the writeup on each of the discussed \\nthemes.  \\n3 IEEE is the world’s largest technical professional organization dedicated to \\nadvancing technology for the benefit of humanity. A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 3}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n5To prepare the data extracted from abstracts for running the LDA \\nmodel, it was important to first clean and organize the text. To this ef-\\nfect, all punctuation marks, html tags, whitespaces, and duplications \\nwere removed from the abstracts by using the “gensim” package in Py-\\nthon alongside the commonly used method of “lemmatization”. Lem-\\nmatization combines all similar words into their root words, thus \\nenhancing data efficiency. Finally, common stop-words were also \\nremoved. Post cleaning and coding, the LDA was used to identify words \\nthat would together represent a common topic/theme. The LDA learns to \\nmodel the topics by going through each document and cluster bag of \\nwords that have a high likelihood of term co-occurrence. By analyzing \\nthe words that describe a cluster, the researcher can then interpret the \\nunderlying topic for each cluster. \\nLDA helped to generate 10 topics, of which only three broad topics \\nwere relevant for our analysis, given our research questions. The bag of \\nwords associated with these topics are provided in Appendix II. The \\nthree topics collectively covered 999 out of the 1709 papers. Next, using \\nthese 999 sub-selected papers, we re-ran a second-stage LDA to deter -\\nmine more precise sub-topics for further analysis. Fig. 1 presents the \\nresults from the second-stage LDA. \\nAfter this exercise was done, the topic that was found to be most \\napplicable to studying personalized education (teaching and learning) \\nand the use of AI was the one highlighted in red in Fig. 1 i.e. topic 1.4 The \\nleft-hand side in the figure represents the inter-topic distance showing \\nthe marginal topic distribution of each topic. The horizontal bar chart \\nrepresents top 30 most relevant terms under topic 1, along with its \\nestimated term frequencies. The closer the circle with each other the \\ngreater is the chance of getting overlapped words under each topic.5 \\nTopic 1 included all the relevant papers on student-technology and \\nteacher-technology interactions. The derived “bag of word” contained \\nunder this topic were: \\n“teaching”; “technology”; “education”; “development”; “informa -\\ntion”; “paper”; “college”; “application”; “quality”; “mode\". \\nThe selected sub-topic had 353 papers, which were read in full. \\nOverall, this process set the right direction for the upcoming discussion \\nwhich revolves around “technological development” i.e. AI and Big Data \\nanalysis in particular in reforming the education sector. As mentioned \\nearlier, the main focus is on “personalized education”. \\n5.Review and trends from the selected literature \\n5.1. Status of the IEEE xplore publications on AI and personalized \\neducation in the top three global EdTech hubs: US, China, and India \\nChina has leading number of recent publications in IEEE Xplore on \\nthe use of AI in education, compared to India and the US (see Fig. 2). \\nAmong the final list of 353 papers selected through topic modelling, \\n272 papers (77 percent) included China in their analysis. It is evident \\nfrom this particular observation that although, so far the Chinese \\nEdTech market has catered to tutoring and language studies and other \\nbasic requirements of the students, the researchers have experimented \\nwith a wide array of possibilities incorporating AI and personalization of \\neducation. So far this has not been reflected well in the market scenario \\nand cannot be captured just by giving a glance on the Chinese EdTech \\nmarket, but its effect is most likely to be observed more dominantly in \\nthe upcoming years. In other words, Chinese literature talks elaborately \\nabout implementation of different AI tools in vast and varied educational disciplines. According to the requirements of any particular \\nfield - which includes engineering to music lessons and of course, lan-\\nguage studies - suitable tools are deployed to enhance learning experi -\\nence. Compared to that, research catering to the Indian domain of the', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 4}),\n",
       " Document(page_content='guage studies - suitable tools are deployed to enhance learning experi -\\nence. Compared to that, research catering to the Indian domain of the \\nliterature mostly talks about a supplementary system to enhance the \\nperformance of the existing traditional schooling system through a \\nchoice of personalization. In fact, Indian literature has also contributed \\nto the discussion of personalization through some administrative usage \\nof AI in this particular work as well. A part of Indian literature can also \\nbe connected to the sudden compulsion of using the virtual mode of \\neducation after the recent worldwide pandemic. This observation tallies \\nwell with the current EdTech scenario in India mentioned in the earlier \\nsection of this paper. Even though a number of EdTech unicorns are \\nharboring in India, the general direction in which they are operating, is \\nmostly tutoring and working as a supplement to the existing traditional \\nsetup of learning. \\nApart from China and India, the US literature talks about varied \\napplication of AI in different disciplines as well, starting from vocational \\neducation, engineering education, K-12, preschooling and so on, the \\narguments can be similar as China, however, the quantity of papers on \\nthe US is relatively lower over the 2020–21 period. In addition to the \\npublication bias (given we have only looked at the literature published \\nin IEEE Xplore), one of the reasons that can be hypothesized is the \\nincumbent status of the US in the field of AI-driven EdTech. The US \\nalready offers diverse array of EdTech services to its learners as \\nmentioned before which gives it its incumbent status. Therefore, it can \\nbe said that only further significant innovation of AI can give the system \\na significant boost in the US education system. \\n5.2. The main areas where AI has been incorporated for personalizing \\neducation \\nThe recent trend of personalization in education sector reforms calls \\nfor a suitable apparatus to analyze behavioral patterns based on data in \\norder to recognize individual specific requirements leading to enhanced \\nstudent performance. Big Data analysis and AI being the colossus of \\nmodern technological innovations, provide an efficacious way of \\n“extracting useful insights from complex heterogeneous datasets to \\nimprove decision making through diagnostic, prescriptive and predic -\\ntive features” (Al Hadwer et al., 2019). Big corporations like Netflix and \\nAmazon use this technique to predict a particular consumer’s set of \\npreferences and recommend suitable products accordingly. In another \\nway, one can think of it as a utility maximizing exercise where a com-\\nputer algorithm tries to incorporate all the factors affecting a particular \\nperson’s utility with the help of an existing database, and tries to pre-\\nscribe the best among the available basket-of-goods based on its \\njudgement, in order to maximize that person’s utility. Therefore, \\nbecause of this very nature of the technique itself, it possesses the po-\\ntential to morph the education sector in the way intended. However, \\nsuch a technique is relatively new and demands rigorous research about \\nscopes, areas of application, and feasibility criteria for effective \\nimplementation. \\n5.2.1. Student-centered learning solutions \\nAs discussed at the very beginning of the paper, the substantial \\nparadigm alteration toward personalization is primarily motivated by \\nthe remissness of the traditional setup to concede the heterogeneity \\namong students and the subsequent hindrances in learning. There is \\nnothing but undisguised distinctive nature of human beings behind this \\nnotion. Learning requirements for a set of students cannot be identical. \\nIn the traditional system, the instructor holds a pivotal position and \\ninstructs the entire set of students according to the curriculum. Evidently \\nthe instructor, the curriculum, and the instructor’s pedagogy of \\ncommunicating the curriculum to the students become the fulcrum of', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 4}),\n",
       " Document(page_content='the instructor, the curriculum, and the instructor’s pedagogy of \\ncommunicating the curriculum to the students become the fulcrum of \\nthe entire system. In reality it is observed that some students in fact find \\na guided, structured way of teaching helpful while others benefit from 4 Selection of topic 1 was also validated through a manual check by reading \\nall the paper abstracts. The other topic identified through the second-stage LDA \\nincluded aspects of AI use in other disciplines or generic educational problems \\nrather than a combination of AI and personalized education – which is the main \\narea of focus for this paper.  \\n5 This is an interactive visualization. By changing topic number top 30 words \\nfor each topic can be seen. A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 4}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n6opportunity of self-motivated exploration and discovery (Tang et al., \\n2020 ). Therefore, it becomes increasingly important to assess the \\nrequirement of a particular student, or a group of students and build a \\ncollaborative structure where the primary focus will be on a student ’s \\nlearning requirements. This is likely to provide a much more engaging \\nlearning experience and thus reduce the risk of failure or dropout (Al \\nHadwer et al., 2019 ). In brief, the learning will become more \\n“student-centered ”. \\nThis dire necessity to accommodate individual specific factors in the \\neducation system brings AI into the scenario as the building block of the \\nnew generation education system. AI, coupled with the existing tech-\\nnological involvement in the sector, is directed to systematically modify \\nand redesign certain crucial components of the education system to \\ncapture and accommodate individual-specific factors. This theory-of- \\nchange supports its contribution to the overall enhancement of the \\nlearning experience across all levels of education, namely: preschool-, \\nprimary and secondary school-, vocational-, and tertiary-levels. This is \\nfurther discussed in the following sections. 5.2.2. Incorporation of learning abilities and habits \\nAI has been found to ease the herculean task of administering com-\\nplex exercises on massive datasets while retaining the heterogeneity \\ntalked about earlier. This qualifies AI as the driving force behind a \\npersonalized education system - since it liberates a system to provide an \\ninclusive platform for all types of learners. AI-powered personalized \\nlearning enables a student-centered educational ecosystem which stands \\non two pillars (Horn and Staker, 2016 ). One relates to catering to the \\nspecific needs of every individual student by means of personalizing and \\ncustomizing the study material; the other involves taking account of the \\nlearning ability of any individual student. Every single student has a \\nunique learning attitude, intention, and motivation to learn with varying \\nlevels of foundational skills and knowledge requirements to ensure the \\neffectiveness of learning. The recent literature across the US, China, and \\nIndia discusses that Artificial Intelligence can comprehensively record \\nand track different learning characteristics of learners and recommend \\nsuitable teaching and learning strategies based on an individual ’s spe-\\ncific learning characteristics (Liang and Hainan, 2019 ). This trans -\\nformation ensures that the students, the protagonists of the education \\nsystem, do not remain on the passive side (Tong et al., 2019 ). Unlike \\nbeing hyper-focused only on the scores as learning outcome, AI-powered \\nsystems have been found to be capable of including even the smallest \\nindividual-specific factors (such as the level of concentration in class, \\nparticipation in learning activities, and even some non-cognitive skills \\nsuch as communication or in-class behavior). This is where the paradigm \\nshifts, the system gets pushed toward personalization and its overall \\nefficiency is enhanced. Identification and incorporation of different \\nlearning styles (visual, auditory, reading/writing/kinesthetic), learning \\nhabits (regular tendencies of students which could be learning condu -\\ncive - such as being organized and taking notes in class, or not – making \\nsystematic mistakes while problem-solving), and the learning pace of \\nstudents enables an AI-powered system to recommend personalized \\n“learning paths ”. A brief summarization can be done by highlighting the \\nfact that the recent literature singularly resonates that AI provides a \\ntangible way of recognizing and integrating the previously neglected \\nheterogeneity among learners. In other words, an “average ” student in \\nFig. 1.Topic Modelling using LDA (Latent Dirichlet Allocation): Snapshot of the Model Results.', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 5}),\n",
       " Document(page_content='heterogeneity among learners. In other words, an “average ” student in \\nFig. 1.Topic Modelling using LDA (Latent Dirichlet Allocation): Snapshot of the Model Results.  \\nFig. 2.Distribution of papers among three countries.  A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 5}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n7terms of overall scores can be “excellent” in terms of one particular \\naspect while very plausibly be “poor” in another. \\n5.2.3. Learning paths \\nThe analogy of utility maximization given at the very beginning of \\nthis section mentions an optimal choice of “basket-of-goods” which \\nmaximizes utility, i.e. to say that it provides the most efficient way of \\ngetting the most out of the learning experience. This can be called a \\n“learning path”. AI-enabled “smart” machines, trained by analyzing \\nexisting data, have been reported to discern behavioral patterns among \\nindividuals, identify each factor responsible for learning experience and \\nlearning outcome and “predict” future moves and outcomes of an indi-\\nvidual learner based on that analysis. This allows an AI-system to clas-\\nsify learners on the basis of those factors and recommend suitable \\nlearning choices as per the capabilities of any particular learner by \\npredicting their moves. \\nEmpowered by innovations e.g. data-mining which uses results from \\ndifferent exercises and uses it to extract valuable information implicit in \\nindividuals from large, unstructured and random data set (Wang et al., \\n2019) the system gains adaptive ability that can identify learners with \\nsimilar characteristics and classify them (Wang et al., 2019); as well as \\nrecommend a learning path to a future learner. The system’s ability to \\nadapt to specific requirements and abilities of a particular learner en-\\nables the recommended learning path to enhance the learning effect of a \\nlearner pushing the performance over the learner’s initial choice of path \\n(Li and Zhang, 2019). Besides, pinpointing strong and weak points of a \\nparticular learner can work as a measure to eliminate learning \\ndifficulties. \\n5.2.4. Diagnostic and predictive solutions instead of remedial solutions \\nClearly, AI offers an easement in detecting and addressing the \\nshortcomings of an individual by proposing countermeasures based on \\nthe data analysis (Li and Wang, 2020). However, the role of data analysis \\nis to be emphasized at this point. A preemptive “diagnosis” of data brings \\nup “predictive” measures. This is what sets AI-enabled education way \\napart from the traditional approach. The “diagnostic” and “predictive” \\nnature of the system opens up a new horizon. Instead of stumbling upon \\nlearning difficulties resulting in grave consequences like failure or \\ndropout, AI makes it possible to raise a flag of caution beforehand, \\ngiving a chance to implement the solutions as a preventive measure, not \\na remedial measure (Tong et al., 2019). More importantly, the “diag -\\nnostic” feature of the system also helps detecting and monitoring the \\nroot causes of the problems, thus addressing it at a nascent stage. \\nTherefore, it works as a proficient monitoring medium to caution any \\nupcoming difficulties, fine-tuning the education management for all \\ninvolved agents (Luo, S. 2019). \\n5.2.5. Augmenting educational content \\nSetting aside the role of AI as an overseer of the education system - \\noptimizing educational environment, the literature is vastly vocal about \\nits unmediated involvement in the learning process itself. Beginning at \\nperforming utterly generic tasks e.g. outlining the subject matter of a \\ntextbook to workable create study guide (Mondal, K., 2019); using data \\nfueled assessment prowess, AI builds “Intelligent Examination Systems” \\nwhich uses automatic computer-aided evaluation for higher efficiency. \\nSuch systems are capable of a wide variety of tasks which includes \\nsetting up customized test for a particular respondent, conducting \\nremote examinations, evaluating subjective and technical answers, and \\nso on (Li and Wang, 2020). In fact, AI-integrated software like Grade -\\nscope can assess an answer to a question as well as can judge the merit of \\na piece of writing. This quick glance at the grassroots assimilates the vast', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 6}),\n",
       " Document(page_content='scope can assess an answer to a question as well as can judge the merit of \\na piece of writing. This quick glance at the grassroots assimilates the vast \\nliterature’s take on AI powered educational resources which “carry the \\ndissemination of teaching content and the organization of teaching ac-\\ntivities” (Zhao et al., 2020). This is why AI has secured its place in \\naugmenting educational content - either by supplementing the tradi-\\ntional classroom teaching or by simply being a self-sustaining host of some learning activities. In both cases, the bigger picture of personal -\\nizing the education sector remains in the foreground. Whether it is \\nlanguage studies, vocational training or physical education, AI has \\nactive involvement in all of them. AI can work as a referee or a coach on \\nthe ground, Deep Learning enabled “Nine Songs” can generate Chinese \\nclassical poetry, Google’s Magenta and Sony’s Flow Machines can \\ncompose music using algorithms - the list goes on (Xu et al., 2020). \\nEvidently, AI contributes to a substantial transformation of the educa -\\ntional content - sometimes optimizing the English teaching environment \\nto get the most out of classroom teaching (Hui, Q., 2020); and sometimes \\nby optimizing engineering education curricula based on the objectives of \\nthe course (Chen et al., 2019). \\n5.2.6. Incorporation of non-cognitive skill development \\nIndisputably, contribution of AI has not been straitjacketed into \\ncurriculum development and outlining textbooks. Built in the fabric of \\nBig Data analysis, AI represents educational content embodied in a \\nnarrative game environment to guide the learner in a self-directed path \\nof learning - also known as “gamified learning”. A simulated environ -\\nment is used to judge the knowledge and requirement of a player \\n(learner) (Tang et al., 2020). Pilot results on student contests and in-\\nterviews of focus groups point out that simulation-based virtual learning \\nenhances strategic thinking and problem-solving skills of the learners. \\nThe most advanced development in the field of simulation is Virtual \\nReality or Augmented Reality (VR or AR). With the help of appropriate \\nhardware and software, it is possible to build an interactive simulated \\nenvironment providing and immersive experience appropriate for \\nparticular instruction purposes (Fan and Zhi, 2020). A real time flawless \\n3D simulation pushes the pedagogical experience beyond the limitations \\nof space-time and can give access to otherwise inaccessible experiences \\nin classroom teaching. This contributes massively to skill development \\nand helps configure real world ideas in a risk-free way (Joseph et al., \\n2020). \\n5.2.7. Recalibrating the role of instructors \\nAs discussed so far, systematic modifications in educational content \\nsubstantiate significant changes in teaching methods. Not surprisingly, \\nthe role of instructors is recalibrated under this new paradigm. Access to \\nMOOCs (Massive Open Online Courses), delivery of knowledge through \\neLearning platforms, cloud classrooms etc. construct a platform for \\nsharing teaching resources (Feng et al., 2019). Clearly, in the era of AI, \\ninstructors are no longer expected to be only information providers, \\neven in developing countries like India. Advancements in AI-powered \\nassessment systems and content augmentation has been found to free \\nup the instructors from the monotonous and repetitive tasks of preparing \\nlesson plans and grading answer sheets. The teaching mode becomes \\nblended with development of flipped classrooms where activities like \\nrecording attendance and designing quiz for the students is handled by \\ncomputers (Liu, X., 2019). Most importantly, since teachers are relieved \\nfrom the repetitive tasks, they can employ their creative and critical \\nfaculties in becoming facilitators and learning motivators, design better \\ncurriculum etc., which contributes to the all-round holistic development', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 6}),\n",
       " Document(page_content='faculties in becoming facilitators and learning motivators, design better \\ncurriculum etc., which contributes to the all-round holistic development \\nof the education system. For instance, Third Space Learning (Tong et al., \\n2019), an AI-enabled platform, was found to reduce teachers’ workload \\nin China. Identifying target students, arranging lecture materials, and \\npreparing lecture notes all used a significant amount of time of teachers. \\nBy leaving these repetitive tasks for the computers to do, an average \\ninstructor was found to save 10 h 50 min per week. This additional time \\nwas reported to be used for building harmonious and solid \\nteacher-student relationships and promoting overall long-term student \\ndevelopment. \\n5.2.8. Incorporation of learning companionship \\nThe literature distinguishes weak Artificial Intelligence from Artifi -\\ncial General Intelligence (AGI). Here AGI represents flexible machines \\nthat can simulate human interaction instead of being trained in one A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 6}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n8repetitive task committed to one single objective. An application of such \\ntechnology is a “chatbot”. A chatbot is an AI-based software that can \\nsimulate human conversation over telephonic and textual platforms \\n(Ranoliya et al., 2017). In the context of the Indian higher education \\nsector, the application of chatbot - independent of the age, gender and \\nlevel of education of the user - delivers a number of benefits. In the era of \\npersonalized learning, an AI chatbot works as a personal learning \\ncompanion. There are chatbots which provide a stimulus in question \\nform, assess the answer given by a learner, and gives feedback. It un-\\nderstands the “need and speed” of an individual learner, reflects on the \\nperformance and provides learning motivation; in short the actions of a \\nchatbot can be categorized in three stages, initiation, discussion, \\nresponse and feedback. Apart from being directly connected to the \\nteaching and learning activity, chatbots provide student guidance and \\nassistance thus contributing to the administrative side of the education \\nsector as well by answering FAQs, resolve problems related to admission \\nprocess, fee payment etc. Chatbots give the students an easy and effi-\\ncient way of communicating with the institution which eases the \\nadministrative workload for any institution. \\n5.3. Present limitations in the AI-enabled personalization \\nA transformation from the traditional one-size-fits-all to a more \\npersonalized structure of learning is surely a key to rebuild the next- \\ngeneration education system. However, as the discussion primarily re-\\nvolves around the incorporation of AI and similar advanced technolo -\\ngies, which are relatively new in the education sector, it is expected to \\nhave a set of new challenges as well. While the existing literature under \\nreview provides a basic outline of some of those challenges, a more \\nelaborate and detailed exploration of the same is definitely left for future \\nresearch. \\nIn its very nature, a personalized learning system is a self-motivated \\nsetup where a set of adaptive learning tools are available for the learners \\nto adjust to their personal preferences and skills. Despite the availability \\nabundance, “motivation to learn” is not guaranteed by this system. This \\nis where the role of instructors as motivators come into play and that \\nbecomes different from what it traditionally was, yet even more crucial \\nthan before in this new system. \\nIt is to be rightfully noted here that AI integration is not a very simple \\nprocess. For example, collection of data, cleansing and effectively using \\nthe data to draw insights is a complicated task which requires a func-\\ntioning, reliable and effective frameworks. \\nFurthermore, Big Data and AI integrated systems are tech-heavy. \\nWhich requires significant amount of digital equipment and other sup-\\nporting infrastructural modifications for a successful implementation. In \\nfact, on the user-end, it requires training for the agents involved in the \\nteaching-learning process to adapt to this new system. Therefore, not \\nonly it requires professional experts to design and implement a digitally \\nequipped system, but also it requires some additional training for the \\nend-users to make the system operational. \\nIn the countries considered in this study, namely USA China and \\nIndia, there is a significant difference in technological literacy, access to \\ndigital equipment, and availability of proper infrastructure. Hence, \\nimplementing EdTech - despite being a fascinating prospect and a game \\nchanger - does have a possibility of creating a serious learning inequality \\nin terms of opportunities and affordability in high- and low-income \\ncountries. \\nAnother question that arises in this context is that even if EdTech and \\nAI enabled education is made available, will it be affordable by \\neveryone? Will the low-income groups of the economies will be able to', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 7}),\n",
       " Document(page_content='AI enabled education is made available, will it be affordable by \\neveryone? Will the low-income groups of the economies will be able to \\navail this newer form of education? Therefore, AI-enabled personalized \\nlearning, while rolling out a series of significant quality upgrade over the traditional setup, also demands a significant investment for a system to \\nbe functional. \\nWhile accessibility, affordability and feasibility are primary concerns \\nabout widespread application of EdTech worldwide, the literature re-\\nmains mostly, but not completely silent about the unforgettable issue of \\ndata privacy and data security. Personal data of the agents involved in \\nthe teaching-learning process is what fuels an AI driven system. Ergo, it \\nbecomes extremely important to stay vigilant for any sort of potential \\nbreach to ensure that the privacy remains protected. The incident of \\nGnosticplyers stealing 932 million user records from 44 companies in \\nChina (Tong et al., 2019) does prove the presence of a potential threat \\nwhile operating an AI powered system. For instance, while using a \\nChatbot in order to resolve some issues with fee payment, one might feel \\nthreatened that sensitive information e.g. bank details and credit card \\nnumbers are not in the safe hands. Therefore, added attention toward \\ndata security and stronger data protection laws are of immense impor -\\ntance. It is important not only to prevent potential disruptions in the \\nsystem, but also to earn people’s trust so they do not feel anxious or \\nhesitated to switch to a new system. \\n6.Conclusion \\nFor the past two years, the educational technology literature has \\nexplored different ways of incorporating AI in education with the \\nagenda of making education more personalized. The literature clearly \\nmentions that the distinctive features of human beings call for the ed-\\nucation sector to marshal its attention toward individual specific \\nlearning requirements of the learners. This motivates the shift from the \\ntraditional “one size fits all” to a personalized format of learning. The \\nkey idea is to switch the spotlight from the curriculum and instructors to \\nthe students; i.e. to make the system more “student centered”. This \\nmeans instead of compelling the students to fit in the curriculum and the \\ninstructions, which was the case earlier, this new system is designed to \\nadjust the curriculum and instructions according to the learning re-\\nquirements and learning abilities of a particular student. Catering to a \\nlearner’s specific needs is likely to motivate the general populace of \\nstudents. \\nThe literature makes another important observation about modern \\nEdTech systems. The essence of Artificial Intelligence makes the systems \\noperate in a “diagnostic” and “predictive” framework; enabling them to \\ntake precautionary measures against learning difficulties and their root \\ncauses on a preemptive basis. \\nWhile the exercise was initiated to personalize learning, it is evident \\nthat technological innovations have taken it one step further. By aug-\\nmenting educational content, providing platforms to share teaching \\nresources and bringing in technologies like VR, Artificial Intelligence \\ntruly changes the paradigm of education to a massive extent - making \\nthe system more interactive, engaging and motivating for the learners. \\nDespite the promising ground of personalized learning, AI enabled \\neducation has its obvious shortcomings. Data privacy issues, availability \\nof digital resources and affordability constraints surely come in the way \\nof promoting such systems for day-to-day practice. Therefore, with the \\ncurrent discussion about the positive sides of EdTech, the question of \\nlearning inequality does not vanish, rather it becomes more pronounced \\nthan before. This discussion demands more attention to ensure \\ndisruption-free, reliable and effective application of AI in EdTech. \\nDeclaration of interests \\nThe authors declare that they have no known competing financial', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 7}),\n",
       " Document(page_content='disruption-free, reliable and effective application of AI in EdTech. \\nDeclaration of interests \\nThe authors declare that they have no known competing financial \\ninterests or personal relationships that could have appeared to influence \\nthe work reported in this paper.  A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 7}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n9Appendix I \\nThe steps followed for the systematic review are explained in Figure A1.\\nFig. A1.Steps followed for the systematic review.  \\nAppendix II \\nLDA topics \\nListed below are the three selected relevant topics from the first-stage LDA (with 999 papers): \\nSelected Topic 1: “student ”, “teacher ”, “factor ”, “program ”, “influence ”, “assessment ”, “year ”, “management ”, “outcome ”, “describe ” \\nSelected Topic 2: “learn ”, “learning ”, “student ”, “user”, “base ”, “paper ”, “provide ”, “system ”, “design ”, “help ” A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 8}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n10Selected Topic 3: “technology ”, “education ”, “development ”, “system ”, “new”, “application ”, “teaching ”, “paper ”, “teach ”, “information ” \\nAppendix III \\nList of papers covered in the Systematic Review are detailed in Table A1.  \\nTable A1 \\nDetails of papers covered in the Systematic Review  \\nTitle of the Paper Author Year \\nDesign and Development of self-Adaptive Learning System Based on Data Analysis Shan Meijuan; Yang Kaili 2020 \\nEco-Environment Construction of English Teaching Using Artificial Intelligence Under \\nBig Data Environment Maohua Sun; Yuangang Li 2020 \\nMassive AI based cloud environment for smart online education with data mining Ying Pei; Gang Li 2021 \\nThe Construction and Discussion of Smart Learning Environment in the Context of 5G Chen Chen; Sha Kun; Wang Yaping; Wang Yue 2020 \\nResearch on Individualized Teaching Based on Big Data Mining Jie Jiang; Lei Zeng 2019 \\nThe Exploration of the Application of VR Technology in Music Education under the \\nBackground of Internet+Duanping Gu; Fangyi Li 2020 \\nResearch on Music Teaching Reform and Innovation Development in the Era of Big \\nData Fangyi Li 2020 \\nAn Applied Research on Big Data Analysis and Mining Technology in Education Yanjie Wang; Chengpo Mu; Xuejian Li; Yu Yang 2019 \\nThe Optimization and Application of Blended Teaching Based on Artificial Intelligence Gu Zheng 2020 \\nImplementation of Online Guiding Framework based on Multimedia and PHP under \\nthe Influence of New Coronavirus Yanxia Zhang; Xiang Gao 2020 \\nCurriculum Reform in Big Data Education at Applied Technical Colleges and \\nUniversities in China Xin Li; Xiaoping Fan; Xilong Qu; Guang Sun; Chen Yang; Biao Zuo; Zhifang Liao 2019 \\nDebate with Maps: A new Pedagogical Architecture Marcos Paulo Drago Lovati; Camila Zacch ´e de Aguiar; Tˆania Barbosa Salles Gava; \\nDavidson Cury 2019 \\nAssessment of Smart Learning Environments in Higher Educational Institutions: A \\nStudy Using AHP-FCE and GA-BP Methods Zhicheng Dai; Chengzhang Sun; Liang Zhao; Zhi Li 2021 \\nResearch on Higher Vocational Teaching Quality Improvement Based on Educational \\nBig Data Ya Wang; Yanmei Yang 2020 \\nResearch on the Value of Smarter Education in the Era of Big Data Jie Jiang 2020 \\nThe Construction of Accounting Curriculum System Based on Artificial Intelligence \\nTechnology Yao Xu 2019 \\nDesign and Implementation of Dance Teaching System Based on Unity3D Feng Tian 2021 \\nA Study on the Training Mode of Preschool Education Talents in the Age of Artificial \\nIntelligence Lu Liu; Feng Xie; Ruyu Tan 2020 \\nApplication of Internet +Big Data and Artificial Intelligence in Vocational Education Wenying Zeng; Siqi Kang; Binning Li 2019 \\nExploring and Evaluating the Scalability and Eficinecy of Apache Spark Using \\nEducational Datasets Jian Zhang; Zijiang Yang; Younes Benslimane 2019 \\nResearch and practice of the application of information means in the teaching of \\nindustrial design in the background of information Ying Lin; Yue Sun 2020 \\nExploration of Multi-level Virtual Simulation Digital Printing Experiment Teaching \\nModel Wang Shi 2020 \\nConstruction of College English Ecological Teaching Mode under Computer Network \\nEnvironment Zhao Hua 2020 \\nConstruction of Accurate Teaching Model Based on Intelligent Teaching \\nTools ——Take the Rain Classroom As An Example Yuting Zhao; Yiyan Lei; Meng Li; Dongqiu Xin 2020 \\nThe Construction and Practice of Mixed Teaching Mode of Software Engineering for \\nNew Engineering Mengzi Zhang; Shaowei Zhang; Xiande HU; Shuying Liu 2020 \\nTowards an artificial intelligence strategy for higher education in Saudi Arabia Majdi Elhajji; Abdulaziz S. Alsayyari; Adel Alblawi 2020 \\nResearch on Teaching Process Management and Quality Monitoring System for Higher \\nEducation Zheng Liu; Gao Shanshan; Shaojing Yuan 2019 \\nDiscussion on Online Teaching Mode of Colleges and Universities under Multi- \\nplatform Integration Feng Ling 2020', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 9}),\n",
       " Document(page_content='Education Zheng Liu; Gao Shanshan; Shaojing Yuan 2019 \\nDiscussion on Online Teaching Mode of Colleges and Universities under Multi- \\nplatform Integration Feng Ling 2020 \\nTeaching Practice of C Language Based on SPOC Wenping Chen; Li Xu; Chaofeng Guan 2020 \\nResearch On The Innovation Mechanism Model Of Education Management Under The \\nBackground Of Artificial Intelligence Technology Cao Fengchao; Peng Xuewen 2020 \\nTeaching Exploration on the Deep Integration of Artificial Intelligence and \\nInformation Technology with Online Experiments Meijuan Chen; Kaiwei Wang; Yufeng Wang; Xiaorong Zhu; Jianhua Shen 2020 \\nPractical Study on Blending Teaching Model of College English Based on SPOC Yun Sun; Yubo Fang; Xia Chen 2020 \\nThoughts on Application of Artificial Intelligence in Teaching of Different Disciplines Fan Xu; Lan Wang; Jian Gao 2020 \\nA study on the blended learning model of online course “Engineering Project \\nManagement ” Xiaolei JI; Xin Zhou; Haiya Zhang 2020 \\nAn Analysis of Oral English Teaching in College Based on Virtual Reality Technology Ning Fang 2019 \\nPreliminary Application Analysis of Mixed Teaching Mode in Colleges and Universities \\nBased on MOOC Platform Qingliang Jiao; Hui Xie 2020 \\nThe reform and practice of the training of computer innovative talents based on SPOC \\nteaching model Ran Li; Yan Lou 2019 \\nResearch on the Teaching Mode of Group Cooperative Learning Based on Blackboard Min Song; Ying Song 2020 \\nProspects for the Application of 5G Technology in Agriculture and Rural Areas Tao Li; Donglin Li 2020 \\nResearch and Practice of Hybrid Teaching Based on AI technology for Foreign \\nLanguage Translation Ting Liu; Eunyoung Kim; Xiaoyan Li; Takaya Yuizono; Yukari Nagai; Yifen Lu 2020 \\nFlipped Classroom Teaching Practice of Compiler Principles Based on MOOC Xinxin Liu 2019 \\nChengxia Zhang; Ying Li; Chengcheng Cai 2020 \\n(continued on next page) A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 9}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n11Table A1 (continued ) \\nTitle of the Paper Author Year \\nApplication and Research of Virtual Reality Technology Based on Big Data in College \\nTeaching Field \\nResearch and Implementation of Teaching System for Higher Vocational Specialty \\nCourses Based on Hybrid Teaching Mode Penglong Zhang; Yongsheng Zhang; Shaojun Fan; Xiaoxiang Huang; Jie Zhang 2019 \\nAspects to Foster Competences for Engineering Graduates: Education 4.0 Paradigm K.M. Soni; Nitasha Hasteer; Anshul Bhardwaj 2020 \\nReform of University Computer Foundation Course Based on Mobile Terminals in Big \\nData Era Yu Nie-fang; Peng Xiao-ning; Mi Chun-qiao; Li Xiao-mei 2019 \\nOn the Modelling and Predication of Teaching Effectiveness with Machine Learning Kun Tian; Wen Liu; Ying He; Ming Yang; Danhua Zhao 2020 \\nConstruction of Modern Information Education Platform Based on Embedded \\nResource Scheduling XuQiang Huang 2020 \\nConstruction of Classroom Teaching Model Based on the 5G Communication \\nTechnology Hanhui Lin; Shaoqun Xie; Ken Cai 2019 \\nThe Reform and Exploration of Teaching Team in Postgraduate Courses Wenhua Qian; Dan Xu; Guowu Yuan; Wu Hao 2020 \\nConstruction of Agile Teaching Team for Software Engineering Major under \\nBackground of New Engineering Jiujiu Yu; Jishan Zhang; Yun Chen; Ning Wu; Yingying Mei; Canglu Zhu; Lili Zhu; \\nXiaoyu Chu 2020 \\nOnline Teaching Practice in Chinese Culture Course Yi-Jheng Chang; Wei-Ling Hsu 2020 \\nExploration on the Cultivation of Innovative Undergraduate Talents in Computer \\nMajor Promoted by Organic Integration of Teaching and Scientific Research Shanshan Gao; Jing Chi; Zheng Liu; Meiyao Tao; Wenhan Dou 2021 \\nApplication of the Online and Offline Blended Learning Mode in Innovation and \\nEntrepreneurship Education Zhichao LIU; Cuie XIONG; Dongxing XIE 2020 \\nDesign and Application of Smart Vocational Education Platform Based on New \\nGeneration Information Technology Jinlong Wang; Jing Zhang; Jing Fan; Shuai Zhang; Jianbin Wang; Yu Geng 2020 \\nResearch on the Sustainable Development Model of Information Technology Literacy \\nof Normal Students Based on Deep Learning Recommendation System Haicheng Bai; Shuai Yang 2019 \\nDiscussion on the key technologies of Intelligent Teaching System application in the \\nera of artificial intelligence 2.0 Tang Ming; Sun Yutong; Chen Jiajun; Zhong Qianyi 2020 \\nThe Marxist Chinese Political Teaching Innovation Model Based on Multimedia \\nDatabase Management System Xiuli Fang; Fengjuan Tian 2019 \\nIn Depth Interview on ICT Ability of University Teachers Yan Zhang; Xiaoli Chu 2020 \\nApplying Python in Brain Science Education Xiaofei Zhang; Jiajin Huang; Yang; Xiang He; Ruohao Liu; Ning Zhong 2019 \\nStrategies to Improve the Effectiveness of Business English Classroom Teaching Based \\non Intelligent Teaching System Yichen Xing 2020 \\nThe Construction and Practice of Blended Learning Mode for the Course Market \\nResearch Based on WeChat Public Platform LIU Juan 2020 \\nThe Application of Computer Information Big Data Technology in College English \\nTeaching Qu Hui 2020 \\nResearch on the teaching of “Internet plus continuing education ” from the perspective \\nof Al Xuelin Qiu 2020 \\nResearch on English Teaching Mode in College Based on Artificial Intelligence Tingyu Jiao 2020 \\nDevelopment and Implementation of Mobile Platform-Oriented Interactive English \\nGrammar Learning System Yanwei Yang 2019 \\nDesign and implementation of intelligent laboratory control system based on Arduino Tang Mingjie; Zeng Qingtao; Zhang Xiaoliang; Huang Hui 2020 \\nResearch on teaching reform and work innovation of HRM driven by AI Tian Wang; Jianbang Lin 2020 \\nInvestigating Critical Factors Affecting the Adoption of Technology for Overall \\nDevelopment of HEI Sahil Manocha; Akanksha Upadhyaya 2019 \\nApplication of modern information technology in mathematical technology Li Long 2020 \\nBlended Teaching Based on Multiple Teaching and Learning Platforms: A Case Study of', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 10}),\n",
       " Document(page_content='Application of modern information technology in mathematical technology Li Long 2020 \\nBlended Teaching Based on Multiple Teaching and Learning Platforms: A Case Study of \\nProgramming Course Chongming Zhang; Yanfei Zhu; Chunmei Wang; Yang Luo; Chuanjiang Li 2021 \\nCyber Security Social Engineers An Extensible Teaching Tool for Social Engineering \\nEducation and Awareness Jin-Ning Tioh; Mani Mina; Douglas W. Jacobson 2019 \\nA Full-chain Innovation Ecological Environment for Postgraduate Education Degui Xiao 2019 \\nConstruction of STEM Interdisciplinary Integration Model Supported by Educational \\nArtificial Intelligence Lili Wu 2021 \\nResearch on the Teaching Reform of Managing the Software Process Course Aijun Zhen; Guoqiang Ma; Kai Wu; Yan Liu 2020 \\nDesign and Implementation of Oral English Learning System Based on Speech \\nRecognition Technology Xiaoqin Zhang 2020 \\nInteractive Teaching Path Analysis of Higher Vocational Ideological and Political \\nCourses Based on Artificial Intelligence Algorithms Zhang Yunfang; Wang Yuexi 2019 \\nExploration of Task-driven Blended Teaching of Marketing Hui LI; Chen LIN; Qiaoyun Wei; Cheng Zhang; Nianwu Zhang; Min Guo 2020 \\nReflections on the Cultivation System of Innovative Talents in Universities in the era of \\nArtificial Intelligence Jianwei Hu 2019 \\nResearch on the Application of Artificial Intelligence Technology in Scientific \\nResearch Management in Colleges and Universities Zhao Yongtao 2019 \\nAn Analyze and Actions to Increase the Quality in STEM Higher Education Radu Vasiu; Diana Andone 2019 \\nA LBS Method for Student Behavior Based on Hybrid Positioning by using big data \\nAnalyzation Xiong Li; Shuna Yan; Yiming Shao; Jiangtao Hao 2019 \\nA Big Data Acquisition And Analysis Method for Student Behavior Based on Hybrid \\nPositioning Xiong Li; Shuna Yan; Yiming Sao 2020 \\nDesign and Analysis of Intelligent Teaching System in Colleges and Universities Based \\non Big Data Application Jing Zhang 2021 \\nResearch on the Course System of Data Science and Engineering Major Zhenping Qiang; Fei Dai; Hong Lin; Yueyu Dong 2019 \\nData Science and its position in university education within National Project IT \\nAcademy-Education for 21st Century L. Antoni; J. Guni ˇs; P. Gurský; ˇS. Horv ´at; S. Krajˇci; O. Krídlo; M. Opiela; A. Szabari; \\nL. ˇSnajder; G. Andrejkov ´a; D. ˇSveda 2020 \\nAnalysis And Visualization of Online Learning Data Based on Crowd Sensing Zhongxian Bai 2020 \\nCollege Students ’ Learning under the Environment of Internet Technology: Strategies \\nand Suggestions Ling Wang 2021 \\n(continued on next page) A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 10}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n12Table A1 (continued ) \\nTitle of the Paper Author Year \\nPrediction of Student Performance Using Linear Regression Boddeti Sravani; Myneni Madhu Bala 2020 \\nA Study on the Cultivation of College Students ’ Political Values in the Era of Big Data Fang Hua; Pan Jian; Hao Wenhui; Yi Kang; Bi junfei 2020 \\nThe Influence of Digital Virtual Technology on Contemporary College Students ’ \\nIdeological and Political Education Baolian Song 2020 \\nResearch on Effective Cooperative Learning Strategies in Group Teaching of Practical \\nCourses Xia Ming; Liu Dan 2020 \\nESP Course Construction and Learning Behavior Analysis Ya-mei Zhang 2020 \\nResearch on Ways to Improve College Students ’ Moral Cultivation Based on Virtual \\nSimulation Technology Bai Yi 2020 \\nResearch and Practice of the Teaching Model of Mechanical Practice Courses in \\nColleges and Universities Based on “Craftsmanship ” Tang Rong jiang; Zhao Rui; Bao Jia ding 2020 \\nResearch on College English Teaching Strategies and Applications Based on Big Data Juanjuan Wang 2019 \\nTeaching Design and Implementation Based on R Language Under the Background of \\nBig Data Dong Wang; Honghe Wei; Baodan Bai 2021 \\nBuilding Smart Classroom of Combinatorial Mathematics Based on PBL Teaching \\nModel Benchao Yang; Guang Zeng; Gang Yu 2019 \\nPractice of ideological and political education in the course of “R language \\nfoundation ” Dong Wang 2020 \\nApplication of Artificial Intelligence Technology in English Learning Platform Chu Yongjuan 2020 \\nFuture Education Trend Learned From the Covid-19 Pandemic: Take « Artificial \\nIntelligence » Online Course As an Example Liu Kexin; Qu Yi; Song Xiaoou; Li Yan 2020 \\nA Review: Predicting the Performance of Students Using Machine learning \\nClassification Techniques Rahul; Rahul Katarya 2019 \\nPractice Teaching Design and Implementation Based on Kolb ’s Learning Theory Pei-shun Liu; Xue-fang Wang 2020 \\nResearch and Application of performance Evaluation Model of Rural Preschool \\nTeachers based on big data Algorithm Peng Li 2020 \\nTechnical Practice of Making Online Workplace Etiquette Courses Based on Camtasia \\nStudio Yan Wang 2020 \\nKnowledge Graph Based Teaching Analysis on Circuit Course Xu Xing; Ji Dou; Wang Xiangjun; Yan Xiaolin 2020 \\nWork-in-Progress —Utilizing Virtual Reality to Promote Active Learning in \\nConstruction Management Sathish Akula; Nikolay Sargsyan; Soundarya Korlapati; Xin Wei; Cheryl D. Seals; \\nJeff Kim 2020 \\nFace Detection to Recognize Students ’ Emotion and Their Engagement: A Systematic \\nReview Benyoussef Abdellaoui; Aniss MOUMEN; Younes EL BOUZEKRI EL IDRISSI; Ahmed \\nRemaida 2020 \\nThe Design of the Challenge Experimental Course of “Information Security System R & \\nD” under the Background of Emerging Engineering Education Ruijin Wang; Shijie Zhou; Mengjie Zhang; Xuchenghao Luo; Jin Wu; Fengli Zhang 2020 \\nA Comparative Study of Information Technology Curriculum Standards in Primary \\nand Secondary Schools in China and the United States, Japan and Britain Jing Liu; Xiaoyan Li; Jun Han 2021 \\nINDReview on Facial Expression Analysis and its Application in Education Qiang Li; Xiwei Liu; Xiaoyan Gong; Sifeng Jing 2019 \\nA Taxonomy of Various Applications of Artificial Intelligence in Education Pooja Rana; Lovi Raj Gupta; Gulshan Kumar; Mithilesh Kumar Dubey 2021 \\nDiscussion on Teaching Reform of Computer Education Major Based on Information \\nKey Competency Yan Liang; Changhe Li 2020 \\nICT- The Smart Education System in India Mantosh Kumar; Thipendra Pal Singh; Tanupriya Choudhury; Subhash Chand \\nGupta 2019 \\nExploration on Curriculum Teaching Based on OBE and AI Jianguo Chen; Huijuan Lu; Hangxia Zhou; Yongxia Zhou 2019 \\nStrategies for Improving the New Media Literacy Education for University Students Dongmei Liu 2020 \\nThe Mechanism of Intelligent Technology Reforming Education Based on the \\nPerspective of Embodied Cognitive Theory* Weina Cheng; Xinguo YU 2020', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 11}),\n",
       " Document(page_content='The Mechanism of Intelligent Technology Reforming Education Based on the \\nPerspective of Embodied Cognitive Theory* Weina Cheng; Xinguo YU 2020 \\nDigital Communication of Chinese Classical Literature in the Era of Big Data Zehao Yao 2021 \\nAwareness, Knowledge, and Attitude towards Artificial Intelligence: Perspectives of \\nVietnamese Information Technology Students Pei-Ju Chao 2020 \\nAdoption of AI-Chatbots to Enhance Student Learning Experience in Higher Education \\nin India Nitirajsingh Sandu; Ergun Gide 2019 \\nAI based Smart Teaching Process During The Covid-19 Pandemic Milan ˇStrbo 2020 \\nEffects of “4D Situational Multimedia Interaction ” on Modern Non-commissioned \\nOfficer Education Zhou Yucheng; Zhang Na; Song Mei; Li Meng 2020 \\nA Comprehensive Methodology to Develop an Efficient Electronic Learning \\nManagement System that is Compatible with Various Applications Huda Khurshed Shawkat Aljader 2019 \\nLearning Analytics to Support Teaching Skills: A Systematic Literature Review Luis Magdiel Oliva-C ´ordova; Antonio Garcia-Cabot; Hector R. Amado-Salvatierra 2021 \\nResearch on the evaluation model of subject competition based on the “four in one” \\npractical innovation ability training mode Znahg Rui; Shi Wenyu 2020 \\nIntelligent evaluation of non-party middle-level cadre team construction in colleges \\nbased on data mining in the Internet background Yue Cao 2021 \\nThe Impact of ICT Advances on Education: A Case Study Chao Duan; Dongpo Guo; Jerry Xie; Jing Zhang 2020 \\nThe Role of Technology to Teaching and Learning Sign Languages: A Systematic \\nMapping Venilton Falvo; Lilian Passos Scatalon; Ellen Francine Barbosa 2020 \\nInteractive AI for Linguistic Education Built on VR Environment Using User Generated \\nContents WooHyun Park; DoJin Park; ByungJune Ahn; SeokHun Kang; HaengYeong Kim; \\nRaeHyeon Kim; JaeHeum Na 2019 \\nExploration and Practice of Internationalization of International Economic and Trade \\nMajor- a case study of Shenyang Aerospace University Zhang Bo; Gao Lianting; Cheng Li 2020 \\nPath for Implementing Ideological and Political Education in the Major of Equipment \\nEconomic Management Yan Peng; Xin Liang; Yuanyuan Chen 2020 \\nUpgrading Higher Education through Open Online Courses Gulchera Shadmanova; Sayibdjan Mirzaev; Xabiba Karimova 2019 \\nResearch on the Practice of Course Ideological and Political Education in Applied \\nUndergraduate Colleges Shunmin Wang 2019 \\nResearch and thinking about the construction of online courses Liu Hui; Li Fengyong 2020 \\n(continued on next page) A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 11}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n13Table A1 (continued ) \\nTitle of the Paper Author Year \\nImprovement on Teaching Microwave Engineering Course by Incorporating the \\nArtificial Intelligence Technology Yu Miao Gao; Xin Yu Guo; Mei Song Tong 2019 \\nInnovation and Practice of Training Management of Major Directors under the Dual \\nBackgrounds of Intelligent Society and Epidemic Prevention and Control Xiaozhuo Wei; Xing Dong; Yunpeng Li; Wenjun Shao 2021 \\nIntelligent Study on the Opening and Selecting Course Management Model of URP \\nSystem Based on Individual Preference Hailing Xu; Feng Yuan; Tingting Xie 2020 \\nStudy on Experimental Teaching of Building Environment and Energy Application \\nEngineering Jian Chen; Donghua Liu; Guannan Li 2020 \\nAnalysis and strategies of the Professional Development of Information Technology \\nTeachers under the Vision of Artificial Intelligence Qingmin Wei; Mingyong Li; Kaiyue Xiang; Xue Qiu 2020 \\nResearch on University Education Reform in the Era of Artificial Intelligence Xinyi Ling 2020 \\nThe Application of Artificial Intelligence Technology in College Physical Education Xinyu Fu 2020 \\nA Survey of the Development of Artificial Intelligence Technology Zhi Li; Yilin Wang; Yunfang Ji; Wenyu Yang 2020 \\nResearch on school education reform under the background of “5G +education\" Shuai Yang 2020 \\nResearch on the Application of Artificial Intelligence in Education Huiyan Li; Hao Wang 2020 \\nAnalysis of Key Technology Application of Computer Multimedia Technology Yunxiang Zhang; Yunpeng He; Shengcan Jin 2019 \\nApplication and Innovation of Artificial Intelligence Technology in College Sports Zhang Caixia; Liu Liguo 2020 \\nDevelopment Trend and Thinking of Artificial Intelligence in Education Weiyan Liang 2020 \\nImprovement of Education Method by Using Artificial Intelligence Technology Mei Song Tong; Hong Qin Zheng; Guo Chun Wan 2019 \\nThe Development of Artificial Intelligence Education Resources under the Background \\nof the Internet of Things Shuying Zhao; Shuang Chen; Wanjing Li; Dongming Li; Xin Liu; Jie Chen 2020 \\nStudy on the Application and Challenges of Educational Robots in Future Education Dehua Li; Xianning Chen 2020 \\nResearch on the Development Status and Trend of K12 Online Education in China Hang Gao 2020 \\nResearch on Education Development Based on Artificial Intelligence Technology Ya Wang; Yanmei Yang 2020 \\nResearch on the Design and Construction of Intelligent Learning Space in the Era of Big \\nData Juntao Fan; Lin Zhi 2020 \\nConversational Agents to Democratize Artificial Intelligence Jessica Van Brummelen 2019 \\nReview on Development of Smart Education Wanruo Shi; Xiwei Liu; Xiaoyan Gong; Xiaojie Niu; Xinzhu Wang; Sifeng Jing; Hao \\nLu; Nan Zhang; Jie Luo 2019 \\nStatus of Smart Manufacturing in the United States Khalid Hasan Tantawi; Ismail Fidan; Anwar Tantawy 2019 \\nReflections and Countermeasures on the Development of Secondary Vocational \\nTeachers ’ Teaching Ability Based on AI and Students ’ Characteristics Lining Liu; Yongsheng Zhang; Penglong Zhang; Wenqian Sun 2020 \\nResearch on New Teaching Platform Under the Background of “Internet +\" Xi Xu; Guohua Zhan; Zhihua Li 2019 \\nThe Human Resources Development Applications of Machine Learning in the View of \\nArtificial Intelligence Jing Tian 2020 \\nResearch and application of practice teaching reform of HRM major under the \\nbackground of AI Tian Wang; Jianbang Lin 2020 \\nHotspots and Trends of Virtual Reality, Augmented Reality and Mixed Reality in \\nEducation Field Hai Zhang; Yulu Cui; Huaming Shan; Zhili Qu; Wanxiong Zhang; Lujie Tu; Yining \\nWang 2020 \\nResearch on the Effect of Artificial Intelligence Technology on English Learning \\nEfficiency Li Xianhua 2019 \\nThe Application of Artificial Intelligence in Foreign Language Teaching Zhu Yanhua 2020 \\nThe development of distance education in China Qiang Ding; Zhibing ZHONG; Sumeng Xiong; Shimin Guo; Shichao Liao 2020', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 12}),\n",
       " Document(page_content='The development of distance education in China Qiang Ding; Zhibing ZHONG; Sumeng Xiong; Shimin Guo; Shichao Liao 2020 \\nResearch on the Change of Educational Management in the Era of Artificial \\nIntelligence Shuiping Luo 2019 \\nOn the Application of Artificial Intelligence in the Development of New Sports in \\nColleges and Universities in Shanghai Xu Jian 2020 \\nResearch on personalized service of military vocational education under the \\nperspective of “internet +” Xiao shuang Wang; Jing Zhao; Ya ni Zhang 2020 \\nResearch on the talent training mode of Application- oriented Undergraduate Cross- \\nborder e-commerce Innovation and Entrepreneurship Education Xi Yang; Ming Luo 2020 \\nThe change of teachers ’ role in teaching under the environment of “Artificial \\nIntelligence +” Jing Liu; Shuli Wang 2020 \\nThe concept change and organization transformation of Vocational Education under \\nthe Internet thinking Guohua Zhu; Zhaoxue Wu 2020 \\nAugmented Reality for Smarter Bangladesh Muhtasim Riffat; Abrar Yasir; Intisar Tahmid Naheen; Shuva Paul; Md Tanvir Ahad 2020 \\nResearch on the Application of Internet Technology in Adaptive Education of \\nAccounting Major Yan Xu; Nanyun Xiao 2021 \\nThe Impact of Artificial Intelligence and Blockchain on the Accounting Profession Yingying Zhang; Feng Xiong; Yi Xie; Xuan Fan; Haifeng Gu 2020 \\nResearch on the New Capability Structure of University Accounting Talents under the \\nBackground of Artificial Intelligence and Blockchain Yanli Yang 2020 \\nResearch on Construction and Application of Accounting Information System Based on \\nBlockchain Technology YanRu Kong; HuiYing Chen 2020 \\nResearch on the Teaching Reform of Finance and Accounting Major under the \\nBackground of Big Data Li Huimin; Song Guomin 2020 \\nResearch on the construction technology of college students ’ thought and behavior \\nguidance system based on 5G environment Yunli Cheng; Xiaohui Wang; Shuang He 2020 \\nEnlightenment of Digital Technology on Stop Motion Animation Teaching Jiang Tao; Gao Zhuo 2020 \\nThe Application of Stereo Image Generation and Composition Algorithms in Desktop- \\nBased Virtual Reality Teaching System Hongling Liu 2019 \\nVirtual Reality – A Paradigm shift in Education Pedagogy S Iwin Thanakumar Joseph; S Benson Edwin Raj; Jamal Mohamed Kiyasudeen 2020 \\nAffective Computing Oriented to Intelligent Education — Reflection and Prospect Chaoyang Wang 2019 \\nThe Framework and Thinking of the Future Primary and Secondary School \\nInformation Support Environment Jun Han; Xiaoyan Li; Jing Liu 2021 \\nThe challenges of the online teaching process - a short review Mihai Oproescu; Adriana-Gabriela Plaiasu; Ionela Niculescu; Viorel Nicolae 2020 \\nStudy on the New Models of Music Industry in the Era of AI and Blockchain Mingli Shang; Hui Sun 2020 \\n(continued on next page) A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 12}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n14Table A1 (continued ) \\nTitle of the Paper Author Year \\nIoT Application Technology Recent Development and the Engineering Talent \\nComprehensive Training Intelligent Framework Haiye Qiao; Zhiliang Xiao; Jiahao Yu 2020 \\nInstructional Use of Virtual Reality in E-Learning Environments Ghaliya Alfarsi; Azmi bin Mohd. Yusof; Ragad M Tawafak; Sohail Iqbal Malik; Roy \\nMathew; Mohammed Waseem Ashfaque 2020 \\nDesign and Implementation of Virtual Immersive Classroom in Big Data Environment Juntao Fan; Lin Zhi 2020 \\nWork-in-Progress —A Proposal to Design of Virtual Reality Tool for Learning \\nMechatronics as a Smart Industry Trainer Education Leticia Neira Tovar; Edson Casta ˜neda; Víctor Ríos Leyva; Daniel Leal 2020 \\nDesign Research of Physical Virtual Experiment Based on Virtual Reality Technology Yuan Jiugen; Yang Jing; Xing Ruonan 2020 \\nAnalysis of the Application of Artificial Intelligence Technology in the Construction of \\nSmart Campus Weiyan Liang 2020 \\nPrivacy, Data Rights and Cybersecurity: Technology for Good in the Achievement of \\nSustainable Development Goals Katina Michael; Shannon Kobran; Roba Abbas; Salah Hamdoun 2019 \\nResearch on Building Smart Campus Based on Cloud Computing Technology Yizhi Li 2020 \\nGuest Editorial Special Issue on Game Competition Frameworks for Research and \\nEducation Liu, J., Perez-Liebana, D., Cazenave, T., Thawonmas 2019 \\nAn Overview of Electronic Games in the Academic Areas Ghaliya Alfarsi; Azmi bin Mohd. Yusof; Ragad M Tawafak; Sohail Iqbal Malik; Roy \\nMathew; Mohammed Waseem Ashfaque 2020 \\nApplication of Artificial Intelligence System in Smart Education in Cloud Environment \\nwith Optimization Models Zhiyuan Huang 2021 \\nPersonalized Elearning Open Platform For Alphabetization Awareness In Rural Areas \\nOf Morocco P Subashini; M Krishnaveni; TT Dhivyaprabha; B Preethi; A. Hayar; M. ElAlaoui \\nElHanafi; M. Joundi; Elm. Kheddioui 2019 \\nRomanian pre-university education from the perspective of school management Jianu Eugenia; Mihai Oproescu; Dumitru Tudosoiu 2019 \\nThe Application of IoT Technology to a Manufacturing Process: Case Study Khaldoon Hijazin; Tieling Zhang 2019 \\nInformation Security Practice of Intelligent Knowledge Ecological Communities with \\nCloud Computing Yingjue Ma; Hui-jun Ni; Yanping Li 2021 \\nResearch on the Construction of Online Learning Education Space Under the \\nBackground of Artificial Intelligence +Education Yao Wei 2020 \\nA Study on Providing Blended Learning Support to EFL Students of Advanced English \\nCourse Duan Yuan-Bing; Wang Jing-Zheng 2020 \\nHolographic Classroom Based on Digital Twin and Its Application Prospect Liu Shuguang; BA Lin 2020 \\nA Survey on Future of Augmented Reality with AI in Education R Kaviyaraj; M. Uma 2021 \\nFramework for the Development of Virtual Labs for Industrial Internet of Things and \\nHyperconnected Systems Maurice Dawson; Francisco Garcia Martinez; Pedro Taveras 2019 \\nIssues and Challenges in Learning Foundation Linear Algebra Course with Technology: \\nA Literature Review Gurwinder Singh; Neha Tuli; Archana Mantri 2021 \\nResearch on the Cultivation of the Core Competences and Values of Information \\nTechnology for Normal School Students Based on Maker Education Mo Zhihui; Zhang Shilan 2020 \\nInvestigation of Machine Learning Assistance to Education Megha Gupta; Gunjan Batra 2021 \\nVR Course Construction Oriented by Innovation Project Development Jin Ying 2019 \\nResearch on the Disciplinary Evolution of Deep Learning and the Educational \\nRevelation Xue Wang; Haiyan He; Ping Li; Lei Zhang 2019 \\nApplication of Machine Learning in Network Security Situational Awareness Zhao Yifan 2021 \\nResearch on the Construction of Information Platform of Employment and \\nEntrepreneurship for College Bin Xu; Bo Zhang 2020 \\nDo MOOCs Sustain the UNESCO ’s Quality Education Goal? Edmundo Tovar; Bernardo Tabuenca; Ahmed Alzaghoul; Carlos Delgado Kloos; Jim', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 13}),\n",
       " Document(page_content='Entrepreneurship for College Bin Xu; Bo Zhang 2020 \\nDo MOOCs Sustain the UNESCO ’s Quality Education Goal? Edmundo Tovar; Bernardo Tabuenca; Ahmed Alzaghoul; Carlos Delgado Kloos; Jim \\nSluss; ´Africa L´opez-Rey; Elena Ruiz; F´elix García-Loro; Elio Sancrist ´obal; Miguel \\nRodríguez Artacho; Sergio Martin; Manuel Castro; Russ Meier; Nelson Piedra 2019 \\nCreating Virtual Reality and Augmented Reality Development in Classroom: Is it a \\nHype? Vinh T. Nguyen; Kwanghee Jung; Tommy Dang 2019 \\nMathCloud: A Discrete Cloud Implementation to Enhance Learning Experience in \\nMathematics Anjum Zameer Bhat; Lakshmi Kameshwari; Baldev Singh 2020 \\nAI-NLP Analytics: A thorough Comparative Investigation on India-USA Universities \\nBranding on the Trending Social Media Platform “Instagram ” G. S. Thejas; Kundan Kumar; S. S. Iyengar; Prajwal Badrinath; N. R. Sunitha 2019 \\nMalware Analysis Platform Based on Software Gene for Cyberspace Security Practice \\nTeaching Fudong Liu; Ping Zhang; Yifan Hou; Lixin Wang; Zheng Shan; Junchao Wang 2020 \\nResearch on the Construction and Innovation of Lifelong Education System Under the \\nBackground of Big Data Jian Sun; Ting Wang; Ming Luo 2020 \\nResearch on Optimization Strategy of University Maker Space Ecosystem under \\nArtificial Intelligence Background Hongli Hu; Mi Ding 2020 \\nAssisting Information Systems students to Engage with the Internet of Things (IoT) Marita Turpin; Machdel Matthee; Sean Kruger; Jean-Paul van Belle 2020 \\nThe reform and development of education promoted by information technology in the \\nartificial intelligent era. Xia Shan Dai; Ling Luo; Hao Li; Rong Chen 2020 \\nBlockchain: Application in the System of Teaching Informatization Management of \\nHigher Education Linlin Zhang 2020 \\nManagement of Online Education Based on Blockchains Lei Gao 2020 \\nAnalysis on the Thinking Innovation of Ideological and Political Education Based on \\nthe Theory of Blockchain in the Information Age Xiaoyu Liu; Xiaofu Liu; Zhenpeng Guo 2020 \\nResearch on the Development Status and Future Trend of Early-Childhood Education \\nin China under the background of Education Informatization Chengnan Liu 2020 \\nResearch on the construction of school education management decision system based \\non Data Mining Framework Yihong Liu 2020 \\nProject analysis of “Intelligent Robot Experience Center ” based on “Idea VR” platform Bei Han; Luo Yang; Yang Qu 2021 \\nThe Case for a Portable Open-Source 3D Ultrasound: Issues, Benefits, and Challenges Yazmin Feliz; Pooja Jethani; Patricia Jastrzebska-Perfect; Hod Lipson 2019 \\nResearch on practice of online and offline mixed teaching based on wisdom tree \\nplatform — taking course of “principles of electrical appliances ” as an example Lei SHI 2020 \\nThe practice and exploration of Internet online education Shichao Liao; Qiang Ding; Sumeng Xiong; Maorong Hu 2020 \\n(continued on next page) A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 13}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n15Table A1 (continued ) \\nTitle of the Paper Author Year \\nConstruction and analysis of foreign language online guiding model based on \\nclassroom network environment and face recognition Junhui Shi 2021 \\nResearch On New Models Of “flipped classroom ” In Higher Education Ning Sun; Xinyan Shi 2020 \\nExploration and Practice on Industrial Robot Experimental Teaching Based on \\nVirtuality and Reality Combination Lingyun Feng 2020 \\nAnalysis of the college students ’ online learning status and implementation strategies \\nduring the epidemic Dongqing Wang; Wenjun Pei; Huan Liu 2020 \\nInternationalization Process of “Double First Class ” Universities Based on Big Data Chan Wu 2020 \\nResearch on the New Era Artificial Intelligence Promoting the Reform of College \\nEnglish Ecological Teaching Ling Gui 2020 \\nDiscussion on the application of artificial intelligence technology in the construction \\nof physical education class in Higher Vocational College Lin jia huan 2020 \\nAn Analysis of the Optimization Strategies of Ecological College English Teaching \\nBased on Artificial Intelligence Weishi Wang 2020 \\nSuggestions on Accelerating the Implementation of Artificial Intelligence Technology \\nin University Information System Kun Niu; Cheng Cheng; Hui Gao; Xinjie Zhou 2019 \\nConstruction and Application of Teaching Resources Library Regarding Flight \\nAttendant Specialty Mei He 2020 \\nExploration and Practice of Online Teaching for Data Structure in Epidemic Period Xuemei Wang; Xuelan Zou; Weifeng Yin 2020 \\nResearch on the Application of Smart Classroom in Higher Mathematics Teaching Jie Shen; Qinglin Wu 2021 \\nAn Application of Face Recognition Technology in University Classroom Teaching Yang Tao 2020 \\nProblems and suggestions of online learning for Chemical Engineering Majors in \\ncolleges and universities Yue Zhe; Shi Binbin; Liu Chunrun; Bao Minghao; Wu Yutian 2020 \\nThe Application of SPOC-Based Deep Learning Model in Psychological Health \\nEducation of College Students in Post-MOOC Era He-Chen Yang; Han-Bin Wu 2019 \\nStudy on the application of network resources in home teaching Li Guoxia; Mao Jianjing; Zhang Dongpo; Yang Jing; Sun Bin 2020 \\nThe Support of Internet Technology in Physical Education Classroom in the New \\nCoronary Pneumonia Epidemic Xiaoming Zhang 2020 \\nHybrid Teaching Practice Based on Internet Platforms —A Case Study of the \\nCourse “Introduction to Tourism ” Guo Yajuan; Zhang Cheng; Kang Xinmeng 2020 \\nThe Reform of Ideological and Political Course Online Teaching During COVID-19 \\nOutbreak A Case Study of Sichuan Technology and Business University Zhao-xue Zhang; Meng-xuan Zhang 2020 \\nApplication and Practice of VR Virtual Education Platform in Improving the Quality \\nand Ability of College Students Qian Zhang 2020 \\nResearch and practice of Internet Teaching – Take the course of Innovation and \\nEntrepreneurship Education and Practice as an example ManJu Deng; ZeZHou Feng 2020 \\nApplication and Model of Virtual Reality in Physical Experiment Yuan Jiugen; Fan Anqi; Xing Ruonan 2020 \\nRobotics to Enhance the Teaching and Learning Process Rawaa Al-Jumeily; Hoshang Kolivand; Shatha Ghareeb; Jamila Mustafina; \\nMohammed Al-khafajiy; Thar Baker 2021 \\nResearch on the construction of digital media professional group under the guidance of \\n“1 +X” vocational skills Hainie Meng 2020 \\nOn Application of “Artificial Intelligence Plus Large Data ” in Public Maths Course \\nTeaching of Engineering Colleges Zheng Mali; Chen Huaxi 2019 \\nProblems and Reform Ideas in Law Theory Teaching in Universities Based on Big Data \\nAnalysis Li Yayuan 2020 \\nAn FFM-based Model for Students ’ In-class Learning Postures Estimation Ziyun Zhao; Shifeng Zhang; Kangying Hu; Zhan Chen; Junqi Guo 2020 \\nPractical Teaching and Vocational Integration Orientation of Applied Undergraduate \\nCivil Engineering: Take Fuzhou University of International Studies and Trade as an \\nexample Hu Yukui 2020', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 14}),\n",
       " Document(page_content='Practical Teaching and Vocational Integration Orientation of Applied Undergraduate \\nCivil Engineering: Take Fuzhou University of International Studies and Trade as an \\nexample Hu Yukui 2020 \\nInvestigation and Analysis on the Training Methods of International Skilled Talents in \\nHigher Vocational Education Chunqing Meng 2020 \\nOn the Application Analysis and Innovation of New Media of Party Building in \\nColleges and Universities Based on SPSS Jian Dong; Shenshen Guo; Bin Wu; Jianru Xie 2020 \\nResearch on the Application of Virtual Reality Technology in the Teaching Model Jie Jiang; Lei Zeng 2019 \\nResearch on the Construction and Application of Desktop Virtual Reality Teaching \\nSystem Hongling Liu 2020 \\nResearch on the reform of foreign training teaching under the background of \\ninformatization Hong Ju Xiao 2020 \\nCourse of Circuit and Electronic Technology for Computer Major Xiao-feng Zhang 2019 \\nPractice and exploration of modern apprenticeship system of accounting major \\n—Based on the mode of “Financial Sharing Center\" Zhao Yan 2020 \\nThe Innovative Education of “Smart Finance ” under the Promotion of Educational \\nInformationization Yuan Zhang; Yi Wu; Murong Zheng; Xinyi Lin; Yutong Zhang 2019 \\nReform Research and Practice of Army Equipment Teaching Model Based on \\nEducation Informatization Jingjing Wang; Wei Zhang; Ming Lu; Hui Yi 2020 \\nDevelopment of Job Skill Model Based on EIS—Take Purchasing Role as an Example Runxin Yang; Jimei Li; Meijie Du 2020 \\nSchool-Enterprise Cooperation on Python Data Analysis Teaching Xinxin Liu; Hongyun Xu 2019 \\nResearch on Efficient Teaching Mode for Group Training Course Based on Dynamic \\nSystem Simulator Xin Zhang; Shaoke Shi; Bin Sun 2021 \\nResearch on the Co-construction and Sharing of Teaching Resources Under the \\n“Internet Plus” Environment Yinqiang Feng; Guohua Zhan; Zhihua Li 2019 \\nEducation of society as a tool to counteract disinformation in implementing new \\ntechnologies. On the example of 5G mobile telecommunications network and \\nWarsaw sewage system. Urszula Soler; Mariusz Busilo 2019 \\nA review of 5G applications and key technoligies Rongli Gai; Xiaoyan Du; Shuya Ma; Na Chen; Shouchuan Gao 2021 \\n(continued on next page) A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 14}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n16Table A1 (continued ) \\nTitle of the Paper Author Year \\nApplication of WeChat Mini Program in Secondary School Students ’ Homework \\nGuidance Zhijun Yang; Cuilian Lv; Jianhou Gan; Ning Lei 2019 \\nResearch on the Deep Integration of Modern Information Technology and Five \\nEducation Yujiao Wang; Haiyun Lin; Li Sun; Dawei Zhang; Junwei Wang; Lina She 2020 \\nSupply and Demand of Ai-Aided Language Education Aihua Zhu 2020 \\nResearch on semantic Retrieval Framework Design based on Ontology Shi Jing; Liu Jia 2020 \\nDesign of online teaching quality evaluation system for Private University: Research \\nbased on deep learning algorithm Cui Beiqing; Zhou Chunrong 2020 \\nHow to Promote the Development of Youth Information Technology Education in \\nChina through Programming Ability for Adolescents Standard Jin Ying; Zhang Jie; Tao Ye; Zhang Li 2020 \\nStudy on the Evaluation of Practical Teaching Quality in Applied Undergraduate \\nColleges Zaijuan Xu 2020 \\nResearch on Information-based Teaching and its Influence on Future Education under \\nthe Background of Epidemic Situation Wanhong Peng; Xiaoniu Li; Lilin Fan 2020 \\nIsea: An Interesting Application of Chemistry Education Based on AR Jing Jin; Tong Liu; Yilei Wang; Chunpeng Wang 2019 \\nConstruction of Double-Precision Wisdom Teaching Framework Based on Blockchain \\nTechnology in Cloud Platform Shukun Liu; Yinglong Dai; Zuowei Cai; Xianmin Pan; Chaoliang Li 2021 \\nResearch on College English Teaching Model Assisted by Computer Software Yi Huang 2020 \\nExploration of Interactive Foreign Language Teaching Mode Based on Artificial \\nIntelligence Ming Luo; Lian Cheng 2020 \\nConstruction and Application of Information-Based Teaching Resources Sharing \\nPlatform Based on Deep Learning Baiqiang Gan; Fei Deng; Chi Zhang; Jing Li 2019 \\nInvestigation and Analysis of Online Teaching in Higher Vocational Colleges during \\nthe COVID-19 Epidemic Juan Ang; Hongmei Zhang 2021 \\nResearch on the Balanced Development of High Quality Compulsory Education Yujiao Wang 2020 \\nResearch on Artificial Intelligence Assisted Teacher Developmental Evaluation from \\nthe Perspective of Reflective Practice Liu Yangjun; Li Hao; Chen Rong 2020 \\nCompetition Neural Network Model Application in the Bilingual Teaching Quality \\nEvaluation of Universities Chao Wan; Hua Kang; Feng Jin; Xin Long Zhu 2020 \\nDesign and Implementation of intelligent Learning Companion System Based on \\nWeChat Mini Program Xue Zhang; Xiaomei Yu; Wenqian Sun 2020 \\nA Review on Techniques, Characteristics and approaches of an intelligent tutoring \\nChatbot system Mohammed Waseem Ashfaque; Sumegh Tharewal; Sohail Iqhbal; Charansing N. \\nKayte 2020 \\nInstructional Design of Blended Teaching Based on Mosoteach: In the Case of \\nCustomer Service Course (Bilingual) Liu Haiyan 2020 \\nConstruction of Intelligent Learning Environment for Multiple Learning Methods Fei Li 2019 \\nThe Teaching Reform of Higher Vocational Business English Course \\nInformationization on the Background of Education Informationization 2.0 Jine Deng 2019 \\nA Synergy of Artificial Intelligence and Education in the 21st Century Classrooms Kuheli Mondal 2019 \\nNovice Programmer to New-Age Application Developer: What Makes Python their \\nFirst Choice? Ramachandran Trichur Narayanan 2019 \\nAnalysis of Teaching Evaluation in the Field of Vocational Education in China Wenqian Sun; Xiaomei Yu; Xue Zhang; Lining Liu; Penglong Zhang 2020 \\nA Virtual Reality-based Spoken English Learning Platform Chengyao Wang 2021 \\nThe Framework of Constructing University Comprehensive Evaluation System Based \\non Online Comments Xue Li; Qian Wang; Qian Jia; Juan Shi 2019 \\nStrengthening the Practical Capacity of Students: an Educational Case Study about \\nTeaching Feedback in Electronics Circuit Hua Fan; Zonglin Li; Quanyuan Feng; Qi Wei 2021 \\nResearch on the Strategy for Constructing Smart Kindergarten System Qiu Huaxiang 2020', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 15}),\n",
       " Document(page_content='Teaching Feedback in Electronics Circuit Hua Fan; Zonglin Li; Quanyuan Feng; Qi Wei 2021 \\nResearch on the Strategy for Constructing Smart Kindergarten System Qiu Huaxiang 2020 \\nStrategies, methods and problems of online education in China during the epidemic* Yu Bai; Zhe Li; Fuzheng Zhao; Yan Jiang 2020 \\nResearch on Problems and Countermeasures of English Education Activities in \\nKindergartens –A case of kindergarten A in Dazu District of Chongqing Liu Jingjing; Yang Xuelan 2020 \\nThe Creation and Case Study of Smart Learning Environment Jie Jiang; DeKun Xu 2020 \\nArtificial Intelligence and Education Adina Magda Florea; Serban Radu 2019 \\nLogical Construction and Realization of Intelligent Service in AI Library Zhang Jing 2019 \\nIndustry 4.0: An Integrated Distance Learning Solution Sara Nu˜nez; Jesus Mendoza Padilla 2020 \\nResearch on the Construction of Liberal Arts Laboratory in Universities under the \\nBackground of New Liberal Arts Education Hang Gao 2020 \\nIoT based Empowerment by Smart Health Monitoring, Smart Education and Smart \\nJobs Sreenivas Eeshwaroju; Praveena Jakkula; Subramanian Ganesan 2020 \\nSharing Cloud Platform Applied to Teaching System Reform based on “5G +Smart \\nEducation ” Innovation Fan Yang; Wang Luo 2020 \\nIncorporation of Modelling and Simulation Techniques with the Education on \\nElectromagnetics and Microwave Technology Si Ce Wang 2019 \\nResearch on Teaching Design Strategies in the Field of Science for Top Class in \\nInclusive Private Kindergartens Shu Wang; Xiaoying Yang; Zhenyan Liu 2020 \\nDesign of Training Platform for IOT Based on Cloud Services Xiangrong Zeng; Hongbo Li; Zhiyuan Zhu; Ming Tang; Chuyan Zhang; Jing Guo 2020 \\nEvaluation of Smart Humanity Systems and Novel UV-Oriented Solution for \\nIntegration, Resilience, Inclusiveness and Sustainability Shengsheng Cao; Chaoyi Wang; Zhiyuan Yang; Hao Yuan; Aijing Sun; Haoyu Xie; \\nLifeng Zhang; Yajun Fang 2020 \\nReverse thinking teaching discussion in high school information technology under \\nnew curriculum standards Jian Gao; Lan Wang 2019 \\nThe Intelligent Management of Counselors in Higher Vocational Colleges under the \\nBackground of Informatization Dai Shasha 2020 \\nDesign of Children ’s Education Auxiliary System Based on CNN Shen Mengting; Cen Gang; Zhou Wen; Zhu Runkai; Liang Yaqin 2020 \\nResearch on the Cultivation Mode of Application-Oriented E-Commerce Talents Under \\nthe Background of Smart New Retail Luo Lisheng 2021 \\n2021 \\n(continued on next page) A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 15}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n17Table A1 (continued ) \\nTitle of the Paper Author Year \\nDevelopment of Information Technology Telecom Chatbot: An Artificial Intelligence \\nand Machine Learning Approach Mallikarjuna Gowda C P; Anupam Srivastava; Shubham Chakraborty; Anurag \\nGhosh; Harsh Raj \\nThe Application of Novel Information Technologies in the Health and Educational \\nSystems of Montenegro Vanessa Mahoney 2019 \\nIBM Watson Application as FAQ Assistant about Moodle Jeferson da Silva Oliveira; Danubia Bueno Espíndola; Regina Barwaldt; Luciano \\nMaciel Ribeiro; Marcelo Pias 2019 \\nAn Innovation in Craftsman-like Talents Development Mode Based on Intelligent \\nManufacturing Specialty Group Construction Sike Jin; Jiali Jin; Weihua Zhou; Junhuan Lin 2021 \\nThe Research on the Application of Big Data in the Credit System of Higher Vocational \\nColleges Wei Zhang; Jialiang Liu; Liwen He; Fang Zhang 2020 \\nApplication of SalesForce Platform in Online Teaching in Colleges and Universities \\nunder Epidemic Situation Jing Hu; Bo Zhang 2020 \\nComposition of Online Teaching and Academic Ability under the Background of \\nArtificial Intelligence and HTML Zhida Zhu 2021 \\nAnalysis of the Construction of College English Ecological Teaching Model in The Age \\nof Artificial Intelligence Chu Yongjuan 2020 \\nWays to Enhance the Influence of Academic Journals Based on MOOC Resources Shuhui WANG; Xi CHEN; Jian YAO 2020 \\nEducation Technology for Online Learning in Times of Crisis Haiyan Cai; Irwin King 2020 \\nEducational Technology Market Analysis Victor V. Timchenko; Sergey Y. Trapitsin; Zoya V. Apevalova 2020 \\nResearch on The Construction of Course Knowledge Graph of High School Information \\nTechnology Jian Gao; Lan Wang; Fan Xu 2020 \\nTeaching Reform and Innovation in “College Movie English” Course under the \\nbackground of “Internet Plus” Lingjun Zheng 2020 \\nAdvanced practices: web technologies in the educational process and science Yelena Chaiko; Nadezhda Kunicina; Antons Patlins; Anastasia Zhiravetska 2020 \\nAnalysis and Design of Voice Assisted Learning System Based on Baidu AI Ru Zhang; Weiyang Chen; Min Xu; YangYang 2019 \\nPreparing Software Quality Assurance Professionals: Metamorphic Exploration for \\nMachine Learning Sen Yang; Dave Towey; Zhi Quan Zhou; T.Y. Chen 2019 \\nApplication of Virtual Reality in Building Interior Decoration Engineering Practice Yen-Kun Hsu; Szu-Hsien Peng; Meng-Shiou Wu 2019 \\nCultural Structures of Knowledge from Wikipedia Networks of First Links Maxime Gabella 2019  \\nReferences \\nAl Hadwer, A., Gillis, D., & Rezania, D. (2019 March). Big data analytics for higher \\neducation in the cloud era. In In 2019 IEEE 4th international conference on big data \\nanalytics (ICBDA) (pp. 203–207). IEEE. https://doi.org/10.1109/ \\nICBDA.2019.8713257.  \\nBlei, D. M., & Lafferty, J. D. (2009). Topic models. In Text mining (pp. 101–124). \\nChapman and Hall/CRC.  \\nBooth, A., Noyes, J., Flemming, K., Gerhardus, A., Wahlster, P., Van Der Wilt, G. J., \\nMozygemba, K., Refolo, P., Sacchini, D., Tummers, M., & Rehfuess, E. (2016). \\nGuidance on choosing qualitative evidence synthesis methods for use in health technology \\nassessments of complex interventions. Bremen (DE): Integrate-HTA.  \\nChen, J., Lu, H., Zhou, H., & Zhou, Y. (2019 August). Exploration on curriculum teaching \\nbased on OBE and AI. In In 2019 10th international conference on information \\ntechnology in medicine and education (ITME) (pp. 385–389). IEEE. https://doi.org/ \\n10.1109/ITME.2019.00093.  \\nCook, C. R., Kilgus, S. P., & Burns, M. K. (2018). Advancing the science and practice of \\nprecision education to enhance student outcomes. Journal of School Psychology, 66, \\n4–10. https://doi.org/10.1016/j.jsp.2017.11.004 \\nFan, J., & Zhi, L. (2020 August). Design and implementation of virtual immersive \\nclassroom in big data environment. In 2020 15th international conference on computer \\nscience & education (ICCSE) (pp. 430–432). IEEE. https://doi.org/10.1109/', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 16}),\n",
       " Document(page_content='classroom in big data environment. In 2020 15th international conference on computer \\nscience & education (ICCSE) (pp. 430–432). IEEE. https://doi.org/10.1109/ \\nICCSE49874.2020.9201648.  \\nFeng, Y., Zhan, G., & Li, Z. (2019 August). Research on the Co-construction and sharing \\nof teaching resources under the\" internet plus\" environment. In 2019 10th \\ninternational conference on information technology in medicine and education (ITME) \\n(pp. 498–502). IEEE. https://doi.org/10.1109/ITME.2019.00117.  \\nFryer, L. K., Ainley, M., Thompson, A., Gibson, A., & Sherlock, Z. (2017). Stimulating and \\nsustaining interest in a language course: An experimental comparison of Chatbot and \\nHuman task partners. Computers in Human Behavior, 75, 461–468. https://doi.org/ \\n10.1016/j.chb.2017.05.045 \\nFu, J. (2013). Complexity of ICT in education: A critical literature review and its \\nimplications. International Journal of education and Development using ICT, 9(1), \\n112–125. \\nHolon, I. Q. (2022). Global EdTech unicorns. January 22 https://www.holoniq. \\ncom/edtech-unicorns/. \\nHorn, M. B., & Staker, H. (2016). Blended leaning: 21st century learning revolution. \\nHui, Q. (2020 October). The application of computer information big data technology in \\ncollege English teaching. In 2020 international conference on computers, information \\nprocessing and advanced education (CIPAE) (pp. 345–350). IEEE. https://doi.org/ \\n10.1109/CIPAE51077.2020.00092.  \\nHwang, G. J., Sung, H. Y., Chang, S. C., & Huang, X. C. (2020). A fuzzy expert system- \\nbased adaptive learning approach to improving students’ learning performances by \\nconsidering affective and cognitive factors. Computers & Education: Artificial \\nIntelligence, 1, Article 100003. https://doi.org/10.1016/j.caeai.2020.100003 Joseph, S. I. T., Raj, S. B. E., & Kiyasudeen, J. M. (2020 November). Virtual reality–a \\nparadigm shift in education pedagogy. In 2020 seventh international conference on \\ninformation technology trends (ITT) (pp. 72–79). IEEE. https://doi.org/10.1109/ \\nITT51279.2020.9320880.  \\nLiang, Q., & Hainan, N. C. (2019 May). Adaptive learning model and implementation \\nbased on big data. In 2019 2nd international conference on artificial intelligence and big \\ndata (ICAIBD) (pp. 183–186). IEEE. https://doi.org/10.1109/ \\nICAIBD.2019.8836984.  \\nLiu, D. Y. T., Bartimote-Aufflick, K., Pardo, A., & Bridgeman, A. J. (2017). Data-driven \\npersonalization of student learning support in higher education. In Learning analytics: \\nFundaments, applications, and trends (pp. 143–169). Cham: Springer. https://doi.org/ \\n10.1007/978-3-319-52977-6_5.  \\nLi, H., & Wang, H. (2020 August). Research on the application of artificial intelligence in \\neducation. In 2020 15th international conference on computer science & education \\n(ICCSE) (pp. 589–591). IEEE. https://doi.org/10.1109/ICCSE49874.2020.9201743.  \\nLi, W., & Zhang, L. (2019 October). Personalized learning path generation based on \\nnetwork embedding and learning effects. In 2019 IEEE 10th international conference \\non software engineering and service science (ICSESS) (pp. 316–319). IEEE. https://doi. \\norg/10.1109/ICSESS47205.2019.9040721.  \\nLuo, S. (2019 October). Research on the change of educational management in the era of \\nartificial intelligence. In 2019 12th international conference on intelligent computation \\ntechnology and automation (ICICTA) (pp. 442–445). IEEE. https://doi.org/10.1109/ \\nICICTA49267.2019.00101.  \\nMondal, K. (2019 November). A synergy of artificial intelligence and education in the 21 \\nst century classrooms. In 2019 international conference on digitization (ICD) (pp. \\n68–70). IEEE. https://doi.org/10.1109/ICD47981.2019.9105727.  \\nPopay, J., Roberts, H., Sowden, A., Petticrew, M., Arai, L., Rodgers, M., … Duffy, S. \\n(2006). Guidance on the conduct of narrative synthesis in systematic reviews. \\nA product from the ESRC methods programme Version, 1(1), b92. \\nRanoliya, B. R., Raghuwanshi, N., & Singh, S. (2017 September). Chatbot for university', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 16}),\n",
       " Document(page_content='A product from the ESRC methods programme Version, 1(1), b92. \\nRanoliya, B. R., Raghuwanshi, N., & Singh, S. (2017 September). Chatbot for university \\nrelated FAQs. In 2017 international conference on advances in computing. In \\nCommunications and informatics (ICACCI) (pp. 1525–1530). IEEE. https://doi.org/ \\n10.1109/ICACCI.2017.8126057.  \\nSkinner, B. F. (1958). Teaching Machines: From the experimental study of learning come \\ndevices which arrange optimal conditions for self-instruction. Science, 128(3330), \\n969–977. \\nTang, Y., Liang, J., Hare, R., & Wang, F. Y. (2020). A personalized learning system for \\nparallel intelligent education. IEEE Transactions on Computational Social Systems, 7 \\n(2), 352–361. https://doi.org/10.1109/TCSS.2020.2965198 \\nTong, M. S., Zheng, H. Q., & Wan, G. C. (2019 December). Improvement of education \\nmethod by using artificial intelligence technology. In 2019 IEEE international \\nconference on engineering, technology and education (TALE) (pp. 1–5). IEEE. https:// \\ndoi.org/10.1109/TALE48000.2019.9225891.  \\nWalkington, C., & Bernacki, M. L. (2019). Personalizing algebra to students’ individual \\ninterests in an intelligent tutoring system: Moderators of impact. International Journal \\nof Artificial Intelligence in Education, 29(1), 58–88. https://doi.org/10.1007/s40593- \\n018-0168-1 A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 16}),\n",
       " Document(page_content='Computers and Education: Artificial Intelligence 3 (2022) 100068\\n18Wang, Y., Mu, C., Li, X., & Yang, Y. (2019 August). An applied research on big data \\nanalysis and mining technology in education. In 2019 international conference on \\nsensing, diagnostics, prognostics, and control (SDPC) (pp. 116–120). IEEE. https://doi. \\norg/10.1109/SDPC.2019.00029.  \\nXu, D., & Wang, H. (2006). Intelligent agent supported personalization for virtual \\nlearning environments. Decision Support Systems, 42(2), 825–843. https://doi.org/ \\n10.1016/j.dss.2005.05.033 \\nXu, F., Wang, L., & Gao, J. (2020 August). Thoughts on application of artificial \\nintelligence in teaching of different disciplines. In 2020 15th international conference \\non computer science & education (ICCSE) (pp. 703–707). IEEE. https://doi.org/ \\n10.1109/ICCSE49874.2020.9201885.  Yonezawa, S., McClure, L., & Jones, M. (2012). Personalization in schools. The Education \\nDigest, 78(2), 41–47. \\nZhang, K., & Aslan, A. B. (2021). AI technologies for education: Recent research & future \\ndirections. Computers & Education: Artificial Intelligence, 2, Article 100025. https:// \\ndoi.org/10.1016/j.caeai.2021.100025 \\nZhao, S., Chen, S., Li, W., Li, D., Liu, X., & Chen, J. (2020 August). The development of \\nartificial intelligence education resources under the background of the internet of \\nthings. In 2020 Chinese control and decision conference (CCDC) (pp. 2327–2332). \\nIEEE. https://doi.org/10.1109/CCDC49329.2020.9164663.  A. Bhutoria', metadata={'source': 'repositorio\\\\1-s2.0-S2666920X22000236-main.pdf', 'page': 17}),\n",
       " Document(page_content='FOCUS\\nA decision-support system for assessing the function of machine\\nlearning and artificial intelligence in music education for network\\ngames\\nZou Hong Yun1•Yasser Alshehri2•Noha Alnazzawi2•Ijaz Ullah3•Salma Noor4•Neelam Gohar4\\nAccepted: 16 July 2022 / Published online: 13 September 2022\\n/C211The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2022\\nAbstract\\nWith the impressive enhancement and development of computer technology, artiﬁcial intelligence (AI) and machine\\nlearning (ML) are implemented in every ﬁeld of life. Music is one of these sectors where AI and ML have been applied andgained traction in recent years. Both AI and ML are cutting-edge ﬁelds that are utilized to create and manipulate sounds in\\ngames, music, and other applications. Innovative and sophisticated approaches based on AI and machine learning are being\\nused to improve music teaching. Furthermore, by employing these methods, the sounds in games can be made moreefﬁcient and effective. Evaluation of the role of AI and ML in music education is one of the most difﬁcult and challenging\\nareas for teaching and learning researchers due to the use of these approaches. The Fuzzy Analytical Hierarchy Process\\n(Fuzzy AHP) approach was used to assess the role of AI and machine learning in music instruction. Fuzzy AHP is a basicand straightforward way of making better decisions based on criteria and options. In the proposed study, we used Fuzzy\\nAHP to determine the weightages of seven criteria and ﬁve alternatives. When we tested these paradigms, we got good\\nresults that let us move forward and improve the principles and framework for AI and ML to help music education growcreatively.\\nKeywords Music education /C1Computer game /C1Intelligent approach /C1Machine learning /C1AI/C1Fuzzy AHP\\n1 Introduction\\nArtiﬁcial intelligence and machine learning are emerging\\nﬁelds that have attracted an increasing number of new-\\ncomers in recent years. AL and ML are the two fastest-\\ndeveloping technologies in human science and technologyhistory with major breakthroughs in the ﬁelds of musiceducation, games, and robotics. The music sector is boos-\\nted as a result of the application of these technologies, and\\ncomposers have more options to produce efﬁcient andeffective music, which may then be embedded in computer\\ngames to make them more appealing. Composers have an\\ninteractive and efﬁcient environment and tools to writeattractive and effective music as well as improved music\\ninstruction for games, with recognitions of AI and machine\\nlearning technologies. Nowadays, sound is an importantcomponent of effective games, as gamer believe that sound\\nwill make games more persuasive and effective.\\nResearch has thoroughly analyses some major tech-\\nniques to use AI in music education (Holland 2000 ). The\\ndiscipline is highly interdisciplinary, involving substantial\\nparticipations from different disciplines such as music,education, AI, human computer interaction and many other\\ndisciplines. Furthermore, AI in music education itself is a\\nvery emerging ﬁeld which make the usage of musiceffective and efﬁcient for various purposes such as com-\\nputer games and others. Shang ( 2019 ) has presented a study\\nthat reviewed the development history along with evolutionCommunicated by Shah Nazir.\\n&Ijaz Ullah\\nijaz.ullah@masterschool.eitdigital.eu\\n1College of Art, Hubei Polytechnic University, Hubei\\nProvince, Huangshi 435003, China\\n2Computer Science and Engineering Department, Yanbu\\nIndustrial College, Royal Commission for Jubail at Yanbu,Yanbu Industrial City, Yanbu, Saudi Arabia\\n3Department of Informatics, University of Rennes 1, Rennes,France\\n4Shaheed Benazir Bhutto Women University Peshawar,,Peshawar, Pakistan\\n123Soft Computing (2022) 26:11063–11075\\nhttps://doi.org/10.1007/s00500-022-07401-4 (0123456789().,-volV) (0123456789(). ,- volV)', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 0}),\n",
       " Document(page_content='of AI technology in music education. The study has dis-\\ncussed the usage and implementation of AI in music edu-\\ncation. Furthermore, the study equated and reviewed the\\nbeneﬁts and drawbacks of traditional as well as AI-appliedmusic education mode. In addition, it has examined the\\noutcomes of the study statistically via questionnaire, and\\nassumed that the integration of music education and AI willbe the novel trend of the upcoming music education.\\nStraeubig ( 2020 ) has observed remarkable enhancements in\\nthe gaming industry using artiﬁcial intelligence technology.\\nWhile these developments are explained in terms of tech-\\nnological progress, the way people address their culturaland societal impact is largely decoupled. The study pro-\\nposes a substitute rhetoric by guessing about the develop-\\nment of AI in the societal system. The study furtherdiscussed the usage and implementation of artiﬁcial intel-\\nligence and machine learning in the video game industry\\nand studied a good understanding of AI in games alongwith committed AI programmers. Digital games have\\ngained importance as a new model in education and are\\neasily accessible as well as affordable for anyone, whichmakes them usable and effective. Digital games offer\\nopportunities for at-scale teaching and learning.\\nGiannakos et al. ( 2020 ) have presented a study to review\\nnovel research into games for assisting AI and ML in\\neducation. After studying concisely, the related research\\nand games are selected and included in this qualitativecontent investigation. Based on the evaluation, the study\\nproposes a summary of related articles and games, as well\\nas how many games offer a speciﬁc opportunity todemonstrate the amount of several concepts in AI and ML.\\nIn the music ﬁeld and games, AI and ML technologies play\\na primary role. And AI and ML provided more tools toenhance music education and develop attractive and\\nmemorable games. Moreover, music is used in games to\\nmake them more attractive and memorable which in turnimproves the players’ interest in playing games. The con-\\ntributions of the proposed study are following:\\n•To discuss the AI and ML paradigms and their role in\\nmusic education and games.\\n•To evaluate the efﬁcient and effective role of AI and\\nML in music education.\\n•To evaluate the role of these AI and ML paradigms in\\nmusic education for games using Fuzzy AHP method tomeasure the overall weightage.\\nThe paper is structured in the sections as; Sect. 2dis-\\ncusses the literature associated to the proposed research.\\nSection 3shows the detail of the methodology and ﬂow of\\nthe proposed research. Results and discussions are given inSect. 4. The paper is concluded in Sect. 5.2 Literature review\\nAL and ML are the two most rapidly evolving primary\\ntechnologies in human science and technology history,\\nwith notable successes in ﬁelds, such as music instruction,\\ngames, and robots. Researchers are attempting to developdifferent techniques for evaluating the contribution of AI\\nand machine learning in game and music teaching. As a\\nresult, a variety of techniques have been devised. Zhouet al. ( 2017 ) have focused on a study that proposes a col-\\nlaborative and good platform for game AI education called\\nBotzone, aiming to make easy the teaching procedure ofgame AI courses and encourage the AI students to self-\\nstudy. Botzone is a general online game AI platform that is\\ndesigned to assess different employments of game AI byimplementing them as mediators in a diversity of games\\nand playing with each other. The presented platform has\\nbeen efﬁciently utilized in several artiﬁcial intelligence\\ncompetitions and courses. Furthermore, the structure and\\nfeatures of Botzone are studied and explained. Recently,artiﬁcial intelligence technology has evolved rapidly and\\nbrought a lot of enhancements in both research and\\nindustry. Amato et al .(2019 ) have presented a study that\\ndiscusses upcoming technological advances in the ﬁeld of\\nartiﬁcial intelligence as well as their emerging impact on', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 1}),\n",
       " Document(page_content='industry. Amato et al .(2019 ) have presented a study that\\ndiscusses upcoming technological advances in the ﬁeld of\\nartiﬁcial intelligence as well as their emerging impact on\\ninventive industries. The study objective is to offer arealistic perception of the scope of AI actions in inventive\\norganizations, present a vision of how this technology can\\nparticipate for research and invention purposes in such acontext, and ﬁnd exploration and progress challenges.\\nCarbonell et al. ( 1983 ) have proposed a study that\\nnegotiates the objective of machine learning along withcomputer modelling of learning processes in their several\\nmanifestations, ﬁnding the theme matter of machine\\nlearning. The machine learning discipline is organizedaround three main research focus which are task-oriented\\nstudies, cognitive simulation, and theoretical analysis.\\nAdditionally, an equally elementary scientiﬁc aim ofmachine learning is the research of alternative learning\\nappliances, including the ﬁnding of different induction\\nalgorithms, which also discusses the scope and drawbacksof certain approaches, along with the information that must\\nbe accessible to the students. Avdeeff ( 2019 ) has developed\\nan overview that studies the ﬁrst AI-human interactedalbum, which uses Sony’s Flow Machine technologies. The\\nstudy reviews the existing and developing applications of\\nartiﬁcial intelligence in popular music creation, as well aslinks those applications with myths and uncertainties that\\nhave been distributed in discourses about the usage of AI in\\ngeneral, and how these uncertainties link to the idea of anaudio uncanny valley. By presenting the concept of AIPM,\\nthe study provides a lens through which to analyze the11064 Z. HongYun et al.\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 1}),\n",
       " Document(page_content='newer and infrequent melodies and harmonization made\\npossible through AI music generation and interrogates how\\nthis content equates to the broader speculations about\\nauthenticity in popular music as well as wider expectationsof anthropocentric inventiveness. Sidana ( 2019 ) has\\naddressed a study to evaluate the usage and implementation\\nof artiﬁcial intelligence and its effectiveness in the ﬁeld ofeducation. The study searched for and collected 26 usable\\narticles from Google Scholars, which were negotiated from\\nthe aspects of conceptual outline, uses, and assessment of\\nartiﬁcial intelligence. Several conceptual outlines were\\nidentiﬁed in the study. The existing study discusses thenumerous kinds of AI uses in teaching, music education,\\nreading, and drawing, and so on, and tests them success-\\nfully. Furthermore, the study also successfully assessed theseveral uses of AI. However, sometimes slower speed and\\nsoftware glitches arise, and sometimes no beneﬁts of uti-\\nlizing the equipment over conventional tutoring areobserved. Hamdaoui et al. ( 2015 ) have conducted research\\non how educational games ensure a functional educational\\nexperience as well as enjoyable gameplay for each type ofstudent or gamer. By using different AI algorithms, the\\nmost proﬁtable video games adapt the playing involvement\\nto the gamer. The study presents an adaptive mechanismthat consists of two bricks called ‘‘AI brick’’ and ‘‘IMSLD\\nbrick.’’ The AI brick will adapt the game play based on the\\ngamer’s gaming fashion, own decisions and performance inthe game. While the IMSLD brick will be based on IMSLD\\ncomponents to adapt the education content based on the\\nplayer’s or student’s understanding and learning fashion.Thus, at the same time, the study makes sure of the fun as\\nwell as the operative educational experience.\\nMich ( 2020 ) has proposed a study that AI is assisting in\\nthe computerization of tasks as well as activities that alter\\nthe job landscape as much as they have impacted on our\\ndaily routine. The ﬁrst chapter of the study discusses the AIdeﬁnition and its major research areas, along with its uses.\\nThe next part also negotiates the nature and importance of\\nmachine learning for AI solicitations. Current techniquesare also categorized and illustrated. Furthermore, the study\\nexplained the AI equipment along with solutions for\\nassisted functionalities and automation tasks. At the end,the upcoming trends as well as risks relevant to the uses of\\nAI are deliberated. Nart ( 2016 ) has been shown in a study\\nthat the role of tutor has altered as the traditional teachingapproaches, uses, and strategies have left its position to the\\nlearner-centered methods, strategies, and uses of the\\ntwenty-ﬁrst century. The major goal of the study is toidentify the software utilized that seemed to be beneﬁcial\\nin music education as well as the application of software in\\nmusic education. To determine these goals, the studyanalyzed the publications and research of existing literature\\nusing a screening approach and the gathered data wasbrought together and interpreted. In the end, it was con-\\ncluded that there is a lot of software available to be used in\\nmusic education, which offers an efﬁcient and effective\\neducation method for both tutors and learners. Yu and Ding(2020 ) have developed that AI tutoring is a primary part of\\ninternet education and an inevitable trend of the period. AI-\\ncreated robots detect infants’ voice emotions and auto-matically identify and play functional music. Some music\\nrobots with certain neural networks can recognize music,\\nexamine music, and make music. In the professional music\\nlearning discipline, all types of novel collaborative teach-\\ning music intelligent systems grounded in music AI tech-nology will be a novel mode of observing music, cognitive\\nmusic, inventing music along with music learning. Recent\\ndevelopments of artiﬁcial intelligence technology broughta lot of enhancement in music education. Yang ( 2020 ) has', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 2}),\n",
       " Document(page_content='music, inventing music along with music learning. Recent\\ndevelopments of artiﬁcial intelligence technology broughta lot of enhancement in music education. Yang ( 2020 ) has\\nconcentrated on a study that presents a music tutoring\\ntechnique based on AI to overcome the limitations of tra-ditional music instructing techniques. In order to enhance\\nthe quality of music tutoring, the novel method combines\\nthe characteristics of traditional music education with thoseof artiﬁcial intelligence. The investigational outcomes\\nindicate that AI can efﬁciently enhance the quality of tra-\\nditional music instruction as well as excellently promotethe growth of music learning.\\nZhaoran ( 2021 ) has focused a study that explains the\\ndifference between listening to music activities has beenfocused. The survey was arranged to ﬁnd out the impact of\\nmusic education. The outcomes indicate that listening to\\nmusic is an essential hobby, speciﬁcally when most kidsare open to music. Furthermore, the study indicates that\\nhome music schools and music schools have a moderately\\ngood attitude towards meeting several machine learning aswell as processor home music tutoring activities such as\\nlistening and chilling at home, making emotional as well as\\nsocial connections, along with inspiration and active edu-cation relevant to a speciﬁc topic and music school. Sturm\\net al. ( 2019 ) have proposed a study that implements\\nmachine learning to music modelling and typically presentsmodel designs, coaching techniques along with datasets, as\\nwell as measures the performance of the system utilizing\\nquantitative measures like qualitative listening tests. Thestudy intends to investigate its usefulness and impact on\\npractical experts, and then build on those ﬁndings to inform\\nthe growth and applications of machine learning. Further-more, the study develops and utilize numerous uses of\\nmachine learning for music invention as well as shows an\\nopen performance of the outcomes. Ceylan et al. ( 2021 )\\nhave presented a study that shows music genre classiﬁca-\\ntion is one of the most efﬁcient and reliable methods in\\nmusic classiﬁcation. The study’s goal is to develop a deeplearning algorithm that can categorize ten different music\\ngenres. The study makes the classiﬁcation through theA decision-support system for assessing the function of machine learning and artiﬁcial … 11065\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 2}),\n",
       " Document(page_content='GTZAN dataset to expose the effectiveness of the model\\nby relating it with others. Furthermore, the analysis utilizes\\na CNN to categorize music genres, taking into account the\\nearlier successful outcomes. Finally, the study develops amodel that performs better in categorizing music genres by\\nutilizing fewer data points than previous revisions. Jam-\\nshidi et al. ( 2021 ) have focused on a study whose objective\\nis to lay the foundation for education and performing music\\nvirtually. MOOCs are developing as we are moving toward\\nvirtual classes. Through MOOCs, existing music courses\\nmostly concentrate on peer assessment as a means of\\nevaluating the learners’ performance. The key aim of thestudy is to condense the teacher’s load as well as offer a\\nvirtual concurrent performance response. As a contribution\\nto music learning, the study presents a novel technologicaloutline to computerize music education for learning how to\\nplay any preferred song through current machine learning\\nstrategies for ﬂexibility in numerous learning fashions. Pan.(2021 ) has developed a study that demonstrates how the\\ncollaboration of AI technology and advanced information\\ntechnology has enabled a novel way for the enhancementof the modern music industry. With the development of\\nvirtual learning, virtual classes, and other tutoring\\napproaches, the modern music learning mode has begun toundergo signiﬁcant changes. The integrated use of artiﬁ-\\ncially functional technology in the discipline of music\\nlearning can better reform music education. In addition, thestudy also negotiates the collaboration of artiﬁcial intelli-\\ngence with music education in real-world cases. Xu et al.\\n(2021 ) have concentrated on a study that found music\\ninformation is broadly utilized in music information\\nretrieval, music suggestion, music therapy, and so on. The\\nstudy made connections between audio features, individualfactors, and emotions by implementing machine learning\\napproaches. In order to predict the supposed emotion and\\nfelt emotion of music correspondingly, they utilized audiofeatures along with individual features as input. The out-\\ncomes indicate that the actual individual features can\\nexpressively enhance the model’s effect as well as thatconstant individual features have no effect.\\nTian ( 2020 ) The features of generality as well as\\nuniqueness of music key learners in autonomous educationin the network atmosphere are examined through the\\nanalysis and study on the autonomous education of music\\nmain learners in the network atmosphere, and some issuesare discovered in the study presented solutions to these\\nissues to assist learners of music majors to utilize scientiﬁc\\nand improved virtual education methods to learn musictheory education along with abilities built up to compen-\\nsate for the deﬁciency of traditional instructing approaches\\nand attain the purpose of sponsoring as well as enhance theeffectiveness of learning. Yuan ( 2020 ) has proposed a\\nstudy in which the status quo of the universal deﬁciency ofAI elementary knowledge in postgraduates at conservato-\\nries of music and art is examined. The requirement of\\nproviding standard science subjects in ‘‘Music and AI’’ is\\nhighlighted. The interdisciplinary article outcomes in theAI and music education disciplines are explained, catego-\\nrized, and shortened. Also, the study presented and\\nexplained the contents of the standard science subject‘‘Music and AI’’ in detail. Zhang and Yang ( 2021 ) have\\npresented a study that reviews the related knowledge of\\nmachine learning as well as some important complications\\nin the development of the Ologit model and also shows\\nsome particular ideas for designing a distance tutoringsystem for music and dance developments based on the\\nexisting college syllabus system setting. Furthermore, the\\nstudy examines the particular condition of the distancemusic dance learning system to enhance the learning value\\nof music dance courses and has faith that a learning variant', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 3}),\n",
       " Document(page_content='study examines the particular condition of the distancemusic dance learning system to enhance the learning value\\nof music dance courses and has faith that a learning variant\\nmodel can be built to increase the learners’ attentiveness inthe courses of music dance. In addition, the study efﬁ-\\nciently enhanced the quality of music and dance education.\\nMicheloni et al. ( 2019 ) have focused on a case-study that\\ndiscusses a videogame called Musa, in which gamers are\\nled into an imaginary world where music is magic, as well\\nas every movement is carried out through it, integratedwith an educational path, to make gamers capable of\\nlearning and, in continuous moments, to summarized this\\nknowledge from a game, just by playing. The videogamewas evaluated, and the results show that learners are cap-\\nable of learning some fundamental knowledge to play the\\npiano during the game after the ﬁrst couple of sessions.Additionally, the outcomes found from the experiment\\npoint out the tangible opportunity to use this application\\nwith numerous tools such as guitar, ﬂute, or voice. Dai.(2021 ) has focused on a study to analyzed the intelligent\\ntutoring design with the assistance of AI technology. The\\nstudy employs cutting-edge information technologies suchas big data, IoT, and mobile internet, as well as AI, to\\ncreate a comprehensive set of scientiﬁcally intelligent\\nmusic tutoring design models. Perception instructing offersa recommendation for the overall process, before, during,\\nas well as after class, assisting tutors to better carry out\\nwisdom instructing, assisting learners to expand interactiveand autonomous education, as well as promoting the wis-\\ndom conversion of tutoring approaches along with learning\\napproaches to an assured extent. Furthermore, musicclassroom tutoring has become more directed and efﬁcient.\\nChen and Wen. ( 2021 ) have developed a study that rec-\\nommends the Music Composition along with MelodyGeneration Adjustable (MCMGA) architecture to develop\\nadaptive music. Its key aim is to develop music in real-time\\nthat reﬂects numerous moods that can be achieved via asolo combination of the chord-sequence originator on a\\ncross graph. Also, the study examined a search melody11066 Z. HongYun et al.\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 3}),\n",
       " Document(page_content='predictor along with an emotional expression concept. Two\\nquantitative consumer studies were found by testing the\\nprogram. The ﬁrst is based on music generation, while the\\nsecond is based on valence expression through total dis-sonance. The study results indicate that every other portion\\nof the creation and propagation grows the perceptual worth\\nof the produced music along with the relative efﬁciency ofthe analysis of reactivity through dissonance grounded on\\ndifferent parameters such as accessibility, usability, and so\\non.\\n3 Methodology\\nArtiﬁcial intelligence and machine learning are two cut-ting-edge technologies that are used to create and modify\\nsounds in games, music, and other applications. To\\nimprove music education, innovative and advanced tech-nologies based on AI and machine learning are being\\ndeployed. Additionally, using these strategies, game noises\\ncan be made more efﬁcient and effective. Due to the usageof these methodologies, evaluating the function of AI and\\nML in music education is one of the most demanding and\\ndifﬁcult topics for teaching and learning researchers. Plutand Pasquier ( 2020 ) have mentioned that music is an\\nimportant part of videogames and plays a key role in the\\nenhancement of the gaming industry. Most of the writers ofthe music used in games are human composers, and the\\nmusic is played as a linear piece behind gameplay. Adap-\\ntive or creative music systems can be used to lengthen themusical content or make novel musical content utilizing AI\\nand algorithms. In addition, the study proposes a classiﬁ-\\ncation of generative music in games to enable analysis andnegotiation of generative music systems. Also, the study\\nshows an analysis of the existing state of the art of gen-\\nerative music systems in games, as well as negotiates thechallenges and perceptions of generative music for games.\\nBarate `et al. ( 2013 ) have concentrated on a study that\\nproved that possessive games have proved to be an efﬁcienttool in several disciplines. The key aim of the study is to\\ndemonstrate some potential uses for music and their ben-\\neﬁts. The study also offered a number of deﬁnitions alongwith examples focusing on the use of serious games in\\nmusic learning. After indicating a universal method to this\\nproblem, the next part of the study concentrated on amultilayer technique for music information to get a rich\\nand comprehensive music description for a music piece.\\nFurther, the study indicates some case studies and uses.Rogers ( 2017 ) has proposed that there are several forms of\\nsound in games, and they have the potential to efﬁciently\\nimpact the gamer experience. The study examines that howthe existence of several kinds of audio impacts gamer\\nimmersion, interaction, and efﬁciency and also analyze theusage and implementation of audio in the increasingly\\nimmersive virtual reality gaming technology. Furthermore,\\nthe study explores how audio design impacts the gamer\\nexperience in traditional and VR games, and also helps toconsider the usage of sound within gamer-game collabo-\\nration, by observing the immersive effect of particular\\naudio kinds along with their differences.\\nMostly decisions include uncertainty and ambiguity that\\nare normally faced in every sector of life. To handle these\\nissues and evaluate the role of AI and ML, we used Fuzzy\\nAnalytical Hierarchy Process (Fuzzy AHP) method. Fuzzy\\nAHP method is the extended form of AHP method used todeal with uncertainty, ambiguity, and fuzzy judgement but\\nmostly used in multi-criterions decision-making compli-\\ncations. In the presented study, Fuzzy AHP method is usedto assessed the role of AI and ML paradigms in music\\neducation for games. Figure 1shows the goal, criterions\\nand alternatives. Here the goal is to evaluate the role of AIand ML, criterions are qualitative, responsive, formalized,\\nbeneﬁcial, speciﬁcity, rationality, and performance along\\nwith different alternatives which are presented as paradigm1, paradigm 2, paradigm 3, paradigm 4, and paradigm 5.', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 4}),\n",
       " Document(page_content='beneﬁcial, speciﬁcity, rationality, and performance along\\nwith different alternatives which are presented as paradigm1, paradigm 2, paradigm 3, paradigm 4, and paradigm 5.\\n3.1 Features extraction and selection\\nWe read the literature and mined several features from itfor the aim of gathering features, as indicated in Table 1.\\nFollowing the collection of features from previous work,\\nwe chose seven common features for evaluating AI and\\nmachine learning technologies in music learning as shownin Table 2. These features are widely used in many sug-\\ngested studies.\\n3.2 Fuzzy AHP for weight calculation using\\ngeometric mean method\\nThe current research created a decision matrix for these\\nfeatures and give values to them which are given below:\\nStep 1. Draw a pairwise Decision matrix n*n.\\nA¼a11 ... a1n\\na21 ... a2n\\nan1 ... ann2\\n43\\n5 ð1Þ\\nStep 2. Replace linguistic numbers by fuzzy numbers.\\nFor reciprocal the formula is:\\nA/C01¼l;m;u ðÞ/C01¼1=u;1=m;1=l ðÞ ð 2Þ\\nwhereas l is lower number, m is middle number, and u is\\nupper number.\\nStep 3. We calculate the Fuzzy geometric value by the\\ngiven formula.A decision-support system for assessing the function of machine learning and artiﬁcial … 11067\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 4}),\n",
       " Document(page_content='Fuzzy geometric value riðÞ\\n¼A1/C3A2...::/C3An\\n¼ l1;m1;u1 ðÞ /C3 l2;m2;u2 ðÞ /C3 l3;m3;u3 ðÞ /C3 ... ... ::/C3ln;mn;un ðÞ ðÞ\\n¼ l1/C3l2/C3l3/C3...::/C3ln ðÞ1=n;/C16\\nm1/C3m2/C3... ... /C3mn ðÞ1=n;u1/C3u2/C3... ... /C3un ðÞ1=n/C17\\nð3Þ\\nwhere ‘‘n’’ indicate the number of criteria.\\nStep 4. For measuring the fuzzy weights (W i), we know\\nthe formula which is;\\nWi¼ri/C3r1;r2;r3;... ... ::;r10 ðÞ/C01ð4Þ\\nStep 5. Defuzziﬁcation: Weights are measured through\\nthe following formula:\\nCentre of Area wiðÞ ¼ lþmþu=3 ð5Þ\\nby implementing the above average formula, we get the\\nweight values from fuzzy weights.\\nStep 6. If the total sum of weights is greater than 1 so\\ntransform weight values to normalized form. The formula\\nfor normalized weights are,\\nNormalized Weights ¼wiPiwið6Þ\\nThe fuzzy scale is given in Table 3.By applying step 1, we draw a pair-wise decision matrix\\nof 7*7 which is consists of criterions and their values as\\nshown in Table 4.\\nThrough the implementation of step 2, here the lin-\\nguistic numbers are replaced by fuzzy numbers which is\\nused for further calculation like ﬁndings weightage etc. as\\nshown in Table 5.\\nBy using Eq. 3, the fuzzy geometric mean value of each\\ncriteria is calculated and used for further calculation like\\nﬁndings fuzzy weights etc. as shown in Table 6.\\nHere multiple steps from 4 to 6 are applied to calculate\\nmultiple values such as fuzzy weight values, weights and\\nnormalized weights values. Also ranked each criteriaaccording to their value. In addition, the given table is\\nrepresenting the weightage value of each criteria and their\\nranking as shown in Table 7.\\nFigure 2indicating the ranking of criterions while rep-\\nresenting that each criteria has different color.\\nRepeat step 1 to 6 for all levels of the hierarchy, look the\\ntables from 7 to 13.\\nTo calculate the weightage of alternatives, we draw\\nalternatives based decision mat rix based on qualitative crite-\\nria. The given matrix is 5*5 and containing the values of each\\nalternative along with Fuzzy Geometric values, fuzzyweights, weights and normalized weights and steps 1 to 6 is\\nrepeated for the overall calculation as shown in Table 8.\\nIn the given Table 9, we draw a pair-wise comparison\\nmatrix having alternatives based on responsive criteria.\\nAlso it contains fuzzy numbers and different values like\\nFig. 1 Goal, criterions and alternatives of the proposed approach11068 Z. HongYun et al.\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 5}),\n",
       " Document(page_content='fuzzy geometric values, fuzzy weights and weightage of\\neach alternative.\\nTo calculate weightage of alternatives, we draw a pair-\\nwise decision matrix of alternatives based on formalizedcriteria and identify the normalized weightage values of\\neach alternatives as shown in Table 10.Table 1 Extracted features from literature review\\nCitations Extracted features\\nHolland ( 2000 ) Substantial, Cognitive psychology, autonomous, interaction, abbreviate, reasonable, formalized, Well-deﬁned,\\nExpressive, Sophisticated, Quality, Clear\\nStraeubig ( 2020 ) Constructive, Consciousness, Affordable credit, parametrized, Computational Creativity, Novelty, Usefulness, Creative,\\nResponsive\\nZhou et al. ( 2017 ) Expandability, Simpliﬁed, Competitive, Interactive, Repetitive, Real-time, Complexity, Validating, Optimization,\\nExpansible, Supportive, Rationality\\nAmato et al. ( 2019 ) Creative, Accurate, Realistic, Media Diversity, Personalization, Inclusivity, Cost, Efﬁciently, Interactive endeavor,\\nInnovative, Complexity, Expressivity, Qualitative, Formalized\\nAvdeeff ( 2019 ) Authenticity, Speciﬁcity, Creativity, Captivating, Interaction, Generative Modelling, Extensive, Quality, Responsive,\\nConcretize, Rationality\\nSidana ( 2019 ) Effectiveness, Conceptual, Augmented, Efﬁciency, Possibility, Applicability, multi-agent systems, inadequacy, modify,\\nQualitative, Comprehensible, Interactive, Supportive, Responsive\\nNart ( 2016 ) Accessible, Manageable, Beneﬁcial, Effective, Efﬁcient, Descriptive, Interactive, Useful, Concretize, Comprehensive,\\nFormalized\\nYu and Ding ( 2020 ) Sensitivity, Interactive, Cognitive, Manageable, Complexity, Stability, Rationality, Accuracy\\nZhaoran. ( 2021 ) Qualitative, Performance, standardized, Effective, Scaffolding, Exactness, Efﬁciently, Accuracy, Interactive\\nSturm et al. ( 2019 ) Qualitative, Usefulness, Beneﬁcial, Effectively, Performance, Creative, Acceptable, Sensible, Speciﬁcity\\nCeylan et al. ( 2021 ) Valid, Effective, Efﬁciency, Complex, Maintaining, Accuracy, Meaningful, Performance, Storage\\nJamshidi et al.\\n(2021 )Performance, Real-time, Sizes, Automate, Adaptability, Qualitative\\nTian ( 2020 ) Autonomous, Knowledge, Efﬁciency, Reasonable, Effectively, Accessible, Speciﬁcity, Availability, Accurate,\\nYuan ( 2020 ) Rationality, Sensibility, Interactive, Effective, Efﬁciency, Optimize, Performance\\nZhang and Yang\\n(2021 )Diversify, Attentive, Viability, Speciﬁcity, Quality, Reasonable, Efﬁciency, Synthesized\\nDai ( 2021 ) Personalized, Adaptive, Efﬁciency, Interactive, Effective, Accurately, Dynamic, Qualitative, Performance, Stability,\\nFormalized, Beneﬁcial\\nChen and Wen\\n(2021 )Quality, Real-time, Adaptive, Feasible, Effectiveness, Reactivity, Usability, Accessibility, Performance, Adjustable,\\nResponsive, Rationality\\nPlut and Pasquier\\n(2020 )Generative, Sequential, Descriptive, Interaction, Rationality, Adaptive, Real-time, Resource-intensive, Performance\\nFolorunso et al.\\n(2021 )Accuracy, Time-domain, Performance, Descriptive, Consistent, Compatible, Optimize\\nBarate `et al. ( 2013 ) Effective, Notable, Cognitive, Intellectual, Interactivity, Usable, Responsive, Speciﬁcity, Rationality, Computer-driven\\nTable 2 Select common\\nfeaturesNo Features\\n1 Qualitative\\n2 Responsive3 Formalized4 Beneﬁcial5 Speciﬁcity6 Rationality7 PerformanceTable 3 Fuzzy scale\\nEqual Moderate Strong Very strong Extremely strong\\n13 57 9\\n(1,1,1) (2,3,4) (4,5,6) (6,7,8) (9,9,9)Intermediate values24 68(1,2,3) (3,4,5) (5,6,7) (7,8,9)A decision-support system for assessing the function of machine learning and artiﬁcial … 11069\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 6}),\n",
       " Document(page_content='Table 4 Pair-wise comparison matrix\\nIndex Criteria Qualitative Responsive Formalized Beneﬁcial Speciﬁcity Rationality Performance\\n1 Qualitative 1 5 1/3 4 7 1/2 3\\n2 Responsive 1/5 1 2 3 1/4 1/3 63 Formalized 3 1/2 1 1/5 6 4 1/34 Beneﬁcial 1/4 1/3 5 1 4 3 1/55 Speciﬁcity 1/7 4 1/6 /C144 1 1/2 5\\n6 Rationality 2 3 1/4 1/3 2 1 77 Performance 1/3 1/6 3 5 1/5 1/7 1\\nTable 5 Fuzziﬁed pair-wise decision matrix\\nIndex Criteria Qualitative Responsive Formalized Beneﬁcial Speciﬁcity Rationality Performance\\n1 Qualitative 1,1,1 4,5,6 1/4,1/3,1/2 3,4,5 6,7,8 1/3,1/2,1/1 2,3,4\\n2 Responsive 1/6,1/5,1/4 1,1,1 1,2,3 2,3,4 1/5,1/4,1/3 1/4,1/3,1/2 5,6,73 Formalized 2,3,4 1/3,1/2,1/1 1,1,1 1/6,1/5,1/4 5,6,7 3,4,5 1/4,1/3,1/2\\n4 Beneﬁcial 1/5,1/4,1/3 /C144,1/3,1/2 4,5,6 1,1,1 3,4,5 2,3,4 1/6,1/5,1/4\\n5 Speciﬁcity 1/8,1/7,1/6 3,4,5 1/7,1/6,1/5 1/5,1/4,1/3 1,1,1 1/3,1/2,1/1 4,5,66 Rationality 1,2,3 2,3,4 1/5,1/4,1/3 1/4,1/3,1/2 1,2,3 1,1,1 6,7,87 Performance 1/4,1/3,1/2 1/7,1/6,1/5 2,3,4 4,5,6 1/6,1/5,1/4 1/8,1/7,1/6 1,1,1\\nTable 6 Fuzzy geometric value ( r)\\nCriteria Qualitative Responsive Formalized Beneﬁcial Speciﬁcity Rationality Performance Fuzzy Geometric value\\nQualitative 1,1,1 4,5,6 /C144,1/3,1/2 3,4,5 6,7,8 1/3,1/2,1/1 2,3,4 1.41,1.81,2.37\\nResponsive 1/6,1/5,1/4 1,1,1 1,2,3 2,3,4 1/5,1/4,1/3 /C144,1/3,1/2 5,6,7 0.70,0.92,1.19\\nFormalized 2,3,4 1/3,1/2,1/1 1,1,1 1/6,1/5,1/4 5,6,7 3,4,5 /C144,1/3,1/2 0.87,1.12,1.49\\nBeneﬁcial 1/5,1/4,1/3 /C144,1/3,1/2 4,5,6 1,1,1 3,4,5 2,3,4 1/6,1/5,1/4 0.79,0.99,1.25\\nSpeciﬁcity 1/8,1/7,1/6 3,4,5 1/7,1/6,1/5 1/5,1/4,1/3 1,1,1 1/3,1/2,1/1 4,5,6 0.54,0.66,0.85Rationality 1,2,3 2,3,4 1/5,1/4,1/3 /C144,1/3,1/2 1,2,3 1,1,1 6,7,8 0.93,1.31,1.71\\nPerformance /C144,1/3,1/2 1/7,1/6,1/5 2,3,4 4,5,6 1/6,1/5,1/4 1/8,1/7,1/6 1,1,1 0.48,0.58,0.72\\nTable 7 Criterions weightages and Ranking using Fuzzy Geometric value\\nIndex Criteria Fuzzy geometric value ( ri) Fuzzy weights ( Wi) Weights ( wi) Normalized weights Ranking\\n1 Qualitative 1.41,1.81,2.37 0.146,0.244,0.412 0.267 0.246 1\\n2 Responsive 0.70,0.92,1.19 0.072,0.124,0.207 0.134 0.123 5\\n3 Formalized 0.87,1.12,1.49 0.090,0.151,0.259 0.166 0.153 34 Beneﬁcial 0.79,0.99,1.25 0.082,0.133,0.217 0.144 0.133 45 Speciﬁcity 0.54,0.66,0.85 0.056,0.089,0.147 0.097 0.089 66 Rationality 0.93,1.31,1.71 0.096,0.176,0.297 0.189 0.174 27 Performance 0.48,0.58,0.72 0.049,0.078,0.125 0.084 0.077 711070 Z. HongYun et al.\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 7}),\n",
       " Document(page_content='For the calculation of weightage of each alternative, we\\ndraw n*n matrix of alternatives based on beneﬁcial criteria\\nby repeating steps 1 to 6 as shown in Table 11.\\nBy repeating and applying steps 1 to 6, we draw the\\nmatrix and calculate the normalized weight of each alter-\\nnative based on speciﬁcity criteria as shown in Table 12.\\nTable 13indicating the normalized weight values of\\neach alternative based on rationality criteria and the values\\nis calculated by using the above Eqs. 1,2,3,4,5and6\\nHere, we draw alternatives pair-wise comparison matrix\\nbased on performance criteria and calculate the normalizedweightage of each alternative using the given equations as\\nshown in Table 14.\\nIn the given Table 15, we calculate results and ranking\\neach alternative by using the following formula.\\nW1\\nW2\\n:\\n:\\n:2\\n666643\\n77775/C3w11 w12 w1m\\nw21 w22 w2m\\n:::\\n:::\\nwm1wm2wmm2\\n666643\\n77775ð7Þ\\nwhere ‘‘m’’ shows the number of alternatives.\\nBy employing the given matrix formula, we calculate\\nthe results of all given alternatives and ranking them as\\nshown in Table 15.\\nFigure 3representing the results and rankings of each\\nalternative. While results values have blue color and\\nrankings have orange color.\\n4 Result and discussions\\nDue to the rapid development of computer technology,artiﬁcial intelligence and machine learning approaches areused and implemented in every sector of life. Music\\n01234567\\nRankingCriterions Ranking\\nQualita/g415ve Responsive Formalized Beneﬁcial\\nSpeciﬁcity Ra/g415onality Performance\\nFig. 2 Rankings of criterions\\nTable 8 Alternatives pair-wise comparison matrix based on qualitative criteria\\nQualitative Paradigm\\n1Paradigm\\n2Paradigm\\n3Paradigm\\n4Paradigm\\n5Fuzzy\\ngeometricvalue (r\\ni)Fuzzy Weights Weights\\n(Wi)Normalized\\nweights (W i)\\nParadigm 1 (1,1,1) 2,3,4 4,5,6 1,2,3 1/5,1/4,1/3 1.09,1.49,1.88 0.167,0.284,0.451 0.301 0.284\\nParadigm 2 1/4,1/3,1/2 (1,1,1) 5,6,7 1/5,1/4,1/3 4,5,6 1.00,1.19,1.47 0.154,0.227,0.352 0.244 0.230Paradigm 3 1/6,1/5,1/4 1/7,1/6,1/5 (1,1,1) 6,7,8 2,3,4 0.76,0.92,1.09 0.117,0.175,0.261 0.184 0.173\\nParadigm 4 1/3,1/2,1/1 3,4,5 1/8,1/7,1/6 (1,1,1) 1/6,1/5,1/4 0.45,0.56,0.72 0.069,0.106,0.172 0.115 0.108\\nParadigm 5 3,4,5 1/6,1/5,1/4 /C144,1/3,1/2 4,5,6 (1,1,1) 0.86,1.05,1.30 0.132,0.200,0.312 0.214 0.202\\nTable 9 Alternatives pair-wise comparison matrix based on responsive criteria\\nResponsive Paradigm\\n1Paradigm\\n2Paradigm\\n3Paradigm\\n4Paradigm\\n5Fuzzy\\ngeometric value\\n(ri)Fuzzy weights Weights\\n(Wi)Normalized\\nWeights ( Wi)\\nParadigm 1 (1,1,1) 3,4,5 5,6,7 1,2,3 1/8,1/7,1/\\n61.13,1.46,1.75 0.175,0.278,0.414 0.289 0.273\\nParadigm 2 1/5,1/4,1/\\n3(1,1,1) 2,3,4 /C144,1/3,1/2 4,5,6 0.83,1.04,1.31 0.128,0.198,0.310 0.212 0.201\\nParadigm 3 1/7,1/6,1/\\n51/4,1/3,1/\\n2(1,1,1) 6,7,8 2,3,4 0.84,1.02,1.26 0.130,0.194,0.298 0.207 0.196\\nParadigm 4 1/3,1/2,1/\\n12,3,4 1/8,1/7,1/\\n6(1,1,1) 1/6,1/5,1/\\n40.42,0.53,0.69 0.065,0.101,0.163 0.109 0.103\\nParadigm 5 6,7,8 1/6,1/5,1/\\n4/C144,1/3,1/2 4,5,6 (1,1,1) 0.99,1.18,1.43 0.153,0.225,0.338 0.238 0.225A decision-support system for assessing the function of machine learning and artiﬁcial … 11071\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 8}),\n",
       " Document(page_content='Table 10 Alternatives pair-wise comparison matrix based on formalized criteria\\nFormalized Paradigm\\n1Paradigm\\n2Paradigm\\n3Paradigm\\n4Paradigm\\n5Fuzzy\\ngeometric value(r\\ni)Fuzzy weights Weights\\n(Wi)Normalized\\nWeights ( Wi)\\nParadigm\\n1(1,1,1) 7,8,9 5,6,7 /C144,1/3,1/2 1/3,1/2,1/\\n11.23,1.51,1.99 0.180,0.280,0.467 0.309 0.289\\nParadigm\\n21/9,1/8,1/\\n7(1,1,1) 2,3,4 1,2,3 4,5,6 0.97,1.30,1.58 0.142,0.241,0.371 0.251 0.235\\nParadigm\\n31/7,1/6,1/\\n5/C144,1/3,1/2 (1,1,1) 6,7,8 2,3,4 0.84,1.02,1.26 0.123,0.189,0.296 0.202 0.189\\nParadigm\\n42,3,4 1/3,1/2,1/\\n11/8,1/7,1/\\n6(1,1,1) 6,7,8 0.86,1.08,1.38 0.126,0.201,0.324 0.217 0.203\\nParadigm\\n51,2,3 1/6,1/5,1/\\n4/C144,1/3,1/2 1/8,1/7,1/\\n6(1,1,1) 0.34,0.45,0.56 .049,0.083,0.131 0.087 0.081\\nTable 11 Alternatives pair-wise comparison matrix based on beneﬁcial criteria\\nBeneﬁcial Paradigm\\n1Paradigm\\n2Paradigm\\n3Paradigm\\n4Paradigm\\n5Fuzzy geometric\\nvalue ( ri)Fuzzy weights Weights\\n(Wi)Normalized\\nWeights ( Wi)\\nParadigm\\n1(1,1,1) 7,8,9 3,4,5 1/4,1/3,1/\\n25,6,7 1.92,2.29,2.75 0.263,0.382,0.566 0.403 0.384\\nParadigm\\n21/9,1/8,1/\\n7(1,1,1) 1/6,1/5,1/\\n43,4,5 4,5,6 0.73,0.87,1.01 0.100,0.145,0.208 0.151 0.143\\nParadigm\\n31/5,1/4,1/\\n34,5,6 (1,1,1) 1/8,1/7,1/\\n62,3,4 0.72,0.87,1.04 0.098,0.145,0.214 0.152 0.144\\nParadigm\\n42,3,4 1/5,1/4,1/\\n36,7,8 (1,1,1) 1,2,3 1.19,1.60,1.99 0.163,0.267,0.409 0.279 0.265\\nParadigm\\n51/7,1/6,1/\\n51/6,1/5,1/\\n4/C144,1/3,1/2 1/3,1/2,1/\\n1(1,1,1) 0.28,0.35,0.47 0.038,0.058,0.096 0.064 0.061\\nTable 12 Alternatives pair-wise comparison matrix based on speciﬁcity criteria\\nSpeciﬁcity Paradigm\\n1Paradigm\\n2Paradigm\\n3Paradigm\\n4Paradigm\\n5Fuzzy\\ngeometric value(r\\ni)Fuzzy weights Weights\\n(Wi)Normalized\\nWeights ( Wi)\\nParadigm\\n1(1,1,1) 4,5,6 1/8,1/7,1/\\n62,3,4 7,8,9 1.47,1.75,2.03 0.217,0.313,0.442 0.324 0.310\\nParadigm\\n21/6,1/5,1/\\n4(1,1,1) 5,6,7 3,4,5 1/6,1/5,1/\\n40.82,0.99,1.16 0.121,0.177,0.252 0.183 0.175\\nParadigm\\n36,7,8 1/7,1/6,1/\\n5(1,1,1) 1,2,3 5,6,7 1.33,1.68,2.01 0.196,0.301,0.438 0.311 0.298\\nParadigm\\n41/4,1/3,1/\\n21/5,1/4,1/\\n31/3,1/2,1/\\n1(1,1,1) 3,4,5 0.54,0.69,0.96 0.079,0.123,0.209 0.137 0.131\\nParadigm\\n51/9,1/8,1/\\n74,5,6 1/7,1/6,1/\\n51/5,1/4,1/\\n3(1,1,1) 0.41,0.47,0.56 0.060,0.084,0.122 0.088 0.08411072 Z. HongYun et al.\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 9}),\n",
       " Document(page_content='education is one of the primary sectors among them in\\nwhich AI and ML are used and make music ﬁelds develop.\\nBoth AI and ML provide different intelligent tools to\\ncompose effective and attractive music for games andmake the music and games enjoyable for users. By dis-\\ncussing these technologies, we evaluate the role of AI and\\nML in music education by using the Fuzzy AnalyticalHierarchy Process (Fuzzy AHP) method. First, weidentiﬁed the goal, criteria, and alternatives and then cal-\\nculated the weightage values of each criteria and alterna-\\ntive. Furthermore, we compare the alternatives based on\\neach criterion to calculate their weightage values and rankthem. In the study, it was determined that the qualitative\\ncriteria have high importance with a value of 0.246 by\\nfollowing rationality criteria with a value of 0.174, for-malized criterion with a value of 0.153, beneﬁcial criterionTable 13 Alternatives pair-wise comparison matrix based on rationality criteria\\nRationality Paradigm\\n1Paradigm\\n2Paradigm\\n3Paradigm\\n4Paradigm\\n5Fuzzy\\ngeometric value(r\\ni)Fuzzy weights Weights\\n(Wi)Normalized\\nweights ( Wi)\\nParadigm\\n1(1,1,1) /C144,1/3,1/2 1/6,1/5,1/\\n43,4,5 6,7,8 0.93,1.13,1.37 0.138,0.211,0.321 0.223 0.210\\nParadigm\\n22,3,4 (1,1,1) 5,6,7 1/3,1/2,1/\\n11/6,1/5,1/\\n40.88,1.12,1.47 0.131,0.209,0.345 0.228 0.214\\nParadigm\\n34,5,6 1/7,1/6,1/\\n5(1,1,1) 5,6,7 1,2,3 1.22,1.57,1.90 0.181,0.293,0.446 0.306 0.288\\nParadigm\\n41/5,1/4,1/\\n31,2,3 1/7,1/6,1/\\n5(1,1,1) 1/5,1/4,1/\\n30.35,0.45,0.57 0.052,0.084,0.133 0.089 0.083\\nParadigm\\n51/8,1/7,1/\\n64,5,6 1/3,1/2,1/\\n13,4,5 (1,1,1) 0.86,1.06,1.36 0.128,0.198,0.319 0.215 0.202\\nTable 14 Alternatives pair-wise comparison matrix based on performance criteria\\nPerformance Paradigm\\n1Paradigm\\n2Paradigm\\n3Paradigm\\n4Paradigm\\n5Fuzzy\\ngeometricvalue ( r\\ni)Fuzzy weights Weights\\n(Wi)Normalized\\nweights ( Wi)\\nParadigm 1 (1,1,1) 2,3,4 1/5,1/4,1/\\n34,5,6 1/8.1/7,1/\\n60.72,0.87,1.04 0.088,0.134,0.208 0.143 0.133\\nParadigm 2 /C144,1/3,1/2 (1,1,1) 2,3,4 6,7,8 1/3,1/2,1/\\n10.99,1.28,1.74 0.121,0.198,0.348 0.222 0.206\\nParadigm 3 3,4,5 /C144,1/3,1/2 (1,1,1) 1,2,3 1/5,1/4,1/\\n30.68,0.92,1.19 0.083,0.142,0.238 0.154 0.143\\nParadigm 4 1/6,1/5,1/\\n41/8,1/7,1/\\n61/3,1/2,1/\\n1(1,1,1) 1/6,1/5,1/\\n40.25,0.30,0.39 0.030,0.046,0.078 0.051 0.047\\nParadigm 5 6,7,8 1,2,3 3,4,5 4,5,6 (1,1,1) 2.35,3.08,3.72 0.289,0.477,0.744 0.503 0.468\\nTable 15 Results and ranking of alternatives using fuzzy AHP method\\nCriteria alternatives Qualitative Responsive Formalized Beneﬁcial Speciﬁcity Rationality Performance Results Rankings\\nCriteria Weights 0.246 0.123 0.153 0.133 0.089 0.174 0.077\\nParadigm 1 0.284 0.273 0.289 0.384 0.310 0.210 0.133 0.27 1Paradigm 2 0.230 0.201 0.235 0.143 0.175 0.214 0.206 0.203 2Paradigm 3 0.173 0.196 0.189 0.144 0.298 0.288 0.143 0.201 3Paradigm 4 0.108 0.103 0.203 0.265 0.131 0.083 0.047 0.134 5Paradigm 5 0.202 0.225 0.081 0.061 0.084 0.202 0.468 0.175 4A decision-support system for assessing the function of machine learning and artiﬁcial … 11073\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 10}),\n",
       " Document(page_content='with a value of 0.133, responsive criterion with a value of\\n0.123, speciﬁcity criteria having a value of 0.089, and theworst one is the performance criterion with a value of\\n0.077. After calculating the weightage of each criterion, we\\nmeasure the weightage of alternatives based on criteria,which indicates that paradigm 1 has higher importance\\nwith a result value of 0.27 and rank 1 by following para-\\ndigm 2 with a result value of 0.203 and rank 2, paradigm 3having a result value of 0.201 and rank 3, and paradigm 5\\nwith a value of 0.175 and rank 4, and paradigm 4 with a\\nvalue of 0.134 and rank 5. The study efﬁciently evaluatesthe role of AI and ML paradigms in music education and\\nalso discusses their different methods used in music edu-\\ncation. Figure 4indicates the normalized weightage values\\nalong with the rankings of each criteria.\\nFigure 5showing the overall weightage values, results\\nand ranking of each alternative.\\n5 Conclusion\\nArtiﬁcial intelligence and machine learning approaches areentrenched in music education as a result of the rapidgrowth of information technology. Composing high-quality\\nmusic with AI and ML technology is critical for a com-\\nposer. The music in games has a direct impact on gamers’productivity and experience, and developers have used AIand machine learning to include sounds in games to reﬂect\\nmany circumstances in games, such as fear, suspense, andproviding player information. Visually impaired people can\\nbeneﬁt from a game’s appealing audio by being guided to\\nmake different moves depending on the situation. Fur-thermore, a variety of AI and machine learning-based\\nequipment is available to help students learn music more\\neffectively and efﬁciently, as well as to improve games byincluding higher-quality sounds. The suggested research\\nexamines how artiﬁcial intelligence and machine learning\\nparadigms in music education are evaluated. We used theFuzzy AHP method to evaluate various options, which is a\\nrelatively basic and strong decision-making method. Fol-\\nlowing other alternatives, the alternative paradigm 1 hasachieved a high rank and placed at position ﬁrst with a\\nvalue of 0.27, while the criterion qualitative has a high\\nranking and placed with a weightage value of 0.246. Theresults show that the Fuzzy AHP method is particularly\\nsuccessful and efﬁcient in evaluating the use of AI and\\nmachine learning in music education.\\nFunding No funding statement is available.\\nData availability No data is available.\\nDeclarations\\nConflict of interest The authors have no conflict of interest.\\nReferences\\nAvdeeff M (2019) Artiﬁcial intelligence & popular music: SKYGGE,\\nﬂow machines, and the audio uncanny valley. Arts 8(4):130\\nBarate `A, Bergomi MG, Ludovico LA (2013) Development of serious\\ngames for music education. J e-Learn Knowl Soc 9(2):89–104\\nCarbonell JG, Michalski RS, Mitchell TM (1983) An overview of\\nmachine learning. Mach Learn I:3–23\\nCeylan HC, Hardalac ¸ N, Kara AC (2021) Automatic music genre\\nclassiﬁcation and its relation with music education. World JEduc 11(2):36–450123456\\n00.050.10.150.20.250.3\\nParadigm 1 Paradigm 2 Paradigm 3 Paradigm 4 Paradigm 5Alternatives Results and Rankings\\nResults Rankings\\nFig. 3 Results and rankings of alternatives\\n012345678\\n00.050.10.150.20.250.3Criterions Normalized weightage values and Rankings\\nNormalized Weights Ranking\\nFig. 4 Normalized weightage values and rankings of criterions\\n0123456Weights values, Results and Rankings of Alternatives\\nAlternatives Criteria Weights Paradigm 1 Paradigm 2\\nParadigm 3 Paradigm 4 Paradigm 5\\nFig. 5 Overall weightage values, results and rankings of alternatives11074 Z. HongYun et al.\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 11}),\n",
       " Document(page_content='Chen N, & Wen G (2021) Music composition feasibility using a\\nquality classiﬁcation model based on artiﬁcial intelligence,\\nAggression and Violent Behavior, 101632\\nDai DD (2021) Artiﬁcial intelligence technology assisted music\\nteaching design. Scientiﬁc Program 2021:1–10. https://doi.org/\\n10.1155/2021/9141339\\nFolorunso SO, Afolabi SA, Owodeyi AB (2021) Dissecting the genre\\nof Nigerian music with machine learning models. J King Saud\\nUniv- Comput Inf Sci. https://doi.org/10.1016/j.jksuci.2021.07.\\n009\\nG. Amato et al., 2019 ‘‘AI in the media and creative industries,’’\\narXiv preprint arXiv:.04175\\nGiannakos M, Voulgari I, Papavlasopoulou S, Papamitsiou Z,\\nYannakakis G (2020) Games for artiﬁcial intelligence andmachine learning education: review and perspectives. In:Giannakos M (ed) Non-formal and informal science learning\\nin the ICT era. Springer Singapore, Singapore, pp 117–133.\\nhttps://doi.org/10.1007/978-981-15-6747-6_7\\nHamdaoui N, Idrissi MK & Bennani S (2015) AMEG: Adaptive\\nmechanism for educational games based on IMSLD and artiﬁcial\\nintelligence, In: 2015 10th international conference on intelligentsystems: theories and applications (SITA) IEEE, pp 1-6\\nHolland S (2000) Artiﬁcial intelligence in music education: a critical\\nreview. Read Music Artif Intell 20:239–274\\nJamshidi F, Marghitu D, and Chapman R 2021 ‘‘Developing an online\\nmusic teaching and practicing platform via machine learning: areview paper,’’ In: International conference on human-computer\\ninteraction, vol 12769, pp 95-108, Springer\\nLin Y, Ding J (2020) Application of music artiﬁcial intelligence in\\npreschool music education. IOP Conf Ser Mater Sci Eng\\n750(1):012101. https://doi.org/10.1088/1757-899X/750/1/\\n012101\\nMich L (2020) Artiﬁcial intelligence and machine learning. In: Xiang\\nZ, Fuchs M, Gretzel U, Ho ¨pken W (eds) Handbook of\\ne-Tourism. Springer International Publishing, Cham, pp 1–21.\\nhttps://doi.org/10.1007/978-3-030-05324-6_25-1\\nMicheloni E, Tramarin M, Roda `A, Chiaravalli F (2019) Playing to\\nplay: a piano-based user interface for music education video-\\ngames. Multimed Tools Appl 78(10):13713–13730\\nNart S (2016) Music software in the technology integrated music\\neducation. Turkish Online J Educ Technol-TOJET 15(2):78–84\\nPan T (2022) Application of artiﬁcial intelligence system in music\\neducation. In: Macintyre J, Zhao J, Ma X (eds) The 2021\\nInternational conference on machine learning and big dataanalytics for IoT security and privacy: SPIoT-2021 Volume 1.\\nSpringer International Publishing, Cham, pp 1115–1121. https://\\ndoi.org/10.1007/978-3-030-89508-2_146\\nPlut C, Pasquier P (2020) Generative music in video games: State of\\nthe art, challenges, and prospects. Entertain Comput 33:100337Rogers K 2017 ‘‘Exploring the role of audio in games,’’ In: Extended\\nabstracts publication of the annual symposium on computer-\\nhuman interaction in play, pp 727–731\\nShang M (2019) The Application of Artiﬁcial Intelligence in Music\\nEducation. In: Huang D-S, Jo K-H, Huang Z-K (eds) Intelligent\\ncomputing theories and application: 15th international confer-ence, ICIC 2019, Nanchang, China, August 3–6, 2019, Proceed-ings, Part II. Springer Publishing, Cham, pp 662–668. https://doi.\\norg/10.1007/978-3-030-26969-2_62\\nSidana M (2019) A review of the use of artiﬁcial intelligence in the\\nﬁeld of education, Int J Artif Intell Mach Learn, vol 1, no 3\\nStraeubig M (2020) Games, AI and systems. Eludamos J Comput\\nGame Culture 10(1):141–160\\nSturm BL et al (2019) Machine learning research that matters for\\nmusic creation: a case study. J New Music Res 48(1):36–55\\nTian L (2020) Development of online music education supporting\\nautonomous learning. IOP Conf Ser Mater Sci Eng\\n750(1):012012. https://doi.org/10.1088/1757-899X/750/1/\\n012012\\nXu L et al (2021) Effects of individual factors on perceived emotion\\nand felt emotion of music: based on machine learning methods.Psychol Music 49(5):1069–1087\\nYang F 2020 ‘‘Artiﬁcial intelligence in music education,’’ In: 2020', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 12}),\n",
       " Document(page_content='and felt emotion of music: based on machine learning methods.Psychol Music 49(5):1069–1087\\nYang F 2020 ‘‘Artiﬁcial intelligence in music education,’’ In: 2020\\nInternational conference on robots & intelligent system (ICRIS),\\nIEEE, pp 483–484\\nYuan S (2020) Application and study of musical artiﬁcial intelligence\\nin music education ﬁeld. J Phys Conf Ser 1533(3):032033.\\nhttps://doi.org/10.1088/1742-6596/1533/3/032033\\nZhang E, Yang Y (2021) Music dance distance teaching system based\\non Ologit model and machine learning. J Ambient Intell\\nHumaniz Comput. https://doi.org/10.1007/s12652-021-03221-w\\nZhaoran S (2021) Wireless processor application in home music\\nteaching based on machine learning. Microprocess Microsyst80:103359\\nZhou H, Zhou Y, Zhang H, Huang H, & Li W (2017) Botzone: a\\ncompetitive and interactive platform for game AI education, In:Proceedings of the ACM turing 50th celebration conference-China, pp 1-5\\nPublisher’s Note Springer Nature remains neutral with regard to\\njurisdictional claims in published maps and institutional afﬁliations.\\nSpringer Nature or its licensor holds exclusive rights to this article\\nunder a publishing agreement with the author(s) or other rightsh-\\nolder(s); author self-archiving of the accepted manuscript version ofthis article is solely governed by the terms of such publishing\\nagreement and applicable law.A decision-support system for assessing the function of machine learning and artiﬁcial … 11075\\n123', metadata={'source': 'repositorio\\\\A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games.pdf', 'page': 12}),\n",
       " Document(page_content='IOP Conference Series: Materials Science and Engineering\\nPAPER • OPEN ACCESS\\nA Study on Music Education Based on Artificial\\nIntelligence\\nTo cite this article: Feiyan Ye 2020 IOP Conf. Ser.: Mater. Sci. Eng.  750 012115 \\n\\xa0\\nView the article online  for updates and enhancements. You may also like \\nRETRACTED: Research on the \\nApplication Value of Orff Music Education \\nSystem in College Music Education Based \\non Computer New Media Technology \\nMina Liu-\\nRETRACTED: Strategy of Diversified \\nMusic Education in Our Country Based on \\nthe Analysis of Big Data \\nYu Rui-\\nResearch on Music Education Model by \\nUsing Computer Music Technology in \\nColleges\\nYang Zhou -\\n \\nThis content was downloaded from IP address 164.41.169.83 on 18/09/2023 at 15:29', metadata={'source': 'repositorio\\\\A Study on Music Education Based on Artificial Intelligence.pdf', 'page': 0}),\n",
       " Document(page_content='Content from this work may be used under the terms of the Creative Commons Attribution 3.0 licence. Any further distribution\\nof this work must maintain attribution to the author(s) and the title of the work, journal citation and DOI.\\nPublished under licence by IOP Publishing LtdCCCIS2019 \\nIOP Conf. Series: Materials Science and Engineering 750 (2020) 012115 IOP Publishing \\ndoi:10.1088/1757-899X/750/1/012115 \\n1A Study  on Music  Education  Based  on Artificial  Intelligence  \\nFeiyan  Ye* \\nZhaotong  University,  Yunnan,  China,657000  \\n*Corresponding  author  e-mail : hkyhsthans@outlook.com  \\nAbstract:  Artificial  intelligence  has developed  rapidly  and is widely  used in various  \\nfields.  Music  robots  with specific  neural  networks  can understand,  analyze,  and create  \\nmusic.  In this paper,  based  on the artificial  intelligence  technology,  human  music  \\nintelligence  is analyzed  through  big data to explore  and discuss  the construction  of \\nvarious  new interactive  teaching  music  intelligent  systems  in the field of professional  \\nmusic  education  with music  artificial  intelligence  technology  as the platform,  seeking  a \\nnew mode  of music  perception,  cognition,  creation,  and education.   \\nKeywords:  Artificial  Intelligence,  Music  Perception,  Music  Cognition,  Music  \\nEducation  \\n1. Introduction  \\nArtificial  intelligence  (AI) falls in the three-way  cross-cutting  disciplines  of natural,  social,  and technical  \\nsciences  and is a new science  and technology  designed  to study,  simulate,  extend,  and extend  human  \\nintelligence  for applications  in various  fields.  Music  artificial  intelligence  is based  on artificial  \\nintelligence  technology.  It analyzes  human  music  intelligence  through  big data,  simulates  the \\ninformation  process  of human  sight,  hearing,  touch,  feeling,  thinking  and reasoning,  and constructs  its \\nown neural  network  and algorithm  generation.  It is finally  applied  to human  music  perception,  cognition,  \\nstudy,  and creation,  and a new “human-computer  interaction”  music  teaching  model  is established  [1]. \\nTraditional  infant  music  perception  education  is divided  into two categories:  one is based  on the daily  \\nlives  of infants  and young  children,  which  is played  as background  music  and often  surrounds  the \\nperiphery  of the subject  to perform  subtle  influences.  Before  they go to bed, they need  to adjust  their \\nemotions  and create  a space  atmosphere,  or even  to soothe  the music  during  bedtime.  At this time,  the \\nmusic  should  be quiet,  soft and quiet.  When  they are playing  and lively,  they become  cheerful  and have', metadata={'source': 'repositorio\\\\A Study on Music Education Based on Artificial Intelligence.pdf', 'page': 1}),\n",
       " Document(page_content=\"CCCIS2019 \\nIOP Conf. Series: Materials Science and Engineering 750 (2020) 012115 IOP Publishing \\ndoi:10.1088/1757-899X/750/1/012115 \\n2a certain  rhythm.  The synchronization  of emotions  and music  help them  grow  up physically  and mentally.  \\nThis category  is referred  to as functional  music  [2]. In another  category,  basic  music  education  is \\nconsciously  and purposefully  infiltrated  in infants  and young  children's  daily  music  perception,  such as \\ntraining  the ability  to imitate  pitch  and rhythm  and beat.  It is proven  through  scientific  practice  that the \\nability  to fix pitch  memory  in music  is critical  for children  at the age of 3-6 [3]. Musical  rhythm  training  \\nis of great  help to infants'  intellectual  development  and physical  coordination.  Currently,  various  types  \\nof early  childhood  music  education  institutions  in the society  mostly  use unidirectional  pitch  and \\nrhythmic  rhythm  training,  and only through  interaction  during  the class  time period,  which  has a \\nrelatively  large  limitation.  The development  of music  technology  will enable  infants  and young  children  \\nto perceive  music  more  scientifically,  reasonably,  and pleasantly.  Since  2016,  China's  artificial  \\nintelligence  field has risen  to the national  strategic  level  [4]. Major  domestic  companies  have  also \\ndesigned  and produced  massive  intelligent  robots  with life characteristics,  and gradually  become  a \\nmember  of the family.  They  know  astronomy,  geography,  Chinese,  mathematics,  English,  science,  \\nmusic,  art, etc. They  are all proficient  and can interact  with each other  in various  life scenarios.  The \\nmachine  has language  recognition  capabilities,  which  can perform  analysis  based  on the big data through  \\nits own neural  network  and starts  to communicate  with people.  In infant  music  education,  traditional  \\ninfant  music  perception  training  has gradually  moved  to a new artificial  intelligence  music  education  \\nmodel  for active  robot  teaching  and interactive  communication  [5]. “Music  information  retrieval  \\ntechnology  is an important  part of music  technology.  It is based  on music  acoustics  and extracts  audio  \\nfeatures  based  on audio  signal  processing.  The back  station  uses a variety  of machine  learning  techniques  \\nin artificial  intelligence.”  MIR  technology  extracts  massive  digital  music  audio  information  for \\nautomated  technical  analysis  and classifies  it according  to the independent  characteristics  of each music.  \\nMusic  artificial  intelligence  screens  big data information  for early  music  education  resources.  A rich \\nknowledge  material  library  suitable  for infant  music  education  is established  in the background,  which  \\nforms  its own standardized  and accurate  early  education  system  [6]. The robot  uses automatic  language  \\nand speech  recognition  processing  technology  to sense  the living  scenes  of infants  and young  children  \\nand their emotions,  and automatically  recognizes  and plays  functional  music.  The robot  is like a music  \\nteacher  at home.  Combined  with children's  living  habits,  they use specific  pitches  and rhythms  to \\naccompany  daily  life, subtly,  and step by step into primary  music  education.  Based  on the music  artificial  \\nintelligence  Internet,  robots  are like colossal  music  libraries.  Traditional  networks  use keywords  to find \\nmusic.  Currently,  artificial  intelligence  can understand  the speaking  intentions  of children  and parents  \\nthrough  its own neural  network,  interact  with humans  through  voice,  and provide  various  types  of music  \\nservices.  \\nBased  on artificial  intelligence  technology,  human  music  intelligence  is analyzed  in this paper  \\nthrough  the big data to explore  and discuss  various  new interactive  teaching  music  intelligent  systems\", metadata={'source': 'repositorio\\\\A Study on Music Education Based on Artificial Intelligence.pdf', 'page': 2}),\n",
       " Document(page_content=\"CCCIS2019 \\nIOP Conf. Series: Materials Science and Engineering 750 (2020) 012115 IOP Publishing \\ndoi:10.1088/1757-899X/750/1/012115 \\n3built based  on music  artificial  intelligence  technology  in the field of professional  music  education  and \\nseeks  a new model  for music  perception,  cognition,  creation,  and education.  \\n2. Music  Percept1ion  and Cognition  \\nGiven  the current  situation,  in the context  of the development  of artificial  intelligence,  the research,  \\npromotion,  and application  of music  artificial  intelligence  in the field of music  education  will be \\nimproved  (as shown  in Figure  1). \\n \\nFigure  1. Relationship  between  music  artificial  intelligence  and music  education  \\nMusic  education  in primary  and secondary  schools  in China  mainly  includes  the following  aspects:  \\nthe appreciation  of music,  theoretical  study  (basic  music  theory  and music  history),  and technical  skills  \\n(learning  instrument  performance,  singing,  chorus,  band  training).  The current  teaching  situation  is that \\nstudents  like music,  but it does not mean  that they like to take music  lessons.  Given  this common  \\nphenomenon,  music  teachers  continue  to innovate  various  new teaching  models,  such as increasing  the \\nuse of multimedia  teaching  and modern  network  information  technology;  through  the research  and \\napplication  of the teaching  methods  of the Orff,  Kodaly,  and Dalcroz  systems  to maximize  the students'  \\nparticipation  in teaching.  In view  of the rapid  development  of artificial  intelligence  in the new era, the \\nauthor  proposed  that the construction  and configuration  of “3D artificial  intelligence  music  classrooms-\\nprimary  and secondary  music  scene  space”  in primary  and secondary  schools  would  greatly  increase  \\nstudents'  interest  and enthusiasm  for studying  music.  The teaching  ideas  of new ideas  and technologies\", metadata={'source': 'repositorio\\\\A Study on Music Education Based on Artificial Intelligence.pdf', 'page': 3}),\n",
       " Document(page_content='CCCIS2019 \\nIOP Conf. Series: Materials Science and Engineering 750 (2020) 012115 IOP Publishing \\ndoi:10.1088/1757-899X/750/1/012115 \\n4provide  some  exploration,  research,  and thinking.  \\n3. Undergraduate  Education  in Music  \\nCertainly,  the traditional  undergraduate  professional  music  education  and the teaching  system  are \\nimportant,  and the new era of artificial  intelligence  technology  into music  education  is also imperative  \\nand mutually  reinforcing.  Music  artificial  intelligence  will provide  a new multi-dimensional  teaching  \\npractice  platform  for undergraduate  professional  music  education.  \\n3.1. Application  of music  artificial  intelligence  in the composition  subject  \\nThe traditional  theory  of composition  technology  has a modular  teaching  system,  such as harmony,  \\ntexture,  and music  paragraph  structure.  Music  AI can not only simulate  its teaching  system  but also \\npossess  efficient  and independent  powerful  composing  arithmetic  capabilities.  The first artificial  \\nintelligence  music  composition  software  Orb Composer  is of great  significance  (as shown  in Figure  2). \\nCurrently,  six basic  music  templates  are introduced  in the software,  including  wind  music,  string  music,  \\npiano,  electronics,  Pop-Rock,  and Ambient  pre-selection.  Good  music  environment.  Through  the \\nfollowing  simple  steps:  A. setting  the speed,  tempo  and tone;  B. selecting  the block  structure  determines  \\nthe overall  melody  structure  of the work,  selecting  chords  and musical  instruments  (preset  basic  music  \\ntemplates  are available);  C. selecting  the automatic  generation.  Orb Composer  software  can instantly  \\ncreate  a specific  style  of music.  The artificial  intelligence  of music  enables  those  who know  a little about  \\nmusic  to complete  the “composition”  dream  immediately.  For those  who have  some  music  composition  \\nskills  , the software  can trigger  their creative  inspiration,  and the automatically  generated  works  can be \\npersonalized  and professionally  modified.  The essential  use of Orb Composer  software  is shown  as \\nfollows:', metadata={'source': 'repositorio\\\\A Study on Music Education Based on Artificial Intelligence.pdf', 'page': 4}),\n",
       " Document(page_content=\"CCCIS2019 \\nIOP Conf. Series: Materials Science and Engineering 750 (2020) 012115 IOP Publishing \\ndoi:10.1088/1757-899X/750/1/012115 \\n5\\n \\nFigure  2. Orb Composer,  an intelligent  music  composition  software  for artificial  intelligence  \\n3.2. Application  of music  artificial  intelligence  in the discipline  of music  performance  \\nIn the traditional  music  performance  discipline,  music  is used to perform  image  formation  and form  \\nexpression.  With  the development  of artificial  intelligence,  the intervention  of music  artificial  \\nintelligence  will be a new form  of music  performance  of “human-computer  interaction”.  The \\n“Information  Philharmonic”  system  invented  by Professor  Christopher  Raphael  of the School  of \\nInformation  Computing  and Engineering  at Indiana  University  in the United  States  could  provide  solo \\nand soloists  with a complete  and professional  orchestra  accompaniment  in real-time.  In November  2018,  \\nit held  the “AI Night—Music  Artificial  Music  Accompaniment  System  Concert”  jointly  with the \\nCentral  Academy  of Music.  In addition  to using  artificial  intelligence  technology  to concert  classical  \\nmusic,  it also performed  concerto  to Chinese  music  “Great  Wall  Caprice”  . “Information  Philharmonic”  \\nsystem  has a powerful  artificial  intelligence  system  learning  ability  and can generate  various  calculation  \\nmethods.  It can interactively  change  according  to the change  of the player's  music  rhythm  and \\ncontinuously  adjust  and improve  his own accompaniment  ability.  \\nFor the editing  of different  categories  of music  by AI, it can process  different  music  performance  \\ndiscipline  data:  \\n1) Boolean  type\", metadata={'source': 'repositorio\\\\A Study on Music Education Based on Artificial Intelligence.pdf', 'page': 5}),\n",
       " Document(page_content='CCCIS2019 \\nIOP Conf. Series: Materials Science and Engineering 750 (2020) 012115 IOP Publishing \\ndoi:10.1088/1757-899X/750/1/012115 \\n6 is the i-th element  in U, that is, .  representsthe  jth element  in U, iU1,2,3,, i n \\uf0ce \\uf04b\\njA\\n.  representsthe  attribute  value  of the i-th element,  and the j-th attribute.   1,2,3,, j n \\uf03d \\uf04b\\nijSjka\\nrepresentsthe  k-th attribute  value   in the j-th attribute,  where  t representsthe  class  1,2,3,, k t \\uf0ce \\uf04b\\nnumber  of an attribute.   representsthe  count  of , and the dependency  between  attribute- \\uf028\\uf029jk Najka\\nvalue  pairs  can be expressed  by the membership  function  of the attribute  value,  as shown  in formula  (1): \\n                       (1) \\uf028\\uf029 \\uf028 \\uf029, 1,2,, ASij N jknk n \\uf06d \\uf061 \\uf03d \\uf03d \\uf04b\\nWhere  n representsthe  data number.  \\n2) Numeric  type \\nSuppose  l representsthe  number  of classes  of attributes,   representsthe  first class,   \\nlC \\uf028\\uf029 NCl\\nrepresentsthe  number  of attributes  in ,  representsthe  i-th attribute  value  in class  l, and the \\nlClC\\nmembership  function  of the attribute  value  representsas  shown  in formula  (2): \\n                  (2) \\uf028\\uf029\\uf028\\uf029 \\uf028\\uf029,1,2,3,,1,2,3,i\\nA l l C NC nl i \\uf06d \\uf03d \\uf03d \\uf03d\\uf04b \\uf04b\\n3) Class  attributes  \\nThe membership  function  of the class  attribute  is shown  in formula  (3): \\n                  (3) \\uf028\\uf029\\uf028\\uf029 \\uf028\\uf029 , 1,2,3, , 1,2,3,i\\nA l l C N C nl i \\uf06d \\uf03d \\uf03d \\uf03d \\uf04b \\uf04b\\nThe meaning  of the variable  is the same  as the membership  function  of the above  numeric  type.  \\n4) Null membership  function  \\n                     (4) \\uf028\\uf029\\uf028\\uf029 \\uf028 \\uf029\\n\\uf028\\uf029 \\uf028 \\uf029\\n\\uf028\\uf029 \\uf028 \\uf0290 0\\n0 0 0\\n0 0min ,\\n,\\nmax ,A ij\\nA ij A ij\\nA ijS rl\\nS mid S l r h\\nS r h\\uf06d\\n\\uf06d \\uf06d\\n\\uf06d\\uf0ec \\uf0a3\\uf0ef\\uf0ef\\uf03d \\uf03c \\uf03c \\uf0ed\\n\\uf0ef\\n\\uf0ef \\uf0b3\\uf0ee\\nThe null membership  function  is shown  in formula  (4), where   is the attribute  value  of the i-th ijS\\nelement  and the j-th attribute.   is the proportion  of the value  Null in all data,   is the corresponding  0r0h\\nthreshold  with a higher  percentage,  and  is the corresponding  threshold  with a lower  percentage.  0l', metadata={'source': 'repositorio\\\\A Study on Music Education Based on Artificial Intelligence.pdf', 'page': 6}),\n",
       " Document(page_content=\"CCCIS2019 \\nIOP Conf. Series: Materials Science and Engineering 750 (2020) 012115 IOP Publishing \\ndoi:10.1088/1757-899X/750/1/012115 \\n74. New  Directions  in Music  Research  \\nCurrently,  intelligent  music  interactive  teaching  platforms  have  sprung  up, and they have  customized  \\npersonalized  teaching  based  on big data analysis.  Teachers  teach  online  and restore  the one-to-one  and \\none-to-many  teaching  scenes.  Combining  the music  recognition  technology  in the new music  artificial  \\nintelligence  technology  makes  the teaching  interaction  interesting  and can provide  answers,  grading,  \\nand learning  suggestions  at any time,  which  is efficient  and at a low cost. Hence,  to ensure  that the \\nlearning  platform  is stable,  safe, advanced  and easy to use, and that the professional  music  knowledge  \\nin the platform  is accurate,  rational,  continuous,  and authoritative,  professional  music  discipline  groups  \\nand technical  team  of science  and technology  should  cooperate  closely  for a long time;  leading  and \\nguiding  their respective  student  teams  with graduate  tutors  in music  and science  majors,  and jointly  \\napplying  for horizontal  and interdisciplinary  related  scientific  research  projects,  which  is conducive  to \\nthe long-term  continuous  research  and development  of this scientific  research.  \\nThere  are many  views  about  whether  artificial  intelligence  can replace  human  beings,  but it is an \\ninevitable  fact that chess  and Go have  been  defeated  by artificial  intelligence.  They  cannot  replace  \\nhumans,  but they are superior  in many  respects.  Currently,  robots  can understand,  analyze,  create  music,  \\nand apply  to music  teaching.  With  the continuous  improvement  of computer  computing  capabilities,  and \\nthe development  and research  of robots'  deep  learning  in the context  of big data,  a new music  ecosystem  \\nof music  artificial  intelligence  + database  + music  teaching  that interacts  with apps + social  functions  \\nwill be an inevitable  trend  in the future.  \\nReferences  \\n[1] Emine  Kıvanç  Öztuğ,  Burcu  Karagöz.  An evaluation  of music  education  in Northern  Cyprus  \\nbased  on teacher  opinions  and documents[J].  Quality  & Quantity,  2017,  52(S):1-12.  \\n[2] Kilic,  Deniz  Beste  Çevik.  Examining  Music  Teachers'  Self-Confidence  Levels  in Using  \\nInformation  and Communication  Technologies  for Education  Based  on Measurable  \\nVariables.[J].  Educational  Research  & Reviews,  2017,  12(3):101-107.  \\n[3] Yumin  Diao.  Research  on Software  Development  of Continuing  Education  Based  on Big \\nData[J].  Wireless  Personal  Communications,  2018(6):1-10.  \\n[4] Chuifeng  Fan, Biying  Jiang,  Xiuying  Shi. Update  on research  and application  of problem-\\nbased  learning  in medical  science  education:  Problem-Based  Learning  in Medical  Science  \\nEducation[J].  Biochemistry  & Molecular  Biology  Education  A Bimonthly  Publication  of \\nthe International  Union  of Biochemistry  & Molecular  Biology,  2017,  46(3):1-14.  \\n[5] Ritesh  Sarkhel,  Nibaran  Das, Amit  K. Saha.  An improved  Harmony  Search  Algorithm  \\nembedded  with a novel  piecewise  opposition  based  learning  algorithm[J].  Engineering  \\nApplications  of Artificial  Intelligence,  2018,  67(3):317-330.\", metadata={'source': 'repositorio\\\\A Study on Music Education Based on Artificial Intelligence.pdf', 'page': 7}),\n",
       " Document(page_content='CCCIS2019 \\nIOP Conf. Series: Materials Science and Engineering 750 (2020) 012115 IOP Publishing \\ndoi:10.1088/1757-899X/750/1/012115 \\n8[6] Begic,  Jasna  Šulentic|Begic,  Amir|Škojo,  Tihana.  Opinions  of University  Music  Teachers  \\non the Musical  Competencies  Necessary  for Primary  Education  Teachers.[J].  International  \\nJournal  of Higher  Education,  2017,  6(1):197-204.', metadata={'source': 'repositorio\\\\A Study on Music Education Based on Artificial Intelligence.pdf', 'page': 8}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   A\\tutilização\\tdas\\tTecnologias\\tda\\tInformação\\te\\tComunicação\\tnas\\tpráticas\\tdocentes:\\tum\\testudo\\tcom\\tegressos\\tde\\tcurso\\tde\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância\\tda\\tUnB\\tJosué\\tBerto\\tdos\\tSantos\\tJúnior\\tUniversidade\\tde\\tBrasília\\tjosueberto@yahoo.com.br\\tPaulo\\tRoberto\\tAffonso\\tMarins\\tUniversidade\\tde\\tBrasília\\tpramarins@gmail.com Comunicação\\tResumo:\\tEste\\tpresente\\testudo\\ttem\\tcomo\\tobjetivo\\tapresentar\\tuma\\tpesquisa\\tde\\tmestrado\\tem\\tandamento\\t que\\t traz\\t como\\t tema\\t a\\t utilização\\t das\\tTecnologias\\t da\\t Informação\\t e\\t Comunicação\\t(TIC)\\t nas\\t práticas\\tdocentes\\t dos\\t egressos\\t do\\t curso\\t de\\t Licenciatura\\t em\\t Música\\t a\\tDistância\\t da\\tUniversidade\\t de\\t Brasília\\t (UnB).\\tPortanto,\\ta\\tmetodologia\\tdeste\\t artigo\\té\\t uma\\t pesquisa\\tbibliográfica\\tde\\tonde\\tsurgiram\\ta\\tdescrição\\tdo\\ttema,\\tjustificativa,\\tproblematização,\\tos\\tobjetivos,\\trevisão\\tde\\tliteratura\\te\\tmetodologia\\tda\\tpesquisa.\\tPor\\tmeio\\tda\\trevisão\\tde\\tliteratura\\tpercebe-se\\tum\\taumento\\tde\\tpesquisas\\tque\\tabordam\\to\\tuso\\tdas\\tTIC\\tpor\\tprofessores\\tde\\tmúsica,\\tos\\tsaberes\\te\\tcompetências\\t docentes\\t diante\\t as\\t inovações\\t tecnológicas.\\tDessa\\t forma,\\to\\t Projeto\\t Pedagógico\\tdo\\tCurso\\t(PPC)\\taponta\\tque\\té\\tviável\\tinvestigar\\tcomo\\tos\\tegressos\\tdo\\tcurso\\tde\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância\\tda\\tUnB\\tenfrentam\\ta\\tutilização\\tde\\trecursos\\ttecnológicos\\tna\\tprática\\tdocente.\\tEspera-se\\tque\\teste\\testudo\\tpossa\\tcontribuir\\tna\\tárea\\tde\\tEducação\\tMusical\\tcom\\trelação\\tao\\tensino\\tde\\t música\\t e\\tuso\\t das\\t TIC,\\t principalmente\\t na\\t Educação\\t Básica,\\t bem\\t como\\t trazer\\t inovações\\ttecnológicas\\tpara\\tcursos\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância.\\tPalavras\\tchave:\\tTecnologias\\tda\\tInformação\\te\\tComunicação;\\tPráticas\\tdocentes;\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância.\\tIntrodução\\tA\\tutilização\\tde\\trecursos\\ttecnológicos\\tdurante\\tos\\tprocessos\\tde\\tensino\\te\\taprendizagem\\tdemandam\\tnovas\\tcompetências\\te\\testratégias\\tna\\tprática\\tdocente,\\tassim\\tcomo\\tnos\\tmomentos\\tde\\tcapacitação\\tno\\tuso\\tdas\\tTecnologias\\tda\\tInformação\\te\\tComunicação\\t(TIC)\\tdurante\\ta\\tformação\\tpedagógica\\tde\\tprofessores.\\tDessa\\tforma,\\teste\\ttrabalho\\tapresenta\\tcomo\\ttemática\\tde\\testudo\\ta', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 0}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   utilização\\t das\\t TIC\\t nas\\t práticas\\t docentes\\t dos\\t egressos\\t do\\t curso\\t de\\t Licenciatura\\t em\\t Música\\t a\\tDistância\\tda\\tUniversidade\\tde\\tBrasília\\t(UnB).\\tPortanto,\\tconsiderando\\to\\treferido\\tcontexto,\\ttorna-se\\tviável\\tinvestigar\\tcomo\\tos\\tegressos\\tinserem\\tas\\tTIC\\tna\\tsala\\tde\\taula\\tde\\tescolas\\tde\\tEducação\\tBásica.\\tCom\\to\\tcrescimento\\tdas\\tfontes\\tde\\treprodução\\tsonora\\te\\tvisual,\\tas\\trelações\\tcom\\tas\\tTIC\\te\\ta\\t música\\tconduzem\\tpara\\t mais\\treflexões\\t sobre\\t as\\t diferentes\\t formas\\t de\\t seu\\t uso\\t na\\tprática\\tdocente\\t do\\t ensino\\t da\\t música.\\t Segundo\\t Gohn\\t (2009)\\t existe\\t uma\\t mudança\\t muito\\t rápida\\t na\\tpesquisa\\tligada\\tà\\ttecnologia:\\tInvestigar\\t assuntos\\t relacionados\\t à\\t tecnologia\\t é\\tcomo\\t perseguir\\t a\\t própria\\tsombra:\\tquando\\tse\\tchega\\tao\\tponto\\tintencionado,\\to\\tobjeto\\tde\\tinteresse\\tjá\\testá\\tum\\t pouco\\t mais\\t a\\t frente.\\t Trata-se\\t de\\t um\\t universo\\t de\\t conhecimento\\t em\\tconstante\\tmutação.\\t(GOHN,\\t2009,\\tp.\\t13).\\tNa\\tatuação\\tprofissional,\\té\\tviável\\tque\\tos\\tegressos\\testejam\\tpreparados\\tpara\\taceitar\\tos\\tdesafios\\tdo\\t uso\\t das\\tTIC\\tno\\t processo\\t de\\t ensino\\t e\\t aprendizagem\\t nas\\t aulas\\t de\\t música\\t na\\tEducação\\tBásica,\\tpois\\tcomo\\tafirmam\\tLeme\\te\\tBellochio\\t(2007):\\tUma\\tvez\\tque\\ta\\teducação\\tno\\tmundo\\tde\\thoje\\ttende\\ta\\tser\\ttecnológica,\\to\\tque,\\tpor\\tsua\\tvez,\\tvai\\texigir\\to\\tentendimento\\te\\tinterpretação\\tde\\ttecnologias,\\to\\tprofessor\\tde\\t música\\t opta,\\t para\\t trabalhar,\\t por\\t estar\\t interado\\t e\\t consciente\\t quanto\\t às\\ttecnologias\\tmusicais\\te\\tsua\\tutilização\\tcomo\\tinstrumento\\tmediador\\tna\\teducação\\tmusical\\t ou\\t não,\\t o\\t que\\t se\\treflete\\t na\\t prática\\t conforme\\t a\\t sua\\t experiência\\tindividual\\tcom\\tas\\tmesmas.\\t(LEME;\\tBELLOCHIO,\\t2007,\\tp.\\t88).\\tÉ\\tdesejável\\tque\\tdurante\\ta\\tformação\\tdos\\tegressos\\ta\\taproximação\\tdo\\tambiente\\treal\\tda\\tprática\\tdocente\\tseja\\tampliada.\\tDada\\testa\\taproximação\\tdo\\tambiente\\tde\\tformação\\te\\to\\tambiente\\tda\\tsala\\tde\\taula\\to\\tpróximo\\tpasso\\tseria\\trefletir\\tsobre\\ta\\tcapacitação\\tdos\\tegressos,\\tsegundo\\tVicent\\te\\tMerrion\\t(1996)\\tafirma:\\t\\t[…]\\tpreparados\\tpara\\ta\\temergente\\tinteração\\tsofisticada\\tentre\\to\\testudante\\te\\ta\\tmúsica,\\t o\\t estudante\\t e\\t a\\t tecnologia,\\t e\\to\\t estudante\\t e\\t o\\t professor.\\t É\\t vital\\t que\\teducadores\\tmusicais\\tliderem\\to\\tdesenvolvimento\\tmusical\\te\\tnão\\tsimplesmente\\tsigam\\tas\\ttendências\\ttecnológicas.\\t(VICENT;\\tMERRION,\\t1996,\\tp.\\t40).', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 1}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   Sendo\\t assim,\\t este\\t trabalho\\t configura-se\\t como\\t pesquisa\\t bibliográfica\\t e\\t recorre\\ta\\tliteratura\\t no\\t intuito\\t de\\t verificar\\t como\\t as\\t pesquisas\\t estão\\t abordando\\t o\\t uso\\t das\\t TIC\\t por\\tprofessores\\t de\\t música,\\t principalmente,\\t daqueles\\t que\\t são\\t egressos\\t de\\t cursos\\t de\\t música\\t a\\tdistância\\te\\toutras\\táreas\\tde\\tconhecimento.\\tMetodologia\\tA\\tmetodologia\\tconsiste\\tem\\tuma\\tpesquisa\\tbibliográfica\\tcom\\tuma\\trevisão\\tde\\tliteratura\\tacerca\\tdo\\ttema\\tutilização\\tdas\\tTIC\\tnas\\tpráticas\\tdocentes\\tdos\\tegressos\\tdo\\tcurso\\tde\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância\\tda\\tUnB.\\tBuscou-se\\ta\\tfundamentação\\tem\\tProdanov\\te\\tFreitas\\t(2013)\\tque\\tdiz\\tque\\ta\\tpesquisa\\tbibliográfica\\té\\tconcebida\\tpor\\tmeio\\tde\\tmateriais\\tjá\\tpublicados.\\tJá\\tpara\\tPenna\\t(2015)\\té\\t por\\t meio\\t da\\trevisão\\t de\\t literatura\\t que\\t surgem\\ta\\t descrição\\t do\\t tema,\\t justificativa,\\tproblematização,\\tos\\tobjetivos,\\trevisão\\tde\\tliteratura\\te\\tmetodologia.\\t\\tConstruindo\\to\\tprojeto\\tde\\tpesquisa\\tEste\\t projeto\\t de\\t pesquisa\\t traz\\t como\\t tema\\to\\t uso\\t das\\tTIC\\tnas\\t práticas\\t docentes\\t dos\\tegressos\\tdo\\tcurso\\tde\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância\\tda\\tUnB.\\tO\\tinteresse\\tsurgiu\\ta\\tpartir\\tda\\tminha\\t experiência,\\t ao\\t longo\\t de\\t seis\\t anos,\\t atuando\\t como\\t tutor\\t a\\t distância\\t e\\t professor\\tsupervisor\\tnas\\tdisciplinas\\tdo\\treferido\\tcurso.\\t\\tMediante\\t a\\t experiência\\t de\\t tutoria\\t a\\t distância,\\t foi\\t possível\\t vivenciar\\t a\\t utilização\\t de\\ttecnologias\\t aplicadas\\tnos\\t momentos\\t síncronos1\\te\\t assíncronos2\\tpor\\t meio\\t dos\\t recursos\\teducacionais\\tcomo\\tos\\tmateriais\\tdidáticos\\tno\\tformato\\timpresso\\te\\tonline;\\tvideoconferências\\tque\\tsão\\tferramentas\\tde\\tabordagem\\tsíncrona\\tonde\\tpessoa-a-pessoa\\tou\\tgrupos\\tpodem\\tiniciar\\tuma\\tcomunicação\\t através\\t de\\t computadores\\t conectados\\t a\\t rede\\t com\\tweb\\tcâmera\\t e\\tsoftware\\tespecífico\\te\\to\\tAmbiente\\tVirtual\\tde\\tAprendizagem\\t(AVA)\\tque\\tse\\tconstitui\\to\\tlugar\\tonde\\to\\taluno\\tpossa\\tfazer\\tuma\\tleitura\\thiper-textual\\te\\tmultimídia.\\t\\tO\\t curso\\t de\\t Licenciatura\\t em\\t Música\\t a\\tDistância\\t da\\tUnB\\ttem\\t como\\t objetivo\\t fornecer\\t                                                1 Comunicação que acontece de forma imediata e em tempo real entre aluno e professor. 2 Comunicação que acontece a medida que os alunos e professor acessam as mensagens sem um tempo definido.', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 2}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   subsídios\\t teórico-práticos\\t para\\t desenvolver\\t um\\tfuturo\\t educador\\t musical\\t reflexivo,\\t com\\tautonomia\\t e\\t conhecimento\\t para\\t mobilizar\\t saberes\\t e\\t competências\\t condizentes\\t com\\t seu\\tcontexto\\tde\\tatuação\\tem\\tconformidade\\t(UNIVERSIDADE\\tDE\\tBRASÍLIA,\\t2011).\\t\\tDesta\\tforma,\\to\\tuso\\tdas\\tTIC\\tna\\tEducação\\ta\\tDistância\\tobjetiva\\tdesenvolver\\ta\\taprendizagem\\tcolaborativa\\tpor\\tmeio\\tde\\tvariadas\\t situações\\t de\\t interação\\t aluno-aluno,\\t além\\t da\\t interação\\t aluno-professor.\\tPortanto,\\t o\\testar\\t junto\\t virtual\\t(VALENTE,\\t 2005)\\tpretende\\t potencializar\\t condições\\t de\\t aprendizagem\\t e\\tcolaboração\\t durante\\t o\\t curso.\\t A\\t elaboração\\t do\\t curso\\t de\\t música\\ta\\t distância,\\t por\\t meio\\t do\\t seu\\t\\tProjeto\\tPedagógico\\tdo\\tCurso\\t(PPC),\\tbuscou\\trespaldo\\tna\\tlegislação\\tbrasileira:\\tPara\\tgarantir\\to\\tacesso\\tàs\\tpráticas\\teducativo-musicais\\tprevistas\\tnos\\tParâmetros\\tCurriculares\\tNacionais\\t(PCNs),\\tem\\tconcordância\\tcom\\ta\\tLei\\tde\\tDiretrizes\\te\\tBases\\tda\\t Educação\\t Nacional\\t (LDBEN),\\t e\\t asseguradas\\t pela\\t recente\\t Lei\\t 11.769/2008\\tsancionada\\t pelo\\t presidente\\t da\\t República\\t em\\t 18\\t de\\t agosto\\t de\\t 2008,\\t que\\testabelece\\ta\\tobrigatoriedade\\tda\\tmúsica\\tno\\tcurrículo\\tescolar,\\té\\tnecessário\\tque\\thaja\\teducadores\\tmusicais\\tpreparados\\tpara\\tatuar\\tna\\tdiversidade\\tde\\tcontextos\\teducacionais\\t (escolas\\t de\\t educação\\t básica,\\t escolas\\t de\\t música,\\t ONGs\\t etc.).\\t(UNIVERSIDADE\\tDE\\tBRASÍLIA,\\t2011,\\tp.\\t7).\\tDesse\\tmodo,\\to\\tPPC\\tfoi\\telaborado\\tde\\tacordo\\tcom\\tas\\tDiretrizes\\tCurriculares\\tNacionais\\tpara\\tos\\tCursos\\tde\\tGraduação\\tem\\tMúsica\\t(Resolução\\tno\\t2,\\tde\\t8\\tde\\tmarço\\tde\\t2004),\\ta\\tResolução\\tCNE/CP\\t01,\\tde\\t18\\tde\\tfevereiro\\tde\\t2002\\te\\ta\\tResolução\\tCNE/CP\\t02,\\tde\\t19\\tde\\tfevereiro\\tde\\t2002\\t–\\tque\\t tratam\\t dos\\t cursos\\t de\\t Licenciatura,\\t de\\t graduação\\tplena,\\t de\\t formação\\t de\\t professores\\t da\\tEducação\\tBásica\\tem\\tnível\\tsuperior\\tenfatizando,\\tdessa\\tforma,\\ta\\tformação\\tpara\\to\\tuso\\tdidático\\tde\\tTIC.\\t\\tO\\t curso\\t de\\t Licenciatura\\t em\\t Música\\t a\\tDistância\\tda\\tUnB\\tpretende\\t conduzir\\t o\\t futuro\\teducador\\tmusical\\tpara\\tdiferentes\\tpossibilidades\\tde\\tpropostas\\tmetodológicas\\tatuais\\tonde\\tesse\\t\\tseja\\tcapaz\\tde\\tcriar\\te\\tdesenvolvê-las\\tde\\tforma\\tcoerentes\\tcom\\to\\tcontexto\\tno\\tqual\\tatuará.\\tDesse\\tmodo,\\tos\\tobjetivos\\trelacionados\\tao\\tuso\\tde\\tTIC\\tno\\tcurso\\tsão:\\tIncentivar\\ta\\taprendizagem\\tcolaborativa\\tpor\\tmeio\\tdas\\tTICs.\\t\\tIntegrar\\te\\tutilizar\\trecursos\\tnaturais\\te\\ttecnológicos\\tdisponíveis\\tna\\tsua\\tprática;\\tProcurar\\tcaminhos\\te\\tsoluções\\tnovas\\tou\\talternativas\\tpara\\tos\\tproblemas;\\tPromover\\t permanente\\t instrumentalização\\t dos\\t recursos\\t humanos\\t envolvidos\\tno\\t domínio\\t dos\\t códigos\\tde\\t informação\\t e\\t comunicação,\\t bem\\t como\\t suas', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 3}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   respectivas\\t tecnologias,\\t além\\t de\\t estimular\\t o\\t desenvolvimento\\t do\\t pensa-\\tmento\\t autônomo,\\t da\\t curiosidade\\t e\\t criatividade,\\t apoiados\\t na\\t aprendizagem\\tcolaborativa;\\tDesenvolver\\t o\\t uso\\t educacional\\t e\\t integrado\\t dos\\t meios\\t de\\t comunicação,\\tbuscando\\t formas\\t didáticas\\t apropriadas\\t às\\t peculiaridades\\t e\\t à\\t linguagem\\t de\\tcada\\tum;\\t(UNIVERSIDADE\\tDE\\tBRASÍLIA,\\t2011,\\tp.\\t8-10).\\tConforme\\t Marins\\t e\\t Narita\\t (2012)\\t na\\tabordagem\\t sobre\\t o\\t planejamento\\t e\\timplementação\\tdo\\tcurso\\tde\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância\\tda\\tUnB\\tos\\tautores\\tconcluem\\tque\\ta\\tintenção\\tda\\tcoordenação\\tdo\\tcurso\\té\\tacompanhar\\ta\\tintegração\\tprofissional\\tdos\\tegressos\\tpor\\tmeio\\tde\\tpesquisa\\tdirecionadas\\tao\\tmodo\\tcomo\\tos\\tegressos\\testão\\tlidando\\tcom\\tos\\tdesafios\\tprofissionais\\tno\\tensino\\tda\\tmúsica\\tna\\tEducação\\tBásica.\\t\\tAtualmente,\\to\\tcurso\\tde\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância\\tda\\tUnB\\ttem\\t110\\tprofessores\\tformados,\\tporém\\tnão\\tse\\tsabe\\tquantos\\testão\\tatuando\\tem\\tsala\\tde\\taula\\te\\tse\\tinserem\\tas\\tTIC\\tnas\\tpráticas\\tdocentes\\te\\tquais\\tseriam\\testas\\tTIC.\\tDurante\\ta\\tformação\\tpedagógica,\\tos\\tegressos\\tdo\\tcurso\\tde\\tmúsica\\ttiveram\\tacesso\\ta\\tpelo\\tmenos\\tduas\\t diciplinas\\t ligadas\\t diretamente\\t ao\\t uso\\t de\\tTIC\\tque\\t são\\t elas:\\t Laboratório\\t de\\t Música\\t e\\tTecnologia\\te\\tTecnologias\\tContemporâneas\\t na\\tEscola.\\tPortanto,\\t pressupõe-se\\t que\\t esses\\tegressos\\tutilizem\\tas\\tTIC\\tnas\\tsalas\\tde\\taula\\tvisto\\tque\\to\\tpróprio\\tPPC\\t(2011)\\tenfatiza\\ta\\tformação\\tpara\\to\\tuso\\tdidático\\tdas\\tTIC.\\tDessa\\t forma,\\temergiram\\t algumas\\t inquietações\\t e\\tsurgiram\\tquestionamentos\\tque\\trefletiram\\tno\\tproblema\\tde\\tpesquisa.\\tPortanto,\\to\\tpresente\\ttrabalho\\ttraz\\tcomo\\tquestão\\tprincipal:\\tEm\\t \\t meio\\t ao\\t contexto\\t de\\t integração\\t profissional\\t dos\\t egressos\\t do\\t curso\\t de\\t Licenciatura\\t em\\tMúsica\\t a\\t Distância\\tda\\tUnB\\tno\\t ensino\\t da\\t música\\t na\\t Educação\\t Básica,\\tcomo\\tos\\t egressos\\tenfrentam\\tos\\t desafios\\tna\\t utilização\\t de\\t recursos\\t tecnológicos\\t na\\t prática\\t docente?\\tAssim,\\t as\\tquestões\\t específicas\\t se\\t configuram\\t em:\\tQuais\\t TIC\\t estão\\t sendo\\t utilizadas\\t por\\t esses\\t egressos?\\tDentre\\t as\\t TIC\\t utilizadas\\t quais\\t estão\\t relacionadas\\t a\\t sua\\t formação\\t no\\t curso?\\tComo\\t essas\\tTIC\\tpotencializam\\to\\tensino\\tda\\tmúsica\\tnos\\tcontextos\\tde\\tatuação\\tdos\\tegressos?\\t\\tMediante\\t as\\t questões\\t este\\t estudo\\t propõe\\t atender\\tcomo\\tobjetivo\\t geral:\\tinvestigar\\tcomo\\t os\\t egressos\\tdo\\t curso\\t de\\tLicenciatura\\t em\\tMúsica\\t a\\tDistância\\t da\\tUnB\\tenfrentam\\tos\\tdesafios\\tna\\t utilização\\t de\\t recursos\\t tecnológicos\\t na\\t prática\\t docente.\\tQuanto\\taos\\t objetivos\\tespecíficos\\to\\t intuito\\t é:\\tidentificar\\t as\\t TIC\\t que\\testão\\t sendo\\t utilizadas\\t pelos\\t egressos;\\t verificar', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 4}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   dentre\\t as\\t TIC\\t utilizadas\\t quais\\t estão\\t relacionadas\\t à\\t formação\\t do\\t egresso\\t no\\t curso;\\tidentificar\\tcomo\\tessas\\tTIC\\tpotencializam\\to\\tensino\\tda\\tmúsica\\tnos\\tcontextos\\tde\\tatuação\\tdos\\tegressos.\\t\\tPortanto,\\tpara\\tdiscutir\\to\\ttema\\ta\\tpartir\\tdo\\t“estado\\tdo\\tconhecimento”\\t(PEREIRA,\\t2013),\\tapresenta-se\\tna\\trevisão\\tde\\tliteratura\\tinicial\\tos\\tseguintes\\tautores:\\tBorges\\t(2010);\\tKruger\\t(2010);\\tRosas\\t (2013);\\tOliveria-Torres\\t (2012);\\tMéio\\t (2014);\\t Cernev\\t (2015);\\t Ortiz-Rodrigues\\t (2015)\\t e\\tSantos\\t(2015).\\tBorges\\t(2010)\\tbuscou\\tcompreender\\tcomo\\tos\\testudantes\\tdo\\túltimo\\tano\\tde\\ttrês\\tcursos\\tde\\tgraduação\\tem\\tmúsica\\tno\\tEstado\\tde\\tSanta\\tCatarina\\testão\\trelacionando\\tas\\tTIC\\tcom\\tas\\tpráticas\\tdocentes\\tem\\tconformidade\\tcom\\to\\tcurrículo\\te\\ta\\tfundamentação\\tlegal\\tdos\\tcursos\\tde\\tLicenciatura\\tem\\tMúsica.\\tOs\\tresultados\\t\\tda\\tpesquisa\\tde\\tBorges\\t(2010)\\tapontam\\tque\\tpode-se\\tencontrar\\to\\tuso\\tde\\t TIC\\t nas\\t três\\t instituições\\t de\\t ensino\\t superior\\t do\\t Estado\\t de\\t Santa\\t Catarina\\t na\\t forma\\t de\\tcomposição\\t de\\t músicas,\\t para\\t auto-acompanhamento\\t musical\\t no\\t estudo\\t da\\t improvisação,\\t no\\tprocesso\\tde\\tgravação\\tdigital\\tque\\té\\testudado\\tnestes\\tcursos,\\tna\\teditoração\\tde\\tpartituras\\tcom\\to\\tuso\\tde\\tcomputadores,\\tnas\\ttablaturas\\tque\\tsão\\tproduzidas\\tdigitalmente,\\tna\\ttecnologia\\tdigital\\tque\\té\\tutilizada\\tpara\\treproduzir\\tmúsica,\\te\\tnos\\tarquivos\\tdigitais\\tque\\tsão\\ttrocados\\tentre\\testudantes\\te\\tprofessores.\\tApesar\\t deste\\t resultado,\\t acredita-se\\t que\\t a\\t problematização\\t sobre\\t TIC\\t e\\t os\\tprocessos\\t de\\t construção\\t de\\t conhecimento\\t musical\\t podem\\t ser\\t aprofundados\\t com\\t intuito\\t de\\tsubsidiar\\t a\\t elaboração\\t de\\t currículos\\t coerentes\\t com\\t a\\t inserção\\t das\\t TIC\\tnos\\tcursos\\t de\\tLicenciatura\\t em\\t Música.\\tO\\t autor\\t conclui\\t que\\t a\\ttecnologia\\t é\\t utilizada\\t no\\t fazer\\t musical,\\t mas\\tpouco\\trelacionada\\tcom\\tos\\taspectos\\tespecíficos\\tda\\tdocência.\\t\\tKruger\\t(2010)\\tapresentou\\ta\\tEducação\\ta\\tDistância\\t(EaD)\\tna\\tmúsica\\tcomo\\tuma\\tgrande\\taliada\\t na\\t mediação\\t pedagógica\\t e\\t organizacional\\t no\\t curso\\t de\\tformação\\t continuada\\t dos\\tprofessores\\tcom\\tcinco\\tdocentes\\tque\\tatuaram\\tna\\tCoordenadoria\\tde\\tProgramas\\tEducacionais\\tda\\tFundação\\t Orquestra\\t Sinfônica\\t do\\t Estado\\t de\\t São\\tPaulo.\\t No\\tresultados\\t a\\t autora\\t traz\\t algumas\\tsugestões\\t para\\t programas\\t semelhantes,\\t tais\\t como:\\t a\\t elaboração\\t de\\t projetos\\t baseados\\t na\\tprática\\t musical\\t coletiva\\t (incluindo\\t composição\\t e\\t execução,\\t não\\t apenas\\t apreciação),\\t a\\tvalorização\\t da\\t formação\\t continuada\\t dos\\t professores,\\t realizada\\t com\\t maior\\t acompanhamento\\tdo\\t trabalho\\t em\\t sala\\t de\\t aula,\\t via\\t EaD\\t uma\\t grande\\t aliada\\t na\\t mediação\\t pedagógica\\t e', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 5}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   organizacional.\\t\\t\\tRosas\\t (2013)\\t buscou\\t mapear\\t as\\t competências\\t para\\t o\\t contexto\\t tecnológico-musical\\teducacional\\t que\\t docentes\\t e\\tdiscentes\\t podem\\t encontrar\\t com\\t relação\\t ao\\t uso\\t das\\t TIC\\tdirecionadas\\t para\\t música,\\t em\\t especial\\t as\\t TIC\\t gratuitas\\t e\\t baseadas\\t na\\tWeb.\\tOs\\t resultados\\t da\\treferida\\t pesquisa\\t apontam\\t para\\t as\\t contribuições\\tque\\t as\\tdiversas\\t ferramentas\\t digitais\\tonline\\tgratuitas\\tdedicadas\\tà\\tmúsica\\te\\tde\\trecursos,\\tcomo\\tos\\tobjetos\\tde\\taprendizagem\\tdesenvolvidos\\tpor\\t equipes\\t interdisciplinares.\\t Já\\t na\\t Educação\\t Musical,\\t a\\t pesquisa\\t contruibuiu\\t com\\t a\\torganização\\tdo\\tmodelo\\tde\\tcurso\\tdescrito\\tpara\\ta\\tformação\\tde\\tprofessores\\tonde\\to\\tfoco\\tfoi\\to\\tuso\\tde\\ttecnologias\\tdigitais\\tpara\\to\\tdesenvolvimento\\tde\\tcompetências\\ttais\\tcomo:\\tos\\tconhecimentos,\\tas\\t habilidades\\t e\\t as\\t atitudes\\t para\\t uma\\t atuação\\t eficaz\\t no\\t contexto\\t tecnológico-musical\\teducacional. Oliveira-Torres\\t(2012)\\tbuscou\\tcompreender\\tcomo\\ta\\tpedagogia\\tmusical\\tonline\\tacontece\\tno\\tAVA\\ta\\tplataforma\\tmoodle\\tno\\tcurso\\tde\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância\\tda\\tUnB.\\tA\\tautora\\tconclui\\t que\\t o\\t uso\\t das\\t TICs\\t possibilitou\\t e\\t beneficiou\\t de\\t forma\\t pedagógica\\t o\\t ensino\\t e\\taprendizagem\\t musical\\t por\\t meio\\t dos\\t ambientes\\t virtuais\\t de\\t aprendizagem.\\t Além\\t disso,\\t a\\tpedagogia\\t musical\\tonline\\té\\t possível\\t e\\t a\\t procura\\t por\\t essa\\t modalidade\\t de\\t ensino\\t é\\t crescente,\\ttendo\\tem\\tvista\\ta\\tsua\\tflexibilidade\\tna\\torganização\\tdo\\ttempo\\te\\tdo\\tespaço.\\tMéio\\t(2014)\\tbuscou\\tinvestigar\\tcomo\\tuma\\tatividade\\tde\\tcriação\\tmusical\\t\\tcom\\to\\tuso\\tde\\tTIC\\t(o\\tsoftware\\tde\\tvideoconferência\\tSkype,\\tum\\tgrupo\\tna\\trede\\tsocial\\tFacebook,\\te\\to\\teditor\\tde\\tpartituras\\tonline\\tNoteflight)\\tpode\\t ajudar\\t na\\t formação\\tde\\t professores\\t em\\t um\\t curso\\t de\\tLicenciatura\\t em\\tMúsica\\t a\\t Distância.\\tNos\\tresultados\\to\\t autor\\t indica\\ta\\t necessidade\\t de\\t mais\\tatividades\\t de\\t criação\\t musical\\t e\\t de\\t colaboração.\\t Ademais,\\t as\\t TIC\\t utilizadas\\t foram,\\t segundo\\t o\\tautor,\\t\\tde\\tgrande\\tajuda\\tno\\tdesenvolvimento\\tdo\\tprojeto\\tcolaborativo,\\tfavorecendo\\ta\\tinteração\\te\\toferecendo\\t ferramentas\\t úteis\\t ao\\t trabalho\\t de\\t criação\\t musical.\\t Méio\\t (2014)\\t concluiu\\tque\\t a\\tpesquisa\\tapontou\\tpara\\ta\\texistência\\tde\\tvários\\tpossíveis\\tbenefícios\\tdecorrentes\\tda\\tparticipação\\tdos\\tlicenciandos\\tno\\tprojeto,\\tdentre\\tas\\tquais:\\tcompetência\\tno\\tuso\\tdas\\tTICs\\te\\tde\\tsítios\\tvariados\\tpara\\to\\tensino\\tda\\tmúsica,\\tincorporação\\tda\\tcolaboração\\tna\\tprática\\tde\\tensino\\te\\tenriquecimento\\tdo\\tconteúdo\\tutilizado.\\t\\tCernev\\t (2015)\\tinvestigou\\t a\\t aprendizagem\\t musical\\t colaborativa\\t e\\t a\\t motivação\\t dos', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 6}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   alunos\\t para\\t aprender\\t utilizando\\t as\\t TIC\\t(redes\\t sociais\\t como\\tFacebook,\\tYouTube,\\tTwitter,\\tSoundCloud\\te\\talguns\\tjogos\\tonline)\\tno\\tcontexto\\tda\\tEducação\\tBásica.\\tOs\\tresultados\\tapontaram\\tpara\\tas\\tdiferentes\\testratégias\\tque\\tos\\talunos\\tadotaram\\tem\\tsala\\tde\\taula\\ttais\\tcomo\\ta\\tmediação\\ttecnológica,\\tdo\\texperimentar,\\ttestar,\\tretirar\\te\\tinserir\\toutras\\tformas\\tde\\tmanipular\\tos\\tmateriais\\tsonoros\\tque\\tsão\\tferramentas\\tque\\tauxiliam\\ta\\tconstruir\\to\\tpensamento\\tmusical.\\tEsta\\tmediação\\ttecnológica\\t propiciou\\t que\\t o\\t processo\\t de\\t colaboração\\t fosse\\t mais\\t fácil\\t em\\t uma\\t atividade\\tmusical,\\tgerando\\tuma\\testratégia\\tsocial\\tde\\taprendizagem.\\tEstas\\testratégias\\ttambém\\tindicam\\tas\\trelações\\tque\\tos\\talunos\\testabeleceram\\tcom\\tas\\ttecnologias\\tdigitais\\tbem\\tcomo\\ta\\tmotivação\\tdos\\testudantes\\tpara\\tas\\taulas\\tde\\tmúsica.\\t\\tOrtiz-Rodrigues\\t (2015)\\t buscou\\t descrever,\\t analisar\\t e\\t interpretar\\t a\\tutilização\\t das\\tsugestões\\t de\\t aulas\\t de\\t música\\t disponibilizadas\\t no\\t Portal\\t do\\t Professor\\t do\\t MEC3,\\t que\\t consiste\\tnum\\t espaço\\t tipo\\t repositório\\t de\\t Recursos\\t Educacionais\\t Abertos\\t (REA)4\\tpara\\t aulas\\t de\\t música.\\tEntre\\t os\\t resultados\\t obtidos,\\t destaca-se\\t a\\tpouca\\t utilização\\t das\\t sugestões\\t de\\t aulas\\t do\\t Portal\\tpelos\\tprofessores\\tno\\tplanejamento\\tde\\tsuas\\tatividades\\tmusicais.\\tNas\\taulas\\tde\\tmúsica\\tanalisadas,\\to\\t uso\\t de\\t TIC\\t apresenta-se\\t como\\t uma\\t ferramenta\\t de\\t apoio\\t para\\t atividades\\t e\\t ainda\\t é\\t pouco\\texplorado\\tcomo\\trecurso\\tmúsico\\tpedagógico.\\t\\tPor\\tfim,\\tSantos\\t(2015)\\tapresenta\\tque\\ta\\tutilização\\tdas\\tTIC\\tpor\\tparte\\tdos\\tprofessores\\tna\\tsala\\t aula\\t representou-se\\t como\\t motivacão\\t entre\\t os\\t \\t alunos.\\tOs\\t resultados\\t apontam\\t para\\t a\\treflexão\\t do\\t uso\\t pedagógico\\t das\\t TIC\\t como\\t uma\\t possibilidade\\t de\\t integrar\\t uma\\t metodologia\\talinhada\\tao\\tmomento\\ttecnológico\\tatual.\\tSão\\tapresentados\\tfatores\\tque\\tdificultam\\to\\tensino\\tda\\tmúsica\\t com\\t o\\t uso\\t das\\t TIC,\\t tais\\t como\\t a\\t falta\\t de\\t infraestrutura,\\t a\\t burocracia,\\t a\\t falta\\t de\\tinvestimento\\t pelas\\t camadas\\t administrativas.\\tPorém,\\t o\\t autor\\t reforça\\t que\\t os\\t professores,\\tmesmo\\tdiante\\tas\\tdificuldades,\\tsão\\tfavoráveis\\ta\\tintegração\\tdos\\trecursos\\ttecnológico\\tna\\tsala\\tde\\taula.\\tPor\\t meio\\t da\\t revisão\\t de\\t literatura\\t inicial\\t percebe-se\\tque\\t as\\t tendências\\t das\\tpesquisas\\tque\\t abordam\\t o\\t uso\\t das\\t TIC\\t por\\t professores\\t de\\t música,\\t os\\t saberes\\t e\\t competências\\t docentes\\t                                                3\\tMinistério\\tda\\tEducação.\\t4 São recursos\\tdigitais\\tde\\tlivre\\tacesso\\te\\tde\\tlicença\\taberta.', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 7}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   diante\\tas\\tinovações\\ttecnológicas.\\tAssim,\\ttorna-se\\trelevante\\tverificar\\tcomo\\tos\\tegressos\\tdo\\tcurso\\tde\\tLicenciatura\\t em\\tMúsica\\t a\\tDistância\\t da\\tUnB\\tinserem\\t as\\tTIC\\tna\\t sala\\t de\\t aula\\t de\\t escolas\\t de\\tEducação\\tBásica.\\t\\tDessa\\tforma,\\tconsiderando\\ta\\tproposta\\tde\\tpesquisa,\\tna\\tmetodologia,\\taposta-se\\tem\\tum\\testudo\\tqualitativo\\t (YIN,\\t 2001;\\t GIL,\\t 2002\\t e\\t PRODANOV;\\t FREITAS,\\t2013)\\tcom\\t os\\t egressos\\t do\\tcurso\\t de\\tLicenciatura\\t em\\tMúsica\\t a\\t Distância\\t da\\tUnB\\ttendo\\tcomo\\tinstrumentos\\t de\\t coleta\\t de\\tdados\\to\\tquestionário\\te\\ta\\tentrevista\\tsemiestruturada.\\tO\\tquestionário\\tvisando\\tdelineamento\\tdo\\tperfil\\tdos\\tegressos\\tque\\tutilizam\\tas\\tTIC\\tnas\\tpráticas\\tdocentes\\te\\ta\\tentrevista\\tsemiestruturada\\tno\\tintuito\\tde\\tverificar\\te\\tidentificar\\tcomo\\tas\\tTIC\\tpotencializam\\to\\tensino\\tda\\tmúsica\\tnos\\tcontextos\\tde\\tatuação\\tdos\\tegressos.\\t\\tConsiderações\\tfinais\\tEste\\t trabalho\\tconsiste\\t de\\tum\\t projeto\\t de\\t pesquisa\\t de\\t mestrado\\t em\\t andamento\\tque\\taborda\\t a\\tutilização\\t das\\t TIC\\t nas\\t práticas\\t docentes\\t dos\\t egressos\\t do\\t curso\\t de\\t Licenciatura\\t em\\tMúsica\\t a\\tDistância\\t da\\tUnB.\\tPortanto,\\t por\\t meio\\t da\\t problematização\\t e\\t revisão\\t de\\t literatura\\t o\\ttema\\tde\\tpesquisa\\ttorna-se\\tinstigante\\tpara\\ta\\tárea\\tde\\tEducação\\tMusical\\te\\tEAD,\\tprincipalmente,\\tpor\\t estar\\t relacionada\\tcom\\t a\\t formação\\t e\\tas\\t práticas\\t docentes\\t de\\t egressos\\t de\\tum\\t curso\\t de\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância.\\t\\tA\\tliteratura\\trevela\\tque\\to\\tuso\\tdas\\tTIC\\tna\\tprática\\tdocente\\tde\\tegressos\\tde\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância\\té\\tuma\\ttemática\\tque\\ttem\\tum\\tgrande\\tpontencial\\ta\\tser\\texplorada,\\tvisto\\tque,\\thá\\tuma\\tcrescente\\tutilização\\tdas\\tTIC\\tem\\tcontextos\\tdiversos.\\tA\\timportância\\t\\tde\\tfocar\\tno\\tegressos\\tse\\t deve\\t ao\\t fato\\t de\\t que\\t durante\\t o\\t curso,\\t os\\t alunos\\tdo\\t curso\\t de\\t Licenciatura\\t em\\t Música\\t a\\tDistância\\tda\\tUnB\\ttêm\\tcontato\\tcom\\tas\\tTIC\\t\\tpor\\tmeio\\tdos\\tmateriais\\tdidáticos\\tno\\tAVA\\tassim\\tcomo\\to\\tuso\\tda\\tinternet\\te\\tsoftware\\tde\\tmúsica,\\tporém,\\tpouco\\tse\\tsabe\\tsobre\\tessa\\tutilização\\tnas\\taulas\\tde\\tmúsica\\tna\\tEducação\\tBásica\\te/ou\\toutros\\tcontextos.\\t\\tDiante\\tdo\\texposto,\\tconsiderando\\to\\tuso\\tda\\tTICs\\tna\\tformação\\tde\\tegressos\\tem\\tcursos\\tde\\tLicenciatura\\tem\\tMúsica\\ta\\tdistância,\\tjuntamente\\tcom\\ta\\tcrescente\\tutilização\\tdas\\tTICs,\\tespera-se\\tentão,\\tque\\teste\\testudo\\tpossa\\tcontribuir\\tna\\tárea\\tde\\tEducação\\tMusical\\tcom\\trelação\\tao\\tensino\\tde', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 8}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   música\\te\\tuso\\tdas\\tTIC,\\tprincipalmente\\tna\\tEducação\\tBásica,\\tbem\\tcomo\\ttrazer\\tsugestões\\tno\\tque\\ttange\\tà\\tinovações\\ttecnológicas\\tpara\\tcursos\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância.', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 9}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   Referências\\tBORGES,\\tGilberto\\tAndré.\\tTecnologias\\tda\\tinformação\\te\\tcomunicação\\tna\\tformação\\tinicial\\tdo\\tprofessor\\tde\\tmúsica:\\tum\\testudo\\tsobre\\to\\tuso\\tde\\trecursos\\ttecnológicos\\tpor\\testudantes\\tde\\tlicenciatura\\tem\\tmúsica\\tno\\testado\\tde\\tSanta\\tCatarina.\\tDissertação\\t(Mestrado\\tem\\tmúsica).\\tUniversidade\\tdo\\tEstado\\tde\\tSanta\\tCatarina,\\tFlorianópolis,\\t2010.\\t\\tCERNEV,\\tFrancine\\tKemmer.\\tAprendizagem\\tmusical\\tcolaborativa\\tmediada\\tpelas\\ttecnologias\\tdigitais:\\tmotivação\\tdos\\talunos\\te\\testratégias\\tde\\taprendizagem.\\tTese\\t(Doutorado\\tem\\tMúsica).\\tPrograma\\tde\\tPós-Graduação\\tem\\tMúsica,\\tUniversidade\\tFederal\\tdo\\tRio\\tGrande\\tdo\\tSul,\\tPorto\\tAlegre,\\t2015.\\t\\tGIL,\\tA.\\tC.\\tComo\\telaborar\\tprojetos\\tde\\tpesquisa.\\t4.\\ted.\\tSão\\tPaulo:\\tAtlas,\\t2010.\\t\\t\\tGOHN,\\tDaniel\\tMarcondes.\\tEducação\\tMusical\\ta\\tdistância:\\tproposta\\tde\\tensino\\te\\taprendizagem\\tde\\tpercussão.\\tTese\\tde\\tdoutorado\\tem\\tCiências\\tda\\tComunicação.\\tSão\\tPaulo:\\tUniversidade\\tde\\tSão\\tPaulo,\\tEscola\\tde\\tComunicações\\te\\tArtes,\\t2009.\\t\\tKRUGER,\\tSusana\\tEster.\\tA\\tpercepção\\tde\\tdocentes\\tsobre\\ta\\tformação\\tcontinuada\\tem\\teducação\\tmusical,\\tapoiada\\tpela\\tEducação\\ta\\tDistância,\\tem\\tum\\tcontexto\\torquestral.\\t[307f.].\\tTese\\t(Doutorado\\tem\\tEducação).\\tPontifícia\\tUniversidade\\tCatólica\\tde\\tSão\\tPaulo,\\tSão\\tPaulo,\\t2010.\\t\\tLEME,\\tGerson\\tRios;\\tBELLOCHIO,\\tCláudia\\tRibeiro.\\tProfessores\\tde\\tescolas\\tde\\tmúsica:\\tum\\testudo\\tsobre\\ta\\tutilização\\tde\\ttecnologias.\\tRevista\\tda\\tABEM,\\tPorto\\tAlegre,\\tV.\\t17,\\t87-96,\\tset.\\t2007.\\t\\tMARINS,\\tPaulo\\tRoberto\\tAffonso;\\tNARITA,\\tFlávia\\tMotoyama.\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância\\tnaUnB:\\tplanejamento\\te\\timplementação.\\tIn:\\tFERNANDES,\\tMaria\\tLidia\\tB.\\t(org.).\\tTrajetória\\tdas\\tlicenciaturas\\tda\\tUnB:\\tEaD\\tem\\tfoco.\\tBrasília:\\tEditora\\tUnB,\\t2012,\\tp.151-167.\\t\\tMARTINS,\\t\\tElaine.\\tO\\tque\\té\\tMP3?.\\tTECMUNDO,\\t2008.\\tDisponível\\tem:\\t<http://www.tecmundo.com.br/musica/214-o-que-e-mp3-.htm>.\\tAcesso\\tem:\\t01\\tjun.\\t2016.\\t\\tMÉIO,\\tDaniel\\tBaker.\\tCriação\\tmusical\\tcom\\to\\tuso\\tdas\\tTIC:\\tum\\testudo\\tcom\\talunos\\tde\\tlicenciatura\\tem\\tmúsica\\ta\\tdistância\\tda\\tUnB.\\tDissertação\\t(Mestrado\\tem\\tMúsica).\\tPrograma\\tde\\tPós-graduação\\tmúsica\\tem\\tcontexto,\\tUniversidade\\tde\\tBrasília,\\tBrasília,\\t2014.\\t\\tOLIVEIRA-TORRES,\\tFernanda\\tde\\tAssis.\\tPedagogia\\tmusical\\tonline:\\tum\\testudo\\tde\\tcaso\\tno\\tensino\\tsuperior\\tde\\tmúsica\\ta\\tdistância.\\tTese\\t(Doutorado\\tem\\tMúsica).\\tPrograma\\tde\\tPós-Graduação\\tem\\tMúsica,\\tUniversidade\\tFederal\\tdo\\tRio\\tGrande\\tdo\\tSul,\\tPorto\\tAlegre,\\t2012.', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 10}),\n",
       " Document(page_content='XIV\\tEncontro\\tRegional\\tCentro-Oeste\\tda\\tABEM\\tDiversidade\\thumana,\\tresponsabilidade\\tsocial\\te\\tcurrículos:\\tinterações\\tna\\teducação\\tmusical\\tCuiabá,\\t23\\ta\\t25\\tde\\tnovembro\\tde\\t2016   ORTIZ\\tRODRIGUEZ,\\tMaria\\tDébora.\\tA\\tmúsica\\tno\\t“espaço\\tda\\taula”\\tdo\\tportal\\tdo\\tprofessor\\tde\\t2008-2014\\u202f:\\tas\\taulas\\tpara\\to\\tensino\\tmédio.\\t\\tDissertação\\t(Mestrado\\tem\\tMúsica).Programa\\tde\\tPós-graduação\\tmúsica\\tem\\tcontexto,\\tUniversidade\\tde\\tBrasília,\\tBrasília,\\t2015.\\t\\tPENNA,\\tMaura.\\tConstruindo\\to\\tprimeiro\\tprojeto\\tde\\tpesquisa\\tem\\teducação\\te\\tmúsica.\\tPorto\\tAlegre:\\tSulinas,\\t2015.\\t\\tPEREIRA,\\tMarcos\\tVinícius\\tMedeiros.\\tFundamentos\\tteórico-metodológicos\\tda\\tpesquisa\\tem\\teducação:\\to\\tensino\\tsuperior\\tem\\tmúsica\\tcomo\\tobjeto.\\tRevista\\tda\\tFAEEBA\\t–\\tEducação\\te\\tContemporaneidade,\\tSalvador,\\tv.\\t22,\\tn.\\t40,\\tp.\\t221-233,\\tjul./dez.\\t2013.\\t\\t\\tPRODANOV,\\tCleber\\tCristiano;\\tFREITAS,\\tErnani\\tCesar\\tde.\\tMetodologia\\tdo\\ttrabalho\\tcientífico:\\tmétodos\\te\\ttécnicas\\tda\\tpesquisa\\te\\tdo\\ttrabalho\\tacadêmico.\\t2.\\ted.\\tNovo\\tHamburgo\\t–\\tRGS:\\tUniversidade\\tFeevale,\\t2013,\\tp.114.\\t\\tROSAS,\\tFátima\\tWeber.\\tCompetências\\tpara\\to\\tcontexto\\ttecnológico-musical:\\tum\\tfoco\\tnas\\ttecnologias\\tdigitais\\tonline\\tpara\\ta\\teducação.\\tDissertação\\t(Mestrado\\tem\\tMúsica).\\tPrograma\\tde\\tPós-Graduação\\tem\\tMúsica,\\tUniversidade\\tFederal\\tdo\\tRio\\tGrande\\tdo\\tSul,\\tPorto\\tAlegre,\\t2013.\\t\\tSANTOS,\\tAlexandre\\tHenrique\\tdos.\\tAs\\ttecnologias\\tde\\tinformação\\te\\tcomunicação\\t(TIC)\\tna\\teducação\\tmusical:\\tum\\testudo\\tsobre\\ta\\trelação\\tdas\\tlicenciaturas\\tem\\tmúsica\\tcom\\to\\tfenômeno\\ttecnológico.\\tDissertação\\t(Mestrado\\tem\\tMúsica).\\tPrograma\\tde\\tPós-Graduação\\tem\\tMúsica,\\tUniversidade\\tEstadual\\tde\\tCampinas,\\tCampinas,\\t2015.\\t\\tUNIVERSIDADE\\tDE\\tBRASÍLIA.\\tProjeto\\tPedagógico\\tdo\\tCurso\\tde\\tLicenciatura\\tem\\tMúsica\\ta\\tDistância\\tda\\tUnB,\\t2011.\\tDisponível\\tem:\\t<http://www.ead.unb.br/moodle2013/pluginfile.php/93199/mod_resource/content/2/Proje\\tto%20Pol%C3%ADtico%20Pedag%C3%B3gico_atualizado%20em%2026.05.2012_SEM%20BI\\tBLIOGRAFIA.pdf>.\\tAcesso\\tem:\\t10\\tago.\\t2016.\\t\\t\\tVALENTE,\\tJ.\\tA.\\tA\\tEspiral\\tda\\tEspiral\\tde\\tAprendizagem:\\to\\tprocesso\\tde\\tcompreensão\\tdo\\tpapel\\tdas\\ttecnologias\\tde\\tinformação\\te\\tcomunicação\\tna\\teducação.\\t2005.\\tTese\\t(Livre\\tDocência)\\t–\\tUniversidade\\tEstadual\\tde\\tCampinas.\\tCampinas,\\tSão\\tPaulo.\\t\\tYIN,\\tR.\\tK.\\tEstudo\\tde\\tcaso:\\tplanejamento\\te\\tmétodos.\\t2.\\ted.\\tPorto\\tAlegre:\\tBookman,\\t2001.', metadata={'source': 'repositorio\\\\A utilização das Tecnologias da Informação e Comunicação nas práticas docentes um estudo com egressos de curso de Licenciatura em Música a Distância.pdf', 'page': 11}),\n",
       " Document(page_content='Do original:\\nArtificial Intelligence\\nTradução autorizada do idioma inglês da edição publicada por Prentice Hall\\nCopyright © 2010, 2003,1995 by Pearson Education, Inc.\\n© 2013, Elsevier Editora Ltda.\\nTodos os direitos reservados e protegidos pela Lei n\\no\\n 9.610, de 19/02/1998.\\nNenhuma parte deste livro, sem autorização prévia por escrito da editora, poderá ser reproduzida ou transmitida sejam quais forem os\\nmeios empregados: eletrônicos, mecânicos, fotográficos, gravação ou quaisquer outros.\\nCoordenação de produção\\n: Silvia Lima\\nCopidesque\\n: Ivone Teixeira\\nEditoração eletrônica\\n: DTPhoenix Editorial\\nRevisão gráfica\\n: Marília Pinto de Oliveira\\nConversão para eBook\\n: Freitas Bastos\\nElsevier Editora Ltda.\\nConhecimento sem Fronteiras\\nRua Sete de Setembro, 111 – 16\\no\\n andar\\n20050-006 – Centro – Rio de Janeiro – RJ – Brasil\\nRua Quintana, 753 – 8\\no\\n andar\\n04569-011 – Brooklin – São Paulo – SP – Brasil\\nServiço de Atendimento ao Cliente\\n0800-0265340\\nsac@elsevier.com.br\\nISBN da edição original: 978-0136042594\\nISBN: 978-85-352-3701-6\\nNota:\\n Muito zelo e técnica foram empregados na edição desta obra. No entanto, podem ocorrer erros de digitação, impressão ou dúvida\\nconceitual. Em qualquer das hipóteses, solicitamos a comunicação ao nosso Serviço de Atendimento ao Cliente, para que possamos\\nesclarecer ou encaminhar a questão.\\n   Nem a editora nem o autor assumem qualquer responsabilidade por eventuais danos ou perdas a pessoas ou bens, originados do uso\\ndesta publicação.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 2}),\n",
       " Document(page_content='CIP-Brasil. Catalogação-na-fonte.\\nSindicato Nacional dos Editores de Livros, RJ\\nR925i\\nRussell, Stuart J. (Stuart Jonathan), 1962-\\nInteligência artificial / Stuart Russell, Peter Norvig; tradução Regina Célia Simille. – Rio\\nde Janeiro: Elsevier, 2013.\\nTradução de: Artificial intelligence, 3rd ed.\\nInclui bibliografia e índice\\nISBN 978-85-352-3701-6\\n1. Inteligência artificial. I. Norvig, Peter, 1956- II. Título.\\n11-\\n5978\\nCDD: 006.3\\nCDU: 004.81', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 3}),\n",
       " Document(page_content='Para Loy, Gordon, Lucy e Isaac\\n — S.J.R.\\nPara Kris, Isabella e Juliet\\n — P.N.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 4}),\n",
       " Document(page_content='A\\nPrefácio\\ninteligência artificial\\n (IA) é um grande campo, e este é um grande livro. Tentamos explorar toda\\na extensão do assunto, que abrange lógica, probabilidade e matemática do contínuo, além de\\npercepção, raciocínio, aprendizado, ação e, ainda, tudo o que se refere à eletrônica, desde\\ndispositivos microeletrônicos até robôs para exploração planetária. O livro também é grande porque\\nnos aprofundamos na apresentação de resultados.\\nO subtítulo deste livro é “Uma Abordagem Moderna”. O significado pretendido dessa frase um\\ntanto vazia é que tentamos sintetizar o que hoje é conhecido numa estrutura comum, em vez de\\ntentarmos explicar cada subcampo da IA em seu próprio contexto histórico. Pedimos desculpas\\nàqueles que trabalham em subcampos, que, como resultado, receberam menos reconhecimento do que\\ndeveriam.\\nNovidades desta edição\\nEsta edição capturou as mudanças em IA que tiveram lugar desde a última edição em 2003. Houve\\naplicações importantes de tecnologia de IA, tais como a implantação generalizada da prática de\\nreconhecimento de fala, tradução automática, veículos autônomos e robótica de uso doméstico.\\nHouve marcos em algoritmos, como a solução do jogo de damas, e um significativo progresso\\nteórico, particularmente em áreas como a do raciocínio probabilístico, aprendizado de máquina e\\nvisão computacional. Mais importante, do nosso ponto de vista, é a evolução contínua na maneira\\ncomo pensamos sobre essa área e, dessa forma, como organizamos este livro. As principais\\nmudanças foram as seguintes:\\n•  Colocamos mais ênfase em ambientes parcialmente observáveis e não determinísticos,\\nespecialmente nas configurações não probabilísticas de pesquisa e planejamento. Os conceitos\\nde \\nestado de crença\\n (um conjunto de mundos possíveis) e \\nestimação de estado\\n (manutenção do\\nestado de crença) foram introduzidos nesta versão; mais adiante, adicionamos probabilidades.\\n•  Além de discutir os tipos de ambientes e tipos de agentes, agora cobrimos com mais\\nprofundidade os tipos de \\nrepresentações\\n que um agente pode utilizar. Distinguimos entre\\nrepresentações \\natômicas\\n (em que cada estado do mundo é tratado como uma caixa-preta),\\nrepresentações \\nfatoradas\\n (em que um estado é um conjunto de atributos/pares de valor) e\\nrepresentações \\nestruturadas\\n (em que o mundo consiste em objetos e relações entre eles).\\n•  Nossa cobertura do planejamento aprofundou-se sobre o planejamento contingente em ambientes\\nparcialmente observáveis, incluindo\\u200b\\u200b uma nova abordagem para o planejamento hierárquico.\\n•  Adicionamos um novo material de modelos probabilísticos de primeira ordem, incluindo\\nmodelos de \\nuniverso aberto\\n para casos de incerteza quanto à existência de objetos.\\n•  Reescrevemos totalmente o capítulo introdutório de aprendizado de máquina, salientando uma\\nvariedade ampla de aprendizagem mais moderna de algoritmos, colocando-os em um patamar', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 5}),\n",
       " Document(page_content='teórico mais consistente.\\n•  Expandimos a cobertura de pesquisa na Web e de extração de informações e de técnicas de\\naprendizado a partir de conjuntos de dados muito grandes.\\n•  20% das citações desta edição são de trabalhos publicados depois de 2003.\\n•  Estimamos que 20% do material é novo. Os 80% restantes refletem trabalhos mais antigos, mas\\nforam amplamente reescritos para apresentar uma imagem mais unificada da área.\\nVisão geral do livro\\nO principal tema unificador é a ideia de \\nagente inteligente\\n. Definimos a IA como o estudo de\\nagentes que recebem percepções do ambiente e executam ações. Cada agente implementa uma função\\nque mapeia sequências de percepções em ações, e abordaremos diferentes maneiras de representar\\nessas funções, tais como sistemas de produção, agentes reativos, planejadores condicionais em\\ntempo real, redes neurais e sistemas de teoria de decisão. Explicaremos o papel da aprendizagem\\ncomo uma extensão do alcance do projetista em ambientes desconhecidos e mostraremos que esse\\npapel restringe o projeto de agentes, favorecendo a representação explícita do conhecimento e do\\nraciocínio. Trataremos da robótica e da visão, não como problemas definidos independentemente,\\nmas como ocorrendo a serviço da realização de objetivos. Enfatizamos a importância do ambiente da\\ntarefa na determinação do projeto apropriado de agentes.\\nNosso principal objetivo é transmitir as \\nideias\\n que emergiram nos últimos cinquenta anos de\\npesquisa sobre a IA e nos dois últimos milênios de trabalhos relacionados a esse tema. Procuramos\\nevitar uma formalidade excessiva na apresentação dessas ideias, ao mesmo tempo em que tentamos\\npreservar a exatidão. Quando consideramos apropriado, incluímos algoritmos em pseudocódigo para\\ntornar as ideias concretas; nosso pseudocódigo é descrito de forma sucinta no Apêndice B.\\nEste livro se destina principalmente ao uso em cursos de graduação ou de extensão. Também pode\\nser usado em curso de pós-graduação (talvez com a inclusão de algumas das principais fontes de\\nconsulta sugeridas nas notas bibliográficas). O único pré-requisito é a familiaridade com os\\nconceitos básicos de ciência da computação (algoritmos, estruturas de dados, complexidade) em\\nnível básico; os fundamentos matemáticos necessários encontram-se no Apêndice A.\\n Os exercícios que exigem programação significativa estão marcados com um \\nícone de\\nteclado\\n. Esses exercícios podem ser mais bem resolvidos aproveitando-se o repositório de código\\nem \\naima.cs.berkeley.edu\\n. Alguns deles são grandes o suficiente para serem considerados\\nprojetos semestrais. Vários exercícios exigem alguma investigação da literatura de referência; esses\\nexercícios estão marcados com o ícone de \\nlivro\\n.\\n Ao longo do livro, os pontos importantes estão indicados por um pequeno ícone de mão\\napontando\\n. Incluímos um índice extenso, com cerca de 6.000 termos, a fim de facilitar a localização\\nde itens no livro. Onde quer que um \\nnovo termo\\n seja definido pela primeira vez, ele também estará\\nindicado na margem.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 6}),\n",
       " Document(page_content='Sobre o site\\n*\\naima.cs.berkeley.edu\\n, \\no site do\\n livro, contém:\\n•  implementações dos algoritmos do livro em várias linguagens de programação\\n•  uma lista de mais de 1.000 escolas que utilizaram o livro, muitas com links para materiais de\\ncursos on-line e ementas\\n•  uma lista comentada com mais de 800 links para diversos sites com conteúdo útil de IA\\n•  uma lista, capítulo por capítulo, de materiais de consulta e links suplementares\\n•  instruções sobre como participar de um grupo de discussão referente ao livro\\n•  instruções sobre como entrar em contato com os autores para fazer perguntas ou comentários\\nSobre a capa\\nA capa mostra a posição final do jogo decisivo da partida 6 de 1997 entre o campeão de xadrez\\nGarry Kasparov e o programa DEEP BLUE. Kasparov, com a cor preta, foi forçado a desistir,\\ntornando essa a primeira vez que um computador derrotou um campeão do mundo em uma partida de\\nxadrez. No topo está a imagem de Kasparov. À sua esquerda está o robô humanoide Asimo e, à sua\\ndireita, Thomas Bayes (1702-1761), cujas ideias sobre probabilidade, como medida de crença,\\nformam a base de muito da tecnologia moderna de IA. Abaixo vemos o MarsExploration Rover, um\\nrobô que aterrissou em Marte em 2004 e tem explorado o planeta desde então. À direita está Alan\\nTuring (1912-1954), cujo trabalho fundamental definiu os campos da ciência da computação em geral\\ne da inteligência artificial em particular. No fundo está Shakey (1966-1972), o primeiro robô a\\ncombinar percepção, modelagem do mundo, planejamento e aprendizado. Junto com Shakey está o\\nlíder de projeto Charles Rosen (1917-2002). Embaixo à direita está Aristóteles (384-322 a.C.),\\npioneiro no estudo da lógica, seu trabalho foi o estado da arte até o século XIX (cópia de um busto\\npor Lisipo). Na parte inferior à esquerda, levemente escondido atrás dos nomes dos autores, está um\\nalgoritmo de planejamento por Aristóteles de \\nDe Motu Animalium\\n no original em grego. Atrás do\\ntítulo está uma porção da rede bayesiana CPSC para diagnóstico médico (Pradhan \\net al\\n., 1994).\\nAtrás do tabuleiro de xadrez encontra-se parte do modelo lógico bayesiano para detectar explosões\\nnucleares a partir de sinais sísmicos.\\nCréditos: Stan Honda/Getty (Kasparov), Biblioteca do Congresso (Bayes), Nasa (Mars rover),\\nNational Museum of Rome (Aristóteles), Peter Norvig (livro), Ian Parker (silhueta de Berkeley),\\nShutterstock (Asimo, peças de xadrez), Time Life/Getty (Shakey, Turing).\\nAgradecimentos\\nEste livro não teria sido possível sem os muitos colaboradores cujos nomes não consegui colocar\\nna capa. Jitendra Malik e David Forsyth escreveram o Capítulo 24 (visão computacional) e Sebastian\\nThrun escreveu o Capítulo 25 (robótica). Vibhu Mittal escreveu parte do Capítulo 22 (linguagem\\nnatural). Nick Hay, Mehran Sahami e Ernest Davis escreveram alguns dos exercícios. Zoran Duric', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 7}),\n",
       " Document(page_content='(George Mason), Thomas C. Henderson (Utah), Leon Reznik (RIT), Michael Gourley (Central\\nOklahoma) e Ernest Davis (NYU) revisaram o manuscrito e fizeram sugestões úteis. Agradecemos a\\nErnie Davis, em especial por sua capacidade incansável para ler múltiplos rascunhos e ajudar a\\nmelhorar o livro. Nick Hay formatou a bibliografia e no prazo final permaneceu até às 05h30\\ncodificando para melhorar o livro. Jon Barron formatou e melhorou os diagramas nesta edição,\\nenquanto Tim Huang, Mark Paskin e Cynthia Bruyns ajudaram com diagramas e algoritmos em\\nedições anteriores. Ravi Mohan e Ciaran O’Reilly escreveram e mantiveram os exemplos de código\\nJava no site. John Canny escreveu o capítulo de robótica para a primeira edição e Douglas Edwards\\npesquisou as notas históricas. Tracy Dunkelberger, Allison Michael, Scott Disanno e Jane Bonnell da\\nPearson fizeram o melhor possível para nos manter dentro do cronograma e deram muitas sugestões\\núteis. Mais útil de todas foi Julie Sussman, P.P.A., que leu todos os capítulos, proporcionando\\nmelhorias extensivas. Nas edições anteriores tivemos revisores que nos avisavam se deixávamos\\numa vírgula de fora, corrigiam para \\nqual\\n quando colocávamos \\nque\\n, Julie avisava-nos quando nos\\nesquecíamos de um sinal de menos e corrigia para \\nx\\ni\\n quando colocávamos \\nx\\nj\\n. Para cada erro de\\ndigitação ou explicação confusa que permaneceu no livro, tenha certeza de que Julie corrigiu pelo\\nmenos cinco. Ela perseverou mesmo quando uma falha de energia a obrigou a trabalhar com luz da\\nlanterna, em vez da incandescência do LCD.\\nStuart gostaria de agradecer\\n a seus pais pelo apoio e incentivo constante, e à sua esposa, Loy\\nSheflott, por sua paciência infinita e sabedoria ilimitada. Ele espera que Gordon, Lucy, George e\\nIsaac logo estejam lendo este livro, após perdoá-lo por ter trabalhado tanto. O RUGS (Russell’s\\nUnusual Group of Students — Grupo Incomum de Alunos de Russell) foi de uma utilidade sem igual,\\ncomo sempre.\\nPeter gostaria de agradec\\ner a seus pais (Torsten e Gerda), os responsáveis pelo início de sua\\ncarreira, e também à sua esposa (Kris), a seus filhos (Bella e Juliet), colegas e amigos pelo incentivo\\ne pela tolerância durante as longas horas de escrita e durante as horas ainda mais longas em que foi\\npreciso reescrever algumas páginas.\\nNós dois agradecemos\\n aos bibliotecários em Berkeley, Stanford, e à Nasa e aos desenvolvedores\\ndo CiteSeer, Wikipédia e Google, que revolucionaram a maneira de pesquisar. Não podemos\\nagradecer a todas as pessoas que utilizaram o livro e fizeram sugestões, mas gostaríamos de observar\\nos comentários especialmente úteis de Gagan Aggarwal, Eyal Amir, Ion Androutsopoulos, Krzysztof\\nApt, Warren Haley Armstrong, Ellery Aziel, Jeff Van Baalen, Darius Bacon, Brian Baker, Shumeet\\nBaluja, Don Barker, Tony Barrett, James Newton Bass, Don Beal, Howard Beck, Wolfgang Bibel,\\nJohn Binder, Larry Bookman, David R. Boxall, Ronen Brafman, John Bresina, Gerhard Brewka,\\nSelmer Bringsjord, Carla Brodley, Chris Brown, Emma Brunskill, Wilhelm Burger, Lauren Burka,\\nCarlos Bustamante, João Cachopo, Murray Campbell, Norman Carver, Emmanuel Castro, Anil\\nChakravarthy, Dan Chisarick, Berthe Choueiry, Roberto Cipolla, David Cohen, James Coleman, Julie\\nAnn Comparini, Corinna Cortes, Gary Cottrell, Ernest Davis, Tom Dean, Rina Dechter, Tom\\nDietterich, Peter Drake, Chuck Dyer, Doug Edwards, Robert Egginton, Asma’a El-Budrawy, Barbara\\nEngelhardt, Kutluhan Erol, Oren Etzioni, Hana Filip, Douglas Fisher, Jeffrey Forbes, Ken Ford, Eric\\nFosler-Lussier, John Fosler, Jeremy Frank, Alex Franz, Bob Futrelle, Marek Galecki, Stefan\\nGerberding, Stuart Gill, Sabine Glesner, Seth Golub, Gosta Grahne, Russ Greiner, Eric Grimson,\\nBarbara Grosz, Larry Hall, Steve Hanks, Othar Hansson, Ernst Heinz, Jim Hendler, Christoph', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 8}),\n",
       " Document(page_content='Herrmann, Paul Hilfinger, Robert Holte, Vasant Honavar, Tim Huang, Seth Hutchinson, Joost Jacob,\\nMark Jelasity, Magnus Johansson, Istvan Jonyer, Dan Jurafsky, Leslie Kaelbling, Keiji Kanazawa,\\nSurekha Kasibhatla, Simon Kasif, Henry Kautz, Gernot Kerschbaumer, Max Khesin, Richard Kirby,\\nDan Klein, Kevin Knight, Roland Koenig, Sven Koenig, Daphne Koller, Rich Korf, Benjamin\\nKuipers, James Kurien, John Lafferty, John Laird, Gus Larsson, John Lazzaro, Jon LeBlanc, Jason\\nLeatherman, Frank Lee, Jon Lehto, Edward Lim, Phil Long, Pierre Louveaux, Don Loveland, Sridhar\\nMahadevan, Tony Mancill, Jim Martin, Andy Mayer, John McCarthy, David McGrane, Jay\\nMendelsohn, Risto Miikkulanien, Brian Milch, Steve Minton, Vibhu Mittal, Mehryar Mohri, Leora\\nMorgenstern, Stephen Muggleton, Kevin Murphy, Ron Musick, Sung Myaeng, Eric Nadeau, Lee\\nNaish, Pandu Nayak, Bernhard Nebel, Stuart Nelson, XuanLong Nguyen, Nils Nilsson, Illah\\nNourbakhsh, Ali Nouri, Arthur Nunes-Harwitt, Steve Omohundro, David Page, David Palmer, David\\nParkes, Ron Parr, Mark Paskin, Tony Passera, Amit Patel, Michael Pazzani, Fernando Pereira,\\nJoseph Perla, Wim Pijls, Ira Pohl, Martha Pollack, David Poole, Bruce Porter, Malcolm Pradhan,\\nBill Pringle, Lorraine Prior, Greg Provan, William Rapaport, Deepak Ravichandran, Ioannis\\nRefanidis, Philip Resnik, Francesca Rossi, Sam Roweis, Richard Russell, Jonathan Schaeffer,\\nRichard Scherl, Heinrich Schuetze, Lars Schuster, Bart Selman, Soheil Shams, Stuart Shapiro, Jude\\nShavlik, Yoram Singer, Satinder Singh, Daniel Sleator, David Smith, Bryan So, Robert Sproull, Lynn\\nStein, Larry Stephens, Andreas Stolcke, Paul Stradling, Devika Subramanian, Marek Suchenek, Rich\\nSutton, Jonathan Tash, Austin Tate, Bas Terwijn, Olivier Teytaud, Michael Thielscher, William\\nThompson, Sebastian Thrun, Eric Tiedemann, Mark Torrance, Randall Upham, Paul Utgoff, Peter van\\nBeek, Hal Varian, Paulina Varshavskaya, Sunil Vemuri, Vandi Verma, Ubbo Visser, Jim Waldo,\\nToby Walsh, Bonnie Webber, Dan Weld, Michael Wellman, Kamin Whitehouse, Michael Dean\\nWhite, Brian Williams, David Wolfe, Jason Wolfe, Bill Woods, Alden Wright, Jay Yagnik, Mark\\nYasuda, Richard Yen, Eliezer Yudkowsky, Weixiong Zhang, Ming Zhao, Shlomo Zilberstein e nossos\\nestimados colegas os Revisores Anônimos.\\n*\\n Conteúdo em inglês.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 9}),\n",
       " Document(page_content='Sobre os Autores\\nSt\\nuart Russell\\n nasceu em 1962 em Portsmouth, Inglaterra. Bacharelou-se com louvor em Física pela\\nUniversidade de Oxford em 1982, e doutorou-se em Ciência da Computação por Stanford em 1986.\\nEntrou para o corpo docente da Universidade da Califórnia, em Berkeley, onde leciona Ciência da\\nComputação, dirige o Centro para Sistemas Inteligentes e ocupa a cátedra Smith-Zadeh de\\nEngenharia. Em1990, recebeu o Prêmio Presidencial ao Jovem Cientista (\\nPresidential Young\\nInvestigatorAward\\n), concedido pela National Science Foundation, e, em 1995, foi covencedor do\\nPrêmio de Computação e Pensamento (\\nComputers and Thought Award\\n).\\nFoi professor da cadeira Miller em 1996 na Universidade de Califórnia, e indicado para a bolsa\\ndocente \\nChancellor\\n. Em 1998, foi o palestrante da Conferência Forsythe Memorial, na Universidade\\nde Stanford. É membro efetivo da Associação Americana de Inteligência Artificial e ex-integrante do\\nConselho Executivo da entidade. Já publicou mais de cem artigos sobre uma ampla gama de tópicos\\nligados à inteligência artificial. Entre seus outros livros, incluem-se: \\nThe Use of Knowledge in\\nAnalogy and Induction\\n e (com Eric Wefald) \\nDo the Right Thing: Studies in Limited Rationality\\n.\\nPeter Norvig\\n atualmente é diretor de Pesquisa na Google, Inc. e foi o diretor responsável pelos\\nalgoritmos de busca do núcleo da Web de 2002 até 2005.\\nÉ membro efetivo da Associação Americana de Inteligência Artificial e da Associação para\\nMáquinas de Computação. Anteriormente, foi chefe da Divisão de Ciências Computacionais no Ames\\nResearch Center, da NASA, onde supervisionou a pesquisa e o desenvolvimento da robótica e da\\ninteligência artificial para a agência espacial americana. Antes disso, foi cientista-chefe da Junglee,\\nonde ajudou a desenvolver um dos primeiros serviços de acesso a informações pela Internet.\\nBacharelou-se em matemática aplicada pela Brown University e doutorou-se em Ciência da\\nComputação pela Universidade de Califórnia, em Berkeley. Ele recebeu os prêmios Distinguished\\nAlumni e Engineering Innovation de Berkeley e a Exceptional Achievement Medal da NASA. Tem\\natuado como professor da Universidade do Sul da Califórnia e pesquisador em Berkeley. Seus outros\\nlivros são: \\nParadigms of AI Programming: Case Studies in Common Lisp, Verbmobil: A\\nTranslation System for Face-to-Face Dialog\\n, e \\nIntelligent Help Systems for UNIX\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 10}),\n",
       " Document(page_content='P\\nNota dos revisores técnicos da edição brasileira\\narticipar do projeto editorial de um livro importante como \\nInteligência artificial\\n, de Russel e\\nNorvig, é para nós motivo de orgulho e satisfação, considerando o impacto e a importância dessa\\nobra no ensino de inteligência artificial.\\nA revisão técnica da tradução é atividade complexa e de grande responsabilidade, pois exige a\\nescolha de termos para a tradução de conceitos técnicos, de forma a facilitar seu entendimento e, ao\\nmesmo tempo, preservar sua vinculação com a forma original, simplificando com isso o acesso do\\nleitor às fontes de conhecimento que permitam prosseguimento de seus estudos.\\nPara garantir a qualidade da revisão técnica, cada um dos revisores se concentrou nos capítulos\\nrelacionados às suas atividades de pesquisa. Assim, a professora Liliane Nunes de Barros revisou os\\ncapítulos 2 a 6, 10, 11, 17 e 21; a Professora Renata Wassermann revisou os capítulos 7 a 9, 12, 26 e\\n27; e o Professor Flávio Soares Corrêa da Silva revisou os capítulos 13 a 16, 18 a 20, 22 a 25 e os\\nApêndices.\\nAgradecemos à Elsevier — especialmente à Luciana Félix Macedo e Brunna Prado — pela\\noportunidade de participar deste projeto, e à Regina Célia Simille de Macedo pela excelente\\ntradução.\\nFlávio Soares Corrêa da Silva – Professor associado\\nLiliane Nunes de Barros – Professora associada\\nRenata Wassermann – Professora associada\\nDepartamento de Ciências da Computação – IME – USP', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 11}),\n",
       " Document(page_content='Sumário\\nCapa\\nFolha de Rosto\\nCréditos\\nEpigraph\\nPrefácio\\nSobre os Autores\\nNota dos revisores técnicos da edição brasileira\\nPARTE I\\nInteligência artif\\nicial\\n1. Introdução\\n1.1 O que é IA?\\n1.2 Os fundamentos da inteligência artificial\\n1.3 História da inteligência artificial\\n1.4 O estado da arte\\n1.5 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n2. Agentes inteligentes\\n2.1 Agentes e ambientes\\n2.2 Bom comportamento: o conceito de racionalidade\\n2.3 A natureza dos ambientes\\n2.4 A estrutura de agentes\\n2.5 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\nPARTE II', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 12}),\n",
       " Document(page_content='Resolução de problemas\\n3. Resolução de problemas por meio de busca\\n3.1 Agentes de resolução de problemas\\n3.2 Exemplos de problemas\\n3.3 Em busca de soluções\\n3.4 Estratégias de busca sem informação\\n3.5 Estratégia de busca informada (heurística)\\n3.6 Funções heurísticas\\n3.7 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n4. Além da busca clássica\\n4.1 Algoritmos de busca local e problemas de otimização\\n4.2 Busca local em espaços contínuos\\n4.3 Busca com ações não determinísticas\\n4.4 Pesquisando com observações parciais\\n4.5 Agentes de busca on-line em ambientes desconhecidos\\n4.6 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n5. Busca competitiva\\n5.1 Jogos\\n5.2 Decisões ótimas em jogos\\n5.3 Poda alfa-beta\\n5.4 Decisões imperfeitas em tempo real\\n5.5 Jogos estocásticos\\n5.6 Jogos parcialmente observáveis\\n5.7 Programas de jogos de última geração\\n5.8 Abordagens alternativas\\n5.9 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n6. Problemas de satisfação de restrições', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 13}),\n",
       " Document(page_content='6.1 Definição de problemas de satisfação de restrições\\n6.2 Propagação de restrição: inferência em PSRs\\n6.3 Busca com retrocesso para PSRs\\n6.4 Busca local para PSRs\\n6.5 A estrutura de problemas\\n6.6 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\nPARTE III\\nConhecimento, pensamento e planejamento\\n7. Agentes lógicos\\n7.1 Agentes baseados em conhecimento\\n7.2 O mundo de wumpus\\n7.3 Lógica\\n7.4 Lógica proposicional: uma lógica muito simples\\n7.5 Prova de teoremas proposicionais\\n7.6 Verificação de modelos proposicionais eficientes\\n7.7 Agentes baseados em lógica proposicional\\n7.8 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n8. Lógica de primeira ordem\\n8.1 Uma revisão da representação\\n8.2 Sintaxe e semântica da lógica de primeira ordem\\n8.3 Utilização da lógica de primeira ordem\\n8.4 Engenharia de conhecimento em lógica de primeira ordem\\n8.5 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n9. Inferência em lógica de primeira ordem\\n9.1 Inferência proposicional \\nversus\\n inferência de primeira ordem\\n9.2 Unificação e elevação\\n9.3 Encadeamento para a frente', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 14}),\n",
       " Document(page_content='9.4 Encadeamento para trás\\n9.5 Resolução\\n9.6 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n10. Planejamento clássico\\n10.1 Definição do planejamento clássico\\n10.2 Algoritmos de planejamento como busca em espaço de estados\\n10.3 Grafos de planejamento\\n10.4 Outras abordagens clássicas de planejamento\\n10.5 Análise das abordagens de planejamento\\n10.6 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n11. Planejamento e ação no mundo real\\n11.1 Tempo, escalonamentos e recursos\\n11.2 Planejamento hierárquico\\n11.3 Planejamento e ação em domínios não determinísticos\\n11.4 Planejamento multiagente\\n11.5 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n12. Representação de conhecimento\\n12.1 Engenharia ontológica\\n12.2 Categorias e objetos\\n12.3 Eventos\\n12.4 Eventos mentais e objetos mentais\\n12.5 Sistemas de raciocínio para categorias\\n12.6 Raciocínio com informações default\\n12.7 O mundo de compras da internet\\n12.8 Resumo\\nNotas bibliográficas e históricas\\nExercícios', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 15}),\n",
       " Document(page_content='PARTE IV\\nConhecimento incerto e pensamento\\n13. Quantificando a incerteza\\n13.1 Como agir em meio à incerteza\\n13.2 Notação básica de probabilidade\\n13.3 Inferência com o uso de distribuições conjuntas totais\\n13.4 Independência\\n13.5 A regra de Bayes e seu uso\\n13.6 De volta ao mundo de wumpus\\n13.7 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n14. Raciocínio probabilístico\\n14.1 Representação do conhecimento em um domínio incerto\\n14.2 A semântica das redes bayesianas\\n14.3 Representação eficiente de distribuições condicionais\\n14.4 Inferência exata em redes bayesianas\\n14.5 Inferência aproximada em redes bayesianas\\n14.6 Modelos de probabilidade relacional e de primeira ordem\\n14.7 Outras abordagens para raciocínio incerto\\n14.8 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n15. Raciocínio probabilístico temporal\\n15.1 Tempo e incerteza\\n15.2 Inferência em modelos temporais\\n15.3 Modelos ocultos de Markov\\n15.4 Filtros de Kalman\\n15.5 Redes bayesianas dinâmicas\\n15.6 Manutenção e controle de muitos objetos\\n15.7 Resumo\\nNotas bibliográficas e históricas\\nExercícios', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 16}),\n",
       " Document(page_content='16. Tomada de decisões simples\\n16.1 Combinação de crenças e desejos sob incerteza\\n16.2 A base da teoria da utilidade\\n16.3 Funções utilidade\\n16.4 Funções utilidade multiatributo\\n16.5 Redes de decisão\\n16.6 O valor da informação\\n16.7 Sistemas especialistas de teoria da decisão\\n16.8 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n17. Tomada de decisões complexas\\n17.1 Problemas de decisão sequencial\\n17.2 Iteração de valor\\n17.3 Iteração de política\\n17.4 MDPs parcialmente observáveis\\n17.5 Decisões com vários agentes: teoria dos jogos\\n17.6 Projeto de mecanismos\\n17.7 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\nPARTE V\\nAprendizagem\\n18. Aprendendo a partir de exemplos\\n18.1 Formas de aprendizagem\\n18.2 Aprendizagem supervisionada\\n18.3 Aprendizagem em árvores de decisão\\n18.4 Avaliação e escolha da melhor hipótese\\n18.5 Teoria da aprendizagem\\n18.6 Regressão e classificação com modelos lineares\\n18.7 Redes neurais artificiais\\n18.8 Modelos não paramétricos\\n18.9 Máquinas de vetores de suporte', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 17}),\n",
       " Document(page_content='18.10 Aprendizagem por agrupamento\\n18.11 Aprendizagem de máquina na prática\\n18.12 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n19. Conhecimento em aprendizagem\\n19.1 Uma formulação lógica da aprendizagem\\n19.2 Conhecimento em aprendizagem\\n19.3 Aprendizagem baseada na explanação\\n19.4 Aprendizagem com o uso de informações de relevância\\n19.5 Programação em lógica indutiva\\n19.6 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n20. Aprendizagem de modelos probabilísticos\\n20.1 Aprendizagem estatística\\n20.2 Aprendizagem com dados completos\\n20.3 Aprendizagem com variáveis ocultas: o algoritmo EM\\n20.4 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n21. Aprendizagem por reforço\\n21.1 Introdução\\n21.2 Aprendizagem por reforço passiva\\n21.3 Aprendizagem por reforço ativa\\n21.4 Generalização da aprendizagem por reforço\\n21.5 Busca de políticas\\n21.6 Aplicações de aprendizagem por reforço\\n21.7 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\nPARTE VI\\nComunicação, percepção e ação', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 18}),\n",
       " Document(page_content='22. Processamento de linguagem natural\\n22.1 Modelos de linguagem\\n22.2 Classificação de texto\\n22.3 Recuperação de informação\\n22.4 Extração de informação\\n22.5 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n23. Linguagem natural para comunicação\\n23.1 Gramática com estrutura frasal\\n23.2 Análise sintática\\n23.3 Gramáticas aumentadas e interpretação semântica\\n23.4 Tradução automática\\n23.5 Reconhecimento de voz\\n23.6 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n24. Percepção\\n24.1 Formação de imagens\\n24.2 Operações iniciais de processamento de imagens\\n24.3 Reconhecimento de objeto por aparência\\n24.4 Reconstrução do mundo em 3-D\\n24.5 Reconhecimento de objetos a partir de informação estrutural\\n24.6 Utilização da visão\\n24.7 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n25. Robótica\\n25.1 Introdução\\n25.2 Hardware de robôs\\n25.3 Percepção robótica\\n25.4 Planejamento do movimento\\n25.5 Planejamento de movimentos incertos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 19}),\n",
       " Document(page_content='25.6 Movimento\\n25.7 Arquiteturas de software para robótica\\n25.8 Domínios de aplicação\\n25.9 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\nPARTE VII\\nConclusão\\n26. Fundamentos filosóficos\\n26.1 IA fraca: as máquinas podem agir com inteligência?\\n26.2 IA forte: as máquinas podem realmente pensar?\\n26.3 A ética e os riscos de desenvolver a inteligência artificial\\n26.4 Resumo\\nNotas bibliográficas e históricas\\nExercícios\\n27. IA, presente e futuro\\n27.1 Componentes de agentes\\n27.2 Arquiteturas de agentes\\n27.3 Estamos indo na direção correta?\\n27.4 E se a IA tiver sucesso?\\nA. Fundamentos matemáticos\\nA.1 Análise de complexidade e notação o( )\\nA.2 Vetores, matrizes e álgebra linear\\nA.3 Distribuições de probabilidade\\nNotas bibliográficas e históricas\\nB. Notas sobre linguagens e algoritmos\\nB.1 Definição de linguagens com a forma de Backus−Naur (BNF)\\nB.2 Descrição de algoritmos com pseudocódigo\\nB.3 Ajuda on-line\\nBibliografia', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 20}),\n",
       " Document(page_content='PARTE I\\nInteligência artificial', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 21}),\n",
       " Document(page_content='D\\nCAPÍTULO\\n \\n1\\nIntrodução\\nEm que tentamos explicar por que consideramos a inteligência artificial um\\nassunto digno de estudo e em que procuramos definir exatamente o que é a\\ninteligência artificial, pois essa definição é importante antes de iniciarmos\\nnosso estudo.\\nenominamos nossa espécie \\nHomo sapiens\\n — homem sábio — porque nossa \\ninteligência\\n é tão\\nimportante para nós. Durante milhares de anos, procuramos entender \\ncomo pensamos\\n, isto é,\\ncomo um mero punhado de matéria pode perceber, compreender, prever e manipular um mundo\\nmuito maior e mais complicado que ela própria. O campo da \\ninteligência artificial\\n, ou IA, vai ainda\\nmais além: ele tenta não apenas compreender, mas também \\nconstruir\\n entidades inteligentes.\\nA IA é um dos campos mais recentes em ciências e engenharia. O trabalho começou logo após a\\nSegunda Guerra Mundial, e o próprio nome foi cunhado em 1956. Juntamente com a biologia\\nmolecular, a IA é citada regularmente como “o campo em que eu mais gostaria de estar” por\\ncientistas de outras disciplinas. Um aluno de física pode argumentar, com boa dose de razão, que\\ntodas as boas ideias já foram desenvolvidas por Galileu, Newton, Einstein e o resto. IA, por outro\\nlado, ainda tem espaço para vários Einsteins e Edisons em tempo integral.\\nAtualmente, a IA abrange uma enorme variedade de subcampos, do geral (aprendizagem e\\npercepção) até tarefas específicas, como jogos de xadrez, demonstração de teoremas matemáticos,\\ncriação de poesia, direção de um carro em estrada movimentada e diagnóstico de doenças. A IA é\\nrelevante para qualquer tarefa intelectual; é verdadeiramente um campo universal.\\n1.1 O QUE É IA?\\nAfirmamos que a IA é interessante, mas não dissemos o que ela \\né\\n. Na \\nFigura 1.1\\n podemos\\nvisualizar oito definições de IA, dispostas ao longo de duas dimensões. Em linhas gerais, as que\\nestão na parte superior da tabela se relacionam a \\nprocessos de pensamento\\n e \\nraciocínio\\n, enquanto as\\ndefinições da parte inferior se referem ao \\ncomportamento\\n. As definições do lado esquerdo medem o\\nsucesso em termos de fidelidade ao desempenho \\nhumano\\n, enquanto as definições do lado direito\\nmedem o sucesso comparando-o a um conceito \\nideal\\n de inteligência, chamado de \\nracionalidade\\n. Um\\nsistema é racional se “faz a coisa certa”, dado o que ele sabe.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 23}),\n",
       " Document(page_content='Historicamente, todas as quatro estratégias para o estudo da IA têm sido seguidas, cada uma delas\\npor pessoas diferentes com métodos diferentes. Uma abordagem centrada nos seres humanos deve ser\\nem parte uma ciência empírica, envolvendo hipóteses e confirmação experimental. Uma abordagem\\nracionalista\\n1\\n envolve uma combinação de matemática e engenharia. Cada grupo tem ao mesmo tempo\\ndesacreditado e ajudado o outro. Vamos examinar as quatro abordagens com mais detalhes.\\nPensando como um humano\\nPensando racionalmente\\n“O novo e interessante esforço para fazer os computadores\\npensarem (...) \\nmáquinas com mentes\\n, no sentido total e\\nliteral.”\\n(Haugeland, 1985)\\n“[Automatização de] atividades que associamos ao\\npensamento humano, atividades como a tomada de decisões,\\na resolução de problemas, o aprendizado...” (Bellman,\\n1978)\\n“O estudo das faculdades mentais\\npelo uso de modelos\\ncomputacionais.” (Charniak e\\nMcDermott, 1985)\\n“O estudo das computações que\\ntornam possível perceber,\\nraciocinar e agir.” (Winston, 1992)\\nAgindo como seres humanos\\nAgindo racionalmente\\n“A arte de criar máquinas que executam funções que exigem\\ninteligência quando executadas por pessoas.” (Kurzweil,\\n1990)\\n“O estudo de como os computadores podem fazer tarefas\\nque hoje são melhor desempenhadas pelas pessoas.” (Rich\\nand Knight, 1991)\\n“Inteligência Computacional é o\\nestudo do projeto de agentes\\ninteligentes.” (Poole \\net al\\n., 1998)\\n“AI... está relacionada a um\\ndesempenho inteligente de\\nartefatos.” (Nilsson, 1998)\\nFigura 1.1\\n Algumas definições de inteligência artificial, organizadas em quatro categorias.\\n1.1.1 Agindo de forma humana: a abordagem do teste de Turing\\nO \\nteste de Turing\\n, proposto por Alan Turing (1950), foi projetado para fornecer uma definição\\noperacional satisfatória de inteligência. O computador passará no teste se um interrogador humano,\\ndepois de propor algumas perguntas por escrito, não conseguir descobrir se as respostas escritas vêm\\nde uma pessoa ou de um computador. O Capítulo 26 discute os detalhes do teste e também se um\\ncomputador seria de fato inteligente se passasse nele. Por enquanto, observamos que programar um\\ncomputador para passar no teste exige muito trabalho. O computador precisaria ter as seguintes\\ncapacidades:\\n•  \\nprocessamento de linguagem natural\\n para permitir que ele se comunique com sucesso em um\\nidioma natural;\\n•  \\nrepresentação de conhecimento\\n para armazenar o que sabe ou ouve;\\n•  \\nraciocínio automatizado\\n para usar as informações armazenadas com a finalidade de responder a\\nperguntas e tirar novas conclusões;\\n•  \\naprendizado de máquina\\n para se adaptar a novas circunstâncias e para detectar e extrapolar', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 24}),\n",
       " Document(page_content='padrões.\\nO teste de Turing evitou deliberadamente a interação física direta entre o interrogador e o\\ncomputador porque a simulação \\nfísica\\n de uma pessoa é desnecessária para a inteligência. Entretanto,\\no chamado \\nteste de Turing total\\n inclui um sinal de vídeo, de forma que o interrogador possa testar\\nas habilidades de percepção do indivíduo, além de oferecer ao interrogador a oportunidade de\\nrepassar objetos físicos “pela janelinha”. Para ser aprovado no teste de Turing total, o computador\\nprecisará de:\\n•  \\nvisão computacional\\n para perceber objetos e\\n•  \\nrobótica\\n para manipular objetos e movimentar-se.\\nEssas seis disciplinas compõem a maior parte da IA, e Turing merece crédito por projetar um teste\\nque permanece relevante depois de 60 anos. Ainda assim, os pesquisadores da IA têm dedicado\\npouco esforço à aprovação no teste de Turing, acreditando que seja mais importante estudar os\\nprincípios básicos da inteligência do que reproduzir um exemplar. O desafio do “voo artificial” teve\\nsucesso quando os irmãos Wright e outros pesquisadores pararam de imitar os pássaros e começaram\\na usar túneis de vento e aprender sobre aerodinâmia. Os textos de engenharia aeronáutica não\\ndefinem como objetivo de seu campo criar “máquinas que voem exatamente como pombos a ponto de\\npoderem enganar até mesmo outros pombos”.\\n1.1.2 Pensando de forma humana: a estratégia de modelagem cognitiva\\nSe pretendemos dizer que dado programa pensa como um ser humano, temos de ter alguma forma\\nde determinar como os seres humanos pensam. Precisamos \\npenetrar\\n nos componentes reais da mente\\nhumana. Existem três maneiras de fazer isso: através da introspecção — procurando captar nossos\\npróprios pensamentos à medida que eles se desenvolvem — através de experimentos psicológicos —\\nobservando uma pessoa em ação; e através de imagens cerebrais, observando o cérebro em ação.\\nDepois que tivermos uma teoria da mente suficientemente precisa, será possível expressar a teoria\\ncomo um programa de computador. Se os comportamentos de entrada/saída e sincronização do\\nprograma coincidirem com os comportamentos humanos correspondentes, isso será a evidência de\\nque alguns dos mecanismos do programa também podem estar operando nos seres humanos. Por\\nexemplo, Allen Newell e Herbert Simon, que desenvolveram o GPS, o “Resolvedor Geral de\\nProblemas” (do inglês “General Problem Solver”) (Newell e Simon, 1961), não se contentaram em\\nfazer seu programa resolver problemas de modo correto. Eles estavam mais preocupados em\\ncomparar os passos de suas etapas de raciocínio aos passos de indivíduos humanos resolvendo os\\nmesmos problemas. O campo interdisciplinar da \\nciência cognitiva\\n reúne modelos computacionais da\\nIA e técnicas experimentais da psicologia para tentar construir teorias precisas e verificáveis a\\nrespeito dos processos de funcionamento da mente humana.\\nA ciência cognitiva é um campo fascinante por si só, merecedora de diversos livros e de pelo\\nmenos uma enciclopédia (Wilson e Keil, 1999). Ocasionalmente, apresentaremos comentários a\\nrespeito de semelhanças ou diferenças entre técnicas de IA e a cognição humana. Porém, a ciência', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 25}),\n",
       " Document(page_content='cognitiva de verdade se baseia necessariamente na investigação experimental de seres humanos ou\\nanimais. Deixaremos esse assunto para outros livros à medida que supomos que o leitor tenha acesso\\nsomente a um computador para realizar experimentação.\\nNos primórdios da IA, frequentemente havia confusão entre as abordagens: um autor argumentava\\nque um algoritmo funcionava bem em uma tarefa e que, \\nportanto\\n, era um bom modelo de desempenho\\nhumano ou vice-versa. Os autores modernos separam os dois tipos de afirmações; essa distinção\\npermitiu que tanto a IA quanto a ciência cognitiva se desenvolvessem com maior rapidez. Os dois\\ncampos continuam a fertilizar um ao outro, principalmente na visão computacional, que incorpora\\nevidências neurofisiológicas em modelos computacionais.\\n1.1.3 Pensando racionalmente: a abordagem das “leis do pensamento”\\nO filósofo grego Aristóteles foi um dos primeiros a tentar codificar o “pensamento correto”, isto é,\\nos processos de raciocínio irrefutáveis. Seus \\nsilogismos\\n forneceram padrões para estruturas de\\nargumentos que sempre resultavam em conclusões corretas ao receberem premissas corretas — por\\nexemplo, “Sócrates é um homem; todos os homens são mortais; então, Sócrates é mortal”. Essas leis\\ndo pensamento deveriam governar a operação da mente; seu estudo deu início ao campo chamado\\nlógica\\n.\\nOs lógicos do século XIX desenvolveram uma notação precisa para declarações sobre todos os\\ntipos de coisas no mundo e sobre as relações entre elas (compare isso com a notação aritmética\\nbásica, que fornece apenas declarações a respeito de números). Por volta de 1965, existiam\\nprogramas que, em princípio, podiam resolver \\nqualquer\\n problema solucionável descrito em notação\\nlógica (contudo, se não houver solução, o programa poderá entrar num laço infinito). A chamada\\ntradição \\nlogicista\\n dentro da inteligência artificial espera desenvolver tais programas para criar\\nsistemas inteligentes.\\nEssa abordagem enfrenta dois obstáculos principais. Primeiro, não é fácil enunciar o conhecimento\\ninformal nos termos formais exigidos pela notação lógica, em particular quando o conhecimento é\\nmenos de 100% certo. Em segundo lugar, há uma grande diferença entre ser capaz de resolver um\\nproblema “em princípio” e resolvê-lo na prática. Até mesmo problemas com apenas algumas\\ncentenas de fatos podem esgotar os recursos computacionais de qualquer computador, a menos que\\nele tenha alguma orientação sobre as etapas de raciocínio que deve tentar primeiro. Embora ambos\\nos obstáculos se apliquem a \\nqualquer\\n tentativa de construir sistemas de raciocínio computacional,\\neles surgiram primeiro na tradição logicista.\\n1.1.4 Agindo racionalmente: a abordagem de agente racional\\nUm \\nagente\\n é simplesmente algo que age (a palavra \\nagente\\n vem do latino \\nagere\\n, que significa\\nfazer). Certamente todos os programas de computador realizam alguma coisa, mas espera-se que um\\nagente computacional faça mais: opere sob controle autônomo, perceba seu ambiente, persista por um\\nperíodo de tempo prolongado, adapte-se a mudanças e seja capaz de criar e perseguir metas. Um', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 26}),\n",
       " Document(page_content='agente racional\\n é aquele que age para alcançar o melhor resultado ou, quando há incerteza, o melhor\\nresultado esperado.\\nNa abordagem de “leis do pensamento” para IA, foi dada ênfase a inferências corretas. Às vezes, a\\nrealização de inferências corretas é uma \\nparte\\n daquilo que caracteriza um agente racional porque\\numa das formas de agir racionalmente é raciocinar de modo lógico até a conclusão de que dada ação\\nalcançará as metas pretendidas e, depois, agir de acordo com essa conclusão. Por outro lado, a\\ninferência correta não representa \\ntoda\\n a racionalidade; em algumas situações, não existe nenhuma\\nação comprovadamente correta a realizar, mas mesmo assim algo tem de ser feito. Também existem\\nmodos de agir racionalmente que não se pode dizer que envolvem inferências. Por exemplo, afastar-\\nse de um fogão quente é um ato reflexo, em geral mais bem-sucedido que uma ação mais lenta\\nexecutada após cuidadosa deliberação.\\nTodas as habilidades necessárias à realização do teste de Turing também permitem que o agente\\nhaja racionalmente. Representação do conhecimento e raciocínio permitem que os agentes alcancem\\nboas decisões. Precisamos ter a capacidade de gerar sentenças compreensíveis em linguagem natural\\nporque enunciar essas sentenças nos ajuda a participar de uma sociedade complexa. Precisamos\\naprender não apenas por erudição, mas também para melhorar nossa habilidade de gerar\\ncomportamento efetivo.\\n A abordagem do agente racional tem duas vantagens sobre as outras abordagens. Primeiro, ela é\\nmais geral que a abordagem de “leis do pensamento” porque a inferência correta é apenas um dentre\\nvários mecanismos possíveis para se alcançar a racionalidade. Em segundo lugar, ela é mais\\nacessível ao desenvolvimento científico do que as estratégias baseadas no comportamento ou no\\npensamento humano. O padrão de racionalidade é matematicamente bem definido e completamente\\ngeral, podendo ser “desempacotado” para gerar modelos de agente que comprovadamente irão\\natingi-lo. Por outro lado, o comportamento humano está bem adaptado a um ambiente específico e é\\ndefinido como a soma de tudo o que os humanos fazem. \\nPortanto\\n, \\neste livro se concentrará nos\\nprincípios gerais de agentes racionais e nos componentes para construí\\n-\\nlos\\n. Veremos que, apesar\\nda aparente simplicidade com que o problema pode ser enunciado, surge uma enorme variedade de\\nquestões quando tentamos resolvê-lo. O Capítulo 2 descreve algumas dessas questões com mais\\ndetalhes.\\nDevemos ter em mente um ponto importante: logo veremos que alcançar a racionalidade perfeita\\n— sempre fazer a coisa certa — não é algo viável em ambientes complicados. As demandas\\ncomputacionais são demasiado elevadas. Porém, na maior parte do livro, adotaremos a hipótese de\\ntrabalho de que a racionalidade perfeita é um bom ponto de partida para a análise. Ela simplifica o\\nproblema e fornece a configuração apropriada para a maioria do material básico na área. Os\\nCapítulos 5 e 17 lidam explicitamente com a questão da \\nracionalidade limitada\\n — agir de forma\\napropriada quando não existe tempo suficiente para realizar todas as computações que gostaríamos\\nde fazer.\\n1.2 OS FUNDAMENTOS DA INTELIGÊNCIA ARTIFICIAL\\nNesta seção, apresentaremos um breve histórico das disciplinas que contribuíram com ideias,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 27}),\n",
       " Document(page_content='pontos de vista e técnicas para a IA. Como qualquer histórico, este foi obrigado a se concentrar em\\num pequeno número de pessoas, eventos e ideias, e ignorar outros que também eram importantes.\\nOrganizamos o histórico em torno de uma série de perguntas. Certamente, não desejaríamos dar a\\nimpressão de que essas questões são as únicas de que as disciplinas tratam ou que todas as\\ndisciplinas estejam se encaminhando para a IA como sua realização final.\\n1.2.1 Filosofia\\n•  Regras formais podem ser usadas para obter conclusões válidas?\\n•  Como a mente (o intelecto) se desenvolve a partir de um cérebro físico?\\n•  De onde vem o conhecimento?\\n•  Como o conhecimento conduz à ação?\\nAristóteles (384-322 a.C.), cujo busto aparece na capa deste livro, foi o primeiro a formular um\\nconjunto preciso de leis que governam a parte racional da mente. Ele desenvolveu um sistema\\ninformal de silogismos para raciocínio apropriado que, em princípio, permitiam gerar conclusões\\nmecanicamente, dadas as premissas iniciais. Muito mais tarde, Ramon Lull (1315) apresentou a ideia\\nde que o raciocínio útil poderia na realidade ser conduzido por um artefato mecânico. Thomas\\nHobbes (1588-1679) propôs que o raciocínio era semelhante à computação numérica, ou seja, que\\n“efetuamos somas e subtrações em nossos pensamentos silenciosos”. A automação da própria\\ncomputação já estava bem próxima; por volta de 1500, Leonardo da Vinci (1452-1519) projetou, mas\\nnão construiu, uma calculadora mecânica; reconstruções recentes mostraram que o projeto era\\nfuncional. A primeira máquina de calcular conhecida foi construída em torno de 1623 pelo cientista\\nalemão Wilhelm Schickard (1592-1635), embora a Pascaline, construída em 1642 por Blaise Pascal\\n(1623-1662), seja mais famosa. Pascal escreveu que “a máquina aritmética produz efeitos que\\nparecem mais próximos ao pensamento que todas as ações dos animais”. Gottfried Wilhelm Leibnitz\\n(1646-1716) construiu um dispositivo mecânico destinado a efetuar operações sobre conceitos, e não\\nsobre números, mas seu escopo era bastante limitado. Leibnitz superou Pascal através da construção\\nde uma calculadora que podia somar, subtrair, multiplicar e extrair raízes, enquanto a Pascaline só\\npodia adicionar e subtrair. Alguns especularam que as máquinas não poderiam fazer apenas cálculos,\\nmas realmente ser capazes de pensar e agir por conta própria. Em seu livro de 1651, \\nLeviatã\\n,\\nThomas Hobbes sugeriu a ideia de um “animal artificial”, argumentando: “Pois o que é o coração,\\nsenão uma mola; e os nervos, senão tantas cordas; e as articulações, senão tantas rodas.”\\nDizer que a mente opera, pelo menos em parte, de acordo com regras lógicas e construir sistemas\\nfísicos que emulam algumas dessas regras é uma coisa; outra é dizer que a mente em si \\né\\n esse sistema\\nfísico. René Descartes (1596-1650) apresentou a primeira discussão clara da distinção entre mente e\\nmatéria, e dos problemas que surgem dessa distinção. Um dos problemas relacionados com uma\\nconcepção puramente física da mente é o fato de que ela parece deixar pouco espaço para o livre-\\narbítrio: se a mente é governada inteiramente por leis físicas, então ela não tem mais livre-arbítrio\\nque uma pedra que “decide” cair em direção ao centro da Terra. Descartes advogava fortemente a\\nfavor do poder da razão em entender o mundo, uma filosofia hoje chamada de \\nracionalismo\\n, e que\\ntinha Aristóteles e Leibnitz como membros. Descartes também era um proponente do \\ndualismo\\n. Ele', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 28}),\n",
       " Document(page_content='sustentava que havia uma parte da mente humana (ou alma, ou espírito) que transcende a natureza,\\nisenta das leis físicas. Por outro lado, os animais não possuem essa qualidade dual; eles podiam ser\\ntratados como máquinas. Uma alternativa para o dualismo é o \\nmaterialismo\\n. O materialismo sustenta\\nque a operação do cérebro de acordo com as leis da física \\nconstitui\\n a mente. O livre-arbítrio é\\nsimplesmente o modo como a percepção das escolhas disponíveis se mostra para a entidade que\\nescolhe.\\nDada uma mente física que manipula o conhecimento, o próximo problema é estabelecer a origem\\ndo conhecimento. O movimento chamado \\nempirismo\\n, iniciado a partir da obra de Francis Bacon\\n(1561-1626), \\nNovum Organum\\n,\\n2\\n se caracterizou por uma frase de John Locke (1632-1704): “Não há\\nnada na compreensão que não estivesse primeiro nos sentidos.” A obra de David Hume (1711-1776),\\nA Treatise of Human Nature\\n (Hume, 1739) propôs aquilo que se conhece hoje como o princípio de\\nindução\\n: as regras gerais são adquiridas pela exposição a associações repetidas entre seus\\nelementos. Com base no trabalho de Ludwig Wittgenstein (1889-1951) e Bertrand Russell (1872-\\n1970), o famoso Círculo de Viena, liderado por Rudolf Carnap (1891-1970), desenvolveu a doutrina\\ndo \\npositivismo lógico\\n. Essa doutrina sustenta que todo conhecimento pode ser caracterizado por\\nteorias lógicas conectadas, em última análise, a \\nsentenças de observação\\n que correspondem a\\nentradas sensoriais; desse modo, o positivismo lógico combina o racionalismo e o empirismo.\\n3\\n A\\nteoria da confirmação\\n de Carnap e Carl Hempel (1905-1997) tentava compreender a aquisição do\\nconhecimento através da experiência. O livro de Carnap, \\nThe Logical Structure of the World\\n (1928),\\ndefiniu um procedimento computacional explícito para extrair conhecimento de experiências\\nelementares. Provavelmente, foi a primeira teoria da mente como um processo computacional.\\nO último elemento no quadro filosófico da mente é a conexão entre conhecimento e ação. Essa\\nquestão é vital para a IA porque a inteligência exige ação, bem como raciocínio. Além disso, apenas\\npela compreensão de como as ações são justificadas podemos compreender como construir um\\nagente cujas ações sejam justificáveis (ou racionais). Aristóteles argumentava (no \\nDe Motu\\nAnimalium\\n) que as ações se justificam por uma conexão lógica entre metas e conhecimento do\\nresultado da ação (a última parte deste extrato também aparece na capa deste livro, no original em\\ngrego):\\nPorém, como explicar que o pensamento às vezes esteja acompanhado pela ação e às vezes não, às\\nvezes esteja acompanhado pelo movimento e outras vezes não? Aparentemente, acontece quase o\\nmesmo no caso do raciocínio e na realização de inferências sobre objetos imutáveis. Contudo,\\nnesse caso o fim é uma proposição especulativa (…) enquanto aqui a conclusão que resulta das\\nduas premissas é uma ação. (…) Preciso me cobrir; um casaco é uma coberta. Preciso de um\\ncasaco. O que eu preciso, tenho de fazer; preciso de um casaco. Tenho de fazer um casaco. E a\\nconclusão, “tenho de fazer um casaco”, é uma ação.\\nNa obra \\nÉtica a Nicômaco\\n (Livro III. 3, 1112b), Aristóteles desenvolve esse tópico um pouco\\nmais, sugerindo um algoritmo:\\nNão deliberamos sobre os fins, mas sobre os meios. Um médico não delibera sobre se deve ou não\\ncurar nem um orador sobre se deve ou não persuadir, (…) Eles dão a finalidade por estabelecida e\\nprocuram saber a maneira de alcançá-la; se lhes parece poder ser alcançada por vários meios,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 29}),\n",
       " Document(page_content='procuram saber o mais fácil e o mais eficaz; e se há apenas um meio para alcançá-la, procuram\\nsaber \\ncomo\\n será alcançada por esse meio e por que outro meio alcançar \\nesse\\n primeiro, até chegar\\nao primeiro princípio, que é o último na ordem de descoberta. (…) e o que vem em último lugar na\\nordem da análise parece ser o primeiro na ordem da execução. E, se chegarmos a uma\\nimpossibilidade, abandonamos a busca; por exemplo, se precisarmos de dinheiro e não for\\npossível consegui-lo; porém, se algo parecer possível, tentaremos realizá-lo.\\n4\\nO algoritmo de Aristóteles foi implementado 2.300 anos mais tarde, por Newell e Simon, em seu\\nprograma GPS. Agora, poderíamos denominá-lo sistema de planejamento regressivo (ver o Capítulo\\n10.)\\nA análise baseada em metas é útil, mas não nos diz o que fazer quando várias ações alcançarem a\\nmeta ou quando nenhuma ação a alcançar por completo. Antoine Arnauld (1612-1694) descreveu\\ncorretamente uma fórmula quantitativa para definir que ação executar em casos como esse (ver o\\nCapítulo 16). O livro de John Stuart Mill (1806-1873), \\nUtilitarianism\\n (Mill, 1863), promoveu a\\nideia de critérios de decisão racionais em todas as esferas da atividade humana. A teoria de decisões\\né mais formalmente discutida na próxima seção.\\n1.2.2 Matemática\\n•  Quais são as regras formais para obter conclusões válidas?\\n•  O que pode ser computado?\\n•  Como raciocinamos com informações incertas?\\nOs filósofos demarcaram a maioria das ideias importantes sobre a IA, mas o salto para uma\\nciência formal exigiu certo nível de formalização matemática em três áreas fundamentais: lógica,\\ncomputação e probabilidade.\\nA ideia de lógica formal pode ser traçada até os filósofos da Grécia antiga, mas seu\\ndesenvolvimento matemático começou realmente com o trabalho de George Boole (1815-1864), que\\ndefiniu os detalhes da lógica proposicional ou lógica booleana (Boole, 1847). Em 1879, Gottlob\\nFrege (1848-1925) estendeu a lógica de Boole para incluir objetos e relações, criando a lógica de\\nprimeira ordem que é utilizada hoje.\\n5\\n Alfred Tarski (1902-1983) introduziu uma teoria de referência\\nque mostra como relacionar os objetos de uma lógica a objetos do mundo real.\\nA próxima etapa foi determinar os limites do que poderia ser feito com a lógica e a computação.\\nAcredita-se que o primeiro \\nalgoritmo\\n não trivial seja o algoritmo de Euclides para calcular o maior\\ndivisor comum. A palavra \\nalgoritmo\\n (e a ideia de estudá-lo) vem de Al-Khowarazmi, um\\nmatemático persa do século IX, cujos escritos também introduziram os numerais arábicos e a álgebra\\nna Europa. Boole e outros discutiram algoritmos para dedução lógica e, no final do século XIX,\\nforam empreendidos esforços para formalizar o raciocínio matemático geral como dedução lógica.\\nEm 1930, Kurt Gödel (1906-1978) mostrou que existe um procedimento efetivo para provar qualquer\\nafirmação verdadeira na lógica de primeira ordem de Frege e Russell, mas essa lógica não poderia\\ncaptar o princípio de indução matemática necessário para caracterizar os números naturais. Em 1931,\\nGödel mostrou que existem de fato limites sobre dedução. Seu \\nteorema da incompletude\\n mostrou', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 30}),\n",
       " Document(page_content='que, em qualquer teoria formal tão forte como a aritmética de Peano (a teoria elementar dos números\\nnaturais), existem afirmações verdadeiras que são indecidíveis no sentido de que não existem provas\\nna teoria.\\nEsse resultado fundamental também pode ser interpretado como a demonstração de que existem\\nalgumas funções sobre os inteiros que não podem ser representadas por um algoritmo, isto é, não\\npodem ser calculadas. Isso motivou Alan Turing (1912-1954) a tentar caracterizar exatamente que\\nfunções \\nsão\\n \\ncomputáveis\\n — capazes de ser computáveis. Na realidade, essa noção é ligeiramente\\nproblemática porque a noção de computação ou de procedimento efetivo realmente não pode ter uma\\ndefinição formal. No entanto, a tese de Church-Turing, que afirma que a máquina de Turing (Turing,\\n1936) é capaz de calcular qualquer função computável, em geral é aceita como definição suficiente.\\nTuring também mostrou que existiam algumas funções que nenhuma máquina de Turing poderia\\ncalcular. Por exemplo, nenhuma máquina pode determinar, \\nde forma geral\\n, se dado programa\\nretornará uma resposta sobre certa entrada ou se continuará funcionando para sempre.\\nEmbora a decidibilidade e a computabilidade sejam importantes para a compreensão da\\ncomputação, a noção de \\ntratabilidade\\n teve um impacto muito maior. Em termos gerais, um problema\\né chamado de intratável se o tempo necessário para resolver instâncias dele cresce exponencialmente\\ncom o tamanho das instâncias. A distinção entre crescimento polinomial e exponencial da\\ncomplexidade foi enfatizada primeiro em meados da década de 1960 (Cobham, 1964; Edmonds,\\n1965). Ela é importante porque o crescimento exponencial significa que até mesmo instâncias\\nmoderadamente grandes não podem ser resolvidas em qualquer tempo razoável. Portanto, devemos\\nprocurar dividir o problema global de geração de comportamento inteligente em subproblemas\\ntratáveis, em vez de subproblemas intratáveis.\\nComo é possível reconhecer um problema intratável? A teoria da \\nNP-completude\\n, apresentada\\nprimeiro por Steven Cook (1971) e Richard Karp (1972), fornece um método. Cook e Karp\\ndemonstraram a existência de grandes classes de problemas canônicos de busca combinatória e de\\nraciocínio que são NP-completos. Qualquer classe de problemas à qual a classe de problemas NP-\\ncompletos pode ser reduzida provavelmente é intratável (embora não tenha sido provado que\\nproblemas NP-completos são necessariamente intratáveis, a maioria dos teóricos acredita nisso).\\nEsses resultados contrastam com o otimismo com que a imprensa popular saudou os primeiros\\ncomputadores — “Supercérebros eletrônicos” que eram “Mais rápidos que Einstein!”. Apesar da\\ncrescente velocidade dos computadores, o uso parcimonioso de recursos é que caracterizará os\\nsistemas inteligentes. \\nGrosso modo\\n, o mundo é uma instância de um problema \\nextremamente\\n grande!\\nTrabalhar com IA ajudou a explicar por que algumas instâncias de problemas NP-completos são\\ndifíceis, enquanto outras são fáceis (Cheeseman \\net al\\n., 1991).\\nAlém da lógica e da computação, a terceira grande contribuição da matemática para a IA é a teoria\\nda \\nprobabilidade\\n. O italiano Gerolamo Cardano (1501-1576) foi o primeiro a conceber a ideia de\\nprobabilidade, descrevendo-a em termos dos resultados possíveis de jogos de azar. Em 1654, Blaise\\nPascal (1623-1662), numa carta para Pierre Fermat (1601-1665), mostrou como predizer o futuro de\\num jogo de azar inacabado e atribuir recompensas médias aos jogadores. A probabilidade se\\ntransformou rapidamente em uma parte valiosa de todas as ciências quantitativas, ajudando a lidar\\ncom medidas incertas e teorias incompletas. James Bernoulli (1654-1705), Pierre Laplace (1749-\\n1827) e outros pesquisadores aperfeiçoaram a teoria e introduziram novos métodos estatísticos.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 31}),\n",
       " Document(page_content='Thomas Bayes (1702-1761), que aparece na capa deste livro, propôs uma regra para atualizar\\nprobabilidades à luz de novas evidências. A regra de Bayes e o campo resultante chamado análise\\nbayesiana formam a base da maioria das abordagens modernas para raciocínio incerto em sistemas\\nde IA.\\n1.2.3 Economia\\n•  Como devemos tomar decisões para maximizar a recompensa?\\n•  Como devemos fazer isso quando outros não podem nos acompanhar?\\n•  Como devemos fazer isso quando a recompensa pode estar distante no futuro?\\nA ciência da economia teve início em 1776, quando o filósofo escocês Adam Smith (1723-1790)\\npublicou \\nAn Inquiry into the Nature and Causes of the Wealth of Nations\\n. Embora os antigos gregos\\ne outros filósofos tenham contribuído para o pensamento econômico, Smith foi o primeiro a tratá-lo\\ncomo ciência, usando a ideia de que podemos considerar que as economias consistem em agentes\\nindividuais que maximizam seu próprio bem-estar econômico. A maioria das pessoas pensa que a\\neconomia trata de dinheiro, mas os economistas dirão que, na realidade, a economia estuda como as\\npessoas fazem escolhas que levam a resultados preferenciais. Quando o McDonalds oferece um\\nhambúrguer por um dólar, está afirmando que prefere o dólar e espera que os clientes prefiram o\\nhambúrguer. O tratamento matemático de “resultados preferenciais” ou \\nutilidade\\n foi formalizado\\nprimeiro por Léon Walras (1834-1910) e aperfeiçoado por Frank Ramsey (1931) e, mais tarde, por\\nJohn von Neumann e Oskar Morgenstern em seu livro \\nThe Theory of Games and Economic Behavior\\n(1944).\\nA \\nteoria da decisão\\n, que combina a teoria da probabilidade com a teoria da utilidade, fornece\\numa estrutura formal e completa para decisões (econômicas ou outras) tomadas sob a incerteza, ou\\nseja, em casos nos quais as descrições probabilísticas captam de forma apropriada o ambiente do\\ntomador de decisões. Isso é adequado para “grandes” economias em que cada agente não precisa\\nlevar em conta as ações de outros agentes como indivíduos. No caso das “pequenas” economias, a\\nsituação é muito mais parecida com um \\njogo\\n: as ações de um jogador podem afetar de forma\\nsignificativa a utilidade de outro (positiva ou negativamente). O desenvolvimento da \\nteoria dos\\njogos\\n por Von Neumann e Morgenstern (consulte também Luce e Raiffa, 1957) incluiu o\\nsurpreendente resultado de que, em alguns jogos, um agente racional deve adotar políticas que são\\n(ou pelo menos parecem ser) aleatórias. Ao contrário da teoria da decisão, a teoria dos jogos não\\noferece uma receita inequívoca para a seleção de ações.\\nDe modo geral, os economistas não trataram a terceira questão da listagem anterior, ou seja, como\\ntomar decisões racionais quando as recompensas das ações não são imediatas, mas resultam de\\nvárias ações executadas \\nem sequência\\n. Esse tópico foi adotado no campo de \\npesquisa operacional\\n,\\nque emergiu na Segunda Guerra Mundial dos esforços britânicos para otimizar instalações de radar e,\\nmais tarde, encontrou aplicações civis em decisões complexas de administração. O trabalho de\\nRichard Bellman (1957) formalizou uma classe de problemas de decisão sequencial chamados\\nprocessos de decisão de Markov\\n, que estudaremos nos Capítulos 17 e 21.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 32}),\n",
       " Document(page_content='O trabalho em economia e pesquisa operacional contribuiu muito para nossa noção de agentes\\nracionais, ainda que por muitos anos a pesquisa em IA se desenvolvesse ao longo de caminhos\\ninteiramente separados. Uma razão para isso era a aparente \\ncomplexidade\\n da tomada de decisões\\nracionais. Herbert Simon (1916-2001), o pesquisador pioneiro da IA, ganhou o Prêmio Nobel de\\neconomia em 1978 por seu trabalho inicial demonstrando que modelos baseados em \\nsatisfação\\n — a\\ntomada de decisões “boas o suficiente”, em vez de calcular laboriosamente uma decisão ótima —\\nforneciam uma descrição melhor do comportamento humano real (Simon, 1947). Desde os anos 1990,\\nressurgiu o interesse pelas técnicas da teoria da decisão para sistemas de agentes (Wellman, 1995).\\n1.2.4 Neurociência\\n•  Como o cérebro processa informações?\\nA \\nneurociência\\n é o estudo do sistema nervoso, em particular do cérebro. Apesar de o modo exato\\ncomo o cérebro habilita o pensamento ser um dos grandes mistérios da ciência, o fato de ele\\nhabilitar\\n o pensamento foi avaliado por milhares de anos devido à evidência de que pancadas fortes\\nna cabeça podem levar à incapacitação mental. Também se sabe há muito tempo que o cérebro dos\\nseres humanos tem algumas características diferentes; em aproximadamente 335 a.C., Aristóteles\\nescreveu: “De todos os animais, o homem é o que tem o maior cérebro em proporção ao seu\\ntamanho.”\\n6\\n Ainda assim, apenas em meados do século XVIII o cérebro foi amplamente reconhecido\\ncomo a sede da consciência. Antes disso, acreditava-se que a sede da consciência poderia estar\\nlocalizada no coração e no baço.\\nO estudo da afasia (deficiência da fala) feito por Paul Broca (1824-1880) em 1861, com pacientes\\ncujo cérebro foi danificado, demonstrou a existência de áreas localizadas do cérebro responsáveis\\npor funções cognitivas específicas. Em particular, ele mostrou que a produção da fala estava\\nlocalizada em uma parte do hemisfério cerebral esquerdo agora chamada área de Broca.\\n7\\n Nessa\\népoca, sabia-se que o cérebro consistia em células nervosas ou \\nneurônios\\n, mas apenas em 1873\\nCamillo Golgi (1843-1926) desenvolveu uma técnica de coloração que permitiu a observação de\\nneurônios individuais no cérebro (ver a \\nFigura 1.2\\n). Essa técnica foi usada por Santiago Ramon y\\nCajal (1852-1934) em seus estudos pioneiros das estruturas de neurônios do cérebro.\\n8\\n Nicolas\\nRashevsky (1936, 1938) foi o primeiro a aplicar modelos matemáticos ao estudo do sistema nervoso.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 33}),\n",
       " Document(page_content='Figura 1.2\\n Partes de uma célula nervosa ou neurônio. Cada neurônio consiste em um corpo celular ou\\nsoma, que contém um núcleo celular. Ramificando-se a partir do corpo celular, há uma série de\\nfibras chamadas dendritos e uma única fibra longa chamada axônio. O axônio se estende por uma\\nlonga distância, muito mais longa do que indica a escala desse diagrama. Em geral, um axônio têm 1\\ncm de comprimento (100 vezes o diâmetro do corpo celular), mas pode alcançar até 1 metro. Um\\nneurônio faz conexões com 10-100.000 outros neurônios, em junções chamadas sinapses. Os sinais se\\npropagam de um neurônio para outro por meio de uma complicada reação eletroquímica. Os sinais\\ncontrolam a atividade cerebral em curto prazo e também permitem mudanças a longo prazo na\\nposição e na conectividade dos neurônios. Acredita-se que esses mecanismos formem a base para o\\naprendizado no cérebro. A maior parte do processamento de informações ocorre no córtex cerebral,\\na camada exterior do cérebro. A unidade organizacional básica parece ser uma coluna de tecido com\\naproximadamente 0,5 mm de diâmetro, contendo cerca de 20.000 neurônios e estendendo-se por toda\\na profundidade do córtex, cerca de 4 mm nos seres humanos.\\nAtualmente, temos alguns dados sobre o mapeamento entre áreas do cérebro e as partes do corpo\\nque elas controlam ou das quais recebem entrada sensorial. Tais mapeamentos podem mudar\\nradicalmente no curso de algumas semanas, e alguns animais parecem ter vários mapas. Além disso,\\nnão compreendemos inteiramente como outras áreas do cérebro podem assumir o comando de certas\\nfunções quando uma área é danificada. Praticamente não há teoria que explique como a memória de\\num indivíduo é armazenada.\\nA medição da atividade do cérebro intacto teve início em1929, com a invenção do\\neletroencefalógrafo (EEG) por Hans Berger. O desenvolvimento recente do processamento de\\nimagens por ressonância magnética funcional (fMRI — \\nfunctional Magnetic Resonance Imaging\\n)\\n(Ogawa \\net al\\n., 1990; Cabeza e Nyberg, 2001) está dando aos neurocientistas imagens sem\\nprecedentes de detalhes da atividade do cérebro, tornando possíveis medições que correspondem em\\naspectos interessantes a processos cognitivos em ação. Essas medições são ampliadas por avanços\\nna gravação da atividade dos neurônios em uma única célula. Os neurônios individuais podem ser\\nestimulados eletricamente, quimicamente ou mesmo opticamente (Han e Boyden, 2007), permitindo\\nque os relacionamentos neuronais de entrada-saída sejam mapeados. Apesar desses avanços, ainda\\nestamos longe de compreender como realmente funciona qualquer desses processos cognitivos.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 34}),\n",
       " Document(page_content='A conclusão verdadeiramente espantosa é que \\numa coleção de células simples pode levar ao\\npensamento\\n, \\nà ação e à consciência\\n ou, nas palavras incisivas de John Searle (1992), \\nos\\n \\ncérebros\\ngeram mentes\\n. A única teoria alternativa real é o misticismo, que significa operar em algum reino\\nmístico que está além da ciência física.\\nDe alguma forma cérebros e computadores digitais têm propriedades diferentes. A \\nFigura 1.3\\nmostra que os computadores têm um ciclo de tempo que é um milhão de vezes mais rápido que o\\ncérebro. O cérebro é composto por muito mais capacidade de armazenamento e interconexões que um\\ncomputador pessoal de última geração, apesar de os maiores supercomputadores apresentarem uma\\ncapacidade similar a do cérebro. Entretanto, observe que o cérebro não parece usar todos os seus\\nneurônios simultaneamente. Os futuristas enaltecem demais esses números, apontando para uma\\npróxima \\nsingularidade\\n em que os computadores alcançariam um nível sobrehumano de performance\\n(Vinge, 1993; Kurzweil, 2005), mas as comparações cruas não são especialmente informativas.\\nMesmo com um computador com capacidade ilimitada, não saberíamos como atingir o nível de\\ninteligência do cérebro.\\n \\nSupercomputador\\nComputador pessoal\\nMente\\nhumana\\nUnidades computacionais\\nUnidades de\\narmazenamaneto\\n \\nTempo de ciclo\\nOperações/seg\\nAtualizações de\\nmemória/seg\\n10\\n4\\n CPUs, 10\\n12\\ntransistores\\n10\\n14\\n bits RAM\\n10\\n15\\n bits disco\\n10\\n−9\\n seg\\n10\\n15\\n10\\n14\\n4 CPUs, 10\\n9\\ntransistores\\n10\\n11\\n bits\\n10\\n13\\n RAM bits disco\\n10\\n−9\\n seg\\n10\\n10\\n10\\n10\\n10\\n11\\n neurônios\\n10\\n11\\n neurônios\\n10\\n14\\n sinapses\\n10\\n−3\\n seg\\n10\\n17\\n10\\n14\\nFigura 1.3\\n Comparação grosseira dos recursos computacionais brutos disponíveis entre o\\nsupercomputador Blue Gene da IBM, um computador pessoal típico de 2008 e o cérebro humano. Os\\nnúmeros do cérebro são fixos essencialmente, enquanto os números do supercomputador crescem por\\num fator de 10, mais ou menos a cada cinco anos, permitindo-lhe alcançar paridade aproximada com\\no cérebro. O computador pessoal está atrasado em todas as métricas, exceto no tempo de ciclo.\\n1.2.5 Psicologia\\n•  Como os seres humanos e os animais pensam e agem?\\nNormalmente, considera-se que as origens da psicologia científica remontam ao trabalho do físico\\nalemão Hermann von Helmholtz (1821-1894) e de seu aluno Wilhelm Wundt (1832-1920). Helmholtz\\naplicou o método científico ao estudo da visão humana, e seu \\nHandbook of Physiological Optics\\n é\\ndescrito até hoje como “o mais importante tratado sobre a física e a fisiologia da visão humana”\\n(Nalwa, 1993, p. 15). Em 1879, Wundt abriu o primeiro laboratório de psicologia experimental na', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 35}),\n",
       " Document(page_content='Universidade de Leipzig. Ele insistia em experimentos cuidadosamente controlados, nos quais seus\\ncolaboradores executariam uma tarefa perceptiva ou associativa enquanto refletiam sobre seus\\nprocessos de pensamento. O controle cuidadoso percorreu um longo caminho para transformar a\\npsicologia em ciência, mas a natureza subjetiva dos dados tornava improvável que um pesquisador\\ndivergisse de suas próprias teorias. Por outro lado, os biólogos que estudavam o comportamento\\nanimal careciam de dados introspectivos e desenvolveram uma metodologia objetiva, como\\ndescreveu H. S. Jennings (1906) em seu influente trabalho \\nBehavior of the Lower Organisms\\n.\\nAplicando esse ponto de vista aos seres humanos, o movimento chamado \\nbehaviorismo\\n, liderado por\\nJohn Watson (1878-1958), rejeitava \\nqualquer\\n teoria que envolvesse processos mentais com base no\\nfato de que a introspecção não poderia fornecer evidência confiável. Os behavioristas insistiam em\\nestudar apenas medidas objetivas das percepções (ou \\nestímulos\\n) dados a um animal e suas ações\\nresultantes (ou \\nrespostas\\n). O behaviorismo descobriu muito sobre ratos e pombos, mas teve menos\\nsucesso na compreensão dos seres humanos.\\nA visão do cérebro como um dispositivo de processamento de informações, uma característica\\nimportante da \\npsicologia cognitiva\\n, tem suas origens nos trabalhos de William James (1842-1910).\\nHelmholtz também insistiu que a percepção envolvia uma forma de inferência lógica inconsciente. O\\nponto de vista cognitivo foi em grande parte eclipsado pelo behaviorismo nos Estados Unidos, mas\\nna Unidade de Psicologia Aplicada de Cambridge, dirigida por Frederic Bartlett (1886-1969), a\\nmodelagem cognitiva foi capaz de florescer. \\nThe Nature of Explanation\\n, de Kenneth Craik (1943),\\naluno e sucessor de Bartlett, restabeleceu com vigor a legitimidade de termos “mentais” como\\ncrenças e objetivos, argumentando que eles são tão científicos quanto, digamos, usar a pressão e a\\ntemperatura ao falar sobre gases, apesar de eles serem constituídos por moléculas que não têm\\nnenhuma dessas duas propriedades. Craik especificou os três passos fundamentais de um agente\\nbaseado no conhecimento: (1) o estímulo deve ser traduzido em uma representação interna, (2) a\\nrepresentação é manipulada por processos cognitivos para derivar novas representações internas e\\n(3) por sua vez, essas representações são de novo traduzidas em ações. Ele explicou com clareza por\\nque esse era um bom projeto de um agente:\\nSe o organismo transporta um “modelo em escala reduzida” da realidade externa e de suas\\npróprias ações possíveis dentro de sua cabeça, ele é capaz de experimentar várias alternativas,\\nconcluir qual a melhor delas, reagir a situações futuras antes que elas surjam, utilizar o\\nconhecimento de eventos passados para lidar com o presente e o futuro e, em todos os sentidos,\\nreagir de maneira muito mais completa, segura e competente às emergências que enfrenta. (Craik,\\n1943)\\nApós a morte de Craik, em um acidente de bicicleta em 1945, seu trabalho teve continuidade com\\nDonald Broadbent, cujo livro \\nPerception and Communication\\n (1958) foi um dos primeiros trabalhos\\na modelar fenômenos psicológicos como processamento de informações. Enquanto isso, nos Estados\\nUnidos, o desenvolvimento da modelagem de computadores levou à criação do campo da \\nciência\\ncognitiva\\n. Pode-se dizer que o campo teve início em um seminário em setembro de 1956 no MIT\\n(veremos que esse seminário ocorreu apenas dois meses após a conferência em que a própria IA\\n“nasceu”). No seminário, George Miller apresentou \\nThe Magic Number Seven\\n, Noam Chomsky\\napresentou \\nThree Models of Language\\n e Allen Newell e Herbert Simon apresentaram \\nThe Logic', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 36}),\n",
       " Document(page_content='Theory Machine\\n. Esses três documentos influentes mostraram como modelos de computadores\\npodiam ser usados para tratar a psicologia da memória, a linguagem e o pensamento lógico,\\nrespectivamente. Agora é comum entre os psicólogos a visão de que “uma teoria cognitiva deve ser\\ncomo um programa de computador” (Anderson, 1980), isto é, ela deve descrever um mecanismo\\ndetalhado de processamento de informações por meio do qual alguma função cognitiva poderia ser\\nimplementada.\\n1.2.6 Engenharia de computadores\\n•  Como podemos construir um computador eficiente?\\nPara a inteligência artificial ter sucesso, precisamos de inteligência e de um artefato. O\\ncomputador tem sido o artefato preferido. O computador eletrônico digital moderno foi criado\\nindependentemente e quase ao mesmo tempo por cientistas de três países que participavam da\\nSegunda Guerra Mundial. O primeiro computador \\noperacional\\n foi a máquina eletromecânica de\\nHeath Robinson,\\n9\\n construída em 1940 pela equipe de Alan Turing com um único propósito: decifrar\\nmensagens alemãs. Em 1943, o mesmo grupo desenvolveu o Colossus, uma poderosa máquina de uso\\ngeral baseada em válvulas eletrônicas.\\n10\\n O primeiro computador \\nprogramável\\n operacional foi o Z-3,\\ncriado por Konrad Zuse na Alemanha, em 1941. Zuse também criou os números de ponto flutuante e a\\nprimeira linguagem de programação de alto nível, denominada Plankalkul. O primeiro computador\\neletrônico\\n, o ABC, foi montado por John Atanasoff e por seu aluno Clifford Berry, entre 1940 e\\n1942, na Iowa State University. A pesquisa de Atanasoff recebeu pouco apoio ou reconhecimento; foi\\no ENIAC, desenvolvido como parte de um projeto militar secreto na University of Pennsylvania por\\numa equipe que incluía John Mauchly e John Eckert, que provou ser o precursor mais influente dos\\ncomputadores modernos.\\nDesde aquele tempo, cada geração de hardware de computador trouxe aumento em velocidade e\\ncapacidade, e redução no preço. O desempenho é duplicado a cada 18 meses aproximadamente, até\\npor volta de 2005, quando os problemas de dissipação de energia levaram os fabricantes a começar\\na multiplicação do número de núcleos de CPU e não a velocidade de clock. Espera-se, atualmente,\\nque futuros aumentos de energia venham de um paralelismo maciço, uma convergência curiosa com\\nas propriedades do cérebro.\\nÉ claro que existiam dispositivos de cálculo antes do computador eletrônico. As primeiras\\nmáquinas automatizadas, datando do século XVII, foram descritas na página 6. A primeira máquina\\nprogramável\\n foi um tear criado em 1805 por Joseph Marie Jacquard (1752-1834), que utilizava\\ncartões perfurados para armazenar instruções relativas ao padrão a ser tecido. Na metade do século\\nXIX, Charles Babbage (1792-1871) projetou duas máquinas, mas não concluiu nenhuma delas. A\\n“máquina diferencial” se destinava a calcular tabelas matemáticas para projetos de engenharia e\\ncientíficos. Ela foi finalmente construída e se mostrou funcional em 1991 no Science Museum em\\nLondres (Swade, 2000). A “máquina analítica” de Babbage era bem mais ambiciosa: ela incluía\\nmemória endereçável, programas armazenados e saltos condicionais, e foi o primeiro artefato capaz\\nde executar computação universal. A colega de Babbage, Ada Lovelace, filha do poeta Lord Byron,\\ntalvez tenha sido a primeira programadora do mundo (a linguagem de programação Ada recebeu esse', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 37}),\n",
       " Document(page_content='nome em homenagem a ela). Ela escreveu programas para a máquina analítica não concluída e até\\nmesmo especulou que a máquina poderia jogar xadrez ou compor música.\\nA IA também tem uma dívida com a área de software da ciência da computação, que forneceu os\\nsistemas operacionais, as linguagens de programação e as ferramentas necessárias para escrever\\nprogramas modernos (e artigos sobre eles). Porém, essa é uma área em que a dívida foi paga: o\\ntrabalho em IA foi pioneiro em muitas ideias que foram aproveitadas posteriormente na ciência da\\ncomputação em geral, incluindo compartilhamento de tempo, interpretadores interativos,\\ncomputadores pessoais com janelas e mouse, ambientes de desenvolvimento rápido, tipo de dados de\\nlista ligada, gerenciamento automático de armazenamento e conceitos fundamentais de programação\\nsimbólica, funcional, declarativa e orientada a objetos.\\n1.2.7 Teoria de controle e cibernética\\n•  Como os artefatos podem operar sob seu próprio controle?\\nCtesíbio de Alexandria (cerca de 250 a.C.) construiu a primeira máquina autocontrolada: um\\nrelógio de água com um regulador que mantinha uma taxa de fluxo constante. Essa invenção mudou a\\ndefinição do que um artefato poderia fazer. Antes, somente os seres vivos podiam modificar seu\\ncomportamento em resposta a mudanças no ambiente. Outros exemplos de sistemas de controle\\nrealimentados autorreguláveis incluem o regulador de máquinas a vapor, criado por JamesWatt\\n(1736-1819), e o termostato, criado por Cornelis Drebbel (1572-1633), que também inventou o\\nsubmarino. A teoria matemática de sistemas realimentados estáveis foi desenvolvida no século XIX.\\nA figura central na criação daquilo que se conhece hoje como \\nteoria de controle\\n foi Norbert\\nWiener (1894-1964). Wiener foi um matemático brilhante que trabalhou com Bertrand Russell, entre\\noutros, antes de se interessar por sistemas de controle biológico e mecânico e sua conexão com a\\ncognição. Como Craik (que também utilizou sistemas de controle como modelos psicológicos),\\nWiener e seus colegas Arturo Rosenblueth e Julian Bigelow desafiaram a ortodoxia behaviorista\\n(Rosenblueth \\net al\\n., 1943). Eles viram o comportamento consciente como o resultado de um\\nmecanismo regulador tentando minimizar o “erro” — a diferença entre o estado atual e o estado\\nobjetivo. No final da década de 1940, Wiener, juntamente com Warren McCulloch, Walter Pitts e\\nJohn von Neumann, organizou uma série de conferências que influenciou os novos modelos\\nmatemáticos e computacionais da cognição. O livro de Wiener, \\nCybernetics\\n (1948), tornou-se \\nbest-\\nseller\\n e despertou o público para a possibilidade de máquinas dotadas de inteligência artificial.\\nEnquanto isso, na Grã-Bretanha, W. Ross Ashby (Ashby, 1940) foi pioneiro em ideias semelhantes.\\nAshby, Alan Turing, Grey Walter e outros formaram o Ratio Club para “aqueles que tinham as ideias\\nde Wiener antes de surgir o livro de Wiener”. \\nDesign for a Brain\\n (1948, 1952), de Ashby, elaborava\\na sua ideia de que a mente poderia ser criada com a utilização de mecanismos \\nhomeostáticos\\ncontendo laços de realimentação para atingir comportamento adaptável estável.\\nA moderna teoria de controle, em especial o ramo conhecido como controle estocástico ótimo, tem\\ncomo objetivo o projeto de sistemas que maximizam uma \\nfunção objetivo\\n sobre o tempo. Isso\\ncorresponde aproximadamente à nossa visão da IA: projetar sistemas que se comportem de maneira', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 38}),\n",
       " Document(page_content='ótima. Então, por que a IA e a teoria de controle são dois campos diferentes, apesar das conexões\\nestreitas entre seus fundadores? A resposta reside no acoplamento estrito entre as técnicas\\nmatemáticas familiares aos participantes e os conjuntos de problemas correspondentes que foram\\nincluídos em cada visão do mundo. O cálculo e a álgebra de matrizes, as ferramentas da teoria de\\ncontrole, eram adequados para sistemas que podem ser descritos por conjuntos fixos de variáveis\\ncontínuas, enquanto a IA foi criada em parte como um meio de escapar das limitações percebidas. As\\nferramentas de inferência lógica e computação permitiram que os pesquisadores da IA considerassem\\nalguns problemas como linguagem, visão e planejamento, que ficavam completamente fora do campo\\nde ação da teoria de controle.\\n1.2.8 Linguística\\n•  Como a linguagem se relaciona com o pensamento?\\nEm 1957, B. F. Skinner publicou \\nVerbal Behavior\\n. Essa obra foi uma descrição completa e\\ndetalhada da abordagem behaviorista para o aprendizado da linguagem, escrita pelo mais\\nproeminente especialista no campo. Porém, curiosamente, uma crítica do livro se tornou tão\\nconhecida quanto o próprio livro e serviu para aniquilar o interesse pelo behaviorismo. O autor da\\nresenha foi o linguista Noam Chomsky, que tinha acabado de publicar um livro sobre sua própria\\nteoria, \\nSyntactic Structures\\n (\\nEstruturas sintáticas\\n). Chomsky chamou a atenção para o fato de que a\\nteoria behaviorista não tratava da noção de criatividade na linguagem — ela não explicava como\\numa criança podia compreender e formar frases que nunca tinha ouvido antes. A teoria de Chomsky\\n— baseada em modelos sintáticos criados pelo linguista indiano Panini (c. 350 a.C.) — podia\\nexplicar esse fato e, diferentemente das teorias anteriores, era formal o bastante para poder, em\\nprincípio, ser programada.\\nPortanto, a linguística moderna e a IA “nasceram” aproximadamente na mesma época e cresceram\\njuntas, cruzando-se em um campo híbrido chamado \\nlinguística computacional\\n ou \\nprocessamento de\\nlinguagem natural\\n. O problema de compreender a linguagem logo se tornou consideravelmente mais\\ncomplexo do que parecia em 1957. A compreensão da linguagem exige a compreensão do assunto e\\ndo contexto, não apenas a compreensão da estrutura das frases. Isso pode parecer óbvio, mas só foi\\namplamente avaliado na década de 1960. Grande parte do trabalho anterior em \\nrepresentação do\\nconhecimento\\n (o estudo de como colocar o conhecimento em uma forma que um computador possa\\nutilizar) estava vinculado à linguagem e era suprido com informações da pesquisa em linguística que,\\npor sua vez, estava conectada a décadas de pesquisa sobre a análise filosófica da linguagem.\\n1.3 HISTÓRIA DA INTELIGÊNCIA ARTIFICIAL\\nCom o material que vimos até agora, estamos prontos para estudar o desenvolvimento da própria\\nIA.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 39}),\n",
       " Document(page_content='1.3.1 A gestação da inteligência artificial (1943-1955)\\nO primeiro trabalho agora reconhecido como IA foi realizado por Warren McCulloch e Walter\\nPitts (1943). Eles se basearam em três fontes: o conhecimento da fisiologia básica e da função dos\\nneurônios no cérebro; uma análise formal da lógica proposicional criada por Russell e Whitehead; e\\na teoria da computação de Turing. Esses dois pesquisadores propuseram um modelo de neurônios\\nartificiais, no qual cada neurônio se caracteriza por estar “ligado” ou “desligado”, com a troca para\\n“ligado” ocorrendo em resposta à estimulação por um número suficiente de neurônios vizinhos. O\\nestado de um neurônio era considerado “equivalente em termos concretos a uma proposição que\\ndefinia seu estímulo adequado”. Por exemplo, eles mostraram que qualquer função computável podia\\nser calculada por certa rede de neurônios conectados e que todos os conectivos lógicos (e, ou, não\\netc.) podiam ser implementados por estruturas de redes simples. McCulloch e Pitts também\\nsugeriram que redes definidas adequadamente seriam capazes de aprender. Donald Hebb (1949)\\ndemonstrou uma regra de atualização simples para modificar as intensidades de conexão entre\\nneurônios. Sua regra, agora chamada \\naprendizado de Hebb\\n, continua a ser um modelo influente até\\nhoje.\\nDois alunos de Harvard, Marvin Minsky e Dean Edmonds, construíram o primeiro computador de\\nrede neural em 1950. O SNARC, como foi chamado, usava 3.000 válvulas eletrônicas e um\\nmecanismo de piloto automático retirado de um bombardeiro B-24 para simular uma rede de 40\\nneurônios. Mais tarde, em Princeton, Minsky estudou computação universal em redes neurais. A\\nbanca examinadora de seu doutorado mostrou-se cética sobre esse tipo de trabalho, sem saber se\\ndeveria ser classificado como um trabalho de matemática. Porém, segundo contam, von Neumann\\nteria dito: “Se não é agora, será algum dia.” Mais tarde, Minsky acabou provando teoremas\\nimportantes que mostravam as limitações da pesquisa em redes neurais.\\nSurgiram vários exemplos de trabalhos que hoje podem ser caracterizados como IA, mas a visão\\nde Alan Turing foi talvez a mais influente. Já em 1947, ele proferia palestras sobre o tema na\\nSociedade Matemática de Londres e articulou um programa de trabalhos persuasivo em seu artigo de\\n1950, “Computing Machinery and Intelligence”. Nesse artigo, ele apresentou o teste de Turing,\\naprendizagem de máquina, algoritmos genéticos e aprendizagem por reforço. Propôs a ideia do \\nChild\\nProgramme\\n, explicando: “Em vez de tentar produzir um programa para estimular a mente adulta, não\\nseria melhor produzir um que estimulasse a mente infantil?”\\n1.3.2 O nascimento da inteligência artificial (1956)\\nPrinceton foi o lar de outra figura influente na IA, John McCarthy. Após receber seu PhD lá, em\\n1951, e trabalhar por dois anos como instrutor, McCarthy mudou-se para Stanford e depois para\\nDartmouth College, que iria se tornar o local oficial de nascimento desse campo. McCarthy\\nconvenceu Minsky, Claude Shannon e Nathaniel Rochester a ajudá-lo a reunir pesquisadores dos\\nEstados Unidos interessados em teoria de autômatos, redes neurais e estudo da inteligência. Eles\\norganizaram um seminário de dois meses em Dartmouth, no verão de 1956. A proposta dizia:\\n11', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 40}),\n",
       " Document(page_content='Propusemos que um estudo de dois meses e dez homens sobre inteligência artificial fosse\\nrealizado durante o verão de 1956 no Dartmouth College, em Hanover, New Hampshire. O estudo\\nera para prosseguir com a conjetura básica de que cada aspecto da aprendizagem ou qualquer\\noutra característica da inteligência pode, em princípio, ser descrita tão precisamente a ponto de\\nser construída uma máquina para simulá-la. Será realizada uma tentativa para descobrir como\\nfazer com que as máquinas usem a linguagem, a partir de abstrações e conceitos, resolvam os tipos\\nde problemas hoje reservados aos seres humanos e se aperfeiçoem. Achamos que poderá haver\\navanço significativo em um ou mais desses problemas se um grupo cuidadosamente selecionado de\\ncientistas trabalhar em conjunto durante o verão.\\nHavia 10 participantes ao todo, incluindo Trenchard More, de Princeton, Arthur Samuel, da IBM,\\ne Ray Solomonoff e Oliver Selfridge, do MIT.\\nDois pesquisadores da Carnegie Tech,\\n12\\n Allen Newell e Herbert Simon, simplesmente roubaram o\\nshow. Embora os outros tivessem ideias e, em alguns casos, programas para aplicações específicas\\ncomo jogos de damas, Newell e Simon já tinham um programa de raciocínio, o Logic Theorist (LT),\\nsobre o qual Simon afirmou: “Criamos um programa de computador capaz de pensar não\\nnumericamente e, assim, resolvemos o antigo dilema mente-corpo.”\\n13\\n Logo após o seminário, o\\nprograma foi capaz de demonstrar a maioria dos teoremas do Capítulo 2 do livro \\nPrincipia\\nMathematica\\n de Russell e Whitehead. Contam que Russell ficou encantado quando Simon mostrou a\\nele que o programa havia criado uma prova de um teorema que era mais curta que a do livro. Os\\neditores do \\nJournal of Symbolic Logic\\n ficaram menos impressionados; eles rejeitaram um artigo\\nescrito em parceria por Newell, Simon e pelo Logic Theorist.\\nO seminário de Dartmouth não trouxe nenhuma novidade, mas apresentou uns aos outros todos os\\npersonagens importantes da história. Nos 20 anos seguintes, o campo seria dominado por essas\\npessoas e por seus alunos e colegas do MIT, da CMU, de Stanford e da IBM.\\nExaminando a proposta do seminário de Dartmouth (McCarthy \\net al\\n., 1955), podemos ver por que\\nera necessário que a IA se tornasse um campo separado. Por que todo o trabalho feito na IA não\\npodia ficar sob o nome de teoria de controle, pesquisa operacional ou teoria da decisão que, afinal\\nde contas, têm objetivos semelhantes aos da IA? Ou, então, por que a IA não poderia ser um ramo da\\nmatemática? Primeiro, porque a IA abraçou desde o início a ideia de reproduzir faculdades humanas\\ncomo criatividade, autoaperfeiçoamento e uso da linguagem, e nenhum dos outros campos tratava\\ndessas questões. A segunda resposta é a metodologia. A IA é o único desses campos que claramente\\né um ramo da ciência da computação (embora a pesquisa operacional compartilhe uma ênfase em\\nsimulações por computador), e a IA é o único campo a tentar construir máquinas que funcionarão de\\nforma autônoma em ambientes complexos e mutáveis.\\n1.3.3 Entusiasmo inicial, grandes expectativas (1952-1969)\\nOs primeiros anos da IA foram repletos de sucessos, mas de uma forma limitada. Considerando-se\\nos primitivos computadores, as ferramentas de programação da época e o fato de que apenas alguns\\nanos antes os computadores eram vistos como objetos capazes de efetuar operações aritméticas e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 41}),\n",
       " Document(page_content='nada mais, causava surpresa o fato de um computador realizar qualquer atividade remotamente\\ninteligente. Em geral, a classe intelectual preferia acreditar que “uma máquina nunca poderá realizar\\nX\\n” (veja, no Capítulo 26, uma longa lista de \\nX\\n reunidos por Turing). Os pesquisadores da IA\\nrespondiam naturalmente demonstrando um \\nX\\n após outro. John McCarthy se referiu a esse período\\ncomo a era do “Olhe, mamãe, sem as mãos!”.\\nO sucesso inicial de Newell e Simon prosseguiu com o General Problem Solver (solucionador de\\nproblemas gerais) ou GPS. Diferentemente do Logic Theorist, esse programa foi projetado desde o\\ninício para imitar protocolos humanos de resolução de problemas. Dentro da classe limitada de\\nquebra-cabeças com a qual podia lidar, verificou-se que a ordem em que o programa considerava\\nsubmetas e ações possíveis era semelhante à ordem em que os seres humanos abordavam os mesmos\\nproblemas. Desse modo, o GPS talvez tenha sido o primeiro programa a incorporar a abordagem de\\n“pensar de forma humana”. O sucesso do GPS e de programas subsequentes como modelos de\\ncognição levou Newell e Simon (1976) a formularem a famosa hipótese do \\nsistema de símbolos\\nfísicos\\n, que afirma que “um sistema de símbolos físicos tem os meios necessários e suficientes para\\numa ação inteligente geral”. O que eles queriam dizer é que qualquer sistema (ser humano ou\\nmáquina) que exiba inteligência deve operar manipulando estruturas de dados compostas por\\nsímbolos. Veremos, mais adiante, que essa hipótese enfrentou desafios provenientes de muitas\\ndireções.\\nNa IBM, Nathaniel Rochester e seus colegas produziram alguns dos primeiros programas de IA.\\nHerbert Gelernter (1959) construiu o Geometry Theorem Prover, que podia demonstrar teoremas que\\nseriam considerados bastante complicados por muitos alunos de matemática. A partir de 1952,\\nArthur Samuel escreveu uma série de programas para jogos de damas que eventualmente aprendiam a\\njogar em um nível amador elevado. Ao mesmo tempo, ele contestou a ideia de que os computadores\\nsó podem realizar as atividades para as quais foram programados: seu programa aprendeu\\nrapidamente a jogar melhor que seu criador. O programa foi demonstrado na televisão em fevereiro\\nde 1956, causando impressão muito forte. Como Turing, Samuel teve dificuldades para conseguir um\\nhorário em que pudesse utilizar os computadores. Trabalhando à noite, ele usou máquinas que ainda\\nestavam na bancada de testes na fábrica da IBM. O Capítulo 5 aborda os jogos de computador, e o\\nCapítulo 21 explica as técnicas de aprendizado usadas por Samuel.\\nJohn McCarthy saiu de Dartmouth para o MIT e lá contribuiu com três realizações cruciais em um\\nano histórico: 1958. No MIT AI Lab Memo N\\no\\n. 1, McCarthy definiu a linguagem de alto nível \\nLisp\\n,\\nque acabou por se tornar a linguagem de programação dominante na IA pelos próximos 30 anos. Com\\no Lisp, McCarthy teve a ferramenta de que precisava, mas o acesso a recursos de computação\\nescassos e dispendiosos também era um sério problema. Em resposta, ele e outros pesquisadores do\\nMIT criaram o compartilhamento de tempo (\\ntime sharing\\n). Também em 1958, McCarthy publicou um\\nartigo intitulado \\nPrograms with common sense\\n, em que descrevia o Advice Taker, um programa\\nhipotético que pode ser visto como o primeiro sistema de IA completo. Como o Logic Theorist e o\\nGeometry Theorem Prover, o programa de McCarthy foi projetado para usar o conhecimento com a\\nfinalidade de buscar soluções para problemas.\\nEntretanto, diferentemente dos outros, ele procurava incorporar o conhecimento geral do mundo.\\nPor exemplo, McCarthy mostrou que alguns axiomas simples permitiriam ao programa gerar um\\nplano para dirigir até o aeroporto e embarcar em um avião. O programa também foi criado de forma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 42}),\n",
       " Document(page_content='a poder aceitar novos axiomas no curso normal de operação, permitindo assim que adquirisse\\ncompetência em novas áreas \\nsem ser reprogramado\\n. Portanto, o Advice Taker incorporava os\\nprincípios centrais de representação de conhecimento e de raciocínio: de que é útil ter uma\\nrepresentação formal e explícita do mundo do modo como as ações de um agente afetam o mundo e o\\nseu funcionamento, e ser capaz de manipular essa representação com processos dedutivos. É notável\\ncomo grande parte do artigo de 1958 permanece relevante até hoje.\\nO ano de 1958 também marcou a época em que Marvin Minsky foi para o MIT. Porém, sua\\ncolaboração inicial com McCarthy não durou muito. McCarthy enfatizava a representação e o\\nraciocínio em lógica formal, enquanto Minsky estava mais interessado em fazer os programas\\nfuncionarem e, eventualmente, desenvolveu uma perspectiva contrária ao estudo da lógica. Em 1963,\\nMcCarthy fundou o laboratório de IA em Stanford. Seu plano de usar a lógica para construir o\\nAdvice Taker definitivo foi antecipado pela descoberta feita por J. A. Robinson do método de\\nresolução (um algoritmo completo para demonstração de teoremas para a lógica de primeira ordem;\\nconsulte o Capítulo 9). O trabalho em Stanford enfatizou métodos de uso geral para raciocínio lógico.\\nAs aplicações da lógica incluíam os sistemas para responder a perguntas e os sistemas de\\nplanejamento de Cordell Green (Green, 1969b) e o projeto de robótica Shakey no novo Stanford\\nResearch Institute (SRI). Este último projeto, descrito com mais detalhes no Capítulo 25, foi o\\nprimeiro a demonstrar a integração completa do raciocínio lógico e da atividade física.\\nMinsky orientou vários alunos que escolheram problemas limitados cuja solução parecia exigir\\ninteligência. Esses domínios limitados se tornaram conhecidos como \\nmicromundos\\n. O programa\\nSAINT de James Slagle (1963) era capaz de resolver problemas de cálculo integral típicos do\\nprimeiro ano dos cursos acadêmicos. O programa ANALOGY de Tom Evans (1968) resolvia\\nproblemas de analogia geométrica que apareciam em testes de QI. O programa STUDENT de Daniel\\nBobrow (1967) resolvia problemas clássicos de álgebra, como este:\\nSe o número de clientes que Tom consegue é igual ao dobro do quadrado de 20% do número de\\nanúncios que ele publica e se o número de anúncios publicados é 45, qual é o número de clientes\\nque Tom consegue?\\nO mais famoso micromundo foi o mundo de blocos, que consiste em um conjunto de blocos sólidos\\ncolocados sobre uma mesa (ou, com maior frequência, sobre a simulação de uma mesa), como mostra\\na \\nFigura 1.4\\n. Uma tarefa típica nesse mundo é reorganizar os blocos de certa maneira, utilizando a\\nmão de um robô que pode erguer um bloco de cada vez. O mundo de blocos foi a base do projeto de\\nvisão de David Huffman (1971), do trabalho em visão e propagação de restrições de David Waltz\\n(1975), da teoria do aprendizado de Patrick Winston (1970), do programa de compreensão de\\nlinguagem natural de Terry Winograd (1972) e do sistema de planejamento de Scott Fahlman (1974).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 43}),\n",
       " Document(page_content='Figura 1.4\\n Uma cena do mundo de blocos. O programa SHRDLU (Winograd, 1972) tinha acabado de\\ncompletar o comando: “Encontre um bloco mais alto que o bloco que você está segurando e coloque-\\no na caixa.”\\nO trabalho pioneiro baseado nas redes neurais de McCulloch e Pitts também prosperou. O trabalho\\nde Winograd e Cowan (1963) mostrou que grande número de elementos podia representar\\ncoletivamente um conceito individual, com aumento correspondente na robustez e no paralelismo. Os\\nmétodos de aprendizado de Hebb foram aperfeiçoados por Bernie Widrow (Widrow e Hoff, 1960;\\nWidrow, 1962), que denominou suas redes \\nadalines\\n, e por Frank Rosenblatt (1962) com seus\\nperceptrons\\n. \\nO teorema da convergência do perceptron\\n (Block \\net al.,\\n 1962) determina que o\\nalgoritmo de aprendizagem podia ajustar os pesos de conexão de um perceptron para\\ncorresponderem a quaisquer dados de entrada, desde que existisse tal correspondência. Esses\\ntópicos são cobertos no Capítulo 20.\\n1.3.4 Uma dose de realidade (1966-1973)\\nDesde o início, os pesquisadores da IA eram ousados nos prognósticos de seus sucessos futuros.\\nEsta declaração de Herbert Simon em 1957 frequentemente é citada:\\nNão é meu objetivo surpreendê-los ou chocá-los, mas o modo mais simples de resumir tudo isso é\\ndizer que agora existem no mundo máquinas que pensam, aprendem e criam. Além disso, sua\\ncapacidade de realizar essas atividades está crescendo rapidamente até o ponto — em um futuro\\nvisível — no qual a variedade de problemas com que elas poderão lidar será correspondente à\\nvariedade de problemas com os quais lida a mente humana.\\nTermos como “futuro visível” podem ser interpretados de várias maneiras, mas Simon também fez\\npredições mais concretas: a de que dentro de 10 anos um computador seria campeão de xadrez e que\\num teorema matemático significativo seria provado por uma máquina. Essas previsões se realizaram', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 44}),\n",
       " Document(page_content='(ou quase) no prazo de 40 anos, em vez de 10. O excesso de confiança de Simon se devia ao\\ndesempenho promissor dos primeiros sistemas de IA em exemplos simples. Contudo, em quase todos\\nos casos, esses primeiros sistemas acabaram falhando desastrosamente quando foram experimentados\\nem conjuntos de problemas mais extensos ou em problemas mais difíceis.\\nO primeiro tipo de dificuldade surgiu porque a maioria dos primeiros programas não tinha\\nconhecimento de seu assunto; eles obtinham sucesso por meio de manipulações sintáticas simples.\\nUma história típica ocorreu durante os primeiros esforços de tradução automática, que foram\\ngenerosamente subsidiados pelo National Research Council dos Estados Unidos, em uma tentativa de\\nacelerar a tradução de documentos científicos russos após o lançamento do Sputnik em 1957.\\nInicialmente, imaginava-se que transformações sintáticas simples baseadas nas gramáticas russas e\\ninglesas, e a substituição de palavras com a utilização de um dicionário eletrônico, seriam suficientes\\npara preservar os significados exatos das orações. O fato é que a tradução exata exige conhecimento\\nprofundo do assunto para solucionar ambiguidades e estabelecer o conteúdo da sentença. A famosa\\nretradução de “o espírito está disposto mas a carne é fraca”\\n14\\n como “a vodca é boa mas a carne é\\npodre” ilustra as dificuldades encontradas. Em 1966, um relatório criado por um comitê consultivo\\ndescobriu que “não existe nenhum sistema de tradução automática para texto científico em geral, e\\nnão existe nenhuma perspectiva imediata nesse sentido”. Toda a subvenção do governo dos Estados\\nUnidos para projetos acadêmicos de tradução foi cancelada. Hoje, a tradução automática é uma\\nferramenta imperfeita, mas amplamente utilizada em documentos técnicos, comerciais,\\ngovernamentais e da Internet.\\nO segundo tipo de dificuldade foi a impossibilidade de tratar muitos dos problemas que a IA\\nestava tentando resolver. A maior parte dos primeiros programas de IA resolvia problemas\\nexperimentando diferentes combinações de passos até encontrar a solução. Essa estratégia funcionou\\ninicialmente porque os micromundos continham pouquíssimos objetos e, consequentemente, um\\nnúmero muito pequeno de ações possíveis e sequências de soluções muito curtas. Antes do\\ndesenvolvimento da teoria de complexidade computacional, era crença geral que o “aumento da\\nescala” para problemas maiores era apenas uma questão de haver hardware mais rápido e maior\\ncapacidade de memória. Por exemplo, o otimismo que acompanhou o desenvolvimento da prova de\\nteoremas por resolução logo foi ofuscado quando os pesquisadores não conseguiram provar teoremas\\nque envolviam mais que algumas dezenas de fatos. \\nO fato de um programa poder encontrar uma\\nsolução em princípio não significa que o programa contenha quaisquer dos mecanismos\\nnecessários para encontrá-la na prática\\n.\\n A ilusão do poder computacional ilimitado não ficou confinada aos programas de resolução de\\nproblemas. Os primeiros experimentos de \\nevolução automática\\n (agora chamados \\nalgoritmos\\ngenéticos\\n) (Friedberg, 1958; Friedberg \\net al\\n., 1959) se baseavam na convicção sem dúvida correta\\nde que, realizando-se uma série apropriada de pequenas mutações em um programa em código de\\nmáquina, seria possível gerar um programa com bom desempenho para qualquer tarefa simples.\\nEntão, a ideia era experimentar mutações aleatórias com um processo de seleção para preservar\\nmutações que parecessem úteis. Apesar de milhares de horas de tempo de CPU, quase nenhum\\nprogresso foi demonstrado. Os algoritmos genéticos modernos utilizam representações melhores e\\ntêm mais sucesso.\\nA incapacidade de conviver com a “explosão combinatória” foi uma das principais críticas à IA', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 45}),\n",
       " Document(page_content='contidas no relatório Lighthill (Lighthill, 1973), que formou a base para a decisão do governo\\nbritânico de encerrar o apoio à pesquisa da IA em todas as universidades, com exceção de duas (a\\ntradição oral pinta um quadro um pouco diferente e mais colorido, com ambições políticas e\\nhostilidades pessoais, cuja descrição não nos interessa aqui).\\nUma terceira dificuldade surgiu devido a algumas limitações fundamentais nas estruturas básicas\\nque estavam sendo utilizadas para gerar o comportamento inteligente. Por exemplo, o livro de\\nMinsky e Papert, \\nPerceptrons\\n (1969), provou que, embora os perceptrons (uma forma simples de\\nrede neural) pudessem aprender tudo o que eram capazes de representar, eles podiam representar\\nmuito pouco. Em particular, um perceptron de duas entradas (restringido para ser mais simples que a\\nforma que Rosemblatt estudou) não podia ser treinado para reconhecer quando suas duas entradas\\neram diferentes. Embora seus resultados não se aplicassem a redes mais complexas de várias\\ncamadas, a subvenção de pesquisas relacionadas a redes neurais logo se reduziu a quase nada.\\nIronicamente, os novos algoritmos de aprendizado por retropropagação para redes de várias camadas\\nque acabaram de provocar um enorme renascimento na pesquisa de redes neurais no final da década\\nde 1980 foram, na verdade, descobertos primeiro em 1969 (Bryson e Ho, 1969).\\n1.3.5 Sistemas baseados em conhecimento: a chave para o poder? (1969-1979)\\nO quadro de resolução de problemas que havia surgido durante a primeira década de pesquisas em\\nIA foi o de um mecanismo de busca de uso geral que procurava reunir passos elementares de\\nraciocínio para encontrar soluções completas. Tais abordagens foram chamadas \\nmétodos fracos\\nporque, embora gerais, não podiam ter aumento de escala para instâncias de problemas grandes ou\\ndifíceis. A alternativa para métodos fracos é usar um conhecimento mais amplo e específico de\\ndomínio que permita passos de raciocínio maiores e que possam tratar com mais facilidade casos\\nque ocorrem tipicamente em especialidades estritas. Podemos dizer que, para resolver um problema\\ndifícil, praticamente é necessário já saber a resposta.\\nO programa DENDRAL (Buchanan \\net al\\n., 1969) foi um exemplo inicial dessa abordagem. Ele foi\\ndesenvolvido em Stanford, onde Ed Feigenbaum (um antigo aluno de Herbert Simon), Bruce\\nBuchanan (filósofo transformado em cientista de computação) e Joshua Lederberg (geneticista\\nlaureado com um Prêmio Nobel) formaram uma equipe para resolver o problema de inferir a\\nestrutura molecular a partir das informações fornecidas por um espectrômetro de massa. A entrada\\npara o programa consiste na fórmula elementar da molécula (por exemplo, C\\n6\\nH\\n13\\nNO\\n2\\n) e o espectro\\nde massa que fornece as massas dos diversos fragmentos da molécula gerada quando ela é\\nbombardeada por um feixe de elétrons. Por exemplo, o espectro de massa poderia conter um pico em\\nm\\n = 15, correspondendo à massa de um fragmento metil (CH\\n3\\n).\\nA versão ingênua do programa gerou todas as estruturas possíveis consistentes com a fórmula e\\ndepois previu qual seria o espectro de massa observado para cada uma, comparando esse espectro\\ncom o espectro real. Como se poderia esperar, esse é um problema intratável mesmo para moléculas\\nde tamanho moderado. Os pesquisadores do DENDRAL consultaram especialistas em química\\nanalítica e descobriram que eles trabalhavam procurando padrões conhecidos de picos no espectro\\nque sugerissem subestruturas comuns na molécula. Por exemplo, a regra a seguir é usada para', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 46}),\n",
       " Document(page_content='reconhecer um subgrupo cetona (C=O), que pesa 28 unidades de massa:\\nse\\n existem dois picos em \\nx\\n1\\n e \\nx\\n2\\n tais que\\n(a) \\nx\\n1\\n + \\nx\\n2\\n = \\nM\\n + 28 (\\nM\\n é a massa da molécula inteira);\\n(b) \\nx\\n1\\n – 28 é um pico;\\n(c) x\\n2\\n – 28 é um pico;\\n(d) No mínimo, um entre \\nx\\n1\\n e \\nx\\n2\\n é alto.\\nentão\\n, existe um subgrupo cetona\\nO reconhecimento de que a molécula contém uma subestrutura específica reduz enormemente o\\nnúmero de possíveis candidatos. O DENDRAL era eficiente porque:\\nTodo o conhecimento teórico relevante para resolver esses problemas foi mapeado de sua forma\\ngeral no [componente de previsão de espectro] (“princípios básicos”) para formas especiais\\neficientes (“receitas de bolo”). (Feigenbaum \\net al\\n., 1971)\\nO DENDRAL foi importante porque representou o primeiro sistema bem-sucedido de\\nconhecimento intensivo\\n: sua habilidade derivava de um grande número de regras de propósito\\nespecífico. Sistemas posteriores também incorporaram o tema principal da abordagem de McCarthy\\nno Advice Taker — a separação clara entre o conhecimento (na forma de regras) e o componente de\\nraciocínio.\\nCom essa lição em mente, Feigenbaum e outros pesquisadores de Stanford iniciaram o Heuristic\\nProgramming Project (HPP) para investigar até que ponto a nova metodologia de \\nsistemas\\nespecialistas\\n poderia ser aplicada a outras áreas do conhecimento humano. Em seguida, o principal\\nesforço foi dedicado à área de diagnóstico médico. Feigenbaum, Buchanan e o Dr. Edward Shortliffe\\ndesenvolveram o MYCIN para diagnosticar infecções sanguíneas. Com cerca de 450 regras, o\\nMYCIN foi capaz de se sair tão bem quanto alguns especialistas e muito melhor do que médicos em\\ninício de carreira. Ele também apresentava duas diferenças importantes em relação ao DENDRAL.\\nPrimeiro, diferentemente das regras do DENDRAL, não havia nenhum modelo teórico geral a partir\\ndo qual as regras do MYCIN pudessem ser deduzidas. Elas tinham de ser adquiridas a partir de\\nentrevistas extensivas com especialistas que, por sua vez, as adquiriam de livros didáticos, de outros\\nespecialistas e da experiência direta de estudos de casos. Em segundo lugar, as regras tinham de\\nrefletir a incerteza associada ao conhecimento médico. O MYCIN incorporava um cálculo de\\nincerteza chamado \\nfatores de certeza\\n (consulte o Capítulo 14) que pareciam (na época) se adequar\\nbem à forma como os médicos avaliavam o impacto das evidências no diagnóstico.\\nA importância do conhecimento de domínio também ficou aparente na área da compreensão da\\nlinguagem natural. Embora o sistema SHRDLU de Winograd para reconhecimento da linguagem\\nnatural tivesse despertado bastante interesse, sua dependência da análise sintática provocou alguns\\nproblemas idênticos aos que ocorreram nos primeiros trabalhos em tradução automática. Ele foi\\ncapaz de superar a ambiguidade e reconhecer referências pronominais, mas isso acontecia\\nprincipalmente porque o programa foi criado especificamente para uma única área — o mundo dos\\nblocos. Diversos pesquisadores, entre eles Eugene Charniak, aluno graduado e companheiro de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 47}),\n",
       " Document(page_content='Winograd no MIT, sugeriram que uma compreensão robusta da linguagem exigiria conhecimentos\\ngerais sobre o mundo e um método genérico para utilizar esses conhecimentos.\\nEm Yale, o linguista transformado em pesquisador da IA Roger Schank enfatizou esse ponto,\\nafirmando: “Não existe essa coisa de sintaxe.” Isso irritou muitos linguistas, mas serviu para dar\\ninício a uma discussão útil. Schank e seus alunos elaboraram uma série de programas (Schank e\\nAbelson, 1977; Wilensky, 1978; Schank e Riesbeck, 1981; Dyer, 1983), todos com a tarefa de\\nentender a linguagem natural. Porém, a ênfase foi menos na linguagem em si e mais nos problemas de\\nrepresentação e raciocínio com o conhecimento exigido para compreensão da linguagem. Os\\nproblemas incluíam a representação de situações estereotípicas (Cullingford, 1981), descrição da\\norganização da memória humana (Rieger, 1976; Kolodner, 1983) e compreensão de planos e metas\\n(Wilensky, 1983).\\nO enorme crescimento das aplicações para resolução de problemas reais causou um aumento\\nsimultâneo na demanda por esquemas utilizáveis de representação do conhecimento. Foi\\ndesenvolvido grande número de diferentes linguagens de representação e raciocínio. Algumas se\\nbaseavam na lógica — por exemplo, a linguagem Prolog se tornou popular na Europa, e a família\\nPLANNER, nos Estados Unidos. Outras, seguindo a ideia de \\nframes\\n de Minsky (1975), adotaram\\numa abordagem mais estruturada, reunindo fatos sobre tipos específicos de objetos e eventos, e\\norganizando os tipos em uma grande hierarquia taxonômica análoga a uma taxonomia biológica.\\n1.3.6 A IA se torna uma indústria (de 1980 até a atualidade)\\nO primeiro sistema especialista comercial bem-sucedido, o R1, iniciou sua operação na Digital\\nEquipment Corporation (McDermott, 1982). O programa ajudou a configurar pedidos de novos\\nsistemas de computadores; em 1986, ele estava fazendo a empresa economizar cerca de 40 milhões\\nde dólares por ano. Em 1988, o grupo de IA da DEC tinha 40 sistemas especialistas entregues, com\\noutros sendo produzidos. A Du Pont tinha 100 desses sistemas em uso e 500 em desenvolvimento,\\neconomizando aproximadamente 10 milhões de dólares por ano. Quase todas as corporações\\nimportantes dos Estados Unidos tinham seu próprio grupo de IA e estavam usando ou investigando\\nsistemas especialistas.\\nEm 1981, os japoneses anunciaram o projeto “Fifth Generation”, um plano de 10 anos para montar\\ncomputadores inteligentes que utilizassem Prolog. Em resposta, os Estados Unidos formaram a\\nMicroelectronics and Computer Technology Corporation (MCC) como um consórcio de pesquisa\\nprojetado para assegurar a competitividade nacional. Em ambos os casos, a IA fazia parte de um\\namplo esforço, incluindo o projeto de chips e a pesquisa da interface humana. Na Inglaterra, o\\nrelatório Alvey reabilitou o subsídio que havia sido cortado em consequência do relatório\\nLighthill.\\n15\\n No entanto, em todos os três países, os projetos nunca alcançaram seus objetivos\\nambiciosos.\\nDe modo geral, a indústria da IA se expandiu de alguns milhões de dólares em 1980 para bilhões\\nde dólares em 1988, incluindo centenas de empresas construindo sistemas especialistas, sistemas de\\nvisão, robôs, e software e hardware especializados para esses propósitos. Logo depois, veio um\\nperíodo chamado de “inverno da IA”, em que muitas empresas caíram no esquecimento à medida que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 48}),\n",
       " Document(page_content='deixaram de cumprir promessas extravagantes.\\n1.3.7 O retorno das redes neurais (de 1986 até a atualidade)\\nEm meados dos anos 1980, pelo menos quatro grupos diferentes reinventaram o algoritmo de\\naprendizado por \\nretroprogramação\\n, descoberto pela primeira vez em 1969 por Bryson e Ho. O\\nalgoritmo foi aplicado a muitos problemas de aprendizado em ciência da computação e psicologia, e\\na ampla disseminação dos resultados na coletânea \\nParallel Distributed Processing\\n (Rumelhart e\\nMcClelland, 1986) causou grande excitação.\\nOs chamados modelos \\nconexionistas\\n para sistemas inteligentes eram vistos por alguns como\\nconcorrentes diretos dos modelos simbólicos promovidos por Newell e Simon e da abordagem\\nlogicista de McCarthy e outros pesquisadores (Smolensky, 1988). Pode parecer óbvio que, em certo\\nnível, os seres humanos manipulam símbolos — de fato, o livro de Terrence Deacon, \\nThe Symbolic\\nSpecies\\n (1997), sugere que essa é a \\ncaracterística que define\\n os seres humanos —, mas os\\nconexionistas mais fervorosos questionavam se a manipulação de símbolos tinha qualquer função\\nexplicativa real em modelos detalhados de cognição. Essa pergunta permanece sem resposta, mas a\\nvisão atual é de que as abordagens conexionista e simbólica são complementares, e não concorrentes.\\nComo ocorreu com a separação da IA e da ciência cognitiva, a pesquisa moderna de rede neural se\\nbifurcou em dois campos, um preocupado com a criação de algoritmos e arquiteturas de rede eficazes\\ne a compreensão de suas propriedades matemáticas, o outro preocupado com a modelagem cuidadosa\\ndas propriedades empíricas de neurônios reais e conjuntos de neurônios.\\n1.3.8 A IA se torna uma ciência (de 1987 até a atualidade)\\nNos últimos anos, houve uma revolução no trabalho em inteligência artificial, tanto no conteúdo\\nquanto na metodologia.\\n16\\n Agora, é mais comum usar as teorias existentes como bases, em vez de\\npropor teorias inteiramente novas, fundamentar as afirmações em teoremas rigorosos ou na evidência\\nexperimental rígida, em vez de utilizar como base a intuição e destacar a relevância de aplicações\\nreais em vez de exemplos de brinquedos.\\nEm parte, a IA surgiu como uma rebelião contra as limitações de áreas existentes como a teoria de\\ncontrole e a estatística, mas agora ela inclui esses campos. Conforme afirmou David McAllester\\n(1998):\\nNo período inicial da IA, parecia plausível que novas formas de computação simbólica, como\\nframes e redes semânticas, tornariam obsoleta grande parte da teoria clássica. Isso levou a uma\\nforma de isolacionismo na qual a IA ficou bem separada do restante da ciência da computação.\\nAtualmente, esse isolacionismo está sendo abandonado. Existe o reconhecimento de que o\\naprendizado da máquina não deve ser isolado da teoria da informação, de que o raciocínio incerto\\nnão deve ser isolado da modelagem estocástica, de que a busca não deve ser isolada da\\notimização clássica e do controle, e de que o raciocínio automatizado não deve ser isolado dos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 49}),\n",
       " Document(page_content='métodos formais e da análise estática.\\nEm termos de metodologia, a IA finalmente adotou com firmeza o método científico. Para serem\\naceitas, as hipóteses devem ser submetidas a rigorosos experimentos empíricos, e os resultados\\ndevem ser analisados estatisticamente de acordo com sua importância (Cohen, 1995). Agora é\\npossível replicar experimentos a partir da utilização de repositórios compartilhados de código e\\ndados de teste.\\nO campo de reconhecimento da fala ilustra o padrão. Nos anos 1970, foi experimentada ampla\\nvariedade de arquiteturas e abordagens diferentes. Muitas delas eram bastante \\nad hoc\\n e frágeis, e\\nforam demonstradas em apenas alguns exemplos especialmente selecionados. Nos últimos anos,\\nabordagens baseadas em \\nmodelos ocultos de Markov\\n (MOMs) passaram a dominar a área. Dois\\naspectos dos MOMs são relevantes. Primeiro, eles se baseiam em uma teoria matemática rigorosa.\\nIsso permitiu que os cientistas de reconhecimento de fala se baseassem em várias décadas de\\nresultados matemáticos desenvolvidos em outros campos. Em segundo lugar, eles são gerados por um\\nprocesso de treinamento em um grande conjunto de dados reais de fala. Isso assegura um desempenho\\nrobusto e, em testes cegos rigorosos, os MOMs têm melhorado suas pontuações de forma contínua. A\\ntecnologia da fala e o campo inter-relacionado de reconhecimento de caracteres manuscritos já estão\\nefetuando a transição para aplicações industriais e de consumo em larga escala.\\nObserve que não há nenhuma afirmação científica de que os humanos utilizam MOMs para\\nreconhecer a fala, mas que os MOMs fornecem uma estrutura matemática para a compreensão do\\nproblema e apoiam a alegação da engenharia de que na prática eles funcionam bem.\\nA tradução automática segue o mesmo curso que o reconhecimento de voz. Na década de 1950\\nhouve um entusiasmo inicial por uma abordagem baseada na sequência de palavras, aprendida com\\nmodelos de acordo com os princípios da teoria da informação. A abordagem caiu em desuso na\\ndécada de 1960, mas retornou no final dos anos 1990 e agora domina o campo.\\nAs redes neurais também seguem essa tendência. Grande parte do trabalho em redes neurais nos\\nanos 1980 foi realizada na tentativa de definir a abrangência do que poderia ser feito e de aprender\\ncomo as redes neurais diferem das técnicas “tradicionais”. Utilizando metodologia aperfeiçoada e\\nestruturas teóricas, o campo chegou a uma compreensão tal que, agora, as redes neurais podem ser\\ncomparadas a técnicas correspondentes da estatística, do reconhecimento de padrões e do\\naprendizado de máquina, podendo ser utilizada a técnica mais promissora em cada aplicação. Como\\nresultado desse desenvolvimento, a tecnologia denominada \\nmineração de dados\\n gerou uma nova e\\nvigorosa indústria.\\nA obra de Judea Pearl, \\nProbabilistic Reasoning in Intelligent Systems\\n (1988), levou a uma nova\\naceitação da probabilidade e da teoria da decisão na IA, seguindo um renascimento do interesse\\ndescrito no artigo de Peter Cheeseman, “In Defense of Probability” (1985). O formalismo\\ndenominado \\nrede bayesiana\\n foi criado para permitir a representação eficiente do conhecimento\\nincerto e o raciocínio rigoroso com a utilização desse tipo de conhecimento. Essa abordagem supera\\namplamente muitos problemas dos sistemas de raciocínio probabilístico das décadas de 1960 e\\n1970; agora ele domina a pesquisa de IA sobre raciocínio incerto e sistemas especialistas.\\nA abordagem admite o aprendizado a partir da experiência e combina o melhor da IA clássica e\\ndas redes neurais. O trabalho de Judea Pearl (1982a) e de Eric Horvitz e David Heckerman (Horvitz', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 50}),\n",
       " Document(page_content='e Heckerman, 1986; Horvitz \\net al\\n., 1986) promoveu a ideia de sistemas especialistas \\nnormativos\\n:\\nsistemas que agem racionalmente de acordo com as leis da teoria de decisão e não procuram imitar\\nos passos do pensamento de especialistas humanos. O sistema operacional Windows\\nTM\\n inclui vários\\nsistemas especialistas de diagnóstico normativo para correção de problemas. Os Capítulos 13 a 16\\nexaminam essa área.\\nRevoluções suaves semelhantes a essa ocorreram nos campos de robótica, visão computacional e\\nrepresentação de conhecimento. Uma compreensão melhor dos problemas e de suas propriedades de\\ncomplexidade, combinada à maior sofisticação matemática, resultou em agendas de pesquisa\\nutilizáveis e métodos robustos. Apesar do aumento da formalização e da especialização terem levado\\ncampos como visão e robótica a tornarem-se de alguma forma isolados do “principal” em IA nos\\nanos 1990, essa tendência foi revertida nos últimos anos à medida que ferramentas de aprendizado de\\nmáquina em particular, mostraram-se eficazes para muitos problemas. O processo de reintegração já\\nestá rendendo benefícios significativos.\\n1.3.9 O surgimento de agentes inteligentes (de 1995 até a atualidade)\\nTalvez encorajados pelo progresso na resolução dos subproblemas da IA, os pesquisadores\\ntambém começaram a examinar mais uma vez o problema do “agente como um todo”. O trabalho de\\nAllen Newell, John Laird e Paul Rosenbloom no SOAR (Newell, 1990; Laird \\net al\\n., 1987) é o\\nexemplo mais conhecido de uma arquitetura completa de agente. Um dos ambientes mais importantes\\npara agentes inteligentes é a Internet. Os sistemas de IA se tornaram tão comuns em aplicações da\\nWeb que o sufixo “bot” passou a fazer parte da linguagem cotidiana. Além disso, as tecnologias da\\nIA servem de base a muitas ferramentas da Internet, como mecanismos de pesquisa, sistemas de\\nrecomendação (\\nrecommender systems\\n) e agregadores de conteúdo de construção de sites.\\nUma consequência de tentar construir agentes completos é a constatação de que os subcampos\\npreviamente isolados da IA podem necessitar ser reorganizados quando se tiver que unir os\\nresultados. Em particular, hoje é amplamente reconhecido que os sistemas sensoriais (visão, sonar,\\nreconhecimento de voz etc.) não podem fornecer informações perfeitamente confiáveis sobre o meio\\nambiente. Assim, os sistemas de raciocínio e de planejamento devem ser capazes de lidar com a\\nincerteza. Uma segunda consequência importante pela perspectiva do agente é que a IA foi\\nestabelecida em contato muito mais próximo com outros campos, como teoria de controle e\\neconomia, que também lidam com agentes. O progresso recente do controle de carros robóticos foi\\nderivado de uma mistura de abordagens que vai desde melhores sensores, controle teórico da\\nintegração do sensoriamento, localização e mapeamento, bem como um grau de alto nível de\\nplanejamento.\\nApesar desses sucessos, alguns fundadores influentes da IA, incluindo John McCarthy (2007),\\nMarvin Minsky (2007), Nils Nilsson (1995, 2005) e Patrick Winston (Beal e Winston, 2009),\\nexpressaram descontentamento com a evolução da IA. Achavam que a IA deveria colocar menos\\nênfase na criação de versões cada vez melhores de aplicações eficientes para tarefas específicas, tal\\ncomo dirigir um carro, jogar xadrez ou reconhecer fala. Em vez disso, acreditam que a IA deveria\\nretornar às suas raízes esforçando-se para obter, nas palavras de Simon, “máquinas que pensam, que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 51}),\n",
       " Document(page_content='aprendem e que criam”. Chamam o esforço de \\nIA de nível humano\\n ou HLAI; o primeiro simpósio foi\\nem 2004 (Minsky \\net al.,\\n 2004). O esforço necessitará de grandes bases de conhecimento; Hendler \\net\\nal.\\n (1995) discutem de onde essas bases de conhecimento poderiam vir.\\nUma ideia relacionada é o subcampo da \\ninteligência geral artificial\\n ou IAG (Goertzel e\\nPennachin, 2007), que realizou a sua primeira conferência e organizou o \\nJournal of Artificial\\nGeneral Intelligence\\n em 2008. A IAG procura por um algoritmo universal para aprender e atuar em\\nqualquer ambiente, e tem suas raízes na obra de Ray Solomonoff (1964), um dos participantes da\\nconferência original de Dartmouth em 1956. Garantindo que o que nós criamos é realmente \\nIA\\namigável\\n também é uma preocupação (Yudkowsky, 2008; Omohundro, 2008), para a qual voltaremos\\nno Capítulo 26.\\n1.3.10 Disponibilidade de conjuntos de dados muito grandes (2001 até a\\natualidade)\\nAo longo de 60 anos de história da ciência da computação, a ênfase tem sido no \\nalgoritmo\\n como o\\nassunto principal de estudo. Mas alguns trabalhos recentes da IA sugerem que, para muitos\\nproblemas, faz mais sentido se preocupar com os \\ndados\\n e ser menos exigente sobre qual algoritmo\\naplicar. Isso é verdade devido à disponibilidade crescente de fontes de dados muito grandes: por\\nexemplo, trilhões de palavras de inglês e bilhões de imagens da Web (Kilgarriff e Grefenstette,\\n2006) ou bilhões de pares de bases de sequências genômicas (Collins \\net al.,\\n 2003).\\nUm artigo influente nessa linha de pesquisa foi o trabalho de Yarowsky (1995) sobre\\ndesambiguação de sentido de palavras: dado o uso da palavra “planta” em uma frase, ela se refere a\\nflora ou fábrica? Abordagens anteriores do problema confiavam em rótulos humanos combinados\\ncom algoritmos de aprendizado de máquina. Yarowsky mostrou que a tarefa poderia ser feita, com\\nprecisão superior a 96%, sem quaisquer exemplos rotulados. Em vez disso, dado um \\ncorpus\\n muito\\ngrande de texto não anotado e apenas as definições de dicionário dos dois sentidos, “obras, planta\\nindustrial” e “flora, vida das plantas”, pode-se rotular exemplos no \\ncorpus\\n, e de lá, \\npor iniciativa\\nprópria\\n, aprender novos modelos que ajudem a rotular novos exemplos. Banko e Brill (2001)\\nmostram que técnicas como essa têm um desempenho ainda melhor à medida que a quantidade de\\ntexto disponível vai de um milhão de palavras para um bilhão e que o aumento no desempenho pela\\nutilização de mais dados excede qualquer diferença na escolha do algoritmo; um algoritmo medíocre\\ncom 100 milhões de palavras de dados de treinamento não rotulados supera o melhor algoritmo\\nconhecido com um milhão de palavras.\\nEm outro exemplo, Hays e Efros (2007) discutem o problema do preenchimento de buracos em\\numa fotografia. Suponha que você use o Photoshop para mascarar um ex-amigo de uma foto de grupo,\\nmas agora você precisa preencher a área mascarada com algo que corresponda ao fundo. Hays e\\nEfros definiram um algoritmo que busca, através de uma coleção de fotos, encontrar algo que vá\\ncorresponder. Descobriram que o desempenho de seu algoritmo era pobre quando usavam uma\\ncoleção de apenas 10 mil fotos, mas atravessou o limiar para um excelente desempenho quando\\naumentaram a coleção para dois milhões de fotos.\\nTrabalho como esse sugere que o “gargalo do conhecimento” na IA — o problema de como', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 52}),\n",
       " Document(page_content='expressar todo o conhecimento que um sistema necessita — pode ser resolvido em muitas aplicações\\npor métodos de aprendizagem, em vez de engenharia do conhecimento codificada à mão, desde que\\nos algoritmos de aprendizado tenham dados suficientes para prosseguir (Halevy \\net al\\n., 2009). Os\\nobservadores notaram o surgimento de novas aplicações e escreveram que “o inverno da IA” pode\\nestar produzindo uma nova primavera (Havenstein, 2005). Como Kurzweil (2005) escreveu: “Hoje,\\nmuitos milhares de aplicações de IA estão profundamente enraizadas na infraestrutura de cada\\nindústria.”\\n1.4 O ESTADO DA ARTE\\nO que a IA pode fazer hoje? É difícil uma resposta concisa porque existem muitas atividades em\\nvários subcampos. Aqui, mostramos algumas aplicações; outras serão apresentadas ao longo do\\nlivro.\\nVeículos robóticos:\\n Um carro robótico sem motorista chamado STANLEY acelerou através do\\nterreno acidentado do deserto Mojave a 22 mph, terminando o percurso de 212 quilômetros como o\\nprimeiro para ganhar o DARPA Grand Challenge 2005. STANLEY é um Touareg Volkswagen\\nequipado com câmeras, radares e telêmetros a \\nlaser\\n para detectar o ambiente e computador de bordo\\npara comandar a pilotagem, a frenagem e a aceleração (Thrun, 2006). No ano seguinte, o BOSS da\\nCMU ganhou o Urban Chalenge, dirigindo de forma segura no trânsito pelas ruas de uma base da\\nforça aérea fechada, obedecendo às regras de trânsito e evitando os pedestres e outros veículos.\\nReconhecimento de voz:\\n Um viajante telefonando para a United Airlines para reservar um voo\\npode ter toda a conversa guiada por um sistema automático de reconhecimento de voz e de gestão de\\ndiálogo.\\nPlanejamento autônomo e escalonamento:\\n A uma centena de milhões de quilômetros da Terra, o\\nprograma Remote Agent da Nasa se tornou o primeiro programa de planejamento autônomo de bordo\\na controlar o escalonamento de operações de uma nave espacial (Jonsson \\net al\\n., 2000). O Remote\\nAgent gerou planos de metas de alto nível especificadas a partir do solo e monitorou a execução\\ndaqueles planos — efetuando a detecção, o diagnóstico e a recuperação de problemas conforme eles\\nocorriam. O programa sucessor MAPGEN (Al-Chang \\net al.,\\n 2004) planeja as operações diárias para\\na Mars Exploration Rovers da Nasa, e o MEXAR2 (Cesta \\net al.,\\n 2007) fez o planejamento tanto\\nlogístico como científico para a missão Mars Express da Agência Espacial Europeia, em 2008.\\nJogos:\\n O DEEP BLUE da IBM se tornou o primeiro programa de computador a derrotar o\\ncampeão mundial em uma partida de xadrez, ao vencer Garry Kasparov por um placar de 3,5 a 2,5\\nem uma partida de exibição (Goodman e Keene, 1997). Kasparov disse que sentiu “uma nova espécie\\nde inteligência” do outro lado do tabuleiro. A revista \\nNewsweek\\n descreveu a partida como “o último\\nreduto do cérebro”. O valor das ações da IBM teve um aumento de 18 bilhões de dólares. Campeões\\nhumanos estudaram a perda de Kasparov e foram capazes de empatar algumas partidas nos anos\\nseguintes, mas as mais recentes partidas humano-computador foram conquistadas de maneira\\nconvincente pelo computador.\\nCombate a spam\\n: A cada dia, algoritmos de aprendizagem classificam mais de um bilhão de\\nmensagens como spam, poupando o destinatário de ter que perder tempo excluindo o que, para muitos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 53}),\n",
       " Document(page_content='usuários, poderia incluir 80% ou 90% de todas as mensagens, se não fossem classificadas como\\nspam pelos algoritmos. Devido aos spammers estarem constantemente atualizando suas táticas, é\\ndifícil que uma abordagem estática programada se mantenha, e algoritmos de aprendizagem\\nfuncionam melhor (Sahami \\net al\\n., 1998; Goodman e Heckerman, 2004).\\nPlanejamento logístico:\\n Durante a crise do Golfo Pérsico em 1991, as forças armadas dos\\nEstados Unidos distribuíram uma ferramenta denominada Dynamic Analysis and Replanning Tool, ou\\nDART (Cross e Walker, 1994), a fim de realizar o planejamento logístico automatizado e a\\nprogramação de execução do transporte. Isso envolveu até 50.000 veículos, transporte de carga aérea\\ne pessoal ao mesmo tempo, e teve de levar em conta pontos de partida, destinos, rotas e resolução de\\nconflitos entre todos os parâmetros. As técnicas de planejamento da IA permitiram a geração em\\nalgumas horas de um plano que exigiria semanas com outros métodos. A Defense Advanced Research\\nProject Agency (DARPA) declarou que essa única aplicação compensou com folga os 30 anos de\\ninvestimento da DARPA em IA.\\nRobótica\\n: A iRobot Corporation já vendeu mais de dois milhões de aspiradores robóticos\\nRoomba para uso doméstico. A empresa também disponibilizou o mais robusto PackBot para o\\nIraque e Afeganistão, onde é usado para lidar com materiais perigosos, remover explosivos e\\nidentificar a localização dos franco-atiradores.\\nTradução automática:\\n Um programa de computador traduz automaticamente do árábe para o\\ninglês, permitindo a um nativo de língua inglesa ler o cabeçalho “Ardogan Confirma que a Turquia\\nNão Vai Aceitar Qualquer Tipo de Pressão, Instando-os a Reconhecer Chipre”. O programa utiliza\\num modelo estatístico construído a partir de exemplos de traduções de árabe-inglês e de exemplos de\\ntextos em inglês, totalizando dois trilhões de palavras (Brants \\net al\\n., 2007). Nenhum dos cientistas da\\ncomputação na equipe fala árabe, mas eles entendem as estatísticas e os algoritmos de aprendizado\\nde máquina.\\nEsses são apenas alguns exemplos de sistemas de inteligência artificial que existem hoje em dia.\\nNão é mágica ou ficção científica, mas ciência, engenharia e matemática, e este livro apresenta uma\\nintrodução a tudo isso.\\n1.5 RESUMO\\nEste capítulo define a IA e estabelece os fundamentos culturais sobre os quais ela se desenvolveu.\\nAlguns pontos importantes são:\\n•  Pessoas diferentes abordam a IA com objetivos diferentes em mente. Duas questões importantes\\nsão: Você se preocupa com o pensamento ou com o comportamento? Você quer modelar seres\\nhumanos ou trabalhar a partir de um padrão ideal?\\n•  Neste livro, adotamos a visão de que a inteligência está relacionada principalmente a uma \\nação\\nracional\\n. No caso ideal, um \\nagente inteligente\\n adota a melhor ação possível em uma situação.\\nEstudaremos o problema da criação de agentes que são inteligentes nesse sentido.\\n•  Os filósofos (desde 400 a.C.) tornaram a IA concebível, considerando as ideias de que a mente', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 54}),\n",
       " Document(page_content='é, em alguns aspectos, semelhante a uma máquina, de que ela opera sobre o conhecimento\\ncodificado em alguma linguagem interna e que o pensamento pode ser usado para escolher as\\nações que deverão ser executadas.\\n•  Os matemáticos forneceram as ferramentas para manipular declarações de certeza lógica, bem\\ncomo declarações incertas e probabilísticas. Eles também definiram a base para a compreensão\\nda computação e do raciocínio sobre algoritmos.\\n•  Os economistas formalizaram o problema de tomar decisões que maximizam o resultado\\nesperado para o tomador de decisões.\\n•  Os neurocientistas descobriram alguns fatos sobre como a mente trabalha e a forma como ela se\\nassemelha e se diferencia dos computadores.\\n•  Os psicólogos adotaram a ideia de que os seres humanos e os animais podem ser considerados\\nmáquinas de processamento de informações. Os linguistas mostraram que o uso da linguagem se\\najusta a esse modelo.\\n•  Os engenheiros de computação forneceram máquinas cada vez mais poderosas que tornam\\npossíveis as aplicações de IA.\\n•  A teoria de controle lida com o projeto de dispositivos que agem de forma ótima com base no\\nfeedback\\n do ambiente. Inicialmente, as ferramentas matemáticas da teoria de controle eram bem\\ndiferentes da IA, mas os campos estão se tornando mais próximos.\\n•  A história da IA teve ciclos de sucesso, otimismo impróprio e quedas resultantes no entusiasmo\\ne na subvenção. Também houve ciclos de introdução de novas abordagens criativas e de\\naprimoramento sistemático das melhores estratégias.\\n•  A IA avançou mais rapidamente na última década, devido ao uso mais intenso do método\\ncientífico nas experiências e na comparação entre as abordagens.\\n•  O progresso recente na compreensão da base teórica da inteligência caminha lado a lado com os\\navanços na capacidade de sistemas reais. Os subcampos da IA se tornaram mais integrados, e a\\nIA encontrou uma área de concordância com outras disciplinas.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nO \\nstatus\\n metodológico da inteligência artificial é investigado em \\nThe Sciences of the Artificial\\n, de\\nHerb Simon (1981), que descreve áreas de pesquisas relacionadas a artefatos complexos. Ele\\nexplica como a IA pode ser visualizada ao mesmo tempo como ciência e matemática. Cohen (1995)\\napresenta uma visão geral da metodologia experimental dentro da IA.\\nO teste de Turing (Turing, 1950) foi discutido por Shieber (1994), que criticou severamente a\\nutilidade de sua instanciação na competição Loebner Prize, e por Ford e Hayes (1995), que\\nargumentaram que o teste em si não é útil para IA. Bringsjord (2008) deu conselhos para um juiz do\\nteste de Turing. Shieber (2004) e Epstein \\net al.\\n (2008) coletaram uma série de experimentos sobre o\\nteste de Turing. \\nArtificial Intelligence\\n: \\nThe Very Idea\\n de John Haugeland (1985) expõe de forma\\nlúcida os problemas filosóficos e práticos da IA. Trabalhos anteriores significativos de IA estão\\ncompilados nas coleções de Webber e Nilsson (1981) e de Luger (1995). A \\nEncyclopedia of AI\\n(Shapiro, 1992) contém artigos de pesquisa sobre quase todos os tópicos relacionados à IA assim\\ncomo a Wikipédia. Em geral, esses artigos fornecem um bom ponto de partida para o estudo da', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 55}),\n",
       " Document(page_content='literatura de pesquisa sobre cada tópico. Uma criteriosa e abrangente história da IA é fornecida por\\nNils Nillson (2009), um dos primeiros pioneiros nesse campo.\\nO trabalho mais recente aparece nos anais das conferências sobre IA mais importantes: a bienal\\nInternational Joint Conference on AI (IJCAI), a bienal European Conference on AI (ECAI) e a\\nNational Conference on AI, conhecida principalmente como AAAI, que representa a organização que\\na patrocina. Os principais periódicos referentes à IA em geral são \\nArtificial Intelligence,\\nComputational Intelligence\\n, o \\nIEEE Transactions on Pattern Analysis and Machine Intelligence\\n,\\nIEEE Intelligent Systems\\n e a revista eletrônica \\nJournal of Artificial Intelligence Research\\n. Também\\nexistem muitas conferências e periódicos dedicados a áreas específicas, que abordaremos nos\\ncapítulos apropriados. As principais associações profissionais para a IA são a American\\nAssociation for Artificial Intelligence (AAAI), o ACM Special Interest Group in Artificial\\nIntelligence (SIGART) e a Society for Artificial Intelligence and Simulation of Behaviour (AISB). A\\nrevista da AAAI \\nAI Magazine\\n contém muitos artigos sobre tópicos variados e tutoriais, e seu site,\\naaai.org\\n, contém notícias, tutoriais e informações básicas.\\nEXERCÍCIOS\\nEstes exercícios foram planejados para estimular a discussão, e alguns poderiam ser definidos\\ncomo projetos semestrais. Como outra alternativa, podem ser feitas tentativas preliminares para\\nresolvê-los agora, e essas tentativas podem ser revistas após a conclusão da leitura.\\n1.1\\n Defina com suas próprias palavras: (a) inteligência, (b) inteligência artificial, (c) agente, (d)\\nracionalidade, (e) raciocínio lógico.\\n1.2\\n Leia o artigo original de Turing sobre IA (Turing, 1950). No artigo ele discute diversas objeções\\nsobre sua iniciativa proposta e seu teste de inteligência. Que objeções ainda exercem influência?\\nSuas refutações ainda são válidas? Você consegue imaginar o surgimento de novas objeções de\\ndesenvolvimento desde que ele escreveu seu artigo? No artigo ele prediz que por volta do ano 2000,\\num computador terá 30% de probabilidade de passar em um teste de Turing de 5 minutos com um\\ninterrogador não especializado. Que chance você acha que um computador teria hoje? E daqui a 50\\nanos?\\n1.3\\n As ações reflexas (como recuar de um fogão quente) são racionais? São inteligentes?\\n1.4\\n Suponha que estendamos o programa ANALOGY de Evans para que possa alcançar 200 em um\\nteste de QI. Dessa forma teríamos um programa mais inteligente que um ser humano? Explique.\\n1.5\\n A estrutura neural da lesma do mar \\nAplysia\\n foi amplamente estudada (primeiro por Eric Kandel,\\nPrêmio Nobel) porque tem apenas cerca de 20 mil neurônios, a maioria deles grandes e facilmente\\nmanipuláveis. Assumindo que o ciclo de tempo para um neurônio da \\nAplysia\\n é praticamente o mesmo\\nde um neurônio humano, como é que a capacidade de processsamento, em termos de atualizações por\\nsegundo da memória, compara-se ao computador de alta capacidade descrito na \\nFigura 1.3\\n?\\n1.6\\n Como a introspecção — o exame que alguém faz de seus próprios pensamentos mais íntimos —\\npoderia ser imprecisa? Eu poderia estar errado sobre aquilo em que estou pensando? Discuta.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 56}),\n",
       " Document(page_content='1.7\\n Até que ponto os sistemas seguintes são instâncias de inteligência artificial?\\n•  Leitores de código de barra de supermercados.\\n•  Menus de voz de telefones.\\n•  Mecanismos de busca na Web.\\n•  Algoritmos de roteamento da Internet que respondem dinamicamente ao estado da rede.\\n1.8\\n Muitos dos modelos computacionais de atividades cognitivas que têm sido propostos envolvem\\noperações matemáticas bastante complexas, como a convolução de uma imagem com o filtro de\\nGauss ou encontrar o mínimo da função de entropia. A maioria dos humanos (e, certamente, todos os\\nanimais) nunca aprende esse tipo de matemática e quase ninguém consegue calcular a convolução de\\numa função de Gauss de cabeça. Que sentido há em dizer que o “sistema de visão” está resolvendo\\nesse tipo de matemática enquanto a pessoa real não tem ideia de como fazê-lo?\\n1.9\\n Por que a evolução tenderia a resultar em sistemas que agem racionalmente? Quais são os\\nobjetivos de projeto de tais sistemas?\\n1.10\\n A IA é uma ciência ou engenharia? Nenhum dos dois ou ambos? Explique.\\n1.11\\n “Sem dúvida, os computadores não podem ser inteligentes — eles só podem fazer o que seus\\nprogramadores determinam.” Esta última afirmação é verdadeira e implica a primeira?\\n1.12\\n “Sem dúvida, os animais não podem ser inteligentes — eles só podem fazer o que seus genes\\ndeterminam.” Esta última afirmação é verdadeira e implica a primeira?\\n1.13\\n “Sem dúvida, animais, seres humanos e computadores não podem ser inteligentes — eles só\\npodem fazer o que seus átomos constituintes determinam, de acordo com as leis da física.” Esta\\núltima afirmação é verdadeira e implica a primeira?\\n1.14\\n Examine a literatura de IA para descobrir se as seguintes tarefas podem realmente ser\\nresolvidas por computadores:\\na.\\n Jogar um jogo decente de tênis de mesa (pingue-pongue).\\nb.\\n Dirigir no centro do Cairo, Egito.\\nc.\\n Dirigir em Victorville, Califórnia.\\nd.\\n Comprar mantimentos para uma semana no mercado.\\ne.\\n Comprar uma semana de mantimentos na Web.\\nf.\\n Jogar um jogo decente de \\nbridge\\n em nível competitivo.\\ng.\\n Descobrir e provar novos teoremas matemáticos.\\nh.\\n Escrever uma história intencionalmente engraçada.\\ni.\\n Dar assessoria jurídica competente em uma área especializada de direito.\\nj.\\n Traduzir inglês falado em sueco falado, em tempo real.\\nk.\\n Executar uma operação cirúrgica complexa.\\nPara as tarefas hoje inviáveis, tentar descobrir quais são as dificuldades e prever quando e se alguma\\nvez serão superadas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 57}),\n",
       " Document(page_content='1.15\\n Vários subcampos da IA realizaram concursos através da definição de uma tarefa-padrão,\\nconvidando os pesquisadores a dar o melhor de si. Os exemplos incluem o DARPA Grand\\nChallenge, para carros robóticos, The International Planning Competition, o futebol robótico\\nRobocup, o evento de recuperação de informação TREC e concursos de tradução automática,\\nreconhecimento de voz. Investigue cinco desses concursos e descreva os progressos realizados ao\\nlongo dos anos. Até que ponto os concursos avançaram o estado da arte em IA? Até que ponto\\ncausaram prejuízo ao campo, retirando energia de novas ideias?\\n1\\n Ao fazermos distinção entre comportamento \\nhumano\\n e \\nracional\\n, não estamos sugerindo que os seres humanos sejam\\nnecessariamente “irracionais” no sentido de “emocionalmente instáveis” ou “insanos”. Simplesmente precisamos observar que não\\nsomos perfeitos: nem todos os jogadores de xadrez são grandes mestres e, infelizmente, nem todos os seres humanos conseguem\\nconceito A nos exames. Alguns erros sistemáticos do raciocínio humano estão catalogados em Kahneman \\net al\\n. (1982).\\n2\\n O \\nNovum Organum\\n é uma atualização do \\nOrganon\\n de Aristóteles, ou instrumento de pensamento. Então, podemos considerar\\nAristóteles tanto empirista quanto racionalista.\\n3\\n Nesse quadro, todas as declarações que fazem sentido podem ser confirmadas ou definidas como falsas por experimentação ou pela\\nanálise do significado das palavras. Por eliminar a maior parte da metafísica, como era sua intenção, o positivismo lógico era impopular\\nem alguns círculos.\\n4\\n Tradução direta do grego Pietro Nasseti, Editora Martin Claret, p. 63.\\n5\\n A notação proposta por Frege para a lógica de primeira ordem — uma combinação enigmática de aspectos textuais e geométricos —\\nnunca se tornou popular.\\n6\\n Desde então, foi descoberto que o musaranho (\\nScandentia\\n) tem alta proporção de cérebro em relação à massa corporal.\\n7\\n Muitos citam Alexander Hood (1824) como possível fonte anterior.\\n8\\n Golgi persistiu em sua convicção de que as funções do cérebro eram executadas principalmente em um meio contínuo no qual os\\nneurônios estavam incorporados, enquanto Cajal propunha a “doutrina neuronal”. Os dois compartilharam o Prêmio Nobel em 1906, mas\\npronunciaram discursos mutuamente antagônicos ao aceitarem o mesmo.\\n9\\n Heath Robinson foi um cartunista famoso por suas representações de aparelhos extravagantes e absurdamente complicados para\\nrealizar tarefas diárias como passar manteiga em torradas.\\n10\\n No período do pós-guerra, Turing queria usar esses computadores em pesquisas de IA — por exemplo, um dos primeiros programas\\nde xadrez (Turing \\net al\\n., 1953). Seus esforços foram bloqueados pelo governo britânico.\\n11\\n Esse foi o primeiro uso oficial do termo de McCarthy, \\ninteligência artificial.\\n Talvez “racionalidade computacional” tivesse sido mais\\npreciso e menos ameaçador, mas “IA” pegou. No 50\\no\\n aniversário da conferência de Dartmouth, McCarthy declarou que resistiu aos\\ntermos “computador” ou “computacional” em deferência a Norbert Weiner, que estava promovendo dispositivos cibernéticos analógicos\\nem vez de computadores digitais.\\n12\\n Agora Carnegie Mellon University (CMU).\\n13\\n Newell e Simon também criaram uma linguagem de processamento de listas, a IPL, para escrever o LT. Eles não tinham nenhum\\ncompilador e fizeram a conversão para código de máquina à mão. Para evitar erros, trabalharam em paralelo, gritando números binários\\num para o outro à medida que escreviam cada instrução, a fim de ter certeza de que os números concordavam.\\n14\\n Em inglês: “the spirit is willing, but the flesh is weak”.\\n15\\n Para evitar embaraços, foi criado um novo campo chamado IKBS (Intelligent Knowledge-Based Systems), porque a IA havia sido\\noficialmente cancelada.\\n16\\n Alguns caracterizaram essa mudança como uma vitória dos \\npuros\\n — aqueles que pensam que as teorias da IA devem se\\nfundamentar no rigor matemático — sobre os \\nimpuros', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 58}),\n",
       " Document(page_content='oficialmente cancelada.\\n16\\n Alguns caracterizaram essa mudança como uma vitória dos \\npuros\\n — aqueles que pensam que as teorias da IA devem se\\nfundamentar no rigor matemático — sobre os \\nimpuros\\n — aqueles que preferem experimentar muitas ideias, escrever alguns programas\\ne depois avaliar o que parece estar funcionando. As duas abordagens são importantes. Um deslocamento em direção à pureza implica', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 58}),\n",
       " Document(page_content='que o campo alcançou um nível de estabilidade e maturidade. Se essa estabilidade será interrompida por uma nova ideia impura é outra\\nquestão.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 59}),\n",
       " Document(page_content='O\\nCAPÍTULO\\n \\n2\\nAgentes inteligentes\\nEm que discutimos a natureza dos agentes, perfeitos ou não, a diversidade de\\nambientes e a consequente variedade de tipos de agentes.\\nCapítulo 1 identificou o conceito de \\nagentes racionais\\n como questão central para nossa\\nabordagem da inteligência artificial. Neste capítulo, tornaremos essa noção mais concreta.\\nVeremos que o conceito de racionalidade pode ser aplicado a uma ampla variedade de agentes\\nque operam em qualquer ambiente imaginável. Nosso plano neste livro é usar esse conceito para\\ndesenvolver um pequeno conjunto de princípios de projeto com a finalidade de construir sistemas de\\nagentes bem-sucedidos — sistemas que possam ser adequadamente chamados \\ninteligentes\\n.\\nComeçaremos examinando agentes, ambientes e o acoplamento entre eles. A observação de que\\nalguns agentes se comportam melhor que outros leva naturalmente à ideia de agente racional — um\\nagente que se comporta tão bem quanto possível. A medida da qualidade do comportamento de um\\nagente depende da natureza do ambiente; alguns ambientes são mais difíceis que outros.\\nApresentaremos uma divisão geral dos ambientes em categorias e mostraremos como as\\npropriedades de um ambiente influenciam o projeto de agentes adequados para esse ambiente.\\nDescreveremos vários “esqueletos” básicos de projetos de agentes que serão utilizados no restante\\ndo livro.\\n2.1 AGENTES E AMBIENTES\\nUm \\nagente\\n é tudo o que pode ser considerado capaz de perceber seu \\nambiente\\n por meio de\\nsensores\\n e de agir sobre esse ambiente por intermédio de \\natuadores\\n. Essa ideia simples é ilustrada\\nna \\nFigura 2.1\\n. Um agente humano tem olhos, ouvidos e outros órgãos como sensores, e tem mãos,\\npernas, boca e outras partes do corpo que servem como atuadores. Um agente robótico pode ter\\ncâmeras e detectores da faixa de infravermelho funcionando como sensores e vários motores como\\natuadores. Um agente de software recebe sequências de teclas digitadas, conteúdo de arquivos e\\npacotes de rede como entradas sensórias e atua sobre o ambiente exibindo algo na tela, escrevendo\\nem arquivos e enviando pacotes de rede.\\n Usamos o termo \\npercepção\\n para fazer referência às entradas perceptivas do agente em um dado\\ninstante. A \\nsequência de percepções\\n do agente é a história completa de tudo o que o agente já', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 61}),\n",
       " Document(page_content='percebeu. Em geral, \\na escolha de ação de um agente em qualquer instante dado pode depender da\\nsequência inteira de percepções recebidas até o momento\\n, mas não de percepções não recebidas.\\nSe pudermos especificar a escolha de ação do agente para toda sequência de percepções possível,\\nteremos dito quase tudo o que existe a dizer sobre o agente. Em termos matemáticos, afirmamos que o\\ncomportamento do agente é descrito pela \\nfunção do agente\\n que mapeia qualquer sequência de\\npercepções específica para uma ação.\\nPodemos imaginar a \\ntabulação\\n da função do agente que descreve qualquer agente dado; para a\\nmaioria dos agentes, o resultado seria uma tabela muito grande — na verdade infinita, a menos que\\nseja definido um limite sobre o comprimento das sequências de percepções que queremos\\nconsiderar. Dado um agente para a realização de experimentos, podemos, em princípio, construir\\nessa tabela tentando todas as sequências de percepções e registrando as ações que o agente executa\\nem resposta.\\n1\\n É claro que a tabela é uma caracterização \\nexterna\\n do agente. \\nInternamente\\n, a função\\ndo agente para um agente artificial será implementada pelo \\nprograma do agente\\n. É importante\\nmanter essas duas ideias distintas. A função de agente é uma descrição matemática abstrata; o\\nprograma do agente é uma implementação concreta, executada em um sistema físico.\\nPara ilustrar essas ideias, usaremos um exemplo muito simples — o mundo de aspirador de pó\\nilustrado na \\nFigura 2.2\\n. Esse mundo é tão simples que podemos descrever tudo o que acontece; ele\\ntambém é um mundo inventado e, portanto, podemos criar muitas variações. Esse mundo particular\\ntem apenas dois locais: os quadrados \\nA\\n e \\nB\\n. O agente aspirador de pó percebe em que quadrado está\\ne se existe sujeira no quadrado. Ele pode optar por mover-se para a esquerda, mover-se para a\\ndireita, aspirar a sujeira ou não fazer nada. Uma função do agente muito simples é: se o quadrado\\natual estiver sujo, então aspirar, caso contrário mover-se para o outro quadrado. Uma tabulação\\nparcial da função desse agente é mostrada na \\nFigura 2.3\\n e um programa do agente que o implementa\\naparece na \\nFigura 2.8\\n, página 43.\\nFigura 2.1\\n Agentes interagem com ambientes por meio de sensores e atuadores.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 62}),\n",
       " Document(page_content='Figura 2.2\\n Um mundo de aspirador de pó com apenas dois locais.\\nSequência de percepções\\nAção\\n[\\nA\\n, \\nLimpo\\n]\\n[\\nA\\n, \\nSujo\\n]\\n[\\nB\\n, \\nLimpo\\n]\\n[\\nB\\n, \\nSujo\\n]\\n[\\nA\\n, \\nLimpo\\n], [\\nA\\n, \\nLimpo\\n]\\n[\\nA\\n, \\nLimpo\\n], [\\nA\\n, \\nSujo\\n]\\n.\\n.\\n.\\n[\\nA\\n, \\nLimpo\\n], [\\nA\\n, \\nLimpo\\n], [\\nA\\n, \\nLimpo\\n]\\n[\\nA\\n, \\nLimpo\\n], [\\nA\\n, \\nLimpo\\n], [\\nA\\n, \\nSujo\\n]\\n.\\n.\\n.\\nDireita\\nAspirar\\nEsquerda\\nAspirar\\nDireita\\nAspirar\\n \\nDireita\\nAspirar\\nFigura 2.3\\n Tabulação parcial de uma função de agente simples correspondente ao mundo de\\naspirador de pó mostrado na \\nFigura 2.2\\n.\\nExaminando a \\nFigura 2.3\\n, vemos diversos agentes do mundo de aspirador de pó que podem ser\\ndefinidos simplesmente preenchendo-se de várias maneiras a coluna da direita. Então, a pergunta\\nóbvia é: \\nQual é a maneira correta de preencher a tabela?\\n Em outras palavras, o que torna um\\nagente bom ou ruim, inteligente ou estúpido? Responderemos a essas perguntas na próxima seção.\\nAntes de fecharmos esta seção, enfatizaremos que a noção de um agente deve ser vista como uma\\nferramenta para analisar sistemas, não como uma caracterização absoluta que divide o mundo em\\nagentes e não agentes. Poderíamos visualizar uma calculadora portátil como um agente que escolhe a\\nação de exibir “4” ao receber a sequência de percepções “2 + 2 = ”, mas tal análise dificilmente\\najudaria nossa compreensão da calculadora. De certo modo, todas as áreas de engenharia podem ser\\nvistas como projetar artefatos que interagem com o mundo; a IA opera no que os autores consideram\\nser o final mais interessante do espectro, onde os artefatos têm consideráveis recursos\\ncomputacionais e o ambiente de tarefa requer uma tomada de decisão não trivial.\\n2.2 BOM COMPORTAMENTO: O CONCEITO DE RACIONALIDADE', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 63}),\n",
       " Document(page_content='Um \\nagente racional\\n é aquele que faz tudo certo — em termos conceituais, toda entrada na tabela\\ncorrespondente à função do agente é preenchida de forma correta. É óbvio que fazer tudo certo é\\nmelhor do que fazer tudo errado; porém, o que significa fazer tudo certo?\\nResponderemos a essa antiga questão de uma forma antiquada: considerando as \\nconsequências\\n do\\ncomportamento do agente. Quando um agente é colocado em um ambiente, gera uma sequência de\\nações de acordo com as percepções que recebe. Essa sequência de ações faz com que o ambiente\\npasse por uma sequência de estados. Se a sequência for desejável, o agente teve bom desempenho.\\nEssa noção de “desejável” é capturada por uma \\nmedida de desempenho\\n que avalia qualquer\\nsequência dada dos estados do ambiente.\\nObserve que dissemos estados do \\nambiente\\n, não estados do \\nagente\\n. Se definirmos sucesso em\\ntermos da opinião do agente do seu próprio desempenho, um agente poderia alcançar a racionalidade\\nperfeita simplesmente iludindo-se de que seu desempenho foi perfeito. Os agentes humanos em\\nparticular são notórios por ficar com “dor de cotovelo”, acreditando que realmente não queriam\\nalguma coisa (por exemplo, um Prêmio Nobel) depois de não conseguir.\\n Obviamente, não há uma medida de desempenho fixa para todas as tarefas e agentes;\\nnormalmente, um projetista vai desenvolver uma adequada às circunstâncias. Não é tão fácil como\\nparece. Considere, por exemplo, o agente aspirador de pó da seção anterior. Poderíamos propor\\nmedir o desempenho pela quantidade de sujeira aspirada em um único turno de oito horas. É claro\\nque, no caso de um agente racional, você obtém aquilo que solicita. Um agente racional pode\\nmaximizar essa medida de desempenho limpando a sujeira e, em seguida, despejando-a toda no chão,\\ndepois limpando novamente, e assim por diante. Uma medida de desempenho mais apropriada\\nrecompensaria o agente por deixar o chão limpo. Por exemplo, ele poderia ser recompensado por\\ncada quadrado limpo em cada período (talvez com uma penalidade pela eletricidade consumida e\\npelo ruído gerado). \\nComo regra geral\\n, \\né melhor projetar medidas de desempenho de acordo com o\\nresultado realmente desejado no ambiente\\n, \\nem vez de criá-las de acordo com o comportamento\\nesperado do agente\\n.\\nMesmo que as armadilhas óbvias sejam evitadas, ainda existem algumas questões complexas para\\ndesembaraçar. Por exemplo, a noção de “chão limpo” no parágrafo anterior se baseia na limpeza\\nmédia ao longo do tempo. Ainda assim, a mesma limpeza média pode ser alcançada por dois agentes\\ndiferentes, um dos quais faz o trabalho tedioso de limpeza o tempo todo, enquanto o outro limpa\\nenergicamente, mas faz longas pausas. A estratégia preferível pode parecer um detalhe secundário da\\nciência do trabalho doméstico, mas de fato é uma profunda questão filosófica com extensas\\nimplicações. O que é melhor: uma vida aventureira, cheia de altos e baixos, ou uma existência\\nsegura, porém monótona? O que é melhor: uma economia em que todos vivam em pobreza moderada\\nou aquela em que alguns vivem em plena riqueza enquanto outros são muito pobres? Deixaremos\\nessas perguntas como exercício para o leitor.\\n2.2.1 Racionalidade\\nA definição do que é racional em qualquer instante dado depende de quatro fatores:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 64}),\n",
       " Document(page_content='•  A medida de desempenho que define o critério de sucesso.\\n•  O conhecimento prévio que o agente tem do ambiente.\\n•  As ações que o agente pode executar.\\n•  A sequência de percepções do agente até o momento.\\nIsso conduz a uma \\ndefinição de um agente racional\\n:\\n \\nPara cada sequência de percepções possível\\n, \\num agente racional deve selecionar uma\\nação que se espera venha a maximizar sua medida de desempenho\\n, \\ndada a evidência fornecida\\npela sequência de percepções e por qualquer conhecimento interno do agente\\n.\\nConsidere o agente aspirador de pó simples que limpa um quadrado se ele estiver sujo e passa\\npara o outro quadrado se o primeiro não estiver sujo; essa é a função do agente tabulada na \\nFigura\\n2.3\\n. Esse é um agente racional? Depende! Primeiro, precisamos dizer o que é a medida de\\ndesempenho, o que se conhece sobre o ambiente e quais são os sensores e atuadores que o agente\\ntem. Vamos supor que:\\n•  A medida de desempenho ofereça o prêmio de um ponto para cada quadrado limpo em cada\\nperíodo de tempo, ao longo de um “tempo de vida” de 1.000 passos de tempo.\\n•  A “geografia” do ambiente seja conhecida \\na priori\\n (\\nFigura 2.2\\n), mas a distribuição da sujeira e a\\nposição inicial do agente não sejam previamente conhecidas. Quadrados limpos permanecem\\nlimpos, e a aspiração limpa o quadrado atual. As ações \\nEsquerda\\n e \\nDireita\\n movem o agente\\npara a esquerda e para a direita, exceto quando isso leva o agente para fora do ambiente; nesse\\ncaso, o agente permanece onde está.\\n•  As únicas ações disponíveis são \\nEsquerda\\n, \\nDireita\\n e \\nAspirar\\n.\\n•  O agente percebe corretamente sua posição e se essa posição contém sujeira.\\nAfirmamos que, \\nsob essas circunstâncias\\n, o agente é de fato racional; espera-se que seu\\ndesempenho seja pelo menos tão alto quanto o de qualquer outro agente. O Exercício 2.2 lhe pede\\npara provar esse fato.\\nPodemos ver facilmente que o mesmo agente seria irracional sob circunstâncias diferentes. Por\\nexemplo, uma vez que toda a sujeira seja limpa, o agente oscila desnecessariamente de um lado para\\noutro; se a medida de desempenho incluir uma penalidade de um ponto para cada movimento à\\nesquerda ou à direita, o agente ficará em má situação. Um agente melhor para esse caso não faria\\nnada se tivesse certeza de que todos os quadrados estão limpos. Se quadrados limpos puderem ficar\\nsujos novamente, o agente deve ocasionalmente verificar e voltar a limpá-los, se necessário. Se a\\ngeografia do ambiente for desconhecida, o agente precisará explorá-la, em vez de se fixar nos\\nquadrados \\nA\\n e \\nB\\n. O Exercício 2.2 pede para projetar agentes para esses casos.\\n2.2.2 Onisciência, aprendizado e autonomia\\nPrecisamos ter o cuidado de distinguir entre racionalidade e \\nonisciência\\n. Um agente onisciente', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 65}),\n",
       " Document(page_content='sabe o resultado \\nreal\\n de suas ações e pode agir de acordo com ele; porém, a onisciência é\\nimpossível na realidade. Considere o exemplo a seguir: estou caminhando nos Champs Elysées e de\\nrepente vejo um velho amigo do outro lado da rua. Não existe nenhum tráfego perto e não tenho\\nnenhum outro compromisso; assim, sendo racional, começo a atravessar a rua. Enquanto isso, a\\n10.000 metros de altura, a porta do compartimento de carga se solta de um avião\\n2\\n e, antes de chegar\\nao outro lado da rua, sou atingido. Foi irracional atravessar a rua? É improvável que a notícia de\\nminha morte fosse “idiota tenta cruzar rua”.\\nEsse exemplo mostra que racionalidade não é o mesmo que perfeição. A racionalidade maximiza o\\ndesempenho \\nesperado\\n, enquanto a perfeição maximiza o desempenho \\nreal\\n. Fugir à exigência de\\nperfeição não é apenas uma questão de ser justo com os agentes. Se esperarmos que um agente\\nrealize aquela que virá a ser a melhor ação após o fato, será impossível projetar um agente para\\nsatisfazer essa especificação, a menos que melhoremos o desempenho de bolas de cristal ou\\nmáquinas do tempo.\\nPortanto, nossa definição de racionalidade não exige onisciência porque a escolha racional só\\ndepende da sequência de percepções \\naté o momento\\n. Também devemos assegurar que não\\npermitimos que o agente se engaje sem querer em atividades decididamente pouco inteligentes. Por\\nexemplo, se um agente não olhar para os dois lados antes de atravessar uma estrada movimentada,\\nsua sequência de percepções não o informará de que existe um grande caminhão se aproximando em\\nalta velocidade. Nossa definição de racionalidade afirmaria que agora é correto atravessar a\\nestrada? Longe disso! Primeiro, não seria racional atravessar a estrada dada essa sequência de\\npercepções pouco informativa: o risco de acidente resultante de atravessar a estrada sem olhar para\\nos lados é muito grande. Em segundo lugar, um agente racional deveria escolher a ação “olhar” antes\\nde iniciar a travessia porque olhar ajuda a maximizar o desempenho esperado. A realização de ações\\ncom a finalidade de modificar percepções futuras\\n — às vezes chamada \\ncoleta de informações\\n — é\\numa parte importante da racionalidade e é abordada em profundidade no Capítulo 16. Um segundo\\nexemplo de coleta de informações é dado pela \\nexploração\\n que tem de ser empreendida por um\\nagente aspirador de pó em um ambiente inicialmente desconhecido.\\nNossa definição exige um agente racional não apenas para coletar informações, mas também para\\naprender\\n tanto quanto possível a partir do que ele percebe. A configuração inicial do agente poderia\\nrefletir algum conhecimento prévio do ambiente, mas, à medida que o agente ganha experiência, isso\\npode ser modificado e ampliado. Existem casos extremos em que o ambiente é completamente\\nconhecido \\na priori\\n. Em tais casos, o agente não precisa perceber ou aprender; ele simplesmente age\\nde forma correta. É claro que tais agentes são muito frágeis. Considere o humilde besouro de esterco.\\nDepois de cavar seu ninho e depositar os ovos, ele busca uma bola de esterco em um monte próximo\\npara fechar a entrada. Se, \\ndurante o percurso\\n, a bola de esterco for removida de suas garras, o\\nbesouro seguirá em frente e imitará o fechamento do ninho com a bola de esterco inexistente, sem\\nnotar que ela foi retirada. A evolução construiu uma suposição sobre o comportamento do besouro e,\\nquando essa hipótese é violada, resulta um comportamento malsucedido. A vespa Sphex é um pouco\\nmais inteligente. A fêmea da Sphex cava uma cova, sai, pica uma lagarta e a arrasta até a borda da\\ncova, entra novamente na cova para verificar se tudo está bem, arrasta a lagarta para dentro e\\ndeposita seus ovos. A lagarta servirá como alimento quando os ovos eclodirem. Até aqui tudo bem,\\nmas se um entomologista afastar a lagarta algumas polegadas enquanto a fêmea estiver fazendo a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 66}),\n",
       " Document(page_content='verificação, ela voltará à etapa de “arrastar” de seu plano e continuará o plano sem modificação,\\nmesmo depois de dezenas de intervenções de afastamento de lagartas. A Sphex é incapaz de aprender\\nque seu plano inato está falhando e, portanto, não o modificará.\\nQuando um agente se baseia no conhecimento anterior de seu projetista e não em suas próprias\\npercepções, dizemos que o agente não tem \\nautonomia\\n. Um agente racional deve ser autônomo — ele\\ndeve aprender o que puder para compensar um conhecimento prévio parcial ou incorreto. Por\\nexemplo, um agente aspirador de pó que aprende a prever onde e quando aparecerá mais sujeira\\nfuncionará melhor que um agente incapaz de fazer essa previsão. Na prática, raramente se exige\\nautonomia completa desde o início: quando o agente tem pouca ou nenhuma experiência, ele deve\\nagir ao acaso, a menos que o projetista tenha dado a ele alguma assistência. Então, da mesma forma\\nque a evolução fornece aos animais reflexos internos suficientes para que eles possam sobreviver\\npelo tempo necessário para aprenderem por si mesmos, seria razoável fornecer a um agente de\\ninteligência artificial algum conhecimento inicial, bem como habilidade para aprender.\\nDepois de adquirir experiência suficiente sobre seu ambiente, o comportamento de um agente\\nracional pode se tornar efetivamente \\nindependente\\n de seu conhecimento anterior. Em consequência\\ndisso, a incorporação do aprendizado permite projetar um único agente racional que terá sucesso em\\nampla variedade de ambientes.\\n2.3 A NATUREZA DOS AMBIENTES\\nAgora que temos uma definição de racionalidade, estamos quase prontos para pensar em construir\\nagentes racionais. Porém, primeiro devemos pensar em \\nambientes de tarefas\\n, que são\\nessencialmente os “problemas” para os quais os agentes racionais são as “soluções”. Começamos\\nmostrando como especificar um ambiente de tarefa ilustrando o processo com vários exemplos. Em\\nseguida, mostramos que há vários tipos de ambientes de tarefas. O tipo de ambiente de tarefa afeta\\ndiretamente o projeto apropriado para o programa do agente.\\n2.3.1 Especificando o ambiente de tarefa\\nEm nossa discussão sobre a racionalidade do agente aspirador de pó simples, tivemos de\\nespecificar a medida de desempenho, o ambiente e os atuadores e sensores do agente. Agruparemos\\ntodos esses itens sob o título \\nambiente da tarefa\\n. Para os leitores que gostam de acrônimos,\\nchamaremos essa descrição de \\nPEAS\\n (\\nP\\nerformance, \\nE\\nnvironment, \\nA\\nctuators, \\nS\\nensors —\\ndesempenho, ambiente, atuadores, sensores). Ao projetar um agente, a primeira etapa deve ser\\nsempre especificar o ambiente de tarefa de forma tão completa quanto possível.\\nO mundo do aspirador de pó foi um exemplo simples; vamos considerar um problema mais\\ncomplexo: um motorista de táxi automatizado. Utilizaremos esse exemplo em todo o restante do\\ncapítulo. Devemos destacar, antes que o leitor fique alarmado, que um táxi totalmente automatizado\\nno momento está um pouco além da capacidade da tecnologia atual (veja, na página 28, uma\\ndescrição de um robô motorista). A tarefa completa de dirigir é extremamente \\naberta\\n. Não existe', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 67}),\n",
       " Document(page_content='nenhum limite para as novas combinações de circunstâncias que podem surgir — outra razão para\\ntermos escolhido essa tarefa como foco de discussão. A \\nFigura 2.4\\n resume a descrição PEAS para o\\nambiente de tarefa do táxi. Descreveremos cada elemento com mais detalhes nos próximos\\nparágrafos.\\nTipo de\\nagente\\nMedida de\\ndesempenho\\nAmbiente\\nAtuadores\\nSensores\\nMotorista\\nde táxi\\nViagem segura,\\nrápida, dentro da\\nlei, confortável,\\nmaximizar lucros\\nEstradas, outros\\ntipos de\\ntráfego,\\npedestres,\\nclientes\\nDireção,\\nacelerador,\\nfreio, sinal,\\nbuzina, visor\\nCâmeras, sonar,\\nvelocímetro, GPS,\\nhodômetro, acelerômetro,\\nsensores do motor, teclado\\nFigura 2.4\\n Descrição de PEAS do ambiente de tarefa para um táxi automatizado.\\nPrimeiro, que \\nmedida de desempenho\\n gostaríamos que nosso motorista automatizado tivesse\\ncomo objetivo? As qualidades desejáveis incluem chegar ao destino correto, minimizar o consumo\\nde combustível e desgaste, minimizar o tempo e/ou o custo de viagem, minimizar as violações às leis\\nde trânsito e as perturbações a outros motoristas, maximizar a segurança e o conforto dos passageiros\\ne maximizar os lucros. É óbvio que alguns desses objetivos serão conflitantes; então será necessário\\nfazer uma escolha.\\nEm seguida, qual é o \\nambiente\\n de direção que o táxi enfrentará? Qualquer motorista de táxi deve\\nlidar com diversos tipos de estradas, variando desde estradas rurais e avenidas urbanas até rodovias\\ncom 12 pistas. As estradas contêm outros tipos de tráfego, pedestres, animais perdidos, trabalhadores\\nna pista, policiamento, poças e buracos. O táxi também deve interagir com passageiros potenciais e\\nreais. Existem ainda algumas escolhas opcionais. O táxi poderia precisar operar no sul da Califórnia,\\nonde a neve raramente é um problema, ou no Alasca, onde ela normalmente é um problema. Ele\\nsempre poderia estar dirigindo no lado direito da pista ou talvez quiséssemos que ele fosse flexível o\\nbastante para dirigir no lado esquerdo quando estivesse na Inglaterra ou no Japão. É óbvio que,\\nquanto mais restrito o ambiente, mais fácil se torna o problema de projetar.\\nOs \\natuadores\\n para um táxi automatizado incluem aqueles disponíveis para um motorista humano:\\ncontrole sobre o motor através do acelerador e controle sobre a direção e a frenagem. Além disso,\\nele precisará da saída para uma tela de exibição ou um sintetizador de voz para se comunicar com os\\npassageiros e, talvez, de algum meio para se comunicar com outros veículos, de forma educada ou\\nnão.\\nOs \\nsensores\\n básicos do táxi vão incluir uma ou mais câmeras de TV controláveis para que possa\\nobservar a estrada, que podem ser potencializadas com infravermelho ou sensor sonar para detectar\\ndistâncias de outros carros e obstáculos. Para evitar multas por excesso de velocidade, o táxi deverá\\npossuir velocímetro, e, para controlar o veículo de forma correta, especialmente em curvas, deverá\\nter um acelerômetro. Para conhecer o estado mecânico do veículo, será necessário o conjunto\\nhabitual de sensores do motor, combustível e sistema elétrico. Como muitos motoristas humanos,\\npode querer um sistema de posicionamento global por satélite (GPS) para não se perder. Finalmente,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 68}),\n",
       " Document(page_content='ele precisará de um teclado ou microfone para que o passageiro possa solicitar um destino.\\nNa \\nFigura 2.5\\n, esboçamos os elementos básicos do PEAS para diversos tipos de agentes.\\nExemplos adicionais aparecem no Exercício 2.4. Talvez seja surpresa para alguns leitores que a\\nnossa lista de tipos de agentes inclua alguns programas que operam no ambiente completamente\\nartificial definido pela entrada no teclado e pela saída de caracteres em uma tela. Alguém poderia\\ndizer: “Certamente, esse não é um ambiente real, é?” De fato, o que importa não é a distinção entre\\nambientes “reais” e “artificiais”, mas a complexidade do relacionamento entre o comportamento do\\nagente, a sequência de percepções gerada pelo ambiente e a medida de desempenho. Alguns\\nambientes “reais” na realidade são bastante simples. Por exemplo, um robô projetado para\\ninspecionar peças à medida que elas chegam em uma correia transportadora pode fazer uso de uma\\nsérie de suposições simplificadoras: que a iluminação será sempre perfeita, que os únicos itens na\\ncorreia transportadora serão peças de um tipo que ele conhece e que apenas duas ações serão\\npossíveis (aceitar ou rejeitar).\\nTipo de\\nagente\\nMedida de\\ndesempenho\\nAmbiente\\nAtuadores\\nSensores\\nSistema de\\ndiagnóstico\\nmédico\\nPaciente\\nsaudável,\\nminimizar\\ncustos\\nPaciente,\\nhospital,\\nequipe\\nExibir perguntas,\\ntestes, diagnósticos,\\ntratamentos,\\nindicações\\nEntrada pelo teclado\\npara sintomas,\\ndescobertas, respostas\\ndo paciente\\nSistema de\\nanálise de\\nimagens de\\nsatélite\\nDefinição\\ncorreta da\\ncategoria da\\nimagem\\nLink de\\ntransmissão\\nde satélite em\\nórbita\\nExibir a\\ncategorização da\\ncena\\nArrays de pixels em\\ncores\\nRobô de\\nseleção de\\npeças\\nPorcentagem\\nde peças em\\nbandejas\\ncorretas\\nCorreia\\ntransportadora\\ncom peças;\\nbandejas\\nBraço e mão\\narticulados\\nCâmera, sensores\\nangulares articulados\\nControlador\\nde refinaria\\nMaximizar\\npureza,\\nrendimento,\\nsegurança\\nRefinaria,\\noperadores\\nVálvulas, bombas,\\naquecedores,\\nmostradores\\nSensores de temperatura,\\npressão, produtos\\nquímicos\\nInstrutor de\\ninglês\\ninterativo\\nMaximizar\\nnota de aluno\\nem teste\\nConjunto de\\nalunos,\\nambiente de\\ntestes\\nExibir exercícios,\\nsugestões, correções\\nEntrada pelo teclado\\nFigura 2.5\\n Exemplos de tipos de agentes e suas descrições PEAS.\\nEm contraste, existem alguns \\nagentes de software\\n (ou robôs de software ou, ainda, \\nsoftbots\\n) em\\nambientes ricos e ilimitados. Imagine um softbot operador de website, projetado para vasculhar\\nfontes de notícias da Internet e mostrar os itens interessantes a seus clientes, enquanto vende espaço', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 69}),\n",
       " Document(page_content='de publicidade para gerar renda. Para funcionar bem, ele precisará de algumas habilidades de\\nprocessamento de linguagem natural, precisará aprender o que interessa a cada usuário e investidor e\\nterá de mudar seus planos dinamicamente — por exemplo, quando a conexão para uma fonte de\\nnotícias cair ou quando uma nova fonte estiver on-line. A Internet é um ambiente cuja complexidade\\nrivaliza com a do mundo físico e cujos habitantes incluem muitos agentes artificiais e humanos.\\n2.3.2 Propriedades de ambientes de tarefas\\nA variedade de ambientes de tarefas que podem surgir em IA é sem dúvida vasta. Entretanto,\\npodemos identificar um número bastante reduzido de dimensões ao longo das quais os ambientes de\\ntarefas podem ser divididos em categorias. Em grande parte, essas dimensões determinam o projeto\\napropriado de agentes e a aplicabilidade de cada uma das principais famílias de técnicas de\\nimplementação de agentes. Primeiro, listamos as dimensões, depois analisamos vários ambientes de\\ntarefas para ilustrar as ideias. Aqui, as definições são informais; os capítulos posteriores fornecerão\\ndeclarações e exemplos mais precisos de cada tipo de ambiente.\\nCompletamente observável\\n \\nversus\\n \\nparcialmente observável\\n: Se os sensores de um agente\\npermitem acesso ao estado completo do ambiente em cada instante, dizemos que o ambiente de tarefa\\né completamente observável. Um ambiente de tarefa é de fato completamente observável se os\\nsensores detectam todos os aspectos que são \\nrelevantes\\n para a escolha da ação; por sua vez, a\\nrelevância depende da medida de desempenho. Ambientes completamente observáveis são\\nconvenientes porque o agente não precisa manter qualquer estado interno para acompanhar as\\nmudanças do mundo. Um ambiente poderia ser parcialmente observável devido ao ruído e a sensores\\nimprecisos ou porque partes do estado estão simplesmente ausentes nos dados do sensor — por\\nexemplo, um agente aspirador de pó com apenas um sensor de sujeira local não pode saber se há\\nsujeira em outros quadrados, e um táxi automatizado não pode saber o que outros motoristas estão\\npensando. Se o agente não tiver sensores, o ambiente será \\ninobservável\\n. Alguém poderia pensar que,\\nnesses casos, a situação do agente fica desesperadora, mas, como discutiremos no Capítulo 4, os\\nobjetivos do agente ainda poderão ser alcançáveis, e em alguns casos, com certeza.\\nAgente único\\n \\nversus\\n \\nmultiagente:\\n A distinção entre ambientes de agente único e de multiagente\\npode parecer bastante simples. Por exemplo, um agente que resolve um jogo de palavras cruzadas\\nsozinho está claramente em um ambiente de agente único, enquanto um agente que joga xadrez está em\\num ambiente de dois agentes. Porém, existem algumas questões sutis. Primeiro, descrevemos como\\numa entidade \\npode\\n ser visualizada como um agente, mas não explicamos que entidades \\ndevem\\n ser\\nvisualizadas como agentes. Um agente \\nA\\n (por exemplo, o motorista de táxi) tem de tratar um objeto \\nB\\n(outro veículo) como um agente ou ele pode ser tratado apenas como um objeto comportando-se de\\nacordo com as leis da física, análogo às ondas do mar ou às folhas espalhadas pelo vento? A\\ndistinção fundamental é saber se o comportamento de \\nB\\n é ou não melhor descrito como a\\nmaximização de uma medida de desempenho cujo valor depende do comportamento do agente \\nA\\n. Por\\nexemplo, em xadrez, a entidade oponente \\nB\\n está tentando maximizar sua medida de desempenho que,\\npelas regras de xadrez, minimiza a medida de desempenho do agente \\nA\\n. Desse modo, o jogo de\\nxadrez é um ambiente de multiagente \\ncompetitivo\\n. Por outro lado, no ambiente de direção de um táxi,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 70}),\n",
       " Document(page_content='evitar colisões maximiza a medida de desempenho de todos os agentes; assim, esse é um ambiente de\\nmultiagente parcialmente \\ncooperativo\\n. Ele também é parcialmente competitivo porque, por exemplo,\\napenas um carro pode ocupar um espaço no estacionamento. Os problemas de projeto de agentes que\\nsurgem em ambientes de multiagentes muitas vezes são bem diferentes dos que surgem em ambientes\\nde um único agente; por exemplo, a \\ncomunicação\\n com frequência emerge como um comportamento\\nracional em ambientes de multiagentes; em alguns ambientes competitivos parcialmente observáveis,\\no \\ncomportamento aleatório\\n é racional porque evita as armadilhas da previsibilidade.\\nDeterminístico\\n \\nversus\\n \\nestocástico:\\n Se o próximo estado do ambiente é completamente\\ndeterminado pelo estado atual e pela ação executada pelo agente, dizemos que o ambiente é\\ndeterminístico; caso contrário, ele é estocástico. Em princípio, um agente não precisa se preocupar\\ncom a incerteza em um ambiente completamente observável e determinístico. (Na nossa definição,\\nignoramos a incerteza que surge exclusivamente das ações de outros agentes em um ambiente\\nmultiagente; assim, um jogo pode ser determinístico, mesmo sendo cada agente incapaz de predizer\\nas ações dos outros.) Porém, se o ambiente for parcialmente observável, ele poderá \\nparecer\\nestocástico. A maioria das situações reais é tão complexa que é impossível acompanhar todos os\\naspectos não observados; para finalidades práticas devem ser tratados como estocásticos. O\\nmotorista de táxi é claramente estocástico nesse sentido porque nunca se pode prever o\\ncomportamento do tráfego com exatidão; além disso, pode ocorrer o estouro de um pneu e a falha de\\num motor sem aviso prévio. O mundo do aspirador de pó que descrevemos é determinístico, mas as\\nvariações podem incluir elementos estocásticos, como o aparecimento de sujeira ao acaso e um\\nmecanismo de sucção não confiável (Exercício 2.13). Dizemos que um ambiente é incerto se não for\\ntotalmente observável ou determinístico. Observação final: o nosso uso da palavra “estocástico”\\ngeralmente implica que a incerteza sobre os resultados é quantificada em termos de probabilidades;\\num ambiente \\nnão determinístico\\n é aquele em que as ações são caracterizadas por seus resultados\\npossíveis\\n, sem probabilidade associada a ele. As descrições do ambiente não determinístico são\\nnormalmente associadas às medidas de desempenho que exigem que o agente tenha sucesso em \\ntodos\\nos resultados \\npossíveis\\n de suas ações.\\nEpisódico\\n \\nversus\\n \\nsequencial:\\n Em um ambiente de tarefa episódico, a experiência do agente é\\ndividida em episódios atômicos. Em cada episódio, o agente recebe uma percepção e em seguida\\nexecuta uma única ação. É crucial que o episódio seguinte não dependa das ações executadas em\\nepisódios anteriores. Em ambientes episódicos, a escolha da ação em cada episódio só depende do\\npróprio episódio. Muitas tarefas de classificação são episódicas. Por exemplo, um agente que tem de\\nlocalizar peças defeituosas em uma linha de montagem baseia cada decisão na peça atual,\\nindependentemente das decisões anteriores; além disso, a decisão atual não afeta o fato da próxima\\npeça estar ou não com defeito. Por outro lado, em ambientes sequenciais, a decisão atual poderia\\nafetar todas as decisões futuras.\\n3\\n Jogar xadrez e dirigir um táxi são sequenciais: em ambos os casos,\\nações em curto prazo podem ter consequências a longo prazo. Ambientes episódicos são muito mais\\nsimples que ambientes sequenciais porque o agente não precisa pensar à frente.\\nEstático\\n \\nversus\\n \\ndinâmico:\\n Se o ambiente puder se alterar enquanto um agente está deliberando,\\ndizemos que o ambiente é dinâmico para esse agente; caso contrário, ele é estático. Ambientes\\nestáticos são fáceis de manipular porque o agente não precisa continuar a observar o mundo enquanto\\nestá decidindo sobre a realização de uma ação nem precisa se preocupar com a passagem do tempo.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 71}),\n",
       " Document(page_content='Por outro lado, ambientes dinâmicos estão continuamente perguntando ao agente o que ele deseja\\nfazer; se ele ainda não tiver se decidido, isso será considerado a decisão de não fazer nada. Se o\\npróprio ambiente não mudar com a passagem do tempo, mas o nível de desempenho do agente se\\nalterar, diremos que o ambiente é \\nsemidinâmico\\n. O ambiente em que se dirige um táxi é claramente\\ndinâmico: os outros carros e o próprio táxi continuam a se mover enquanto o algoritmo de direção\\nhesita sobre o que fazer em seguida. O jogo de xadrez, quando jogado com a contagem do tempo, é\\nsemidinâmico. O jogo de palavras cruzadas é estático.\\nDiscreto\\n \\nversus\\n \\ncontínuo:\\n A distinção entre discreto e contínuo aplica-se ao \\nestado\\n do ambiente,\\nao modo como o \\ntempo\\n é tratado, e ainda às \\npercepções\\n e \\nações\\n do agente. Por exemplo, um\\nambiente de jogo de xadrez tem um número finito de estados distintos (excluindo o relógio). O xadrez\\ntambém tem um conjunto discreto de percepções e ações. Dirigir um táxi é um problema de estado\\ncontínuo e tempo contínuo: a velocidade e a posição do táxi e dos outros veículos passam por um\\nintervalo de valores contínuos e fazem isso suavemente ao longo do tempo. As ações de dirigir um\\ntáxi também são contínuas (ângulos de rotação do volante etc.). A entrada proveniente de câmeras\\ndigitais é discreta, em termos estritos, mas em geral é tratada como a representação de intensidades e\\nposições que variam continuamente.\\nConhecido\\n \\nversus\\n \\ndesconhecido\\n: Estritamente falando, essa distinção não se refere ao ambiente\\nem si, mas ao estado de conhecimento do agente (ou do projetista) sobre as “leis da física” no meio\\nambiente. Em um ambiente conhecido, são fornecidas as saídas (ou probabilidades das saídas se o\\nambiente for estocástico) para todas as ações. Obviamente, se o ambiente for desconhecido, o agente\\nterá de aprender como funciona, a fim de tomar boas decisões. Observe que a distinção entre os\\nambientes conhecido e desconhecido não é a mesma que entre ambientes totalmente e parcialmente\\nobserváveis. É perfeitamente possível para um ambiente \\nconhecido\\n ser \\nparcialmente\\n observável —\\npor exemplo, em jogos de cartas solitários, eu conheço as regras, mas sou incapaz de ver as cartas\\nque ainda não foram viradas. Por outro lado, um ambiente \\ndesconhecido\\n pode ser \\ntotalmente\\nobservável — em um novo videogame, a tela pode mostrar o estado inteiro do jogo, mas eu ainda\\nnão sei o que os botões fazem até experimentá-los.\\nComo se poderia esperar, o caso mais difícil é \\nparcialmente observável\\n, \\nmultiagente,\\nestocástico\\n, \\nsequencial\\n, \\ndinâmico\\n, \\ncontínuo e desconhecido.\\n Dirigir um táxi é difícil em todos esses\\nsentidos, exceto que para a maioria dos motoristas o ambiente é conhecido. Dirigir um carro alugado\\nem um país desconhecido, com a geografia e de leis de trânsito desconhecidas, é muito mais\\nemocionante.\\nA \\nFigura 2.6\\n lista as propriedades de vários ambientes familiares. Observe que as respostas nem\\nsempre são definitivas. Por exemplo, descrevemos o robô de seleção de peças como episódico\\nporque ele normalmente considera cada peça isoladamente. Mas, se um dia houver um grande lote de\\npeças defeituosas, o robô deverá aprender através de várias observações que a distribuição de\\ndefeitos mudou e deverá modificar o seu comportamento para as peças subsequentes. A coluna\\n“conhecido/desconhecido” não foi incluída porque, como explicado anteriormente, ela não é\\nestritamente uma propriedade do ambiente. Em alguns ambientes, tais como xadrez e pôquer, é muito\\nfácil suprir o agente com pleno conhecimento das regras, mas não deixa de ser interessante\\nconsiderar como um agente poderá aprender a jogar esses jogos sem tal conhecimento.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 72}),\n",
       " Document(page_content='Ambiente de\\ntarefa\\nObservável\\nAgentes\\nDeterminístico\\nEpisódico\\nEstático\\nDiscreto\\nJogo de\\npalavras\\ncruzadas\\nXadrez com um\\nrelógio\\nCompletamente\\nCompletamente\\nÚnico\\nMulti\\nDeterminístico\\nDeterminístico\\nSequencial\\nSequencial\\nEstático\\nSemi\\nDiscreto\\nDiscreto\\nPôquer\\nGamão\\nParcialmente\\nCompletamente\\nMulti\\nMulti\\nEstocástico\\nEstocástico\\nSequencial\\nSequencial\\nEstático\\nEstático\\nDiscreto\\nDiscreto\\nDireção de táxi\\nDiagnóstico\\nmédico\\nParcialmente\\nParcialmente\\nMulti\\nÚnico\\nEstocástico\\nEstocástico\\nSequencial\\nSequencial\\nDinâmico\\nDinâmico\\nContínuo\\nContínuo\\nAnálise de\\nimagens\\nRobô de\\nseleção de\\npeças\\nCompletamente\\nParcialmente\\nÚnico\\nÚnico\\nDeterminístico\\nEstocástico\\nEpisódico\\nEpisódico\\nSemi\\nDinâmico\\nContínuo\\nContínuo\\nControlador de\\nrefinaria\\nInstrutor\\ninterativo de\\ninglês\\nParcialmente\\nParcialmente\\nÚnico\\nMulti\\nEstocástico\\nEstocástico\\nSequencial\\nSequencial\\nDinâmico\\nDinâmico\\nContínuo\\nDiscreto\\nFigura 2.6\\n Exemplos de ambientes de tarefas e suas características.\\nMuitas das respostas na tabela dependem da forma como o ambiente de tarefa é definido. Listamos\\na tarefa de diagnóstico médico como uma tarefa de agente único porque o processo de doença em um\\npaciente não poderia ser modelado de modo proveitoso como um agente; porém, um sistema de\\ndiagnóstico médico também poderia ter de lidar com pacientes obstinados e funcionários céticos e,\\nassim, o ambiente poderia ter um aspecto multiagente. Além disso, o diagnóstico médico é episódico\\nse a tarefa for concebida como a seleção de um diagnóstico dada uma lista de sintomas; o diagnóstico\\nserá sequencial se a tarefa puder incluir a proposição de uma série de testes, a avaliação do\\nprogresso durante o tratamento, e assim por diante. Também há muitos ambientes episódicos em\\nníveis mais altos que as ações individuais do agente. Por exemplo, um torneio de xadrez consiste em\\numa sequência de jogos; cada jogo é um episódio porque (em geral) a contribuição dos movimentos\\nem um jogo para o desempenho global do agente não é afetada pelos movimentos de seu jogo\\nanterior. Por outro lado, a tomada de decisões em um único jogo certamente é sequencial.\\nO repositório de código associado a este livro (aima.cs.berkeley.edu) inclui implementações de\\nvários ambientes, juntamente com um simulador de ambiente de uso geral que coloca um ou mais\\nagentes em um ambiente simulado, observa seu comportamento com o passar do tempo e os avalia de\\nacordo com determinada medida de desempenho. Com frequência, tais experimentos são executados\\nnão para um único ambiente, mas para muitos ambientes extraídos de uma \\nclasse de ambientes\\n. Por', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 73}),\n",
       " Document(page_content='exemplo, avaliar um motorista de táxi em tráfego simulado requer a execução de muitas simulações\\ncom diferentes condições de tráfego, iluminação e condições metereológicas. Se projetássemos o\\nagente para um único cenário, poderíamos tirar proveito de propriedades específicas do caso\\nparticular, mas não poderíamos criar um bom projeto para dirigir de maneira geral. Por essa razão, o\\nrepositório de código também inclui um \\ngerador de ambientes\\n para cada classe de ambientes que\\nseleciona ambientes específicos (com certas variações aleatórias) nos quais seria possível executar\\no agente. Por exemplo, o gerador de ambientes de aspirador de pó inicializa o padrão de sujeira e a\\nposição do agente de forma aleatória. Então, estamos interessados no desempenho médio do agente\\nsobre a classe de ambientes. Um agente racional para dada classe de ambientes maximiza seu\\ndesempenho médio. Os Exercícios 2.8 a 2.13 conduzem o leitor pelo processo de desenvolver uma\\nclasse de ambientes e de avaliar diversos agentes dentro dessa classe.\\n2.4 A ESTRUTURA DE AGENTES\\nAté agora fizemos referência aos agentes descrevendo o \\ncomportamento —\\n a ação executada após\\nqualquer sequência de percepções específica. Agora, teremos de seguir em frente e descrever o\\nfuncionamento interno desses agentes. O trabalho da IA é projetar o \\nprograma do agente\\n que\\nimplementa a função do agente \\n—\\n que mapeia percepções em ações. Supomos que esse programa\\nserá executado em algum tipo de dispositivo de computação com sensores e atuadores físicos —\\nchamamos esse conjunto de \\narquitetura\\n:\\nagente\\n = \\narquitetura\\n + \\nprograma.\\nÉ óbvio que o programa que escolhermos tem de ser apropriado para a arquitetura. Se o programa\\nrecomendar ações como \\nCaminhar\\n, é melhor que a arquitetura tenha pernas. A arquitetura pode ser\\napenas um PC comum ou talvez um carro robótico com diversos computadores, câmeras e outros\\nsensores a bordo. Em geral, a arquitetura torna as percepções dos sensores disponíveis para o\\nprograma, executa o programa e fornece as escolhas de ação do programa para os atuadores à\\nmedida que elas são geradas. A maior parte deste livro trata do projeto de programas de agentes,\\nembora os Capítulos 24 e 25 lidem diretamente com os sensores e atuadores.\\n2.4.1 Programas de agentes\\nOs programas de agentes que projetaremos neste livro têm todos a mesma estrutura básica: eles\\nrecebem a percepção atual como entrada dos sensores e devolvem uma ação para os atuadores.\\n4\\n Note\\na diferença entre o programa do agente, que toma a percepção atual como entrada, e a função do\\nagente, que recebe o histórico de percepções completo. O programa do agente recebe apenas a\\npercepção atual como entrada, uma vez que nada mais está disponível do ambiente; se as ações do\\nagente dependem da sequência de percepções inteira, o agente terá de memorizar as percepções.\\nDescreveremos os programas de agentes por meio da linguagem de pseudocódigo simples definida\\nno Apêndice B (o repositório de código on-line contém implementações em linguagens de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 74}),\n",
       " Document(page_content='programação reais). Por exemplo, a \\nFigura 2.7\\n mostra um programa de agente bastante trivial que\\nacompanha a sequência de percepções e depois a utiliza para realizar a indexação em uma tabela de\\nações, a fim de decidir o que fazer. A tabela — cujo exemplo foi dado para o mundo do aspirador de\\npó na \\nFigura 2.3\\n — representa explicitamente a função do agente que o programa do agente\\nincorpora. Para construir um agente racional desse modo, devemos construir uma tabela que contenha\\na ação apropriada para todas as sequências de percepções possíveis.\\nfunção\\n AGENTE-DIRIGIDO-POR-TABELA(\\npercepção\\n) \\nretorna\\n uma ação\\n    \\nvariáveis estáticas:\\n \\npercepções\\n, uma sequência, inicialmente vazia\\ntabela\\n, uma tabela de ações, indexada por sequências de percepções,\\ninicialmente completamente especificada\\n    anexar \\npercepção\\n ao fim de \\npercepções\\n    \\nação\\n ← ACESSAR(\\npercepções\\n, \\ntabela\\n)\\n    \\nretornar\\n \\nação\\nFigura 2.7\\n O programa AGENTE-DIRIGIDO-POR-TABELA é invocado para cada nova percepção\\ne retorna uma ação de cada vez. Ele mantém a sequência de percepções completas na memória.\\nÉ instrutivo considerar por que a abordagem orientada a tabelas para construção de agentes está\\ncondenada ao fracasso. Seja \\n o conjunto de percepções possíveis e seja \\nT\\n o tempo de duração do\\nagente (o número total de percepções que ele receberá). A tabela de pesquisa conterá \\nentradas. Considere o táxi automatizado: a entrada visual de uma única câmera chega à velocidade de\\naproximadamente 27 megabytes por segundo (30 quadros por segundo, 640 × 480 pixels com 24 bits\\nde informações de cores). Isso nos dá uma tabela de pesquisa com mais de 10\\n250.000.000.000\\n entradas\\npara uma hora de direção. Até mesmo a tabela de pesquisa para o xadrez — um minúsculo e bem-\\ncomportado fragmento do mundo real — teria pelo menos 10\\n150\\n entradas. O tamanho assustador\\ndessas tabelas (o número de átomos no universo observável é menor que 10\\n80\\n) significa que (a)\\nnenhum agente físico nesse universo terá espaço para armazenar a tabela, (b) o projetista não teria\\ntempo para criar a tabela, (c) nenhum agente poderia sequer apreender todas as entradas de tabelas\\ncorretas a partir de sua experiência e (d) mesmo que o ambiente seja simples o bastante para gerar\\numa tabela de tamanho viável, o projetista ainda não terá nenhuma orientação sobre como inserir as\\nentradas da tabela.\\nApesar de tudo isso, o AGENTE-DIRIGIDO-POR-TABELA \\nfaz\\n o que queremos: implementa a\\nfunção de agente desejada. O desafio fundamental da IA é descobrir como escrever programas que,\\nna medida do possível, produzam um comportamento racional a partir de um pequeno programa em\\nvez de uma grande tabela. Temos muitos exemplos mostrando que isso pode ser feito com sucesso em\\noutras áreas: por exemplo, as enormes tabelas de raízes quadradas usadas por engenheiros e por\\nestudantes antes da década de 1970 foram substituídas por um programa de cinco linhas que\\ncorresponde ao método de Newton e é executado em calculadoras eletrônicas. A pergunta é: a IA\\npode fazer pelo comportamento inteligente em geral o que Newton fez para as raízes quadradas?\\nAcreditamos que a resposta seja sim.\\nNo restante desta seção, descreveremos quatro tipos básicos de programas de agentes que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 75}),\n",
       " Document(page_content='incorporam os princípios subjacentes a quase todos os sistemas inteligentes:\\n•  Agentes reativos simples.\\n•  Agentes reativos baseados em modelo.\\n•  Agentes baseados em objetivos.\\n•  Agentes baseados na utilidade.\\nCada tipo de programa de agente combina componentes específicos de maneiras específicas para\\ngerar ações. A \\nSeção 2.4.6\\n explica, em termos gerais, como converter todos esses agentes em\\nagentes de apendizagem\\n que podem melhorar o desempenho de seus componentes de modo a gerar\\nmelhores ações. Finalmente, a \\nSeção 2.4.7\\n descreve uma variedade de maneiras de como os próprios\\ncomponentes podem ser representados dentro do agente. Essa variedade proporciona um princípio\\norganizador fundamental para o campo e para o próprio livro.\\n2.4.2 Agentes reativos simples\\nO tipo mais simples de agente é o \\nagente reativo simples\\n. Esses agentes selecionam ações com\\nbase na percepção \\natual\\n, ignorando o restante do histórico de percepções. Por exemplo, o agente\\naspirador de pó cuja função do agente é tabulada na \\nFigura 2.3\\n é um agente reativo simples porque\\nsua decisão se baseia apenas na posição atual e no fato de essa posição conter ou não sujeira. Um\\nprograma para esse agente é mostrado na \\nFigura 2.8\\n.\\nNote que o programa do agente aspirador de pó na realidade é muito pequeno em comparação com\\na tabela correspondente. A redução mais óbvia vem de se ignorar o histórico de percepções, o que\\nreduz o número de possibilidades de 4\\nT\\n para apenas 4. Uma pequena redução adicional vem do fato\\nde que, quando o quadrado atual está sujo, a ação não depende da posição em que o agente esteja.\\nComportamentos reativos simples ocorrem mesmo em ambientes mais complexos. Imagine-se\\ncomo o motorista do táxi automatizado. Se o carro da frente frear e suas luzes de freio se acenderem,\\nvocê deve notar esse fato e começar a frear. Em outras palavras, algum processamento é realizado de\\nacordo com a entrada visual para estabelecer a condição que chamamos de “O carro da frente está\\nfreando”. Então, isso ativa alguma conexão estabelecida no programa do agente para a ação\\n“começar a frear”. Chamaremos tal conexão de \\nregra condição-ação\\n,\\n5\\n escrita como:\\nse\\n \\ncarro\\n-\\nda\\n-\\nfrente-está-freando\\n \\nentão\\n \\ncomeçar-a\\n-\\nfrear.\\nOs seres humanos também têm muitas dessas conexões, algumas das quais são respostas\\naprendidas (como dirigir) e outras são reflexos inatos (como piscar quando algo se aproxima de seu\\nolho). No decorrer do livro, veremos várias maneiras diferentes de aprender e implementar tais\\nconexões.\\nO programa da \\nFigura 2.8\\n é específico para um determinado ambiente do aspirador de pó. Uma\\nabordagem mais geral e flexível consiste em primeiro construir um interpretador de uso geral para\\nregras condição-ação e depois criar conjuntos de regras para ambientes de tarefas específicos. A\\nFigura 2.9\\n fornece a estrutura desse programa geral em forma esquemática, mostrando como as regras', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 76}),\n",
       " Document(page_content='condição-ação permitem ao agente fazer a conexão entre percepção e ação (não se preocupe com o\\nfato de esse assunto parecer trivial; ele ficará mais interessante em breve). Utilizamos retângulos\\npara denotar o estado interno atual do processo de decisão do agente e elipses para representar as\\ninformações suplementares usadas no processo. O programa do agente, que também é muito simples,\\né mostrado na \\nFigura 2.10\\n. A função INTERPRETAR-ENTRADA gera uma descrição abstrata do\\nestado atual a partir da percepção, e a função REGRA-CORRESPONDENTE retorna a primeira\\nregra no conjunto de regras que corresponde à descrição de estado dada. Observe que a descrição\\nem termos de “regras” e “correspondência” é puramente conceitual; as implementações reais podem\\nser tão simples quanto uma coleção de portas lógicas que implementam um circuito booleano.\\nOs agentes reativos simples têm a admirável propriedade de serem simples, mas se caracterizam\\npor ter inteligência limitada. O agente da \\nFigura 2.10\\n funcionará \\nsomente se a decisão correta puder\\nser tomada com base apenas na percepção atual, ou seja, apenas se o ambiente for completamente\\nobservável\\n. Até mesmo uma pequena impossibilidade de observação pode causar sérias\\ndificuldades. Por exemplo, a regra de frenagem apresentada anteriormente pressupõe que a condição\\ncarro-da-frente\\n-\\nestá\\n-\\nfreando\\n pode ser determinada a partir da percepção atual — um único quadro\\nde vídeo. Funciona se o carro tiver na frente uma luz de freio central. Infelizmente, modelos mais\\nantigos têm configurações diferentes de lanternas, luzes de freio e luzes de setas, e nem sempre é\\npossível saber por uma única imagem se o carro está freando. Um agente reativo simples que\\ndirigisse atrás de um carro desse tipo frearia contínua e desnecessariamente ou, pior ainda, nunca\\nfrearia.\\nfunção\\n AGENTE-ASPIRADOR-DE-PÓ-REATIVO ([\\nposição\\n, \\nsituação\\n]) \\nretorna\\n uma ação*\\n    \\nse\\n \\nsituação\\n \\n=\\n \\nSujo\\n \\nentão retorna\\n \\nAspirar\\n    \\nsenão se\\n \\nposição\\n \\n=\\n \\nA\\n \\nentão retorna\\n \\nDireita\\n    \\nsenão se\\n \\nposição\\n \\n=\\n \\nB\\n \\nentão retorna\\n \\nEsquerda\\nFigura 2.8\\n Programa do agente para um agente reativo simples no ambiente de aspirador de pó de\\ndois estados. Esse programa implementa a função do agente tabulada na \\nFigura 2.3\\n.\\n* \\nNota do revisor técnico:\\n Como aqui se trata de “pseudocódigo”, é possível traduzir os comandos\\npara facilitar a leitura. Apenas não se traduz quando se trata de uma linguagem de programação real.\\nPodemos ver um problema semelhante surgindo no mundo de aspirador de pó. Suponha que um\\nagente aspirador de pó reativo simples seja destituído de seu sensor de posição e tenha apenas um\\nsensor de sujeira. Tal agente tem apenas duas percepções possíveis: [\\nSujo\\n] e [\\nLimpo\\n]. Ele pode\\nAspirar\\n em resposta a [\\nSujo\\n]; o que deve fazer em resposta a [\\nLimpo\\n]? Mover-se para a \\nEsquerda\\nfalhará (sempre) se ele começar no quadrado \\nA\\n, e mover-se para a \\nDireita\\n falhará (sempre) se ele\\ncomeçar no quadrado \\nB\\n. Com frequência, laços de repetição infinitos são inevitáveis no caso de\\nagentes reativos simples operando em ambientes parcialmente observáveis.\\nÉ possível escapar de laços de repetição infinitos se o agente puder tornar suas ações \\naleatórias\\n.\\nPor exemplo, se o agente aspirador de pó perceber [\\nLimpo\\n], ele pode jogar uma moeda para escolher\\nentre \\nEsquerda\\n e \\nDireita\\n. É fácil mostrar que o agente alcançará o outro quadrado usando duas\\netapas em média. Em seguida, se esse quadrado estiver sujo, ele limpará a sujeira e a tarefa de\\nlimpeza será concluída. Consequentemente, um agente reativo simples aleatório poderia superar um', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 77}),\n",
       " Document(page_content='agente reativo simples determinístico.\\nMencionamos na \\nSeção 2.3\\n que um comportamento aleatório do tipo correto pode ser racional em\\nalguns ambientes multiagentes. Em ambientes de um único agente, em geral a aleatoriedade \\nnão\\n é\\nracional. Ela é um artifício útil que ajuda um agente reativo simples em algumas situações, mas, na\\nmaioria dos casos, podemos fazer muito melhor com agentes determinísticos mais sofisticados.\\nFigura 2.9\\n Diagrama esquemático de um agente reativo simples.\\nfunção\\n AGENTE-REATIVO-SIMPLES (\\npercepção\\n) \\nretorna\\n uma ação\\n    \\nvariáveis estáticas:\\n \\nregras\\n, um conjunto de regras condição-ação\\n    \\n    \\nestado\\n ← INTERPRETAR-ENTRADA (\\npercepção\\n)\\n    \\nregra\\n ← REGRA-CORRESPONDENTE (\\nestado\\n, \\nregras\\n)\\n    \\nação\\n ← AÇÃO-DA-REGRA [\\nregra\\n]\\n    \\nretornar\\n \\nação\\nFigura 2.10\\n Um agente reativo simples. Ele age de acordo com uma regra cuja condição corresponde\\nao estado atual definido pela percepção.\\n2.4.3 Agentes reativos baseados em modelos\\nO modo mais efetivo de lidar com a possibilidade de observação parcial é o agente \\nmonitorar a\\nparte do mundo que ele não pode ver agora\\n. Isto é, o agente deve manter algum tipo de \\nestado\\ninterno\\n que dependa do histórico de percepções e assim reflita pelo menos alguns dos aspectos não\\nobservados do estado atual. Para o problema do freio, o estado interno não é muito extenso —\\napenas o quadro anterior da câmera, que permite ao agente detectar quando duas luzes vermelhas na\\nborda do veículo acendem ou apagam ao mesmo tempo. No caso de outras tarefas de direção, como\\ntrocar de pista, o agente precisa monitorar onde os outros carros estão, se não puder vê-los todos de\\numa vez. E, para que qualquer direção seja possível, o agente precisa saber onde as chaves estão.\\nA atualização dessas informações internas de estado à medida que o tempo passa exige que dois', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 78}),\n",
       " Document(page_content='tipos de conhecimento sejam codificados no programa do agente. Primeiro, precisamos de algumas\\ninformações sobre o modo como o mundo evolui independentemente do agente — por exemplo, que\\num carro que estiver ultrapassando em geral estará mais próximo do que estava um momento antes.\\nEm segundo lugar, precisamos de algumas informações sobre como as ações do próprio agente\\nafetam o mundo — de que, por exemplo, quando o agente girar o volante à direita, o carro irá virar\\npara a direita ou de que, depois de dirigir por cinco minutos na direção norte da autoestrada, em\\ngeral ficamos cinco quilômetros ao norte de onde nos encontrávamos cinco minutos antes. Esse\\nconhecimento de “como o mundo funciona” — seja ele implementado em circuitos booleanos simples\\nou em teorias científicas completas — é chamado de \\nmodelo\\n do mundo. Um agente que usa tal\\nmodelo denomina-se \\nagente baseado em modelo\\n.\\nA \\nFigura 2.11\\n fornece a estrutura do agente reativo baseado em modelo com seu estado interno,\\nmostrando como a percepção atual é combinada com o estado interno antigo para gerar a descrição\\natualizada do estado atual, baseado no modelo do agente de como o mundo funciona.\\nFigura 2.11\\n Agente reativo baseado em modelo.\\nO programa de agente é mostrado na \\nFigura 2.12\\n. A parte interessante é a função ATUALIZAR-\\nESTADO, responsável pela criação da descrição do novo estado interno. Os detalhes de como\\nmodelos e estados são representados variam amplamente dependendo do tipo de ambiente e da\\ntecnologia em particular usada no projeto do agente. Nos Capítulos 4, 12, 11, 15, 17 e 25 aparecem\\nexemplos detalhados de modelos e atualização de algoritmos.\\nfunção\\n AGENTE-REATIVO-BASEADO-EM-MODELOS (\\npercepção\\n) \\nretorna\\n uma ação\\n    \\npersistente:\\n \\nestado\\n, a concepção do agente do estado atual do mundo\\nmodelo\\n, uma descrição de como o próximo estado depende do estado atual e da\\nação\\nregras\\n, um conjunto de regras condição-ação\\nação\\n, a ação mais recente, inicialmente nenhuma\\n    \\n    \\nestado\\n ← ATUALIZAR-ESTADO (\\nestado\\n, \\nação\\n, \\npercepção, modelo\\n)\\n    \\nregra\\n ← REGRA-CORRESPONDENTE (\\nestado\\n, \\nregras\\n)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 79}),\n",
       " Document(page_content='ação\\n ← \\nregra, AÇÃO\\n    \\nretornar\\n \\nação\\nFigura 2.12\\n Um agente reativo baseado em modelo. Ele mantém o estado atual do mundo usando um\\nmodelo interno. Em seguida, ele escolhe uma ação da mesma maneira que o agente reativo simples.\\nIndependentemente do tipo de representação utilizada, raramente é possível para o agente\\ndeterminar \\nexatamente\\n o estado atual de um ambiente parcialmente observável\\n.\\n Em vez disso, a\\ncaixa rotulada “como o mundo se parece agora” (\\nFigura 2.11\\n) representa o “melhor palpite” do\\nagente (ou, às vezes, os melhores palpites). Por exemplo, um táxi automatizado pode não ser capaz de\\nenxergar através de um grande caminhão que parou na sua frente e talvez tenha apenas um palpite do\\nque causou o bloqueio. Assim, a incerteza sobre o estado atual pode ser inevitável, mas o agente\\nainda terá que tomar uma decisão.\\nUm ponto talvez menos óbvio sobre o “estado” interno mantido por um agente baseado em modelo\\né que ele não tem que descrever “como o mundo se parece agora” em sentido literal. Por exemplo, o\\ntáxi pode estar dirigindo de volta para casa e pode ser que exista uma regra para colocar gasolina no\\ncaminho de casa se o tanque estiver pelo menos pela metade. Apesar de que “dirigir de volta para\\ncasa” \\nparece\\n um aspecto do estado do mundo, o fato do \\ndestino\\n do táxi é na verdade um aspecto do\\nestado interno do agente. Se você achar isso intrigante, considere que o táxi possa estar exatamente\\nno mesmo lugar ao mesmo tempo, mas com a intenção de chegar a um destino diferente.\\n2.4.4 Agentes baseados em objetivos\\nConhecer algo sobre o estado atual do ambiente nem sempre é suficiente para decidir o que fazer.\\nPor exemplo, em um entroncamento de estradas, o táxi pode virar à esquerda, virar à direita ou seguir\\nem frente. A decisão correta depende de onde o táxi está tentando chegar. Em outras palavras, da\\nmesma forma que o agente precisa de uma descrição do estado atual, ele também precisa de alguma\\nespécie de informação sobre \\nobjetivos\\n que descreva situações desejáveis — por exemplo, estar no\\ndestino do passageiro. O programa de agente pode combinar isso com o modelo (as mesmas\\ninformações que foram usadas no agente reativo baseado em modelo), a fim de escolher ações que\\nalcancem o objetivo. A \\nFigura 2.13\\n mostra a estrutura do agente baseado em objetivos.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 80}),\n",
       " Document(page_content='Figura 2.13\\n Um agente baseado em modelos e orientado pelos objetivos. Ele monitora o estado do\\nmundo, bem como um conjunto de objetivos que está tentando atingir e escolhe uma ação que (no\\nfinal) levará à realização de seus objetivos.\\nÀs vezes, a seleção da ação baseada em objetivos é direta — por exemplo, quando a satisfação do\\nobjetivo resulta de imediato de uma única ação. Outras vezes ela será mais complicada — por\\nexemplo, quando o agente tiver de considerar longas sequências de ações até encontrar um meio de\\natingir o objetivo. \\nBusca\\n (Capítulos 3 a 5) e \\nplanejamento\\n (Capítulos 10 e 11) são as subáreas da\\nIA dedicados a encontrar sequências de ações que alcançam os objetivos do agente.\\nNote que a tomada de decisões desse tipo é fundamentalmente distinta das regras condição-ação\\ndescritas anteriormente, pelo fato de envolver consideração do futuro, tanto de “O que acontecerá se\\neu fizer isso e aquilo?” e “Isso me fará feliz?”. Nos projetos de agentes reativos, essas informações\\nnão são representadas de forma explícita porque as regras internas fazem o mapeamento direto de\\npercepções para ações. O agente reativo freia quando vê luzes de freio. Em princípio, um agente\\nbaseado em objetivos poderia raciocinar que, se o carro da frente tem suas luzes de freio acesas, ele\\ndiminuirá a velocidade. Dada a forma como o mundo costuma evoluir, a única ação que alcançará o\\nobjetivo de não atingir outros carros é frear.\\nEmbora o agente baseado em objetivos pareça menos eficiente, ele é mais flexível porque o\\nconhecimento que apoia suas decisões é representado de maneira explícita e pode ser modificado. Se\\ncomeçar a chover, o agente poderá atualizar seu conhecimento de como seus freios vão operar de\\nmodo eficiente; isso fará todos os comportamentos relevantes serem alterados automaticamente para\\natender às novas condições. Por outro lado, para o agente reativo, teríamos de reescrever muitas\\nregras condição-ação. O comportamento do agente baseado em objetivos pode ser alterado com\\nfacilidade para ir a um destino diferente, simplesmente especificando o destino como objetivo. As\\nregras do agente reativo sobre quando fazer curvas e quando seguir em frente só funcionarão para um\\núnico destino; todas elas terão de ser substituídas se for preciso ir para algum outro lugar.\\n2.4.5 Agentes baseados na utilidade\\nSozinhos, os objetivos não são realmente suficientes para gerar um comportamento de alta', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 81}),\n",
       " Document(page_content='qualidade na maioria dos ambientes. Por exemplo, existem muitas sequências de ações que levarão o\\ntáxi até seu destino (alcançando assim o objetivo), mas algumas são mais rápidas, mais seguras, mais\\nconfiáveis ou mais econômicas que outras. Os objetivos simplesmente permitem uma distinção\\nbinária crua entre “estados felizes” e “infelizes”, enquanto uma medida de desempenho mais geral\\ndeve permitir uma comparação entre diferentes estados do mundo, de acordo com o grau exato de\\nfelicidade que proporcionariam ao agente. Tendo em vista que “feliz” não soa muito científico, em\\nvez disso, economistas e cientistas da computação usam o termo \\nutilidade\\n.\\n6\\nNós já vimos que uma medida de desempenho atribui uma pontuação para qualquer sequência de\\nestados do ambiente, e assim ela pode distinguir facilmente entre formas mais e menos desejáveis de\\nchegar ao destino do táxi. A função \\nutilidade do agente\\n é essencialmente uma internalização da\\nmedida de desempenho. Se a função utilidade interna e a medida externa de desempenho estiverem\\nem acordo, um agente que escolhe ações que maximizem a sua utilidade será racional de acordo com\\na medida de desempenho externa.\\nVamos enfatizar novamente que essa não é a \\núnica\\n maneira de ser racional — já vimos um\\nprograma de agente racional para o mundo do aspirador de pó (\\nFigura 2.8\\n) que não tem ideia de qual\\nseja sua função utilidade, mas, como os agentes baseados em objetivos, um agente baseado em\\nutilidade tem muitas vantagens em termos de flexibilidade e de aprendizagem. Além disso, em dois\\ntipos de casos, os objetivos são inadequados, mas um agente baseado em utilidade ainda pode tomar\\ndecisões racionais. Primeiro, quando houver objetivos conflitantes, apenas alguns dos quais podem\\nser alcançados (por exemplo, velocidade e segurança), a função utilidade especifica a escolha\\napropriada. Segundo, quando há vários objetivos que o agente pode visar e nenhum dos quais pode\\nser alcançado com certeza, a utilidade proporciona uma maneira em que a probabilidade de sucesso\\npode ser pesada em relação à importância dos objetivos. Observabilidade parcial e estocasticidade\\nsão onipresentes no mundo real e assim, portanto, a tomada de decisão sob incerteza. Tecnicamente\\nfalando, um agente racional baseado em utilidade escolhe a ação que maximiza a \\nutilidade esperada\\ndos resultados da ação, isto é, a utilidade que o agente espera obter, em média, dadas as\\nprobabilidades e as utilidades de cada resultado (o Apêndice A define expectativa mais\\nprecisamente). No Capítulo 16, mostraremos que qualquer agente racional deve se comportar \\ncomo\\nse\\n possuísse uma função utilidade cujo valor esperado ele tenta maximizar. Um agente que possui\\numa função utilidade \\nexplícita\\n pode tomar decisões racionais por meio de um algoritmo de uso geral\\nque não depende da função utilidade específica que está sendo maximizada. Desse modo, a definição\\n“global” de racionalidade — designando-se como racionais as funções de agentes que têm o melhor\\ndesempenho — é transformada em uma restrição “local” sobre projetos de agentes racionais que\\npodem ser expressos em um programa simples.\\nA estrutura de agente baseado na utilidade aparece na \\nFigura 2.14\\n. Os programas de agentes\\nbaseados na utilidade são examinados na Parte IV, em que projetamos agentes de tomada de decisões\\nque devem lidar com a incerteza inerente aos ambientes estocásticos ou parcialmente observáveis.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 82}),\n",
       " Document(page_content='Figura 2.14\\n Um agente baseado em modelo e orientado para a utilidade. Ele usa um modelo do\\nmundo juntamente com uma função utilidade que mede suas preferências entre estados do mundo. Em\\nseguida, ele escolhe a ação que leva à melhor utilidade esperada, na qual a utilidade esperada é\\ncalculada pela média entre todos os estados resultantes possíveis, ponderados pela probabilidade do\\nresultado.\\nNeste ponto, o leitor pode estar se perguntando: “É assim tão simples? Construímos agentes que\\nmaximizam a utilidade esperada e pronto?” É verdade que tais agentes são inteligentes, mas não é\\nsimples. Um agente baseado em utilidade tem de modelar e monitorar seu ambiente, tarefas que\\nenvolvem grande quantidade de pesquisas sobre percepção, representação, raciocínio e\\naprendizagem. Os resultados dessa pesquisa preencheram muitos capítulos deste livro. A escolha da\\nmaximização de utilidade do curso da ação também é uma tarefa difícil, exigindo algoritmos\\nengenhosos que preencheram outros vários capítulos. Mesmo com esses algoritmos, geralmente o\\nraciocínio perfeito é inatingível na prática por causa da complexidade computacional, mencionada no\\nCapítulo 1.\\n2.4.6 Agentes com aprendizagem\\nDescrevemos programas de agentes com vários métodos para selecionar ações. Porém, até agora\\nnão explicamos como os programas de agentes \\npassam a existir\\n. Em seu famoso ensaio inicial,\\nTuring (1950) considera a ideia de realmente programar suas máquinas inteligentes à mão. Ele estima\\nquanto trabalho isso poderia exigir e conclui que “algum método mais eficiente parece desejável”. O\\nmétodo que ele propõe é construir máquinas com aprendizagem e depois ensiná-las. Em muitas áreas\\nde IA, esse é agora o método preferencial para se criar sistemas do estado da arte. O aprendizado\\ntem outra vantagem, como observamos antes: ele permite ao agente operar em ambientes inicialmente\\ndesconhecidos e se tornar mais competente do que seu conhecimento inicial sozinho poderia permitir.\\nNesta seção, introduzimos rapidamente as principais ideias de agentes com aprendizagem. Do\\ncomeço ao fim do livro, faremos comentários sobre oportunidades e métodos de aprendizado em\\ntipos específicos de agentes. A Parte V estuda com muito maior profundidade os diversos algoritmos\\nde aprendizado propriamente ditos.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 83}),\n",
       " Document(page_content='Um agente de aprendizado pode ser dividido em quatro componentes conceituais, como mostra a\\nFigura 2.15\\n. A distinção mais importante se dá entre o \\nelemento de aprendizado\\n, responsável pela\\nexecução de aperfeiçoamentos, e o \\nelemento de desempenho\\n, responsável pela seleção de ações\\nexternas. O elemento de desempenho é o que antes consideramos como sendo o agente completo: ele\\nrecebe percepções e decide sobre ações. O elemento de aprendizado utiliza realimentação do \\ncrítico\\nsobre como o agente está funcionando e determina de que maneira o elemento de desempenho deve\\nser modificado para funcionar melhor no futuro.\\nFigura 2.15\\n Um modelo geral de agentes com aprendizagem.\\nO projeto do elemento de aprendizado depende muito do projeto do elemento de desempenho.\\nQuando se tenta projetar um agente que aprende certa capacidade, a primeira pergunta não é “Como\\nfarei com que ele aprenda isso?”, mas “Que tipo de elemento de desempenho meu agente precisará\\nter para fazer isso depois de ter aprendido como fazê-lo?”. Dado um projeto de agente, podem ser\\nconstruídos mecanismos de aprendizado para otimizar cada parte do agente.\\nO crítico informa ao elemento de aprendizado como o agente está se comportando em relação a um\\npadrão fixo de desempenho. O crítico é necessário porque as próprias percepções não oferecem\\nnenhuma indicação do sucesso do agente. Por exemplo, um programa de xadrez poderia receber uma\\npercepção indicando que aplicou um xeque-mate em seu oponente, mas o programa precisa de um\\npadrão de desempenho para saber que isso é algo bom; a percepção em si não diz nada sobre isso. É\\nimportante que o padrão de desempenho seja fixo. Conceitualmente, deveríamos pensar nele como\\nalgo que está totalmente fora do agente porque o agente não deve modificá-lo para ajustá-lo a seu\\npróprio comportamento.\\nO último componente do agente com aprendizagem é o \\ngerador de problemas\\n. Ele é responsável\\npor sugerir ações que levarão a experiências novas e informativas. A questão é que, se o elemento de\\ndesempenho tivesse a possibilidade, ele continuaria a realizar as melhores ações, dadas as\\ninformações que possui. Porém, se o agente estivesse disposto a realizar uma pequena exploração e\\nexecutar algumas ações que talvez não fossem ótimas a curto prazo, ele poderia descobrir ações\\nmuito melhores a longo prazo. A tarefa do gerador de problemas é sugerir essas ações exploratórias.\\nÉ isso que os cientistas fazem quando realizam experiências. Galileu não pensava que soltar pedras\\ndo alto de uma torre em Pisa teria algum valor em si. Ele não estava tentando quebrar as pedras nem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 84}),\n",
       " Document(page_content='modificar o cérebro dos pedestres desafortunados. Seu objetivo era modificar seu próprio cérebro,\\nidentificando uma teoria melhor sobre o movimento dos objetos.\\nPara tornar o projeto global mais concreto, vamos voltar ao exemplo do táxi automatizado. O\\nelemento de desempenho consiste em qualquer coleção de conhecimento e procedimentos que o táxi\\ntem para selecionar suas ações de dirigir. O táxi vai para a estrada e dirige, usando esse elemento de\\ndesempenho. O crítico observa o mundo e repassa informações ao elemento de aprendizado. Por\\nexemplo, depois que o táxi faz uma rápida mudança para a esquerda cruzando três faixas de tráfego, o\\ncrítico observa a linguagem chocante utilizada por outros motoristas. A partir dessa experiência, o\\nelemento de aprendizado é capaz de formular uma regra afirmando que essa foi uma ação ruim, e o\\nelemento de desempenho é modificado pela instalação da nova regra. O gerador de problemas pode\\nidentificar certas áreas de comportamento que necessitam de melhorias e sugerir experimentos, como\\ntestar os freios em diferentes superfícies de rodagem sob condições distintas.\\nO elemento de aprendizado pode fazer mudanças em qualquer dos componentes de “conhecimento”\\nmostrados nos diagramas de agentes (Figuras 2.9, 2.11, 2.13 e 2.14). Os casos mais simples\\nenvolvem o aprendizado direto a partir da sequência de percepções. A observação de pares de\\nestados sucessivos do ambiente pode permitir ao agente aprender “Como o mundo evolui”, e a\\nobservação dos resultados de suas ações pode permitir que ele aprenda “O que minhas ações fazem”.\\nPor exemplo, se o táxi exercer certa pressão nos freios ao dirigir em uma estrada molhada, ele logo\\ndescobrirá qual é a desaceleração realmente alcançada. É claro que essas duas tarefas de\\naprendizado serão mais difíceis se o ambiente for apenas parcialmente observável.\\nAs formas de aprendizado no parágrafo anterior não precisam ter acesso ao padrão de desempenho\\nexterno — de certo modo, o padrão universal é fazer previsões que concordem com a experiência. A\\nsituação é um pouco mais complexa no caso de um agente baseado em utilidade que deseja aprender\\ninformações de utilidade. Por exemplo, suponha que o agente de direção de táxi não receba dos\\npassageiros nenhuma gorjeta porque o táxi sacolejou muito durante a viagem. O padrão de\\ndesempenho externo deve informar ao agente que a falta de gorjetas é uma contribuição negativa para\\nseu desempenho global; desse modo, o agente talvez fosse capaz de aprender que manobras violentas\\nnão contribuem para sua própria utilidade. De certo modo, o padrão de desempenho distingue parte\\nda percepção de entrada como uma \\nrecompensa\\n (ou \\npenalidade\\n) que fornece realimentação direta\\nsobre a qualidade do comportamento do agente. Os padrões de desempenho internos como dor e\\nfome em animais podem ser entendidos desse modo. Essa questão é discutida com maior\\nprofundidade no Capítulo 21.\\nEm resumo, os agentes têm uma variedade de componentes, e esses componentes podem ser\\nrepresentados de muitas formas dentro do programa do agente; dessa forma, parece haver grande\\nvariedade de métodos de aprendizado. No entanto, existe um único tema unificador. O aprendizado\\nem agentes inteligentes pode ser resumido como um processo de modificação de cada componente do\\nagente, a fim de levar os componentes a um acordo mais íntimo com as informações de realimentação\\ndisponíveis, melhorando assim o desempenho global do agente.\\n2.4.7 Como funcionam os componentes do programa de agente', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 85}),\n",
       " Document(page_content='Descrevemos os programas de agente (em termos de muito alto nível) consistindo de vários\\ncomponentes cuja função é responder a perguntas como: “Como o mundo está agora?”, “Que ações\\ndevo tomar?”, “O que minhas ações realizam?”. A próxima pergunta para um estudante de IA é:\\n“Como funcionam esses componentes?” Levará cerca de mil páginas para começar a responder a\\nessas perguntas apropriadamente, mas queremos chamar a atenção do leitor para algumas distinções\\nbásicas entre as várias maneiras como os componentes podem representar o ambiente que o agente\\nhabita.\\nGrosso modo\\n, podemos colocar as representações ao longo de um eixo de complexidade crescente\\ne poder de expressividade — \\natômico\\n, \\nfatorado\\n e \\nestruturado\\n. Para ilustrar essas ideias,\\nconsideremos um componente do agente em particular, como aquele que lida com “O que minhas\\nações realizam”. Esse componente descreve as alterações que podem ocorrer no ambiente como\\nresultado de executar uma ação, e a \\nFigura 2.16\\n fornece descrições esquemáticas de como as\\ntransições devem ser representadas.\\nFigura 2.16\\n Três maneiras de representar os estados e as transições entre eles. (a) Representação\\natômica: um estado (como B ou C) é uma caixa preta, sem estrutura interna. (b) Representação\\nfatorada: um estado consiste em um vetor de valores de atributos; os valores podem ser booleanos,\\nvalores reais ou um conjunto fixo de símbolos. (c) Representação estruturada: um estado inclui\\nobjetos; cada um deles pode ter atributos próprios, bem como relacionamentos com outros objetos.\\nEm uma \\nrepresentação atômica\\n, cada estado do mundo é indivisível — não tem estrutura interna.\\nConsidere o problema de encontrar um caminho de uma extremidade à outra do país através de\\nalguma sequência de cidades (tratamos esse problema na \\nFigura 3.2\\n). Para resolver esse problema,\\npode ser suficiente reduzir o estado do mundo apenas para o nome da cidade em que estamos — um\\núnico átomo de conhecimento; uma “caixa preta”, cuja única propriedade discernível é a de ser\\nidêntico ou diferente de outra caixa preta. Os algoritmos que formam a base de \\nbusca\\n e de \\njogos\\n(Capítulos 3-5), \\nModelos Ocultos de Markov\\n (Capítulo 15) e os \\nprocessos de decisão de Markov\\n(Capítulo 17) trabalham com representações atômicas ou, pelo menos, tratam as representações \\ncomo\\nse\\n fossem atômicas.\\nAgora considere uma descrição de maior fidelidade para o mesmo problema, em que precisamos\\nnos preocupar com mais do que apenas a localização atômica em uma cidade ou outra, talvez sendo\\nnecessário prestar atenção em quanta gasolina há no tanque, nas coordenadas atuais do GPS, se a luz\\nde advertência do óleo está funcionando, quanto temos de troco para o pedágio, que estação está\\ntocando na rádio, e assim por diante. Uma \\nrepresentação fatorada\\n divide cada estado em um', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 86}),\n",
       " Document(page_content='conjunto fixo de \\nvariáveis\\n \\u200b\\u200bou \\natributos\\n, cada um dos quais pode ter um \\nvalor\\n. Enquanto dois estados\\natômicos diferentes não têm nada em comum — são apenas caixas pretas diferentes —, dois estados\\nfatorados diferentes podem compartilhar alguns atributos (como estar em alguma localização GPS\\nespecífica) e não compartilhar outros (como ter muita ou nenhuma gasolina), o que torna muito mais\\nfácil planejar como ir de um estado para o outro. Com representações fatoradas, também se pode\\nrepresentar a \\nincerteza\\n — por exemplo, a ignorância sobre a quantidade de combustível no tanque\\npode ser representada deixando o atributo em branco. Muitas áreas importantes da IA são baseadas\\nem representações fatoradas, incluindo algoritmos de \\nsatisfação de restrição\\n (Capítulo 6), \\nlógica\\nproposicional\\n (Capítulo 7), \\nplanejamento\\n (Capítulos 10 e 11), \\nredes bayesianas\\n (Capítulos 13-16)\\ne algoritmos de \\naprendizado de máquina\\n nos Capítulos 18, 20 e 21. Para muitos propósitos, é\\nnecessário entender que o mundo tem \\ncoisas\\n que estão \\nrelacionadas\\n umas com as outras, não apenas\\nvariáveis com valores. Por exemplo, podemos notar que um grande caminhão à nossa frente está se\\nmovendo em sentido contrário na entrada de carros de uma fazenda de gado leiteiro, mas uma vaca\\nsoltou-se e está bloqueando o caminho do caminhão. É pouco provável que uma representação\\nfatorada esteja pré-definida com o atributo\\nCaminhãoMovendoParaTrásFrenteEntradaFazendaLeiteiraBloqueadoVacaPerdida\\n com valor\\nverdadeiro\\n ou \\nfalso\\n. Em vez disso, precisaríamos de uma \\nrepresentação estruturada\\n, em que\\nobjetos, como vacas e caminhões e seus relacionamentos diversos e variados, possam ser\\nexplicitamente descritos (ver a \\nFigura 2.16\\nc). Representações estruturadas são base de \\nbancos de\\ndados relacionais\\n e \\nlógica de primeira ordem\\n (Capítulos 8, 9 e 12), \\nmodelos de probabilidade de\\nprimeira ordem\\n (Capítulo 14), de \\naprendizagem baseada em conhecimento\\n (Capítulo 19) e grande\\nparte da \\ncompreensão da linguagem natural\\n (Capítulos 22 e 23). Na verdade, quase tudo o que os\\nseres humanos expressam em linguagem natural diz respeito aos objetos e seus relacionamentos.\\nComo mencionamos anteriormente, o eixo ao longo do qual estão as representações atômica,\\nfatorada e estruturada é o eixo de \\nexpressividade\\n crescente. Grosseiramente falando, uma\\nrepresentação mais expressiva pode capturar, pelo menos de forma mais concisa, tudo o que algo\\nmenos expressivo pode capturar e ainda um pouco mais. Muitas vezes, a linguagem mais expressiva é\\nmuito\\n mais concisa; por exemplo, as regras do xadrez podem ser escritas em uma página ou duas de\\numa linguagem com representação estruturada, como lógica de primeira ordem, mas requer milhares\\nde páginas, quando escritas em uma linguagem com representação fatorada, como a lógica\\nproposicional. Por outro lado, o raciocínio e a aprendizagem se tornam mais complexos à medida\\nque aumenta o poder expressivo da representação. Para obter os benefícios das representações\\nexpressivas, evitando as suas limitações, pode ser que para o mundo real os sistemas inteligentes\\nnecessitem operar simultaneamente em todos os pontos ao longo do eixo de expressividade.\\n2.5 RESUMO\\nEste capítulo foi uma espécie de excursão vertiginosa pela IA, que concebemos como a ciência de\\nprojeto de agentes. Aqui estão os pontos importantes a serem lembrados:\\n•  Um \\nagente\\n é algo que percebe e age em um ambiente. A \\nfunção do agente\\n especifica a ação\\nexecutada pelo agente em resposta a qualquer sequência de percepções.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 87}),\n",
       " Document(page_content='•  A \\nmedida de desempenho\\n avalia o comportamento do agente em um ambiente. Um \\nagente\\nracional\\n age para maximizar o valor esperado da medida de desempenho, dada a sequência de\\npercepções recebida até o momento.\\n•  Uma especificação de \\nambiente de tarefa\\n inclui a medida de desempenho, o ambiente externo,\\nos atuadores e os sensores. Ao se projetar um agente, o primeiro passo sempre deve ser\\nespecificar o ambiente de tarefa de maneira tão completa quanto possível.\\n•  Os ambientes de tarefas variam ao longo de diversas dimensões significativas. Eles podem ser\\ncompleta ou parcialmente observáveis, agente único ou multiagente, determinísticos ou\\nestocásticos, episódicos ou sequenciais, estáticos ou dinâmicos, discretos ou contínuos e\\nconhecidos ou desconhecidos.\\n•  O \\nprograma do agente\\n implementa a função do agente. Existe uma variedade de projetos\\nbásicos de programas de agentes, refletindo o tipo de informação explicitada e usada no\\nprocesso de decisão. Os projetos variam em eficiência, síntese e flexibilidade. O projeto\\napropriado do programa do agente depende da natureza do ambiente.\\n•  Os \\nagentes reativos simples\\n respondem diretamente a percepções, enquanto os \\nagentes\\nreativos baseados em modelos\\n mantêm o estado interno para controlar aspectos do mundo que\\nnão estão evidentes na percepção atual. Os \\nagentes baseados em objetivos\\n agem para alcançar\\nseus objetivos, e os \\nagentes baseados em utilidade\\n tentam maximizar sua própria “felicidade”\\nesperada.\\n•  Todos os agentes podem melhorar seu desempenho por meio do \\naprendizado\\n.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nO papel central da ação na inteligência — a noção de raciocínio prático — remonta pelo menos à\\népoca da \\nÉtica a Nicômaco\\n de Aristóteles. O raciocínio prático também foi o assunto do importante\\nartigo de McCarthy (1958), “Programs with Common Sense”. Os campos da robótica e da teoria de\\ncontrole, por sua própria natureza, se preocupam principalmente com a elaboração de agentes\\nfísicos. O conceito de \\ncontrolador\\n em teoria de controle é idêntico ao de um agente em IA. Talvez\\nseja surpreendente o fato de a IA ter se concentrado, durante a maior parte de sua história, em\\ncomponentes de agentes isolados — sistemas de resposta a perguntas, provadores de teoremas,\\nsistemas de visão, e assim por diante — em lugar de agentes completos. A discussão de agentes no\\ntexto de Genesereth e Nilsson (1987) foi uma exceção importante. A visão do agente como um todo é\\nagora extensamente aceita no campo e é tema central em textos recentes (Poole \\net al\\n., 1998; Nilsson,\\n1998); Padgham e Winikoff, 2004; Jones, 2007).\\nO Capítulo 1 identificou as raízes do conceito de racionalidade na filosofia e na economia. Em IA,\\no conceito era de interesse periférico até meados da década de 1980, quando começou a suscitar\\nmuitas discussões sobre os próprios fundamentos técnicos do campo. Um artigo de Jon Doyle (1983)\\npreviu que o projeto de agentes racionais viria a ser a missão central da IA, enquanto outros tópicos\\npopulares acabariam por constituir novas disciplinas.\\nA atenção cuidadosa às propriedades do ambiente e as suas consequências para o projeto de\\nagentes racionais é mais presente na teoria de controle tradicional — por exemplo, sistemas de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 88}),\n",
       " Document(page_content='controle clássicos (Dorf e Bishop, 2004; Kirk, 2004) lidam com ambientes completamente\\nobserváveis e determinísticos; o controle ótimo estocástico (Kumar e Varaiya, 1986; Bertsekas e\\nShreve, 2007) trata de ambientes estocásticos parcialmente observáveis, e o controle híbrido\\n(Henzinger e Sastry, 1998; Cassandras e Lygeros, 2006) lida com ambientes que contêm elementos\\ndiscretos e elementos contínuos. A distinção entre ambientes completa e parcialmente observáveis\\ntambém é central na literatura de \\nprogramação dinâmica\\n desenvolvida na área de pesquisa\\noperacional (Puterman, 1994), que discutiremos no Capítulo 17.\\nOs agentes reativos constituíram o modelo fundamental para psicólogos comportamentais como\\nSkinner (1953), que tentou reduzir a psicologia de organismos a mapeamentos de entrada/saída ou\\nestímulo/resposta. O avanço desde o behaviorismo até o funcionalismo em psicologia, que foi pelo\\nmenos em parte orientado pela aplicação da metáfora de computadores a agentes (Putnam, 1960;\\nLewis, 1966), inseriu no cenário o estado interno do agente. A maioria dos trabalhos relacionados à\\nIA vê a ideia de agentes reativos puros com estado como algo demasiado simples para proporcionar\\ngrande avanço, mas o trabalho de Rosenschein (1985) e Brooks (1986) questionou essa suposição\\n(ver o Capítulo 25). Nos últimos anos, muito trabalho tem sido dedicado à busca de algoritmos\\neficientes para controlar ambientes complexos (Hamscher \\net al\\n., 1992; Simon, 2006). O programa\\nRemote Agent (descrito na página 28) que controlava a espaçonave Deep Space One (descrita na\\npágina 28) é um exemplo particularmente impressionante (Muscettola \\net al\\n., 1998; Jonsson \\net al\\n.,\\n2000).\\nOs agentes baseados em objetivos são previstos em tudo desde a visão de Aristóteles do\\nraciocínio prático até os primeiros artigos de McCarthy sobre a IA baseada em lógica. Shakey the\\nRobot (Fikes e Nilsson, 1971; Nilsson, 1984) foi a primeira materialização robótica de um agente\\nlógico baseado em objetivos. Uma análise lógica completa sobre agentes baseados em objetivos foi\\napresentada em Genesereth e Nilsson (1987), e uma metodologia de programação baseada em\\nobjetivos, denominada programação orientada a agentes, foi desenvolvida por Shoham (1993). A\\nabordagem baseada em agente é hoje extremamente popular na engenharia de software (Ciancarini e\\nWooldridge, 2001). Também se infiltrou na área de sistemas operacionais, onde a \\ncomputação\\nautonômica\\n refere-se a sistemas computacionais e redes que se monitoram e se controlam com um\\nlaço de percepção-ação e métodos de aprendizado de máquina (Kephart e Chess, 2003). Observando\\nque uma coleção de programas de agente projetada para trabalhar juntos em um verdadeiro ambiente\\nmultiagente, necessariamente apresenta modularidade — os programas não compartilham o estado\\ninterno e se comunicam uns com os outros somente através do ambiente —, é comum na área de\\nsistemas multiagentes\\n projetar o programa de agente, de um único agente, como uma coleção de\\nsubagentes autônomos. Em alguns casos, pode até mesmo ser provado que o sistema resultante\\ndevolve as mesmas soluções ótimas que um projeto monolítico.\\nA visão de agentes baseada em objetivos também domina a tradição da psicologia cognitiva na\\nárea de resolução de problemas, começando com o influente trabalho \\nHuman Problem Solving\\n(Newell e Simon, 1972) e passando por todo o trabalho mais recente de Newell (Newell, 1990). Os\\nobjetivos, analisados com maior profundidade como \\ndesejos\\n (gerais) e \\nintenções\\n (atuais), são\\ncentrais para a teoria de agentes desenvolvida por Bratman (1987). Essa teoria tem sido influente\\ntanto para a compreensão da linguagem natural quanto para sistemas multiagentes.\\nHorvitz \\net al\\n. (1988) sugerem especificamente o uso da racionalidade concebida como a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 89}),\n",
       " Document(page_content='maximização da utilidade esperada, como base para a IA. O texto de Pearl (1988) foi o primeiro em\\nIA a abordar em profundidade a teoria de probabilidade e utilidade; sua exposição de métodos\\npráticos para raciocínio e tomada de decisões sob incerteza talvez tenha sido o maior fator para a\\nrápida mudança em direção a agentes baseados em utilidade nos anos 1990 (ver a Parte IV).\\nO projeto geral de agentes com aprendizagem representado na \\nFigura 2.15\\n é clássico na literatura\\nde aprendizagem de máquinas (Buchanan \\net al\\n., 1978; Mitchell, 1997). Exemplos do projeto,\\nmaterializados em programas, remontam no mínimo ao programa de aprendizado de Arthur Samuel\\n(1959, 1967) para jogar damas. Os agentes com aprendizagem são descritos em profundidade na\\nParte V.\\nO interesse em agentes e em projeto de agentes cresceu com rapidez nos últimos anos, em parte\\ndevido ao crescimento da Internet e à necessidade percebida de se desenvolver \\nsoftbots\\nautomatizados e móveis (Etzioni e Weld, 1994). Documentos relevantes estão reunidos em \\nReadings\\nin Agents\\n (Huhns e Singh, 1998), e em \\nFoundations of Rational Agency\\n (Wooldridge e Rao, 1999).\\nTextos sobre sistemas multiagentes normalmente fornecem uma boa introdução a muitos aspectos do\\nprojeto de agente (Weiss, 2000a; Wooldridge, 2002). Uma série de conferências dedicadas aos\\nagentes começou nos anos 1990, incluindo o Internacional Workshop on Agent Theories, Archictures\\nand Languages (ATAL), a International Conference on Autonomous Agents (AGENTS) e a\\nInternational Conference on Multi-Agents Systems (ICMAS). Em 2002, essas três se fundiram para\\nformar a International Conference on Autonomous Agents and Multiagent Systems (AAMAS). O\\nperiódico \\nAutonomous Agents and Multi-Agent Systems\\n foi fundado em 1998. Finalmente, \\nDung\\nBeetle Ecology\\n (Hanski e Cambefort, 1991) fornece grande quantidade de informações interessantes\\nsobre o comportamento de besouros de esterco. O YouTube traz gravações de vídeo inspiradas em\\nsuas atividades.\\nEXERCÍCIOS\\n2.1\\n Suponha que a medida de desempenho preocupa-se apenas com os T primeiros passos de tempo\\ndo ambiente e ignora tudo a partir de então. Mostre que a ação de um agente racional depende não\\napenas do estado do ambiente, mas também do passo de tempo que ele alcançou.\\n2.2\\n Vamos examinar a racionalidade de várias funções do agente aspirador de pó.\\na.\\n Mostre que a função do agente aspirador de pó simples descrito na \\nFigura 2.3\\n é realmente\\nracional, conforme as suposições listadas na página 38.\\nb.\\n Descreva uma função de agente racional para o caso em que cada movimento custa um ponto. O\\nprograma de agente correspondente exige estado interno?\\nc.\\n Descreva possíveis projetos de agentes para os casos em que quadrados limpos podem ficar\\nsujos e a geografia do ambiente é desconhecida. Faz sentido para o agente aprender a partir de sua\\nexperiência nessas situações? Em caso afirmativo, o que ele deve aprender? Se não, por quê?\\n2.3\\n Para cada uma das seguintes afirmações, diga se é verdadeiro ou falso e justifique com exemplos\\na sua resposta ou com contraexemplos se for o caso.\\na.\\n Um agente que detecta apenas informações parciais sobre o estado não pode ser perfeitamente', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 90}),\n",
       " Document(page_content='racional.\\nb.\\n Existem ambientes de tarefa nos quais nenhum agente reativo puro pode comportar-se\\nracionalmente.\\nc.\\n Existe um ambiente de tarefa em que todo agente é racional.\\nd.\\n A entrada para o programa de agente é a mesma que a entrada para a função de agente.\\ne.\\n Toda função de agente é implementável por uma combinação de programa/máquina.\\nf.\\n Suponha que um agente selecione sua ação uniformemente ao acaso do conjunto de ações\\npossíveis. Existe um ambiente de tarefa determinista em que esse agente é racional.\\ng.\\n É possível para um dado agente ser perfeitamente racional em dois ambientes de tarefa\\ndistintos.\\nh.\\n Todo agente é racional em um ambiente não observável.\\ni.\\n Um agente jogador de pôquer perfeitamente racional nunca perde.\\n2.4\\n Para cada uma das seguintes atividades, forneça uma descrição PEAS do ambiente da tarefa e\\ncaracterize-o em termos das propriedades listadas na \\nSeção 2.3.2\\n.\\n•  Jogar futebol.\\n•  Explorar os oceanos subterrâneos de Titã.\\n•  Comprar livros usados de I\\u200b\\u200bA na Internet.\\n•  Jogar uma partida de tênis.\\n•  Praticar tênis contra uma parede.\\n•  Realizar um salto de altura.\\n•  Licitações de um item em um leilão.\\n2.5\\n Defina com suas próprias palavras os termos a seguir: agente, função de agente, programa de\\nagente, racionalidade, autonomia, agente reativo, agente baseado em modelo, agente baseado em\\nobjetivos, agente baseado em utilidade, agente com aprendizagem.\\n2.6\\n Este exercício explora as diferenças entre funções de agentes e programas de agentes.\\na.\\n Pode haver mais de um programa de agente que implemente uma dada função de agente? Dê um\\nexemplo ou mostre por que não é possível.\\nb.\\n Existem funções de agente que não podem ser implementadas por qualquer programa de agente?\\nc.\\n Dada uma arquitetura de máquina fixa, cada programa de agente implementa exatamente uma\\nfunção de agente?\\nd.\\n Dada uma arquitetura com \\nn\\n bits de armazenamento, quantos programas de agentes distintos são\\npossíveis nessa arquitetura?\\ne.\\n Suponha manter fixo o programa de agente, mas aumentamos a velocidade da máquina por um\\nfator de dois. Isso muda a função de agente?\\n2.7\\n Escreva programas de agente de pseudocódigo para os agentes baseados em objetivos e em\\nutilidade.\\nTodos os exercícios a seguir estão relacionados à implementação de ambientes e agentes para o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 91}),\n",
       " Document(page_content='mundo de aspirador de pó.\\n2.8\\n Implemente um simulador de ambiente de medição de desempenho para o mundo de aspirador de\\npó representado na \\nFigura 2.2\\n e especificado na página 38. Sua implementação deve ser modular, de\\nforma que os sensores, os atuadores e as características do ambiente (tamanho, forma, localização da\\nsujeira etc.) possam ser alterados com facilidade. (\\nNota:\\n Para algumas opções de linguagens de\\nprogramação e sistemas operacionais, já existem implementações no repositório de código on-line.)\\n2.9\\n Implemente um único agente reflexo para o ambiente de vácuo do Exercício 2.8. Execute o\\nambiente com esse agente para todas as configurações iniciais sujas e localizações do agente\\npossíveis. Registre a nota de desempenho de cada configuração e a nota média global.\\n2.10\\n Considere uma versão modificada do ambiente de aspirador de pó do Exercício 2.8, na qual o\\nagente é penalizado com um ponto para cada movimento.\\na.\\n Um agente reativo simples pode ser perfeitamente racional para esse ambiente? Explique.\\nb.\\n E um agente reativo com estado? Projete tal agente.\\nc.\\n Como suas respostas para os itens \\na\\n e \\nb\\n mudarão se as percepções do agente fornecerem o\\nstatus\\n limpo/sujo de cada quadrado no ambiente?\\n2.11\\n Considere uma versão modificada do ambiente de aspirador de pó do Exercício 2.8, na qual a\\ngeografia do ambiente — extensão, limites e obstáculos — é desconhecida, como também a\\nconfiguração inicial de sujeira (o agente também pode se mover \\nAcima\\n e \\nAbaixo\\n, além de \\nEsquerda\\n e\\nDireita\\n).\\na.\\n Um agente reativo simples pode ser perfeitamente racional para esse ambiente? Explique.\\nb.\\n Um agente reativo simples com uma função de agente \\naleatório\\n pode superar um agente reativo\\nsimples? Projete tal agente e faça a medição de seu desempenho em vários ambientes.\\nc.\\n Você poderia projetar um ambiente no qual seu agente aleatório tenha um desempenho muito\\nruim? Mostre seus resultados.\\nd.\\n Um agente reativo com estado pode superar um agente reativo simples? Projete tal agente e faça\\na medição de seu desempenho em vários ambientes. Você pode projetar um agente racional\\ndesse tipo?\\n2.12\\n Repita o Exercício 2.11 para o caso em que o sensor de posição é substituído por um sensor de\\n“impacto” que detecta as tentativas realizadas pelo agente para se mover para um obstáculo ou cruzar\\nos limites do ambiente. Suponha que o sensor de impacto pare de funcionar; como o agente deverá se\\ncomportar?\\n2.13\\n Os ambientes de aspiradores de pó de todos os exercícios anteriores eram determinísticos.\\nDescreva possíveis programas de agentes para cada uma das versões estocásticas listadas a seguir:\\na.\\n Lei de Murphy: durante 25% do tempo, a ação de \\nAspirar\\n falha ao limpar o chão se ele está sujo\\ne deposita sujeira no chão se ele está limpo. De que maneira seu programa de agente é afetado\\nse o sensor de sujeira fornece a resposta errada durante 10% do tempo?\\nb.\\n Crianças pequenas: em cada período de tempo, cada quadrado limpo tem uma chance de 10%\\nde se tornar sujo. Você poderia apresentar um projeto de agente racional para esse caso?', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 92}),\n",
       " Document(page_content='1\\n Se o agente utilizasse alguma aleatoriedade para escolher suas ações, teríamos de experimentar cada sequência muitas vezes para\\nidentificar a probabilidade de cada ação. Talvez alguém considere a atuação aleatória bastante tola, mas veremos mais adiante, neste\\ncapítulo, que ela pode ser muito inteligente.\\n2\\n Veja N. Henderson, “New door latches urged for Boeing 747 jumbo jets”, \\nWashington Post\\n, 24 de agosto de 1989.\\n3\\n A palavra “sequencial” também é usada em ciência da computação como antônimo de “paralelo”. Os dois significados não têm\\nqualquer correlação.\\n4\\n Existem outras opções para a estrutura do programa do agente; por exemplo, poderíamos fazer os programas dos agentes serem\\ncoprocedimentos\\n que são executados de forma assíncrona com o ambiente. Cada um desses procedimentos tem uma porta de entrada\\ne uma porta de saída, e consiste em um laço que lê a porta de entrada em busca de percepções e grava ações na porta de saída.\\n5\\n Também chamadas \\nregras situação-ação\\n, \\nregras de produção\\n ou \\nregras se-então\\n.\\n6\\n A palavra “utilidade” aqui se refere à “qualidade de ser útil,” não à empresa elétrica ou de rede de água.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 93}),\n",
       " Document(page_content='PARTE II\\nResolução de problemas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 94}),\n",
       " Document(page_content='O\\nCAPÍTULO\\n \\n3\\nResolução de problemas\\npor meio de busca\\nEm que vemos como um agente pode encontrar uma sequência de ações que\\nalcança seus objetivos quando nenhuma ação isolada é capaz de fazê-lo.\\ns agentes mais simples examinados no Capítulo 2 eram os agentes reativos, que baseiam suas\\nações em um mapeamento direto de estados em ações. Tais agentes não podem operar bem em\\nambientes para os quais esse mapeamento seria grande demais para se armazenar e levaria muito\\ntempo para se aprender. Por outro lado, os agentes baseados em objetivos, consideram ações futuras\\ne o quanto seus resultados são desejáveis.\\nEste capítulo descreve um tipo de agente baseado em objetivo chamado \\nagente de resolução de\\nproblemas\\n. Os agentes de resolução de problemas utilizam representações \\natômicas\\n, conforme\\ndescrito na \\nSeção 2.4.7\\n, ou seja, os estados do mundo são considerados como um todo, sem estrutura\\ninterna visível para os algoritmos de resolução de problemas. Os agentes baseados em objetivos que\\nutilizam representações \\nfatoradas\\n ou \\nestruturadas\\n mais avançadas, geralmente são chamados de\\nagentes de planejamento e serão discutidos nos Capítulos 7 e 10.\\nNossa discussão sobre a resolução de problemas começa com uma definição precisa dos\\nproblemas\\n e de suas \\nsoluções\\n e fornece vários exemplos para ilustrar essas definições. Em seguida,\\ndescrevemos vários algoritmos de busca de propósito geral que podem ser utilizados para resolver\\nesses problemas. Veremos diversos algoritmos de busca \\nsem informação\\n — algoritmos para os\\nquais não se fornece nenhuma informação sobre o problema a não ser sua definição. Embora alguns\\ndesses algoritmos possam resolver qualquer problema solucionável, nenhum deles pode fazê-lo de\\nforma eficiente. Os algoritmos de busca \\ninformada\\n, por outro lado, podem ter sucesso a partir de\\nalguma orientação sobre onde procurar soluções.\\nNeste capítulo, nos limitaremos ao tipo mais simples de ambiente de tarefa, para o qual a solução\\npara um problema é sempre uma \\nsequência fixa\\n de ações. O caso mais geral, no qual as ações futuras\\ndo agente podem variar dependendo de percepções futuras, será tratado no Capítulo 4.\\nEste capítulo utiliza os conceitos de complexidade assintótica (isto é, a notação \\nO\\n ()) e NP-\\ncompleteza. Os leitores que não estão familiarizados com esses conceitos deverão consultar o\\nApêndice A.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 96}),\n",
       " Document(page_content='3.1 AGENTES DE RESOLUÇÃO DE PROBLEMAS\\nOs agentes inteligentes devem maximizar sua medida de desempenho. Como mencionamos no\\nCapítulo 2, esse objetivo é às vezes simplificado se o agente pode adotar um \\nobjetivo\\n que deseja\\nsatisfazer. Primeiro, vamos examinar por que e como um agente poderia realizar isso.\\nImagine um agente na cidade de Arad, na Romênia, aproveitando uma viagem de férias. A medida\\nde desempenho do agente contém muitos fatores: ele quer melhorar seu bronzeado, melhorar seu\\nconhecimento do idioma romeno, ver as paisagens, apreciar a vida noturna, evitar ressacas, e assim\\npor diante. O problema de decisão é complexo e envolve muitos compromissos e leitura cuidadosa\\nde guias de viagem. Agora, suponha que o agente tenha uma passagem não reembolsável para partir\\nde Bucareste na manhã seguinte. Nesse caso, faz sentido para o agente adotar o \\nobjetivo\\n de chegar a\\nBucareste. Os cursos de ação que não chegam a Bucareste a tempo podem ser rejeitados sem\\nconsideração adicional, e o problema de decisão do agente fica bastante simplificado. Os objetivos\\najudam a organizar o comportamento, limitando o que o agente está tentando alcançar e,\\nconsequentemente, as ações que ele precisa considerar. \\nA formulação de objetivos\\n, baseada na\\nsituação atual e na medida de desempenho do agente, é o primeiro passo para a resolução de\\nproblemas.\\nVamos considerar que um objetivo seja um conjunto de estados do mundo — exatamente os\\nestados em que o objetivo é satisfeito. A tarefa do agente é descobrir como agir, agora e no futuro,\\npara que atinja o estado objetivo. Antes de poder fazer isso, ele precisa decidir (ou precisamos\\ndecidir por ele) que tipo de ações e estados deveria considerar. Se tentasse considerar ações ao\\nnível de “mover o pé esquerdo para a frente uma polegada” ou “girar o volante um grau para a\\nesquerda”, o agente provavelmente nunca conseguiria sair do estacionamento, quanto mais chegar a\\nBucareste, porque nesse nível de detalhe existe muita incerteza no mundo e haveria muitos passos\\npara se chegar a uma solução. A \\nformulação de problemas\\n é o processo de decidir que ações e\\nestados devem ser considerados, dado um objetivo. Examinaremos mais adiante os detalhes desse\\nprocesso. No momento, vamos supor que o agente vai considerar ações no nível de dirigir desde uma\\ncidade importante até outra. Cada estado corresponderá, portanto, a estar em uma determinada\\ncidade.\\nNosso agente agora adotou o objetivo de dirigir para Bucareste e está considerando para onde ir a\\npartir de Arad. Existem três estradas que saem de Arad, uma em direção a Sibiu, uma para Timisoara\\ne uma para Zerind. Nenhuma delas atinge o objetivo; assim, a menos que o agente esteja muito\\nfamiliarizado com a geografia da Romênia, ele não saberá que estrada deve seguir.\\n1\\n Em outras\\npalavras, o agente não saberá qual das ações possíveis é a melhor porque não conhece ainda o\\nsuficiente sobre o estado que resulta da execução de cada ação. Se o agente não tiver nenhuma\\ninformação adicional, ou seja, se o ambiente for \\ndesconhecido\\n no sentido definido na \\nSeção 2.3\\n, ele\\nnão terá escolha a não ser tentar uma das ações de forma aleatória. Essa triste situação é discutida no\\nCapítulo 4.\\n Porém, suponha que o agente tenha um mapa da Romênia. A finalidade de um mapa é fornecer\\nao agente informações sobre os estados em que ele próprio pode visitar e sobre as ações que ele\\npode executar. O agente pode usar essas informações para considerar estágios \\nsubsequentes\\n de uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 97}),\n",
       " Document(page_content='jornada hipotética passando por cada uma das três cidades, procurando descobrir um percurso que\\neventualmente chegue a Bucareste. Depois de encontrar um caminho no mapa de Arad até Bucareste,\\nele poderá alcançar seu objetivo executando as ações de dirigir que correspondem aos passos da\\nviagem. Em geral, \\num agente com várias opções imediatas de valor desconhecido pode decidir o\\nque fazer examinando primeiro ações futuras que levam eventualmente a estados de valor\\nconhecido.\\nPara ser mais específico sobre o que entendemos por “examinar as ações futuras”, temos que ser\\nmais específicos sobre as propriedades do ambiente, como definido na \\nSeção 2.3\\n. Por ora,\\nassumiremos que o ambiente é \\nobservável\\n, de modo que o agente sempre conhecerá o estado atual.\\nPara o agente dirigir na Romênia, é razoável supor que cada cidade no mapa tenha uma placa\\nindicando o nome da cidade aos motoristas que chegam. Assumiremos também que o ambiente seja\\ndiscreto\\n; assim, em qualquer estado dado, haverá apenas um número finito de ações para escolher.\\nIsso é verdadeiro para a navegação na Romênia, pois cada cidade é conectada a um pequeno número\\nde outras cidades. Supomos que o ambiente seja \\nconhecido\\n; assim, o agente sabe quais estados serão\\nalcançados em cada ação (para problemas de navegação, ter um mapa preciso é suficiente para\\natender a essa condição). Finalmente, assumiremos que o ambiente seja \\ndeterminístico\\n; portanto,\\ncada ação tem exatamente um resultado. Em condições ideais, isso é verdadeiro para o agente na\\nRomênia — significa que, se escolher dirigir de Arad para Sibiu, acabará em Sibiu. Certamente as\\ncondições nem sempre são ideais, como mostraremos no Capítulo 4.\\n \\nSob essas premissas, a solução para qualquer problema é uma sequência fixa de ações.\\n“\\nClaro!”, pode-se dizer, “o que mais poderia ser?” Bem, em geral, poderia ser uma estratégica\\nramificada que recomenda ações diferentes no futuro dependendo das percepções recebidas. Por\\nexemplo, em condições menos que ideais, o agente poderá planejar dirigir de Arad para Sibiu e\\ndepois para Rimnicu Vilcea, mas pode também necessitar de um plano de contingência, caso\\nacidentalmente chegue a Zerind, em vez de em Sibiu. Felizmente, se o agente souber o estado inicial\\ne o ambiente for conhecido e determinístico, saberá exatamente onde estará após a primeira ação e o\\nque vai perceber. Uma vez que, após a primeira ação, é possível receber apenas uma percepção, a\\nsolução poderá especificar apenas uma segunda ação possível, e assim por diante.\\nEsse processo de procurar por tal sequência de ações que alcançam o objetivo é chamado de\\nbusca\\n. Um algoritmo de busca recebe um problema como entrada e devolve uma \\nsolução\\n sob a forma\\nde uma sequência de ações. Depois que uma solução é encontrada, as ações recomendadas podem ser\\nexecutadas. Isso se chama fase de \\nexecução\\n. Desse modo, temos um simples projeto de “formular,\\nbuscar, executar” para o agente, como mostra a \\nFigura 3.1\\n. Depois de formular um objetivo e um\\nproblema a resolver, o agente chama um procedimento de busca para resolvê-lo. Em seguida, ele\\nutiliza a solução para orientar suas ações, fazendo o que a solução recomendar como a próxima ação\\n— em geral, a primeira ação da sequência — e então removendo esse passo da sequência. Depois\\nque a solução for executada, o agente formulará um novo objetivo.\\nObserve que, enquanto o agente está executando a sequência de solução, \\nele ignora sua percepção\\nao escolher uma ação porque sabe com antecedência qual será\\n. Um agente que realiza seus planos\\ncom os olhos fechados, por assim dizer, deve estar completamente certo do que está acontecendo. Os\\nteóricos de controle chamam isso de um sistema de \\nmalha aberta\\n, pois ignorar a percepção quebra o\\nlaço entre o agente e o ambiente.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 98}),\n",
       " Document(page_content='Primeiramente, descreveremos o processo de formulação de problemas e depois dedicaremos a\\nparte principal do capítulo a diversos algoritmos para a função BUSCA. Não discutiremos mais neste\\ncapítulo as funções ATUALIZAR-ESTADO e FORMULAR-PROBLEMAS.\\n3.1.1 Problemas e soluções bem definidos\\nUm \\nproblema\\n pode ser definido formalmente por cinco componentes:\\n•  O \\nestado inicial\\n em que o agente começa. Por exemplo, o estado inicial do nosso agente na\\nRomênia poderia ser descrito como \\nEm\\n(\\nArad\\n).\\nfunção\\n AGENTE-DE RESOLUÇÃO-DE-PROBLEMAS-SIMPLES(percepção) \\nretorna\\n uma \\nação\\n    \\npersistente:\\n \\nseq,\\n uma sequência de ações, inicialmente vazia\\nestado,\\n alguma descrição do estado atual do mundo\\nobjetivo,\\n um objetivo, inicialmente nulo\\nproblema,\\n uma formulação de problema\\n    \\nestado\\n ← ATUALIZAR-ESTADO(\\nestado\\n, \\npercepção)\\n    \\nse\\n \\nseq\\n está vazia \\nentão faça\\n        \\nobjetivo\\n ← FORMULAR-OBJETIVO(\\nestado\\n)\\n        \\nproblema\\n ← FORMULAR-PROBLEMA(\\nestado\\n, \\nobjetivo\\n)\\n        \\nseq\\n ← BUSCA(\\nproblema\\n)\\n        \\nse\\n \\nseq\\n = falhar \\nentão retorne\\n uma ação nula\\n    \\nação\\n ← PRIMEIRO(\\nseq\\n)\\n    \\nseq\\n ← RESTO(\\nseq\\n)\\n    \\nretornar \\nação\\nFigura 3.1\\n Um agente simples de resolução de problemas. Primeiro, ele formula um objetivo e um\\nproblema, busca uma sequência de ações que resolvem o problema e depois executa as ações, uma\\nde cada vez. Quando essa sequência se completa, ele formula outro objetivo e recomeça.\\n•  Uma descrição das \\nações\\n possíveis que estão disponíveis para o agente. Dado um estado\\nparticular \\ns,\\n AÇÕES\\n(s)\\n devolve um conjunto de ações que podem ser executadas em \\ns.\\n Dizemos\\nque cada uma dessas ações é \\naplicável\\n em \\ns.\\n Por exemplo, a partir do estado \\nEm(Arad),\\n as ações\\naplicáveis são: {Ir(\\nSibiu\\n), Ir(\\nTimisoara\\n), Ir(\\nZerind\\n)}.\\n•  Uma descrição do que cada ação faz; o nome formal é \\nmodelo de transição\\n, especificado por\\numa função RESULTADO(\\ns, a\\n) que devolve o estado que resulta de executar uma ação \\na\\n em\\nestado \\ns.\\n Usamos também o termo \\nsucessor\\n para nos referirmos a qualquer estado acessível a\\npartir de determinado estado por uma única ação.\\n2\\n Por exemplo, temos RESULTADO (Em\\n(\\nArad\\n), Ir (\\nZerind\\n)) = Em (\\nZerind\\n). Juntos, o estado inicial, as ações e o modelo de transição\\ndefinem implicitamente o \\nespaço de estados\\n do problema — o conjunto de todos os estados\\nacessíveis a partir do estado inicial, por qualquer sequência de ações. O espaço de estados', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 99}),\n",
       " Document(page_content='forma uma rede dirigida ou um \\ngrafo\\n em que os nós são estados e os arcos entre os nós são\\nações (o mapa da Romênia mostrado na \\nFigura 3.2\\n pode ser interpretado como um grafo do\\nespaço de estados se visualizarmos cada estrada como duas possíveis ações de dirigir, uma para\\ncada sentido). Um \\ncaminho\\n no espaço de estados é uma sequência de estados conectados por\\numa sequência de ações.\\n•  O \\nteste de objetivo\\n, que determina se um estado é um estado objetivo. Às vezes existe um\\nconjunto explícito de estados objetivo possíveis, e o teste simplesmente verifica se o estado\\ndado é um deles. O objetivo do agente na Romênia é o conjunto unitário {Em(\\nBucareste\\n)}.\\nAlgumas vezes, o objetivo é especificado por uma propriedade abstrata, e não por um conjunto\\nde estados explicitamente enumerado. Por exemplo, no xadrez, o objetivo é alcançar um estado\\nchamado “xeque-mate”, em que o rei do oponente está sob ataque e não consegue escapar.\\nFigura 3.2\\n Mapa rodoviário simplificado de parte da Romênia.\\n•  Uma função de \\ncusto de caminho\\n que atribui um custo numérico a cada caminho. O agente de\\nresolução de problemas escolhe uma função de custo que reflete sua própria medida de\\ndesempenho. Para o agente que tenta chegar a Bucareste, o tempo é essencial e, assim, o custo de\\num caminho poderia ser seu comprimento em quilômetros. Neste capítulo, supomos que o custo\\nde um caminho pode ser descrito como a soma dos custos das ações individuais ao longo do\\ncaminho.\\n3\\n O \\ncusto do passo\\n de adotar a ação \\ns\\n para alcançar o estado \\ns´\\n é denotado por \\nc(s, a, s\\n´).\\n Os custos dos passos para a Romênia são mostrados na \\nFigura 3.2\\n como distâncias de rotas.\\nVamos supor que os custos dos passos sejam não negativos.\\n4\\nOs elementos precedentes definem um problema e podem ser reunidos em uma única estrutura de\\ndados que é fornecida como entrada para um algoritmo de resolução de problemas. Uma \\nsolução\\npara um problema é um caminho desde o estado inicial até um estado objetivo. A qualidade da\\nsolução é medida pela função de custo de caminho, e uma \\nsolução ótima\\n tem o menor custo de\\ncaminho entre todas as soluções.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 100}),\n",
       " Document(page_content='3.1.2 Formulação de problemas\\nNa seção anterior, propusemos uma formulação do problema de chegar a Bucareste em termos do\\nestado inicial, ações, modelo de transição, teste de objetivo e custo de caminho. Essa formulação\\nparece razoável, mas é ainda um \\nmodelo\\n — uma descrição matemática abstrata — e não do mundo\\nreal. Compare a descrição do estado simples que escolhemos, \\nEm(Arad),\\n a uma viagem real\\ncruzando o país, em que o estado do mundo inclui muitos itens: os companheiros de viagem, o\\nprograma de rádio atual, a paisagem vista da janela, a proximidade de policiais, a distância até a\\npróxima parada para descanso, as condições da estrada, o tempo, e assim por diante. Todas essas\\nconsiderações são omitidas de nossas descrições de estados porque são irrelevantes para o problema\\nde encontrar uma rota para Bucareste. O processo de remover detalhes de uma representação é\\nchamado \\nabstração\\n.\\nAlém de abstrair a descrição do estado, devemos abstrair as próprias ações. Uma ação de direção\\ntem muitos efeitos. Além de mudar a posição do veículo e de seus ocupantes, ela gasta tempo,\\nconsome combustível, gera poluição e muda o agente (como se costuma dizer, viajar é expandir seus\\nhorizontes). Nossa formulação leva em conta apenas a mudança de posição. Além disso, existem\\nmuitas ações que omitiremos por completo: ligar o rádio, olhar pela janela, diminuir a velocidade ao\\nse aproximar de policiais, e assim por diante. É claro que não especificamos ações no nível de “girar\\no volante um grau para a esquerda”.\\nPodemos ser mais precisos quanto à definição do nível apropriado de abstração? Pense nos\\nestados abstratos e nas ações que escolhemos como correspondentes a grandes conjuntos de estados\\ndetalhados do mundo e sequências detalhadas de ações. Agora, considere uma solução para o\\nproblema abstrato: por exemplo, o caminho de Arad para Sibiu para Rimnicu Vilcea para Pitesti para\\nBucareste. Essa solução abstrata corresponde a um grande número de caminhos mais detalhados.\\nComo exemplo, poderíamos dirigir com o rádio ligado entre Sibiu e Rimnicu Vilcea, e depois\\ndesligá-lo pelo restante da viagem. A abstração será \\nválida\\n se pudermos expandir qualquer solução\\nabstrata em uma solução no mundo mais detalhado; uma condição suficiente é que, para cada estado\\ndetalhado como “em Arad”, existe um caminho detalhado para algum estado como “em Sibiu”, e\\nassim por diante.\\n5\\n A abstração é \\nútil\\n se a execução de cada uma das ações na solução é mais fácil\\nque o problema original; nesse caso, elas são fáceis o bastante para poderem ser executadas sem\\nbusca ou planejamento adicional para qualquer agente de direção. A escolha de uma boa abstração\\nenvolve, portanto, a remoção da maior quantidade possível de detalhes, enquanto se preserva a\\nvalidade e se assegura que as ações abstratas são fáceis de executar. Se não fosse a habilidade de\\nelaborar abstrações úteis, os agentes inteligentes seriam completamente sufocados pelo mundo real.\\n3.2 EXEMPLOS DE PROBLEMAS\\nA abordagem de resolução de problemas é aplicada a uma ampla série de ambientes de tarefas.\\nListamos aqui alguns dos mais conhecidos, fazendo distinção entre \\nproblemas de mundos\\nsimplificados\\n e \\nproblemas do mundo real.\\n Um \\nmundo simplificado\\n se destina a ilustrar ou exercitar\\ndiversos métodos de resolução de problemas. Ele pode ter uma descrição concisa e exata e ser,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 101}),\n",
       " Document(page_content='portanto, utilizável por diferentes pesquisadores para comparar o desempenho dos algoritmos. Um\\nproblema do mundo real\\n é aquele cujas soluções de fato interessam às pessoas. Tais problemas\\ntendem a não apresentar uma única descrição consensual, mas tentaremos dar uma ideia geral de suas\\nformulações.\\n3.2.1 Problemas de mundo simplificado\\nO primeiro exemplo que examinaremos é o mundo do aspirador de pó introduzido inicialmente no\\nCapítulo 2 (veja a \\nFigura 2.2\\n.). Ele pode ser formulado como um problema da seguinte forma:\\n•  \\nEstados\\n: O estado é determinado tanto pela posição do agente como da sujeira. O agente está em\\numa entre duas posições, cada uma das quais pode conter sujeira ou não. Desse modo, há 2 × 2\\n2\\n= 8 estados do mundo possíveis. Um ambiente mais amplo com \\nn\\n posições tem \\nn · 2\\nn\\n estados.\\n•  \\nEstado inicial\\n: Qualquer estado pode ser designado como o estado inicial.\\n•  \\nAções\\n: Nesse ambiente simples, cada estado tem apenas três ações: \\nEsquerda, Direita\\n e\\nAspirar.\\n Ambientes mais amplos podem também incluir \\nEm Cima\\n e \\nEmbaixo.\\n•  \\nModelo de transição\\n: As ações têm seus efeitos esperados, a não ser as ações: mover para a\\nEsquerda\\n no quadrado mais à esquerda, mover para \\na Direita\\n, no quadrado mais à direita, e\\nAspirar\\n, no quadrado limpo, que não tem nenhum efeito. O espaço de estados completo é\\nmostrado na \\nFigura 3.3\\n.\\n•  \\nTeste de objetivo:\\n Verifica se todos os quadrados estão limpos.\\n•  \\nCusto de caminho:\\n Cada passo custa 1 e, assim, o custo do caminho é o número de passos do\\ncaminho.\\nComparado com o mundo real, esse problema de mundo simplificado tem posições discretas,\\nsujeira discreta, limpeza confiável e nunca se torna sujo depois de limpo. No Capítulo 4 relaxaremos\\nalgumas dessas suposições.\\nFigura 3.3\\n O espaço de estados para o mundo do aspirador de pó. Os arcos denotam ações: E =\\nEsquerda\\n, D = \\nDireita\\n, A = \\nAspirar\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 102}),\n",
       " Document(page_content='O \\nquebra-cabeça de oito peças\\n (veja um exemplo na \\nFigura 3.4\\n), consiste de um tabuleiro 3 × 3\\ncom oito peças numeradas e um quadrado vazio. Uma peça adjacente ao quadrado vazio pode\\ndeslizar para esse quadrado. O objetivo é alcançar um estado objetivo especificado, como o do lado\\ndireito da figura. A formulação-padrão é dada por:\\nFigura 3.4\\n Uma instância típica do quebra-cabeça de oito peças.\\n•  \\nEstados:\\n Uma descrição de estado especifica a posição de cada uma das oito peças e do\\nquadrado vazio em um dos nove quadrados.\\n•  \\nEstado inicial\\n: Qualquer estado pode ser designado como o estado inicial. Observe que\\nqualquer objetivo específico pode ser alcançado a partir de exatamente metade dos estados\\niniciais possíveis (Exercício 3.4).\\n•  \\nAções:\\n A formulação mais simples define as ações como movimentos do quadrado vazio\\nEsquerda\\n, \\nDireita\\n, \\nPara Cima ou Para Baixo\\n. Pode haver subconjuntos diferentes desses,\\ndependendo de onde estiver o quadrado vazio.\\n•  \\nModelo de transição\\n: Dado um estado e ação, ele devolve o estado resultante; por exemplo, se\\naplicarmos \\nEsquerda\\n para o estado inicial na \\nFigura 3.4\\n, o estado resultante terá comutado o 5 e\\no branco.\\n•  \\nTeste de objetivo\\n: Verifica se o estado corresponde à configuração de estado objetivo mostrada\\nna \\nFigura 3.4\\n (são possíveis outras configurações de objetivos).\\n•  \\nCusto de caminho\\n: Cada passo custa 1 e,assim, o custo do caminho é o número de passos do\\ncaminho.\\nQue abstrações incluímos aqui? As ações são reduzidas a seus estados iniciais e finais, ignorando-\\nse as posições intermediárias por onde uma peça está deslizando. Abstraímos ações como sacudir o\\ntabuleiro quando as peças ficam presas e descartar a extração das peças com uma faca e colocá-las\\nde volta no tabuleiro. Ficamos com uma descrição das regras do quebra-cabeça, evitando todos os\\ndetalhes de manipulações físicas.\\nO quebra-cabeça de oito peças pertence à família de \\nquebra-cabeças de blocos deslizantes\\n,\\nusados com frequência como problemas de teste para novos algoritmos de busca em IA. Essa família\\né conhecida como NP-completa; assim, ninguém espera encontrar métodos significativamente\\nmelhores no pior caso que os algoritmos de busca descritos neste capítulo e no próximo. O quebra-\\ncabeça de oito peças tem 9!/2 = 181.440 estados acessíveis e é resolvido com facilidade. O quebra-\\ncabeça de 15 peças (em um tabuleiro 4 × 4) tem aproximadamente 1,3 trilhão de estados, e instâncias\\naleatórias podem ser resolvidas de forma ótima em alguns milissegundos pelos melhores algoritmos\\nde busca. O quebra-cabeça de 24 peças (em um tabuleiro 5 × 5) tem cerca de 10\\n25\\n estados, e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 103}),\n",
       " Document(page_content='instâncias aleatórias demandam muitas horas para resolver de forma ótima.\\nO objetivo do \\nproblema de oito rainhas\\n é posicionar oito rainhas em um tabuleiro de xadrez de\\ntal forma que nenhuma rainha ataque qualquer outra (uma rainha ataca qualquer peça situada na\\nmesma linha, coluna ou diagonal). A \\nFigura 3.5\\n mostra uma tentativa de solução que falhou: a rainha\\nna coluna mais à direita é atacada pela rainha do canto superior esquerdo.\\nFigura 3.5\\n Uma quase solução para o problema das oito rainhas (a solução fica como exercício).\\nEmbora existam algoritmos de propósito específico eficientes para esse problema e para toda a\\nfamília de \\nn\\n rainhas, ele continua a ser um problema interessante de teste para algoritmos de busca.\\nHá dois tipos principais de formulações. Uma \\nformulação incremental\\n envolve operadores que\\nampliam\\n a descrição dos estados, iniciando com um estado vazio. Para o problema de oito rainhas,\\nisso significa que cada ação acrescenta uma rainha ao estado. Uma \\nformulação de estados\\ncompletos\\n começa com todas as oito rainhas e as desloca pelo tabuleiro. Em qualquer caso, o custo\\nde caminho não tem nenhum interesse porque apenas o estado final é importante. A primeira\\nformulação incremental que se poderia experimentar é:\\n•  \\nEstados:\\n Qualquer disposição de 0-8 rainhas no tabuleiro é um estado.\\n•  \\nEstado inicial\\n: Nenhuma rainha no tabuleiro.\\n•  \\nAções:\\n Colocar uma rainha em qualquer quadrado vazio.\\n•  \\nModelo de transição:\\n Devolver uma rainha adicionada em qualquer quadrado específico no\\ntabuleiro.\\n•  \\nTeste de objetivo:\\n Oito rainhas estão no tabuleiro e nenhuma é atacada.\\nNessa formulação, temos 64 · 63 · · · 57 ≈ 1,8 × 10\\n14\\n sequências possíveis para investigar. Uma\\nformulação melhor proibiria a colocação de uma rainha em qualquer quadrado que já estiver sob\\nataque:\\n•  \\nEstados:\\n Todas as possíveis disposições de \\nn\\n rainhas (0 ≤ n ≤ 8), uma por coluna nas \\nn\\n colunas\\nmais à esquerda, sem que nenhuma rainha ataque outra.\\n•  \\nAções:\\n Adicione uma rainha a qualquer quadrado na coluna vazia mais à esquerda, de tal modo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 104}),\n",
       " Document(page_content='que ela não seja atacada por qualquer outra rainha.\\nEssa formulação reduz o espaço de estados de oito rainhas de 1,8 × 10\\n14\\n para apenas 2.057, e as\\nsoluções são fáceis de encontrar. Por outro lado, para 100 rainhas, a formulação inicial tem\\naproximadamente 10\\n400\\n estados, enquanto a formulação melhorada tem cerca de 10\\n52\\n estados\\n(Exercício 3.5) — uma grande melhoria, mas não o suficiente para tornar o problema tratável. A\\nSeção 4.1\\n descreve a formulação de estados completos, e o Capítulo 6 apresenta um algoritmo\\nsimples que resolve com facilidade até mesmo o problema de um milhão de rainhas.\\nNosso problema de mundo simplificado final foi inventado por Donald Knuth (1964) e ilustra\\ncomo podem surgir espaços de estados infinitos. Knuth conjecturou que, começando com o número 4,\\numa sequência de fatoriais, raiz quadrada e operações de arredondamento para baixo é possível\\nchegar a qualquer inteiro positivo desejado. Por exemplo, podemos chegar a 5 de 4 da seguinte\\nforma:\\nA definição do problema é muito simples:\\n•  \\nEstados:\\n Números positivos.\\n•  \\nEstado inicial:\\n 4.\\n•  \\nAções:\\n Aplicar fatorial, raiz quadrada ou operação arredondamento para baixo (somente fatorial\\nde números inteiros).\\n•  \\nModelo de transição:\\n Como dado pelas definições matemáticas das operações.\\n•  \\nTeste de objetivo:\\n Estado é o inteiro positivo desejado.\\nDo que sabemos, não há limite do quão grande é um número que pode ser construído no processo\\nde alcançar determinado objetivo, por exemplo, o número 620.448.401.733.239.439.360.000 é\\ngerado na expressão para 5, de modo que o espaço de estados para esse problema é infinito. Tal\\nespaço de estados surge com frequência em tarefas que envolvem a geração de expressões\\nmatemáticas, circuitos, provas, programas e outros objetos definidos de forma recursiva.\\n3.2.2 Problemas do mundo real\\nJá vimos como o \\nproblema de roteamento\\n é definido em termos de posições especificadas e\\ntransições ao longo de ligações entre eles. Uma variedade de aplicativos utiliza algoritmos de\\nroteamento. Alguns, como sites da Web e sistemas para automóveis que fornecem instruções de\\ndireção, são extensões relativamente simples do exemplo da Romênia. Outros, como sistemas de\\nroteamento de fluxos de vídeo em redes de computadores, planejamento de operações militares e\\nplanejamento de viagens aéreas, implicam especificações muito mais complexas. Considere os\\nproblemas de viagens aéreas que devem ser resolvidos através de um site da Web de planejamento\\nde viagem:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 105}),\n",
       " Document(page_content='•  \\nEstados\\n: Cada estado, obviamente, inclui uma posição (por exemplo, um aeroporto) e o tempo\\npresente. Além disso, como o custo de uma ação (um segmento de voo) pode depender de\\nsegmentos anteriores, das suas bases de tarifa e da sua condição de ser nacional ou internacional,\\no estado deverá ter registro de informações adicionais sobre esses aspectos “históricos”.\\n•  \\nEstado inicial\\n: Especificado pela pergunta do usuário.\\n•  \\nAções:\\n Pegar qualquer voo a partir da posição atual, em qualquer classe de assento, partindo\\napós o instante atual, deixando tempo suficiente para translado no aeroporto, se necessário.\\n•  \\nModelo de transição\\n: O estado resultante de pegar um voo terá o destino do voo como a\\nposição atual e a hora de chegada do voo como o instante atual.\\n•  \\nTeste de objetivo\\n: Estamos no destino final especificado pelo usuário?\\n•  \\nCusto do caminho\\n: Ele depende do valor da moeda, do tempo de espera, horário do voo,\\nprocedimentos de imigração e de atendimento ao cliente, qualidade do assento, horário do dia,\\ntipo de avião, milhagem acumulada etc.\\nOs sistemas comerciais de informações para viagens utilizam uma formulação de problema desse\\ntipo, com muitas complicações adicionais para manipular as estruturas bizantinas de tarifas que as\\nempresas aéreas impõem. Porém, qualquer viajante experiente sabe que nem toda viagem aérea\\ntranscorre de acordo com os planos. Um sistema realmente bom deve incluir planos de contingência\\n— como reservas de emergência em voos alternativos — até o ponto em que esses planos possam ser\\njustificados pelo custo e pela probabilidade de fracasso do plano original.\\nOs \\nproblemas de roteiro de viagem\\n estão diretamente relacionados aos problemas de roteamento,\\nmas apresentam uma importante diferença. Por exemplo, considere o problema: “Visitar cada cidade\\nda \\nFigura 3.2\\n pelo menos uma vez, começando e terminando em Bucareste.” Como ocorre com o\\nroteamento, as ações correspondem a viagens entre cidades adjacentes. Porém, o espaço de estados é\\nbastante diferente. Cada estado deve incluir não apenas a posição atual, mas também o \\nconjunto de\\ncidades que o agente visitou\\n. Assim, o estado inicial seria “\\nEm\\n(\\nBucareste\\n),\\nVisitado\\n({\\nBucareste\\n})”, um estado intermediário típico seria “\\nEm\\n(\\nVaslui\\n), \\nVisitado\\n({\\nBucareste\\n,\\nUrziceni,Vaslui\\n})”, e o teste de objetivo verificaria se o agente está em Bucareste e se todas as 20\\ncidades foram visitadas.\\nO \\nproblema do caixeiro-viajante\\n (TSP) é um problema de roteiro de viagem em que cada cidade\\ndeve ser visitada exatamente uma vez. O objetivo é encontrar o percurso \\nmais curto\\n. O problema é\\nconhecido por ser NP-difícil, mas um grande esforço tem sido empregado para melhorar os recursos\\nde algoritmos de TSP. Além de planejar viagens para caixeiros-viajantes, esses algoritmos são\\nusados para tarefas como planejar movimentos de máquinas automáticas para perfuração de placas\\nde circuitos e de máquinas industriais em fábricas.\\nUm problema de \\nleiaute de circuitos eletrônicos VLSI\\n exige o posicionamento de milhões de\\ncomponentes e conexões em um chip para minimizar a área, minimizar retardos de circuitos,\\nminimizar capacitâncias de fuga e maximizar o rendimento industrial. O problema de leiaute vem\\ndepois da fase do projeto lógico, e normalmente se divide em duas partes: \\nleiaute de células\\n e\\nroteamento de canais\\n. No leiaute de células, os componentes primitivos do circuito são agrupados\\nem células, cada uma das quais executa alguma função conhecida. Cada célula tem uma área ocupada\\nfixa (tamanho e forma) e exige um certo número de conexões para cada uma das outras células. O', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 106}),\n",
       " Document(page_content='objetivo é dispor as células no chip de tal forma que elas não se sobreponham e exista espaço para\\nque os fios de conexão sejam colocados entre as células. O roteamento de canais encontra uma rota\\nespecífica para cada fio passando pelos espaços vazios entre as células. Esses problemas de busca\\nsão extremamente complexos, mas sem dúvida vale a pena resolvê-los. Mais adiante neste capítulo,\\napresentaremos alguns algoritmos capazes de solucioná-los.\\nA \\nnavegação de robôs\\n é uma generalização do problema de roteamento descrito anteriormente.\\nEm vez de seguir um conjunto discreto de rotas, um robô pode se mover em um espaço contínuo com\\n(em princípio) um conjunto infinito de ações e estados possíveis. No caso de um robô em movimento\\ncircular sobre uma superfície plana, o espaço é essencialmente bidimensional. Quando o robô tem\\nbraços e pernas ou rodas que também devem ser controlados, o espaço de busca passa a ter várias\\ndimensões. São exigidas técnicas avançadas só para tornar finito o espaço de busca. Examinaremos\\nalguns desses métodos no Capítulo 25. Além da complexidade do problema, robôs reais também\\ndevem lidar com erros nas leituras de seus sensores e nos controles do motor.\\nA \\nsequência automática de montagem\\n de objetos complexos por um robô foi demonstrada\\nprimeiramente por FREDDY (Michie, 1972). Desde então, o progresso tem sido lento mas seguro,\\naté chegar ao ponto em que a montagem de objetos complexos como motores elétricos se torna\\neconomicamente viável. Em problemas de montagem, o objetivo é encontrar uma ordem na qual\\ndevem ser montadas as peças de algum objeto. Se for escolhida a ordem errada, não haverá como\\nacrescentar alguma peça mais adiante na sequência sem desfazer uma parte do trabalho já realizado.\\nA verificação da viabilidade de um passo na sequência é um problema geométrico difícil de busca,\\nintimamente relacionado à navegação de robôs. Desse modo, a geração de ações válidas é a parte\\ndispendiosa da sequência de montagem. Qualquer algoritmo prático deve evitar explorar mais do que\\numa fração minúscula desse espaço de estados. Outro problema de montagem importante é o \\nprojeto\\nde proteínas\\n, em que o objetivo é encontrar uma sequência de aminoácidos que serão incorporados\\nem uma proteína tridimensional com as propriedades adequadas para curar alguma doença.\\n3.3 EM BUSCA DE SOLUÇÕES\\nDepois de formular alguns problemas, precisamos resolvê-los. Uma solução é uma sequência de\\nações, de modo que os algoritmos de busca consideram várias sequências de ações possíveis. As\\nsequências de ações possíveis que começam a partir do estado inicial formam uma \\nárvore de busca\\ncom o estado inicial na raiz; os ramos são as ações, e os \\nnós\\n correspondem aos estados no espaço de\\nestados do problema. A \\nFigura 3.6\\n apresenta os primeiros passos no crescimento da árvore de busca\\npara encontrar uma rota de Arad para Bucareste. O nó raiz da árvore corresponde ao estado inicial,\\nEm(Arad)\\n. O primeiro passo é testar se esse é um estado objetivo (é claro que não é, mas é\\nimportante verificar isso, a fim de podermos resolver problemas complicados como “partindo de\\nArad, chegar a Arad”). Então é necessário considerar a escolha de diversas ações. Isso é feito pela\\nexpansão\\n do estado atual, ou seja, aplicando cada ação válida no estado atual, \\ngerando\\n assim um\\nnovo conjunto de estados. Nesse caso, adicionaremos três novos ramos a partir do \\nnó pai\\n \\nEm\\n(\\nArad)\\nconduzindo a três novos \\nnós filhos\\n: \\nEm\\n(\\nSibiu\\n), \\nEm\\n(\\nTimisoara\\n) e \\nEm\\n(\\nZerind\\n). Agora temos de\\nescolher qual dessas três possibilidades merece consideração adicional.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 107}),\n",
       " Document(page_content='Figura 3.6\\n Árvores de busca parciais para localização de uma rota desde Arad até Bucareste. Nós\\nque foram expandidos estão sombreados; nós que foram gerados mas ainda não foram expandidos\\ntêm contorno em negrito; nós que ainda não foram gerados são mostrados em linhas leves tracejadas.\\nEssa é a essência da busca — seguir uma opção agora e deixar as outras reservadas para mais\\ntarde, no caso da primeira escolha não levar a uma solução. Vamos supor que escolhemos primeiro\\nSibiu. Verificamos se ela é um estado objetivo (não é) e depois o expandimos para obter \\nEm\\n(\\nArad\\n),\\nEm\\n(\\nFagaras\\n), \\nEm\\n(\\nOradea\\n) e \\nEm\\n(\\nRimnicuVilcea\\n). Portanto, podemos escolher qualquer dessas\\nquatro opções ou então voltar e escolher Timisoara ou Zerind. Cada um desses seis nós é um \\nnó\\nfolha\\n, ou seja, um nó sem filhos na árvore. O conjunto de todos os nós folhas disponíveis para\\nexpansão em um dado ponto é chamado de \\nborda\\n (muitos autores chamam de \\nlista aberta\\n, que é tanto\\ngratificante menos significativo quanto menos preciso, pois outras estruturas de dados são mais\\nadequadas do que uma lista). Na \\nFigura 3.6\\n, a borda de cada árvore é constituída por aqueles nós\\ncom contornos em negrito.\\nO processo de expansão dos nós na borda continua até que uma solução seja encontrada ou não\\nexistam mais estados a expandir. O algoritmo geral BUSCA-EM-ÁRVORE é mostrado\\ninformalmente na \\nFigura 3.7\\n. Todos os algoritmos de busca compartilham essa estrutura básica; eles\\nvariam fundamentalmente de acordo com a forma escolhida para o próximo estado a expandir — a\\nchamada \\nestratégia de busca\\n.\\nfunção\\n BUSCA-EM-ÁRVORE(\\nproblema\\n) \\nretorna\\n uma solução ou falha\\n    inicializar a borda utilizando o estado inicial do \\nproblema\\n    \\nrepita\\n        \\nse\\n \\nborda vazia\\n \\nentão retornar\\n falha', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 108}),\n",
       " Document(page_content='escolher um nó folha e o remover da borda\\n        \\nse\\n o nó contém um estado objetivo \\nentão retornar\\n a solução correpondente\\n        expandir o nó escolhido, adicionando os nós resultantes à borda\\n    \\n    \\nfunção\\n BUSCA-EM-GRAFO(\\nproblema\\n) \\nretorna\\n uma solução ou falha\\n    inicializar a borda utilizando o estado inicial do \\nproblema\\n    \\ninicializar o conjunto explorado tornando-o vazio\\n    \\nrepita\\n        \\nse\\n \\nborda vazia\\n \\nentão retornar\\n falha\\n        escolher um nó folha e o remover da borda\\n        \\nse\\n o nó contiver um estado objetivo \\nentão retornar\\n a solução correpondente\\n        \\nadicionar o nó ao conjunto explorado\\n        expandir o nó escolhido, adicionando os nós resultantes à borda\\n            \\napenas se não estiver na borda ou no conjunto explorado\\nFigura 3.7\\n Descrição informal do algoritmo geral de busca em árvore e busca em grafo. As partes da\\nBUSCA-EM-GRAFO marcadas em negrito e itálico são as adições necessárias para tratar estados\\nrepetidos.\\nO leitor atento notará algo peculiar sobre a árvore de busca mostrada na \\nFigura 3.6\\n: inclui o\\ncaminho de Arad para Sibiu e de volta para Arad novamente! Dizemos que \\nEm(Arad)\\n é um \\nestado\\nrepetido\\n na árvore de busca, gerado, nesse caso, por um \\ncaminho em laço\\n. A consideração de tais\\ncaminhos em laço significa que a árvore de busca completa para a Romênia é \\ninfinita\\n porque não há\\nlimite de quantas vezes se pode percorrer um laço. Por outro lado, o espaço de estados — o mapa\\nmostrado na \\nFigura 3.2\\n — tem apenas 20 estados. Como discutimos na \\nSeção 3.4\\n, os laços podem\\nfazer com que certos algoritmos falhem, tornando insolúveis os problemas que seriam solúveis.\\nFelizmente, não é necessário considerar caminhos em laço. Podemos contar mais com a intuição:\\nporque custos de caminho são aditivos e os custos de passo são não negativos, um caminho em laço\\npara qualquer estado dado nunca será melhor do que o mesmo caminho com o laço removido.\\nCaminhos em laço são um caso especial do conceito mais geral de \\ncaminhos redundantes\\n, que\\nexistem sempre que houver mais de uma maneira para ir de um estado a outro. Considere os\\ncaminhos Arad-Sibiu (140 km de comprimento) e Arad-Zerind-Oradea-Sibiu (297 km de\\ncomprimento). Obviamente, o segundo caminho é redundante — é apenas uma forma pior de chegar\\nao mesmo estado. Se você estiver preocupado em alcançar o objetivo, nunca haverá qualquer razão\\npara manter mais de um caminho para qualquer estado dado porque qualquer estado objetivo que\\npode ser acessado através da extensão de um caminho também será acessível através da extensão do\\noutro.\\nEm alguns casos, é possível definir o problema em si de modo a eliminar os caminhos\\nredundantes. Por exemplo, se formularmos o problema das oito rainhas de modo que uma rainha\\npossa ser colocada em qualquer coluna, cada estado com \\nn\\n rainhas poderá ser alcançado por \\nn!\\ncaminhos diferentes; mas, se reformularmos o problema de modo que cada nova rainha seja colocada\\nna coluna à esquerda vazia, então cada estado poderá ser alcançado apenas através de um caminho.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 109}),\n",
       " Document(page_content='Em outros casos, caminhos redundantes são inevitáveis. Inclui todos os problemas nos quais as\\nações são reversíveis, como problemas de roteamento e quebra-cabeças de blocos deslizantes. A\\nbusca de rota em uma \\ngrade retangular\\n (como a utilizada mais adiante na \\nFigura 3.9\\n) é um exemplo\\nparticularmente importante em jogos de computador. Em tal grade, cada estado tem quatro\\nsucessores; assim, uma árvore de busca de profundidade \\nd\\n, que inclui estados repetidos tem folhas\\n4\\nd\\n, mas há apenas cerca de 2\\nd\\n2\\n estados distintos dentro de \\nd\\n passos de determinado estado. Para \\nd\\n =\\n20, significa cerca de um trilhão de nós, mas apenas cerca de 800 estados distintos. Assim, seguir\\ncaminhos redundantes pode fazer com que um problema tratável se torne intratável. Isso é verdadeiro\\nmesmo para os algoritmos que sabem como evitar laços infinitos.\\n Como diz o ditado, \\nos algoritmos que se esquecem de sua história estão fadados a repeti-la.\\nA maneira de evitar a exploração de caminhos redundantes é lembrar por onde passou. Para fazer\\nisso, aumentaremos o algoritmo da BUSCA-EM-ÁRVORE com uma estrutura de dados chamada de\\nconjunto explorado\\n (também conhecida como \\nlista fechada\\n), que lembra de todo o nó que foi\\nexpandido. Nós que foram gerados recentemente que casam com nós anteriormente gerados — os que\\nestão no conjunto explorado ou na borda — podem ser descartados em vez de adicionados à borda.\\nO novo algoritmo, chamado BUSCA-EM-GRAFO, é apresentado informalmente na \\nFigura 3.7\\n. Os\\nalgoritmos específicos deste capítulo são extraídos desse projeto geral.\\nClaramente, a árvore de busca construída pelo algoritmo de BUSCA-EM-GRAFO, contém no\\nmáximo uma cópia de cada estado; assim, podemos imaginá-la como uma árvore que cresce\\ndiretamente sobre o grafo do espaço de estados, como mostrado na \\nFigura 3.8\\n. O algoritmo tem outra\\npropriedade interessante: a borda \\nsepara\\n o grafo do espaço de estados em região explorada e\\ninexplorada, de modo que cada caminho do estado inicial para o estado inexplorado tem que passar\\npor um estado da borda (se isso parece óbvio, tente agora o Exercício 3.13). Essa propriedade é\\nilustrada na \\nFigura 3.9\\n. Como cada passo move um estado da borda para a região explorada,\\nenquanto alguns estados da região inexplorada movem-se para a borda, vemos que o algoritmo está\\nanalisando \\nsistematicamente\\n os estados no espaço de estados, um por um, até encontrar uma solução.\\n3.3.1 Infraestrutura para algoritmos de busca\\nAlgoritmos de busca exigem uma estrutura de dados para manter o controle da árvore de busca que\\nestá sendo construída. Para cada nó \\nn\\n da árvore, temos uma estrutura que contém quatro\\ncomponentes:\\n•  \\nn\\n.ESTADO: o estado no espaço de estado a que o nó corresponde;\\n•  \\nn\\n.PAI: o nó na árvore de busca que gerou esse nó;\\n•  \\nn\\n.AÇÃO: a ação que foi aplicada ao pai para gerar o nó;\\n•  \\nn\\n.CUSTO-DO-CAMINHO: o custo, tradicionalmente denotado por \\ng(n)\\n, do caminho do estado\\ninicial até o nó, indicado pelos ponteiros para os pais.\\nDados os componentes de um nó pai, é fácil verificar como calcular os componentes necessários\\npara um nó filho. A função de NÓ-FILHO toma um nó pai e uma ação e devolve o nó filho resultante:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 110}),\n",
       " Document(page_content='função\\n NÓ-FILHO(\\nproblema, pai, ação\\n) \\nretorna \\num nó\\n    \\nretorna\\n um nó com\\n        ESTADO = \\nproblema\\n.RESULTADO(\\npai\\n.ESTADO, \\nação\\n),\\n        PAI = pai, AÇÃO = ação,\\n        CUSTO-DE-CAMINHO = \\npai\\n.CUSTO-DE-CAMINHO + \\nproblema\\n.CUSTO-DO-\\nPASSO(\\npai\\n.ESTADO, \\nação\\n)\\nFigura 3.8\\n Uma sequência de árvores de busca gerada pela busca em grafo no problema da Romênia,\\nda \\nFigura 3.2\\n. Em cada estágio, estendemos cada caminho em um passo. Repare que, na terceira fase,\\na cidade mais ao norte (Oradea) tornou-se um beco sem saída: os seus sucessores já foram\\nexplorados através de outros caminhos.\\nFigura 3.9\\n A propriedade de separação da BUSCA-EM-GRAFO foi ilustrada no problema da grade\\nretangular. A borda (nós brancos) sempre separa a região explorada do espaço de estados (nós\\nnegros) da região inexplorada (nós cinzas). Em (a), apenas a raiz foi expandida. Em (b), um nó folha\\nfoi expandido. Em (c), os sucessores restantes da raiz foram expandidos no sentido horário.\\nA estrutura de dados do nó está representada na \\nFigura 3.10\\n. Observe como os ponteiros do PAI\\nencadeiam os nós juntos em uma estrutura de árvore. Esses ponteiros também permitem que o\\ncaminho da solução seja extraído quando é encontrado um nó objetivo; utiliza-se a função SOLUÇÃO\\npara devolver a sequência de ações obtidas seguindo os ponteiros do pai de volta para a raiz.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 111}),\n",
       " Document(page_content='Figura 3.10\\n Nós são as estruturas de dados a partir das quais a árvore de busca é construída. Cada\\nnó tem um pai, um estado e diversos campos de anotação. As setas (ponteiros) apontam do filho para\\no pai.\\nAté agora, não fomos muito cuidadosos na distinção entre nós e estados, mas ao escrever\\nalgoritmos detalhados é importante fazer essa distinção. Um nó é uma anotação da estrutura de dados\\nusada para representar a árvore de busca. Um estado corresponde a uma configuração do mundo.\\nAssim, os nós estão em caminhos particulares, tal como definido pelos ponteiros PAI, enquanto os\\nestados não estão. Além disso, dois nós diferentes podem conter o mesmo estado do mundo se esse\\nestado for gerado através de dois caminhos de busca diferentes.\\nAgora, que temos os nós, precisamos de um lugar para colocá-los. A borda precisa ser\\narmazenada de tal forma que o algoritmo de busca possa facilmente escolher o próximo nó para\\nexpandir de acordo com sua estratégia preferida. A estrutura de dados apropriada para isso é uma\\nfila\\n. As operações sobre uma fila são:\\n•  VAZIA?(\\nfila\\n) devolve verdadeiro somente se não existir mais nenhum elemento na fila.\\n•  POP(\\nfila\\n) remove o primeiro elemento da fila e o devolve.\\n•  INSERIR(\\nelemento\\n, \\nfila\\n) insere um elemento na fila e devolve a fila resultante.\\nAs filas são caracterizadas pela \\nordem\\n em que armazenam os nós inseridos. Três variantes mais\\ncomuns são: o primeiro a entrar na fila é o primeiro a sair ou a \\nfila FIFO\\n (first in, first out), que\\ndispara o elemento \\nmais antigo\\n da fila; o último a entrar na fila é o último a sair ou \\nfila\\n \\nLIFO\\n (last\\nin, last out) (também conhecida como \\npilha\\n), que dispara o elemento \\nmais recente\\n da fila; e a \\nfila de\\nprioridade\\n, que dispara o elemento da fila com a maior prioridade de acordo com alguma função de\\nordenação.\\nO conjunto explorado pode ser implementado com uma tabela hash para permitir um controle\\neficaz de estados repetidos. Com uma boa implementação, a inserção e a busca podem ser realizadas\\nem tempos aproximadamente constantes, não importando quantos estados estiverem armazenados.\\nDeve-se ter o cuidado de implementar a tabela hash com a correta noção de igualdade entre estados.\\nPor exemplo, no problema do caixeiro-viajante, é necessário que a tabela hash saiba que o conjunto\\nde cidades visitadas {Bucareste, Urziceni, Vaslui} é o mesmo que {Urziceni, Vaslui, Bucharest}. Às\\nvezes isso pode ser alcançado mais facilmente, forçando que as estruturas de dados para os estados\\nestejam em alguma \\nforma canônica,\\n isto é, estados logicamente equivalentes deverão mapear a\\nmesma estrutura de dados. No caso de estados descritos por conjuntos, por exemplo, uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 112}),\n",
       " Document(page_content='representação de um vetor de bits ou uma lista ordenada sem repetições seriam canônicos, ao passo\\nque uma lista não ordenada, não seria.\\n3.3.2 Medição de desempenho de resolução de problemas\\nAntes de entrar no projeto de algoritmos de busca específicos, precisamos considerar os critérios\\nque podem ser usados para se fazer uma escolha entre eles. Podemos avaliar o desempenho do\\nalgoritmo em quatro aspectos:\\n•  \\nCompleteza\\n: O algoritmo oferece a garantia de encontrar uma solução quando ela existir?\\n•  \\nOtimização:\\n A estratégia encontra a solução ótima, como definido na página 68?\\n•  \\nComplexidade de tempo:\\n Quanto tempo ele leva para encontrar uma solução?\\n•  \\nComplexidade de espaço:\\n Quanta memória é necessária para executar a busca?\\nA complexidade de tempo e a complexidade de espaço de memória são sempre consideradas em\\nrelação a alguma medida da dificuldade do problema. Em ciência da computação teórica, a medida\\ntípica é o tamanho do grafo do espaço de estados, | \\nV\\n | + | \\nE\\n |, onde \\nV\\n é o conjunto de vértices (nós)\\ndo grafo e \\nE\\n é o conjunto de arestas (arcos). Isso é apropriado quando o grafo for uma estrutura de\\ndados explícita que é a entrada para o programa de busca (o mapa da Romênia é um exemplo dessa\\nestrutura). Em IA, o grafo é sempre representado \\nimplicitamente\\n pelo estado inicial, ações, modelo\\nde transição, com frequência infinito. Por essas razões, a complexidade é expressa em termos de três\\nquantidades: \\nb\\n, o \\nfator de ramificação\\n ou número máximo de sucessores de qualquer nó; \\nd\\n, a\\nprofundidade\\n do nó objetivo menos profundo (ou seja, o número de passos ao longo do caminho da\\nraiz até o estado objetivo mais próximo); e \\nm\\n, o comprimento máximo de qualquer caminho no\\nespaço de estados. Com frequência, o tempo é medido em termos do número de nós gerados durante\\na busca, e o espaço é medido em termos do número máximo de nós armazenados na memória. Na\\nmaior parte, descreveremos a complexidade de tempo e espaço para a busca em uma árvore. Para um\\ngrafo, a resposta depende do quão “redundante” são os caminhos no espaço de estados.\\nPara avaliar a efetividade de um algoritmo de busca, podemos considerar apenas \\no custo de busca\\n— que, em geral, depende da complexidade de tempo, mas também pode incluir um termo para uso\\nda memória — ou podemos usar o \\ncusto total\\n, que combina o custo de busca e o custo de caminho da\\nsolução encontrada. Para o problema de localizar uma rota desde Arad até Bucareste, o custo de\\nbusca é o período de tempo exigido pela busca, e o custo de solução é o comprimento total do\\ncaminho em quilômetros. Desse modo, para calcular o custo total, temos de somar quilômetros e\\nmilissegundos. Não existe nenhuma “taxa de conversão oficial” entre essas duas unidades de medida,\\nmas, nesse caso, talvez fosse razoável converter quilômetros em milissegundos usando uma\\nestimativa da velocidade média do carro (porque o tempo é o que importa ao agente). Isso permite ao\\nagente encontrar um ponto de equilíbrio ótimo, no qual se torna contraproducente realizar\\ncomputação adicional para encontrar um caminho mais curto. O problema mais geral de\\ncompensação entre diferentes recursos será examinado no Capítulo 16.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 113}),\n",
       " Document(page_content='3.4 ESTRATÉGIAS DE BUSCA SEM INFORMAÇÃO\\nEsta seção focaliza diversas estratégias de busca reunidas sob o título de \\nbusca sem informação\\n(também chamada \\nbusca cega\\n). A expressão significa que elas não têm nenhuma informação\\nadicional sobre estados, além daquelas fornecidas na definição do problema. Tudo o que elas podem\\nfazer é gerar sucessores e distinguir um estado objetivo de um estado não objetivo. Todas as\\nestratégias de busca se distinguem pela \\nordem\\n em que os nós são expandidos. As estratégias que\\nsabem se um estado não objetivo é “mais promissor” que outro são chamadas estratégias de \\nbusca\\ninformada\\n ou \\nbusca heurística\\n; elas serão estudadas na \\nSeção 3.5\\n.\\n3.4.1 Busca em largura\\nA \\nbusca em largura\\n (BrFS – Breadth-first search) é uma estratégia simples em que o nó raiz é\\nexpandido primeiro, em seguida todos os sucessores do nó raiz são expandidos, depois os sucessores\\ndesses nós\\n, e assim por diante. Em geral, todos os nós em dada profundidade na árvore de busca são\\nexpandidos, antes que todos os nós no nível seguinte sejam expandidos.\\nA busca em largura é uma instância do algoritmo de busca em grafo (\\nFigura 3.7\\n), em que o nó mais\\nraso não expandido é escolhido para expansão. Isso é conseguido simplesmente utilizando uma fila\\nFIFO para a borda. Assim, novos nós (que são sempre mais profundos do que seus pais) vão para o\\nfim da fila, e nós antigos, que são mais rasos que os novos, são expandidos primeiro. Há um ligeiro\\nrefinamento no algoritmo genérico de busca em grafos, pois o teste de objetivo é aplicado a cada nó\\nquando é \\ngerado\\n e não quando é selecionado para expansão. Essa decisão será explicada a seguir,\\nquando discutirmos a complexidade do tempo. Observe também que o algoritmo, que segue o modelo\\ngeral para a busca em grafos, descarta qualquer caminho novo para um estado já na borda ou no\\nconjunto explorado; é fácil verificar que tal caminho deverá pelo menos ser tão profundo quanto\\naquele já encontrado. Assim, a busca em largura sempre terá o caminho mais raso para todo o nó na\\nborda.\\nO pseudocódigo é apresentado na \\nFigura 3.11\\n. A \\nFigura 3.12\\n mostra o progresso da busca em uma\\nárvore binária simples.\\nfunção\\n BUSCA-EM-LARGURA(\\nproblema\\n) \\nretorna\\n uma solução ou falha\\n    \\nnó\\n ← um nó com ESTADO = \\nproblema\\n.ESTADO-INICIAL, CUSTO-DE-CAMINHO = 0\\n    \\nse\\n \\nproblema\\n.TESTE-DE-OBJETIVO(nó.ESTADO) \\nsenão retorne\\n SOLUÇÃO(\\nnó\\n),\\n    \\nborda\\n ← uma fila FIFO com \\nnó\\n como elemento único\\n    \\nexplorado\\n ← conjunto vazio\\n    \\nrepita\\n        \\nse\\n VAZIO?(\\nborda\\n), \\nentão retorne\\n falha\\n        nó ← POP(\\nborda\\n) / * escolhe o nó mais raso na \\nborda\\n */\\n        adicione\\n nó\\n.ESTADO para \\nexplorado\\n        \\npara cada\\n \\naçã\\no \\nem\\n \\nproblema\\n.AÇÕES(nó.ESTADO) \\nfaça\\n            filho ← NÓ-FILHO(\\nproblema, nó, ação\\n),', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 114}),\n",
       " Document(page_content='se \\n(filho.ESTADO)não está em \\nexplorado\\n ou \\nborda\\n \\nentão\\n                \\nse\\n \\nproblema.\\nTESTE-DE-OBJETIVO(filho.ESTADO) \\nentão retorne\\n SOLUÇÃO(\\nfilho\\n)\\n                \\nborda\\n ← INSIRA(\\nfilho, borda\\n)\\nFigura 3.11\\n Busca em largura em um grafo.\\nFigura 3.12\\n Busca em largura em uma árvore binária simples. Em cada fase, o próximo nó a ser\\nexpandido é indicado por um marcador.\\nComo avaliar a busca em largura de acordo com os quatro critérios da seção anterior? Podemos\\nfacilmente verificar que ela é c\\nompleta\\n — se o nó objetivo mais raso estiver em alguma\\nprofundidade finita \\nd\\n, a busca em largura acabará por encontrá-lo depois de gerar todos os nós mais\\nrasos (desde que o fator de ramificação \\nb\\n seja finito). Observe que, logo que um nó objetivo é\\ngerado, sabemos que é o nó objetivo mais raso porque todos os nós mais rasos já devem ter sido\\ngerados e falhado no teste de objetivo. Agora, o nó objetivo \\nmais raso\\n não é necessariamente o\\nótimo\\n; tecnicamente, a busca em largura é ideal se o custo do caminho for uma função não\\ndecrescente da profundidade do nó. O mais comum desse cenário é que todas as ações têm o mesmo\\ncusto.\\nAté aqui, o que se falou sobre busca em largura tem sido boas notícias. As notícias sobre o tempo\\ne o espaço não são tão boas. Imagine a busca em uma árvore uniforme onde cada estado tenha \\nb\\nsucessores. A raiz da árvore de busca gera \\nb\\n nós no primeiro nível, cada um dos quais gera \\nb\\n outros\\nnós, totalizando \\nb\\n2\\n no segundo nível. Cada um \\ndesses\\n outros nós gera \\nb\\n outros nós, totalizando \\nb\\n3\\n nós\\nno terceiro nível, e assim por diante. Agora, suponha que a solução esteja na profundidade \\nd\\n. No pior\\ncaso, é o último nó gerado naquele nível. Então, o número total de nós gerados é:\\nb\\n + \\nb\\n2\\n + \\nb\\n3\\n + … + \\nb\\nd\\n = \\nO\\n(\\nb\\nd\\n).\\n(Se o algoritmo fosse aplicar o teste de objetivo para nós ao serem selecionados para a expansão, em\\nvez de ao serem gerados, toda a camada de nós na profundidade \\nd\\n seria expandida antes que o\\nobjetivo fosse detectado e a complexidade de tempo seria \\nO\\n (\\nb\\nd +1\\n).).\\nQuanto à complexidade do espaço: para qualquer tipo de busca em grafos, que armazena todos os\\nnós expandidos no conjunto \\nexplorado\\n, a complexidade do espaço está sempre dentro de um fator de\\nb\\n da complexidade do tempo. Em particular, para busca em largura em grafos, cada nó gerado\\npermanecerá na memória. Haverá \\nO\\n (\\nb\\nd−1\\n) nós no conjunto explorado e \\nO\\n(\\nb\\nd\\n) nós na borda; assim, a\\ncomplexidade de espaço será \\nO\\n(\\nb\\nd\\n)\\n,\\n ou seja, será dominada pelo tamanho da borda. Mudar para uma\\nbusca em árvore não iria poupar muito espaço e, em um espaço de estados com muitos caminhos\\nredundantes, a mudança poderia custar grande parte do tempo.\\nUm limite de complexidade exponencial tal como \\nO\\n(\\nb\\nd\\n), é assustador. A \\nFigura 3.13\\n mostra por\\nque, listando para vários valores de profundidade \\nd\\n da solução, o tempo e a memória necessários', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 115}),\n",
       " Document(page_content='para uma busca em largura com fator de ramificação \\nb\\n = 10. A tabela assume a geração de um milhão\\nde nós por segundo e o requisito de 1.000 bytes de armazenamento para um nó. Muitos problemas\\npodem ser ajustados a essas suposições (de um fator de 100 para mais ou para menos), quando\\nexecutados em um computador pessoal moderno.\\nProfundidade\\nNós\\nTempo\\nMemória\\n2\\n110\\n0,11 milissegundo\\n107 kilobytes\\n4\\n11.110\\n11 milissegundos\\n10,6 megabytes\\n6\\n10\\n6\\n1,1 segundo\\n1 gigabyte\\n8\\n10\\n8\\n2 minutos\\n103 gigabytes\\n10\\n10\\n10\\n3 horas\\n10 terabytes\\n12\\n10\\n12\\n13 dias\\n1 petabyte\\n14\\n10\\n14\\n3,5 anos\\n99 petabytes\\n16\\n10\\n16\\n350 anos\\n10 exabytes\\nFigura 3.13\\n Requisitos de tempo e memória para a busca em largura. Os números mostrados\\nassumem fator de ramificação \\nb\\n = 10; um milhão de nós/segundo; 1.000 bytes/nó.\\n Duas lições podem ser aprendidas a partir da \\nFigura 3.13\\n. Em primeiro lugar, \\nos requisitos de\\nmemória são um problema maior para a busca em largura do que o tempo de execução\\n. Deve-se\\nesperar 13 dias pela solução de um problema importante com profundidade de busca 12, mas nenhum\\ncomputador pessoal tem a memória principal da ordem de petabytes que ele exigiria. Felizmente,\\nexistem outras estratégias de busca que exigem menos memória.\\n A segunda lição é que o tempo ainda é um fator importante. Se seu problema tem uma solução\\nna profundidade 16, então (dadas nossas suposições) ele demorará 350 anos para que a busca em\\nlargura a encontre (ou, na realidade, qualquer busca sem informação). Em geral, \\nos problemas de\\nbusca de complexidade exponencial não podem ser resolvidos por métodos sem informação, para\\nqualquer instância, exceto as menores\\n.\\n3.4.2 Busca de custo uniforme\\nQuando todos os custos de passos forem iguais, a busca em largura será ótima porque sempre\\nexpande o nó \\nmais raso\\n não expandido. Através de uma simples extensão, podemos encontrar um\\nalgoritmo que é ótimo para qualquer função de custo do passo. Em vez de expandir o nó mais raso, a\\nbusca de custo uniforme\\n expande o nó \\nn\\n com o \\ncusto de caminho g\\n(\\nn\\n) \\nmais baixo\\n. Isso é feito', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 116}),\n",
       " Document(page_content='através do armazenamento da borda como uma fila de prioridade ordenada por \\ng\\n. O algoritmo é\\nmostrado na \\nFigura 3.14\\n.\\nfunção BUSCA-DE-CUSTO-UNIFORME(\\nproblema\\n) \\nretorna\\n uma solução ou falha\\n    nó ← um nó com ESTADO = \\nproblema.\\nESTADO-INICIAL, CUSTO-DE-CAMINHO = 0 \\n    \\nborda\\n ← fila de prioridade ordenada pelo CUSTO-DE-CAMINHO, com \\nnó\\n como elemento\\núnico\\n    \\nexplorado\\n ← um conjunto vazio \\n    \\nrepita\\n        \\nse\\n VAZIO?(\\nborda\\n), \\nentão retornar\\n falha\\n        nó ← POP(\\nborda\\n) / * escolhe o nó de menor custo na \\nborda\\n */\\n        \\nse\\n \\nproblema\\n.TESTE-OBJETIVO(nó.ESTADO) \\nentão retornar\\n SOLUÇÃO(\\nnó\\n)\\n        adicionar (nó.ESTADO) para \\nexplorado \\n        \\npara cada\\n ação \\nem\\n \\nproblema\\n. AÇÕES(nó.ESTADO) \\nfaça\\n            \\nfilho\\n ← NÓ-FILHO (\\nproblema, nó, ação\\n)\\n            \\nse\\n (filho.ESTADO) não está na \\nborda \\nou \\nexplorado\\n \\nentão\\n                \\nborda\\n ← INSIRA (\\nfilho, borda\\n)\\n            \\nsenão se\\n (filho.ESTADO) está na \\nborda\\n com o maior CUSTO-DE-CAMINHO \\nentão\\n                substituir aquele nó \\nborda\\n por \\nfilho\\nFigura 3.14\\n Busca de custo uniforme em um grafo. O algoritmo é idêntico ao algoritmo geral de\\nbusca de grafo na \\nFigura 3.7\\n, exceto pelo uso de uma fila de prioridade e pela adição de uma\\nverificação extra, caso um caminho mais curto para um estado de borda seja descoberto. A estrutura\\nde dados para a \\nborda\\n deve permitir os testes eficientes de pertinência em conjunto, por isso deve\\ncombinar os recursos de uma fila de prioridade e de uma tabela hash.\\nAlém da ordem da fila por custo do caminho, há duas outras diferenças significativas na busca em\\nlargura. A primeira é que o teste de objetivo é aplicado a um nó quando ele é \\nselecionado para a\\nexpansão\\n (como no algoritmo genérico da busca em grafos mostrado na \\nFigura 3.7\\n) e não quando é\\ngerado pela primeira vez. A razão é que o primeiro nó objetivo que é \\ngerado\\n pode estar em um\\ncaminho abaixo do ótimo. A segunda diferença é que é adicionado um teste, caso seja encontrado um\\ncaminho melhor para um nó atualmente na borda.\\nAmbas as modificações entram em jogo no exemplo mostrado na \\nFigura 3.15\\n, onde o problema é ir\\nde Sibiu para Bucareste. Os sucessores de Sibiu são Rimnicu Vilcea e Fagaras, com custos de 80 e\\n99, respectivamente. O nó de menor custo, Rimnicu Vilcea, será o próximo a ser expandido,\\nacrescentando Pitesti com custo 80 + 97 = 177. O nó de menor custo é agora Fagaras, por isso será\\nexpandido, acrescentando Bucareste com custo de 99 + 211 = 310. Agora foi gerado um nó objetivo,\\nmas a busca de custo uniforme se mantém, escolhendo Pitesti para expansão e adicionando um\\nsegundo caminho para Bucareste com um custo de 80 + 97 + 101 = 278. Em seguida o algoritmo\\nverifica se esse novo caminho é melhor do que o antigo, isto é, de modo que o antigo seja descartado.\\nBucareste, agora com o custo \\ng\\n 278, será selecionada para a expansão e a solução será devolvida.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 117}),\n",
       " Document(page_content='Figura 3.15\\n Parte do espaço de estados da Romênia, selecionada para ilustrar a busca de custo\\nuniforme.\\n É fácil verificar que a busca de custo uniforme em geral é ótima. Em primeiro lugar,\\nobservamos que sempre que a busca de custo uniforme seleciona um nó \\nn\\n para expansão, o caminho\\nideal para esse nó foi encontrado (se esse não fosse o caso, haveria de ter outro nó na borda \\nn\\n′ no\\ncaminho ótimo a partir do nó inicial até \\nn\\n, pela propriedade de separação de grafo da \\nFigura 3.9\\n; por\\ndefinição, \\nn\\n′ teria um custo \\ng\\n menor do que \\nn\\n e teria sido selecionado em primeiro lugar). Então,\\ndevido aos custos de passo serem não negativos, os caminhos nunca ficam menores à medida que os\\nnós são adicionados. Esses dois fatos juntos implicam que a \\nbusca de custo uniforme expande os\\nnós na ordem de seu custo de caminho ótimo\\n. Assim, o primeiro nó objetivo que foi selecionado\\npara expansão deverá ser a solução ótima.\\nA busca de custo uniforme não se importa com o \\nnúmero\\n de passos que um caminho tem, mas\\napenas com o seu custo total. Por isso, ela ficará presa em um laço infinito se existir um caminho com\\nsequência infinita de ações a custo zero — por exemplo, uma sequência de ações \\nNoOp\\n.\\n6\\n A\\ncompleteza será garantida se o custo de cada passo exceder uma constante positiva pequena \\n∊\\n.\\nA busca de custo uniforme é orientada por custos de caminhos em vez de profundidades; assim,\\nsua complexidade não pode ser caracterizada com facilidade em termos de \\nb\\n e \\nd\\n. Em vez disso, seja\\nC\\n* o custo da solução ótima,\\n7\\n e suponha que toda ação custe pelo menos \\n∊\\n. Então, a complexidade de\\ntempo e espaço do pior caso do algoritmo é \\n, que pode ser muito maior que \\nb\\nd\\n. Essa é a\\nrazão por que a busca de custo uniforme pode explorar grandes árvores de pequenos passos antes de\\nexplorar caminhos envolvendo passos grandes e talvez úteis. Quando todos os custos de passos\\nforem iguais, \\n será simplesmente \\nb\\nd\\n+1\\n. Quando todos os custos de passo são iguais, a busca de\\ncusto uniforme é similar à busca em largura, exceto que a busca em largura para logo que gerar um\\nobjetivo, enquanto que a busca de custo uniforme examina todos os nós à profundidade do objetivo\\npara verificar se algum deles tem custo mais baixo; portanto, a busca de custo uniforme tem mais\\ntrabalho, expandindo os nós à profundidade \\nd,\\n desnecessariamente.\\n3.4.3 Busca em profundidade\\nA \\nbusca em profundidade\\n (DFS – Depth-first search) sempre expande o nó \\nmais profundo\\n na\\nborda atual da árvore de busca. O progresso da busca é ilustrado na \\nFigura 3.16\\n. A busca prossegue\\nimediatamente até o nível mais profundo da árvore de busca, onde os nós não têm sucessores. À', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 118}),\n",
       " Document(page_content='medida que esses nós são expandidos, eles são retirados da borda e, então, a busca “retorna” ao nó\\nseguinte mais profundo que ainda tem sucessores inexplorados.\\nFigura 3.16\\n Busca em profundidade em uma árvore binária. A região inexplorada é mostrada em\\ncinza-claro. Os nós explorados sem descendentes na borda são removidos da memória. Os nós na\\nprofundidade 3 não têm sucessores e \\nM\\n é o único nó objetivo.\\nO algoritmo de busca em profundidade é uma instância do algoritmo de busca em grafo da \\nFigura\\n3.7\\n; enquanto a busca em largura utiliza uma fila FIFO, a busca em profundidade utiliza uma fila\\nLIFO. Uma fila LIFO significa que o nó gerado mais recentemente é escolhido para expansão. Deverá\\nser o nó mais profundo não expandido porque é mais profundo do que seu pai, que, por sua vez, era o\\nnó não expandido mais profundo quando foi selecionado.\\nComo alternativa para a implementação do estilo da BUSCA EM GRAFOS, é comum implementar\\nprimeiro a busca em profundidade com uma função recursiva que chama a si mesma para cada um\\ndos seus filhos por vez (a \\nFigura 3.17\\n apresenta um algoritmo em profundidade recursivo incluindo\\num limite de profundidade).\\nfunção\\n BUSCA-EM-PROFUNDIDADE-LIMITADA(problema, limite) \\nretorna \\numa solução ou\\nfalha/corte\\nretornar\\n BPL-RECURSIVA (CRIAR-NÓ(\\nproblema,\\n ESTADO-INICIAL), \\nproblema, limite\\n)\\nfunção\\n BPL-RECURSIVA(\\nnó, problema, limite\\n) \\nretorna \\numa solução ou falha/corte\\n    \\nse\\n \\nproblema\\n. TESTAR-OBJETIVO (nó.ESTADO) então, \\nretorna\\n SOLUÇÃO (nó) \\n    \\nse não se\\n \\nlimite\\n = 0 \\nentão retorna\\n \\ncorte', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 119}),\n",
       " Document(page_content='senão\\n        \\ncorte_ocorreu\\n? ← falso \\npara cada\\n ação \\nno\\n problema.AÇÕES(nó.ESTADO) \\nfaça\\n            \\nfilho\\n ← NÓ-FILHO (\\nproblema, nó, ação\\n) \\n            \\nresultado\\n ← BPL-RECURSIVA (\\ncriança, problema limite − 1\\n) \\n            \\nse\\n \\nresultado \\n= \\ncorte\\n  \\nentão\\n \\ncorte_ocorreu\\n? ← verdadeiro\\n            \\nsenão se\\n \\nresultado\\n ≠ \\nfalha\\n \\nentão retorna\\n \\nresultado\\n        \\nse\\n corte_ocorreu\\n? \\nentão retorna\\n \\ncorte\\n \\nsenão retorna\\n \\nfalha\\nFigura 3.17\\n Uma implementação recursiva da busca em árvore de profundidade limitada.\\nAs propriedades da busca em profundidade dependem fortemente da versão utilizada da busca ser\\na busca em grafos ou a busca em árvore. A versão da busca em grafos, que evita estados repetidos e\\ncaminhos redundantes, é completa em espaços de estados finitos porque acabará por expandir cada\\nnó. A versão da busca em árvore, por outro lado, \\nnão\\n é completa — por exemplo, na \\nFigura 3.6\\n, o\\nalgoritmo seguirá o laço Arad-Sibiu-Arad-Sibiu para sempre. A busca em profundidade em árvore\\npode ser modificada, sem qualquer custo extra de memória, para verificar novos estados com relação\\naos nós do caminho da raiz até o nó atual; isso evita laços em espaço de estados finitos, mas não\\nevita a proliferação de caminhos redundantes. Em espaço de estados infinitos, ambas as versões\\nfalham se um caminho não objetivo infinito for encontrado. Por exemplo, no problema 4 de Knuth, a\\nbusca em profundidade ficaria aplicando o operador fatorial para sempre.\\nPor motivos semelhantes, ambas as versões são não ótimas. Por exemplo, na \\nFigura 3.16\\n, a busca\\nem profundidade vai explorar a subárvore esquerda toda, mesmo sendo o nó \\nC\\n um nó objetivo. Se o\\nnó \\nJ\\n também fosse um nó objetivo, a busca em profundidade iria devolvê-lo como solução em vez de\\nC\\n, que seria uma solução melhor; então, a busca em profundidade não é ótima.\\nA complexidade temporal da busca em profundidade em grafo é limitada pelo tamanho do espaço\\nde estados (que certamente pode ser infinito). A busca em profundidade em árvore, por outro lado,\\npoderá gerar todos os nós \\nO\\n(\\nb\\nm\\n)\\n na árvore de busca, onde \\nm\\n é a profundidade máxima de qualquer\\nnó; isso pode ser muito maior do que o tamanho do espaço de estados. Observe que \\nm\\n em si pode ser\\nmuito maior do que \\nd\\n (profundidade da solução mais rasa) e é infinito se a árvore for ilimitada.\\nAté agora, a busca em profundidade parece não apresentar uma vantagem clara sobre a busca em\\nlargura, então por que incluí-la? O motivo é a complexidade espacial. Para uma busca em grafos, não\\nhá vantagem, mas uma busca em profundidade em árvore precisa armazenar apenas um único\\ncaminho da raiz até um nó folha, juntamente com os nós irmãos remanescentes não expandidos para\\ncada nó no caminho. Uma vez que um nó é expandido, ele pode ser removido da memória, tão logo\\ntodos os seus descendentes tenham sido completamente explorados (veja a \\nFigura 3.16\\n). Para um\\nespaço de estados com fator de ramificação \\nb\\n e profundidade máxima \\nm\\n, a busca em profundidade\\nexige o armazenamento de apenas \\nO\\n(\\nbm\\n) nós. Usando as mesmas suposições da \\nFigura 3.13\\n e\\nsupondo que nós na mesma profundidade do nó objetivo não têm sucessores, verificamos que a busca\\nem profundidade exigiria 156 kilobytes, em vez de 10 exabytes na profundidade \\nd\\n = 16, um espaço\\nsete trilhões de vezes menor. Isso levou à adoção da busca em profundidade em árvore como o\\ncarro-chefe básico de muitas áreas da IA, incluindo a satisfação de restrição (Capítulo 6), a\\nsatisfatibilidade proposicional (Capítulo 7) e a programação lógica (Capítulo 9). Para o restante', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 120}),\n",
       " Document(page_content='desta seção, nos concentraremos principalmente na versão de busca em árvore da busca em\\nprofundidade.\\nUma variante da busca em profundidade chamada \\nbusca com retrocesso\\n utiliza ainda menos\\nmemória. (veja o Capítulo 6 para mais detalhes). No retrocesso, apenas um sucessor é gerado de\\ncada vez, em lugar de todos os sucessores; cada nó parcialmente expandido memoriza o sucessor que\\ndeve gerar em seguida. Desse modo, é necessária apenas a memória \\nO\\n(\\nm\\n), em vez de \\nO\\n(\\nbm\\n). A\\nbusca com retrocesso permite ainda outro truque de economia de memória (e de economia de tempo):\\na ideia de gerar um sucessor pela \\nmodificação\\n direta da descrição do estado atual, em vez de copiá-\\nlo primeiro. Isso reduz os requisitos de memória a apenas uma descrição de estado e a \\nO\\n(\\nm\\n) ações.\\nPara que isso funcione, devemos ser capazes de desfazer cada modificação quando voltarmos para\\ngerar o próximo sucessor. No caso de problemas com grandes descrições de estados, como a\\nmontagem robótica, essas técnicas são críticas para o sucesso.\\n3.4.4 Busca em profundidade limitada\\nO fracasso constrangedor da busca em profundidade em espaço de estados infinito pode ser\\natenuado pela busca em profundidade com um limite de profundidade predeterminado \\nl\\n. Isto é, nós na\\nprofundidade \\nl\\n são tratados como se não tivessem sucessores. Essa abordagem é chamada de \\nbusca\\nem profundidade limitada\\n. O limite de profundidade resolve o problema de caminhos infinitos.\\nInfelizmente, ele também introduz uma fonte adicional de incompleteza, se escolhermos \\nl\\n < \\nd\\n, ou seja,\\no objetivo mais raso está além do limite de profundidade (isso não é improvável quando \\nd\\n é\\ndesconhecido). A busca em profundidade limitada também não será ótima se escolhermos \\nl\\n > \\nd\\n. Sua\\ncomplexidade de tempo é \\nO\\n(\\nb\\nl\\n) e sua complexidade de espaço é \\nO\\n(\\nbl\\n). A busca em profundidade\\npode ser visualizada como um caso especial da busca em profundidade limitada com \\nl\\n = ∞.\\nÀs vezes, limites de profundidade podem se basear no conhecimento que se tem do problema. Por\\nexemplo, no mapa da Romênia há 20 cidades. Portanto, sabemos que, se existe uma solução, ela deve\\nter o comprimento 19 no caso mais longo, e então \\nl\\n = 19 é uma escolha possível. Porém, de fato, se\\nestudassemos cuidadosamente o mapa, descobriríamos que qualquer cidade pode ser alcançada a\\npartir de qualquer outra cidade em, no máximo, nove passos. Esse número, conhecido como\\ndiâmetro\\n do espaço de estados, nos dá um limite de profundidade melhor, o que leva a uma busca em\\nprofundidade limitada mais eficiente. No entanto, na maioria dos problemas, não conhecemos um\\nbom limite de profundidade antes de resolvermos o problema.\\nA busca em profundidade limitada pode ser implementada como uma modificação simples do\\nalgoritmo geral de busca em árvore ou em grafos. Alternativamente, pode ser implementada como um\\nalgorismo simples recursivo como mostrado na \\nFigura 3.17\\n. Observe que a busca em profundidade\\nlimitada pode terminar com dois tipos de falhas: o valor-padrão \\nfalha\\n indica nenhuma solução; o\\nvalor \\ncorte\\n indica nenhuma solução dentro do limite de profundidade.\\n3.4.5 Busca de aprofundamento iterativo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 121}),\n",
       " Document(page_content='A \\nbusca de aprofundamento iterativo\\n (IDS – Iterative Deepening Search) (ou busca em\\nprofundidade de aprofundamento iterativo) é uma estratégia geral, usada com frequência em\\ncombinação com a busca em profundidade em árvore, que encontra o melhor limite de profundidade.\\nEla faz isso aumentando gradualmente o limite — primeiro 0, depois 1, depois 2, e assim por diante\\naté encontrar um objetivo. Isso ocorrerá quando o limite de profundidade alcançar \\nd\\n, a profundidade\\ndo nó objetivo mais raso. O algoritmo é mostrado na \\nFigura 3.18\\n. O aprofundamento iterativo\\ncombina os benefícios da busca em profundidade e da busca em largura. Como na busca em\\nprofundidade, seus requisitos de memória são muito modestos: \\nO\\n(\\nbd\\n), para sermos precisos. Como\\nna busca em largura, ele é completo quando o fator de ramificação é finito, e ótimo quando o custo de\\ncaminho é uma função não decrescente da profundidade do nó. A \\nFigura 3.19\\n mostra quatro iterações\\nda BUSCA-DE-APROFUNDAMENTO-ITERATIVO em uma árvore de busca binária, onde a\\nsolução é encontrada na quarta iteração.\\nfunção\\n BUSCA-DE-APROFUNDAMENTO-ITERATIVO(\\nproblema\\n) \\nretorna\\n uma solução ou\\nfalha\\npara\\n profundidade = 0 \\naté\\n ∞ \\nfaça\\nresultado\\n ← BUSCA-EM-PROFUNDIDADE-LIMITADA(\\nproblema\\n, \\nprofundidade\\n)\\nse\\n \\nresultado\\n ≠ \\ncorte\\n \\nentão retornar\\n \\nresultado\\nFigura 3.18\\n Algoritmo de busca de aprofundamento iterativo que aplica repetidamente a busca em\\nprofundidade limitada com limites crescentes. Ele termina quando uma solução é encontrada ou se a\\nbusca em profundidade limitada devolve \\nfalha\\n, indicando que não existe nenhuma solução.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 122}),\n",
       " Document(page_content='Figura 3.19\\n Quatro iterações de busca de aprofundamento iterativo em uma árvore binária.\\nA busca de aprofundamento iterativo pode parecer um desperdício porque os estados são gerados\\nvárias vezes. Na verdade, esse custo não é muito alto porque, em uma árvore de busca com o mesmo\\n(ou quase o mesmo) fator de ramificação em cada nível, a maior parte dos nós estará no nível\\ninferior e, assim, não importa muito se os níveis superiores são gerados várias vezes. Em uma busca\\nde aprofundamento iterativo, os nós no nível inferior (profundidade \\nd\\n) são gerados uma vez, os do\\npenúltimo nível inferior são gerados duas vezes, e assim por diante, até os filhos da raiz, que são\\ngerados \\nd\\n vezes. Portanto, o número total de nós gerados é:\\nN\\n(IDS) = (\\nd\\n)\\nb\\n + (\\nd –\\n 1)\\nb\\n2\\n +…+ (1)\\nb\\nd\\n,\\no que dá uma complexidade de tempo igual a \\nO\\n(\\nb\\nd\\n) — assintomaticamente, a mesma da busca em\\nprofundidade. Há um custo extra em gerar os níveis mais altos múltiplas vezes, mas não é grande. Por\\nexemplo, se \\nb\\n = 10 e \\nd\\n = 5, os números são:\\nN\\n(IDS) = 50 + 400 + 3.000 + 20.000 + 100.000 = 123.450\\nN\\n(BFS) = 10 + 100 + 1.000 + 10.000 + 100.000 = 111.100.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 123}),\n",
       " Document(page_content='Se você está realmente preocupado com a repetição da repetição, você pode usar uma\\nabordagem híbrida que executa a busca em largura até que quase toda a memória disponível seja\\nconsumida, e então executar o aprofundamento iterativo de todos os nós na borda. \\nEm geral\\n, \\no\\naprofundamento iterativo é o método de busca sem informação preferido quando o espaço de\\nbusca é grande e a profundidade da solução não é conhecida\\n.\\nA busca por aprofundamento iterativo é análoga à busca em largura, pelo fato de explorar uma\\ncamada completa de novos nós em cada iteração, antes de passar para a próxima camada. Parece que\\nseria interessante desenvolver um algoritmo iterativo análogo à busca de custo uniforme, herdando as\\ngarantias de caráter ótimo do algoritmo anterior, ao mesmo tempo em que se reduz suas necessidades\\nde memória. A ideia é usar limites crescentes de custo de caminho, em vez de limites crescentes de\\nprofundidade. O algoritmo resultante, chamado \\nbusca de alongamento iterativo\\n, é explorado no\\nExercício 3.17. Infelizmente, o alongamento iterativo incorre em uma sobrecarga substancial, em\\ncomparação com a busca de custo uniforme.\\n3.4.6 Busca bidirecional\\nA ideia que rege a busca bidirecional é executar duas buscas simultâneas — uma direta, a partir\\ndo estado inicial, e a outra inversa, a partir do objetivo, esperando que as duas buscas se encontrem\\nem um ponto intermediário (\\nFigura 3.20\\n). A motivação é que \\nb\\nd\\n/2\\n + \\nb\\nd\\n/2\\n é muito menor que \\nb\\nd\\n ou, na\\nfigura, a área dos dois círculos pequenos é menor que a área do único círculo grande com centro no\\ninício e que chega até o objetivo.\\nImplementa-se a busca bidirecional substituindo o teste de objetivo por uma verificação para ver\\nse as bordas das duas buscas se cruzam; se isso ocorre, foi encontrada uma solução. (É importante\\nperceber que a primeira solução que foi encontrada pode não ser a ótima, mesmo que as duas buscas\\ntenham sido em largura; haverá necessidade de uma busca adicional para se certificar de que não\\nexiste algum outro atalho através do espaço.) A verificação poderá ser realizada quando o nó for\\ngerado ou selecionado para expansão e, com a tabela hash, terá um tempo constante. Por exemplo, se\\num problema tem solução à profundidade d = 6 e cada direção executa a busca em largura de um nó\\npor vez, então, no pior caso, as duas buscas se encontram quando tiverem gerado todos os nós à\\nprofundidade 3. Para b = 10 isso é um total de 2.220 gerações de nós, comparado com 1.111.110 de\\numa busca em largura padrão. Assim, a complexidade de tempo da busca bidirecional usando a busca\\nem largura nas duas direções é \\nO\\n(\\nb\\nd/2\\n). A complexidade do espaço é também \\nO\\n(\\nb\\nd/2\\n). Podemos\\nreduzir isso por cerca da metade, se uma das duas buscas for feita por aprofundamento iterativo, mas,\\npelo menos uma das bordas deve ser mantida na memória para que possa ser feita a verificação do\\ncruzamento. Esse requisito de espaço é a deficiência principal da busca bidirecional.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 124}),\n",
       " Document(page_content='Figura 3.20\\n Visão esquemática de uma busca bidirecional prestes a ter sucesso quando uma\\nramificação a partir do nó inicial encontra uma ramificação a partir do nó objetivo.\\nA redução da complexidade de tempo torna a busca bidirecional atraente, mas como realizaremos\\na busca inversa? Isso não é tão fácil quanto parece. Sejam os \\npredecessores\\n de um estado \\nx\\n todos\\naqueles estados que têm \\nx\\n como sucessor. A busca bidirecional requer um método de cálculo dos\\npredecessores. Quando todas as ações no espaço de estados forem reversíveis, os predecessores de\\nx\\n serão apenas seus sucessores. Outros casos podem exigir uma engenhosidade substancial.\\nConsidere a questão do que queremos dizer com a palavra “objetivo” na frase “busca inversa a\\npartir do objetivo”. No caso do quebra-cabeça de oito peças e da localização de uma rota na\\nRomênia, existe apenas um estado objetivo; assim, a busca inversa é muito semelhante à busca direta.\\nSe houver vários estados objetivos \\nexplicitamente listados\\n — por exemplo, os dois estados objetivo\\nlivres de sujeira da \\nFigura 3.3\\n —, poderemos construir um novo estado objetivo fictício cujos\\npredecessores imediatos serão todos os estados objetivo reais. Mas, se o objetivo for uma descrição\\nabstrata, tal como o objetivo de que “nenhuma rainha ataque outra rainha” no problema \\nn\\n-rainhas,\\nentão é difícil usar a busca bidirecional.\\n3.4.7 Comparação entre estratégias de busca sem informação\\nA \\nFigura 3.21\\n compara estratégias de busca em termos dos quatro critérios de avaliação definidos\\nna \\nSeção 3.3.2\\n. Essa comparação refere-se às versões de busca em árvore. Para buscas em grafos, a\\nprincipal diferença é que a busca em profundidade é completa para espaço de estados finitos e que as\\ncomplexidades de espaço e de tempo estão limitadas pelo tamanho do espaço de estados.\\nCritério\\nEm\\nlargura\\nCusto\\nuniforme\\nEm\\nprofundidade\\nEm\\nprofundidade\\nlimitada\\nAprofundamento\\nIterativo\\nBidirecional\\n(se\\naplicável)\\nCompleta?\\nTempo\\nEspaço\\nÓtima?\\nSim\\na\\nO\\n(\\nb\\nd\\n)\\nO\\n(\\nb\\nd\\n)\\nSim\\nc\\nSim\\na,b\\nSim\\nNão\\nO\\n(\\nb\\nm\\n)\\nO\\n(\\nb\\nm\\n)\\nNão\\nNão\\nO\\n(\\nb\\nl\\n)\\nO\\n(\\nb\\nl\\n)\\nNão\\nSim\\na\\nO\\n(\\nb\\nd\\n)\\nO\\n(\\nb\\nd\\n)\\nSim\\nc\\nSim\\na,d\\nO\\n(\\nb\\nd\\n/2\\n)\\nO\\n(\\nb\\nd\\n/2\\n)\\nSim\\nc,d\\nFigura 3.21\\n Avaliação de estratégias de busca em árvore. \\nb\\n é o fator de ramificação; \\nd\\n é a\\nprofundidade da solução mais rasa; \\nm\\n é a profundidade máxima da árvore de busca; \\nl\\n é o limite de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 125}),\n",
       " Document(page_content='profundidade. As anotações sobrescritas são: \\na\\n completa se \\nb\\n é finito; \\nb\\n completa se o custo do passo\\né ≥ \\n∊\\n para \\n∊\\n positivo; \\nc\\n ótima se os custos dos passos são todos idênticos; \\nd\\n se ambos os sentidos\\nutilizam busca em largura.\\n3.5 ESTRATÉGIA DE BUSCA INFORMADA (HEURÍSTICA)\\nEsta seção mostra como uma estratégia de \\nbusca informada\\n — a que utiliza conhecimento de um\\nproblema específico além da definição do problema em si — pode encontrar soluções de forma mais\\neficiente do que uma estratégia de busca sem informação.\\nA abordagem geral que consideramos é chamada \\nbusca de melhor escolha\\n. A busca de melhor\\nescolha é uma instância do algoritmo geral da BUSCA-EM-ÁRVORE em que um nó é selecionado\\npara a expansão com base em uma \\nfunção de avaliação\\n, f(n).\\n A função de avaliação é analisada\\ncomo uma estimativa de custo, de modo que o nó com \\na menor\\n avaliação será expandido primeiro. A\\nimplementação da busca em grafos de melhor escolha é idêntica à busca de custo uniforme (\\nFigura\\n3.14\\n), exceto pelo uso de \\nf\\n em vez de \\ng\\n para ordenar a fila de prioridade.\\nA escolha de \\nf\\n determina a estratégia de busca (por exemplo, como mostra o Exercício 3.21, a\\nbusca de melhor escolha em árvore inclui a busca em profundidade como caso especial). A maior\\nparte dos algoritmos de melhor escolha inclui como componente de \\nf\\n uma função heurística, denotada\\npor \\nh(n):\\nh(n) =\\n custo estimado do caminho de menor custo do estado do nó \\nn\\n para um estado objetivo.\\n(Note que \\nh(n)\\n recebe um \\nnó\\n como entrada, mas, ao contrário de \\ng(n)\\n, depende apenas do \\nestado\\nnaquele nó.) Por exemplo, na Romênia, pode-se estimar o custo do caminho de menor custo de Arad\\npara Bucareste através da distância em linha reta de Arad para Bucareste.\\nFunções heurísticas são a forma mais comum como o conhecimento adicional do problema é\\ntransmitido ao algoritmo de busca. Estudaremos heurísticas mais profundamente na \\nSeção 3.6\\n. Por\\nora, consideramos as heurísticas como funções arbitrárias, não negativas, de problemas específicos,\\ncom uma restrição: se \\nn\\n for um nó objetivo, então \\nh(n)\\n = 0. O restante desta seção abrange duas\\nmaneiras de usar a informação heurística para orientar a busca.\\n3.5.1 Busca gulosa de melhor escolha\\nA \\nbusca gulosa de melhor escolha\\n8\\n tenta expandir o nó que está mais próximo do objetivo, com o\\nfundamento de que isso pode conduzir a uma solução rapidamente. Assim, ela avalia os nós usando\\napenas a função heurística, ou seja, \\nf(n) = h(n).\\nVamos ver como isso funciona para problemas de roteamento na Romênia; usaremos a heurística\\nde \\ndistância em linha reta\\n (DLR), que chamaremos de \\nh\\nDLR\\n. Se o objetivo for Bucareste,\\nprecisaremos saber as distâncias em linha reta para Bucareste, apresentadas na \\nFigura 3.22\\n. Por\\nexemplo, \\nh\\nDLR\\n (\\nEm\\n(\\nArad\\n)) = 366. Observe que os valores de \\nh\\nDLR\\n não podem ser calculados da', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 126}),\n",
       " Document(page_content='descrição do problema em si. Além disso, é preciso certa experiência para saber que \\nh\\nDLR\\n está\\ncorrelacionado com as distâncias reais da estrada e, portanto, é uma heurística útil.\\nArad\\nBucareste\\nCraiova\\nDrobeta\\nEforie\\nFagaras\\nGiurgiu\\nHirsova\\nIasi\\nLugoj\\n366\\n0\\n160\\n242\\n161\\n176\\n77\\n151\\n226\\n244\\nMehadia\\nNeamt\\nOradea\\nPitesti\\nRimnicu Vilcea\\nSibiu\\nTimisoara\\nUrziceni\\nVaslui\\nZerind\\n241\\n234\\n380\\n100\\n193\\n253\\n329\\n80\\n199\\n374\\nFigura 3.22\\n Valores de \\nh\\nDLR\\n — distâncias em linha reta para Bucareste.\\nA \\nFigura 3.23\\n mostra o andamento de uma busca gulosa de melhor escolha utilizando \\nh\\nDLR\\n para\\nencontrar um caminho de Arad para Bucareste. O primeiro nó a ser expandido a partir de Arad será\\nSibiu porque é mais perto de Bucareste do que Zerind ou Timisoara. O próximo nó a ser expandido\\nserá Fagaras porque é o mais próximo. Fagaras, por sua vez, vai gerar Bucareste, que é o objetivo.\\nPara esse problema particular, a busca gulosa de melhor escolha utilizando \\nh\\nDLR\\n encontra uma\\nsolução, sem nunca expandir um nó que não estiver no caminho da solução; portanto, seu custo de\\nbusca é mínimo. Não é ótimo, no entanto: o caminho via Sibiu e Fagaras para Bucareste é 32\\nquilômetros mais longo que o caminho através de Rimnicu Vilcea e Pitesti. Isso mostra por que o\\nalgoritmo é chamado de “ambicioso”; a cada passo ele tenta chegar o mais próximo do objetivo que\\npuder.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 127}),\n",
       " Document(page_content='Figura 3.23\\n Etapas de uma busca gulosa de melhor escolha em árvore para Bucareste com a\\nheurística de distância em linha reta \\nh\\nDLR\\n. Os nós são rotulados com os seus valores \\nh\\n.\\nA busca gulosa de melhor escolha em árvore também é incompleta, mesmo em um espaço de\\nestados finito, exatamente como a busca em profundidade. Considere o problema de ir de Iasi para\\nFagaras. A heurística sugere que Neamt seja expandida primeiro porque é mais próxima de Fagaras,\\nmas isso é um beco sem saída. A solução é ir primeiro a Vaslui — um passo que, de acordo com a\\nheurística, é na verdade mais longe do objetivo — e, em seguida, continuar para Urziceni, Bucareste\\ne Fagaras. No entanto, o algoritmo nunca irá encontrar essa solução porque expandir Neamt coloca\\nIasi de volta na borda, Iasi está mais perto de Fagaras que Vaslui e, assim, Iasi será novamente\\nexpandida, levando a um laço infinito (a versão de busca em grafos \\né\\n completa em espaços finitos,\\nmas não infinitos). O pior caso de complexidade de tempo e de espaço para a versão em árvore é\\nO\\n(\\nb\\nm\\n), onde \\nm\\n é a profundidade máxima do espaço de busca. Com uma boa função heurística, no\\nentanto, a complexidade pode ser reduzida substancialmente. O montante da redução depende do\\nproblema particular e da qualidade da heurística.\\n3.5.2 Busca A*: minimização do custo total estimado da solução', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 128}),\n",
       " Document(page_content='A forma de solução mais amplamente conhecida da busca de melhor escolha é chamada de \\nbusca\\nA*\\n (pronuncia-se “busca A estrela”). Ela avalia os nós através da combinação de \\ng\\n(\\nn\\n), o custo para\\nalcançar o nó, e \\nh\\n(\\nn\\n), o custo para ir do nó ao objetivo:\\nf\\n(\\nn\\n) \\n= g\\n(\\nn\\n) \\n+ h\\n(\\nn\\n).\\nUma vez que \\ng\\n(\\nn\\n) dá o custo do caminho desde o nó inicial até o nó \\nn\\n e \\nh\\n(\\nn\\n) é o custo estimado do\\ncaminho de menor custo de \\nn\\n até o objetivo, teremos\\nf\\n (\\nn\\n) = custo estimado da solução de menor custo através de \\nn.\\nAssim, se estamos tentando encontrar a solução de menor custo, algo razoável para tentar em\\nprimeiro lugar, seria o nó com o menor valor de \\ng\\n(\\nn\\n) \\n+ h\\n(\\nn\\n). Acontece que essa estratégia é mais do\\nque apenas razoável: desde que a função heurística \\nh\\n(\\nn\\n) satisfaça certas condições, a busca A* será\\ncompleta e ótima. O algoritmo é idêntico à BUSCA-DE-CUSTO-UNIFORME, exceto que A* usa \\ng +\\nh\\n em vez de \\ng\\n.\\nCondições para otimalidade: admissibilidade e consistência\\nA primeira condição requerida para otimalidade é que \\nh\\n(\\nn\\n) seja uma \\nheurística admissível\\n. Uma\\nheurística admissível é a que nunca superestima o custo de atingir o objetivo. Devido à \\ng\\n(\\nn\\n) ser o\\ncusto real para atingir \\nn\\n ao longo do caminho atual, e \\nf\\n(\\nn) = g\\n(\\nn\\n) \\n+ h\\n(\\nn\\n), temos como consequência\\nimediata que \\nf\\n(\\nn\\n) nunca irá superestimar o verdadeiro custo de uma solução ao longo do caminho\\natual através de \\nn.\\nHeurísticas admissíveis são otimistas por natureza porque imaginam que o custo de resolver o\\nproblema seja menor do que realmente é. Um exemplo óbvio de uma heurística admissível é a \\nh\\nDLR\\nda distância em linha reta que usaremos para chegar a Bucareste. A distância em linha reta é\\nadmissível porque o caminho mais curto entre dois pontos quaisquer é uma linha reta, então a reta\\nnão pode ser uma superestimativa. Na \\nFigura 3.24\\n, mostramos a evolução de uma busca A* em\\nárvore para Bucareste. Os valores de \\ng\\n são calculados a partir dos custos dos passos na \\nFigura 3.2\\n, e\\nos valores de \\nh\\nDLR\\n são apresentados na \\nFigura 3.22\\n. Observe, particularmente, que Bucareste\\naparece pela primeira vez na borda na etapa (e), mas não é selecionada para expansão porque seu\\nf-\\ncusto (450) é maior que o de Pitesti (417). Outra maneira de dizer isso é que \\npode\\n haver uma\\nsolução através de Pitesti, cujo custo seja tão baixo quanto 417, de modo que o algoritmo nao vai se\\ncontentar com uma solução que custe 450.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 129}),\n",
       " Document(page_content='Figura 3.24\\n Etapas em uma busca A* para Bucareste. Nós são rotulados com \\nf = g + h\\n. Os valores\\nde \\nh\\n são as distâncias em linha reta para Bucareste tomadas a partir da \\nFigura 3.22\\n.\\nUma segunda condição um pouco mais forte chamada \\nconsistência\\n (ou, algumas vezes,\\nmonotonicidade\\n) é necessária apenas para aplicativos de A* para busca em grafos.\\n9\\n Uma heurística\\nh\\n(\\nn\\n) será consistente se, para cada nó \\nn\\n e para todo sucessor \\nn\\n′ de \\nn\\n gerado por uma ação \\na\\n, o custo\\nestimado de alcançar o objetivo de \\nn\\n não for maior do que o custo do passo de chegar a \\nn\\n′ \\nm\\nais o\\ncusto estimado de alcançar o objetivo de \\nn\\n′.\\nh\\n(\\nn\\n) \\n≤ c\\n(\\nn, a, n\\n′) \\n+ h\\n(\\nn\\n′)\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 130}),\n",
       " Document(page_content='Essa é uma forma genérica de \\ndesigualdade triangular\\n, que estipula que cada um dos lados de um\\ntriângulo não pode ser mais longo que a soma dos outros dois lados. Aqui, o triângulo é formado por\\nn, n\\n′ e o objetivo \\nG\\nn\\n mais próximo de \\nn\\n. Para uma heurística admissível, a desigualdade faz todo\\nsentido: se houvesse uma rota de \\nn\\n para \\nG\\nn\\n via \\nn\\n′ que fosse mais barata do que \\nh\\n(\\nn\\n), que violasse a\\npropriedade de que \\nh\\n(\\nn\\n) está em um limite inferior de custo para chegar a \\nG\\nn\\n.\\nÉ bastante fácil mostrar (Exercício 3.39) que toda a heurística consistente é também admissível. A\\nconsistência é, portanto, uma exigência mais rigorosa que a admissibilidade, mas deve-se trabalhar\\nbastante para construir heurísticas que sejam admissíveis, mas não consistentes. Todas as heurísticas\\nadmissíveis que discutiremos neste capítulo são também consistentes. Considere por exemplo, \\nh\\nDLR\\n.\\nSabemos que a desigualdade triangular genérica é satisfeita quando cada lado é medido pela\\ndistância em linha reta e que a distância em linha reta entre \\nn\\n e \\nn\\n′ não é maior que \\nc(n, a, n\\n′). Assim,\\nh\\nDLR\\n é uma heurística consistente.\\nOtimalidade de A*\\n Como mencionamos anteriormente, A* tem as seguintes propriedades: \\na versão de busca em\\nárvore de A* é ótima se h\\n(\\nn\\n) \\nfor admissível, enquanto a versão de busca em grafos de A* é ótima\\nse h\\n(\\nn\\n) \\nfor consistente.\\nApresentaremos a segunda dessas duas afirmações, uma vez que é mais útil. O argumento se\\nespelha essencialmente no argumento de otimalidade da busca de custo uniforme com \\ng\\n substituído\\npor \\nf\\n, exatamente como definida no próprio algoritmo A*.\\n No primeiro passo iremos estabelecer o seguinte: \\nse h\\n(\\nn\\n) \\nfor consistente, então os valores de\\nf\\n(\\nn\\n) \\nao longo de qualquer caminho serão não decrescentes\\n. A prova vem diretamente da definição\\nde consistência. Suponha que \\nn\\n′ seja sucessor de \\nn\\n, então \\ng\\n(\\nn\\n′) = \\ng(n\\n) \\n+ c\\n(\\nn, a, n\\n′\\n)\\n para alguma ação\\na\\n e teremos:\\nf\\n(\\nn\\n′) \\n= g\\n(\\nn\\n′) \\n+ h\\n(\\nn\\n′) \\n= g\\n(\\nn\\n) \\n+ c\\n(\\nn, a, n\\n′) \\n+ h\\n(\\nn\\n′) \\n≥ g\\n(\\nn\\n) \\n+ h\\n(\\nn\\n) \\n= f\\n(\\nn\\n)\\n.\\n O próximo passo será provar que sempre que A* \\nselecionar um nó n para expansão, o\\ncaminho ótimo para aquele nó foi encontrado.\\n Se isso não fosse verdade, deveria haver outro nó da\\nborda \\nn\\n′ no caminho ótimo do nó inicial até \\nn,\\n pela propriedade de separação de grafos da \\nFigura 3.9\\nporque \\nf\\n é não decrescente ao longo de qualquer caminho, \\nn\\n′ teria menor \\nf-\\ncusto que \\nn\\n e teria sido\\nselecionado em primeiro lugar.\\nDas duas observações anteriores, segue que a sequência de nós expandidos por A* utilizando a\\nBUSCA_EM_GRAFOS está em ordem não decrescente de \\nf\\n(\\nn\\n). Assim, o primeiro nó objetivo\\nselecionado para a expansão deve ser uma solução ótima porque \\nf\\n é o custo real para nós objetivo\\n(que têm \\nh\\n = 0) e todos os outros nós objetivo visitados posteriormente terão custo igual ou maior.\\nO fato de que os custos \\nf\\n são não decrescentes ao longo de qualquer caminho significa que\\npodemos também extrair \\ncontornos\\n no espaço de estados, como os contornos de um mapa\\ntopográfico. A \\nFigura 3.25\\n mostra um exemplo. Dentro do contorno rotulado 400, todos os nós têm\\nf\\n(\\nn\\n) menor ou igual a 400, e assim por diante. Então, devido a A* expandir o nó de borda de menor \\nf\\n-\\ncusto, podemos ver que uma busca A* espalha-se a partir do nó de início, adicionando nós em faixas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 131}),\n",
       " Document(page_content='concêntricas de \\nf-\\ncusto crescente.\\nFigura 3.25\\n Mapa da Romênia mostrando contornos em \\nf\\n = 380, \\nf\\n = 400 e \\nf\\n = 420, com Arad como o\\nestado inicial. Os nós dentro de um contorno dado tem \\nf\\n-custo menor ou igual ao valor do contorno.\\nCom busca de custo uniforme (busca A* utilizando \\nh\\n(\\nn\\n) = 0), as faixas serão “circulares” em torno\\ndo estado inicial. Com heurísticas mais precisas, as faixas irão se estender em direção ao estado\\nobjetivo e ficarão mais focadas em torno do caminho ótimo. Se \\nC*\\n for o custo do caminho de solução\\nótima, então podemos dizer o seguinte:\\n•  A* expande todos os nós com \\nf\\n(\\nn\\n) \\n<C*.\\n•  A* pode então expandir alguns dos nós bem sobre o “contorno objetivo” \\n(onde f\\n(\\nn\\n) \\n= C*\\n), antes\\nde selecionar um nó objetivo.\\nA completeza requer que haja apenas um número finito de nós com custo menor ou igual a \\nC\\n*, uma\\ncondição que é verdadeira se todos os custos de passo ultrapassarem alguns \\n∊\\n finitos e se \\nb\\n for finito.\\nObserve que A* não expande os nós com \\nf\\n(\\nn\\n) \\n>C*\\n — por exemplo, Timisoara não foi expandido\\nna \\nFigura 3.24\\n, mesmo sendo um filho da raiz. Dizemos que a subárvore abaixo de Timisoara foi\\npodada\\n; porque \\nh\\nDLR\\n é admissível, o algoritmo pode ignorar essa subárvore com segurança e ainda\\nassim garantir otimalidade. O conceito de poda — eliminação de possibilidades de consideração\\nsem ter de examiná-las — é importante para muitas áreas de IA.\\nUma observação final é que, entre os algoritmos ótimos desse tipo — algoritmos que estendem os\\ncaminhos de busca a partir da raiz e utilizam a mesma informação heurística —, A* é \\notimamente\\neficiente\\n para qualquer dado heurístico consistente. Ou seja, não é garantido que nenhum outro\\nalgoritmo ótimo expanda menos nós do que A* (exceto, possivelmente, através de desempate entre os\\nnós com \\nf\\n(\\nn\\n) \\n= C\\n*). Isso ocorre porque qualquer algoritmo que não expande todos os nós com \\nf\\n(\\nn\\n) \\n<\\nC*\\n corre o risco de perder a solução ótima.\\nÉ muito bom que a busca A* seja completa, ótima e otimamente eficiente entre todos os algoritmos\\ndesse tipo. Infelizmente, isso não significa que A* seja a resposta para todas as nossas necessidades\\nde busca. O problema é que, para a maioria dos problemas, o número de estados dentro do espaço de\\nbusca do contorno objetivo ainda é exponencial no comprimento da solução. Os detalhes da análise', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 132}),\n",
       " Document(page_content='estão fora do escopo deste livro, mas os resultados básicos são os seguintes. Para problemas com\\ncustos de passo constante, o crescimento em tempo de execução como uma função da solução ótima\\nde profundidade \\nd\\n é analisada em termos do \\nerro absoluto\\n ou do \\nerro relativo\\n da heurística. O erro\\nabsoluto é definido como \\nΔ\\n ≡ \\nh* – h\\n, onde \\nh*\\n é o custo real a partir da raiz para o objetivo, e o erro\\nrelativo é definido como \\n∊\\n ≡ (\\nh*\\n – \\nh\\n)/\\nh*.\\nA complexidade resultante depende fortemente das suposições feitas sobre o espaço de estados. O\\nmodelo mais simples estudado é um espaço de estados que tem um único objetivo e é essencialmente\\numa árvore com ações reversíveis (um quebra-cabeças de oito peças satisfaz o primeiro e o terceiro\\ndesses pressupostos). Nesse caso, a complexidade de tempo de A* é exponencial no erro máximo\\nabsoluto, ou seja, \\nO\\n(\\nb\\nΔ\\n). Para os custos de passo constante, podemos escrever isso como \\nO(b\\n∊\\nd\\n),\\nonde \\nd\\n é a solução de profundidade. Para quase todas as heurísticas na prática, o erro absoluto é pelo\\nmenos proporcional ao custo do caminho \\nh\\n*, por isso \\n∊\\n é constante ou crescente e a complexidade de\\ntempo é exponencial em \\nd\\n. Nós também podemos verificar o efeito de uma heurística mais precisa:\\nO\\n(\\nb\\n∊\\nd\\n) = \\nO\\n(\\nb\\n∊\\n)\\nd\\n), então o fator de ramificação efetivo (mais formalmente definido na próxima\\nseção) é \\nb\\n∊\\n.\\nQuando o espaço de estados tem muitos estados objetivos, particularmente estados objetivos\\nquase ótimos\\n, o processo de busca pode ser desviado do caminho ótimo e haverá um custo adicional\\nproporcional extra ao número de objetivos cujo custo está dentro do fator \\n∊\\n de custo ótimo.\\nFinalmente, no caso geral de um grafo, a situação é ainda pior. Pode haver muitos estados\\nexponencialmente com \\nf\\n(\\nn\\n) \\n< C*\\n, mesmo que o erro absoluto esteja limitado por uma constante. Por\\nexemplo, considere uma versão do mundo do aspirador de pó, onde o agente pode limpar qualquer\\nquadrado pelo custo unitário, mesmo sem ter que visitá-lo: nesse caso, os quadrados podem ser\\nlimpos em qualquer ordem. Com \\nN\\n quadrados sujos inicialmente, existem 2\\nn\\n estados em que um\\nsubconjunto foi limpo e todos eles estão no caminho da solução ótima — e, portanto, satisfazem \\nf\\n(\\nn\\n)\\n< C*,\\n mesmo que a heurística tenha um erro de 1.\\nA complexidade de A* muitas vezes torna impraticável insistir em encontrar uma solução ótima.\\nVariantes de A* que encontrem rapidamente soluções subótimas podem ser utilizadas ou, por vezes,\\nser projetadas heurísticas que sejam mais precisas, mas não necessariamente admissíveis. Em\\nqualquer caso, o uso de uma boa heurística ainda oferece economia enorme em comparação com o\\nuso de uma busca não informada. Na \\nSeção 3.6\\n veremos a questão projetar uma boa heurística.\\nO tempo de computação, contudo, não é a principal desvantagem de A*. Por manter todos os nós\\ngerados na memória (como fazem todos os algoritmos de BUSCA-EM-GRAFOS), a busca A*\\ngeralmente atinge um limite de memória (“estouro de memória”) do espaço bem antes de exceder um\\ndado limite de tempo. Por essa razão, A* não é praticável para muitos problemas de larga escala.\\nHá, no entanto, algoritmos que superam o problema de espaço sem sacrificar a otimalidade ou\\nintegridade, a um custo pequeno em tempo de execução, conforme discutiremos a seguir.\\n3.5.3 Busca heurística limitada pela memória\\nA maneira mais simples para reduzir os requisitos de memória para A* é adaptar a ideia de\\naprofundamento iterativo para o contexto de busca heurística, resultando no algoritmo de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 133}),\n",
       " Document(page_content='aprofundamento iterativo A*\\n (IDA* – Iterative Deepening A*). A principal diferença entre IDA* e\\no aprofundamento iterativo padrão é que o corte utilizado é o \\nf-\\ncusto (\\ng + h)\\n em vez da profundidade;\\nem cada iteração, o valor de corte é o menor \\nf-\\ncusto de qualquer nó que excedeu o corte na iteração\\nanterior. O IDA* é prático para muitos problemas com custos de passo unitário e evita a sobrecarga\\nassociada à manutenção de uma fila ordenada de nós. Infelizmente, ele sofre das mesmas dificuldades\\ndos custos de valor real que a versão iterativa da busca de custo uniforme descrita no Exercício 3.17.\\nEsta seção examina brevemente outros dois algoritmos de memória limitada, chamados RBFS e\\nMA*.\\nA \\nbusca recursiva\\n \\nde melhor escolha\\n (RBFS – Recursive Best First Search) é um algoritmo\\nrecursivo simples que tenta imitar a operação de busca padrão pela melhor escolha, mas usando\\napenas um espaço linear de memória. O algoritmo é mostrado na \\nFigura 3.26\\n. Sua estrutura é\\nsemelhante ao de uma busca em profundidade recursiva, mas, em vez de continuar indefinidamente\\nseguindo o caminho atual, ele utiliza a variável \\nf_limite\\n para acompanhar o \\nf\\n-valor do melhor\\ncaminho \\nalternativo\\n disponível de qualquer ancestral do nó atual. Se o nó atual exceder esse limite,\\na recursão reverte para o caminho alternativo. Com a reversão da recursão, o RBFS substitui o \\nf\\n-\\nvalor de cada nó ao longo do caminho por um \\nvalor de backup\\n — o melhor \\nf\\n-valor de seus filhos.\\nDessa forma, a RBFS lembra o \\nf\\n-valor das melhores folhas da subárvore esquecida e pode, portanto,\\ndecidir se vale a pena reexpandir a subárvore algum tempo mais tarde. A \\nFigura 3.27\\n mostra como a\\nRBFS atinge Bucareste.\\nfunção\\n BUSCA-RECURSIVA-PELA-MELHOR(\\nproblema\\n) \\nretorna\\n uma solução ou falha\\n    \\nretorna\\n RBFS(\\nproblema\\n, FAZ-NÓ(\\nproblema\\n. ESTADO-INICIAL), ∞)\\nfunção\\n RBFS (\\nproblema\\n, \\nnó,\\n \\nf_limite\\n) \\nretorna\\n uma solução ou falha e um limite novo \\nf_custo\\n    \\nse\\n problema. TESTE-OBJETIVO(nó.ESTADO) \\nentão retorne\\n SOLUÇÃO (\\nnó\\n)\\n    \\nsucessores\\n ← [ ]\\n    \\npara cada\\n \\nação\\n \\nem\\n \\nproblema\\n. AÇÕES(nó.ESTADO) \\nfazer\\n        adicionar NÓ-FILHO(\\nproblema, nó, ação\\n) em \\nsucessores\\n    \\nse\\n \\nsucessores\\n estiver vazio \\nentão retornar\\n falha), ∞\\n    \\npara cada\\n \\ns\\n \\nem\\n \\nsucessores\\n \\nfazer\\n / * atualizar \\nf\\n com o valor da busca anterior, se houver */\\n        s.\\nf\\n ← max(\\ns.g\\n + \\ns.h, nó.f\\n))\\n    \\nrepita\\n        \\nmelhor\\n ← valor \\nf\\n mais baixo do nó em \\nsucessores\\n        \\nse\\n \\nmelhor\\n.\\nf\\n > \\nf_limite\\n \\nentão retornar\\n \\nfalha, melhor\\n.\\nf\\n        \\nalternativa\\n ← segundo valor \\nf\\n mais baixo entre \\nsucessores\\n        \\nresultado\\n, \\nmelhor\\n.\\nf\\n ← RBFS(\\nproblema, melhor\\n, min(\\nf_limite\\n, \\nalternativa\\n)\\n        \\nse\\n \\nresultado\\n ≠ \\nfalha\\n \\nentão retornar\\n \\nresultado\\nFigura 3.26\\n Algoritmo para busca de melhor escolha recursiva.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 134}),\n",
       " Document(page_content='Figura 3.27\\n Etapas de uma busca RBFS para a rota mais curta para Bucareste. O valor do \\nf\\n_limite\\npara cada chamada recursiva é mostrado no topo de cada nó atual, e cada nó é rotulado com seu\\nf-\\ncusto\\n.\\n (a) O caminho via Rimnicu Vilcea é seguido até que a melhor folha atual (Pitesti) tenha um\\nvalor que é pior do que o melhor caminho alternativo (Fagaras). (b) A recursão reverte e o melhor\\nvalor da folha da subárvore esquecida (417) é copiado para Rimnicu Vilcea, então Fagaras é\\nexpandida, revelando um melhor valor da folha de 450. (c) A recursão reverte e o melhor valor da\\nfolha da subárvore esquecida (450) é copiado para Fagaras, então Rimnicu Vilcea é expandida.\\nDessa vez, devido ao melhor caminho alternativo (através de Timisoara), custa pelo menos 447, e a\\nexpansão continua para Bucareste.\\nA RBFS é um pouco mais eficiente do que a IDA*, mas ainda sofre pela geração excessiva de um\\nmesmo nó. No exemplo da \\nFigura 3.27\\n, a RBFS segue o caminho via Rimnicu Vilcea, depois “muda\\nde ideia” e tenta Fagaras, e depois muda de ideia novamente. Essas mudanças de ideia ocorrem\\nporque, cada vez que o melhor caminho atual é estendido, seu \\nf-\\nvalor possivelmente cresce — \\nh\\ngeralmente é menos otimista para nós mais perto do objetivo. Quando isso acontece, o segundo\\nmelhor caminho pode se tornar o melhor caminho; assim, a busca tem que recuar para segui-lo. Cada\\nmudança de ideia corresponde a uma iteração da IDA* e pode exigir muitas reexpansões de nós\\nesquecidos para recriar o melhor caminho e estendê-lo com mais um nó.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 135}),\n",
       " Document(page_content='Como a busca em árvore A*, a RBFS é um algoritmo ótimo se a função heurística \\nh\\n(\\nn)\\n for\\nadmissível. Sua complexidade de espaço é linear com relação à profundidade da solução ótima, mas\\na sua complexidade de tempo é bastante difícil de caracterizar: ela depende tanto da precisão da\\nfunção heurística como do quão frequente o melhor caminho se altera à medida que os nós são\\nexpandidos.\\nAs buscas IDA* e RBFS sofrem por usarem \\npouca\\n memória. Entre iterações, a IDA* retém apenas\\num número único: o limite atual do \\nf-\\ncusto. A RBFS retém mais informações na memória, mas utiliza\\napenas espaço linear: mesmo se mais memória estiver disponível, a RBFS não teria como fazer uso\\ndela. Por esquecerem muito do que fizeram, ambos os algoritmos podem acabar reexpandindo os\\nmesmos estados muitas vezes. Além disso, eles sofrem o crescimento potencialmente exponencial em\\ncomplexidade associado com caminhos redundantes em grafos (veja a \\nSeção 3.3\\n).\\nParece sensato, portanto, usar toda a memória disponível. Dois algoritmos que fazem isso são o\\nMA*\\n (A* de memória limitada) e o \\nSMA*\\n (MA* simplificado). O SMA* é bem mais simples, de\\nmodo que iremos descrevê-lo. O SMA* procede exatamente como o A*, expandindo a melhor folha\\naté que a memória esteja cheia. Nesse ponto, não poderá adicionar um novo nó à árvore de busca\\nsem suprimir um antigo. O SMA* sempre suprime o \\npior\\n nó folha — o que tem o maior \\nf_\\nvalor.\\nComo o RBFS, o SMA*, em seguida, faz o backup do valor do nó esquecido em seu pai. Dessa\\nforma, o ancestral de uma subárvore esquecida conhece a qualidade do melhor caminho daquela\\nsubárvore. Com essa informação, o SMA* regenera a subárvore somente quando todos os outros\\ncaminhos foram mostrados como piores do que o caminho que ele esqueceu. Outra maneira de dizer\\nisso é que, se todos os descendentes de um nó \\nn\\n forem esquecidos, não saberemos para onde ir a\\npartir de \\nn\\n, mas ainda teremos uma ideia de como vale a pena ir a algum lugar de \\nn\\n.\\nO algoritmo completo é muito complicado para reproduzir aqui,\\n10\\n mas há uma sutileza que vale a\\npena mencionar. Dissemos que o SMA* expande a melhor folha e exclui a pior folha. E, se \\ntodos\\n os\\nnós folha tiverem o mesmo \\nf_\\nvalor? Para evitar a seleção do mesmo nó para exclusão e expansão, o\\nSMA* expande a melhor folha mais \\nnova\\n e exclui a pior folha \\nmais antiga\\n. Estas coincidem quando\\nhá apenas uma folha, mas nesse caso a árvore de busca atual deve ser um único caminho da raiz até a\\nfolha que preenche toda a memória. Se a folha não for um nó objetivo, \\nmesmo que esteja em um\\ncaminho de solução ótima\\n, essa solução não será alcançável com a memória disponível. Desta\\nforma, o nó poderá ser descartado exatamente como se não tivesse sucessores.\\nO SMA* estará completo se houver qualquer solução acessível, isto é, se \\nd\\n, a profundidade do nó\\nobjetivo mais raso, for menor que o tamanho da memória (expressa em nós). Será ótimo se qualquer\\nsolução ótima for alcançada; caso contrário, ele devolverá a melhor solução alcançável. Em termos\\npráticos, o SMA* é uma escolha bastante robusta para encontrar soluções ótimas, especialmente\\nquando o espaço de estados é um grafo, os custos de passo não são uniformes e a geração do nó é\\ncara em comparação com a sobrecarga de manutenção da borda e do conjunto explorado.\\nPara problemas muito difíceis, no entanto, muitas vezes o SMA* é forçado a alternar\\nconstantemente entre muitos caminhos candidatos à solução, da qual pode caber na memória apenas\\num pequeno subconjunto (isso se assemelha ao problema de \\ndegradação\\n em sistemas de paginação\\nde disco). Então, o tempo extra que é necessário para a regeneração repetida dos mesmos nós\\nsignifica que os problemas que poderiam ser praticamente solúveis com A*, dada a memória\\nilimitada, tornam-se intratáveis por SMA*. Isso significa dizer que \\nas limitações de memória podem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 136}),\n",
       " Document(page_content='se tornar um problema intratável do ponto de vista de tempo computacional\\n. Embora nenhuma\\nteoria atual explique o equilíbrio entre tempo e memória, esse parece ser um problema inevitável. A\\núnica saída é abandonar a exigência de otimalidade.\\n3.5.4 Aprendizagem para melhorar a busca\\nApresentamos diversas estratégias fixas — busca em largura, busca gulosa de melhor escolha, e\\nassim por diante — que foram projetadas por cientistas da computação. Um agente pode \\naprender\\npara melhorar a busca? A resposta é sim, e o método se baseia em um conceito importante chamado\\nde \\nespaço de estados do nível meta.\\n Cada estado em um espaço de estados do nível meta representa\\no estado (computacional) interno de um programa que faz a busca em um \\nespaço de estado do nível\\nobjeto\\n, tal como a Romênia. Por exemplo, o estado interno do algoritmo A* consiste na árvore de\\nbusca atual. Cada ação no espaço de estados do nível meta é um passo computacional que altera o\\nestado interno; por exemplo, cada passo computacional em A* expande um nó folha e adiciona seus\\nsucessores na árvore. Assim, a \\nFigura 3.24\\n, que mostra uma sequência de árvores de busca cada vez\\nmaiores, pode ser vista como representando um caminho no espaço de estados do nível meta onde\\ncada estado no caminho é uma árvore de busca no nível objeto.\\nAgora, o caminho na \\nFigura 3.24\\n tem cinco passos, incluindo um passo, a expansão de Fagaras,\\nque não é especialmente útil. Para os problemas mais difíceis, haverá muitos erros desse tipo, e um\\nalgoritmo de \\naprendizagem no nível meta\\n pode aprender com essas experiências para evitar\\nexplorar subárvores pouco promissoras. As técnicas utilizadas para esse tipo de aprendizagem são\\ndescritas no Capítulo 21. O objetivo da aprendizagem é minimizar o \\ncusto total\\n da solução do\\nproblema, fazendo um compromisso entre o custo computacional e o custo do caminho.\\n3.6 FUNÇÕES HEURÍSTICAS\\nNesta seção, examinaremos a heurística para o quebra-cabeças de oito peças, a fim de esclarecer a\\nnatureza da heurística em geral.\\nO quebra-cabeças de oito peças é um dos primeiros problemas de busca heurística. Como\\nmencionado na \\nSeção 3.2\\n, o objetivo do quebra-cabeças é deslizar as peças horizontal ou\\nverticalmente para o espaço vazio até que a configuração corresponda à configuração objetivo\\n(\\nFigura 3.28\\n).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 137}),\n",
       " Document(page_content='Figura 3.28\\n Exemplo típico de instância do quebra-cabeças de oito peças. A solução é de 26 passos\\nlongos.\\nO custo médio da solução para uma instância do quebra-cabeças de oito peças gerada\\naleatoriamente é de cerca de 22 passos. O fator de ramificação é cerca de 3 (quando a peça branca\\nestiver no meio, é possível quatro movimentos, quando estiver em um canto, dois; quando estiver ao\\nlongo de uma borda, três). Isso significa que uma busca exaustiva da árvore de profundidade 22\\nficaria em cerca de 3\\n22\\n ≈ 3,1 \\n×\\n 10\\n10\\n estados. Uma busca em grafos reduziria isso de um fator de cerca\\nde 170.000, porque apenas 9!/2 = 181.440 estados distintos são alcançáveis (veja o Exercício 3.4).\\nEsse é um número gerenciável, mas o número correspondente para o quebra-cabeças de 15 é de\\naproximadamente 10\\n13\\n, assim a próxima tarefa é encontrar uma boa função heurística. Se quisermos\\nencontrar as soluções mais curtas usando A*, precisamos de uma função heurística que nunca\\nsuperestime o número de passos até o objetivo. Há um longo histórico de tais heurísticas para o\\nquebra-cabeças de 15 peças. Seguem as duas mais utilizadas:\\n•  \\nh\\n1\\n = número de peças fora de lugar. Para a \\nFigura 3.28\\n, todas as oito peças estão fora de lugar,\\nde modo que o estado inicial teria \\nh\\n1\\n = 8. \\nh\\n1\\n é uma heurística admissível porque é claro que\\nqualquer peça que esteja fora de lugar deverá ser movida pelo menos uma vez.\\n•  \\nh\\n2\\n = soma das distâncias das peças de suas posições-objetivo. Devido às peças não poderem ser\\nmovidas ao longo de diagonais, a distância que vai contar é a soma das distâncias horizontal e\\nvertical. Isso, às vezes, é chamado de \\ndistância de quarteirão da cidade\\n ou \\ndistância de\\nManhattan\\n. \\nh\\n2\\n é também admissível porque todo movimento que pode ser feito move uma peça\\num passo mais perto do objetivo. As peças 1-8 no estado inicial dão uma distância de Manhattan\\nde:\\nh\\n2\\n = 3 + 1 +2 + 2 + 2 + 3 + 3 + 2 = 18.\\nComo esperado, nenhuma delas superestima o custo da solução verdadeira, que é 26.\\n3.6.1 O efeito da precisão heurística sobre o desempenho\\nUma forma de caracterizar a qualidade de uma heurística é o \\nfator de ramificação efetivo\\n \\nb\\n*. Se\\no número total de nós gerados por A* para um problema particular for \\nN\\n e a solução da profundidade\\nfor \\nd\\n, então \\nb\\n* é o fator de ramificação que uma árvore uniforme de profundidade \\nd\\n teria de ter a fim\\nde conter \\nN\\n + 1 nós. Assim,\\nN\\n +1 = 1 + \\nb\\n* + (\\nb\\n*)\\n2\\n + … + (\\nb\\n*)\\nd\\n.\\nPor exemplo, se A* encontra uma solução à profundidade 5 utilizando 52 nós, então o fator de\\nramificação efetivo é 1,92. O fator de ramificação efetivo pode variar entre instâncias do problema,\\nmas geralmente é razoavelmente constante para problemas difíceis. (A existência de um fator de\\nramificação efetivo parte do resultado, mencionado anteriormente, implica que o número de nós\\nexpandidos por A* cresce exponencialmente com a solução da profundidade.) Portanto, as medidas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 138}),\n",
       " Document(page_content='experimentais de \\nb\\n* em um pequeno conjunto de problemas podem fornecer um bom guia para a\\nutilidade geral da heurística. Uma heurística bem projetada teria um valor de \\nb\\n* próximo de 1,\\npermitindo que problemas bem grandes sejam resolvidos a um custo computacional razoável.\\nPara testar as funções heurísticas \\nh\\n1\\n e \\nh\\n2\\n, geramos 1.200 problemas aleatórios com soluções que\\nvão de 2 a 24 (100 para cada número par) e as resolvemos com busca de aprofundamento iterativo\\nA* e com busca em árvore usando tanto \\nh\\n1\\n como \\nh\\n2\\n. A \\nFigura 3.29\\n apresenta o número médio de nós\\ngerados por cada estratégia e o fator de ramificação efetivo. Os resultados sugerem que \\nh\\n2\\n é melhor\\ndo que \\nh\\n1\\n, e é muito melhor do que utilizar busca de aprofundamento iterativo. Mesmo para\\nproblemas pequenos com \\nd\\n = 12, A* com \\nh\\n2\\n é 50.000 vezes mais eficiente que a busca não informada\\nde aprofundamento iterativo.\\n \\nCusto da Busca (nós gerados)\\nFator de Ramificação Efetivo\\nd\\nIDS\\nA*(\\nh\\n1\\n)\\nA*(\\nh\\n2\\n)\\nIDS\\nA*(\\nh\\n1\\n)\\nA*(\\nh\\n2\\n)\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\n18\\n20\\n22\\n24\\n10\\n112\\n680\\n6384\\n47127\\n3644035\\n-\\n-\\n-\\n-\\n-\\n-\\n6\\n13\\n20\\n39\\n93\\n227\\n539\\n1301\\n3056\\n7276\\n18094\\n39135\\n6\\n12\\n18\\n25\\n39\\n73\\n113\\n211\\n363\\n676\\n1219\\n1641\\n2,45\\n2,87\\n2,73\\n2,80\\n2,79\\n2,78\\n-\\n-\\n-\\n-\\n-\\n-\\n1,79\\n1,48\\n1,34\\n1,33\\n1,38\\n1,42\\n1,44\\n1,45\\n1,46\\n1,47\\n1,48\\n1,48\\n1,79\\n1,45\\n1,30\\n1,24\\n1,22\\n1,24\\n1,23\\n1,25\\n1,26\\n1,27\\n1,28\\n1,26\\nFigura 3.29\\n Comparação dos custos da busca e fatores de ramificação para a BUSCA-DE-\\nAPROFUNDAMENTO-ITERATIVO (IOS) e algoritimos de A* com \\nh\\n1\\n, \\nh\\n2\\n. Calcula-se a média dos\\ndados sobre 100 exemplos do quebra-cabeças de oito peças para cada uma das diversas soluções\\nque se distanciam de \\nd.\\nA questão é se \\nh\\n2\\n é sempre melhor que \\nh\\n1\\n. A resposta é: “Essencialmente, sim.” É fácil verificar a\\npartir das definições das duas heurísticas que, para qualquer nó \\nn\\n, \\nh\\n2\\n(\\nn\\n) ≥ \\nh\\n1\\n(n\\n). Dizemos portanto\\nque \\nh\\n2\\n \\ndomina\\n \\nh\\n1\\n. A dominação se traduz diretamente em eficiência: A* utilizando \\nh\\n2\\n nunca irá\\nexpandir mais nós do que A* utilizando \\nh\\n1\\n (exceto, possivelmente, para alguns nós com \\nf\\n(\\nn\\n) \\n= C\\n*). O\\nargumento é simples. Lembre-se da observação de que cada nó com \\nf\\n(\\nn\\n) < \\nC\\n* certamente será\\nexpandido. É o mesmo que dizer que cada nó com \\nh\\n(\\nn\\n) < \\nC\\n* – \\ng\\n(\\nn\\n) certamente será expandido. Mas,\\ndevido a \\nh\\n2\\n ser pelo menos tão grande quanto \\nh\\n1\\n para todos os nós, cada nó que de fato for expandido', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 139}),\n",
       " Document(page_content='pela busca A* com \\nh\\n2\\n será de fato também expandido com \\nh\\n1\\n, e \\nh\\n1\\n poderá fazer com que outros nós\\ntambém sejam expandidos. Por isso, geralmente é melhor utilizar uma função heurística com valores\\nmais elevados desde que seja consistente e que o cálculo do tempo para a heurística não seja muito\\nlongo.\\n3.6.2 Geração de heurísticas admissíveis de problemas relaxados\\nVimos que tanto \\nh\\n1\\n (peças em lugares errados) como \\nh\\n2\\n (distância de Manhattan) são heurísticas\\nbastante boas para o quebra-cabeças de oito peças e que \\nh\\n2\\n é melhor. Como \\nh\\n2\\n apareceu? É possível\\npara um computador inventar tal heurística mecanicamente?\\nh\\n1\\n e \\nh\\n1\\n são estimativas do comprimento do caminho restante para o quebra-cabeças de oito peças,\\nmas são também comprimentos de caminho perfeitamente precisos para versões simplificadas do\\nquebra-cabeça. Se as regras do quebra-cabeça forem alteradas de modo que uma peça possa ser\\nmovida para qualquer lugar em vez de apenas para o quadrado adjacente vazio, então \\nh\\n1\\n dará o\\nnúmero exato de passos para a solução mais curta. Da mesma forma, se uma peça puder ser movida\\num quadrado em qualquer direção, mesmo para um quadrado ocupado, \\nh\\n2\\n dará o número exato de\\npassos para a menor solução. Um problema com poucas restrições sobre as ações é chamado de\\nproblema relaxado\\n. O grafo de espaço de estados do problema relaxado é um \\nsupergrafo\\n do espaço\\nde estados original porque a eliminação das restrições cria arestas adicionais no grafo.\\n Em razão do problema relaxado acrescentar arestas para o espaço de estados, qualquer solução\\nótima do problema original será, por definição, também uma solução do problema relaxado, mas o\\nproblema relaxado pode ter \\nmelhores\\n soluções, se as arestas adicionadas fornecerem atalhos. Assim,\\no custo de uma solução ótima para um problema relaxado é uma heurística admissível para o\\nproblema original.\\n Além disso, como a heurística derivada é o custo exato para o problema\\nrelaxado, este deverá obedecer à desigualdade triangular e, portanto, ser \\nconsistente\\n (ver \\nSeção\\n3.5.2\\n).\\nSe a definição do problema for escrita em linguagem formal, é possível construir problemas\\nrelaxados automaticamente.\\n11\\n Por exemplo, se as ações do quebra-cabeças de oito peças forem\\ndescritas como\\nUma peça pode se mover do quadrado A para B se\\nA for horizontal ou verticalmente adjacente a B \\ne\\n B estiver vazio,\\npodemos gerar três problemas relaxados, removendo uma ou ambas as condições:\\n(a) Uma peça pode se mover do quadrado A para o quadrado B se A for adjacente a B.\\n(b) Uma peça pode se mover do quadrado A para o quadrado B se B estiver vazio.\\n(c) Uma peça pode se mover do quadrado A para o quadrado B.\\nA partir de (a), podemos derivar \\nh\\n2\\n (distância de Manhattan). O raciocínio é que \\nh\\n2\\n seria a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 140}),\n",
       " Document(page_content='pontuação adequada se movêssemos cada peça por vez para o seu destino. A heurística derivada de\\n(b) será discutida no Exercício 3.31. A partir de (c), podemos derivar \\nh\\n1\\n (peças em lugar errado)\\nporque seria a pontuação adequada se as peças pudessem ser movidas para o destino final em um\\npasso. Observe que é crucial que os problemas relaxados gerados por essa técnica possam ser\\nresolvidos essencialmente \\nsem busca\\n porque as regras relaxadas permitem que o problema seja\\ndecomposto em oito subproblemas independentes. Se o problema relaxado for difícil de resolver, os\\nvalores da heurística correspondente serão caros para serem obtidos.\\n12\\nUm programa chamado ABSOLVER pode gerar heurísticas automaticamente a partir de definições\\nde problemas utilizando o método do “problema relaxado” e várias outras técnicas (Prieditis, 1993).\\nO ABSOLVER gerou uma heurística nova para o quebra-cabeças de oito peças melhor do que\\nqualquer heurística preexistente e encontrou a primeira heurística útil para o famoso quebra-cabeças\\ndo cubo de Rubik (também conhecido como cubo mágico).\\nUm problema com a geração de novas funções heurísticas é que muitas vezes não se consegue\\nobter uma única heurística “claramente melhor”. Se uma coleção de heurísticas admissíveis \\nh\\n1\\n… \\nh\\nm\\nestiver disponível para um problema e nenhuma delas dominar qualquer uma das outras, qual delas\\nse deve escolher? Como se constata, não é preciso fazer uma escolha. Podemos ter o melhor dos\\nmundos através da definição\\nh\\n(\\nn\\n) = max {\\nh\\n1\\n(\\nn\\n),…, h\\nm\\n(\\nn\\n)}.\\nEssa heurística composta utiliza qualquer função que seja mais precisa no nó em questão. Em\\nrazão das heurísticas da composição serem admissíveis, \\nh\\n é admissível, mas também é fácil provar\\nque \\nh\\n é consistente. Além disso, \\nh\\n domina todos os seus componentes heurísticos.\\n3.6.3 Geração de heurísticas admissíveis de subproblemas: bancos de dados de\\npadrões\\nAs heurísticas admissíveis podem também ser derivadas da solução de custo de um \\nsubproblema\\ndo problema dado. Por exemplo, a \\nFigura 3.30\\n mostra um subproblema da instância do quebra-\\ncabeças de oito peças da \\nFigura 3.28\\n. O subproblema envolve levar as peças 1, 2, 3, 4 para suas\\nposições corretas. O custo da solução ótima desse subproblema é claramente um limite inferior do\\ncusto do problema completo. Em alguns casos o custo de um subproblema pode ser mais preciso do\\nque a distância de Manhattan.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 141}),\n",
       " Document(page_content='Figura 3.30\\n Um subproblema da instância do quebra-cabeças de oito peças apresentado na \\nFigura\\n3.28\\n. A tarefa é ter as peças 1, 2, 3 e 4 em suas posições corretas, sem se preocupar com o que\\nacontece com as outras peças.\\nA ideia por trás \\ndos bancos de dados de padrões\\n é armazenar os custos exatos de solução para\\ntodas as instâncias possíveis do subproblema — em nosso exemplo, todas as configurações possíveis\\ndas quatro peças e da posição em branco (os locais das outras quatro peças são irrelevantes para fins\\nde resolução do subproblema, mas a movimentação das peças será levada em conta em relação ao\\ncusto). Então vamos calcular uma heurística admissível \\nh\\nBD\\n para cada estado completo encontrado\\ndurante uma busca, simplesmente pelo exame da configuração correspondente do subproblema no\\nbanco de dados. O próprio banco de dados é construído através de busca reversa\\n13\\n do objetivo e do\\nregistro do custo de cada novo padrão encontrado; o custo dessa busca é amortizado ao longo das\\nmuitas instâncias do problema.\\nA escolha de 1-2-3-4 é bastante arbitrária; também podemos construir bases de dados para 5-6-7-\\n8, 2-4-6-8, e assim por diante. Cada banco de dados produz uma heurística admissível, e essas\\nheurísticas podem ser combinadas, como explicado anteriormente, extraindo o valor máximo. Uma\\nheurística combinada desse tipo é muito mais precisa do que a distância de Manhattan; o número de\\nnós gerados na resolução aleatória do quebra-cabeças de 15 peças pode ser reduzido por um fator de\\n1.000.\\nA dúvida é se as heurísticas obtidas a partir do banco de dados 1-2-3-4 e 5-6-7-8 poderiam ser\\nsomadas\\n, pois parece que os dois subproblemas não se sobrepõem. Será que isso ainda resultaria em\\numa heurística admissível? A resposta é não, porque as soluções dos subproblemas 1-2-3-4 e 5-6-7-\\n8 para um dado estado quase certamente irão compartilhar alguns movimentos — é improvável que\\n1-2-3-4 possam ser movidos para seus lugares sem tocar em 5-6-7-8 e vice-versa. Mas, e se não\\ncontássemos esses movimentos? Ou seja, não registramos o custo total de resolver o subproblema 1-\\n2-3-4, mas apenas o número de movimentos envolvendo 1-2-3-4. Então é fácil verificar que a soma\\ndos dois custos ainda é um limite inferior sobre o custo de resolver todo o problema. Essa é a ideia\\npor trás dos \\nbancos de dados de padrões disjuntos\\n. Com tais bancos de dados, é possível resolver\\naleatoriamente o quebra-cabeças de 15 peças em poucos milissegundos — o número de nós gerados\\né reduzido por um fator de 10.000 em comparação com a utilização da distância de Manhattan. Para\\num quebra-cabeças de 24 peças, pode ser obtido um aumento de eficiência de cerca de um fator de\\num milhão.\\nOs bancos de dados de padrões disjuntos funcionam para o quebra-cabeças de peças deslizantes\\nporque o problema pode ser dividido de tal forma que cada movimento afete apenas um\\nsubproblema, pois apenas uma peça pode ser movimentada por vez. Para um problema como o do\\ncubo de Rubik, esse tipo de subdivisão é difícil porque cada movimento afeta oito ou nove dos 26\\ncubos. Foram propostas formas mais gerais de definição de heurísticas aditivas admissíveis que se\\naplicam ao cubo de Rubik (Yang \\net al\\n., 2008), mas elas não resultaram em uma heurística melhor do\\nque a melhor heurística não aditiva para o problema.\\n3.6.4 Aprendizagem de heurísticas a partir da experiência', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 142}),\n",
       " Document(page_content='Uma função heurística \\nh\\n(\\nn\\n) deve ser capaz de estimar o custo de uma solução começando pelo\\nestado do nó \\nn\\n. Como um agente poderia construir tal função? Nas seções anteriores foi dada uma\\nsolução, isto é, conceber problemas relaxados para os quais uma solução ótima pode ser facilmente\\nencontrada. Outra solução é aprender com a experiência. “Experiência” aqui significa, por exemplo,\\nresolver muitos quebra-cabeças de oito peças. Cada solução ótima para o problema do quebra-\\ncabeças de oito peças fornece exemplos dos quais \\nh\\n(\\nn\\n) pode ser aprendido. Cada exemplo consiste\\nem um estado do caminho da solução e do custo real da solução a partir desse ponto. A partir desses\\nexemplos, pode ser utilizado um algoritmo de aprendizagem para construir uma função \\nh\\n(\\nn\\n) que pode\\n(com sorte) prever os custos de solução para outros estados que surgirem durante a busca. As\\ntécnicas para fazer apenas isso utilizando redes neurais, árvores de decisão e outros métodos são\\ndemonstradas no Capítulo 18 (os métodos de aprendizagem por reforço descritos no Capítulo 21\\ntambém são aplicáveis).\\nOs métodos de aprendizagem indutiva funcionam melhor quando supridos de \\ncaracterísticas\\n de\\num estado que são relevantes para predizer o valor do estado, em vez de apenas uma simples\\ndescrição do estado. Por exemplo, a característica de “número de peças fora do lugar” pode ser útil\\nem predizer a distância real de um estado a partir do objetivo. Vamos chamar essa característica de\\nx\\n1\\n (\\nn\\n). Poderíamos extrair 100 configurações geradas aleatoriamente do quebra-cabeças de oito\\npeças e reunir estatísticas sobre seus custos reais de solução. Podemos considerar que, quando \\nx\\n1\\n(\\nn\\n)\\nfor 5, o custo médio de solução será cerca de 14, e assim por diante. Tendo em conta esses dados, o\\nvalor de \\nx\\n1\\n poderá ser utilizado para prever \\nh\\n(\\nn\\n)\\n.\\n Certamente poderemos utilizar várias\\ncaracterísticas. Uma segunda característica \\nx\\n2\\n(\\nn\\n) pode ser o “número de pares de peças adjacentes\\nque não são adjacentes no estado objetivo”. Como deveríamos combinar \\nx\\n1\\n(\\nn\\n) e \\nx\\n2\\n(\\nn\\n) para prever\\nh\\n(\\nn\\n)? Uma abordagem comum é usar uma combinação linear:\\nh\\n(\\nn\\n) \\n= c\\n1\\nx\\n1\\n(\\nn\\n) \\n+ c\\n2\\nx\\n2\\n(\\nn\\n)\\n.\\nAs constantes \\nc\\n1\\n e \\nc\\n2\\n são ajustadas para proporcionar o melhor ajuste para os dados reais sobre os\\ncustos da solução. Espera-se que tanto \\nc\\n1\\n como \\nc\\n2\\n sejam positivos porque as peças fora de lugar e os\\npares incorretos adjacentes tornam o problema mais difícil de resolver. Observe que essa heurística\\nsatisfaz a condição de \\nh\\n(\\nn\\n) = 0 para os estados-objetivo, mas não é necessariamente admissível ou\\nconsistente.\\n3.7 RESUMO\\nEste capítulo introduziu métodos que um agente pode usar para selecionar ações em ambientes\\ndeterminísticos, observáveis, estáticos e completamente conhecidos. Em tais casos, o agente pode\\nconstruir sequências de ações que alcançam seus objetivos; esse processo é chamado de \\nbusca\\n.\\n•  Antes de um agente poder começar a procurar soluções, ele deve identificar um \\nobjetivo\\n e\\nformular um \\nproblema\\n bem definido.\\n•  Um problema consiste em cinco partes: o \\nestado inicial\\n, um conjunto de \\nações\\n, um \\nmodelo de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 143}),\n",
       " Document(page_content='transição\\n descrevendo os resultados dessas ações, uma função \\nteste de objetivo\\n e uma função\\ncusto de caminho\\n. O ambiente do problema é representado por um \\nespaço de estados\\n. Um\\ncaminho\\n pelo espaço de estados a partir do estado inicial até um estado objetivo é uma \\nsolução\\n.\\n•  Algoritmos de busca tratam estados e ações como atômicos: sem considerar qualquer estrutura\\ninterna que possam ter.\\n•  Um algoritmo genérico de BUSCA-EM-ÁRVORE considera todos os caminhos possíveis para\\nencontrar uma solução, enquanto um algoritmo de BUSCA-EM-GRAFO evita a consideração de\\ncaminhos re\\u200bdundantes.\\n•  Os algoritmos de busca são analisados em termos de \\ncompleteza\\n, \\notimização\\n, \\ncomplexidade de\\ntempo\\n e \\ncomplexidade de espaço\\n. A complexidade depende de \\nb\\n, o fator de ramificação no\\nespaço de estados, e de \\nd\\n, a profundidade da solução mais rasa.\\n•  Métodos de busca não informados têm acesso apenas à definição do problema. Os algoritos\\nbásicos são os seguintes:\\n–  A \\nbusca em largura\\n seleciona para expansão os nós mais rasos; ela é completa, ótima para\\npassos de custo unitário, mas tem complexidade de tempo exponencial.\\n–  A \\nbusca de custo uniforme\\n expande o nó com o menor custo de caminho, \\ng\\n(\\nn\\n) e é ótima para\\npassos de custos genéricos.\\n–  A \\nbusca em profundidade\\n expande o nó não expandido mais profundo. Ela não é completa\\nnem ótima, mas tem complexidade espacial linear. A \\nbusca em profundidade limitada\\nadiciona um limite em profundidade.\\n–  A \\nbusca de aprofundamento iterativo\\n chama a busca em profundidade com limites\\ncrescentes de profundidade até encontrar um objetivo. Ela é completa, ótima para passos de\\ncusto unitário, tem complexidade de tempo comparável à busca em largura e tem\\ncomplexidade de espaço linear.\\n–  A \\nbusca bidirecional\\n pode reduzir enormemente a complexidade de tempo, mas nem sempre é\\naplicável e pode exigir muito espaço.\\n•  Os métodos de busca informada podem ter acesso a uma função \\nheurística\\n \\nh\\n(\\nn\\n) que estima o\\ncusto de uma solução a partir de \\nn\\n.\\n–  O algoritmo geral de \\nbusca de melhor\\n escolha seleciona um nó para a expansão de acordo\\ncom uma \\nfunção de avaliação.\\n–  A \\nbusca gulosa\\n de melhor escolha expande os nós com \\nh\\n(\\nn\\n) mínimo. Não é ótima, mas pode\\nser eficiente.\\n–  Uma \\nbusca A*\\n expande os nós com \\nf\\n(\\nn\\n) = \\ng\\n(\\nn\\n) + \\nh\\n(\\nn\\n) mínimo. A* é completa e ótima, desde\\nque \\nh\\n(\\nn\\n) seja admissível (para a BUSCA-EM-ÁRVODE) ou consistente (para a BUSCA-EM-\\nGRAFO). A complexidade de espaço do A* ainda é proibitiva.\\n–  \\nRBFS\\n (busca recursiva de melhor escolha) e \\nSMA*\\n (A* de memória limitada simplificada)\\nsão algoritmos robustos, de busca ótima, que utilizam porções limitadas de memória; dado um\\ntempo suficiente, podem resolver os problemas que A* não pode resolver, por ficar sem\\nmemória.\\n•  O desempenho de algoritmos de busca heurística depende da qualidade da função heurística.\\nPode-se, por vezes, construir uma boa heurística, através do relaxamento da definição do\\nproblema, armazenando os custos de solução pré-computados dos subproblemas em um banco de\\ndados de padrões ou aprendendo a partir da experiência com uma classe de problemas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 144}),\n",
       " Document(page_content='NOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nO tema busca em espaço de estados teve origem mais ou menos em sua forma atual nos primórdios\\nda IA. O trabalho de Newell e Simon sobre a Logic Theorist (1957) e o GPS (1961) levou ao\\nestabelecimento dos algoritmos de busca como as armas fundamentais do arsenal dos pesquisadores\\nde IA da década de 1960 e ao estabelecimento da resolução de problemas como tarefa canônica da\\nIA. O trabalho em pesquisa operacional por Richard Bellman (1957) mostrou a importância dos\\ncustos de caminho aditivo na simplificação dos algoritmos de otimização. O texto \\nAutomated\\nProblem Solving\\n de Nils Nilsson (1971) estabeleceu a área sobre uma base teórica sólida.\\nA maior parte dos problemas de busca em espaço de estados analisados neste capítulo tem uma\\nlonga história na literatura e são menos triviais do que parecem ser. O problema dos missionários e\\ncanibais usado no Exercício 3.9 foi analisado em detalhes por Amarel (1968). Ele foi considerado\\nanteriormente em IA por Simon e Newell (1961) e em pesquisa operacional por Bellman e Dreyfus\\n(1962).\\nO quebra-cabeça de oito peças é um irmão menor do quebra-cabeça de 15 peças, cuja história foi\\ncontada extensamente por Slocum e Sonneveld (2006). Acreditava-se amplamente ter sido inventada\\npelo famoso projetista de jogos americano Sam Loyd, com base em suas alegações sobre os\\nresultados a partir de 1891 (Loyd, 1959). Na verdade, foi inventado por Noyes Chapman, um agente\\nde correio em Canastota, Nova York, em meados da década de 1870. (Chapman foi incapaz de\\npatentear sua invenção, a patente genérica foi concedida a Ernest Kinsey em 1878, abrangendo\\nblocos deslizantes com letras, números ou imagens.) Rapidamente atraiu a atenção do público e dos\\nmatemáticos (Johnson e Story, 1879; Tait, 1880). Os editores do \\nAmerican Journal of Mathematics\\ndeclararam: “Nas últimas semanas, o quebra-cabeça de 15 peças chegou ao público americano e\\npode-se dizer com segurança que ele atraiu a atenção de nove entre dez pessoas de ambos os sexos e\\nde todas as idades e condições sociais na comunidade.” Ratner e Warmuth (1986) mostraram que a\\nversão geral de \\nn\\n × \\nn\\n do quebra-cabeça pertence à classe de problemas NP-completos.\\nO problema de oito rainhas foi originalmente publicado anonimamente na revista alemã de xadrez\\nSchach\\n em 1848; mais tarde, ele foi atribuído a um certo Max Bezzel. O problema foi republicado\\nem1850 e, nessa época, atraiu a atenção do eminente matemático Carl Friedrich Gauss, que tentou\\nenumerar todas as soluções possíveis. Inicialmente ele achou apenas 72, mas eventualmente achou a\\nresposta correta de 92, apesar de Nauck ter publicado primeiro todas as 92 soluções, em 1850. Netto\\n(1901) generalizou o problema para \\nn\\n rainhas, e Abramson e Yung (1989) encontraram um algoritmo\\nO\\n(\\nn\\n).\\nCada um dos problemas de busca do mundo real listado nesse capítulo foi assunto de um grande\\nesforço de pesquisa. Os métodos para selecionar voos ótimos de linhas aéreas permanecem\\npatenteados em sua maior parte, mas Carl de Marcken (em comunicação pessoal) mostrou que a\\ncotação e as restrições de passagens de linhas aéreas se tornaram tão complicadas que o problema de\\nselecionar um voo ótimo é formalmente \\nindecidível\\n. O problema do caixeiro-viajante (TSP) é um\\nproblema combinatório-padrão em ciência da computação teórica (Lawler \\net al\\n., 1992). Karp (1972)\\nprovou que o TSP é NP-difícil, mas foram desenvolvidos métodos efetivos de aproximação\\nheurística (Lin e Kernighan, 1973). Arora (1998) criou um esquema de aproximação completamente\\npolinomial para TSPs euclidianos. Os métodos de leiaute de VLSI foram pesquisados por Shahookar', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 145}),\n",
       " Document(page_content='e Mazumder (1991), e surgiram muitos artigos em periódicos de otimização de leiaute de VLSI. Os\\nproblemas de navegação e montagem de robôs são discutidos no Capítulo 25.\\nOs algoritmos de busca sem informação para resolução de problemas constituem um tópico central\\nda ciência de computação clássica (Horowitz e Sahni, 1978) e da pesquisa operacional (Dreyfus,\\n1969). A busca em largura foi formulada para resolver labirintos por Moore (1959). O método de\\nprogramação dinâmica\\n (Bellman, 1957), que registra sistematicamente soluções para todos os\\nsubproblemas de comprimentos crescentes, pode ser visto como uma forma de busca em largura\\nsobre grafos. O algoritmo de caminhos mais curtos de dois pontos de Dijkstra (1959) é a origem da\\nbusca de custo uniforme. Esses trabalhos também apresentaram a ideia de conjuntos explorados e de\\nborda (listas abertas e fechadas).\\nUma versão de aprofundamento iterativo projetada para faser uso eficiente do relógio no xadrez\\nfoi usada primeiro por Slate e Atkin (1977) no programa de jogo de xadrez CHESS 4.5. O algoritmo\\nB de Martelli (1977) inclui um aspecto de aprofundamento iterativo e também domina o pior caso de\\ndesempenho de heurística admissível, mas inconsistente, de A*. A técnica do aprofundamento\\niterativo veio à tona no trabalho de Korf (1985a). A busca bidirecional, que foi apresentada por Pohl\\n(1971), também pode ser eficaz em alguns casos.\\nO uso da informação heurística na resolução de problemas apareceu em um ensaio inicial por\\nSimon e Newell (1958), mas a frase “busca heurística” e o uso de funções heurísticas que estimam a\\ndistância até o objetivo vieram um pouco mais tarde (Newell e Ernst, 1965; Lin, 1965). Doran e\\nMichie (1966) realizaram estudos experimentais extensos de busca heurística. Embora tenham\\nanalisado o comprimento do caminho e a “penetrância” (a razão entre o comprimento do caminho e o\\nnúmero total de nós examinados até então), eles parecem ter ignorado as informações fornecidas pelo\\ncaminho de menor custo \\ng\\n(\\nn\\n). O algoritmo A*, incorporando o custo do caminho atual em busca\\nheurística, foi desenvolvido por Hart, Nilsson e Raphael (1968), com algumas correções posteriores\\n(Hart \\net al\\n., 1972). Dechter e Pearl (1985) demonstraram a eficiência ótima de A*.\\nO ensaio original de A* introduziu a condição de consistência sobre as funções heurísticas. A\\ncondição monotone foi introduzida por Pohl (1977) como uma simples substituição, mas Pearl (1984)\\nmostrou que os dois eram equivalentes.\\nPohl (1977) foi pioneiro no estudo da relação entre o erro em funções heurísticas e a\\ncomplexidade do tempo de A*. Os resultados básicos foram obtidos para a de busca em árvore com\\ncusto do passo unitário e um nó objetivo único (Pohl, 1977; Gaschnig, 1979; Huyn \\net al\\n., 1980; Pearl,\\n1984) e com múltiplos nós objetivos (Dinh \\net al\\n., 2007). O “fator de ramificação efetivo” foi\\nproposto por Nilsson (1971) como medida empírica da eficiência que é equivalente a assumir o\\ncusto de tempo de \\nO\\n((\\nb\\n*)\\nd\\n). Para a busca em árvore aplicada a um grafo, Korf \\net al\\n. (2001)\\nargumentam que o custo do tempo é mais bem modelado como \\nO\\n(\\nb\\nd\\n−k\\n), onde \\nk\\n depende da precisão\\nheurística; no entanto, essa análise tem suscitado alguma controvérsia. Para a busca em grafos,\\nHelmert e Röger (2008) observaram que vários problemas conhecidos continham um número\\nexponencial de nós em caminhos da solução ótima, implicando complexidade de tempo exponencial\\npara A*, mesmo com erro absoluto constante em \\nh\\n.\\nExistem muitas variações sobre o algoritmo A*. Pohl (1973) propôs o uso de \\nponderação\\ndinâmica\\n, que usa uma soma ponderada \\nf\\nw\\n(\\nn\\n) = \\nw\\ng\\ng\\n(\\nn\\n) + \\nw\\nh\\nh\\n(\\nn\\n) do comprimento do caminho atual\\ne da função heurística como uma função de avaliação, em vez da simples soma \\nf\\n(\\nn\\n) = \\ng\\n(\\nn\\n) + \\nh\\n(\\nn\\n)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 146}),\n",
       " Document(page_content='utilizada em A*. Os pesos \\nw\\ng\\n e \\nw\\nh\\n são ajustados dinamicamente conforme a busca avança. O\\nalgoritmo de Pohl pode ser demonstrado como \\n∊\\n-admissível, ou seja, garante encontrar soluções com\\num fator 1 + \\n∊\\n da solução ótima, onde \\n∊\\n é um parâmetro fornecido ao algoritmo. A mesma\\npropriedade é exibida pelo algotitmo A*\\n∊\\n (Pearl, 1984), que pode selecionar qualquer nó da borda\\ndesde que a sua relação \\nf-\\ncusto esteja dentro de um fator 1 + \\n∊\\n do nó da borda de menor \\nf_\\ncusto. A\\nseleção pode ser feita de modo a minimizar o custo da busca.\\nVersões bidirecionais de A* têm sido investigadas; uma combinação de A* bidirecional e pontos\\nde referência conhecidos foi utilizada para encontrar rotas de forma eficiente para o serviço de\\nmapas on-line da Microsoft (Goldberg \\net al\\n., 2006). Após coletar um conjunto de caminhos entre os\\npontos de referência, o algoritmo pode encontrar um caminho ótimo entre qualquer par de pontos em\\num grafo de 24 milhões de pontos dos Estados Unidos, buscando em menos de 0,1% do grafo. Outras\\nabordagens para a busca bidirecional incluem a busca em largura que retrocede a partir do primeiro\\nobjetivo até uma profundidade fixa, seguido por uma busca IDA* para a frente (Dillenburg e Nelson,\\n1994; Manzini, 1995).\\nO algoritmo A* e outras buscas de espaço de estados estão intimamente relacionados com as\\ntécnicas \\nbranch-and-bound\\n que são amplamente utilizadas em pesquisa operacional (Lawler e\\nWood, 1966). As relações entre busca de espaço de estados e branch-and-bound têm sido\\ninvestigadas em profundidade (Kumar e Kanal, 1983; Nau \\net al\\n., 1984; Kumar \\net al\\n., 1988). Martelli\\ne Montanari (1978) demonstram uma ligação entre programação dinâmica (ver o Capítulo 17) e\\ncertos tipos de busca de espaço de estados. Kumar e Kanal (1988) tentaram uma “grande unificação”\\nda busca heurística, programação dinâmica e técnicas de branch-and-bound sob o nome de PDC —\\n“processo de decisão composto”.\\nComo os computadores no final dos anos 1950 e início dos anos 1960 tinham no máximo alguns\\nmilhares de palavras de memória principal, a memória limitada da busca heurística foi um tema de\\npesquisa inicial. O Graph Traverser (Doran e Michie, 1966), um dos primeiros programas de busca,\\npassa para um operador após buscar pela melhor escolha até o limite de memória. O IDA* (Korf,\\n1985a, 1985b) foi o primeiro algoritmo ótimo de busca heurística com memória limitada usado\\namplamente e desde então tem sido desenvolvido um grande número de variantes. Uma análise da\\neficiência do IDA* e de suas dificuldades com heurística de valor real aparece em Patrick \\net al\\n.\\n(1992).\\nO RBFS (Korf, 1993) é realmente um pouco mais complicado do que o algoritmo mostrado na\\nFigura 3.26\\n, que é mais próximo de um algoritmo desenvolvido de forma independente chamado de\\nexpansão iterativa\\n (Russell, 1992). O RBFS utiliza o limite inferior, bem como o superior; os dois\\nalgoritmos comportam-se de forma idêntica com heurísticas admissíveis, mas o RBFS expande os\\nnós em ordem da melhor escolha, mesmo com uma heurística não admissível. A ideia de acompanhar\\no melhor caminho alternativo apareceu anteriormente na implementação elegante de Prolog do A* de\\nBratko (1986) e no algoritmo DTA* (Russell e Wefald, 1991). O último trabalho também discute os\\nespaços de estados em metanível e aprendizagem em metanível.\\nO algoritmo MA* apareceu em Chakrabarti \\net al.\\n (1989). O SMA*, ou MA* simplificado, surgiu\\nde uma tentativa de implementar MA* como um algoritmo de comparação para o IE (Russell, 1992).\\nKaindl e Khorsand (1994) aplicaram SMA* para produzir um algoritmo de busca bidirecional que é\\nsubstancialmente mais rápido que os algoritmos anteriores. Korf e Zhang (2000) descreveram uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 147}),\n",
       " Document(page_content='abordagem de divisão e conquista, e Zhou e Hansen (2002) introduziram a busca em grafos de A* de\\nmemória limitada e uma estratégia para mudar para busca em largura e aumentar a eficiência da\\nmemória (Zhou e Hansen, 2006). Korf (1995) fez uma resenha as técnicas de busca de memória\\nlimitada.\\nA ideia de que heurísticas admissíveis podem ser derivadas de relaxamento de problema surgiu no\\nensaio seminal de Held e Karp (1970), que utilizou a heurística da árvore geradora mínima para\\nresolver o TSP (ver o Exercício 3.30).\\nA automação do processo de relaxamento foi implementada com sucesso por Prieditis (1993), com\\nbase no trabalho anterior com Mostow (Mostow e Prieditis, 1989). Holte e Hernadvolgyi (2001)\\ndescreveram as etapas mais recentes para automatizar o processo. O uso de bases de dados de\\npadrões para derivar heurísticas admissíveis é devido a Gasser (1995) e Culberson e Schaeffer\\n(1996, 1998); bancos de dados de padrões disjuntos são descritos por Korf e Felner (2002); um\\nmétodo similar, usando padrões simbólicos, é devido a Edelkamp (2009). Felner \\net al.\\n (2007)\\nmostraram como compactar bancos de dados de padrões para economizar espaço. A interpretação\\nprobabilística da heurística foi investigada em profundidade por Pearl (1984) e Hansson e Mayer\\n(1989).\\nDe longe a fonte mais abrangente sobre algoritmos de busca heurística e heurística é o texto\\nHeuristics\\n de Pearl (1984). Esse livro oferece uma cobertura especialmente boa da grande variedade\\nde ramificações e variações de A*, incluindo provas rigorosas de suas propriedades formais. Kanal\\ne Kumar (1988) apresentaram uma antologia de artigos importantes sobre busca heurística, e\\nRayward-Smith \\net al\\n. (1996) cobriram abordagens da pesquisa operacional. Artigos sobre novos\\nalgoritmos de busca, que curiosamente continuam a ser descobertos, aparecem em revistas como\\nArtificial Inteligence\\n e \\nJournal of the ACM\\n.\\nO tema algoritmos de \\nbusca paralela\\n não foi abordado no capítulo, em parte, porque exige uma\\nlonga discussão sobre arquiteturas de computadores paralelos. A busca paralela tornou-se um tema\\npopular na década de 1990, tanto em IA como em teoria da ciência da computação (Mahanti e\\nDaniels, 1993; Grama e Kumar, 1995; Crauser \\net al\\n., 1998) e está voltando na era das novas\\narquiteturas multicore e cluster (Ralphs \\net al\\n., 2004; Korf e Schultze, 2005). Os algoritmos de busca\\npara grafos muito grandes que requerem armazenamento em disco (Korf, 2008) também apresentam\\nimportância crescente.\\nEXERCÍCIOS\\n3.1\\n Explique por que a formulação do problema deve seguir a formulação do objetivo.\\n3.2\\n O objetivo é dirigir o robô para fora de um labirinto. O robô inicia no meio do labirinto em\\ndireção ao norte. Você pode virar o robô em direção ao norte, sul, leste ou oeste. O robô pode ser\\ncomandado para mover uma certa distância para frente, apesar que irá parar antes de bater no muro.\\na.\\n Formule esse problema. Qual é o tamanho do espaço de estados?\\nb.\\n Ao navegar pelo labirinto, é necessário virar apenas na interseção de dois ou mais corredores.\\nReformule esse problema usando essa observação. Qual será o tamanho do espaço de estados', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 148}),\n",
       " Document(page_content='agora?\\nc.\\n De qualquer ponto do labirinto, podemos mover em qualquer uma das quatro direções, até ter\\nalcançado um ponto de virar e essa é a única ação que precisa ser feita. Reformule o problema\\nusando essas ações. É necessário acompanhar a orientação do robô para resolver esse\\nproblema?\\nd.\\n Na descrição inicial do problema já abstraímos do mundo real, restringindo as ações e\\nremovendo os detalhes. Liste três simplificações que fizemos.\\n3.3\\n Suponha que dois amigos vivam em cidades de locais diferentes em um mapa, tais como mostra o\\nmapa da Romênia na \\nFigura 3.2\\n. Podemos mover cada amigo de cada vez simultaneamente para uma\\ncidade vizinha no mapa. A quantidade de tempo necessário para se deslocar da cidade \\ni\\n à vizinha \\nj\\n é\\nigual à distância da estrada \\nd(i\\n,\\nj)\\n entre as cidades, mas a cada vez que o amigo chega primeiro deve\\nesperar até o outro chegar (e telefonar para o primeiro do celular) antes que comece a próxima vez\\nde se movimentarem. Queremos que os dois amigos se encontrem o mais rápido possível.\\na.\\n Escreva uma formulação detalhada para esse problema de busca (será útil definir alguma\\nnotação formal).\\nb.\\n Seja \\nD(i\\n, \\nj)\\n a distância em linha reta entre as cidades \\ni\\n e \\nj\\n. Qual das seguintes funções\\nheurísticas é admissível? (i) \\nD(i\\n, \\nj)\\n, (ii) 2 \\n⋅\\n \\nD\\n(\\ni\\n, \\nj\\n), (iii) \\nD\\n(\\ni\\n, \\nj\\n)/2.\\nc.\\n Há mapas completamente conectados para os quais não existe solução?\\nd.\\n Há mapas em que todas as soluções requerem que um amigo visite a mesma cidade duas vezes?\\n3.4\\n Mostre que os estados do quebra-cabeça de oito peças se dividem em dois conjuntos disjuntos,\\ntais que qualquer estado seja acessível a partir de qualquer outro estado no mesmo conjunto,\\nenquanto nenhum estado pode ser acessado de qualquer outro estado no outro conjunto. (\\nDica:\\n Veja\\nBerlekamp \\net al.\\n (1982).) Elabore um procedimento para decidir em que conjunto um dado estado se\\nencontra e explique por que isso é útil para gerar estados aleatórios.\\n3.5\\n Considere o problema de \\nn\\n rainhas usando a formulação incremental “eficiente” dada na página\\n72. Explique por que o tamanho do espaço de estados é pelo menos \\n e faça uma estimativa do\\nmaior \\nn\\n para o qual a exploração exaustiva é possível. (\\nDica:\\n Derive um limite inferior sobre o fator\\nde ramificação, considerando o número máximo de quadrados que uma rainha pode atacar em\\nqualquer coluna.)\\n3.6\\n Forneça uma formulação completa do problema para cada um dos seguintes itens. Escolha a\\nformulação suficientemente precisa para ser implementada.\\na.\\n Usando apenas 4 cores, colorir um mapa plano de tal forma que duas regiões adjacentes não\\ntenham a mesma cor.\\nb.\\n Um macaco com 30 cm está em uma sala onde tem algumas bananas suspensas em um teto de 80\\ncm. Ele gostaria de pegar as bananas. A sala contém dois engradados móveis e escaláveis com\\n30 cm de altura que podem ser empilhados.\\nc\\n. Existe um programa que exibe a mensagem “registro de entrada inválido” ao alimentar\\ndeterminado arquivo com registros de entrada. Você sabe que o processamento de cada registro\\né independente de outros registros e deseja descobrir qual registro é inválido.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 149}),\n",
       " Document(page_content='d\\n. Existem três jarras que medem 12, 8 e 3 galões e uma torneira de água. As jarras podem ser\\nenchidas ou esvaziadas uma da outra ou para o chão. Medir exatamente um galão, somente com\\nessas operações.\\n \\n3.7\\n Considere o problema de encontrar o caminho mais curto entre dois pontos em um plano\\nque tem obstáculos poligonais convexos, como mostra a \\nFigura 3.31\\n. Essa é uma idealização do\\nproblema que um robô tem de resolver para navegar em um ambiente congestionado.\\nFigura 3.31\\n Um cenário com objetos poligonais. S e G são os estados de partida e objetivo.\\na.\\n Suponha que o espaço de estados consista de todas as posições (\\nx\\n, \\ny\\n) do plano. Quantos estados\\nexistem? Quantos caminhos existem até o objetivo?\\nb.\\n Explique brevemente por que o caminho mais curto de um vértice de um polígono até qualquer\\noutro vértice na cena deve consistir de segmentos de reta que unem alguns vértices dos\\npolígonos. Agora defina um bom espaço de estados. Qual é o tamanho desse espaço de estados?\\nc.\\n Defina as funções necessárias para implementar o problema de busca, incluindo uma função\\nAÇÕES que receba um vértice como entrada e devolve um conjunto de vetores, sendo que cada\\nvetor mapeia o vértice atual a um dos vértices que pode ser alcançado por uma linha reta. (Não\\nse esqueça dos vizinhos no mesmo polígono.) Utilize a distância em linha reta como função\\nheurística.\\nd.\\n Aplique um ou mais algoritmos deste capítulo para resolver alguns problemas nesse domínio e\\ncomente seu desempenho.\\n3.8\\n Na \\nSeção 3.1.1\\n, dissemos anteriormente que não consideraríamos os problemas com custos de\\ncaminhos negativos. Neste exercício, vamos explorar esse tema com maior profundidade.\\na.\\n Suponha que as ações possam ter custos negativos arbitrariamente grandes; explique por que\\nessa possibilidade forçaria qualquer algoritmo ótimo a explorar todo o espaço de estados.\\nb.\\n Ajudaria se insistíssemos no fato de que os custos dos passos devem ser maiores ou iguais a\\nalguma constante negativa \\nc\\n? Considere tanto a busca em árvores como em grafos.\\nc.\\n Suponha que um conjunto de ações forme um laço no espaço de estados de modo que a cada\\nexecução dessas ações em alguma ordem não resulte em mudança no estado. Se todas essas\\nações tiverem custo negativo, qual será a implicação desse fato sobre o comportamento ótimo\\nde um agente em tal ambiente?', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 150}),\n",
       " Document(page_content='d.\\n É possível imaginar facilmente ações com custo negativo alto, até mesmo em domínios como o\\nde roteamento. Por exemplo, alguns trechos da estrada poderiam ter belas paisagens que\\nsuperem de longe os custos normais em termos de tempo e combustível. Explique, em termos\\nprecisos, dentro do contexto de busca em espaços de estados, por que os seres humanos não\\ndirigem indefinidamente em ciclos por belos cenários e explique como definir o espaço de\\nestados e ações para roteamento, de forma que agentes artificiais também possam evitar ciclos\\nrepetitivos.\\ne.\\n Você pode imaginar um domínio real em que os custos dos passos sejam de tal forma que\\nprovoquem a entrada em ciclos repetitivos?\\n \\n3.9\\n O problema de \\nmissionários e canibais\\n é normalmente enunciado como a seguir. Três\\nmissionários e três canibais estão em um lado de um rio, juntamente com um barco que pode levar\\numa ou duas pessoas. Descubra um meio de fazer todos atravessarem o rio sem deixar que um grupo\\nde missionários de um lado fique em número menor que o número de canibais nesse mesmo lado do\\nrio. Esse problema é famoso em IA porque foi assunto do primeiro artigo que abordou a formulação\\nde problemas a partir de um ponto de vista analítico (Amarel, 1968).\\na.\\n Formule o problema precisamente, fazendo apenas as especificações necessárias para assegurar\\numa solução válida. Faça um diagrama do espaço de estados completo.\\nb.\\n Implemente e resolva o problema de forma ótima, utilizando um algoritmo de busca apropriado.\\nÉ uma boa ideia verificar a existência de estados repetidos?\\nc.\\n Por que você imagina que as pessoas têm dificuldades para resolver esse quebra-cabeça,\\nconsiderando que o espaço de estados é tão simples?\\n3.10\\n Defina com suas próprias palavras os seguintes termos: estado, espaço de estados, árvore de\\nbusca, nó de busca, objetivo, ação, modelo de transição e fator de ramificação.\\n3.11\\n Qual é a diferença entre um estado do mundo, uma descrição do estado e um nó de busca? Por\\nque é útil essa distinção?\\n3.12\\n Uma ação tal como \\nIr(Sibiu)\\n consiste realmente em uma longa sequência de ações mais\\nrefinadas: ligar o carro, soltar o freio, acelerar para a frente etc. Ter ações compostas desse tipo\\nreduz o número de passos em uma sequência de soluções, reduzindo assim o tempo de busca.\\nSuponha que tomemos essa lógica ao extremo, construindo ações supercompostas de todas as\\nsequências possíveis de ações \\nIr\\n. Assim, cada instância do problema é resolvida por uma única ação\\nsupercomposta, como \\nIr(Sibiu)Ir(Rimnicu Vilcea)Ir(Pitesti)Ir(Bucareste)\\n. Explique como a busca\\ntrabalharia nessa formulação. Essa é uma abordagem prática para acelerar a resolução do\\nproblemas?\\n3.13\\n Prove que a BUSCA EM GRAFO satisfaz a propriedade de separação do grafo ilustrada na\\nFigura 3.9\\n (Dica: comece mostrando que a propriedade se mantém no início. Depois mostre que se\\nela se mantém antes da iteração com o algoritmo, mantém-se também depois.) Descreva um algoritmo\\nde busca que viole a propriedade.\\n3.14\\n Qual das seguintes alternativas são falsas e quais são verdadeiras? Explique suas respostas.\\na.\\n A busca em profundidade sempre expande pelo menos tantos nós quanto a busca A* com uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 151}),\n",
       " Document(page_content='heurística admissível.\\nb.\\n h(n) = 0 é uma heurística admissível para o quebra cabeças de 8 peças.\\nc.\\n Em robótica, A* não é útil porque as percepções, estados e ações são contínuas.\\nd.\\n A busca em largura é completa mesmo se os custos de passos iguais a zero forem permitidos.\\ne.\\n Assuma que a torre pode se mover em um tabuleiro de xadrez qualquer quantidade de quadrados\\nem linha reta, verticalmente ou horizontalmente, mas não pode pular sobre as peças. A distância\\nde Manhattan é uma heurística admissível para o problema de movimentar a torre do quadrado\\nA para o B no menor número de movimentos.\\n3.15\\n Considere um espaço de estados onde o estado inicial é o número 1 e cada estado k tem dois\\nsucessores: números 2k e 2k+1.\\na.\\n Represente a porção do espaço de estados para os estados de 1 a 15.\\nb.\\n Suponha que o estado objetivo seja 11. Liste a ordem em que os nós serão visitados pela busca\\nem largura, busca em profundidade limitada com o limite 3 e busca de aprofundamento iterativo.\\nc.\\n Como a busca bidirecional funcionaria nesse problema? Qual é o fator de ramificação em cada\\ndireção?\\nd.\\n A resposta ao item (c) sugere uma reformulação do problema que permitiria resolver o\\nproblema de ir do estado 1 para um determinado estado objetivo com quase nenhuma busca?\\ne.\\n Chame a ação que vai de k para 2k de Esquerda e a ação de k que vai para 2k + 1 de Direita.É\\npossível encontrar um algoritmo que devolva a solução desse problema absolutamente sem\\nnenhuma busca?\\n3.16\\n Uma ferrovia de brinquedo, com trilhos de madeira, contém as peças mostradas na \\nFigura 3.32\\n.\\nA tarefa é conectar essas peças em uma estrada de ferro, sem trilhos sobrepostos e pontas soltas,\\nonde um trem poderia descarrilhar, saindo dos trilhos.\\nFigura 3.32\\n Peças de trilhos de madeira de uma ferrovia de brinquedo; cada uma rotulada com o\\nnúmero de cópias do conjunto. Observe que as peças curvadas e em forma de “garfo” (“desvios” ou\\n“pontos”) podem ser usadas dos dois lados, desse modo, podem se curvar em ambas as direções,\\ndireita ou esquerda. Cada curva subentende 45 graus.\\na\\n. Suponha que as peças se encaixam \\nexatamente\\n sem nenhuma folga. Forneça uma formulação\\nprecisa da tarefa como um problema de busca.\\nb\\n. Identifique um algoritmo de busca não informada adequada para essa tarefa e justifique a sua\\nescolha.\\nc.\\n Explique por que a remoção de qualquer um das peças de “forquilha” torna o problema\\ninsolúvel.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 152}),\n",
       " Document(page_content='d.\\n Dê um limite superior do tamanho total do espaço de estados definido pela sua formulação.\\n(\\nDica\\n: Pense sobre o fator máximo de ramificação para o processo de construção e a profundidade\\nmáxima, ignorando o problema de sobreposição de peças e pontas soltas. Comece simulando\\nque cada peça seja única.)\\n \\n3.17\\n No final da \\nSeção 3.4.5\\n, mencionamos a \\nbusca de alongamento iterativo\\n, uma versão\\niterativa da busca de custo uniforme. A ideia é usar limites crescentes sobre o custo do caminho. Se\\nfor gerado um nó cujo custo de caminho exceda o limite atual, ele será imediatamente descartado.\\nPara cada nova iteração, o limite é definido como o menor custo do caminho de qualquer nó\\ndescartado na iteração anterior.\\na.\\n Mostre que esse algoritmo é ótimo para custos de caminhos em geral.\\nb.\\n Considere uma árvore uniforme com fator de ramificação \\nb\\n, profundidade de solução \\nd\\n e passos\\nde custo unitário. Quantas iterações exigirá o alongamento iterativo?\\nc.\\n Agora, considere passos de custos obtidos no intervalo contínuo [\\n∊\\n, 1], onde 0 < \\n∊\\n < 1. Quantas\\niterações são exigidas no pior caso?\\nd.\\n Implemente o algoritmo e aplique-o a instâncias do quebra-cabeça de oito peças e do caixeiro-\\nviajante. Compare o desempenho do algoritmo ao desempenho da busca de custo uniforme e\\ncomente seus resultados.\\n3.18\\n Descreva um espaço de estados em que a busca de aprofundamento iterativo tenha desempenho\\nmuito pior que o da busca em profundidade (por exemplo, \\nO\\n(\\nn\\n2\\n) \\nversus O\\n(\\nn\\n)).\\n \\n3.19\\n Escreva um programa que receba como entrada duas URLs de páginas da Web e\\nencontre um caminho de links de uma página até a outra. Qual seria uma estratégia de busca\\napropriada? A busca bidirecional é uma boa ideia? Um mecanismo de busca poderia ser usado para\\nimplementar uma função predecessora?\\n \\n3.20\\n Considere o problema do mundo do aspirador de pó definido na \\nFigura 2.2\\n.\\na\\n. Qual dos algoritmos definidos neste capítulo seria apropriado para este problema? O algoritmo\\ndeveria utilizar a busca em árvore ou a busca em grafos?\\nb\\n. Aplique o algoritmo escolhido para calcular uma sequência ótima de ações para um mundo 3 ×\\n3 que no estado inicial tem sujeira nos três quadrados superiores e o agente está no centro.\\nc\\n. Construa um agente de busca para o mundo do aspirador de pó e avalie o seu desempenho em\\num conjunto de mundos 3 × 3 com probabilidade 0,2 de sujeira em cada quadrado. Inclua o\\ncusto de busca, bem como o custo do caminho na medida de desempenho, utilizando uma taxa de\\nconversão razoável.\\nd.\\n Compare o seu melhor agente de busca com um agente reativo aleatório único que aspira se\\nhouver sujeira e caso contrário move-se aleatoriamente.\\ne.\\n Considere o que aconteceria se o mundo fosse ampliado para \\nn × n\\n. Como o desempenho do\\nagente de busca e do agente reativo variam de acordo com \\nn\\n?\\n3.21\\n Prove cada uma das afirmações a seguir ou forneça um contraexemplo:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 153}),\n",
       " Document(page_content='a.\\n A busca em largura é um caso especial de busca de custo uniforme.\\nb\\n. A busca em profundidade é um caso especial de busca em árvore de melhor escolha.\\nc.\\n A busca de custo uniforme é um caso especial de uma busca A*.\\n \\n3.22\\n Compare o desempenho de A* e da RBFS em um conjunto de problemas gerados\\naleatoriamente do quebra-cabeças de oito peças (com distância de Manhattan) e domínios TSP (com\\nMST — consulte o Exercício 3.30). Discuta os resultados. O que acontece com o desempenho da\\nRBFS quando um pequeno número aleatório é adicionado ao valor heurístico no domínio do quebra-\\ncabeças de oito peças?\\n3.23\\n Faça passo a passo a execução de uma busca A* aplicada para o problema de chegar a\\nBucareste a partir de Lugoj utilizando a distância heurística em linha reta. Isto é, mostre a sequência\\nde nós que o algoritmo vai considerar e a pontuação \\nf\\n, \\ng\\n e \\nh\\n para cada nó.\\n \\n3.24\\n Imagine um espaço de estado no qual A* utilizando uma BUSCA-EM-GRAFO devolve\\numa solução subótima com a função h(n) que é admissível mas inconsistente.\\n3.25\\n O \\nalgoritmo heurístico\\n \\nde caminho\\n (Pohl, 1977) é uma busca de melhor escolha em que a\\nfunção avaliação é \\nf(n)\\n = (2 − \\nw\\n)\\ng\\n(\\nn\\n) + \\nwh\\n(\\nn\\n). Para que valores de \\nw\\n ela é completa? Para que\\nvalores é ótima, assumindo que \\nh\\n seja admissível? Que tipo de busca esse algoritmo realiza para \\nw\\n =\\n0, \\nw\\n = 1 e \\nw\\n = 2?\\n3.26\\n Considere a versão ilimitada da grade regular 2-D mostrada na \\nFigura 3.9\\n. O estado inicial está\\nna origem, (0,0), e o estado objetivo está em (\\nx, y\\n).\\na.\\n Qual é o fator de ramificação \\nb\\n nesse espaço de estados?\\nb.\\n Quantos estados distintos existem na profundidade \\nk\\n (para \\nk\\n > 0)?\\nc\\n. Qual é o número máximo de nós expandidos pela busca em largura em árvore?\\nd\\n. Qual é o número máximo de nós expandidos pela busca em largura em grafos?\\ne\\n. \\nh = | u − x | + | v − y |\\n é uma heurística admissível para um estado em (\\nu, v\\n)? Explique.\\nf\\n. Quantos nós são expandidos pela busca em grafos A* utilizando \\nh\\n?\\ng\\n. \\nh\\n permanece admissível se algumas ligações forem removidas?\\nh\\n. \\nh\\n permanece admissível se algumas ligações forem adicionadas entre estados não adjacentes?\\n3.27\\n \\nn\\n veículos ocupam os quadrados (1,1) através de (n,1) (ou seja, a linha inferior) de uma grade n\\nx n. Os veículos devem se movimentar para a linha superior mas em ordem reversa, assim o veículo i\\nque inicia em (i,1) deve terminar em (n – i + 1,n). Em cada etapa, cada um dos n veículos podem se\\nmover um quadrado para cima, para baixo, à esquerda, à direita ou permanecer no lugar. Outro\\nveículo adjacente (mas não mais que um) pode saltar sobre ele. Dois veículos não podem ocupar o\\nmesmo quadrado.\\na.\\n Calcule o tamanho do espaço de estados em função de n.\\nb.\\n Calcule o fator de ramificação em função de n.\\nc.\\n Suponha que o veículo i esteja em \\n(x\\ni\\n, y\\ni\\n); escreva uma heurística \\nh\\ni\\n admissível não trivial para a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 154}),\n",
       " Document(page_content='quantidade de movimentos necessária para chegar ao local objetivo (n – i + 1, n), assumindo\\nnão haver outros veículos na grade.\\nd.\\n Quais das heurísticas seguintes são admissíveis para o problema de mover todos os \\nn\\n veículos\\npara seus destinos? Explique.\\n(i) \\n(ii) max{\\nh\\n1\\n,…, \\nh\\nn\\n}.\\n(iii) min{\\nh\\n1\\n,…, \\nh\\nn\\n}.\\n3.28\\n Crie uma função heurística para o quebra cabeças de 8 peças que às vezes sobrevaloriza, e\\nmostre como ela pode conduzir a uma solução subótima em uma instância particular. (Se desejar\\npode utilizar um computador para auxiliá-lo.) Demonstre que se h nunca sobrevalorizar mais que c,\\nA* utilizando h devolve uma solução cujo custo excede por não mais que c o da solução ótima.\\n3.29\\n Demonstre que se a heurística for consistente, pode ser admissível. Construa uma heurística\\nadmissível que não seja consistente.\\n \\n3.30\\n O problema do caixeiro viajante (TSP) pode ser resolvido com a heurística da árvore\\nde geradora mínima (MST – Minimum-Spanning-Tree), que avalia o custo de completar um roteiro\\nde viagem, dado que um roteiro parcial já foi traçado. O custo da MST de um conjunto de cidades é a\\nmemor soma do custo de ligação de qualquer árvore que conecte todas as cidades.\\na.\\n Mostre como derivar essa heurística de uma versão relaxada do TSP.\\nb.\\n Mostre que o a heurística da MST domina distâncias retas.\\nc.\\n Escreva um gerador de problemas para instâncias do TSP onde as cidades são representadas\\npor pontos aleatórios no quadrado de dimensão unitária.\\nd.\\n Encontre na literatura um algoritmo eficiente para construir a MST e a utilize com a busca A*\\nem grafo para resolver as instâncias do TSP.\\n3.31\\n Na \\nSeção 3.6.2\\n, definimos o relaxamento do quebra cabeças de 8 peças no qual uma peça pode\\nmover do quadrado A para o B se B estiver desocupado. A solução exata desse problema define a\\nheurística de Gaschnig\\n (Gaschnig, 1979). Explique por que a heurística de Gaschnig é pelo menos\\ntão exata como h1 (peças fora de lugar), e mostre casos em que é mais precisa que ambos h1e h2.\\n(distância de Manhattan). Explique como calcular a heurística de Gaschnig eficientemente.\\n \\n3.32\\n Fornecemos duas heurísticas simples para o quebra cabeças de 8 peças: a distãncia de\\nManhattan e peças fora de lugar.\\nDiversas heurísticas na literatura pretendem melhorar isso – consulte, por exemplo Nilson (1971),\\nMostow e Prieditis (1989) e Hansson et al. (1992). Teste essas asserções implementando as\\nheurísticas e comparando o desempenho dos algoritmos resultantes.\\n1\\n Estamos supondo que a maioria dos leitores está na mesma posição, podendo se imaginar com facilidade estar tão desorientado quanto\\nnosso agente. Desculpamo-nos com os leitores romenos que são incapazes de tirar proveito desse exemplo pedagógico.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 155}),\n",
       " Document(page_content='2\\n Muitos tratamentos de resolução de problemas, incluindo edições anteriores deste livro, utilizam a \\nfunção sucessor\\n, que devolve o\\nconjunto de todos os sucessores, em vez das funções AÇÕES e RESULTADO distintas. A função sucessor torna difícil descrever um\\nagente que saiba quais ações pode tentar, mas não as que pode acessar. Além disso, observe que alguns autores utilizam\\nRESULTADO\\n(a,s\\n) em vez de RESULTADO(\\ns\\n, \\na\\n), e alguns usam FAÇA, ou DO em inglês, em vez de RESULTADO.\\n3\\n Esse pressuposto é conveniente algoritmicamente e também teoricamente justificável — vers pág. 649, Capítulo 17.\\n4\\n As implicações de custos negativos são exploradas no Exercício 3.8.\\n5\\n Consulte a \\nSeção 11.2\\n para definições e algoritmos mais completos.\\n6\\n \\nNoOp\\n, ou “não operação”, é o nome de uma instrução em linguagem assembler que não faz nada.\\n7\\n Aqui, e ao longo do livro, o asterisco em \\nC\\n* significa um valor ótimo de \\nC\\n.\\n8\\n Nossa primeira edição chamava-a de \\nbusca gulosa\\n; outros autores têm chamado de \\nbusca de melhor escolha\\n. Nosso uso mais\\ngeral do último termo segue Pearl (1984).\\n9\\n Com uma heurística admissível porém inconsistente, A* requer algumas anotações extras para garantir otimalidade.\\n10\\n Na primeira edição desse livro há um esboço rascunhado.\\n11\\n Nos Capítulos 8 e 10, descrevemos as linguagens formais adequadas para essa tarefa. Com descrições formais que podem ser\\nmanipuladas, a construção de problemas relaxados poderá ser automatizada. Por enquanto, usaremos o português.\\n12\\n Observe que uma heurística perfeita pode ser obtida simplesmente permitindo que \\nh\\n execute uma busca em largura completa “às\\ncegas”. Assim, deve haver um compromisso entre precisão e tempo de computação para as funções heurísticas.\\n13\\n Ao trabalhar em sentido contrário ao objetivo, o custo da solução exata de cada instância encontrada fica imediatamente disponível.\\nEsse é um exemplo de \\nprogramação dinâmica\\n, que discutiremos mais adiante no Capítulo 17.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 156}),\n",
       " Document(page_content='O\\nCAPÍTULO\\n \\n4\\nAlém da busca clássica\\nAo relaxarmos os pressupostos do capítulo anterior nos aproximamos do\\nmundo real.\\nCapítulo 3 se dirigiu a uma única categoria de problemas: observável, determinístico e de\\nambientes conhecidos, em que a solução é uma sequência de ações. Neste capítulo,\\nexaminaremos o que acontece quando esses pressupostos são relaxados. Começaremos com um\\ncaso bastante simples: as Seções 4.1 e 4.2 cobrem algoritmos que executam uma \\nbusca\\n \\nlocal\\n no\\nespaço de estados, avaliando e modificando um ou mais estados atuais, em vez de explorar\\nsistematicamente os caminhos a partir de um estado inicial. Esses algoritmos são apropriados para\\nproblemas em que tudo o que importa é o estado da solução e não o custo do caminho para alcançá-\\nlo. A família de algoritmos de busca local inclui métodos inspirados pela física estatística (\\ntêmpera\\nsimulada\\n) e pela biologia evolutiva (\\nalgoritmos genéticos\\n).\\nAssim, nas Seções 4.3 e 4.4, examinaremos o que acontece quando relaxamos os pressupostos do\\ndeterminismo e da observabilidade. A ideia principal é que, se um agente não pode prever\\nexatamente que percepção vai receber, será necessário considerar o que fazer em cada \\ncontingência\\nque suas percepções possam revelar. Com a observabilidade parcial, o agente também precisará\\nmanter o controle dos estados nos quais ele possa estar.\\nFinalmente, a \\nSeção 4.5\\n investiga a \\nbusca on-line\\n (ou busca e execução), em que o agente se\\ndefronta com um espaço de estados que inicialmente é desconhecido e deve ser explorado.\\n4.1 ALGORITMOS DE BUSCA LOCAL E PROBLEMAS DE OTIMIZAÇÃO\\nOs algoritmos de busca que vimos até agora foram projetados para explorar sistematicamente\\nespaços de busca. Esse caráter sistemático é alcançado mantendo-se um ou mais caminhos na\\nmemória e registrando-se as alternativas que foram exploradas em cada ponto ao longo do caminho e\\nquais delas não foram exploradas. Quando um objetivo é encontrado, o \\ncaminho\\n até esse objetivo\\ntambém constitui uma \\nsolução\\n para o problema.\\nNo entanto, em muitos problemas, o caminho até o objetivo é irrelevante. Por exemplo, no\\nproblema das oito rainhas, o que importa é a configuração final das rainhas, e não a ordem em que\\nelas são posicionadas. Essa mesma propriedade geral se mantém para muitas aplicações importantes,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 158}),\n",
       " Document(page_content='como projeto de circuitos integrados, leiaute de instalações industriais, escalonamento de jornadas\\nde trabalho, programação automática, otimização de rede de telecomunicações, roteamento de\\nveículos e gerenciamento de carteiras.\\nSe o caminho até o objetivo não importa, podemos considerar uma classe diferente de algoritmos,\\naqueles que não se preocupam de forma alguma com os caminhos. Os algoritmos de \\nbusca local\\noperam usando um único \\nestado atual\\n (em vez de vários caminhos) e, em geral, se movem apenas\\npara os vizinhos desse estado. Normalmente, os caminhos seguidos pela busca não são guardados.\\nEmbora os algoritmos de busca local não sejam sistemáticos, eles têm duas vantagens: (1) usam\\npouquíssima memória — normalmente um valor constante; e (2) frequentemente podem encontrar\\nsoluções razoáveis em grandes ou infinitos (contínuos) espaços de estados para os quais os\\nalgoritmos sistemáticos são inadequados.\\nAlém de encontrar objetivos, os algoritmos de busca local são úteis para resolver \\nproblemas de\\notimização\\n, nos quais o objetivo é encontrar o melhor estado de acordo com uma \\nfunção objetivo\\n.\\nMuitos problemas de otimização não se adaptam ao modelo de busca “padrão” introduzido no\\nCapítulo 3. Por exemplo, a natureza fornece uma função objetivo — adaptação reprodutiva — que\\npoderia estar tentando otimizar do ponto de vista da evolução de Darwin, mas não existe nenhum\\n“teste de objetivo” e nenhum “custo de caminho” para esse problema.\\nPara entender a busca local, é muito útil considerar a \\ntopologia de espaço de estados\\n (como na\\nFigura 4.1\\n). Uma topologia tem ao mesmo tempo “posição” (definida pelo estado) e “elevação”\\n(definida pelo valor da função de custo da heurística ou da função objetivo). Se a elevação\\ncorresponder ao custo, o objetivo será encontrar o vale mais baixo — um \\nmínimo global\\n; se a\\nelevação corresponder a uma função objetivo, então o objetivo será encontrar o pico mais alto — um\\nmáximo global\\n (você pode fazer a conversão de um para o outro apenas inserindo um sinal de\\nmenos). Os algoritmos de busca local exploram essa topologia. Um algoritmo de busca local\\ncompleto\\n sempre encontra um objetivo, caso ele exista; um algoritmo \\nótimo\\n sempre encontra um\\nmínimo/máximo global.\\nFigura 4.1\\n Uma topologia de espaço de estados unidimensional, no qual a elevação corresponde à\\nfunção objetivo. O objetivo é encontrar o máximo global. A busca de subida de encosta modifica o\\nestado atual para tentar melhorá-lo, como mostra a seta. As diversas características topográficas são\\ndefinidas no texto.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 159}),\n",
       " Document(page_content='4.1.1 Busca de subida de encosta\\nO algoritmo de busca de \\nsubida de encosta (\\nversão \\nencosta mais íngreme)\\n é mostrado na \\nFigura\\n4.2\\n. Ele é simplesmente um laço repetitivo que se move de forma contínua no sentido do valor\\ncrescente, isto é, encosta acima. O algoritmo termina quando alcança um “pico” em que nenhum\\nvizinho tem valor mais alto. O algoritmo não mantém uma árvore de busca e, assim, a estrutura de\\ndados do nó atual só precisa registrar o estado e o valor de sua função objetivo. A busca de subida\\nde encosta não examina antecipadamente valores de estados além dos vizinhos imediatos do estado\\ncorrente. É como tentar alcançar o cume do Monte Everest em meio a um nevoeiro denso durante uma\\ncrise de amnésia.\\nfunção\\n SUBIDA-DE-ENCOSTA(\\nproblema\\n) \\nretorna\\n um estado que é um máximo local\\n    \\ncorrente\\n ← CRIAR-NÓ(ESTADO-INICIAL[\\nproblema\\n])\\n    \\nrepita\\n        \\nvizinho\\n ← um sucessor de \\ncorrente\\n com valor mais alto\\n        \\nse\\n VALOR[\\nvizinho\\n] VALOR[\\ncorrente\\n] \\nentão retornar\\n ESTADO[\\ncorrente\\n]\\n        \\ncorrente\\n ← \\nvizinho\\nFigura 4.2\\n O algoritmo de busca de subida de encosta é a técnica de busca local mais básica. Em\\ncada passo, o nó atual é substituído pelo melhor vizinho; nessa versão, esse é o vizinho com o\\nVALOR mais alto; porém, se fosse usada uma estimativa de custo de heurística \\nh\\n, encontraríamos o\\nvizinho com o \\nh\\n mais baixo.\\nPara ilustrar a subida de encosta, usaremos o \\nproblema das oito rainhas\\n. Em geral, os algoritmos\\nde busca local utilizam uma \\nformulação de estados completos\\n, onde cada estado tem oito rainhas no\\ntabuleiro, uma por coluna. Os sucessores de um estado são todos os estados possíveis gerados pela\\nmovimentação de uma única rainha para outro quadrado na mesma coluna (de forma que cada estado\\ntenha 8 × 7 = 56 sucessores). A função de custo heurística \\nh\\n é o número de pares de rainhas que estão\\natacando umas às outras, direta ou indiretamente. O mínimo global dessa função é zero, que só ocorre\\nem soluções perfeitas. A \\nFigura 4.3\\n(a) mostra um estado com \\nh\\n = 17. A figura também mostra os\\nvalores de todos os seus sucessores, sendo que os melhores sucessores têm \\nh\\n = 12. Os algoritmos de\\nsubida de encosta normalmente fazem uma escolha aleatória entre o conjunto de melhores sucessores,\\ncaso exista mais de um.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 160}),\n",
       " Document(page_content='Figura 4.3\\n (a) Um estado de oito rainhas com estimativa de custo de heurística \\nh\\n = 17, mostrando o\\nvalor de \\nh\\n para cada sucessor possível obtido pela movimentação de uma rainha dentro de sua\\ncoluna. Os melhores movimentos estão marcados. (b) Um mínimo local no espaço de estados de oito\\nrainhas; o estado tem \\nh\\n = 1, mas todo sucessor tem um custo mais alto.\\nA subida de encosta às vezes é chamada \\nbusca gulosa local\\n porque captura um bom estado vizinho\\nsem decidir com antecedência para onde irá em seguida. Embora a gula seja considerada um dos sete\\npecados capitais, na verdade os algoritmos ambiciosos frequentemente funcionam muito bem. Muitas\\nvezes, a subida de encosta progride com grande rapidez em direção a uma solução porque\\nnormalmente é bem fácil melhorar um estado ruim. Por exemplo, a partir do estado da \\nFigura 4.3\\n(a),\\nbastam cinco passos para alcançar o estado da \\nFigura 4.3\\n(b), que tem \\nh\\n = 1 e está muito próxima de\\numa solução. Infelizmente, a subida de encosta com frequência fica paralisada, pelas seguintes\\nrazões:\\n•  \\nMáximos locais:\\n um máximo local é um pico mais alto que cada um de seus estados vizinhos,\\nembora seja mais baixo que o máximo global. Os algoritmos de subida de encosta que\\nalcançarem a vizinhança de um máximo local serão deslocados para cima em direção ao pico,\\nmas depois ficarão presos, sem ter para onde ir. A \\nFigura 4.1\\n ilustra esquematicamente o\\nproblema. Em termos mais concretos, o estado da \\nFigura 4.3\\n(b) é de fato um máximo local (isto\\né, um mínimo local para o custo \\nh\\n); todo movimento de uma única rainha piora a situação.\\n•  \\nCordilheiras:\\n uma cordilheira é mostrada na \\nFigura 4.4\\n. Cordilheiras resultam em uma\\nsequência de máximos locais que torna muito difícil a navegação para algoritmos ambiciosos.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 161}),\n",
       " Document(page_content='Figura 4.4\\n Ilustração do motivo pelo qual cordilheiras causam dificuldades na subida de encosta. A\\nmalha de estados (círculos escuros) está sobreposta sobre uma cordilheira que se eleva da esquerda\\npara a direita, criando uma sequência de máximos locais que não estão diretamente conectados uns\\naos outros. A partir de cada máximo local, todas as ações disponíveis apontam encosta abaixo.\\n•  \\nPlatôs:\\n um platô é uma área plana da topologia de espaço de estados. Ele pode ser um máximo\\nlocal plano, a partir do qual não existe nenhuma saída encosta acima ou uma \\nplanície\\n, a partir da\\nqual é possível progredir (veja a \\nFigura 4.1\\n). Uma busca de subida de encosta talvez se perca no\\nplatô.\\nEm cada caso, o algoritmo alcança um ponto em que não há nenhum progresso. A partir de um\\nestado do problema de oito rainhas gerado aleatoriamente, a subida de encosta pela trilha mais\\níngreme ficará paralisada 86% do tempo, resolvendo apenas 14% de instâncias de problemas. Ela\\nfunciona com rapidez, demorando apenas quatro passos em média quando tem sucesso e três quando\\nfica presa — nada mal para um espaço de estados com 8\\n8\\n ≈ 17 milhões de estados.\\nO algoritmo da \\nFigura 4.2\\n para ao alcançar um platô em que o melhor sucessor tem o mesmo valor\\ndo estado corrente. Pode ser uma boa ideia prosseguir — permitir um \\nmovimento lateral\\n, na\\nesperança de que o platô seja na realidade uma planície, como mostra a \\nFigura 4.1\\n? Normalmente, a\\nresposta é sim, mas devemos ter cuidado. Se sempre permitirmos movimentos laterais quando não\\nhouver nenhum movimento encosta acima ocorrerá uma repetição infinita sempre que o algoritmo\\nalcançar um máximo local plano que não seja uma planície. Uma solução comum é impor um limite\\nsobre o número de movimentos laterais consecutivos permitidos. Por exemplo, poderíamos permitir\\naté, digamos, 100 movimentos laterais consecutivos no problema de oito rainhas. Isso aumenta a\\nporcentagem de instâncias de problemas resolvidos por subida de encosta de 14% para 94%. O\\nsucesso tem um custo: o algoritmo demora em média 21 passos aproximadamente para cada instância\\nbem-sucedida e 64 passos para cada falha.\\nForam criadas muitas variantes de subida de encosta. A \\nsubida de encosta estocástica\\n escolhe de\\nformas aleatória os movimentos encosta acima; a probabilidade de seleção pode variar com a\\ndeclividade do movimento encosta acima. Em geral, isso converge mais lentamente que a subida\\nmais íngreme, mas em algumas topologias de estados encontra soluções melhores. A \\nsubida de\\nencosta pela primeira escolha\\n implementa a subida de encosta estocástica gerando sucessores ao\\nacaso até ser gerado um sucessor melhor que o estado corrente. Essa é uma boa estratégia quando um\\nestado tem muitos sucessores (por exemplo, milhares).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 162}),\n",
       " Document(page_content='Os algoritmos de subida de encosta descritos até agora são incompletos — com frequência, eles\\ndeixam de encontrar um objetivo que existe porque ficam presos em máximos locais. A \\nsubida de\\nencosta com reinício aleatório\\n adota o conhecido ditado: “Se não tiver sucesso na primeira vez,\\ncontinue tentando.” Ela conduz uma série de buscas de subida de encosta a partir de estados iniciais\\n1\\ngerados de forma aleatória, até encontrar um objetivo. Ela é completa trivialmente, com a\\nprobabilidade se aproximando de 1, porque ela irá eventualmente gerar um estado objetivo como\\nestado inicial. Se cada busca de subida de encosta tiver uma probabilidade de sucesso \\np\\n, o número\\nesperado de reinícios exigidos será 1/\\np\\n. Para instâncias das oito rainhas sem permitir movimentos\\nlaterais, \\np\\n ≈ 0,14; assim, precisamos de aproximadamente sete iterações para encontrar um objetivo\\n(seis falhas e um sucesso). O número esperado de passos é o custo de uma iteração bem-sucedida\\nsomado a (1 – \\np\\n)/\\np\\n vezes o custo de falha ou cerca de 22 passos no total. Quando permitimos\\nmovimentos laterais, são necessárias 1/0,94 ≈ 1,06 iteração em média e (1 × 21) + (0,06/0,94) × 64\\n≈ 25 passos. Então, no caso de oito rainhas, a subida de encosta com reinício aleatório é de fato\\nmuito eficiente. Mesmo para três milhões de rainhas, a abordagem pode encontrar soluções em menos\\nde um minuto.\\n2\\nO sucesso da subida de encosta depende muito da forma da topologia do espaço de estados: se\\nhouver poucos máximos locais e platôs, a subida de encosta com reinício aleatório encontrará uma\\nboa solução com muita rapidez. Por outro lado, muitos problemas reais têm topologia mais parecida\\ncom uma família dispersa de porco-espinhos em um piso plano, com porco-espinho em miniatura\\nvivendo na ponta de cada espinho, \\nad infinitum\\n. Em geral, os problemas NP-difíceis têm um número\\nexponencial de máximos locais em que ficam presos. Apesar disso, um máximo local razoavelmente\\nbom pode ser encontrado com fre\\u200bquência depois de um pequeno número de reinícios.\\n4.1.2 Têmpera simulada\\nUm algoritmo de subida de encosta que \\nnunca\\n faz movimentos “encosta abaixo” em direção a\\nestados com valor mais baixo (ou de custo mais alto) sem dúvida é incompleto porque pode ficar\\npreso em um máximo local. Em contraste, um percurso puramente aleatório — isto é, mover para um\\nsucessor escolhido uniformemente ao acaso a partir do conjunto de sucessores — é completo, mas\\nextremamente ineficiente. Dessa forma, parece razoável tentar combinar a subida de encosta com um\\npercurso aleatório que resulte de algum modo em eficiência e completeza. A \\ntêmpera simulada\\n é\\nesse algoritmo. Em metalurgia, a \\ntêmpera\\n é o processo usado para temperar ou endurecer metais e\\nvidro aquecendo-os a alta temperatura e depois esfriando-os gradualmente, permitindo assim que o\\nmaterial alcance um estado cristalino de baixa energia. Para explicar a têmpera simulada, vamos\\nmudar nosso ponto de vista de subida de encosta para \\ndescida de gradiente\\n (isto é, minimização do\\ncusto) e imaginar a tarefa de colocar uma bola de pingue-pongue na fenda mais profunda em uma\\nsuperfície acidentada. Se simplesmente deixarmos a bola rolar, ela acabará em um mínimo local. Se\\nagitarmos a superfície, poderemos fazer a bola quicar para fora do mínimo local. O artifício é agitar\\ncom força suficiente para fazer a bola sair dos mínimos locais, mas não o bastante para desalojá-la\\ndo mínimo global. A solução de têmpera simulada é começar a agitar com força (isto é, em alta\\ntemperatura) e depois reduzir gradualmente a intensidade da agitação (ou seja, baixar a temperatura).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 163}),\n",
       " Document(page_content='O laço de repetição mais interno do algoritmo de têmpera simulada (\\nFigura 4.5\\n) é muito\\nsemelhante à subida de encosta. Porém, em vez de escolher o \\nmelhor\\n movimento, ele escolhe um\\nmovimento \\naleatório\\n. Se o movimento melhorar a situação, ele sempre será aceito. Caso contrário, o\\nalgoritmo aceitará o movimento com alguma probabilidade menor que 1. A probabilidade decresce\\nexponencialmente com a “má qualidade” do movimento — o valor ∆\\nE\\n segundo o qual a avaliação\\npiora. A probabilidade também decresce à medida que a “temperatura” \\nT\\n se reduz: movimentos\\n“ruins” têm maior probabilidade de serem permitidos no início, quando \\nT\\n estiver alto, e se tornam\\nmais improváveis conforme \\nT\\n diminui. Se o \\nescalonamento\\n diminuir \\nT\\n com lentidão suficiente, o\\nalgoritmo encontrará um valor ótimo global com probabilidade próxima de 1.\\nfunção\\n TÊMPERA-SIMULADA(\\nproblema, escalonamento\\n) \\nretorna\\n um estado solução\\n    \\nentradas:\\n \\nproblema\\n, um problema\\nescalonamento\\n, um mapeamento de tempo para “temperatura”\\n    \\natual\\n ← CRIAR-NÓ(\\nproblema\\n.ESTADO-INICIAL)\\n    \\npara\\n \\nt\\n = 1 \\naté\\n ∞ \\nfaça\\n        \\nT\\n ← \\nescalonamento\\n[\\nt\\n]\\n        \\nse\\n \\nT\\n = 0 \\nentão retornar\\n \\ncorrente\\n        \\npróximo\\n ← um sucessor de \\natual\\n selecionado aleatoriamente\\n        ∆\\nE\\n ← \\npróximo\\n.VALOR – \\natual\\n.VALOR\\n        \\nse\\n ∆\\nE\\n > 0 \\nentão\\n \\natual\\n ← \\npróximo\\n        \\nsenão\\n \\natual\\n ← \\npróximo\\n somente com probabilidade \\ne\\n∆E/T\\nFigura 4.5\\n O algoritmo de têmpera simulada, uma versão de subida de encosta estocástica, onde\\nalguns movimentos encosta abaixo são permitidos. Movimentos encosta abaixo são prontamente\\naceitos no início do escalonamento da têmpera, e depois com menor frequência no decorrer do\\ntempo. A entrada \\nescalonamento\\n define o valor da temperatura \\nT\\n como uma função do tempo.\\nA têmpera simulada foi usada inicialmente de forma extensiva para resolver problemas de leiaute\\nde VLSI no começo dos anos 1980. Ela foi amplamente aplicada ao escalonamento industrial e a\\noutras tarefas de otimização em grande escala. No Exercício 4.4, você será convidado a comparar\\nseu desempenho ao da subida de encosta com reinício aleatório no quebra-cabeça das oito rainhas.\\n4.1.3 Busca em feixe local\\nA manutenção de apenas um nó na memória pode parecer uma reação extrema ao problema de\\nlimitação de memória. O algoritmo de \\nbusca em feixe local\\n3\\n mantém o controle de \\nk\\n estados, em vez\\nde somente um. Ela começa com \\nk\\n estados gerados aleatoriamente. Em cada passo, são gerados todos\\nos sucessores de todos os \\nk\\n estados. Se qualquer um deles for um objetivo, o algoritmo irá parar.\\nCaso contrário, ele selecionará os \\nk\\n melhores sucessores a partir da lista completa e repetirá o\\nprocedimento.\\nÀ primeira vista, uma busca em feixe local com \\nk\\n estados talvez pareça não ser nada mais que a\\nexecução de \\nk\\n reinícios aleatórios em paralelo, e não em sequência. De fato, os dois algoritmos são', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 164}),\n",
       " Document(page_content='bastante diferentes. Em uma busca com reinício aleatório, cada processo de busca funciona de forma\\nindependente dos outros. \\nEm uma busca em feixe local\\n, \\nsão repassadas informações úteis entre os k\\nprocessos paralelos da busca\\n. Com efeito, os estados que geram os melhores sucessores dizem aos\\noutros: “Venha para cá, aqui está melhor!”O algoritmo logo abandonará as buscas infrutíferas e\\ndeslocará seus recursos para o processo em que estiver sendo realizado maior progresso.\\n Em sua forma mais simples, a busca em feixe local pode se ressentir de uma falta de\\ndiversidade entre os \\nk\\n estados — eles podem ficar rapidamente concentrados em uma pequena região\\ndo espaço de estados, tornando a busca pouco mais que uma versão dispendiosa de subida de\\nencosta. Uma variante chamada \\nbusca em feixe estocástica\\n, análoga à subida de encosta estocástica,\\najuda a atenuar esse problema. Em vez de escolher o melhor \\nk\\n a partir do conjunto de sucessores\\ncandidatos, a busca em feixe estocástica escolhe \\nk\\n sucessores de forma aleatória, com a\\nprobabilidade de escolher um determinado sucessor que seja uma função crescente de seu valor. A\\nbusca em feixe estocástica guarda alguma semelhança com o processo de seleção natural, pelo qual\\nos “sucessores” (descendência) de um “estado” (organismo) ocupam a próxima geração de acordo\\ncom seu “valor” (adaptação ou fitness).\\n4.1.4 Algoritmos genéticos\\nUm \\nalgoritmo genético\\n (ou AG) é uma variante de busca em feixe estocástica na qual os estados\\nsucessores são gerados pela combinação de \\ndois\\n estados pais, em vez de serem gerados pela\\nmodificação de um único estado. A analogia em relação à seleção natural é a mesma que se dá na\\nbusca em feixe estocástica, exceto pelo fato de agora estarmos lidando com a reprodução sexuada, e\\nnão com a reprodução assexuada.\\nComo ocorre com a busca em feixe, os AGs começam com um conjunto de \\nk\\n estados gerados\\naleatoriamente, chamado \\npopulação\\n. Cada estado, ou \\nindivíduo\\n, é representado como uma cadeia\\nsobre um alfabeto finito — muito frequentemente, uma cadeia de valores 0 e 1. Por exemplo, um\\nestado das oito rainhas deve especificar as posições das oito rainhas, cada uma em uma coluna de\\noito quadrados e, portanto, exigindo 8 × log\\n2\\n 8 = 24 bits. Como alternativa, o estado poderia ser\\nrepresentado como oito dígitos, cada um no intervalo de 1 a 8 (demonstraremos mais adiante que as\\nduas codificações têm comportamento diferente). A \\nFigura 4.6\\n(a) mostra uma população de quatro\\ncadeias de oito dígitos que representam estados das oito rainhas.\\nFigura 4.6\\n O algoritmo genético, ilustrado por sequências de dígitos que representam os estados das', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 165}),\n",
       " Document(page_content='oito rainhas. A população inicial em (a) é classificada pela função de adaptação em (b), resultando\\nem pares de correspondência em (c). Eles produzem descendentes em (d), sujeitos à mutação em (e).\\nA produção da próxima geração de estados é mostrada na \\nFigura 4.6\\n(b)−(e). Em (b), cada estado é\\navaliado pela função de avaliação ou (na terminologia do AG) pela \\nfunção de adaptação\\n. Uma\\nfunção de adaptação deve retornar valores mais altos para estados melhores; assim, para o problema\\ndas oito rainhas, usamos o número de pares de rainhas \\nnão atacantes\\n, que têm o valor 28 para uma\\nsolução. Os valores dos quatro estados são 24, 23, 20 e 11. Nessa variante específica do algoritmo\\ngenético, a probabilidade de um indivíduo ser escolhido para reprodução é diretamente proporcional\\nà sua pontuação de adaptação, e as porcentagens são mostradas ao lado das pontuações brutas.\\nEm (c), dois pares escolhidos aleatoriamente são selecionados para reprodução, de acordo com as\\nprobabilidades mostradas em (b). Note que um indivíduo é selecionado duas vezes, e um indivíduo\\nnão é selecionado de modo algum.\\n4\\n Para cada par a ser cruzado, é escolhido ao acaso um ponto de\\ncruzamento\\n dentre as posições na cadeia. Na \\nFigura 4.6\\n, os pontos de cruzamento estão depois do\\nterceiro dígito no primeiro par e depois do quinto dígito no segundo par.\\n5\\nEm(d), os próprios descendentes são criados por cruzamento das cadeias pais no ponto de\\ncrossover. Por exemplo, o primeiro filho do primeiro par recebe os três primeiros dígitos do\\nprimeiro pai e os dígitos restantes do segundo pai, enquanto o segundo filho recebe os três primeiros\\ndígitos do segundo pai e o restante do primeiro pai. Os estados das oito rainhas envolvidos nessa\\netapa de reprodução são mostrados na \\nFigura 4.7\\n. O exemplo ilustra o fato de que, quando dois\\nestados pais são bastante diferentes, a operação de cruzamento pode produzir um estado que está\\nlonge do estado de qualquer pai. Em geral, a população é bastante diversa no início do processo e,\\nassim, o cruzamento (como a têmpera simulada) frequentemente executa grandes passos no espaço de\\nestados bem no início do processo de busca e passos menores mais adiante, quando a maioria dos\\nindivíduos é bastante semelhante.\\nFigura 4.7\\n Os estados das oito rainhas correspondentes aos dois primeiros pais na \\nFigura 4.6\\n(c) e à\\nprimeira descendência da \\nFigura 4.6\\n(d). As colunas sombreadas foram perdidas na etapa de\\ncruzamento, e as colunas não sombreadas foram mantidas.\\nFinalmente, em (e), cada posição está sujeita à \\nmutação\\n aleatória com uma pequena probabilidade\\nindependente. Um dígito sofreu mutação no primeiro, no terceiro e no quarto descendente. No\\nproblema das oito rainhas, isso corresponde à escolha de uma rainha ao acaso e à movimentação da\\nrainha para um quadrado aleatório em sua coluna. A \\nFigura 4.8\\n descreve um algoritmo que\\nimplementa todas essas etapas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 166}),\n",
       " Document(page_content='função\\n ALGORITMO-GENÉTICO(\\npopulação\\n, FN-ADAPTA) \\nretorna\\n um indivíduo\\n    \\nentradas:\\n \\npopulação\\n, um conjunto de indivíduos\\nFN-ADAPTA, uma função que mede a adaptação de um indivíduo\\n    repita\\n        \\nnova_população\\n ← conjunto vazio\\n        \\npara\\n \\ni\\n = 1 \\naté\\n TAMANHO(\\npopulação\\n) \\nfaça\\n            \\nx\\n ← SELEÇÃO-ALEATÓRIA(\\npopulação\\n, FN-ADAPTA)\\n            \\ny\\n ← SELEÇÃO-ALEATÓRIA(\\npopulação\\n, FN-ADAPTA)\\n            \\nfilho\\n ← REPRODUZ(\\nx\\n, \\ny\\n)\\n            \\nse\\n (pequena probabilidade aleatória) \\nentão\\n \\nfilho\\n ← MUTAÇÃO(\\nfilho\\n)\\n            adicionar \\nfilho\\n a \\nnova\\n_\\npopulação\\n            \\npopulação\\n ← \\nnova\\n_\\npopulação\\n    \\naté\\n algum indivíduo estar adaptado o suficiente ou até ter decorrido tempo suficiente\\n    \\nretornar\\n o melhor indivíduo em \\npopulação\\n, de acordo com FN-ADAPTA\\n_____________________________________________________________________________________________________________\\nfunção\\n REPRODUZ(\\nx\\n, \\ny\\n) \\nretorna\\n um indivíduo\\n    \\nentradas:\\n \\nx\\n, \\ny\\n, indivíduos pais\\n    \\nn\\n ← COMPRIMENTO(\\nx\\n)\\nc\\n ← número aleatório de 1 a \\nn\\n    \\nretornar\\n CONCATENA(SUBCADEIA(\\nx\\n, 1 \\nc\\n), SUBCADEIA(\\ny\\n, \\nc\\n + 1, \\nn\\n))\\nFigura 4.8\\n Um algoritmo genético.O algoritmo é igual ao que foi representado na \\nFigura 4.6\\n, com\\numa variação: em sua versão mais popular, cada união de dois pais produz apenas um descendente, e\\nnão dois.\\nComo a busca em feixe estocástico, os algoritmos genéticos combinam uma propensão para subir a\\nencosta com a exploração aleatória e com a troca de informações entre processos de busca paralelos.\\nA principal vantagem dos algoritmos genéticos, se houver, vem da operação de cruzamento. Pode ser\\ndemonstrado matematicamente que, se as posições do código genético forem permutadas inicialmente\\nem ordem aleatória, o cruzamento não trará nenhuma vantagem. Intuitivamente, a vantagem vem da\\nhabilidade do cruzamento de combinar grandes blocos de genes que evoluem de forma independente\\npara executar funções úteis, elevando assim o nível de granularidade em que a busca opera. Por\\nexemplo, a colocação das três primeiras rainhas nas posições 2, 4 e 6 (em que elas não atacam as\\noutras) constitui um bloco útil que pode ser combinado com outros blocos para elaborar uma\\nsolução.\\nA teoria de algoritmos genéticos explica como isso funciona usando a ideia de \\nesquema\\n, uma\\nsubcadeia na qual algumas posições podem ser deixadas sem especificação. Por exemplo, o esquema\\n246***** descreve todos os estados de oito rainhas em que as três primeiras rainhas estão nas\\nposições 2, 4 e 6, respectivamente. As cadeias que correspondem ao esquema (como 24613578) são\\nchamadas \\ninstâncias\\n do esquema. É possível mostrar que, se o valor de adaptação médio das\\ninstâncias de um esquema estiver acima da média, então o número de instâncias do esquema dentro\\nda população crescerá com o passar do tempo. É claro que é improvável que esse efeito seja\\nsignificativo, caso bits adjacentes estejam totalmente não relacionados uns com os outros porque,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 167}),\n",
       " Document(page_content='nesse caso, haverá poucos blocos contíguos que proporcionem um benefício consistente. Os\\nalgoritmos genéticos funcionam melhor quando os esquemas correspondem a componentes\\nsignificativos de uma solução. Por exemplo, se a cadeia for uma representação de uma antena, os\\nesquemas poderão representar componentes da antena, como refletores e defletores. É provável que\\num bom componente seja bom em uma grande variedade de projetos diferentes. Isso sugere que o uso\\nbem-sucedido de algoritmos genéticos exige uma cuidadosa engenharia na representação de estados.\\nNa prática, os algoritmos genéticos tiveram amplo impacto sobre problemas de otimização, como\\nleiaute de circuitos e escalonamento de prestação de serviços. No momento, não está claro se o\\ninteresse pelos algoritmos genéticos surge de seu desempenho ou de suas origens esteticamente\\natraente na teoria da evolução. Ainda há muito trabalho a ser feito para identificar as condições sob\\nas quais os algoritmos genéticos funcionam bem.\\n4.2 BUSCA LOCAL EM ESPAÇOS CONTÍNUOS\\nNo Capítulo 2, explicamos a distinção entre ambientes discretos e contínuos, assinalando que a\\nmaioria dos ambientes reais é contínua. Ainda assim, nenhum dos algoritmos que descrevemos\\n(exceto a subida de encosta mais íngreme e a de têmpora simulada) pode manipular espaços\\ncontínuos e espaços de ação porque têm fatores infinitos de ramificação. Esta seção fornece uma\\nintrodução \\nmuito breve\\n a algumas técnicas de busca local para encontrar soluções ótimas em espaços\\ncontínuos. A literatura sobre esse tópico é vasta; muitas técnicas básicas tiveram origem no século\\nXVII, depois do desenvolvimento do cálculo por Newton e Leibniz.\\n6\\n Descobriremos usos para essas\\ntécnicas em diversos lugares no livro, incluindo os capítulos sobre aprendizado, visão e robótica.\\nEVOLUÇÃO E BUSCA\\nA teoria da \\nevolução\\n foi desenvolvida por Charles Darwin em \\nOn the Origin of Species By\\nMeans of Natural Selection\\n (1859) e, independentemente, por Alfred Russel Wallace (1858). A\\nideia central é simples: variações ocorrem na reprodução e serão preservadas em gerações\\nsucessivas em proporção aproximada ao seu efeito sobre a adaptação reprodutiva.\\nA teoria de Darwin foi desenvolvida sem qualquer conhecimento de como as características\\ndos organismos podem ser herdadas e modificadas. As leis probabilísticas que governam esses\\nprocessos foram primeiro identificadas por Gregor Mendel (1866), um monge que fez\\nexperiências com ervilhas. Muito mais tarde, Watson e Crick (1953) identificaram a estrutura da\\nmolécula de DNA e seu alfabeto, AGTC (adenina, guanina, timina, citosina). No modelo-padrão, a\\nvariação ocorre por mutações localizadas na sequência de genes e por cruzamento (no qual o\\nDNA de um descendente é gerado pela combinação de longas seções de DNA de cada pai).\\nA analogia com algoritmos de busca local já foi descrita; a principal diferença entre a busca em\\nfeixe estocástico e a evolução é o uso de reprodução sexuada, na qual os sucessores são gerados a\\npartir de \\nvários\\n organismos em vez de apenas um. Porém, os mecanismos reais da evolução são\\nmuito mais ricos do que permite a maioria dos algoritmos genéticos. Por exemplo, as mutações', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 168}),\n",
       " Document(page_content='podem envolver reversões, duplicações e movimentação de grandes blocos de DNA; alguns vírus\\ntomam emprestado o DNA de um organismo e o inserem em outro; e ainda existem genes de\\ntransposição que nada fazem além de copiar a si mesmos muitos milhares de vezes dentro do\\ngenoma. Existem até mesmo genes que envenenam células de companheiros potenciais que não\\ntransportam o gene, aumentando assim suas chances de replicação. O mais importante é o fato de\\nque os \\npróprios genes codificam os mecanismos\\n pelos quais o genoma é reproduzido e\\nconvertido em um organismo. Em algoritmos genéticos, esses mecanismos constituem um\\nprograma separado que não está representado dentro das cadeias que estão sendo manipuladas.\\nA evolução de Darwin pode parecer ineficiente, tendo gerado cegamente cerca de 10\\n45\\norganismos sem melhorar uma vírgula sequer suas heurísticas de busca. Contudo, 50 anos antes de\\nDarwin, outro grande naturalista francês chamado Jean Lamarck (1809) propôs uma teoria da\\nevolução pela qual as características adquiridas por adaptação durante a vida de um organismo\\nseriam transmitidas aos seus descendentes. Tal processo seria eficaz, mas não parece ocorrer na\\nnatureza. Muito mais tarde, James Baldwin (1896) propôs uma teoria similar em suas\\ncaracterísticas superficiais: que o comportamento aprendido durante a vida de um organismo\\npoderia acelerar a velocidade da evolução. Diferentemente da teoria de Lamarck, a teoria de\\nBaldwin é inteiramente consistente com a evolução de Darwin porque se baseia em forçar a\\nseleção sobre indivíduos que encontram pontos ótimos locais no conjunto de comportamentos\\npossíveis permitidos por sua constituição genética. Simulações em modernos computadores\\nconfirmam que o “efeito de Baldwin” é real, desde que a evolução “comum” possa criar\\norganismos cuja medida interna de desempenho esteja de alguma forma correlacionada à\\nadaptação real.\\nComeçaremos com um exemplo. Vamos supor que queiramos instalar três novos aeroportos em\\nqualquer lugar na Romênia, de tal forma que a soma dos quadrados das distâncias de cada cidade no\\nmapa (\\nFigura 3.2\\n) até o aeroporto mais próximo seja minimizada. Então, o espaço de estados é\\ndefinido pelas coordenadas dos aeroportos: (\\nx\\n1\\n, \\ny\\n1\\n), (\\nx\\n2\\n, \\ny\\n2\\n) e (\\nx\\n3\\n, \\ny\\n3\\n). Esse é um espaço\\nhexadimensional\\n; também dizemos que os estados são definidos por seis \\nvariáveis\\n (em geral, os\\nestados são definidos por um vetor \\nn\\n-dimensional de variáveis, \\nx\\n). A movimentação nesse espaço\\ncorresponde a mover um ou mais dos aeroportos no mapa. A função objetivo \\nf\\n(\\nx\\n1\\n, \\ny\\n1\\n, \\nx\\n2\\n, \\ny\\n2\\n, \\nx\\n3\\n, \\ny\\n3\\n) é\\nrelativamente fácil de calcular para qualquer estado específico, uma vez que sejam calculadas as\\ncidades mais próximas. Façamos C\\ni\\n o conjunto de cidades mais próximas, cujo aeroporto (no estado\\natual) é o aeroporto \\ni.\\n Então, \\nna vizinhança do estado atual\\n, onde os C\\ni\\n permanecem constantes,\\ntemos:\\nEssa expressão é \\nlocalmente\\n correta, mas não globalmente correta porque os conjuntos C\\ni\\n são\\nfunções \\n(\\ndescontínuas) do estado.\\nUma maneira de evitar problemas contínuos é simplesmente \\ntornar\\n \\ndiscreta\\n a vizinhança de cada\\nestado. Por exemplo, podemos mover apenas um aeroporto de cada vez na direção \\nx\\n ou \\ny\\n por um', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 169}),\n",
       " Document(page_content='valor fixo ±\\nΔ.\\n Com seis variáveis, isso nos dá 12 sucessores para cada estado. Podemos então\\naplicar qualquer dos algoritmos de busca local descritos anteriormente. Também é possível aplicar\\ndiretamente a subida de encosta estocástica e a têmpera simulada, sem tornar o espaço discreto.\\nEsses algoritmos escolhem sucessores aleatoriamente, o que pode ser feito pela geração de vetores\\naleatórios de comprimento Δ.\\nExistem muitos métodos que tentam usar o \\ngradiente\\n da topologia para encontrar um máximo. O\\ngradiente da função objetivo é um vetor \\n∇\\nf\\n que fornece a magnitude e a direção da inclinação mais\\níngreme. Em nosso problema, temos:\\nEm alguns casos, podemos encontrar um máximo resolvendo a equação \\n∇\\nf\\n = 0 (por exemplo, isso\\npoderia ser feito se estivéssemos instalando apenas um aeroporto; a solução é a média aritmética das\\ncoordenadas de todas as cidades). Porém, em muitos casos, essa equação não pode ser resolvida de\\nforma fechada. Por exemplo, com três aeroportos, a expressão para o gradiente depende das cidades\\nque estão mais próximas a cada aeroporto no estado atual. Isso significa que podemos calcular o\\ngradiente \\nlocal\\n, mas não \\nglobal,\\n por exemplo,\\nDada uma expressão localmente correta para o gradiente, podemos realizar uma subida pela\\nencosta mais íngreme, atualizando o estado atual de acordo com a fórmula\\nonde \\nα\\n é uma constante pequena chamada frequentemente de \\ntamanho de passo\\n. Em outros casos, a\\nfunção objetivo pode não estar disponível de modo algum em uma forma diferenciável — por\\nexemplo, o valor de um conjunto específico de posições de aeroportos pode ser determinado pela\\nexecução de algum pacote de simulação de grande escala. Nesses casos, um \\ngradiente empírico\\npode ser determinado pela avaliação da resposta a pequenos incrementos e decrementos em cada\\ncoordenada. A busca de gradiente empírico é igual à subida pela encosta mais íngreme em uma\\nversão do espaço de estados dividida em unidades discretas.\\nPor trás da frase “\\nα\\n é uma constante pequena” reside uma enorme variedade de métodos para\\najuste de \\nα.\\n O problema básico é que, se \\nα\\n é pequeno demais, são necessários muitos passos; se \\nα\\n é\\ngrande demais, a busca pode ultrapassar o limite máximo. A técnica de \\nbusca linear\\n tenta superar\\nesse dilema estendendo a direção de gradiente atual — em geral, pela duplicação repetida de \\nα\\n —–\\naté \\nf\\n começar a diminuir novamente. O ponto em que isso ocorrer se torna o novo estado atual.\\nExistem diversas escolas de pensamento relacionadas ao modo como a nova direção deve ser\\nescolhida nesse ponto.\\nPara muitos problemas, o algoritmo mais eficiente é o venerável método de \\nNewton-Raphson\\n.\\nEssa é uma técnica geral para encontrar as raízes de funções, isto é, resolver equações da forma \\ng\\n(\\nx\\n)\\n= 0. Ela funciona calculando uma nova estimativa para a raiz \\nx\\n de acordo com a fórmula de Newton:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 170}),\n",
       " Document(page_content='Para encontrar um máximo ou um mínimo de \\nf\\n, precisamos encontrar \\nx\\n tal que o \\ngradiente\\n seja\\nzero (isto é, \\n∇\\nf\\n(\\nx\\n) = \\n0\\n). Desse modo, \\ng\\n(\\nx\\n) na fórmula de Newton se torna \\n∇\\nf\\n(\\nx\\n), e a equação de\\natualização pode ser escrita em forma de vetor de matriz como:\\nonde \\nH\\nf\\n(\\nx\\n) é a matriz \\nhessiana\\n de segundas derivadas, cujos elementos \\nH\\nij\\n são dados por \\n.\\nPara o nosso exemplo do aeroporto, pode-se notar da Equação 4.2 que \\nH\\nf\\n(\\nx\\n) é particularmente\\nsimples: os elementos fora da diagonal são zero e os elementos da diagonal para o aeroporto \\ni\\n são\\napenas duas vezes o número de cidades em \\nC\\ni\\n. Um cálculo rápido mostra que uma etapa da\\natualização move o aeroporto \\ni\\n diretamente para o centroide de \\nC\\ni\\n,\\n que é o mínimo da expressão\\nlocal para \\nf\\n da Equação 4.1.\\n7\\n Para problemas de dimensões elevadas, no entanto, calcular \\nn\\n² entradas\\nda hessiana e invertê-las pode ser caro, por isso muitas versões aproximadas do método de Newton-\\nRaphson têm sido desenvolvidas.\\nOs métodos de busca local com máximos locais, cordilheiras e platôs em espaços de estados\\ncontínuos, de forma semelhante ao que ocorre em espaços discretos. Reinícios aleatórios e têmpera\\nsimulada são recursos que podem ser usados e frequentemente são úteis. Porém, os espaços\\ncontínuos de dimensões elevadas são lugares grandes em que é fácil se perder.\\nUm último tópico sobre o qual seria útil alguma familiarização é a \\notimização restrita\\n. Um\\nproblema de otimização é restrito se as soluções devem satisfazer a algumas restrições rígidas sobre\\nos valores de cada variável. Por exemplo, em nosso problema de localização de aeroportos,\\npoderíamos restringir os locais ao interior da Romênia e a áreas de terra firme (e não no meio de\\nlagos). A dificuldade dos problemas de otimização restrita depende da natureza das restrições e da\\nfunção objetivo. A categoria mais conhecida é a dos problemas de \\nprogramação linear\\n, em que as\\nrestrições devem ser desigualdades lineares formando um conjunto \\nconvexo\\n8\\n e a função objetivo\\ntambém é linear. A complexidade de tempo de programação linear é polinomial no número de\\nvariáveis.\\nA programação linear provavelmente é a classe mais amplamente estudada e de utilidade mais\\nextensa dos problemas de otimização. É um caso especial do problema mais geral de \\notimização\\nconvexa\\n, que permite que a região de restrição seja qualquer região convexa e o objetivo seja\\nqualquer função convexa na região de restrição. Sob certas condições, problemas de otimização\\nconvexa também são polinomialmente solucionáveis e na prática podem ser viáveis com milhares de\\nvariáveis. Vários problemas importantes no aprendizado de máquina e na teoria de controle podem\\nser formulados como problemas de otimização convexa (ver o Capítulo 20).\\n4.3 BUSCA COM AÇÕES NÃO DETERMINÍSTICAS\\nNo Capítulo 3, assumimos que o ambiente é totalmente observável e determinístico e que o agente\\nsabe quais são os efeitos de cada ação. Portanto, o agente pode calcular exatamente que estado', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 171}),\n",
       " Document(page_content='resulta de qual sequência de ações e sempre sabe em que estado está. Suas percepções não fornecem\\nnenhuma informação nova após cada ação, embora, evidentemente, informem ao agente o estado\\ninicial.\\nQuando o ambiente é parcialmente observável ou não determinístico (ou ambos), a percepção\\ntorna-se útil. Em um ambiente parcialmente observável, cada percepção ajuda a diminuir o conjunto\\nde estados possíveis onde o agente possa estar tornando assim mais fácil para o agente alcançar seus\\nobjetivos. Quando o ambiente é não determinístico, a percepção informa ao agente quais dos\\nresultados possíveis de suas ações realmente ocorreram. Em ambos os casos, a percepção futura não\\npode ser determinada com antecedência e as ações futuras do agente dependerão daquelas\\npercepções futuras. Então, a solução para um problema não é uma sequência, mas um \\nplano de\\ncontingência\\n (também conhecido como estratégia) que especifica o que fazer dependendo das\\npercepções recebidas. Nesta seção, examinamos o caso de não determinismo, deixando a\\nobservabilidade parcial para a \\nSeção 4.4\\n.\\n4.3.1 O mundo defeituoso do aspirador de pó\\nComo exemplo, utilizamos o mundo do aspirador de pó, apresentado pela primeira vez no Capítulo\\n2 e definido como um problema de busca na \\nSeção 3.2.1\\n. Lembre-se de que o espaço de estados tem\\noito estados, como mostrado na \\nFigura 4.9\\n. Há três ações — \\nEsquerda, Direita e Aspirar\\n – e o\\nobjetivo é limpar toda a sujeira (estados 7 e 8). Se o ambiente for observável, determinista e\\ncompletamente conhecido, o problema é trivialmente solucionável por qualquer um dos algoritmos\\ndo Capítulo 3 e a solução é uma sequência de ações. Por exemplo, se o estado inicial for 1, a\\nsequência de ação [\\nAspirar\\n, \\nDireita\\n, \\nEsquerda\\n] vai alcançar um estado objetivo, 8.\\nFigura 4.9\\n Os oito estados possíveis do mundo do aspirador de pó; os estados 7 e 8 são estados\\nobjetivo.\\nAgora, suponha que apresentemos o não determinismo na forma de um aspirador potente, mas\\ndefeituoso. No \\nmundo do aspirador de pó defeituoso\\n, a ação \\naspirar\\n funciona da seguinte forma:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 172}),\n",
       " Document(page_content='•  Quando aplicada a um quadrado sujo, a ação limpa o quadrado e, por vezes, limpa a sujeira do\\nquadrado adjacente, também.\\n•  Quando aplicado a um quadrado limpo, a ação por vezes deposita sujeira no carpete.\\n9\\nPara fornecer uma formulação precisa desse problema, é preciso generalizar a noção do \\nmodelo\\nde transição\\n do Capítulo 3. Em vez de definir o modelo de transição por uma função RESULTADO\\nque devolve um único estado, usaremos uma função RESULTADO que devolve um \\nconjunto\\n de\\nestados resultantes possíveis. Por exemplo, no mundo do aspirador de pó defeituoso, a ação \\nAspirar\\nno estado 1 leva a um estado no conjunto {5, 7} — a sujeira na área à direita ao lado pode ou não ser\\naspirada.\\nPrecisamos também generalizar a noção de \\nsolução\\n para o problema. Por exemplo, se começarmos\\nno estado 1, não existe uma única \\nsequência\\n de ações que resolva o problema. Em vez disso,\\nprecisaremos de um plano de contingência, como o seguinte:\\nAssim, soluções para problemas não determinísticos podem conter comandos \\nse-então-senão\\naninhados, o que significa que elas são \\nárvores\\n, e não sequências. Isso permite a seleção de ações\\ncom base nas contingências que surgem durante a execução. Muitos problemas no mundo real físico\\nsão problemas de contingência, pois a previsão exata é impossível. Por essa razão, muitas pessoas\\nmantêm os olhos bem abertos quando caminham ou dirigem.\\n4.3.2 Árvores de busca E-OU\\nA próxima pergunta é como encontrar soluções para os problemas contingentes não\\ndeterminísticos. Como no Capítulo 3, começamos com a construção de árvores de busca, mas aqui as\\nárvores têm um caráter diferente. Em um ambiente determinístico, a única ramificação é apresentada\\npelas próprias escolhas do agente em cada estado. Chamamos esses nós de \\nnós OU\\n. No mundo do\\naspirador de pó, por exemplo, em um nó OU o agente escolhe \\nEsquerda ou Direita ou Aspirar\\n. Em\\num ambiente não determinístico, a ramificação é também apresentada pela escolha do resultado do\\nambiente\\n para cada ação. Chamamos esses nós de \\nnós E\\n. Por exemplo, a ação \\nAspirar\\n no estado 1\\nleva a um estado no conjunto {5, 7}, então o agente deverá encontrar um plano para o estado 5 \\ne\\n para\\no estado 7. Esses dois tipos de nós alternados levam a uma \\nárvore\\n E-OU, conforme ilustrado na\\nFigura 4.10\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 173}),\n",
       " Document(page_content='Figura 4.10\\n Os dois primeiros níveis da árvore de busca para o mundo do aspirador de pó\\ndefeituoso. Os nós de estado são os nós OU onde deve ser escolhida alguma ação. Todos os\\nresultados deverão ser tratados nos nós E, mostrados como círculos, como indicado pelo arco\\nligando os ramos de saída. A solução encontrada é mostrada nas linhas em negrito.\\nUma solução para um problema de busca E-OU é uma subárvore que (1) tenha um nó objetivo em\\ncada folha, (2) especifique uma ação em cada um de seus nós OU e (3) inclua todos os ramos\\nresultantes em cada um de seus nós E. A solução é apresentada nas linhas em negrito da figura, que\\ncorrespondem ao plano dado na Equação 4.3. (O plano usa a notação se-então-senão para tratar com\\nos ramos E, mas quando há mais de dois ramos em um nó pode ser melhor utilizar o comando \\ncase\\n.)\\nÉ simples modificar o agente de resolução de problemas básicos mostrado na \\nFigura 3.1\\n para\\nexecutar soluções de contingência desse tipo. Pode-se considerar também um projeto de agente um\\npouco diferente, em que o agente pode agir \\nantes\\n que encontre um plano garantido e trate com\\nalgumas contingências apenas à medida que surjam durante a execução. Esse tipo de \\nintercalação\\n de\\nbusca e execução também é útil para problemas de exploração (ver a \\nSeção 4.5\\n) e para jogos (ver o\\nCapítulo 5).\\nA \\nFigura 4.11\\n fornece um algoritmo recursivo em profundidade para busca em grafos E-OU. Um\\naspecto-chave dos algoritmos é a maneira pela qual ele trata com os ciclos, que surgem\\nfrequentemente em problemas não determinísticos (por exemplo, se uma ação, algumas vezes, não\\ntiver efeito ou se um efeito não intencional puder ser corrigido). Se o estado atual for idêntico a um\\nestado no caminho da raiz, ele devolve falha. Isso não significa que \\nnão\\n haja solução a partir do\\nestado atual, mas significa simplesmente que, se \\nexiste\\n uma solução não cíclica, ela deve ser\\nacessível a partir da recursão anterior do estado atual, por isso a nova recursão poderá ser\\ndescartada. Com essa verificação, podemos garantir que o algoritmo termina em todo espaço de\\nestado finito porque cada caminho deve atingir um objetivo, um beco sem saída ou um estado', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 174}),\n",
       " Document(page_content='repetido. Observe que o algoritmo não verifica se o estado atual é uma repetição de um estado em\\nalgum \\noutro\\n caminho a partir da raiz, o que é importante para a eficiência do Exercício 4.5, ao\\ninvestigar essa questão.\\nfunção BUSCA-EM-GRAFOS-E\\n-OU(\\nproblema\\n) \\nretorna um\\n \\nplano condicional ou falha\\n    \\nBUSCA-OU\\n(\\nproblema\\n.Estado-Inicial, \\nproblem\\n, [ ])\\n_____________________________________________________________________________________________________________\\nfunção BUSCA-OU\\n(\\nestado, problema, caminho\\n) \\nretorna um\\n \\nplano condicional ou falha\\n    \\nse\\n \\nproblema\\n.TESTE-OBJETIVO(\\nestado\\n) \\nentão retorna o\\n plano vazio\\n    \\nse\\n \\nestado\\n estiver \\nno caminho\\n \\nentão retorna\\n \\nfalha\\n    \\npara cada ação no\\n \\nproblema\\n.AÇÕES(\\nestado\\n) \\nfaça\\n        plano ← BUSCA-E(RESULTADO(\\nestado, ação\\n), \\nproblema\\n, [\\nestado\\n | \\ncaminho\\n])\\n        \\nse plano\\n \\n≠\\n \\nfalha\\n \\nentão retorna\\n [\\nação\\n | \\nplano\\n]\\nretorna\\n \\nfalha\\n_____________________________________________________________________________________________________________\\nfunção BUSCA-E\\n (\\nestados, problema, caminho\\n) \\nretorna um\\n \\nplano condicional ou falha\\n    \\npara cada\\n \\nsi\\n \\nem e\\nstados \\nfaça\\n        plano\\ni\\n ← BUSCA-OU(\\ns\\ni\\n, problema, caminho)\\n    \\nse o\\n \\nplano\\ni\\n ← \\nfalha\\n \\nentão retorna\\n \\nfalha\\n    \\nretorna\\n [\\nse\\n \\ns\\n1\\n \\nentão\\n \\nplano\\n1\\n \\nsenão se\\n \\ns\\n2\\n \\nentão\\n \\nplano\\n2\\n \\nsenão\\n . . . \\nse\\n \\ns\\nn−1\\n \\nentão\\n \\nplano\\nn−1\\n \\nsenão\\n \\nplano\\nFigura 4.11\\n Um algoritmo de busca em grafos E-OU gerado em ambientes não determinísticos.\\nRetorna um plano condicional que atinge um estado objetivo em todas as circunstâncias. (A notação\\n[\\nx | l\\n] refere-se à lista formada pela adição do objeto \\nx\\n à frente da lista \\nl\\n.)\\nOs grafos E-OU podem também ser exploradas por métodos de busca em largura ou da melhor\\nescolha. O conceito de função heurística deve ser modificado para estimar o custo de uma solução de\\ncontingência, em vez de em sequência, mas a noção de admissibilidade transfere para depois e existe\\numa analogia do algoritmo A* para encontrar soluções ótimas. Nas notas bibliográficas, ao final do\\ncapítulo, são dadas indicações.\\n4.3.3 Tente, tente novamente\\nConsidere o mundo do aspirador de pó com incerteza, que é idêntico ao mundo comum (sem\\ndefeitos) do aspirador de pó, exceto que as ações de movimento, por vezes falham, deixando o agente\\nno mesmo local. Por exemplo, mover para a \\nDireita\\n no estado 1 leva para o conjunto do estado\\n{1,2}. A \\nFigura 4.12\\n mostra parte da busca em grafos; não há explicitamente mais nenhuma solução\\nacíclica do estado 1, e a BUSCA-EM-GRAFOS-E-OU devolveria falha. Há, no entanto, uma \\nsolução\\ncíclica\\n, que é continuar tentando para a \\nDireita\\n até que funcione. Podemos expressar essa solução\\npela adição de um \\nrótulo\\n para denotar uma parte do plano e usar esse rótulo mais tarde, em vez de\\nrepetir o plano em si. Assim, nossa solução cíclica é', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 175}),\n",
       " Document(page_content='Figura 4.12\\n Parte da busca em grafos para o mundo do aspirador de pó com incerteza, onde\\nmostramos (alguns) ciclos explicitamente. Todas as soluções para esse problema são planos cíclicos\\nporque não há nenhuma maneira de mover-se de forma confiável.\\n[\\nAspirar\\n \\nL\\n1\\n,: \\nDireita\\n, \\nse\\n \\nEstado\\n = 5, \\nentão\\n \\nL\\n1\\n \\nsenã\\no \\nAspirar\\n].\\n(A melhor sintaxe para a parte do laço desse plano seria “\\nenquanto\\n \\nestado\\n = 5 \\nfaça\\n \\nDireita\\n”.) Em\\ngeral, um plano cíclico pode ser considerado uma solução, desde que cada folha seja um estado\\nobjetivo e que uma folha seja acessível de cada ponto no plano. O Exercício 4.6 cobre as\\nmodificações necessárias para a BUSCA-EM-GRAFOS-E-OU. A compreensão fundamental é que\\num laço no espaço de estados que volta a um estado \\nL\\n é refletido em um laço no plano que volta ao\\nponto onde o subplano de estado \\nL\\n é executado.\\nDada a definição de uma solução cíclica, um agente que executa tal solução eventualmente\\nalcançará o objetivo, \\ndesde que cada resultado de uma ação não determinística ocorra\\neventualmente\\n. Essa condição é razoável? Depende do motivo para o não determinismo. Se a ação\\njogar um dado, então é razoável supor que pode eventualmente resultar um seis. Se a ação for inserir\\num cartão de chave de hotel na fechadura da porta, mas não funcionar na primeira vez, talvez\\nfuncione eventualmente ou talvez seja a chave errada (ou o quarto errado!). Depois de sete ou oito\\ntentativas, a maioria das pessoas vai assumir que o problema é com a chave e vai voltar para a\\nrecepção para pedir uma nova. Uma maneira de entender essa decisão é dizer que a formulação do\\nproblema inicial (observável, não determinístico) foi abandonada em favor de uma formulação\\ndiferente (parcialmente observável, determinístico), onde a falha é atribuída a uma propriedade não\\nobservável da chave. Essa questão será abordada novamente no Capítulo 13.\\n4.4 PESQUISANDO COM OBSERVAÇÕES PARCIAIS\\nPassaremos agora ao problema de observabilidade parcial, onde a percepção do agente não é\\nsuficiente para definir o estado exato. Como observado no início da seção anterior, se o agente\\nestiver em um dos vários estados possíveis, uma ação pode levar a um dos diversos tipos de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 176}),\n",
       " Document(page_content='resultados possíveis — \\nmesmo se o ambiente for determinístico\\n. O conceito fundamental necessário\\npara resolver problemas parcialmente observáveis é o \\nestado de crença\\n, que representa a crença\\natual do agente sobre os possíveis estados físicos em que poderia estar, dada a sequência de ações e\\npercepções até aquele ponto. Começaremos com o cenário mais simples para o estudo dos estados de\\ncrença, que é quando o agente não tem sensores; então adicionamos um sensoriamento parcial, bem\\ncomo ações não determinísticas.\\n4.4.1 Pesquisar sem observação\\nQuando as percepções do agente \\nnão fornecem nenhuma informação,\\n temos o que chamamos\\nproblema \\nsem sensoriamento\\n ou, algumas vezes, problema \\nconformante\\n. Num primeiro momento,\\npode-se pensar que o agente sem sensoriamento não tem esperança de resolver um problema se não\\ntiver ideia do estado em que ele está; de fato, problemas sem sensoriamento são muitas vezes\\nsolúveis. Além disso, os agentes sem sensoriamento podem ser surpreendentemente úteis,\\nprincipalmente porque eles \\nnão\\n dependem de sensores funcionando corretamente. Em sistemas de\\nmanufatura, por exemplo, foram desenvolvidos muitos métodos engenhosos para orientar\\ncorretamente as peças a partir de uma posição inicial desconhecida usando uma sequência de ações\\ncompletamente sem atividade sensorial. O alto custo da atividade sensorial é outra razão para evitá-\\nla: por exemplo, os médicos geralmente prescrevem um antibiótico de amplo espectro em vez de usar\\no plano de contingência de fazer um exame de sangue caro, ficar à espera dos resultados e então\\nprescrever um antibiótico mais específico e talvez também a hospitalização devido à progressão da\\ninfecção.\\nPodemos também fazer uma versão sem sensoriamento do mundo do aspirador de pó. Suponha que\\no agente conheça a geografia do seu mundo, mas não conheça a localização ou a distribuição da\\nsujeira. Nesse caso, seu estado inicial poderia ser qualquer elemento do conjunto {1, 2, 3, 4, 5, 6, 7,\\n8}. Agora, considere o que acontece se tentar a ação \\nDireita.\\n Isso fará com que ele fique em um dos\\nestados {2, 4, 6, 8} — o agente agora tem mais informações! Além disso, a sequência de ação\\n[\\nDireita, Aspira\\n] sempre vai acabar em um dos estados {4, 8}. Finalmente, a sequência [\\nDireita\\n,\\nAspira\\n, \\nEsquerda\\n, \\nAspira\\n] é a garantia de que atingirá o estado objetivo 7, não importa qual seja o\\nestado de início. Dizemos que o agente pode \\ncoagir\\n o mundo para estado 7.\\nPara resolver problemas sem sensoriamento, buscamos no espaço do estado de crença em vez de\\nno estado físico.\\n10\\n Observe que, no espaço do estado de crença, o problema é \\ntotalmente observável\\nporque o agente sempre conhece o seu próprio estado de crença. Além disso, a solução (se houver) é\\nsempre uma sequência de ações. Isso porque, como nos problemas comuns do Capítulo 3, as\\npercepções recebidas após cada ação são completamente previsíveis — são sempre vazias! Portanto,\\nnão há contingências para planejar. Isso é verdadeiro \\nmesmo se o ambiente for não determinístico.\\nÉ instrutivo ver como é construído o problema de busca de estado de crença. Suponha que o\\nproblema físico subjacente \\nP\\n seja definido por AÇÕES\\nP\\n, RESULTADO\\nP\\n, TESTAR-OBJETIVO\\nP\\n e\\nCusto do passo\\nP\\n. Então, podemos definir o problema sem sensoriamento correspondente da seguinte\\nforma:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 177}),\n",
       " Document(page_content='•  \\nEstados de crença\\n: O espaço de estado de crença inteiro contém cada conjunto possível de\\nestados físicos. Se \\nP\\n tiver \\nN\\n estados, então o problema sem sensoriamento terá até 2\\nn\\n estados,\\nembora muitos possam estar inacessíveis a partir do estado inicial.\\n•  \\nEstado inicial\\n: Normalmente, o conjunto de todos os estados em \\nP\\n, embora em alguns casos o\\nagente tenha mais conhecimento do que isso.\\n•  \\nAções\\n: Isso é um pouco complicado. Suponha que o agente esteja no estado de crença \\nb\\n = {\\ns\\n1\\n,\\ns\\n2\\n}, mas as AÇÕES\\nP\\n (\\ns\\n1\\n) ≠ AÇÕES\\nP\\n (\\ns\\n2\\n); então, o agente não tem certeza de quais ações são\\naplicáveis. Se assumirmos que as ações não aplicáveis não têm nenhum efeito sobre o meio\\nambiente, então é seguro considerar a \\nunião\\n de todas as ações em qualquer dos estados físicos\\nno estado de crença atual \\nb\\n:\\nPor outro lado, se uma ação não aplicável pode ser o fim do mundo, é mais seguro permitir\\napenas a \\ninterseção\\n, isto é, o conjunto de ações aplicáveis em \\ntodos\\n os estados. Para o mundo\\ndo aspirador de pó, cada estado tem as mesmas ações aplicáveis; assim, ambos os métodos dão\\no mesmo resultado.\\n•  \\nModelo de transição\\n: O agente não sabe qual estado no estado de crença é o correto, por isso,\\nele só sabe que pode chegar a qualquer um dos estados resultantes da aplicação da ação para um\\ndos estados físicos no estado de crença. Para ações determinísticas, o conjunto de estados que\\npode ser alcançado é\\nCom ações determinísticas, \\nb\\n′ nunca será maior do que \\nb\\n. Com não determinísticas, temos\\nque pode ser maior do que \\nb\\n, como mostrado na \\nFigura 4.13\\n. O processo de geração de um novo\\nestado de crença após a ação é chamado de etapa de \\npredição\\n; a notação \\nb\\n′ = PREDIÇÃO\\nP\\n(\\nb, a\\n)\\né mais apropriada.\\n•  \\nTestar objetivo\\n: O agente quer um plano que é certo que funcione, o que significa que um estado\\nde crença satisfaz o objetivo somente se \\ntodos\\n os estados físicos nele satisfizerem TESTE-\\nOBJETIVO\\nP\\n. O agente poderá atingir \\nacidentalmente\\n o objetivo antes, mas não saberá que fez\\nisso.\\n•  \\nCusto do passo\\n: Esse é também complicado. Se a mesma ação pode ter custos diferentes em\\ndiferentes estados, então o custo de tomar uma ação em um dado estado de crença pode ser um\\nde vários valores (isso dá origem a uma nova classe de problemas, que vamos explorar no\\nExercício 4.9). Por ora assumimos que o custo de uma ação é o mesmo em todos os estados e por\\nisso pode ser transferido diretamente do problema físico subjacente.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 178}),\n",
       " Document(page_content='Figura 4.13\\n (a) Previsão do próximo estado de crença para o mundo do aspirador de pó sem\\nsensoriamento com uma ação determinística, \\nDireita\\n. (b) Previsão para o mesmo estado de crença e\\nação na versão incerta do mundo do aspirador de pó sem sensoriamento.\\nA \\nFigura 4.14\\n mostra o espaço de estado de crença acessível para o mundo do aspirador de pó\\ndeterminístico, sem sensoriamento. Existem apenas 12 estados de crença acessíveis de 2\\n8\\n = 256\\nestados de crença possíveis.\\nFigura 4.14\\n A porção acessível do espaço de estado de crença para o mundo determinístico do\\naspirador de pó, sem sensoriamento. Cada caixa sombreada corresponde a um estado de crença\\nindividual. Em um passo qualquer, o agente está em um estado de crença particular, mas não sabe em\\nque estado físico está. O estado de crença inicial (completa ignorância) é a caixa central superior. As\\nações são representadas pelas ligações rotuladas. Para maior clareza, os laços para um mesmo\\nestado de crença são omitidos.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 179}),\n",
       " Document(page_content='As definições anteriores permitem a construção automática da formulação do problema de estado\\nde crença a partir da definição do problema físico subjacente. Uma vez feito isso, podemos aplicar\\nqualquer um dos algoritmos de busca do Capítulo 3. Na verdade, podemos fazer um pouco mais do\\nque isso. Na busca em grafos “comum”, os estados recentemente gerados são testados para verificar\\nse são idênticos aos estados existentes. Isso funciona também para os estados de crença; por\\nexemplo, na \\nFigura 4.14\\n, a sequência de ação [\\nAspirar\\n, \\nEsquerda\\n, \\nAspirar\\n] inicia quando o estado\\ninicial atinge o mesmo estado de crença [\\nDireita\\n, \\nEsquerda\\n, \\nAspirar\\n], ou seja, {5, 7}. Agora,\\nconsidere o estado de crença alcançado por [\\nEsquerda\\n], ou seja, {1, 3, 5, 7}. Obviamente, não é\\nidêntico a {5, 7}, mas é um \\nsuperconjunto\\n. É fácil provar (Exercício 4.8) que, se uma sequência de\\nação é uma solução para um estado de crença \\nb\\n, é também uma solução para qualquer subconjunto de\\nb\\n. Assim, podemos descartar alcançar um caminho {1, 3, 5, 7} se {5, 7} já foi gerado. Por outro\\nlado, se {1, 3, 5, 7} já foi gerado e verificado que é solucionável, é garantido que qualquer\\nsubconjunto,\\n como {5, 7}, é solucionável. Esse nível extra de poda pode melhorar drasticamente a\\neficiência da resolução do problema sem sensoriamento.\\nNo entanto, mesmo com essa melhora, a resolução do problema sem sensoriamento como descrito,\\nraramente é viável na prática. A dificuldade não é tanto a vastidão do espaço do estado de crença —\\nmesmo sendo exponencialmente maior do que o espaço de estado físico subjacente; na maioria dos\\ncasos, o fator de ramificação e a extensão da solução no espaço do estado de crença e no espaço do\\nestado físico não são tão diferentes. A verdadeira dificuldade reside no tamanho de cada estado de\\ncrença. Por exemplo, o estado de crença inicial para o mundo do aspirador de pó 10 × 10 contém\\n100 × 2\\n100\\n ou cerca de 10\\n32\\n estados físicos — é demasiado se utilizarmos a representação atômica,\\nque é uma lista explícita de estados.\\nUma solução é utilizar alguma descrição mais compacta para representar o estado de crença. Em\\nportuguês, poderíamos dizer que o agente não sabe “nada” no estado inicial; após mover-se para a\\nEsquerda\\n, poderíamos dizer “Não está na coluna mais à direita”, e assim por diante. O Capítulo 7\\nexplica como fazer isso em um esquema de representação formal. Outra abordagem é evitar os\\nalgoritmos de busca-padrão, que tratam o estado de crença como caixas-pretas, tal como qualquer\\noutro problema de estado. Em vez disso, podemos olhar no \\ninterior\\n dos estados de crença e\\ndesenvolver algoritmos de \\nbusca de estado de crença incremental\\n que constroem a solução de um\\nestado físico de cada vez. Por exemplo, no mundo do aspirador de pó sem sensoriamento, o estado\\nde crença inicial é {1, 2, 3, 4, 5, 6, 7, 8} e temos que encontrar uma sequência de ação que funcione\\nem todos os oito estados. Podemos fazer isso encontrando primeiro uma solução que funcione para o\\nestado 1; então verificamos se funciona para o estado 2; senão, voltamos e encontramos uma solução\\ndiferente para o estado 1, e assim por diante. Como uma busca E-OU tem que encontrar uma solução\\npara todos os ramos de um nó E, esse algoritmo tem que encontrar uma solução para cada estado no\\nestado de crença; a diferença é que a busca E-OU pode encontrar uma solução diferente para cada\\nramo, enquanto uma busca de estado de crença incremental tem que encontrar \\numa\\n solução que\\nfuncione para \\ntodos\\n os estados.\\nA principal vantagem da abordagem incremental é que normalmente é capaz de detectar a falha\\nrapidamente — quando um estado de crença é insolúvel, geralmente é o caso dos primeiros estados\\nexaminados que consistem de um pequeno subconjunto do estado de crença, também é insolúvel. Em\\nalguns casos, isso leva a um aumento de velocidade proporcional ao tamanho dos estados de crença,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 180}),\n",
       " Document(page_content='que poderá ser tão grande quanto o espaço de estado físico em si.\\nMesmo o algoritmo de solução mais eficiente não é de muita utilidade quando não existem\\nsoluções. Muitas coisas simplesmente não podem ser feitas sem atividade sensorial. Por exemplo, o\\nquebra-cabeça de oito peças sem sensoriamento é impossível. Por outro lado, um pouco de atividade\\nsensorial pode contribuir bastante. Por exemplo, cada instância do quebra-cabeça de oito peças pode\\nser resolvido se apenas uma área for perceptível — a solução envolve mover cada peça, por vez,\\npara um local perceptível e, então, se manter atualizado da sua localização de acordo com as ações\\ntomadas.\\n4.4.2 Busca com observações\\nPara um problema geral parcialmente observável, temos que especificar como o ambiente gera\\npercepções para o agente. Por exemplo, poderíamos definir a atividade sensorial local do mundo do\\naspirador de pó como sendo aquela em que o agente tem um sensor de posição e um sensor de sujeira\\nlocal, mas não tem um sensor capaz de detectar a sujeira em outros quadrados. A especificação do\\nproblema formal inclui uma função PERCEPÇÃO(\\ns\\n) que devolva a percepção recebida em um\\ndeterminado estado (se a atividade sensorial for não determinística, então usamos uma função\\nPERCEPÇÃO que devolva um conjunto de percepções possíveis). Por exemplo, na atividade\\nsensorial local do mundo do aspirador de pó, a PERCEPÇÃO no estado 1 é [\\nA\\n, \\nSujo\\n]. Problemas\\ntotalmente observáveis são um caso especial em que a PERCEPÇÃO(\\ns\\n) = \\ns\\n para cada estado \\ns\\n,\\nenquanto os problemas sem sensoriamento são um caso especial em que a PERCEPÇÃO(\\ns\\n) = \\nnulo\\n.\\nQuando as observações são parciais, normalmente é o caso em que vários estados podem produzir\\nqualquer percepção determinada. Por exemplo, a percepção [\\nA\\n, \\nSujo\\n] é produzida pelo estado 3, bem\\ncomo pelo estado 1. Assim, sendo essa a percepção inicial, o estado de crença inicial para a\\natividade sensorial local do mundo do aspirador de pó será {1, 3}. As AÇÕES, CUSTO-DO-PASSO\\ne TESTE-OBJETIVO são construídas a partir do problema físico subjacente, assim como os\\nproblemas sem sensoriamento, mas o modelo de transição é um pouco mais complicado. Podemos\\npensar em transições de um estado de crença para o próximo de uma determinada ação como\\nocorrendo em três etapas, conforme mostra a \\nFigura 4.15\\n:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 181}),\n",
       " Document(page_content='Figure 4.15\\n Dois exemplos de transições dos mundos do aspirador de pó com sensoriamento local.\\n(a) No mundo determinístico, \\nDireita\\n é aplicada no estado de crença inicial, resultando em um\\nestado de crença novo com dois estados físicos possíveis; para aqueles estados, as pecepções\\npossíveis são [\\nB\\n, \\nSujo\\n] e [\\nB\\n, \\nLimpo\\n], levando a dois estados de crença, cada um dos quais unitário.\\n(b) No mundo com observação local de sujeira, \\nDireita\\n é aplicada no estado de crença inicial,\\noriginando um novo estado de crença com quatro estados físicos; para aqueles estados, as\\npercepções possíveis são [\\nA\\n, \\nSujo\\n], [\\nB\\n, \\nSujo\\n], e [\\nB\\n, \\nLimpo\\n], levando a três estados de crença,\\nconforme mostrado.\\n•  A fase de \\nprevisão\\n é a mesma dos problemas sem sensoriamento: dada uma ação \\na\\n no estado de\\ncrença \\nb\\n, o estado de crença previsto é \\n11\\n•  A fase de \\nprevisão de observação\\n determina o conjunto de percepções \\no\\n que poderia ser\\nobservado no estado de crença previsto:\\n•  A fase de \\natualização\\n determina, para cada percepção possível, o estado de crença que\\nresultaria da percepção. O novo estado de crença \\nb\\no\\n é apenas o conjunto de estados em \\n que\\npoderia ter produzido a percepção:\\nObserve que cada estado de crença \\nb\\no\\n atualizado não pode ser maior do que o estado de crença\\nprevisto \\n; as observações podem apenas ajudar a reduzir a incerteza comparado ao caso sem\\nsensoriamento. Ademais, para o sensoriamento determinístico, os estados de crença para as', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 182}),\n",
       " Document(page_content='diferentes percepções possíveis serão disjuntos, formando uma \\npartição\\n do estado de crença original\\nprevisto.\\nColocando esses três estágios juntos, obtemos os estados de crença possíveis resultantes de\\ndeterminada ação e as percepções subsequentes possíveis:\\nNovamente, o não determinismo do problema parcialmente observável vem da incapacidade de\\npredizer exatamente que percepções serão recebidas após a ação; o não determinismo subjacente no\\nambiente físico pode \\ncontribuir\\n para essa incapacidade, ampliando o estado de crença na fase da\\npredição, levando a mais percepções no estágio de observação.\\n4.4.3 Resolvendo problemas parcialmente observáveis\\nA seção anterior mostrou como derivar a função RESULTADOS para um problema de estado de\\ncrença não determinístico de um problema físico subjacente e a função PERCEPÇÃO. Dada tal\\nformulação, o algoritmo de busca E-OU da \\nFigura 4.11\\n pode ser aplicado diretamente para obter uma\\nsolução. A \\nFigura 4.16\\n mostra parte da árvore de busca para o mundo do aspirador de pó de\\nsensoriamento local, assumindo uma percepção inicial [\\nA\\n, \\nSujo\\n]. A solução é o plano condicional\\nFigura 4.16\\n O primeiro nível da árvore de busca E-OU de um problema do mundo do aspirador de\\npó de sensoriamento local; \\nAspirar\\n é o primeiro passo da solução.\\nObserve que, por termos fornecido um problema de estado de crença para o algoritmo de busca E-\\nOU, ele devolveu um plano condicional que testa o estado de crença em vez do estado real. Deveria\\nser assim mesmo: em um ambiente parcialmente observável, o agente não será capaz de executar uma\\nsolução que requeira testar o estado real.\\nComo no caso dos algoritmos de busca-padrão aplicados a problemas sem sensoriamento, o\\nalgoritmo de busca E-OU trata os estados de crença como caixas-pretas, assim como quaisquer', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 183}),\n",
       " Document(page_content='outros estados. Pode-se melhorar essa situação verificando os estados de crença gerados\\nanteriormente que são subconjuntos ou superconjuntos do estado atual, assim como os problemas sem\\nsensoriamento. Pode-se também derivar algoritmos de busca incremental, análogos àqueles descritos\\npara problemas sem sensoriamento, que fornecem avanço substancial sobre a abordagem da caixa-\\npreta.\\n4.4.4 Um agente para ambientes parcialmente observáveis\\nO projeto de um agente de resolução de problema para ambientes parcialmente observáveis é\\nbastante semelhante ao do agente de resolução de problemas simples da \\nFigura 3.1\\n: o agente formula\\num problema, chama um algoritmo de busca (como o de BUSCAE-EM-GRAFOS-E-OU) para\\nresolvê-lo e executa a solução. Há duas diferenças principais. Primeiro, a solução para um problema\\nserá um plano condicional, em vez de uma sequência; se o primeiro passo for uma expressão \\nse-\\nentão-senão\\n, o agente terá que testar a condição da parte \\nse\\n e executar a parte \\nentão\\n ou a parte \\nsenão\\nconforme o caso. Segundo, o agente terá que manter o seu estado de crença, enquanto executa ações e\\nrecebe percepções. Esse processo se assemelha ao processo de atualização da previsão de\\nobservação da Equação 4.5, mas na verdade é mais simples porque a percepção é dada pelo\\nambiente, e não calculada pelo agente. Dado um estado de crença inicial \\nb\\n, uma ação \\na\\n e uma\\npercepção \\no\\n, o novo estado de crença será:\\nA \\nFigura 4.17\\n mostra o estado de crença sendo mantido no mundo do aspirador de pó do \\njardim de\\ninfância\\n com sensoriamento local, onde qualquer área pode ficar suja, a qualquer momento, a menos\\nque o agente esteja naquele momento limpando-a ativamente.\\n12\\nFigura 4.17\\n Dois ciclos de previsão-atualização da manutenção do estado de crença do mundo do\\naspirador de pó de um jardim de infância com sensoriamento local.\\nEm ambientes parcialmente observáveis, que incluem a grande maioria dos ambientes do mundo\\nreal, manter um estado de crença é uma função essencial de qualquer sistema inteligente. Essa função\\npossui vários nomes, incluindo \\nmonitoramento\\n, \\nfiltragem\\n e \\nestimativa de estado\\n. A Equação 4.6 é\\nchamada de \\nestimador de estado\\n \\nrecursivo\\n porque calcula o estado da nova crença a partir da\\nanterior em vez de examinar a sequência inteira de percepção. Se o agente não “ficar para trás”, o\\ncálculo tem que acontecer tão rápido quanto as percepções estão acontecendo. Na medida que o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 184}),\n",
       " Document(page_content='ambiente se torna mais complexo, o cálculo da atualização exata se torna inviável, e o agente terá que\\ncalcular um estado de crença aproximado, talvez enfocando as implicações da percepção dos\\naspectos do ambiente que são de interesse atual. A maioria dos trabalhos sobre esse problema tem\\nsido feita para ambientes de estado contínuo e estocásticos com as ferramentas da teoria da\\nprobabilidade, conforme será explicado no Capítulo 15. Aqui vamos mostrar um exemplo em\\nambiente discreto com sensores determinísticos e ações não determinísticas.\\nO exemplo diz respeito a um robô com a tarefa de \\nlocalização\\n, resolvendo o problema onde\\nestiver, dado um mapa do mundo e uma sequência de percepções e ações. Nosso robô será colocado\\nno ambiente de labirinto da \\nFigura 4.18\\n. O robô é equipado com quatro sonares sonar que informam a\\nexistência de um obstáculo, a parede exterior ou um quadrado preto na figura — em cada uma das\\nquatro direções da bússola. Assumimos que os sensores fornecem dados perfeitamente corretos e que\\no robô tem um mapa correto do ambiente. Mas, infelizmente, o sistema de navegação do robô está\\nquebrado; então, quando ele executa uma ação de \\nmovimento\\n, move-se aleatoriamente a um dos\\nquadrados adjacentes. A tarefa do robô é determinar a sua localização atual.\\nFigure 4.18\\n Posições possíveis do robô, \\n, (a), após uma observação \\nE\\n1\\n= \\nNSO\\n e (b) após uma\\nsegunda observação \\nE\\n2\\n = \\nNS\\n. Quando os sensores precisos (sem ruído) e o modelo de transição é\\npreciso, não existem outras localizações possíveis para o robô de acordo com essa sequência de\\nduas observações.\\nSuponha que o robô acabe de ser ligado, por isso não sabe onde está. Assim, sua crença de estado\\ninicial \\nb\\n consiste no conjunto de todas as localidades. O robô recebe a percepção \\nNSO\\n, o que\\nsignifica que existem obstáculos ao norte, oeste e sul, e faz uma atualização utilizando a equação \\nb\\no\\n =\\nATUALIZAÇÃO(\\nb\\n), gerando as quatro localizações mostradas na \\nFigura 4.18\\n(a). Você pode\\ninspecionar o labirinto para verificar que aquelas são as únicas quatro localizações que produzem a\\npercepção \\nNSO\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 185}),\n",
       " Document(page_content='Em seguida, o robô executa uma ação de \\nmovimento\\n, mas o resultado é não determinístico. A nova\\ncrença de estado, \\nb\\na\\n = PREDIÇÃO(\\nb\\no\\n, \\nMove\\n), contém todos os locais que estão a um passo dos\\nlocais em \\nb\\no\\n. Quando a segunda percepção, \\nNS\\n, chega, o robô ATUALIZA(\\nb\\na\\n, \\nNS\\n) e descobre que o\\nestado de crença foi reduzida a uma única localização mostrada na \\nFigura 4.18\\n(b). Essa é a única\\nlocalização que poderia ser o resultado de\\nCom ações não deterministícas, a etapa PREDIÇÃO aumenta o estado de crença, mas a etapa\\nATUALIZAÇÃO novamente o reduz na medida em que a percepção fornece alguma informação útil\\nde identificação. Às vezes, a percepção não ajuda muito para a localização: se houver um ou mais\\ncorredores longos leste-oeste, um robô poderá receber uma longa sequência de percepções \\nNS\\n, mas\\nnunca saberá em que corredor está.\\n4.5 AGENTES DE BUSCA ON-LINE EM AMBIENTES DESCONHECIDOS\\nAté agora nos concentramos em agentes que utilizam algoritmos de \\nbusca off-line\\n. Eles calculam\\numa solução completa antes de entrar no mundo real e depois executam a solução sem recorrer a suas\\npercepções. Em contraste, um agente de \\nbusca on-line\\n13\\n \\nintercala\\n computação e ação: primeiro, ele\\nexecuta uma ação, depois observa o ambiente e calcula a próxima ação. A busca on-line é uma boa\\nideia em domínios dinâmicos ou semidinâmicos — domínios em que existe uma penalidade por\\ncontinuar calculando durante muito tempo. A busca on-line é também útil em domínios não\\ndeterminísticos porque permite que o agente concentre seus esforços computacionais sobre as\\ncontingências que realmente surgem em vez das que \\npoderiam\\n acontecer, mas provavelmente não\\nocorrerão. Claro, há uma compensação: quanto mais um agente planejar o futuro, menos vezes irá\\nencontrar-se em uma posição difícil.\\nA busca on-line é uma ideia \\nnecessária\\n para ambientes desconhecidos, onde o agente não conhece\\nquais estados existem ou o que suas ações fazem. Nesse estado de ignorância, o agente enfrenta um\\nproblema de exploração\\n e deve usar suas ações como experimentos, a fim de aprender o suficiente\\npara fazer a deliberação (predição e atualização) valer a pena.\\nO exemplo canônico de busca on-line é um robô colocado em um novo edifício e que tem de\\nexplorá-lo para elaborar um mapa que possa ser usado com a finalidade de ir de \\nA\\n até \\nB\\n. Os métodos\\npara escapar de labirintos — um conhecimento exigido dos ambiciosos aspirantes a heróis da\\nantiguidade — também são exemplos de algoritmos de busca on-line. No entanto, a exploração\\nespacial não é a única forma de exploração. Considere um bebê recém-nascido: ele tem muitas ações\\npossíveis, mas não conhece os resultados de nenhuma delas e só experimentou alguns dos estados\\nque tem possibilidade de alcançar. A descoberta gradual do bebê de como o mundo funciona é, em\\nparte, um processo de busca on-line.\\n4.5.1 Problemas de busca on-line', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 186}),\n",
       " Document(page_content='Um problema de busca on-line só pode ser resolvido por um agente que executa ações, e não por\\ncomputação pura. Assumiremos um ambiente determinístico e inteiramente observável (o Capítulo 17\\nfaz o relaxamento dessas suposições), mas estipularemos que o agente sabe apenas o seguinte:\\n•  AÇÕES(\\ns\\n), que devolve uma lista de ações permitidas no estado \\ns\\n.\\n•  A função de custo do passo \\nc\\n(\\ns\\n, \\na\\n, \\ns\\n′) — observe que isso não pode ser usado enquanto o agente\\nnão souber que \\ns\\n′ é o resultado da ação e em \\ns\\n.\\n•  TESTAR-OBJETIVO(\\ns\\n).\\nEm particular, observe que o agente \\nnão pode\\n determinar o RESULTADO(\\ns\\n, \\na\\n), exceto estando\\nrealmente em \\ns\\n e fazendo \\na\\n. Por exemplo, no problema de labirinto mostrado na \\nFigura 4.19\\n, o agente\\nnão sabe que ir \\nPara cima\\n a partir de (1,1) leva a (1,2); nem sabe, tendo feito isso, que ir \\nPara baixo\\no levará de volta a (1,1). Esse grau de ignorância pode ser reduzido em algumas aplicações — por\\nexemplo, um robô explorador poderia saber como suas ações de movimentação funcionam e ser\\nignorante apenas sobre as posições dos obstáculos.\\nFigura 4.19\\n Um problema simples de labirinto. O agente inicia em \\nS\\n e deve chegar a \\nG\\n, mas nada\\nsabe sobre o ambiente.\\nFinalmente, o agente poderia ter acesso a uma função heurística admissível \\nh\\n(\\ns\\n) que avalia a\\ndistância desde o estado atual até um estado objetivo. Por exemplo, na \\nFigura 4.19\\n, o agente talvez\\nconheça a posição do objetivo e seja capaz de usar a heurística da distância de Manhattan.\\nEm geral, o objetivo do agente é alcançar um estado objetivo ao mesmo tempo que minimiza o\\ncusto (outro objetivo possível é simplesmente explorar o ambiente inteiro). O custo é o custo total de\\ncaminho correspondente ao caminho que o agente de fato percorre. É comum comparar esse custo ao\\ncusto do caminho que o agente seguiria \\nse conhecesse o espaço de busca com antecedência\\n, isto é, o\\ncaminho real mais curto (ou a exploração completa mais curta). Na linguagem de algoritmos on-line,\\nisso se denomina \\nrazão competitiva\\n; que gostaríamos que fosse tão pequena quanto possível.\\n Embora isso soe como uma solicitação razoável, é fácil ver que a melhor razão competitiva que\\nse pode alcançar é infinita em alguns casos. Por exemplo, se algumas ações forem \\nirreversíveis\\n —\\nou seja, conduzem a um estado do qual nenhuma ação leva de volta ao estado anterior —, a busca on-\\nline poderá chegar acidentalmente a um estado de \\nbeco sem saída\\n, a partir do qual nenhum estado\\nobjetivo será alcançável. Talvez você considere o termo “acidentalmente” pouco convincente —\\nafinal, poderia existir um algoritmo que não tomasse o caminho do beco sem saída em sua\\nexploração. Nossa afirmativa, para sermos mais precisos, é que \\nnenhum algoritmo pode evitar\\nbecos sem saída em todos os espaços de estados\\n. Considere os dois espaços de estados de becos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 187}),\n",
       " Document(page_content='sem saída da \\nFigura 4.20\\n(a). Para um algoritmo de busca on-line que visitasse os estados \\nS\\n e \\nA\\n, os\\ndois espaços de estados pareceriam \\nidênticos\\n e, assim, ele teria de tomar a mesma decisão em\\nambos. Por essa razão, ele falhará em um deles. Esse é um exemplo de \\ndisputa adversarial\\n —\\npodemos imaginar um oponente que constrói o espaço de estados, enquanto o agente o explora e que\\npode posicionar as metas e os becos sem saída onde desejar.\\nFigura 4.20\\n (a) Dois espaços de estados que poderiam levar um agente de busca on-line a um beco\\nsem saída. Qualquer agente específico falhará em pelo menos um desses espaços. (b) Um ambiente\\nbidimensional que pode fazer um agente de busca on-line seguir uma rota arbitrariamente ineficiente\\naté o objetivo. Seja qual for a escolha do agente, o oponente bloqueará essa rota com outra parede\\nlonga e estreita, para que o caminho seguido seja muito mais longo que o melhor caminho possível.\\nOs becos sem saída constituem uma dificuldade real para a exploração de robôs — escadarias,\\nrampas, precipícios e todos os tipos de terrenos naturais apresentam oportunidades para ações\\nirreversíveis. Para progredir, simplesmente iremos supor que o espaço de estados é \\nexplorável com\\nsegurança\\n — isto é, algum estado objetivo é alcançável a partir de todo estado alcançável. Os\\nespaços de estados com ações reversíveis, como labirintos e quebra-cabeças de oito peças, podem\\nser vistos como grafos não orientados e sem dúvida são exploráveis com segurança.\\nMesmo em ambientes exploráveis com segurança, nenhuma razão competitiva limitada poderá ser\\ngarantida se houver caminhos de custo ilimitado. É fácil mostrar isso em ambientes com ações\\nirreversíveis, mas essa afirmativa também permanece verdadeira para o caso reversível, como\\nmostra a \\nFigura 4.20\\n(b). Por essa razão, é comum descrever o desempenho de algoritmos de busca\\non-line em termos do tamanho do espaço de estados inteiro, e não apenas da profundidade do\\nobjetivo mais raso.\\n4.5.2 Agentes de busca on-line\\nDepois de cada ação, um agente on-line recebe uma percepção informando-o de qual estado ele\\nalcançou; a partir dessa informação, ele pode ampliar seu mapa do ambiente. O mapa atual é usado', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 188}),\n",
       " Document(page_content='para decidir aonde ir em seguida. Essa intercalação de planejamento e ação significa que os\\nalgoritmos de busca on-line são bastante diferentes dos algoritmos de busca off-line que vimos\\nanteriormente. Por exemplo, algoritmos off-line como A* podem expandir um nó em uma parte do\\nespaço e depois expandir imediatamente um nó em outra parte do espaço porque a expansão de nós\\nenvolve ações simuladas, em vez de ações reais. Por outro lado, um algoritmo on-line pode\\ndescobrir sucessores para um nó que ele ocupa fisicamente. Para evitar percorrer todos os caminhos\\nda árvore para expandir o próximo nó, parece melhor expandir nós em uma ordem \\nlocal\\n. A busca em\\nprofundidade tem exatamente essa propriedade porque (exceto quando ocorre retrocesso) o próximo\\nnó expandido é um filho do nó expandido anterior.\\nUm agente de busca on-line em profundidade é mostrado na \\nFigura 4.21\\n. Esse agente armazena seu\\nmapa em uma tabela, \\nResultado\\n[\\ns\\n, \\na\\n], que registra o estado resultante da execução da ação \\na\\n no\\nestado \\ns\\n. Sempre que uma ação para o estado atual não foi explorada, o agente experimenta essa\\nação. A dificuldade surge quando o agente tenta todas as ações em um estado. Na busca off-line em\\nprofundidade, o estado é simplesmente retirado da fila; em uma busca on-line, o agente tem de\\nretroceder fisicamente. Na busca em profundidade, isso significa voltar para o estado a partir do qual\\no agente entrou no estado atual. Isso é conseguido mantendo-se uma tabela que lista, para cada\\nestado, os estados predecessores aos quais o agente ainda não retrocedeu. Se o agente esgotar os\\nestados aos quais ele pode retroceder, sua busca estará completa.\\nfunção\\n AGENTE-DFS-ON-LINE(\\ns\\n′) \\nretorna\\n uma ação\\n    \\nentradas:\\n \\ns\\n′, uma percepção que identifica o estado atual\\n    \\npersistente:\\n \\nresultado\\n, uma tabela, indexada por ação e estado, inicialmente vazia\\nexperimentar\\n, uma tabela que lista, para cada estado visitado, as ações ainda não\\ntentadas\\nretroceder\\n, uma tabela que lista, para cada estado visitado, os retrocessos ainda\\nnão tentados\\ns\\n, \\na\\n, o estado e a ação anteriores, inicialmente nulos\\n    \\nse\\n TESTE-OBJETIVO(\\ns\\n′) \\nentão retornar\\n \\nparar\\n    \\nse\\n \\ns\\n é um novo estado (não em \\nexperimentar\\n) \\nentão\\n \\nexperimentar\\n[\\ns\\n′ ] ← AÇÕES(\\ns\\n′)\\n    \\nse\\n \\ns\\n é não nulo \\nentão\\n        \\nresultado\\n[\\ns\\n′, \\na\\n] ← \\ns\\n′\\n        somar \\ns\\n ao início de \\nretrocesso\\n[\\ns\\n′]\\n    \\nse\\n \\nexperimentar\\n[\\ns\\n′] é vazio \\nentão\\n        \\nse\\n \\nretrocesso\\n[\\ns\\n′] é vazio \\nentão retornar\\n \\nparar\\n        \\nsenão\\n \\na\\n ← uma ação \\nb\\n tal que \\nresultado\\n[\\ns\\n′, \\nb\\n] = DESEMPILHA(\\nretroceder\\n[\\ns\\n′])\\n    \\nsenão\\n \\na\\n ← DESEMPILHA(\\nexperimentar\\n[\\ns\\n′])\\n    \\ns\\n ← \\ns\\n′\\n    \\nretornar\\n \\na\\nFigura 4.21\\n Um agente de busca on-line que utiliza exploração em profundidade. O agente só é\\naplicável em espaços de estados em que toda a ação pode ser “desfeita” por alguma outra ação.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 189}),\n",
       " Document(page_content='Recomendamos que o leitor acompanhe o progresso do AGENTE-DFS-ON-LINE quando aplicado\\nao labirinto da \\nFigura 4.19\\n. É bastante fácil verificar que o agente acabará, no pior caso, percorrendo\\ntoda transição no espaço de estados exatamente duas vezes. Para a exploração, isso é ótimo; por\\noutro lado, para encontrar um objetivo, a razão competitiva do agente poderia ser arbitrariamente\\nruim se resultasse em uma longa excursão quando houvesse um objetivo bem próximo ao estado\\ninicial. Uma variante on-line do aprofundamento iterativo resolve esse problema; no caso de um\\nambiente que seja uma árvore uniforme, a razão competitiva de tal agente será uma constante\\npequena.\\nEm consequência de seu método de retrocesso, o AGENTE-DFS-ON-LINE só funcionará em\\nespaços de estados nos quais as ações são reversíveis. Existem algoritmos um pouco mais complexos\\nque funcionam em espaços de estados gerais, mas nenhum desses algoritmos tem uma razão\\ncompetitiva limitada.\\n4.5.3 Busca local on-line\\nAssim como a busca em profundidade, a \\nbusca de subida de encosta\\n tem a propriedade de\\nlocalidade em suas expansões de nós. De fato, como ela mantém apenas um estado atual na memória,\\na busca de subida de encosta \\njá\\n é um algoritmo de busca on-line! Infelizmente, não é muito útil em\\nsua forma mais simples porque deixa o agente parado em máximos locais, sem ter para onde ir. Além\\ndisso, os reinícios aleatórios não podem ser usados porque o agente não tem como se transportar\\npara um novo estado.\\nEm vez de reinícios aleatórios, poderíamos considerar o uso de um \\npercurso aleatório\\n para\\nexplorar o ambiente. Um percurso aleatório simplesmente seleciona ao acaso uma das ações\\ndisponíveis do estado corrente; a preferência pode ser dada a ações que ainda não foram\\nexperimentadas. É fácil provar que um percurso aleatório irá \\neventualmente\\n encontrar um objetivo\\nou completar sua exploração, desde que o espaço seja finito.\\n14\\n Por outro lado, o processo pode ser\\nmuito lento. A \\nFigura 4.22\\n mostra um ambiente em que um percurso aleatório levará\\nexponencialmente muitos passos para encontrar o objetivo porque, em cada passo, o progresso para\\ntrás é duas vezes mais provável que o progresso para frente. É claro que o exemplo é fictício, mas\\nexistem muitos espaços de estados reais cuja topologia resulta nesses tipos de “armadilhas” para\\npercursos aleatórios.\\nFigura 4.22\\n Um ambiente em que um percurso aleatório levará exponencialmente muitos passos para\\nencontrar o objetivo.\\nA extensão da subida de encosta com \\nmemória\\n em vez de aleatoriedade acaba sendo uma\\nabordagem mais efetiva. A ideia básica é armazenar uma “melhor estimativa atual” \\nH\\n(\\ns\\n) do custo\\npara alcançar o objetivo a partir de cada estado que tenha sido visitado. \\nH\\n(\\ns\\n) começa sendo apenas a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 190}),\n",
       " Document(page_content='estimativa heurística \\nh\\n(\\ns\\n) e é atualizada à medida que o agente ganha experiência no espaço de\\nestados. A \\nFigura 4.23\\n mostra um exemplo simples em um espaço de estados unidimensional. Em (a),\\no agente parece estar preso em um mínimo local plano no estado sombreado. Em vez de permanecer\\nonde está, o agente deve seguir o que parece ser o melhor caminho até o objetivo, dadas as\\nestimativas de custo atuais para seus vizinhos. O custo estimado para alcançar o objetivo através de\\num vizinho \\ns\\n′ é o custo para chegar a \\ns\\n′ somado ao custo estimado para ir de lá até um objetivo —\\nisto é, \\nc\\n(\\ns\\n, \\na\\n, \\ns\\n′) + \\nH\\n(\\ns\\n′). No exemplo, existem duas ações com custos estimados 1 + 9 e 1 + 2, e\\nassim parece melhor mover-se para a direita. Agora, é claro que a estimativa de custo 2 para o\\nestado sombreado foi exageradamente otimista. Tendo em vista que o melhor movimento custa 1 e\\nlevou a um estado distante pelo menos dois passos de um objetivo, o estado sombreado deve estar\\npelo menos três passos distante de um objetivo e, portanto, seu \\nH\\n deve ser atualizado de acordo,\\ncomo mostra a \\nFigura 4.23\\n(b). Continuando esse processo, o agente irá retroceder e avançar mais\\nduas vezes, atualizando \\nH\\n em cada vez e “aplainando” o mínimo local até escapar para a direita.\\nFigura 4.23\\n Cinco iterações de LRTA*em um espaço de estados unidimensional. Cada estado é\\nidentificado com \\nH\\n(\\ns\\n), a estimativa de custo atual para alcançar um objetivo, e cada arco é\\nidentificado com seu custo do passo. O estado sombreado marca a posição do agente, e os valores\\natualizados estimados em cada iteração estão dentro de círculos.\\nUm agente que implementa esse esquema, chamado aprendizado em tempo real A* \\nLRTA*\\n(learning real-time A*), é mostrado na \\nFigura 4.24\\n. Da mesma forma que o AGENTE-BP-ON-LINE,\\nele constrói um mapa do ambiente usando a tabela \\nresultado\\n. Ele atualiza a estimativa de custo para\\no estado que acabou de deixar e depois escolhe o “aparentemente melhor” movimento de acordo com\\nsuas estimativas de custo atuais. Um detalhe importante é que sempre se supõe que ações ainda não\\ntentadas em um estado \\ns\\n levam imediatamente ao objetivo com o menor custo possível, ou seja, \\nh\\n(\\ns\\n).\\nEsse \\notimismo sob incerteza\\n encoraja o agente a explorar novos caminhos, possivelmente\\npromissores.\\nfunção\\n AGENTE-LRTA*(\\ns\\n′) \\nretorna\\n uma ação\\n    \\nentradas:\\n \\ns\\n′, uma percepção que identifica o estado corrente\\n    \\npersistente:\\n \\nresultado\\n, uma tabela, indexada por ação e estado, inicialmente vazia', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 191}),\n",
       " Document(page_content='H\\n, uma tabela de estimativas de custo indexada pelo estado, inicialmente\\nvazia\\ns\\n, \\na\\n, o estado e a ação anteriores, inicialmente nulos\\n    \\nse\\n TESTE-OBJETIVO(\\ns\\n′) \\nentão retornar\\n \\nparar\\n    \\nse\\n \\ns\\n′ é um novo estado (não em \\nH\\n) \\nentão\\n \\nH\\n[\\ns\\n′] ← \\nh\\n(\\ns\\n′)\\n    \\nse\\n \\ns\\n não é nulo\\n        \\nresultado\\n[\\ns\\n, \\na\\n] ← \\ns\\n′\\n        \\nH\\n[\\ns\\n] ← min CUSTO-LRTA*(\\ns\\n, \\nb\\n, \\nresultado\\n[\\ns\\n, \\nb\\n], \\nH\\n)\\nb\\n∊\\nAÇÕES(\\ns\\n)\\n    \\na\\n← uma ação \\nb\\n em AÇÕES(\\ns\\n′) que minimiza CUSTO-LRTA*(\\ns\\n′, \\nb\\n, \\nresultado\\n[\\ns\\n′, \\nb\\n], \\nH\\n)\\n    \\ns\\n ← \\ns\\n′\\n    \\nretornar\\n \\na\\nfunção\\n CUSTO-LRTA*(\\ns\\n, \\na\\n, \\ns\\n′, \\nH\\n) \\nretorna\\n uma estimativa de custo\\n    \\nse\\n \\ns\\n′ é indefinido \\nentão retornar\\n \\nh\\n(\\ns\\n)\\n    \\nsenão retornar\\n \\nc\\n(\\ns\\n, \\na\\n, \\ns\\n′) + \\nH\\n[\\ns\\n′]\\nFigura 4.24\\n AGENTE-LRTA*seleciona uma ação de acordo com os valores de estados vizinhos, que\\nsão atualizados à medida que o agente se move no espaço de estados.\\nUm agente LRTA* oferece a garantia de encontrar um objetivo em qualquer ambiente finito\\nexplorável com segurança. Porém, diferentemente de A*, ele não é completo para espaços de estados\\ninfinitos — há casos em que ele pode ficar indefinidamente perdido. O agente pode explorar um\\nambiente de \\nn\\n estados em \\nO\\n(\\nn\\n2\\n) passos no pior caso, mas com frequência funciona muito melhor. O\\nagente LRTA* é apenas um em uma grande família de agentes on-line que podem ser definidos pela\\nespecificação da regra de seleção de ação e a regra de atualização de diferentes modos.\\nDiscutiremos essa família, desenvolvida originalmente para ambientes estocásticos, no Capítulo 21.\\n4.5.4 Aprendizado em busca on-line\\nA ignorância inicial dos agentes de busca on-line oferece várias oportunidades para aprendizado.\\nEm primeiro lugar, os agentes aprendem um “mapa” do ambiente — mais precisamente, o resultado\\nde cada ação em cada estado — apenas registrando cada uma de suas experiências (note que a\\nsuposição de ambientes determinísticos significa que uma experiência é suficiente para cada ação).\\nEm segundo lugar, os agentes de busca local adquirem estimativas mais precisas do custo de cada\\nestado usando regras de atualização local, como no LRTA*. No Capítulo 21, mostramos que essas\\natualizações convergem eventualmente para valores \\nexatos\\n em todo estado, desde que o agente\\nexplore o espaço de estados da maneira correta. Uma vez conhecidos os valores exatos podem ser\\ntomadas decisões ótimas pela simples movimentação para o sucessor de valor mais baixo, isto é, a\\nsubida de encosta pura é então uma estratégia ótima.\\nSe você seguiu nossa sugestão para acompanhar o comportamento de AGENTE-DFS-ON-LINE no\\nambiente da \\nFigura 4.19\\n, terá notado que o agente não é muito brilhante. Por exemplo, depois de ver', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 192}),\n",
       " Document(page_content='que a ação \\nPara cima\\n vai de (1,1) para (1,2), o agente ainda não tem ideia de que a ação \\nPara baixo\\nvolta a (1,1) ou de que a ação \\nPara cima\\n também vai de (2,1) para (2,2), de (2,2) para (2,3), e assim\\npor diante. Em geral, gostaríamos que o agente aprendesse que \\nPara cima\\n aumenta a coordenada \\ny\\n, a\\nmenos que exista uma parede no caminho, que \\nPara baixo\\n a reduz, e assim por diante. Para que isso\\naconteça, primeiro precisamos de uma representação formal e explicitamente manipulável para esses\\ntipos de regras gerais; até agora, ocultamos a informação contida na caixa-preta chamada função\\nRESULTADO. A Parte III é dedicada a essa questão. Em segundo lugar, precisamos de algoritmos\\nque possam construir regras gerais adequadas a partir das observações específicas feitas pelo agente.\\nEsses assuntos serão estudados no Capítulo 18.\\n4.6 RESUMO\\nEste capítulo examinou algoritmos de busca para problemas além do caso “clássico” de encontrar\\no caminho mais curto para um objetivo em um ambiente observável, determinístico, discreto.\\n•  Métodos de \\nbusca local\\n como \\nsubida de encosta\\n operam sobre formulações de estados\\ncompletos, mantendo na memória apenas um pequeno número de nós. Foram desenvolvidos\\nvários algoritmos estocásticos, incluindo a \\ntêmpera simulada\\n, que devolve soluções ótimas\\nquando recebe um cronograma de resfriamento apropriado.\\n•  Muitos métodos de busca local também se aplicam a problemas de espaços contínuos. A\\nprogramação linear\\n e a \\notimização convexa\\n obedecem a certas restrições sobre a forma do\\nespaço de estados e da natureza da função objetivo, e admitem algoritmos de tempo polinomial\\nque são sempre extremamente eficientes na prática.\\n•  Um \\nalgoritmo genético\\n é uma busca de subida de encosta estocástica em que é mantida uma\\ngrande população de estados. Novos estados são gerados por \\nmutação\\n e por \\ncruzamento\\n, que\\ncombinam pares de estados da população.\\n•  Em ambientes não determinísticos, os \\nagentes\\n podem aplicar pesquisa E-OU para gerar planos\\nde \\ncontingência\\n que alcançam o objetivo, independentemente do resultado que ocorre durante a\\nexecução.\\n•  Quando o ambiente for parcialmente observável, o \\nestado de crença\\n representa o conjunto de\\nestados possíveis em que o agente pode estar.\\n•  Os algoritmos de busca-padrão podem ser aplicados diretamente ao espaço de estado de crença\\npara resolver \\nproblemas sem sensoriamento\\n, e os de busca de estado de crença E-OU podem\\nresolver problemas gerais parcialmente observáveis. Os algoritmos incrementais que constroem\\nsoluções estado por estado em um estado de crença são muitas vezes mais eficientes.\\n•  Os \\nproblemas de exploração\\n surgem quando o agente não tem nenhuma ideia sobre os estados e\\nações de seu ambiente. No caso de ambientes exploráveis com segurança, agentes de \\nbusca on-\\nline\\n podem construir um mapa e encontrar um objetivo, se existir algum. A atualização de\\nestimativas heurísticas a partir da experiência fornece um método efetivo para escapar de\\nmínimos locais.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 193}),\n",
       " Document(page_content='NOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nAs técnicas de busca local têm uma longa história em matemática e ciência da computação. Na\\nrealidade, o método de Newton-Raphson (Newton, 1671; Raphson, 1690) pode ser visto como um\\nmétodo de busca local muito eficiente para espaços contínuos em que as informações de gradiente\\nestão disponíveis. Brent (1973) é uma referência clássica para algoritmos de otimização que não\\nexigem tais informações. A busca em feixe, que apresentamos como algoritmo de busca local, teve\\norigem como uma variante de largura limitada da programação dinâmica para reconhecimento de voz\\nno sistema HARPY (Lowerre, 1976). Um algoritmo relacionado é analisado em profundidade por\\nPearl (1984, Capítulo 5).\\nO tópico de busca local foi revigorado no início dos anos 1990 por resultados surpreendentemente\\nbons para problemas de satisfação de restrições como o das \\nn\\n rainhas (Minton \\net al\\n., 1992) e\\nraciocínio lógico (Selman \\net al\\n., 1992), e pela incorporação da aleatoriedade, de múltiplas buscas\\nsimultâneas e de outros aperfeiçoamentos. Esse renascimento do que Christos Papadimitriou chamou\\nde algoritmos da “Nova Era” também despertou interesse crescente entre os cientistas da computação\\nteórica (Koutsoupias e Papadimitriou, 1992; Aldous e Vazirani, 1994). No campo da pesquisa\\noperacional, uma variante da subida de encosta chamada \\nbusca tabu\\n ganhou popularidade (Glover e\\nLaguna, 1997). Esse algoritmo mantém uma lista tabu de \\nk\\n estados visitados anteriormente que não\\npodem ser revisitados; essa lista tanto pode melhorar a eficiência na busca em grafos, como pode\\npermitir que o algoritmo escape de alguns mínimos locais. Outra melhoria útil em relação à subida\\nde encosta é o algoritmo STAGE (Boyan e Moore, 1998). A ideia é usar os máximos locais\\nencontrados pela subida de encosta com reinício aleatório para ter uma ideia da forma geral da\\ntopologia. O algoritmo ajusta uma superfície suave ao conjunto de máximos locais e depois calcula\\nanaliticamente o máximo global dessa superfície. Este se torna o novo ponto de reinício.\\nDemonstrou-se que o algoritmo funciona na prática em problemas difíceis. Gomes \\net al\\n. (1998)\\nmostraram que as distribuições de tempo de execução de algoritmos de retrocesso sistemático com\\nfrequência têm \\ndistribuição de cauda pesada\\n; isso significa que a probabilidade de um tempo de\\nexecução muito longo é maior do que seria previsto se os tempos de execução estivessem\\nexponencialmente distribuídos. Quando a distribuição do tempo de execução é de cauda pesada, o\\nreinício aleatório encontra em média uma solução mais rápida do que uma única execução para a\\nconclusão.\\nA têmpera simulada foi descrita primeiro por Kirkpatrick \\net al\\n. (1983), que a tomaram emprestada\\ndiretamente do \\nalgoritmo de Metropolis\\n (usado para simular sistemas complexos em física —\\nMetropolis \\net al\\n., 1953 — e foi criada supostamente durante um jantar festivo em Los Alamos). A\\ntêmpera simulada agora é um campo em si mesmo, com centenas de artigos publicados a cada ano.\\nEncontrar soluções ótimas em espaços contínuos é o principal assunto de diversos campos,\\nincluindo a \\nteoria de otimização\\n, a \\nteoria de controle ótimo\\n e o \\ncálculo de variações\\n. As técnicas\\nbásicas são bem explicadas por Bishop (1995); Press \\net al\\n. (2007) cobrem uma vasta gama de\\nalgoritmos e fornecem o software correspondente.\\nComo Andrew Moore indicou, os pesquisadores tiveram inspiração pelos algoritmos de busca e\\notimização de uma ampla variedade de áreas de estudo: metalurgia (têmpora simulada), biologia\\n(algoritmos genéticos), economia (algoritmos baseados no mercado de ações), entomologia', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 194}),\n",
       " Document(page_content='(otimização de colônia de formigas), neurologia (redes neurais), comportamento animal\\n(aprendizagem por reforço), montanhismo (subida de encosta) e outros.\\nA \\nprogramação linear\\n (PL) foi inicialmente estudada sistematicamente pelo matemático russo\\nLeonid Kantorovich (1939). Foi uma das primeiras aplicações de computadores; o \\nalgoritmo\\nsimplex\\n (Dantzig, 1949) ainda é usado, apesar da complexidade exponencial do pior caso.\\nKarmarkar (1984) desenvolveu a família muito mais eficiente de métodos de \\nponto interior\\n, que\\ndemonstrou ter complexidade polinomial para a classe mais geral de problemas de otimização\\nconvexa por Nesterov e Nemirovski (1994). São fornecidas excelentes introduções à otimização\\nconvexa por Ben-Tal e Nemirovski (2001) e Boyd e Vandenberghe (2004).\\nO trabalho de Sewall Wright (1931) sobre o conceito de uma \\ntopologia de adaptação\\n foi um\\nimportante precursor para o desenvolvimento de algoritmos genéticos. Na década de 1950, diversos\\nestatísticos, incluindo Box (1957) e Friedman (1959), utilizaram técnicas evolucionárias em\\nproblemas de otimização, mas somente quando Rechenberg (1965) introduziu as \\nestratégias de\\nevolução\\n para resolver problemas de otimização de aerofólios a abordagem ganhou popularidade.\\nNas décadas de 1960 e 1970, John Holland (1975) defendeu os algoritmos genéticos, não só como\\numa ferramenta útil, mas também como um método para expandir nossa compreensão da adaptação,\\nbiológica ou não (Holland, 1995). O movimento de \\nvida artificial\\n (Langton, 1995) leva essa ideia um\\npasso adiante, visualizando os produtos de algoritmos genéticos como \\norganismos\\n, em vez de\\nsoluções para problemas. O trabalho nesse campo desenvolvido por Hinton e Nowlan (1987) e por\\nAckley e Littman (1991) foi realizado principalmente para esclarecer as implicações do efeito de\\nBaldwin. Para um conhecimento geral sobre os fundamentos da evolução, recomendamos Smith e\\nSzathmáry (1999), Ridley (2004) e Carroll (2007).\\nA maioria das comparações de algoritmos genéticos com outras abordagens (em especial a subida\\nde encosta estocástica) revelou que os algoritmos genéticos convergem mais lentamente (O’Reilly e\\nOppacher, 1994; Mitchell \\net al\\n., 1996; Juels e Wattenberg, 1996; Baluja, 1997). Tais descobertas\\nnão são universalmente populares dentro da comunidade de AG, mas tentativas recentes dentro dessa\\ncomunidade para entender a busca baseada na população como uma forma aproximada de\\naprendizado bayesiano (veja o Capítulo 20) talvez ajudem a reduzir o abismo entre o campo e suas\\ncríticas (Pelikan \\net al\\n., 1999). A teoria de \\nsistemas quadráticos dinâmicos\\n também pode explicar o\\ndesempenho dos AGs (Rabani \\net al.\\n, 1998). Veja em Lohn \\net al\\n. (2001) um exemplo de AG aplicado\\nao projeto de antenas e, em Renner e Ekart (2003), para uma aplicação de projeto assistido por\\ncomputador.\\nO campo de \\nprogramação genética\\n está intimamente relacionado aos algoritmos genéticos. A\\nprincipal diferença é que as representações que sofrem mutações e combinações são programas, em\\nvez de cadeias de bits. Os programas são representados sob a forma de árvores de expressões; as\\nexpressões podem estar em uma linguagem padrão como Lisp ou podem ser projetadas\\nespecificamente para representar circuitos, controladores de robôs, e assim por diante. O cruzamento\\nenvolve a união de subárvores, e não de subcadeias. Essa forma de mutação garante que os\\ndescendentes serão expressões bem formadas, o que não ocorreria se os programas fossem\\nmanipulados como cadeias.\\nO recente interesse em programação genética foi incentivado pelo trabalho de John Koza (Koza,\\n1992, 1994), mas remonta pelo menos aos primeiros experimentos com código de máquina', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 195}),\n",
       " Document(page_content='realizados por Friedberg (1958) e com autômatos de estados finitos, desenvolvidos por Fogel \\net al\\n.\\n(1966). Como no caso de algoritmos genéticos, existe um debate sobre a eficácia da técnica. Koza \\net\\nal\\n. (1999) descrevem experimentos no projeto automatizado dos dispositivos de circuitos utilizando\\nprogramação genética.\\nOs periódicos \\nEvolutionary Computation\\n e \\nIEEE Transactions on Evolutionary Computation\\nestudam algoritmos genéticos e programação genética; também são encontrados artigos em \\nComplex\\nSystems\\n, \\nAdaptive Behavior\\n e \\nArtificial Life\\n. A conferência principal é a \\nGenetic and Evolutionary\\nComputation Conference\\n (GECCO). Mitchell (1996), Fogel (2000) e Langdon e Poli (2002), e o\\nlivro on-line gratuito de Poli \\net al.\\n (2008), oferecem bons textos de visão geral sobre algoritmos\\ngenéticos.\\nA imprevisibilidade e a observabilidade parcial de ambientes reais foram reconhecidas no início\\nde projetos de robótica que utilizavam técnicas de planejamento, incluindo Shakey (Fikes \\net al.\\n,\\n1972) e Freddy (Michie, 1974). Os problemas receberam mais atenção após a publicação do artigo\\ninfluente de McDermott (1978a), \\nPlanning e Acting\\n.\\nO primeiro trabalho a fazer uso explícito de árvores E-OU parece ter sido o programa SAINT de\\nSlagle para a integração simbólica, mencionado no Capítulo 1. Amarel (1967) aplicou a ideia de\\nprova de teorema proposicional, um tópico que será discutido no Capítulo 7, e introduziu um\\nalgoritmo de busca semelhante à BUSCA-EM-GRAFOS-E-OU. O algoritmo foi desenvolvido mais\\nadiante e formalizado por Nilsson (1971), que também descreveu AO*, que, como seu nome sugere,\\nencontra soluções ótimas dada uma heurística admissível. AO* foi analisado e melhorado por\\nMartelli e Montanari (1973). AO* é um algoritmo top-down; uma generalização bottom-up de A* é\\nA*LD, isto é, A* Lightest Derivation (Felzenszwalb e McAllester, 2007). O interesse pela busca E-\\nOU passou por um renascimento nos últimos anos, com novos algoritmos para encontrar soluções\\ncíclicas (Jimenez e Torras, 2000; Hansen e Zilberstein, 2001) e novas técnicas inspiradas por\\nprogramação dinâmica (Bonet e Geffner, 2005).\\nA ideia de transformar problemas parcialmente observáveis em problemas de estado de crença\\noriginou com Astrom (1965) para o caso muito mais complexo de incerteza probabilística (veja o\\nCapítulo 17). Erdmann e Mason (1988) estudaram o problema da manipulação robótica sem\\nsensores, usando uma forma contínua de busca de estado de crença. Eles mostraram que era possível\\norientar uma peça em uma mesa a partir de uma posição inicial arbitrária por uma sequência bem\\nconcebida de ações pendulares. Métodos mais práticos, com base em uma série de barreiras\\ndiagonais precisamente orientadas através de uma correia transportadora, utilizam o mesmo critério\\nalgorítmico (Wiegley \\net al\\n., 1996).\\nA abordagem do estado de crença foi reinventada no contexto de problemas de busca sem\\nsensoriamento e parcialmente observáveis por Genesereth e Nourbakhsh (1993). Foi realizado um\\ntrabalho adicional sobre os problemas sem sensoriamento na comunidade de planejamento baseado\\nem lógica (Goldman e Boddy, 1996; Smith e Weld, 1998). Esse trabalho enfatizou representações\\nconcisas para os estados de crença, como explicado no Capítulo 11. Bonet e Geffner (2000)\\nintroduziram as primeiras heurísticas eficazes para a busca do estado de crença, que foram refinados\\npor Bryce \\net al\\n. (2006). A abordagem incremental da busca do estado de crença, em que as soluções\\nsão construídas de forma incremental para subconjuntos de estados dentro de cada estado de crença,\\nfoi estudada na literatura de planejamento por Kurien \\net al\\n. (2002); vários novos algoritmos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 196}),\n",
       " Document(page_content='incrementais foram apresentados para problemas não determinísticos, parcialmente observáveis por\\nRussell e Wolfe (2005). Referências adicionais para planejamento, em ambientes estocásticos\\nparcialmente observáveis, \\u200b\\u200baparecem no Capítulo 17.\\nOs algoritmos para explorar espaços de estados desconhecidos têm despertado interesse por\\nmuitos séculos. A busca em profundidade em um labirinto pode ser implementada mantendo-se a mão\\nesquerda na parede; os ciclos podem ser evitados marcando-se cada junção. A busca em\\nprofundidade falha com ações irreversíveis; o problema mais geral de exploração de \\ngrafos\\neulerianos\\n (isto é, grafos em que cada nó tem números iguais de arestas de entrada e saída) foi\\nresolvido por um algoritmo criado por Hierholzer (1873). O primeiro estudo algorítmico completo\\ndo problema de exploração de grafos arbitrários foi proposto por Deng e Papadimitriou (1990), que\\ndesenvolveram um algoritmo completamente geral, mas mostraram que não é possível nenhuma razão\\ncompetitiva limitada para explorar um grafo geral. Papadimitriou e Yannakakis (1991) examinaram a\\nquestão de encontrar caminhos até um objetivo em ambientes de planejamento de caminhos\\ngeométricos (em que todas as ações são reversíveis). Eles mostraram que uma pequena razão\\ncompetitiva pode ser alcançada com obstáculos quadrados, mas que não é possível alcançar nenhuma\\nrazão limitada com obstáculos retangulares em geral (veja a \\nFigura 4.20\\n).\\nO algoritmo LRTA* foi desenvolvido por Korf (1990) como parte de uma investigação da \\nbusca\\nem tempo real\\n para ambientes em que o agente deve atuar depois de buscar apenas durante um\\nperíodo de tempo fixo (uma situação muito mais comum em jogos com dois participantes). O LRTA*\\né de fato um caso especial de algoritmos de aprendizado de reforço para ambientes estocásticos\\n(Barto \\net al\\n., 1995). Sua política de otimismo sob incerteza — sempre se dirigir para o estado não\\nvisitado mais próximo — pode resultar em um padrão de exploração menos eficiente no caso não\\ninformado do que a simples busca em profundidade (Koenig, 2000).\\nDasgupta \\net al\\n. (1994) mostram que a busca de aprofundamento iterativo on-line é otimamente\\neficiente para encontrar um objetivo em uma árvore uniforme sem informações heurísticas. Diversas\\nvariantes informadas sobre o tema do LRTA* foram desenvolvidas com diferentes métodos de busca\\ne atualização dentro da parte conhecida do grafo (Pemberton e Korf, 1992). Até agora, não existe\\numa boa compreensão de como encontrar objetivos com eficiência ótima quando se utilizam\\ninformações heurísticas.\\nEXERCÍCIOS\\n4.1\\n Forneça o nome do algoritmo que resulta de cada um dos seguintes casos especiais:\\na.\\n Busca em feixe local com \\nk\\n = 1.\\nb.\\n Busca em feixe local com um estado inicial e nenhum limite sobre o número de estados\\nmantidos.\\nc.\\n Tempêra simulada com T = 0 em todas passos (com omissão do teste de término).\\nd\\n. Têmpora simulada com \\nT\\n = ∞ em todos os passos.\\ne.\\n Algoritmo genético com tamanho de população \\nN\\n = 1.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 197}),\n",
       " Document(page_content='4.2\\n O Exercício 3.16 considera o problema da construção de ferrovias sob a suposição de que as\\npeças se encaixam exatamente sem nenhuma folga. Agora considere o problema real, em que as peças\\nnão se encaixam exatamente, mas permitem até 10 graus de rotação para ambos os lados do\\nalinhamento “apropriado”. Explique como formular o problema para que ele possa ser resolvido por\\ntêmpora simulada.\\n \\n4.3\\n Neste exercício, exploramos a utilização de métodos de busca local para resolver TSP’s\\ndo tipo definido no Exercício 3.30.\\na.\\n Implemente e teste um método de subida de encosta para resolver TSP’s. Compare os resultados\\ncom soluções ótimas obtidas do algoritmo A* com a heurística da MST (Minimum-Spanning-\\nTree) (Exercício 3.30).\\nb.\\n Repita parte (a) utilizando um algoritmo genético em vez de um de subida de encosta. Consulte\\nLarrañaga et al. (1999) se desejar alguma sugestão de representações.\\n \\n4.4\\n Gere um grande número de instâncias do quebra-cabeça de oito peças e de oito rainhas e\\nresolva-as (quando possível) por subida de encosta (com variantes de subida mais íngreme e\\nprimeira escolha), por subida de encosta com reinício aleatório e por têmpera simulada. Meça o\\ncusto da busca e a porcentagem de problemas resolvidos e elabore um gráfico desses valores contra\\no custo da solução ótima. Comente seus resultados.\\n4.5\\n O algoritmo de BUSCA-EM-GRAFOS-E-OU na \\nFigura 4.11\\n verifica os estados repetidos apenas\\nno caminho da raiz até o estado atual. Suponha que, além disso, o algoritmo armazene \\ncada\\n estado\\nvisitado numa lista (veja a BUSCA-EM-LARGURA na \\nFigura 3.11\\n como exemplo). Determine a\\ninformação que deveria ser armazenada e como o algoritmo deveria utilizar essa informação quando\\num estado repetido fosse encontrado. (\\nDica\\n: Será necessário pelo menos distinguir estados para os\\nquais um subplano bem-sucedido foi anteriormente construído e os estados para os quais nenhum\\nsubplano pode ser encontrado.) Explique como utilizar rótulos, conforme definido na \\nSeção 4.3.3\\n,\\npara evitar ter várias cópias de subplanos.\\n \\n4.6\\n Explique exatamente como modificar o algoritmo BUSCA-EM-GRAFOS-E-OU para\\ngerar um plano cíclico se não existir nenhum plano acíclico. Será necessário lidar com três questões:\\nrotulagem das etapas do plano para que um plano cíclico possa apontar para uma parte anterior do\\nplano, modificando a BUSCA-OU para que continue a procurar por planos acíclicos depois de\\nencontrar um plano cíclico e aumentando a representação do plano para indicar se um plano é\\ncíclico. Mostre como o algoritmo funciona (a) no mundo do aspirador de pó com incerteza e (b) no\\nmundo do aspirador de pó defeituoso e incerto. Faça a implementação para verificar os resultados.\\n4.7\\n Na \\nSeção 4.4.1\\n apresentamos os estados de crença para resolver problemas de busca sem\\nsensoriamento. Uma sequência de ações resolve um problema sem sensoriamento se ele mapear cada\\nestado físico no estado de crença inicial \\nb\\n para um estado objetivo. Suponha que o agente conheça \\nh\\n*\\n(\\ns\\n), o custo verdadeiro ideal para resolver o estado físico \\ns\\n em um problema completamente\\nobservável, para cada estado \\ns\\n em \\nb\\n. Encontre uma heurística admissível \\nh\\n(\\nb\\n) para o problema sem\\nsensoriamento em termos desses custos e prove a sua admissibilidade. Comente sobre a precisão\\ndessa heurística para o problema do aspirador de pó sem sensoriamento da \\nFigura 4.14\\n. Quão bom é', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 198}),\n",
       " Document(page_content='o desempenho do A*?\\n4.8\\n Este exercício explora as relações subconjunto-superconjunto entre os estados de crença em\\nambientes sem sensoriamento ou parcialmente observáveis.\\u200b\\u200b\\na\\n. Prove que, se uma sequência de ações for uma solução para um estado de crença \\nb\\n, é também\\numa solução para qualquer subconjunto de \\nb\\n. Pode-se dizer algo sobre os superconjuntos de \\nb\\n?\\nb\\n. Explique em detalhe como modificar a busca em grafos para problemas sem sensoriamento para\\ntirar proveito da resposta em (a).\\nc.\\n Explique em detalhes como modificar a busca E-OU para problemas parcialmente observáveis,\\nalém das modificações descritas em (b).\\n4.9\\n Nas \\nSeção 4.4.1\\n foi pressuposto que determinada ação teria o mesmo custo quando executada em\\nqualquer estado físico dentro de determinado estado de crença (isso leva a um problema de busca em\\nestado de crença com custos de passos bem definidos). Agora, considere o que acontece quando essa\\nsuposição é feita. A noção de otimalidade ainda faz sentido nesse contexto ou requer modificação?\\nConsidere também várias definições possíveis do “custo” de executar uma ação em um estado de\\ncrença; por exemplo, poderíamos usar o \\nmínimo\\n de custos físicos ou o \\nmáximo\\n, ou um \\nintervalo\\n de\\ncusto com o limite inferior sendo o custo mínimo e o limite superior o máximo, ou apenas manter o\\nconjunto de todos os custos possíveis para essa ação. Para cada um deles, explore se A* (com\\nalterações, se necessário) pode devolver soluções ótimas.\\n4.10\\n Considere a versão sem sensoriamento do mundo do aspirador de pó defeituoso. Desenhe o\\nespaço de estado de crença acessível a partir do estado de crença inicial {1, 3, 5, 7} e explique por\\nque o problema é insolúvel.\\n \\n4.11\\n Podemos transformar o problema de navegação do Exercício 3.7 em um ambiente como\\no seguinte:\\n•  A percepção será uma lista de posições, \\nem relação ao agente\\n, dos vértices visíveis. A\\npercepção \\nnão\\n inclui a posição do robô! O robô deve aprender a sua própria posição a partir do\\nmapa; por ora, assuma que cada localidade tem uma “visão” diferente.\\n•  Cada ação será um vetor que descreve um caminho em linha reta a ser seguido. Se o caminho\\nestiver desobstruído, a ação será bem-sucedida; caso contrário, o robô vai parar no primeiro\\nponto em que seu caminho cruzar com um obstáculo. Se o agente devolve um vetor de movimento\\nzero e estiver no objetivo (que é fixo e conhecido), o ambiente teletransporta o agente para uma\\nlocalidade aleatória\\n (não dentro de um obstáculo).\\n•  A medida de desempenho penaliza o agente de um ponto para cada unidade de distância\\npercorrida e premia em 1.000 pontos cada vez que o objetivo for alcançado.\\na.\\n Implemente esse ambiente e um agente de resolução de problema para ele. Após cada\\nteletransporte, o agente terá que formular um novo problema, que envolve descobrir a sua\\nlocalização atual.\\nb\\n. Documente o desempenho do seu agente (faça o agente gerar comentários apropriados à medida\\nque se move ao redor) e relate o seu desempenho ao longo de 100 episódios.\\nc\\n. Modifique o ambiente de modo que 30% das vezes o agente acabe em um destino não', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 199}),\n",
       " Document(page_content='pretendido (escolhido aleatoriamente a partir de outros vértices visíveis, se houver algum; caso\\ncontrário, não há movimento algum). Esse é um modelo grosseiro de erros de movimento de um\\nrobô real. Modifique o agente para que, quando tal erro for detectado, ele descubra onde está e,\\nem seguida, construa um plano de voltar para onde estava e retome ao plano antigo. Lembre-se\\nde que, por vezes, voltar para onde estava também pode falhar! Mostre um exemplo do agente\\nsuperando com sucesso dois erros sucessivos de movimento e ainda alcançando seu objetivo.\\nd.\\n Agora tente dois esquemas diferentes de recuperação após um erro: (1) dirija-se para o vértice\\nmais próximo da rota original; e (2) replaneje uma rota para o objetivo a partir da nova\\nlocalização. Compare o desempenho dos três esquemas de recuperação. A inclusão de custos de\\nbusca afetaria a comparação?\\ne.\\n Agora, suponha que existam localizações onde a visão seja idêntica (por exemplo, suponha que\\no mundo seja uma grade com obstáculos quadrados). Que tipo de problema o agente enfrentaria\\nagora? Com o que as soluções se parecem?\\n4.12\\n Suponha que um agente esteja em um ambiente de labirinto 3 × 3 como o da \\nFigura 4.19\\n. O\\nagente sabe que sua posição inicial é (1,1), que o objetivo está em (3,3) e que as quatro ações \\nPara\\ncima\\n, \\nPara baixo\\n, \\nEsquerda\\n, \\nDireita\\n têm seus efeitos habituais, a menos que sejam bloqueadas por\\numa parede. O agente \\nnão\\n sabe onde estão as paredes internas. Em qualquer estado específico, o\\nagente percebe o conjunto de ações válidas; ele também pode saber se o estado já foi visitado antes\\nou é um novo estado.\\na.\\n Explique como esse problema de busca on-line pode ser visualizado como uma busca off-line\\nno espaço de estados de crença, onde o estado de crença inicial inclui todas as configurações\\npossíveis de ambiente. Qual é o tamanho do estado de crença inicial? Qual é o tamanho do\\nespaço de estados de crença?\\nb.\\n Quantas percepções distintas são possíveis no estado inicial?\\nc.\\n Descreva as primeiras ramificações de um plano de contingência para esse problema. Qual é o\\ntamanho (aproximado) do plano completo?\\nNote que esse plano de contingência é uma solução para \\ntodo ambiente possível\\n que se ajusta à\\ndescrição dada. Portanto, a intercalação de busca e execução não é estritamente necessária, nem\\nmesmo em ambientes desconhecidos.\\n \\n4.13\\n Neste exercício, examinaremos a subida de encosta no contexto da navegação de robôs,\\nusando o ambiente da \\nFigura 3.31\\n como exemplo.\\na.\\n Repita o Exercício 4.11 usando subida de encosta. Seu agente ficará preso em um mínimo local?\\nÉ \\npossível\\n que ele fique preso com obstáculos convexos?\\nb.\\n Construa um ambiente poligonal não convexo no qual o agente fique preso.\\nc.\\n Modifique o algoritmo de subida de encosta de forma que, em vez de realizar uma busca de\\nprofundidade 1 a fim de decidir para onde ir em seguida, ele realize uma busca de profundidade\\nk\\n. Ele deve encontrar o melhor caminho de \\nk\\n passos, percorrer um passo ao longo dele e depois\\nrepetir o processo.\\nd.\\n Existe algum \\nk\\n para o qual o novo algoritmo oferece a garantia de escapar de mínimos locais?', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 200}),\n",
       " Document(page_content='e.\\n Explique como o RTDA* permite ao agente escapar de mínimos locais nesse caso.\\n4.14\\n Como DFS, o DFS on-line é incompleto em espaços de estado reversíveis com caminhos\\ninfinitos. Por exemplo, suponha que os estados sejam pontos em uma grade infinita bidimensional e\\nas ações sejam vetores unitários (1,0), (0,1), (-1,0), (0,-1), nessa ordem. Mostre que a DFS on-line\\niniciando em (0,0) não irá alcançar (1,-1). Em adição a esse estado atual, suponha que o agente possa\\nobservar todos os estados sucessores e as ações que irão conduzir a eles. Escreva um algoritmo que\\nseja completo mesmo para espaços de estado bidirecionais com caminhos infinitos.Que estados ele\\nvisita ao alcançar (1, -1)?\\n1\\n Gerar um estado \\naleatório\\n a partir de um espaço de estados implicitamente especificado pode ser um problema difícil por si só.\\n2\\n Luby \\net al\\n. (1993) provam que é melhor, em alguns casos, reiniciar um algoritmo de busca aleatória depois de um período de tempo\\nfixo e específico, e isso pode ser \\nmuito\\n mais eficiente que deixar cada busca continuar indefinidamente. Proibir ou limitar o número de\\nmovimentos laterais é um exemplo dessa ideia.\\n3\\n A busca em feixe local é uma adaptação da \\nbusca em feixe\\n (\\nbeam search\\n), que é um algoritmo baseado em caminhos.\\n4\\n Existem muitas variantes dessa regra de seleção. Pode-se mostrar que o método de \\nculling\\n (corte, eliminação), no qual todos os\\nindivíduos abaixo de determinado limiar são descartados, converge com maior rapidez que a versão aleatória (Baum \\net al\\n., 1995).\\n5\\n É nessa situação que a codificação é importante. Se for usada uma codificação de 24 bits em vez de oito dígitos, o ponto de\\ncruzamento terá uma chance de 2/3 de estar no meio de um dígito, o que resulta em uma mutação essencialmente arbitrária desse dígito.\\n6\\n Um conhecimento básico de cálculo multivariado e aritmética vetorial será útil durante a leitura desta seção.\\n7\\n Em geral, a atualização Newton-Raphson pode ser vista como um ajuste a uma superfície quadrática para \\nf\\n em \\nx\\n e então se movendo\\ndiretamente para o mínimo daquela superfície, que é também o mínimo de \\nf\\n se \\nf\\n for quadrático.\\n8\\n Um conjunto de pontos \\nS\\n é convexo se a linha que une dois pontos quaisquer em \\nS\\n também estiver contido em \\nS\\n. Uma \\nfunção\\nconvexa\\n é aquele da qual o espaço “acima” forma um conjunto convexo; por definição, funções convexas não têm um mínimo local (em\\noposição ao global).\\n9\\n Supomos que a maioria dos leitores, por enfrentar problemas semelhantes, se identifica com o nosso agente. Pedimos desculpas aos\\nproprietários de utensílios domésticos modernos, eficientes, que não podem tirar vantagem desse exemplo pedagógico.\\n10\\n Em um ambiente totalmente observável, cada estado de crença contém um estado físico. Assim, podemos ver os algoritmos do\\nCapítulo 3 como se estivessem em busca de um espaço de estado de crença de estados de crença singulares.\\n11\\n Aqui, e ao longo do livro, o “acento circunflexo” em \\n significa um valor estimado ou previsto para \\nb\\n.\\n12\\n Pedimos desculpas para aqueles que não estão familiarizados com o efeito de crianças pequenas num ambiente.\\n13\\n O termo “on-line” é de uso comum em ciência da computação para fazer referência a algoritmos que devem processar dados de\\nentrada à medida que eles são recebidos, em vez de esperar que o conjunto de dados de entrada inteiro se torne disponível.\\n14\\n Os percursos aleatórios são completos em grades infinitas unidimensionais e bidimensionais. Em uma grade tridimensional, a\\nprobabilidade de alguma vez o percurso retornar ao ponto de partida é apenas de cerca de 0,3405 (Hughes, 1995).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 201}),\n",
       " Document(page_content='CAPÍTULO\\n \\n5\\nBusca competitiva\\nEm que examinamos os problemas que surgem quando tentamos planejar com\\nantecedência em um mundo no qual outros agentes estão fazendo planos contra\\nnós.\\n5.1 JOGOS\\nO Capítulo 2 examinou os \\nambientes multiagentes\\n, em que cada agente precisa considerar as\\nações de outros agentes e o modo como essas ações afetam seu próprio bem-estar. A\\nimprevisibilidade desses outros agentes pode introduzir muitas \\ncontingências\\n possíveis no processo\\nde resolução de problemas do agente, conforme discutido no Capítulo 4. Neste capítulo,\\nabordaremos ambientes \\ncompetitivos\\n, em que os objetivos dos agentes estão em conflito, dando\\norigem a problemas de \\nbusca competitiva\\n — frequentemente conhecidos como \\njogos\\n.\\nA \\nteoria de jogos\\n (matemática), um ramo da economia, visualiza qualquer ambiente multiagente\\ncomo um jogo, desde que o impacto de cada agente sobre os outros seja “significativo”, não\\nimportando se os agentes são cooperativos ou competitivos.\\n1\\n Em IA, os “jogos” mais comuns são de\\num tipo bastante especializado — que os teóricos de jogos denominam jogos determinísticos de\\nrevezamento de dois jogadores \\nde soma zero\\n com \\ninformações perfeitas\\n (como o xadrez). Em\\nnossa terminologia, isso significa ambientes determinísticos completamente observáveis em que dois\\nagentes agem alternadamente e em que os valores de utilidade no fim do jogo são sempre iguais e\\nopostos (ou simétricos). Por exemplo, se um jogador ganha um jogo de xadrez, o outro jogador\\nnecessariamente perde. É essa oposição entre as funções utilidade dos agentes que gera a situação de\\ncompetição.\\nOs jogos ocuparam as faculdades intelectuais dos seres humanos — chegando algumas vezes a um\\ngrau alarmante — desde que surgiu a civilização. Para pesquisadores de IA, a natureza abstrata dos\\njogos os torna um assunto atraente para estudo. É fácil representar o estado de um jogo e, em geral,\\nos agentes se restringem a um pequeno número de ações cujos resultados são definidos por regras\\nprecisas. Jogos físicos, como críquete e hóquei sobre o gelo, têm descrições muito mais\\ncomplicadas, uma faixa muito maior de ações possíveis e regras bastante imprecisas definindo a\\nlegalidade das ações. Com exceção do futebol de robôs, esses jogos físicos não atraíram muito\\ninteresse na comunidade de IA.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 203}),\n",
       " Document(page_content='Os jogos, diferentemente da maior parte dos miniproblemas estudados no Capítulo 3, são\\ninteressantes \\nporque\\n são muito difíceis de resolver. Por exemplo, o xadrez tem um fator médio de\\nramificação de cerca de 35, e as partidas com frequência chegam até a 50 movimentos por cada\\njogador; assim, a árvore de busca tem aproximadamente 35\\n100\\n ou 10\\n154\\n nós (embora o grafo de busca\\ntenha “apenas” cerca de 10\\n40\\n nós distintos). Os jogos, como o mundo real, exigem portanto a\\nhabilidade de tomar \\nalguma\\n decisão, até mesmo quando o cálculo da decisão \\nótima\\n é inviável. Os\\njogos também penalizam a ineficiência de forma severa. Enquanto uma implementação de busca A*\\ncom a metade da eficiência levará duas vezes mais para executar até a conclusão, um programa de\\nxadrez com metade da eficiência no uso de seu tempo disponível provavelmente será derrubado sem\\npiedade, mantendo-se outros aspectos inalterados. Por essa razão, a busca de jogos elaborou várias\\nideias interessantes sobre como fazer o melhor uso possível do tempo.\\nComeçamos com uma definição do movimento ótimo e um algoritmo para descobri-lo. Em seguida,\\nexaminaremos técnicas para escolher um bom movimento quando o tempo é limitado. A \\npoda\\n nos\\npermite ignorar partes da árvore de busca que não fazem diferença para a escolha final, e as \\nfunções\\nde avaliação\\n de heurísticas nos oferecem a oportunidade de fazer uma aproximação da verdadeira\\nutilidade de um estado sem realizar uma busca completa. A \\nSeção 5.5\\n discute jogos como gamão, que\\nincluem um elemento de sorte; também discutimos o jogo de \\nbridge\\n, que inclui elementos de\\ninformação imperfeita\\n porque nem todas as cartas estão visíveis para cada jogador. Por fim,\\nveremos como os programas de jogos de última geração se comportam contra a oposição humana e,\\nainda, orientações para desenvolvimentos futuros.\\nPrimeiro consideraremos jogos com dois jogadores, que chamaremos MAX e MIN por motivos\\nque logo ficarão óbvios. MAX faz o primeiro movimento, e depois eles se revezam até o jogo\\nterminar. No fim do jogo, os pontos são dados ao jogador vencedor e são impostas penalidades ao\\nperdedor. Um jogo pode ser definido formalmente como uma espécie de problema de busca com os\\nseguintes componentes:\\n•  \\nS\\n0\\n: o \\nestado inicial\\n, que especifica como o jogo é criado no início.\\n•  JOGADORES(\\ns\\n): define qual jogador deve se mover em um estado.\\n•  AÇÕES(\\ns\\n): retornam o conjunto de movimentos válidos em um estado.\\n•  RESULTADO(\\ns\\n, \\na\\n): o \\nmodelo de transição\\n que define o resultado de um movimento.\\n•  TESTE DE TÉRMINO(\\ns\\n): um \\nteste de término\\n, que é verdadeiro quando o jogo termina e, do\\ncontrário, falso. Os estados em que o jogo é encerrado são chamados \\nestados terminais\\n.\\n•  UTILIDADE(\\ns\\n, \\np\\n): uma \\nfunção utilidade\\n (também chamada função objetivo ou função\\ncompensação) define o valor numérico para um jogo que termina no estado terminal \\ns\\n por um\\njogador \\np\\n. No xadrez, o resultado é uma vitória, uma derrota ou um empate, com valores +1, 0 ou\\n. Alguns jogos têm uma variedade mais ampla de resultados possíveis; a compensação no gamão\\nvaria de 0 até +192. Um \\njogo de soma zero\\n é (confusamente) definido como aquele em que a\\ncompensação total para todos os jogadores é a mesma para cada instância do jogo. O xadrez é de\\nsoma zero porque cada jogo tem compensação 0 + 1, 1 + 0 ou \\n + \\n. “Soma constante” teria sido\\num termo melhor, mas soma zero é tradicional e faz sentido se você imaginar que de cada\\njogador é cobrada uma taxa de entrada de \\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 204}),\n",
       " Document(page_content='O estado inicial função AÇÕES e a função RESULTADO definem a \\nárvore de jogo\\ncorrespondente ao jogo — uma árvore onde os nós são estados do jogo e as bordas são movimentos.\\nA \\nFigura 5.1\\n mostra parte da árvore de jogo para o jogo da velha. A partir do estado inicial, MAX\\ntem nove movimentos possíveis. O jogo se alterna entre a colocação de um X por MAX e a\\ncolocação de um O por MIN até alcançarmos nós de folhas correspondentes a estados terminais, tais\\nque um jogador tem três símbolos em uma linha ou todos os quadrados são preenchidos. O número\\nem cada nó de folha indica o valor de utilidade do estado terminal, do ponto de vista de MAX;\\nvalores altos são considerados bons para MAX e ruins para MIN (o que explica os nomes dados aos\\njogadores).\\nFigura 5.1\\n Uma árvore de busca (parcial) para o jogo da velha. O nó superior é o estado inicial, e\\nMAX faz o primeiro movimento colocando um X em um quadrado vazio. Mostramos parte da árvore\\nde busca fornecendo movimentos alternados por MIN (O) e MAX(x), até alcançarmos finalmente os\\nestados terminais, aos quais podem ser atribuídas utilidades de acordo com as regras do jogo.\\nPara o jogo da velha, a árvore de jogo é relativamente pequena, menos de 9! = 362.880 nós\\nterminais. Mas, para o xadrez, há mais de 10\\n40\\n nós, de modo que é melhor pensar na árvore de jogo\\ncomo sendo uma construção teórica que não podemos perceber no mundo físico. Mas,\\nindependentemente do tamanho da árvore de jogo, é trabalho de MAX a busca de uma boa jogada.\\nUsamos o termo \\nárvore de busca\\n para uma árvore que está sobreposta à árvore de jogo completa,\\nexaminando os nós o suficiente para permitir que um jogador determine que lance fazer.\\n5.2 DECISÕES ÓTIMAS EM JOGOS\\nEm um problema de busca normal, a solução ótima seria uma sequência de ações que levasse a um\\nestado objetivo — um estado terminal que representa uma vitória. Por outro lado, em um jogo, MIN\\ntem alguma relação com esse estado. Portanto, MAX deve encontrar uma \\nestratégia\\n de contingência', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 205}),\n",
       " Document(page_content='que especifique o movimento de MAX no estado inicial e depois os movimentos de MAX nos\\nestados resultantes de cada resposta possível de MIN, e depois os movimentos de MAX nos estados\\nresultantes de cada resposta possível de MIN a \\nesses\\n movimentos, e assim por diante.\\nIsso é exatamente análogo ao algoritmo E-OU de busca (\\nFigura 4.11\\n), com MAX no papel de OU e\\nMIN equivalente a E. Grosseiramente falando, uma ótima estratégia leva a resultados pelo menos tão\\nbons como qualquer outra estratégia quando se está jogando com um adversário infalível.\\nComeçaremos mostrando como encontrar essa estratégia ótima.\\nAté mesmo um jogo simples como o jogo da velha é muito complexo para traçarmos a árvore de\\njogo inteira em uma página e, assim, nos limitaremos ao jogo trivial da \\nFigura 5.2\\n. Os movimentos\\npossíveis para MAX no nó raiz são identificados por \\na\\n1\\n, \\na\\n2\\n e \\na\\n3\\n. As respostas possíveis para \\na\\n1\\ncorrespondentes a MIN são \\nb\\n1\\n, \\nb\\n2\\n e \\nb\\n3\\n, e assim sucessivamente. Esse jogo específico termina depois\\nde um movimento realizado por MAX e por MIN. (No linguajar dos jogos, dizemos que essa árvore\\ntem a profundidade de um único movimento, que consiste em dois meios movimentos, cada um dos\\nquais é chamado \\njogada\\n.) As utilidades dos estados terminais nesse jogo variam de 2 a 14.\\nFigura 5.2\\n Uma árvore de jogo de duas jogadas. Os nós ∆ são “nós de MAX”, nos quais é a vez de\\nMAX efetuar um movimento, e os nós \\n∇\\n são “nós de MIN”. Os nós terminais mostram os valores de\\nutilidade para MAX;os outros nós estão identificados com seus valores minimax. O melhor\\nmovimento de MAX na raiz é \\na\\n1\\n porque leva a um estado com o mais alto valor minimax, e a melhor\\nresposta de MIN é \\nb\\n1\\n porque leva a um estado com o mais baixo valor minimax.\\nDada uma árvore de jogo, a estratégia ótima pode ser determinada do \\nvalor minimax\\n de cada nó,\\nque representamos como VALOR-MINIMAX(\\nn\\n). O valor minimax de um nó é a utilidade (para\\nMAX) de se encontrar no estado correspondente, \\nsupondo-se que ambos os jogadores tenham\\ndesempenho ótimo\\n desde esse estado até o fim do jogo. É óbvio que o valor minimax de um estado\\nterminal é simplesmente sua utilidade. Além disso, dada uma escolha, MAX preferirá se mover para\\num estado de valor máximo, enquanto MIN preferirá um estado de valor mínimo. Assim, temos:\\nVamos aplicar essas definições à árvore de jogo da \\nFigura 5.2\\n. Os nós terminais no nível inferior\\nobtiverem os valores utilidade da função UTILIDADE do jogo. O primeiro nó de MIN, identificado', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 206}),\n",
       " Document(page_content='por \\nB\\n, tem três sucessores com valores 3, 12 e 8; portanto, seu valor minimax é 3. De modo\\nsemelhante, os outros dois nós de MIN têm valor minimax 2. O nó raiz é um nó de MAX; seus\\nestados sucessores têm valores minimax 3, 2 e 2; logo, ele tem um valor minimax igual a 3. Também\\npodemos identificar a \\ndecisão minimax\\n na raiz: a ação \\na\\n1\\n é a escolha ótima para MAX porque leva\\nao estado com o mais alto valor minimax.\\nEssa definição de jogo ótimo para MAX supõe que MIN também jogue de forma ótima — ela\\nmaximiza o resultado para MAX no \\npior caso\\n. E se MIN não jogar de forma ótima? Nesse caso, é\\nfácil mostrar (Exercício 5.7) que MAX terá um desempenho ainda melhor. Pode haver outras\\nestratégias contra oponentes não ótimos que poderão funcionar melhor que a estratégia de minimax;\\nporém, essas estratégias necessariamente têm um desempenho pior contra oponentes ótimos.\\n5.2.1 O algoritmo minimax\\nO \\nalgoritmo minimax\\n (\\nFigura 5.3\\n) calcula a decisão minimax a partir do estado corrente. Ela\\nutiliza uma computação recursiva simples dos valores minimax de cada estado sucessor,\\nimplementando diretamente as equações da definição. A recursão percorre todo o caminho\\ndescendente até as folhas da árvore e, depois, os valores minimax são \\npropagados de volta\\n pela\\nárvore, à medida que a recursão retorna. Por exemplo, na \\nFigura 5.2\\n, primeiro o algoritmo efetua uma\\nrecursão descendo a árvore até os três nós de folhas inferiores e emprega a função UTILIDADE\\nsobre eles para descobrir que seus valores são 3, 12 e 8, respectivamente. Em seguida, ele toma o\\nmínimo desses valores, 3, e o devolve como valor propagado de volta para o nó \\nB\\n. Um processo\\nsemelhante fornece os valores propagados de volta de 2 para \\nC\\n e 2 para \\nD\\n. Por fim, tomamos o valor\\nmáximo entre 3, 2 e 2 para obter o valor propagado de volta igual a 3 para o nó raiz.\\nfunção\\n DECISÃO-MINIMAX(\\nestado\\n) \\nretorna\\n \\numa ação\\n    \\nretornar\\n arg max\\na\\n∊\\nAçõES\\n(\\ns\\n)\\n VALOR-MIN(RESULTADO(\\nestado\\n, \\na\\n))\\n_____________________________________________________________________________________________________________\\nfunção\\n VALOR-MAX(\\nestado\\n) \\nretorna\\n \\num valor de utilidade\\n    \\nse\\n TESTE TERMINAL (\\nestado\\n) \\nentão retornar\\n UTILIDADE(\\nestado\\n)\\n    \\nv\\n ← − ∞\\n    \\npara cada\\n \\na\\n \\nem\\n AÇÕES(\\nestado\\n) \\nfaça\\n        \\nv\\n ← MAX(\\nv,\\nVALOR-MIN(RESULTADO(\\ns,a\\n)))\\n    \\nretornar\\n \\nv\\n_____________________________________________________________________________________________________________\\nfunção\\n VALOR-MIN(\\nestado\\n) \\nretorna\\n \\num valor de utilidade\\n    \\nse\\n TESTE-TERMINAL(\\nestado\\n) \\nentão retornar\\n UTILIDADE(\\nestado\\n)\\n    \\nv\\n ← − ∞\\n    \\npara cada\\n \\na\\n \\nem\\n AÇÕES(\\nestado\\n) \\nfaça\\n        \\nv\\n ← MIN(\\nv,\\nVALOR-MAX(RESULTADO(\\ns, a\\n)))\\n    \\nretornar\\n \\nv', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 207}),\n",
       " Document(page_content='Figura 5.3\\n Um algoritmo para calcular decisões minimax. Ele retorna a ação correspondente ao\\nmelhor movimento possível, isto é, o movimento que leva ao resultado com a melhor utilidade, sob a\\nsuposição de que o oponente joga para minimizar a utilidade. As funções VALOR-MAX e VALOR-\\nMIN passam por toda a árvore de jogo, até chegar às folhas, a fim de determinar o valor de\\npropagação de volta de um estado. A notação argmax\\na\\n∊\\ns\\n \\nf\\n(\\na\\n) calcula o elemento \\na\\n do conjunto S que\\npossui o valor máximo de \\nf\\n(\\na\\n).\\nO algoritmo minimax executa uma exploração completa em profundidade da árvore de jogo. Se a\\nprofundidade máxima da árvore é \\nm\\n e existem \\nb\\n movimentos válidos em cada ponto, a complexidade\\nde tempo do algoritmo minimax é \\nO\\n(\\nb\\nm\\n). A complexidade de espaço é \\nO\\n(\\nb\\nm\\n) para um algoritmo que\\ngera todos os sucessores de uma vez ou \\nO\\n(\\nm\\n) para um algoritmo que gera ações, uma de cada vez. É\\nclaro que, em jogos reais, o custo de tempo é totalmente impraticável, mas esse algoritmo serve\\ncomo base para a análise matemática de jogos e para algoritmos mais práticos.\\n5.2.2 Decisões ótimas em jogos com vários participantes\\nMuitos jogos populares permitem mais de dois jogadores. Vamos examinar a maneira de estender\\na ideia de minimax a jogos com vários jogadores. Isso é simples do ponto de vista técnico, mas\\ndestaca algumas questões conceituais novas e interessantes.\\nPrimeiro, precisamos substituir o único valor para cada nó por um \\nvetor\\n de valores. Por exemplo,\\nem um jogo de três jogadores com os participantes \\nA\\n, \\nB\\n e \\nC\\n, um vetor \\n〈\\nv\\nA\\n, \\nv\\nB\\n, \\nv\\nC\\n〉\\n está associado a\\ncada nó. Para os estados terminais, esse vetor fornece a utilidade do estado do ponto de vista de cada\\njogador. (Em jogos de soma zero com dois jogadores, o vetor de dois elementos pode ser reduzido a\\num único valor porque os valores são sempre opostos.) O caminho mais simples para implementar\\nisso é fazer a função UTILIDADE retornar um vetor de utilidades.\\nAgora temos de considerar os estados não terminais. Vamos examinar o nó identificado por \\nX\\n na\\nárvore de jogo da \\nFigura 5.4\\n. Nesse estado, o jogador \\nC\\n define o que fazer. As duas escolhas levam a\\nestados terminais com vetores de utilidade \\n〈\\nv\\nA\\n = 1, \\nv\\nB\\n = 2, \\nv\\nC\\n = 6\\n〉\\n e \\n〈\\nv\\nA\\n = 4, \\nv\\nB\\n = 2, \\nv\\nC\\n = 3\\n〉\\n. Tendo\\nem vista que 6 é maior que 3, \\nC\\n deve-se escolher o primeiro movimento. Isso significa que, se o\\nestado \\nX\\n for alcançado, a jogada subsequente levará a um estado terminal com utilidades \\n〈\\nv\\nA\\n = 1, \\nv\\nB\\n= 2, \\nv\\nC\\n = 6\\n〉\\n. Consequentemente, o valor de \\nX\\n que foi propagado de volta é esse vetor. Em geral, o\\nvalor propagado de volta de um nó \\nn\\n é sempre o vetor de utilidade do estado do sucessor com o mais\\nalto valor para a escolha do jogador em \\nn\\n. Qualquer pessoa que participa de jogos com vários\\njogadores, como Diplomacy\\nTM\\n, logo fica ciente de que muito mais acontece do que em jogos de dois\\njogadores. Os jogos com vários participantes normalmente envolvem \\nalianças\\n, sejam elas formais ou\\ninformais, entre os jogadores. As alianças são feitas e desfeitas à medida que o jogo se desenrola.\\nComo entender tal comportamento? As alianças constituem uma consequência natural de estratégias\\nótimas para cada jogador em um jogo com vários participantes? É possível que sim. Por exemplo,\\nvamos supor que \\nA\\n e \\nB\\n estejam em posições fracas e que \\nC\\n esteja em uma posição mais forte. Então,\\ncom frequência, é ótimo para \\nA\\n e \\nB\\n atacarem \\nC\\n em vez de atacarem um ao outro, para que \\nC\\n não\\ndestrua cada um deles individualmente. Desse modo, a colaboração emerge de um comportamento', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 208}),\n",
       " Document(page_content='puramente egoísta. É claro que, tão logo \\nC\\n se enfraqueça sob o violento ataque conjunto, a aliança\\nperderá seu valor, e \\nA\\n ou \\nB\\n poderá violar o acordo. Em alguns casos, as alianças explícitas apenas\\ntornam concreto aquilo que teria acontecido de qualquer modo. Em outros casos, um estigma social\\nincorpora-se para romper uma aliança, de forma que os jogadores devem buscar o equilíbrio entre a\\nvantagem imediata de romper uma aliança e a desvantagem a longo prazo de serem considerados\\npouco confiáveis. Veja a \\nSeção 17.5\\n para obter mais informações sobre essas complicações.\\nFigura 5.4\\n As três primeiras jogadas de uma árvore de jogo com três jogadores (\\nA\\n, \\nB\\n, \\nC\\n). Cada nó é\\nidentificado com valores do ponto de vista de cada jogador. O melhor movimento está assinalado na\\nraiz.\\nSe o jogo for de soma diferente de zero, a colaboração também poderá ocorrer com apenas dois\\njogadores. Por exemplo, vamos supor que exista um estado terminal com utilidades \\n〈\\nv\\nA\\n = 1.000, \\nv\\nB\\n =\\n1.000\\n〉\\n e que 1.000 seja a mais alta utilidade possível para cada jogador. Então, a estratégia ótima é\\na de ambos os jogadores fazerem todo o possível para alcançar esse estado, isto é, os jogadores\\ncooperarão de forma automática para atingir uma meta mutuamente desejável.\\n5.3 PODA ALFA-BETA\\nO problema da busca minimax é que o número de estados de jogo que ela tem de examinar é\\nexponencial em relação ao número de movimentos. Infelizmente, não podemos eliminar o expoente,\\nmas resulta que podemos efetivamente reduzi-lo pela metade. O artifício é a possibilidade de\\ncalcular a decisão minimax correta sem examinar todos os nós na árvore de jogo. Ou seja, podemos\\ntomar emprestada a ideia de \\npoda\\n do Capítulo 3, a fim de poder deixar de considerar grandes partes\\nda árvore. A técnica específica que examinaremos é chamada \\npoda alfa-beta\\n. Quando é aplicada a\\numa árvore minimax padrão, ela retorna o mesmo movimento que minimax retornaria, mas poda as\\nramificações que não terão influência possível sobre a decisão final.\\nConsidere novamente a árvore de jogo de duas jogadas da \\nFigura 5.2\\n. Vamos acompanhar mais\\numa vez o cálculo da decisão ótima, agora prestando bastante atenção ao que conhecemos em cada\\nponto do processo.\\nOs passos são explicados na \\nFigura 5.5\\n. O resultado é que podemos identificar a decisão minimax\\nsem jamais avaliar dois dentre os nós de folhas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 209}),\n",
       " Document(page_content='Figura 5.5\\n Fases no cálculo da decisão ótima para a árvore de jogo da \\nFigura 5.2\\n. Em cada ponto,\\nmostramos o intervalo de valores possíveis para cada nó. (a) Aprimeira folha sob \\nB\\n tem valor 3.\\nConsequentemente, \\nB\\n, que é um nó de MIN, tem valor \\nmáximo\\n 3. (b) A segunda folha sob \\nB\\n tem valor\\n12; MIN evitaria esse movimento, de forma que o valor de \\nB\\n ainda é, no máximo, 3. (c) Aterceira\\nfolha sob \\nB\\n tem valor 8; vimos todos os estados sucessores de \\nB\\n e, assim, o valor de \\nB\\n é exatamente\\n3. Agora, podemos deduzir que o valor da raiz é \\npelo menos\\n 3, porque MAX tem uma escolha de\\nvalor 3 na raiz. (d) A primeira folha abaixo de \\nC\\n tem o valor 2. Consequentemente, \\nC\\n, que é um nó de\\nMIN, tem valor \\nmáximo\\n 2. Porém, sabemos que \\nB\\n vale 3; portanto, MAX nunca escolheria \\nC\\n. Desse\\nmodo, não há razão para se examinar os outros sucessores de \\nC\\n. Esse é um exemplo de poda alfa-\\nbeta. (e) A primeira folha abaixo de \\nD\\n tem o valor 14, e então \\nD\\n vale \\nno máximo\\n 14. Esse valor\\nainda é mais alto que a melhor alternativa de MAX (isto é, 3) e, portanto, precisamos continuar a\\nexplorar sucessores de \\nD\\n. Note também que agora temos limites para todos os sucessores da raiz e,\\nconsequentemente, o valor da raiz também é no máximo 14. (f) O segundo sucessor de \\nD\\n vale 5 e,\\nassim, novamente precisamos continuar a exploração. O terceiro sucessor vale 2; agora, \\nD\\n vale\\nexatamente 2. A decisão de MAX na raiz é efetuar o movimento para \\nB\\n, o que nos dá o valor 3.\\nIsso também pode ser visto como uma simplificação da fórmula de VALOR-MINIMAX. Sejam \\nx\\n e\\ny\\n valores dos dois sucessores não avaliados do nó \\nC\\n na \\nFigura 5.5\\n e seja \\nz\\n o mínimo entre \\nx\\n e \\ny\\n.\\nEntão, o valor do nó raiz é dado por:\\nEm outras palavras, o valor da raiz e, consequentemente, a decisão minimax são \\nindependentes\\ndos valores das folhas podadas \\nx\\n e \\ny\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 210}),\n",
       " Document(page_content='A poda alfa-beta pode ser aplicada a árvores de qualquer profundidade e frequentemente é\\npossível podar subárvores inteiras em lugar de podar apenas folhas. O princípio geral é este:\\nconsidere um nó \\nn\\n em algum lugar na árvore (veja a \\nFigura 5.6\\n), tal que o Jogador tenha a escolha de\\nmovimento até esse nó. Se o Jogador tiver uma escolha melhor \\nm\\n no nó pai de \\nn\\n ou em qualquer\\nponto de escolha adicional acima dele, então \\nn nunca será alcançado em um jogo real\\n. Assim, uma\\nvez que descobrimos o suficiente sobre \\nn\\n (examinando alguns de seus descendentes) para chegar a\\nessa conclusão, poderemos podá-lo.\\nFigura 5.6\\n O caso geral de poda alfa-beta. Se \\nm\\n é melhor que \\nn\\n para o Jogador, nunca chegaremos a\\nn\\n em um jogo.\\nLembre-se de que a busca minimax é do tipo em profundidade; então, em qualquer instante só\\ntemos de considerar os nós ao longo de um único caminho na árvore. A poda alfa-beta obtém seu\\nnome a partir dos dois parâmetros a seguir, que descrevem limites sobre os valores propagados de\\nvolta que aparecem em qualquer lugar ao longo do caminho:\\nα\\n = o valor da melhor escolha (isto é, a de valor mais alto) que encontramos até o momento em\\nqualquer ponto de escolha ao longo do caminho para MAX.\\nβ\\n = o valor da melhor escolha (isto é, a de valor mais baixo) que encontramos até agora em\\nqualquer ponto de escolha ao longo do caminho para MIN.\\nA busca alfa-beta atualiza os valores de \\nα\\n e \\nβ\\n à medida que prossegue e poda as ramificações\\nrestantes em um nó (isto é, encerra a chamada recursiva) tão logo se sabe que o valor do nó corrente\\né pior que o valor corrente de \\nα\\n ou \\nβ\\n para MAX ou MIN, respectivamente. O algoritmo completo é\\nmostrado na \\nFigura 5.7\\n. Encorajamos o leitor a acompanhar seu comportamento quando ele é\\naplicado à árvore da \\nFigura 5.5\\n.\\nfunção\\n BUSCA-ALFA-BETA(\\nestado\\n) \\nretorna\\n uma ação\\n    \\nv\\n ← VALOR-MAX(\\nestado\\n, –∞, +∞)\\n    \\nretornar\\n a \\nação\\n em AÇÕES(\\nestado\\n) com valor \\nv\\n_____________________________________________________________________________________________________________\\nfunção\\n VALOR-MAX(\\nestado\\n, \\nα\\n, \\nβ\\n) \\nretorna\\n \\num valor de utilidade\\n    \\nse\\n TESTE-TERMINAL(\\nestado\\n) \\nentão retornar\\n UTILIDADE(\\nestado\\n)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 211}),\n",
       " Document(page_content='v\\n← –∞\\n    \\npara cada\\n \\na,\\n em AÇÕES(\\nestado\\n) \\nfaça\\n        \\nv\\n ← MAX(\\nv\\n, VALOR-MIN(RESULTADO(\\ns\\n, \\na\\n), \\nα\\n, \\nβ\\n))\\n        \\nse\\n \\nv\\n ≥ β \\nentão retornar\\n \\nv\\n        α ← MAX(α, \\nv\\n)\\n    \\nretornar\\n \\nv\\n_____________________________________________________________________________________________________________\\nfunção\\n VALOR-MIN(\\nestado\\n, \\nα\\n, \\nβ\\n) \\nretorna\\n \\num valor de utilidade\\n    \\nse\\n TESTE-TERMINAL(\\nestado\\n) \\nentão retornar\\n UTILIDADE(\\nestado\\n)\\n    \\nv\\n ← +∞\\n    \\npara cada\\n \\na,\\n em AÇÕES(\\nestado\\n) \\nfaça\\n        \\nv\\n ← MIN(\\nv\\n, VALOR-MIN(RESULTADO(\\ns\\n, \\na\\n), \\nα\\n, \\nβ\\n))\\n        \\nse\\n \\nv\\n ≤ \\na\\n \\nentão retornar\\n \\nv\\n        \\nβ\\n ← MIN(\\nβ\\n, \\nv\\n)\\n    \\nretornar\\n \\nv\\nFigura 5.7\\n O algoritmo de busca alfa-beta. Note que essas rotinas são idênticas às rotinas de\\nMINIMAX da \\nFigura 5.3\\n, com exceção das duas linhas em cada uma das funções VALOR-MIN e\\nVALOR-MAX que mantêm \\nα\\n e \\nβ\\n (e da necessidade de repassar esses parâmetros).\\n5.3.1 Ordenação de movimentos\\nA efetividade da poda alfa-beta é altamente dependente da ordem em que os estados são\\nexaminados. Por exemplo, na \\nFigura 5.5\\n(e) e (f), não poderíamos podar quaisquer sucessores de \\nD\\nporque os piores sucessores (do ponto de vista de MIN) foram gerados primeiro. Se o terceiro\\nsucessor tivesse sido gerado primeiro, seríamos capazes de podar os outros dois. Isso sugere que\\npoderia valer a pena tentar examinar primeiro os sucessores que têm probabilidade de serem\\nmelhores.\\nSe supusermos que isso pode ser feito,\\n2\\n então o resultado será que alfa-beta precisará examinar\\napenas \\nO\\n(\\nb\\nm\\n/2\\n) nós para escolher o melhor movimento, em vez de \\nO\\n(\\nb\\nm\\n) para minimax. Isso significa\\nque o fator de ramificação efetivo se tornará \\n em vez de \\nb\\n — no caso do xadrez, 6 em vez de 35.\\nEm outras palavras, alfa-beta poderá resolver uma árvore aproximadamente duas vezes tão profunda\\ncomo minimax no mesmo período de tempo. Se os sucessores forem examinados em ordem aleatória,\\nem vez de se tomar o melhor em primeiro lugar, o número total de nós examinados será cerca de\\nO\\n(\\nb\\n3\\nm\\n/4\\n) para um valor moderado de \\nb\\n. No caso do xadrez, uma função de ordenação bastante\\nsimples (como experimentar capturas primeiro, depois ameaças, depois movimentos para a frente e,\\nem seguida, movimentos para trás) levará você a uma distância de aproximadamente duas vezes o\\nresultado do melhor caso, \\nO\\n(\\nb\\nm\\n/2\\n).\\nAcrescentar esquemas dinâmicos de ordenação de movimentos, como tentar primeiro os\\nmovimentos considerados os melhores da última vez, nos levará até bem perto do limite teórico. O\\npassado pode ser o lance anterior — muitas vezes, as mesmas ameaças permanecem — ou poderia', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 212}),\n",
       " Document(page_content='vir da exploração do lance atual. Uma maneira de obter informações do lance atual é com busca de\\naprofundamento iterativo da pesquisa. Primeiro, pesquise uma jogada profunda e registre o melhor\\ncaminho de movimentos. Em seguida, busque uma jogada mais profunda, mas utilize o caminho\\nregistrado para informar a ordenação do movimento. Como vimos no Capítulo 3, o aprofundamento\\niterativo em uma árvore de jogo exponencial acrescenta apenas uma fração constante para o tempo\\ntotal de busca, que pode ser mais do que compensado por uma melhor ordenação de movimento. As\\nmelhores jogadas são muitas vezes chamadas de \\nlances mortais\\n e tentá-los de primeira é chamado de\\nheurística de lance mortal.\\nNo Capítulo 3, observamos que estados repetidos na árvore de busca podem causar um aumento\\nexponencial no custo da busca. Em muitos jogos, estados repetidos ocorrem com frequência devido a\\ntransposições\\n — permutações diferentes da mesma sequência que terminam na mesma posição. Por\\nexemplo, se as brancas têm um movimento \\na\\n1\\n que pode ser respondido pelas pretas com \\nb\\n1\\n e um\\nmovimento não relacionado \\na\\n2\\n no outro lado do tabuleiro que pode ser respondidos por \\nb\\n2\\n, as\\nsequências [\\na\\n1\\n, \\nb\\n1\\n, \\na\\n2\\n, \\nb\\n2\\n] e [\\na\\n1\\n, \\nb\\n2\\n, \\na\\n2\\n, \\nb\\n1\\n] terminarão na mesma posição. Vale a pena armazenar a\\navaliação dessa posição resultante em uma tabela de hash na primeira vez em que ela for encontrada,\\nde forma que não tenhamos de recalculá-la em ocorrências subsequentes.\\nA tabela de hash de posições já vistas é tradicionalmente chamada \\ntabela de transposição\\n; em\\nessência, ela é idêntica à lista \\nexplorada\\n em BUSCA-EM-GRAFO (\\nSeção 3.3\\n). O uso de uma tabela\\nde transposição pode ter um efeito drástico, chegando às vezes a duplicar a profundidade de busca\\nacessível no xadrez. Por outro lado, se estivermos avaliando um milhão de nós por segundo, não será\\nprático manter \\ntodos\\n eles na tabela de transposição. São usadas diversas estratégias para escolher os\\nnós que devem ser mantidos e os que devem ser descartados.\\n5.4 DECISÕES IMPERFEITAS EM TEMPO REAL\\nO algoritmo minimax gera o espaço de busca do jogo inteiro, enquanto o algoritmo alfa-beta nos\\npermite podar grandes partes desse espaço. Porém, alfa-beta ainda tem de fazer a busca em toda a\\ndistância até os estados terminais, pelo menos para uma parte do espaço de busca. Em geral, essa\\nprofundidade não é prática porque os movimentos devem ser realizados em um período de tempo\\nrazoável — normalmente por alguns minutos, no máximo. O artigo de Claude Shannon, \\nProgramming\\na computer for playing chess\\n (1950), propunha em vez disso que os programas cortassem a busca\\nmais cedo e aplicassem uma \\nfunção de avaliação\\n heurística aos estados da busca, transformando\\nefetivamente nós não terminais em folhas terminais. Em outras palavras, a sugestão é alterar minimax\\nou alfa-beta de duas maneiras: substituir a função utilidade por uma função de avaliação de heurística\\nAVAL, que fornece uma estimativa da utilidade da posição, e o teste de término por um \\nteste de\\ncorte\\n que decide quando aplicar AVAL. Isso nos dá o seguinte para minimax heurística para o estado\\ns\\n e profundidade máxima \\nd\\n:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 213}),\n",
       " Document(page_content='5.4.1 Funções de avaliação\\nUma função de avaliação retorna uma \\nestimativa\\n da utilidade esperada do jogo, a partir de uma\\ndada posição, da mesma forma que as funções de heurísticas do Capítulo 3 retornam uma estimativa\\nda distância até a meta.\\nA ideia de um avaliador não era nova quando Shannon a propôs. Durante séculos, os jogadores de\\nxadrez (e os aficionados por outros jogos) desenvolveram meios de julgar o valor de uma posição\\nporque os seres humanos são ainda mais limitados que os programas de computador no volume de\\nbusca que podem realizar. Deve ficar claro que o desempenho de um programa de jogos depende\\nfortemente da qualidade de sua função de avaliação. Uma função de avaliação inexata guiará um\\nagente em direção a posições que acabarão por ser perdidas. Qual é a maneira exata de projetarmos\\nboas funções de avaliação?\\nPrimeiro, a função de avaliação deve ordenar os estados \\nterminais\\n do mesmo modo que a\\nverdadeira função utilidade: estados que são vitórias que devem avaliar empates, que por sua vez\\ndevem ser melhores que perdas. Caso contrário, um agente que utilizasse a função de avaliação\\npoderia errar, mesmo que pudesse antecipar todos os movimentos até o fim do jogo. Em segundo\\nlugar, a computação não deve demorar tempo demais! (O ponto fundamental é a busca mais rápida.)\\nEm terceiro lugar, no caso de estados não terminais, a função de avaliação deve estar fortemente\\nrelacionada com as chances reais de vitória.\\nO leitor deve ter se surpreendido com a expressão “chances de vitória”. Afinal, o xadrez não é um\\njogo de azar: conhecemos o estado corrente com certeza e não há dados envolvidos no processo.\\nContudo, se a busca tiver de ser cortada em estados não terminais, o algoritmo será necessariamente\\nincerto\\n sobre os resultados finais desses estados. Esse tipo de incerteza é induzido por limitações\\ncomputacionais, não informativas.\\nDado o volume limitado de computação que a função de avaliação pode realizar para determinado\\nestado, o melhor que ela pode fazer é arriscar um palpite sobre o resultado final.\\nVamos tornar essa ideia mais concreta. A maioria das funções de avaliação atua calculando\\ndiversas \\ncaracterísticas\\n do estado — por exemplo, no xadrez, teríamos características para o\\nnúmero de peões brancos, pretos, rainhas brancas, pretas, e assim por diante. Consideradas em\\nconjunto, as características definem diversas \\ncategorias\\n ou \\nclasses de equivalência\\n de estados: os\\nestados de cada categoria têm os mesmos valores para todas as características. Por exemplo, ao final\\ndo jogo, uma categoria contém ao todo dois peões \\nversus\\n um peão. Qualquer categoria específica, em\\ntermos gerais, conterá alguns estados que levam a vitórias, alguns que levam a empates e alguns que\\nlevam a derrotas. A função de avaliação não tem como saber quais são os estados de cada grupo,\\nmas pode retornar um único valor capaz de refletir a \\nproporção\\n de estados que conduzem a cada\\nresultado. Por exemplo, vamos supor que nossa experiência sugira que 72% dos estados encontrados\\nna categoria dois peões \\nversus\\n um peão levem a uma vitória (com utilidade +1); 20% levem a uma\\nderrota (0) e 8% a um empate (1/2). Então, uma avaliação razoável dos estados na categoria é a\\nmédia ponderada ou o \\nvalor esperado\\n: (0,72 × +1) + (0,20 × 0) + (0,08 × 1/2) = 0,76. Em princípio,\\no valor esperado pode ser determinado para cada categoria, o que resulta em uma função de\\navaliação que funciona para qualquer estado. Como ocorre com estados terminais, a função de\\navaliação não precisa retornar valores esperados reais, desde que a \\nordenação\\n dos estados seja a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 214}),\n",
       " Document(page_content='mesma.\\nNa prática, essa espécie de análise exige muitas categorias e, consequentemente, muita experiência\\npara estimar todas as probabilidades de vitória. Em vez disso, a maioria das funções de avaliação\\ncalcula contribuições numéricas separadas de cada característica e depois as \\ncombina\\n para encontrar\\no valor total. Por exemplo, os livros introdutórios de xadrez fornecem um \\nvalor material\\n aproximado\\npara cada peça: cada peão vale 1, um cavalo ou um bispo pena 3, uma torre 5 e a rainha 9. Outras\\ncaracterísticas, como “boa estrutura de peões” e “segurança do rei” poderiam valer, digamos, metade\\nde um peão. Esses valores de características são então simplesmente somados para se obter a\\navaliação da posição.\\nUma vantagem segura equivalente a um peão fornece uma probabilidade substancial de vitória, e\\numa vantagem segura equivalente a três peões deve proporcionar uma vitória quase certa, como\\nilustra a \\nFigura 5.8\\n(a). Matematicamente, essa espécie de função de avaliação é chamada \\nfunção\\nlinear ponderada\\n porque pode ser expressa como:\\nFigura 5.8\\n Duas posições de xadrez, que diferem apenas na posição da torre na parte inferior direita.\\nEm (a), as pretas têm uma vantagem de um cavalo e dois peões, que deveria ser o suficiente para\\nvencer o jogo. Em (b), a branca vai capturar a rainha, dando-lhe uma vantagem que deveria ser forte\\no suficiente para vencer.\\nonde cada \\nw\\ni\\n é um peso e cada \\nf\\ni\\n é uma característica da posição. No caso do xadrez, \\nf\\ni\\n poderia\\nrepresentar os números de cada tipo de peça no tabuleiro, \\nw\\ni\\n poderia corresponder aos valores das\\npeças (1 para peão, 3 para bispo etc.).\\nSomar os valores de características parece algo razoável, mas, na verdade, envolve uma\\nsuposição muito forte: que a contribuição de cada característica é \\nindependente\\n dos valores das\\noutras características. Por exemplo, a atribuição do valor 3 a um bispo ignora o fato de que os bispos\\nsão mais poderosos no fim do jogo, quando têm bastante espaço de manobra.\\nPor essa razão, os programas atuais de xadrez e de outros jogos também utilizam combinações \\nnão\\nlineares\\n de características. Por exemplo, um par de bispos poderia valer um pouco mais que o dobro', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 215}),\n",
       " Document(page_content='do valor de um único bispo, e um bispo poderia valer mais no fim do jogo que no início (isto é,\\nquando a característica do \\nnúmero de lances\\n for alta ou a característica do \\nnúmero de peças\\nrestantes\\n for baixa).\\nO leitor atento notará que as características e os pesos \\nnão\\n fazem parte das regras do xadrez! Eles\\nvêm de séculos de experiência humana no jogo de xadrez. Em jogos nos quais esse tipo de\\nexperiência não está disponível, os pesos da função de avaliação podem ser estimados pelas técnicas\\nde aprendizado de máquina do Capítulo 18. Vale a pena reafirmar que a aplicação dessas técnicas ao\\nxadrez confirma que um bispo vale realmente cerca de três peões.\\n5.4.2 Busca com corte\\nA próxima etapa é modificar BUSCA-ALFA-BETA, de modo que ela chame a função heurística\\nAVAL quando for apropriado cortar a busca. Em termos de implementação, substituímos as duas\\nlinhas da \\nFigura 5.7\\n que mencionam TESTE-TERMINAL pela linha a seguir:\\nse\\n TESTE-DE-CORTE(\\nestado\\n, \\nprofundidade\\n) \\nentão retornar\\n AVAL(\\nestado\\n).\\nTambém devemos providenciar alguma notação para que a \\nprofundidade\\n corrente seja\\nincrementada em cada chamada recursiva. A abordagem mais direta para controlar a quantidade de\\nbusca é definir um limite de profundidade fixo, a fim de que TESTE-DE-CORTE (\\nestado\\n,\\nprofundidade\\n) retorne \\nverdadeiro\\n para toda \\nprofundidade\\n maior que alguma profundidade fixa \\nd\\n(ela também deve retornar \\nverdadeiro\\n para todos os estados terminais, como fazia TESTE-\\nTERMINAL). A profundidade \\nd\\n é escolhida de modo que um movimento seja selecionado dentro do\\ntempo previsto. Uma abordagem mais resistente é aplicar o aprofundamento iterativo (veja o\\nCapítulo 3). Quando o tempo se esgota, o programa retorna o movimento selecionado pela busca\\nmais profunda concluída. Como bônus, o aprofundamento iterativo também ajuda com a ordenação do\\nmovimento.\\nNo entanto, essas simples abordagens podem levar a erros, devido à natureza aproximada da\\nfunção de avaliação. Considere mais uma vez a função de avaliação simples para xadrez, baseada na\\nvantagem material. Suponha que o programa pesquise até a profundidade limite, alcançando a\\nposição da \\nFigura 5.8\\n(b), onde as pretas têm a vantagem de um cavalo e dois peões. Isso seria\\nreportado como o valor heurístico do estado, declarando-se assim que o estado será uma vitória\\nprovável das peças pretas. Porém, o próximo movimento das brancas captura a rainha preta sem\\nqualquer compensação. Portanto, a posição resulta na realidade em uma vitória das brancas, mas isso\\nsó pode ser visto observando-se mais uma jogada à frente.\\nÉ óbvio que é necessário um teste de corte mais sofisticado. A função de avaliação deve ser\\naplicada apenas a posições \\nquiescentes\\n — isto é, posições em que é improvável haver grandes\\nmudanças de valores no futuro próximo. Por exemplo, no xadrez, as posições em que podem ser\\nfeitas capturas favoráveis não são quiescentes para uma função de avaliação que simplesmente efetua\\na contagem material. Posições não quiescentes podem ser expandidas adiante, até serem alcançadas\\nposições quiescentes. Essa busca extra é chamada de \\nbusca de quiescência\\n; às vezes, ela se restringe\\na considerar apenas certos tipos de movimentos, como movimentos de captura, que resolverão com', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 216}),\n",
       " Document(page_content='rapidez as incertezas da posição.\\nO \\nefeito de horizonte\\n é mais difícil de eliminar. Ele surge quando o programa está enfrentando\\num movimento feito pelo oponente que causa sérios danos e, em última instância, inevitável, mas\\npoderia ser evitado temporariamente, através de táticas de adiamento. Considere o jogo de xadrez na\\nFigura 5.9\\n. É claro que não há caminho para o bispo preto fugir. Por exemplo, a torre branca pode\\ncapturá-lo movendo-se para h1, depois a1, depois a2; em seguida, uma captura à profundidade da\\njogada 6. Mas as pretas têm uma sequência de movimentos que empurra a captura do bispo “além do\\nhorizonte”. Suponha que os pretas busquem a profundidade da jogada 8. A maioria dos movimentos\\ndas pretas vai levar à captura eventual do bispo e, portanto, serão marcadas como lances “ruins”.\\nMas as pretas considerarão o xeque no rei branco com o peão em e4. Isso fará com que o rei capture\\no peão. Agora as pretas vão considerar o xeque novamente, com o peão em f5, levando a outra\\ncaptura de peão. Isso leva quatro jogadas, e as quatro jogadas restantes não são suficientes para\\ncapturar o bispo. As pretas pensam que a linha de jogo poupou o bispo, ao preço de dois peões,\\nquando na verdade tudo o que foi feito é empurrar a inevitável captura do bispo para além do\\nhorizonte que as pretas podiam visualizar.\\nFigura 5.9\\n O efeito de horizonte. Com as pretas se movendo, o bispo preto está certamente\\ncondenado. Mas as pretas podem evitar esse evento marcando o rei branco com seus peões,\\nobrigando o rei a capturar os peões. Isso empurra a perda inevitável do bispo sobre o horizonte e,\\nportanto, o sacrifício dos peões é visto pelo algoritmo de busca como boas jogadas e não como más.\\nUma estratégia para mitigar o efeito horizonte é a \\nextensão singular\\n, um movimento que é\\n“claramente melhor” do que todos os outros movimentos em determinada posição. Uma vez\\ndescoberto em qualquer lugar da árvore no curso de uma busca, esse movimento singular é lembrado.\\nQuando a busca atinge o limite de profundidade normal, o algoritmo verifica se a extensão singular é\\num movimento legal; se for, permite que o lance seja considerado. Isso faz com que a árvore fique\\nmais profunda, mas, havendo poucas extensões singulares, não adicionará muitos nós totais à árvore.\\n5.4.3 Poda adiantada\\nAté agora, mencionamos a busca com corte em certo nível e dissemos que a realização da busca', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 217}),\n",
       " Document(page_content='alfa-beta não tem nenhum efeito comprovado sobre o resultado (pelo menos com respeito aos valores\\nde avaliação heurística). Também é possível efetuar a \\npoda adiantada\\n, significando que alguns\\nmovimentos em dado nó serão podados de imediato, sem consideração adicional. É claro que a\\nmaioria dos seres humanos que jogam xadrez só considera alguns movimentos a partir de cada\\nposição (pelo menos de forma consciente). Uma abordagem à poda adiantada é a \\nbusca em feixe\\n: em\\ncada jogada, considera-se apenas um “feixe” das \\nn\\n melhores jogadas (de acordo com a função de\\navaliação) em vez de considerar todos os movimentos possíveis. Infelizmente, a abordagem é\\nbastante perigosa porque não há nenhuma garantia de que o melhor movimento não será podado.\\nO algoritmo PROBCUT, ou corte probabilístico (Buro, 1995), é uma versão da poda adiantada de\\nbusca alfa-beta que utiliza a estatística adquirida com a experiência prévia para diminuir a chance de\\na melhor jogada ser podada. A busca alfa-beta poda qualquer nó que esteja \\nprovavelmente\\n fora da\\njanela (\\nα\\n, \\nβ\\n) atual. O PROBCUT também poda nós que \\nprovavelmente\\n estão fora da janela. Ela\\ncalcula essa probabilidade fazendo uma busca superficial para calcular o valor propagado \\nv\\n de um\\nnó e, em seguida, usa a experiência passada para estimar como é que a pontuação de \\nv\\n à\\nprofundidade \\nd\\n na árvore ficaria fora de (\\nα\\n, \\nβ\\n). Buro aplicou essa técnica ao programa Othello,\\nLOGISTELLO, e descobriu que uma versão de seu programa com PROBCUT bateu a versão regular\\nem 64% do tempo, mesmo quando se dá o dobro de tempo à versão regular.\\nA combinação de todas as técnicas descritas aqui resulta em um programa que pode jogar xadrez\\n(ou outros jogos) de modo respeitável. Vamos supor que implementamos uma função de avaliação\\npara xadrez, um teste de corte razoável com uma busca de quiescência, e ainda uma grande tabela de\\ntransposição. Vamos supor também que, depois de meses de tediosa escovação de bits, podemos\\ngerar e avaliar cerca de um milhão de nós por segundo no PC mais atual, o que nos permite buscar\\naproximadamente 200 milhões de nós por movimento sob controles de tempo-padrão (três minutos\\npor movimento). O fator de ramificação para xadrez é cerca de 35 em média, e 35\\n5\\n é\\naproximadamente igual a 50 milhões; assim, se usássemos a busca minimax, só poderíamos examinar\\ncerca de cinco jogadas à frente. Embora não seja incompetente, tal programa pode ser enganado com\\nfacilidade por um jogador de xadrez humano médio, que ocasionalmente pode planejar seis ou oito\\njogadas à frente. Com a busca alfa-beta, chegamos a cerca de 10 jogadas, o que resulta em um nível\\nde desempenho de especialista. A \\nSeção 5.8\\n descreve técnicas adicionais de poda que podem\\nestender a profundidade de busca efetiva a aproximadamente 14 jogadas. Para alcançar o \\nstatus\\n de\\ngrande mestre, precisaríamos de uma função de avaliação extensivamente ajustada e de um grande\\nbanco de dados de movimentos ótimos de abertura e de fim de jogo\\n5.4.4 Busca \\nversus\\n acesso\\nDe alguma forma parece um exagero que um programa de xadrez inicie um jogo, considerando uma\\nárvore de um bilhão de estados de jogo, apenas para concluir que moverá o seu peão para e4. Por\\ncerca de um século, existem livros disponíveis sobre xadrez que descrevem boas jogadas na abertura\\ne encerramento (Tattersall, 1911). Não é de estranhar, portanto, que muitos programas de jogo\\nutilizem a \\ntabela de acesso\\n em vez de busca para abertura e encerramento dos jogos.\\nPara as aberturas, o computador conta principalmente com a perícia dos seres humanos. O melhor', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 218}),\n",
       " Document(page_content='conselho dos peritos humanos de como jogar cada abertura é copiado de livros e introduzido em\\ntabelas para uso do computador. No entanto, os computadores também podem coletar estatísticas de\\num banco de dados de partidas previamente jogadas para ver que sequências de abertura conduzem a\\numa vitória na maioria das vezes. Nos movimentos iniciais há poucas opções e, desse modo,\\ncomentários de peritos e jogos passados dos quais extrair. Normalmente, depois de 10 movimentos\\ntermina-se em uma posição raramente vista, e o programa deve mudar da tabela de acesso para\\nbusca.\\nPerto do final do jogo há novamente poucas posições possíveis e, assim, mais chance de fazer\\nacesso. Mas aqui é o computador que tem a experiência: a análise de computador de finais de jogos\\nvai muito além de qualquer coisa alcançada pelos seres humanos. Um ser humano pode dizer-lhe a\\nestratégia geral para jogar um final do jogo rei e torre \\nversus\\n rei (RTR): reduzir a mobilidade do rei\\noposto, encurralando-o em um canto do tabuleiro, utilizando o seu rei para evitar que o adversário\\nescape do aperto. Outros finais, como rei, bispo e cavalo \\nversus\\n rei (RBCR), são difíceis de dominar\\ne não têm uma descrição sucinta da estratégia. Um computador, por outro lado, pode \\nresolver\\ncompletamente o fim do jogo, produzindo um \\nprograma de ação\\n, que é um mapeamento de todos os\\nestados possíveis para a melhor jogada nesse estado. Então podemos apenas procurar pela melhor\\njogada em vez de recalculá-la novamente. Qual será o tamanho da tabela de acesso RBCR? Acontece\\nque há 462 maneiras como dois reis podem ser colocados no tabuleiro sem estar adjacentes. Depois\\nde os reis serem colocados, haverá 62 quadrados vazios para o bispo, 61 para o cavalo e dois\\njogadores possíveis para o próximo movimento; portanto, haverá apenas 462 × 62 × 61 × 2 =\\n3.494.568 posições possíveis. Algumas dessas são xeque-mates; marque-as como tal em uma tabela.\\nEm seguida, faça uma busca minimax \\nretrógrada:\\n reverter as regras do xadrez para retroceder em\\nvez de mover. Qualquer movimento das brancas que, não importa com qual movimento as pretas\\nrespondam, termina em uma posição marcada como vitória, devendo ser também uma vitória.\\nContinue essa busca até que todas as 3.494.568 posições estejam resolvidas como vitória, perda ou\\nempate e você terá uma tabela de acesso infalível para todos os finais de jogos RBCR.\\nUtilizando essa técnica e com grande esforço de truques de otimização, Ken Thompson (1986,\\n1996) e Lewis Stiller (1992, 1996) resolveram todos os finais de jogos de xadrez com até cinco\\npeças e alguns com seis peças, tornando-os disponíveis na Internet. Stiller descobriu um caso em que\\nexistia um mate forçado, mas exigia 262 movimentos, o que causou alguma consternação porque as\\nregras do xadrez exigem que haja uma captura ou um movimento de um peão dentro de 50 lances.\\nMais tarde, o trabalho de Marc Bourzutschky e Yakov Konoval (Bourzutschky, 2006) resolveu todos\\nos finais de jogo de seis peças sem peão e alguns de sete peças, havendo um final de jogo RTCRTBC\\n(rei, torre, cavalo, rei, torre, bispo, cavalo) que com o melhor jogo requer 517 movimentos até a\\ncaptura, que então conduz a um mate.\\nSe pudéssemos estender o tabuleiro de xadrez de final de jogo de seis para 32 peças, as brancas\\nsaberiam no movimento de abertura se seria uma vitória, perda ou empate. Isso não aconteceu até\\nagora para o xadrez, mas tem acontecido para damas, como é explicado na seção de notas históricas.\\n5.5 JOGOS ESTOCÁSTICOS', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 219}),\n",
       " Document(page_content='Na vida real, existem muitos eventos externos imprevisíveis que podem nos colocar em situações\\ninesperadas. Muitos jogos refletem essa imprevisibilidade, incluindo um elemento aleatório, como o\\nlançamento de dados. Nós os chamamos de \\njogos estocásticos\\n. O gamão é um jogo típico que\\ncombina sorte e habilidade. Os dados são rolados no início da ação de cada jogador para determinar\\nos movimentos válidos. Por exemplo, na posição do jogo de gamão representada na \\nFigura 5.10\\n, as\\npeças brancas tiveram uma rolagem de dados com seis e cinco pontos e têm quatro movimentos\\npossíveis.\\nFigura 5.10\\n Uma posição típica em gamão. O objetivo do jogo é mover todas as peças para fora do\\ntabuleiro. As brancas se movimentam no sentido horário (para a direita) até a posição 25, e as pretas\\nse movimentam no sentido anti-horário (para a esquerda) até 0. Uma peça pode se mover para\\nqualquer posição, a menos que existam várias peças oponentes nessa posição; se houver um\\noponente, ele será capturado e terá de recomeçar. Na posição mostrada, as brancas obtiveram 6 e 5\\nnos dados e devem escolher entre quatro movimentos válidos: (5–10, 5–11), (5–11, 19–24), (5–10,\\n10–16) e (5–11, 11–16), onde a notação (5–11, 11–16) significa mover uma peça da posição 5 para\\na 11 e depois mover uma peça da 11 para a 16.\\nEmbora o jogador com as brancas saiba quais são seus próprios movimentos válidos, ele não sabe\\nqual será a jogada das pretas e, portanto, não sabe quais serão os movimentos válidos das pretas.\\nIsso significa que o jogador com as brancas não pode construir uma árvore de jogo-padrão do tipo\\nque vimos em xadrez e no jogo da velha. Uma árvore de jogo em gamão deve incluir \\nnós de acaso\\nalém de nós MAX e MIN. Os nós de acaso são mostrados como circunferências na \\nFigura 5.11\\n. As\\nramificações que levam a cada nó de acaso denotam as jogadas de dados possíveis, e cada uma é\\nidentificada com a jogada e a chance de que ela ocorra. Existem 36 maneiras de rolar dois dados,\\ntodas igualmente prováveis; porém, como 6–5 é igual a 5–6, existem apenas 21 lançamentos\\ndistintos. Os seis duplos (1–1 a 6–6) têm uma chance de 1/36; dizemos então que \\nP\\n(1−1) = 1/36. Os\\noutros 15 lançamentos distintos têm a probabilidade de 1/18 cada.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 220}),\n",
       " Document(page_content='Figura 5.11\\n Árvore de jogo esquemática para uma posição de gamão.\\nA próxima etapa é entender como tomar decisões corretas. É óbvio que desejaremos escolher o\\nmovimento que leve à melhor posição. Porém, as posições resultantes não têm valores minimax\\ndefinidos. Em vez disso, só podemos calcular o \\nvalor esperado\\n de uma posição: a média sobre\\ntodos os resultados possíveis dos nós de acaso.\\nIsso nos leva a generalizar o \\nvalor minimax\\n para jogos determinísticos até um \\nvalor de\\nexpectiminimax\\n para jogos com nós de acaso. Nós terminais e nós de MAX e MIN (para os quais o\\nlançamento de dados é conhecido) funcionam exatamente do mesmo modo que antes.\\nPara os nós de acaso calculamos o valor esperado, que é a soma do valor de todos os resultados,\\nponderada pela probabilidade de cada ação do acaso:\\nonde \\nr\\n representa um possível lançamento de dados (ou outro evento ao acaso) e RESULTADO (\\ns\\n, \\nr\\n)\\né o mesmo estado que \\ns\\n, com o fato adicional de que o resultado do lançamento de dados é \\nr\\n.\\n5.5.1 Funções de avaliação para os jogos de azar\\nComo ocorre no caso de minimax, a aproximação óbvia a fazer com expectiminimax é cortar a\\nbusca em certo ponto e aplicar uma função de avaliação a cada folha. Poderíamos pensar que as\\nfunções de avaliação de jogos como gamão devem ser exatamente como as funções de avaliação para\\nxadrez — elas só precisam fornecer pontuações mais altas para posições melhores. Porém, de fato, a\\npresença de nós de acaso significa que temos de ser mais cuidadosos sobre o significado dos valores', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 221}),\n",
       " Document(page_content='de avaliação. A \\nFigura 5.12\\n mostra o que acontece: com uma função de avaliação que atribui valores\\n[1, 2, 3, 4] às folhas, o movimento \\na\\n1\\n é melhor; com valores [1, 20, 30, 400], o movimento \\na\\n2\\n é\\nmelhor. Consequentemente, o programa se comportará de forma bastante diferente se fizermos uma\\nmudança na escala de alguns valores de avaliação! Ocorre que, para evitar essa sensibilidade, a\\nfunção de avaliação deve ser uma transformação linear positiva da probabilidade de vencer a partir\\nde uma posição (ou, de modo mais geral, da utilidade esperada da posição). Essa é uma propriedade\\nimportante e geral de situações em que a incerteza está envolvida, como veremos com mais detalhes\\nno Capítulo 16.\\nFigura 5.12\\n Uma transformação com preservação da ordem em valores de folhas altera o melhor\\nmovimento.\\nSe o programa conhecesse com antecedência todos os lançamentos de dados que ocorreriam no\\nrestante do jogo, a resolução de um jogo com dados seria muito semelhante à resolução de um jogo\\nsem dados, o que minimax faz no tempo \\nO\\n(\\nb\\nm\\n), onde \\nb\\n é o fator de ramificação e \\nm\\n é a profundidade\\nmáxima da árvore de jogo. Como expectiminimax também está considerando todas as sequências de\\nlançamentos de dados possíveis, ele levará o tempo \\nO\\n(\\nb\\nm\\nn\\nm\\n), onde \\nn\\n é o número de lançamentos\\ndistintos.\\nAinda que a profundidade da busca se limitasse a alguma profundidade pequena \\nd\\n, o custo extra\\ncomparado com o de minimax tornaria pouco realista considerar a possibilidade de examinar uma\\ndistância muito grande à frente na maioria dos jogos de azar. Em gamão, \\nn\\n é 21e \\nb\\n em geral é cerca\\nde 20, mas, em algumas situações, ele pode chegar a 4.000 em lançamentos de dados que resultam em\\nvalores duplos. Talvez essas jogadas sejam tudo o que poderíamos administrar.\\nOutro modo de pensar no problema é: a vantagem de alfa-beta é que ela ignora desenvolvimentos\\nfuturos que simplesmente não irão acontecer, dada a melhor jogada. Desse modo, ela se concentra em\\nocorrências prováveis. Em jogos com dados, não há \\nnenhuma\\n sequência provável de movimentos\\nporque, para que esses movimentos ocorressem, os dados primeiro teriam de cair da maneira correta\\npara torná-los válidos. Esse é um problema geral sempre que a incerteza entra em cena: as\\npossibilidades são enormemente multiplicadas, e a formação de planos de ação detalhados se torna\\ninútil porque o mundo talvez não acompanhe o jogo.\\nSem dúvida deve ter ocorrido ao leitor que talvez algo como a poda alfa-beta poderia ser aplicada\\na árvores de jogos com nós de acaso. Na verdade, isso é possível. A análise para nós de MIN e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 222}),\n",
       " Document(page_content='MAX fica inalterada, mas também podemos podar nós de acaso, usando um pouco de engenhosidade.\\nConsidere o nó de acaso \\nC\\n da \\nFigura 5.11\\n e o que acontece ao seu valor à medida que examinamos e\\navaliamos seus filhos. É possível encontrar um limite superior sobre o valor de \\nC\\n antes de\\nexaminarmos todos os seus filhos? (Lembre-se de que alfa-beta precisa disso para podar um nó e sua\\nsubárvore.) À primeira vista, pode parecer impossível porque o valor de \\nC\\n é a \\nmédia\\n dos valores de\\nseus filhos e, a fim de calcular a média de um conjunto de números, temos que verificar todos os\\nnúmeros. No entanto, se impusermos limites sobre os valores possíveis da função utilidade,\\npoderemos chegar a limites para a média sem verificar todos os números. Por exemplo, se dissermos\\nque todos os valores de utilidade estão entre –2 e +2, o valor de nós folhas será limitado e, nesse\\ncaso, \\npoderemos\\n impor um limite superior sobre o valor de um nó de acaso sem examinar todos os\\nseus filhos.\\nUma alternativa é fazer a \\nsimulação de Monte Carlo\\n para avaliar uma posição. Comece com um\\nalgoritmo de busca alfa-beta (ou outro).\\nA partir de uma posição inicial, faça com que o algoritmo jogue milhares de jogos contra si\\nmesmo, usando arremessos de dados aleatórios. No caso do gamão, o percentual de vitórias\\nresultante tem se mostrado uma boa aproximação do valor da posição, mesmo que o algoritmo tenha\\numa heurística imperfeita e esteja em busca apenas de algumas jogadas (Tesauro, 1995). Para jogos\\ncom dados, esse tipo de simulação chama-se \\nlançamento.\\n5.6 JOGOS PARCIALMENTE OBSERVÁVEIS\\nMuitas vezes, o xadrez tem sido descrito como guerra em miniatura, mas carece de pelo menos\\numa característica importante de guerras reais, chamada \\nobservabilidade parcial\\n. Na “névoa da\\nguerra”, a existência e a disposição das unidades inimigas é muitas vezes desconhecida até ser\\nrevelada por contato direto. Como resultado, a guerra inclui o uso de observadores e espiões para\\ncolher informações e uso de dissimulação e blefe para confundir o inimigo. Os jogos parcialmente\\nobserváveis compartilham essas características e são, portanto, qualitativamente diferentes dos jogos\\ndescritos nas seções anteriores.\\n5.6.1 Kriegspiel: xadrez parcialmente observável\\nEm jogos \\ndeterminísticos\\n parcialmente observáveis, a incerteza sobre o estado do tabuleiro\\nresulta inteiramente da falta de acesso às escolhas feitas pelo adversário. Essa categoria inclui os\\njogos infantis como batalha naval (em que cada jogador coloca os navios em locais escondidos do\\nadversário e não se movem) e Stratego (no qual a localização das peças é conhecida, mas os tipos\\ndas peças permanecem ocultos). Vamos examinar o jogo de \\nKriegspiel\\n, uma variante parcialmente\\nobservável de xadrez em que as partes podem se mover, mas são completamente invisíveis para os\\nadversários.\\nAs regras do Kriegspiel são as seguintes: brancas e pretas veem um tabuleiro que contém apenas\\nsuas próprias peças. Um árbitro, que pode ver todas as peças, julga o jogo e faz anúncios periódicos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 223}),\n",
       " Document(page_content='que os dois jogadores escutam. Por sua vez, as brancas propõem ao árbitro qualquer movimento que\\nseria legal se não houvesse peças pretas. Se o movimento de fato não for legal (por causa das peças\\npretas), o árbitro anuncia “ilegal”. Nesse caso, as brancas podem manter os movimentos propostos\\naté que seja encontrado um legal — e aprendem mais sobre a localização das peças pretas no\\nprocesso. Uma vez que seja proposto um lance legal, o árbitro anuncia uma ou mais das seguintes\\nopções: “Capture no quadrado \\nX\\n” se houver uma captura, e “Xeque em \\nD\\n” se o rei preto estiver em\\nxeque, onde \\nD\\n é a direção do xeque e pode ser um dos “cavalos”, “linha”, “coluna”, “diagonal\\nlonga” ou “diagonal curta” (no caso de xeque a descoberto, o árbitro pode fazer dois anúncios de\\n“xeque”). Se houver um xeque-mate ou afogamento nas pretas, o árbitro avisa; caso contrário, é a vez\\ndo lance do preto.\\nO Kriegspiel pode parecer terrivelmente impossível, mas os humanos o administram muito bem e\\nos programas de computador estão começando a alcançá-lo. Ajuda lembrar a noção de \\nestado de\\ncrença\\n, como definido na \\nSeção 4.4\\n e ilustrado na \\nFigura 4.14\\n — o conjunto de todos os estados do\\ntabuleiro \\nlogicamente possível\\n dá o histórico completo das percepções até o momento. Inicialmente,\\no estado de crença branco é uma peça avulsa porque as peças pretas ainda não se moveram. Após um\\nmovimento das brancas e uma resposta das pretas, o estado de crença das brancas contém 20\\nposições porque as pretas têm 20 respostas a qualquer movimento das brancas. Manter o controle do\\nestado de crença no decorrer do jogo é exatamente o problema da \\nestimativa de estado\\n, para o qual\\na etapa de atualização é dada na Equação 4.6. Podemos mapear a estimativa de estado do Kriegspiel\\ndiretamente para o quadro parcialmente observável, não determinístico da \\nSeção 4.4\\n, se\\nconsiderarmos o adversário como fonte de não determinismo, ou seja, os RESULTADOS do\\nmovimento das brancas são compostos do resultado (previsível) do próprio movimento das brancas e\\npelo resultado imprevisível dado pela resposta das pretas.\\n3\\nDado um estado de crença atual, as brancas podem perguntar: “Posso ganhar o jogo?” Para um\\njogo parcialmente observável, a noção de \\nestratégia\\n é alterada; em vez de especificar um\\nmovimento a ser feito para cada \\nmovimento\\n possível que o adversário possa fazer, precisamos de um\\nmovimento para cada \\nsequência de percepção\\n possível que possa ser recebida. Para o Kriegspiel,\\numa estratégia vencedora, ou \\nxeque-mate garantido\\n, é aquela que, para cada sequência de\\npercepção possível, leva a um xeque-mate real para cada estado do tabuleiro possível no estado de\\ncrença atual, independentemente da forma como o adversário se move. Com essa definição, o estado\\nde crença do adversário é irrelevante — a estratégia tem que funcionar, mesmo que o adversário\\npossa ver todas as peças. Isso simplifica muito cálculo. A \\nFigura 5.13\\n mostra parte de um xeque-\\nmate garantido para um final de jogo RTR (rei, torre contra rei). Nesse caso, as pretas têm apenas\\numa peça (o rei); assim, um estado de crença para as brancas pode ser mostrado em um tabuleiro\\nsimples marcando cada posição possível do rei preto.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 224}),\n",
       " Document(page_content='Figura 5.13\\n Parte de um xeque-mate garantido RTR, mostrado ao final do jogo, em um tabuleiro\\nreduzido. No estado de crença inicial, o rei preto está em uma das três localizações possíveis.\\nAtravés de uma combinação de movimentos de sondagem, a estratégia se reduz para um. A conclusão\\ndo xeque-mate é deixada como exercício.\\nO algoritmo genérico de busca E-OU pode ser aplicado no espaço de estado de crença para\\nencontrar os xeque-mates garantidos, como na \\nSeção 4.4\\n. O algoritmo de estado de crença\\nincremental mencionado na seção muitas vezes encontra xeque-mates no meio do jogo até uma\\nprofundidade 9 — provavelmente muito além das habilidades dos jogadores humanos.\\nAlém dos xeque-mates garantidos, o Kriegspiel admite um conceito inteiramente novo que não faz\\nsentido em jogos totalmente observáveis: \\nxeque-mate probabilístico\\n. Ainda é requerido que tais\\nxeque-mates funcionem em cada estado do tabuleiro em estado de crença; são probabilísticos com\\nrespeito à randomização dos movimentos do jogador vencedor. Para obter a ideia básica, considere\\no problema de encontrar um rei preto solitário utilizando apenas o rei branco. Simplesmente\\nmovendo de forma aleatória, o rei branco \\neventualmente\\n dará de cara com o rei preto, mesmo que\\neste último tente evitar esse destino, desde que o preto não pode se manter imaginando movimentos\\nevasivos corretos indefinidamente. Na terminologia da teoria da probabilidade, a detecção ocorre\\ncom probabilidade\\n 1. O final de jogo RBCR — rei, bispo e cavalo, contra o rei — está ganha nesse\\nsentido; a branca apresenta à preta uma sequência infinita aleatória de escolhas, para uma das quais a\\npreta vai imaginar incorretamente e revelar sua posição, levando ao xeque-mate. O fim do jogo\\nRBBR, por outro lado, se ganha com probabilidade 1 − \\n∊\\n.\\nA branca pode forçar uma vitória apenas, deixando um de seus bispos sem proteção em um\\nmovimento. Se acontecer de a preta estar no lugar certo e capturar o bispo (um movimento que iria\\nperder se o bispo estivesse protegido), a partida estará empatada. A branca pode optar por um', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 225}),\n",
       " Document(page_content='movimento arriscado em algum ponto escolhido randomicamente no meio de uma distância muito\\nlonga, reduzindo assim \\n∊\\n para uma constante arbitrariamente pequena, mas não pode reduzir \\n∊\\n para\\nzero.\\nÉ muito raro que um xeque-mate garantido ou probabilístico possa ser encontrado em qualquer\\nprofundidade razoável, exceto ao final do jogo. Às vezes, uma estratégia de xeque-mate funciona\\npara \\nalguns\\n dos estados do tabuleiro no estado de crença atual, mas não para outros. Tentar tal\\nestratégia pode ter sucesso, levando a um \\nxeque-mate acidental\\n — acidental no sentido de que a\\nbranca não poderia \\nsaber\\n que seria xeque-mate — se acontecer de as peças pretas estarem nos\\nlugares certos (a maioria dos xeque-mates em jogos entre os seres humanos é dessa natureza\\nacidental). Essa ideia leva naturalmente à questão de \\no quanto provável\\n é que determinada estratégia\\nirá vencer, o que leva, por sua vez, à questão do \\nquanto é provável\\n que cada estado do tabuleiro, no\\nestado de crença atual, é o verdadeiro estado do tabuleiro.\\n Uma primeira inclinação deverá ser propor que todas as posições do tabuleiro, no estado de\\ncrença atual, sejam igualmente prováveis, mas isso pode não estar certo. Considere, por exemplo, o\\nestado de crença da branca após o primeiro lance do jogo da preta. Por definição (assumindo que a\\npreta desempenha otimamente), a preta deve ter jogado um ótimo lance, e assim deveria ser atribuída\\numa probabilidade zero a todas as posições do tabuleiro resultantes de lances subótimos. Esse\\nargumento não é muito certo também porque o objetivo de \\ncada jogador não é apenas mover as\\npeças para os quadrados à direita, mas também minimizar a informação que o adversário tem\\nsobre sua localização.\\n Jogar qualquer estratégia “ótima” previsível fornece informações ao\\nadversário. Por isso, o jogo ideal em jogos parcialmente observáveis \\u200b\\u200brequer uma vontade de jogar de\\nalguma forma \\nao acaso\\n (é por isso que os inspetores de higiene de restaurante fazem visitas de\\ninspeção aleatórias). Isso significa selecionar ocasionalmente lances que podem parecer\\n“intrinsecamente” fracos, mas ganham força a partir de sua forte imprevisibilidade porque é\\nimprovável que o adversário tenha preparado qualquer defesa contra eles.\\nA partir dessas considerações, parece que as probabilidades associadas com as posições do\\ntabuleiro no estado de crença atual só podem ser calculadas a partir de uma estratégia ótima\\nrandomizada; por sua vez, o cálculo dessa estratégia parece exigir conhecimento das probabilidades\\ndas diversas posições que o tabuleiro possa ter. Esse enigma pode ser resolvido adotando a noção da\\nteoria dos jogos de uma solução de \\nequilíbrio\\n, que será abrangida no Capítulo 17. Um equilíbrio\\nespecifica uma estratégia ótima randomizada para cada jogador. Porém, calcular o equilíbrio é\\nproibitivamente caro, mesmo para pequenos jogos, e está fora de questão para o Kriegspiel.\\nAtualmente, o projeto de algoritmos eficientes para o jogo geral de Kriegspiel é um tópico de busca\\naberta. A maioria dos sistemas realiza a perspectiva de profundidade limitada em seu próprio espaço\\nde estado de crença, ignorando o estado de crença do adversário. As funções de avaliação são\\nsemelhantes às do jogo observável, mas incluem um componente para o tamanho do estado de crença\\n— quanto menor, melhor!\\n5.6.2 Jogos de cartas\\nOs jogos de cartas dão muitos exemplos de observabilidade parcial \\nestocástica\\n, onde a falta de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 226}),\n",
       " Document(page_content='informação é gerada aleatoriamente. Por exemplo, em muitos jogos, no início do jogo as cartas são\\ndistribuídas aleatoriamente, com cada jogador recebendo uma mão que não é visível para os outros\\njogadores. Tais jogos incluem \\nbridge\\n, \\nwhist\\n, \\nhearts\\n e algumas formas de pôquer.\\nÀ primeira vista, pode parecer que esses jogos de cartas são como jogos de dados: as cartas são\\ndistribuídas de forma aleatória e determinam as jogadas disponíveis para cada jogador, mas no\\ninício todos os “dados” são jogados! Mesmo que essa analogia acabe sendo incorreta, ela sugere um\\nalgoritmo efetivo: considerar todas as distribuições possíveis das cartas invisíveis, resolver cada\\numa como se fosse um jogo totalmente observável, e então escolher o lance que tem a melhor média\\nde resultado sobre todos os lances. Suponha que cada mão ocorra com a probabilidade \\nP\\n(\\ns\\n), então o\\nlance que queremos é\\nAqui, executaremos o MINIMAX exato se computacionalmente viável; caso contrário,\\nexecutaremos o H-MINIMAX.\\nAgora, na maioria dos jogos de carta, o número de mãos possíveis é bastante grande. Por exemplo,\\nno jogo de \\nbridge\\n, cada jogador vê apenas duas das quatro mãos; existem duas mãos invisíveis, de\\n13 cartas cada, então o número de mãos é (26/13) = 10.400.600. A resolução de uma mão é muito\\ndifícil, por isso resolver 10 milhões está fora de questão. Em vez disso, recorreremos a uma\\naproximação de Monte Carlo: em vez de somar \\ntodas\\n as rodadas, tomamos uma \\namostra aleatória\\nde \\nN\\n rodadas, onde a probabilidade de a rodada \\ns\\n aparecer na amostra é proporcional a \\nP\\n(\\ns\\n):\\n[Observe que \\nP\\n(\\ns\\n) não aparece explicitamente no somatório porque as amostras já estão extraídas de\\nacordo com \\nP\\n(\\ns\\n).] À medida que \\nN\\n aumenta, a soma sobre a amostra aleatória tende ao valor exato,\\nmas mesmo para \\nN\\n relativamente pequeno — digamos, de 100 a 1.000 — o método dá uma boa\\naproximação. Pode também ser aplicado a jogos determinísticos, como o de Kriegspiel, a partir de\\nalgumas estimativas razoáveis de \\nP\\n(\\ns\\n).\\nPara jogos como \\nwhist\\n e \\nhearts\\n, nos quais não há fase de lance ou de apostas antes de o jogo\\ncomeçar, cada rodada será igualmente provável e, assim, os valores de \\nP\\n(\\ns\\n) são todos iguais. Para o\\nbridge\\n, o jogo é precedido por uma fase de leilão, em que cada equipe indica quantos \\ntricks\\n espera\\nganhar. Como os jogadores fazem seus lances com base em suas cartas, os outros jogadores\\naprendem mais sobre a probabilidade de cada lance. Levar isso em conta para decidir como jogar a\\nmão é complicado, pelas razões mencionadas em nossa descrição do Kriegspiel: os jogadores podem\\nfazer os lances de forma a minimizar a informação transmitida aos seus adversários. Mesmo assim, a\\nabordagem é bastante eficaz para o \\nbridge\\n, como mostraremos na \\nSeção 5.7\\n.\\nA estratégia descrita nas Equações 5.1 e 5.2 chama-se às vezes \\nmédia sobre clarividência\\n porque\\nassume que o jogo vai se tornar observável para ambos os jogadores imediatamente após o primeiro\\nlance. Apesar de seu apelo intuitivo, a estratégia pode conduzir a um extravio. Considere a seguinte\\nhistória:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 227}),\n",
       " Document(page_content='Dia 1: A estrada \\nA\\n leva a um monte de moedas de ouro; a estrada \\nB\\n leva a uma bifurcação. Tome a\\nestrada da esquerda e você encontrará uma grande pilha de ouro; tome a estrada da direita e você\\nserá atropelado por um ônibus.\\nDia 2: A estrada \\nA\\n leva a um monte de moedas de ouro; a estrada \\nB\\n leva a uma bifurcação. Tome a\\nestrada da direita e você encontrará uma grande pilha de ouro; tome a estrada da esquerda e você\\nserá atropelado por um ônibus.\\nDia 3: A estrada \\nA\\n leva a um monte de moedas de ouro; a estrada \\nB\\n leva a uma bifurcação. Um\\nramo da bifurcação leva a uma grande pilha de ouro, mas, se tomar o caminho errado será\\natropelado por um ônibus. Infelizmente, você não sabe qual é o correto.\\nA média sobre clarividência leva ao seguinte raciocínio: no dia 1, \\nB\\n é a escolha certa; no dia 2, \\nB\\né a escolha certa; no dia 3, a situação é a mesma que a do dia 1 ou 2, então \\nB\\n deverá ser ainda a\\nescolha certa.\\nAgora podemos ver como uma média sobre a clarividência falha: não considera o \\nestado de\\ncrença\\n em que o agente estará depois da ação. Um estado de crença de total ignorância não é\\ndesejável, especialmente quando uma possibilidade certa é a morte. Por assumir que cada estado\\nfuturo será automaticamente de perfeito conhecimento, a abordagem nunca seleciona ações que\\nreúnem informações\\n (como o primeiro lance na \\nFigura 5.13\\n); nem vai escolher as ações que\\nescondem informação do adversário ou fornece informação a um parceiro porque se assume que eles\\njá conhecem as informações e ela nunca vai \\nblefar\\n no pôquer,\\n4\\n pois assume que o adversário pode\\nver as suas cartas. No Capítulo 17, vamos mostrar como construir algoritmos que fazem todas essas\\ncoisas pela virtude de resolver o verdadeiro problema de decisão parcialmente observável.\\n5.7 PROGRAMAS DE JOGOS DE ÚLTIMA GERAÇÃO\\nEm 1965, o matemático russo Alexander Kronrod chamou o xadrez de “\\nDrosophila\\n inteligência\\nartificial”. John McCarthy discorda: enquanto os geneticistas usam moscas de frutas para fazer\\ndescobertas que se aplicam à biologia de forma mais ampla, a IA usou o xadrez para fazer o\\nequivalente à criação de moscas de fruta muito rápidas. Talvez a melhor analogia seja de que o\\nxadrez é para a IA o mesmo que a corrida automobilística de Grand Prix é para a indústria do\\nautomóvel: programas de última geração de jogo são incrivelmente rápidos, máquinas altamente\\notimizadas, que incorporam os últimos avanços da engenharia, mas eles não são muito úteis para\\nfazer as compras ou dirigir fora da estrada. No entanto, corridas e jogos geram excitação e um fluxo\\nconstante de inovações que são adotadas por uma comunidade maior. Nesta seção, verificaremos o\\nque é preciso para se sair bem em vários jogos.\\nXadrez:\\n o programa de xadrez da IBM, Deep Blue, agora aposentado, foi muito conhecido por\\nderrotar o campeão mundial Garry Kasparov em um jogo de exibição amplamente divulgado. O Deep\\nBlue executou em um computador paralelo com 30 processadores IBM RS/6000 fazendo busca alfa-\\nbeta. A única parte era uma configuração personalizada de 480 processadores de xadrez VLSI que\\nrealizava a geração de movimento e de ordenação para os últimos poucos níveis da árvore e\\navaliava os nós folha. O Deep Blue buscava até 30 bilhões de posições por movimento, alcançando', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 228}),\n",
       " Document(page_content='rotineiramente uma profundidade igual a 14. O coração da máquina é uma busca alfa-beta de\\naprofundamento iterativo padrão com uma tabela de transposição, mas a chave de seu sucesso parece\\nter sido sua habilidade de gerar extensões além do limite de profundidade para linhas suficientemente\\ninteressantes de movimentos forçados. Em alguns casos, a busca alcançou uma profundidade de 40\\njogadas. A função de avaliação tinha mais de 8.000 características, muitas delas descrevendo\\npadrões de peças altamente específicos. Foi usado um “livro de aberturas” com aproximadamente\\n4.000 posições, bem como um banco de dados de 700.000 jogos de grandes mestres a partir do qual\\npodiam ser extraídas recomendações consensuais. O sistema também utilizava um grande banco de\\ndados de finais de jogos com posições resolvidas, contendo todas as posições com cinco peças e\\nmuitas com seis peças. Esse banco de dados tem o efeito de estender de forma significativa a\\nprofundidade efetiva da busca, permitindo ao Deep Blue jogar com perfeição em alguns casos, até\\nmesmo quando está a muitos movimentos de distância do xeque-mate.\\nO sucesso do Deep Blue reforçou a ampla convicção de que o progresso dos jogos de\\ncomputadores vinha principalmente de um hardware cada vez mais poderoso — uma visão\\nencorajada pela IBM. Mas as melhorias algorítmicas têm permitido aos programas executar em PCs-\\npadrão, para ganhar campeonatos mundiais de xadrez por computador. Diversas heurísticas de poda\\nsão usadas para reduzir o fator de ramificação efetivo a menos de 3 (comparado ao fator de\\nramificação real de aproximadamente 35). A mais importante delas é a heurística de \\nmovimento\\nnulo\\n, que gera um bom limite inferior sobre o valor de uma posição, usando uma busca rasa na qual o\\noponente chega ao dobro de movimentos no início. Esse limite inferior frequentemente permite a\\npoda alfa-beta sem o custo de uma busca em profundidade total. Também é importante a \\npoda de\\nfutilidades\\n, que ajuda a decidir com antecedência que movimentos causarão um corte beta nos nós\\nsucessores.\\nO HYDRA pode ser visto como o sucessor do Deep Blue. O HYDRA executa em um cluster de\\nprocessador de 64 com 1 gigabyte por processador e com hardware personalizado em forma de chips\\nFPGA (\\nfield programmable gate array\\n: arranjo de portas programável em campo). O HYDRA\\natinge 200 milhões de avaliações por segundo, o mesmo que o Deep Blue, mas alcança 18 camadas\\nde profundidade, em vez de apenas 14, por causa do uso agressivo da heurística de movimento nulo e\\npoda adiantada.\\nO RYBKA, vencedor do Campeonato Mundial de Xadrez de Computador de 2008 e 2009, é\\nconsiderado o computador jogador mais forte do momento. Ele utiliza um processador Xeon de 8-\\ncore e 3,2 GHz Intel imediatamente disponível, mas pouco se sabe sobre a concepção do programa.\\nSua principal vantagem parece ser a sua função de avaliação, que foi ajustada pelo seu\\ndesenvolvedor principal, o mestre internacional Vasik Rajlich, e pelo menos três outros grandes\\nmestres.\\nOs jogos mais recentes sugerem que os programas de computador mais avançados de xadrez\\nimpulsionaram todos os competidores humanos (veja as observações históricas para detalhes).\\nJogo de damas:\\n Jonathan Schaeffer e seus colegas desenvolveram o CHINOOK, que executa em PCs\\ne utiliza busca alfa-beta. O Chinook derrotou o campeão humano de longa data em uma partida\\nabreviada em 1990, e desde 2007 tem sido capaz de jogar perfeitamente utilizando busca alfa-beta\\ncombinada com uma base de dados de 39 trilhões de posições finais.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 229}),\n",
       " Document(page_content='O jogo \\nOthello\\n, também chamado Reversi, provavelmente é mais popular como jogo de computador\\ndo que como jogo de tabuleiro. Ele tem um espaço de busca menor que o do xadrez, em geral de 5-15\\nmovimentos válidos, mas a experiência de avaliação teve de ser desenvolvida desde o início. Em\\n1997, o programa Logistello (Buro, 2002) derrotou o campeão mundial humano, Takeshi Murakami,\\npor seis jogos a zero. De modo geral, todos reconhecem que os seres humanos não são capazes de\\nsuperar os computadores no Othello.\\nGamão:\\n A \\nSeção 6.5\\n explicou por que a inclusão da incerteza dos lançamentos de dados torna uma\\nbusca profunda um luxo dispendioso. A maior parte do trabalho em gamão se dedicou a melhorar a\\nfunção de avaliação. Gerry Tesauro (1992) combinou o método de aprendizado de reforço de Samuel\\ncom as técnicas de redes neurais para desenvolver um avaliador notavelmente preciso que é utilizado\\ncom uma busca até a profundidade 2 ou 3. Depois de disputar mais de um milhão de jogos de\\ntreinamento contra si mesmo, o programa de Tesauro, TD-GAMMON ficou competitivo com os\\nmelhores jogadores humanos. Em alguns casos, as opiniões do programa nos movimentos de abertura\\ndo jogo alteraram de forma radical a sabedoria adquirida.\\nO \\nGo\\n é o jogo de tabuleiro mais popular na Ásia, exigindo de seus profissionais, no mínimo, tanta\\ndisciplina quanto o xadrez. Como o tabuleiro tem 19 × 19 e os lances são permitidos na entrada de\\n(quase) todos os quadrados em branco, o fator de ramificação começa em 361, um valor assustador\\npara os métodos de busca alfa-beta comum. Além disso, é difícil escrever uma função de avaliação\\nporque o controle do território é muitas vezes imprevisível até o fim do jogo. Portanto, os programas\\nde topo, como o MoGo, evitam a busca alfa-beta e, em vez disso, utilizam os lançamentos de Monte\\nCarlo. A malícia é decidir que lances fazer no curso do lançamento. Não há poda agressiva; todos os\\nmovimentos são possíveis. O método de limites de confiança superior em árvores funciona ao fazer\\nmovimentos aleatórios nas primeiras poucas iterações e, ao longo do tempo, guiando o processo de\\namostragem para selecionar os lances que levaram a vitórias nas amostras anteriores. São\\nadicionados alguns truques, incluindo \\nregras baseadas em conhecimento\\n que sugerem lances em\\nparticular sempre que determinado padrão foi detectado e \\nlimitou a busca local\\n para decidir\\nquestões táticas. Alguns programas também incluem técnicas especiais da \\nteoria combinatória dos\\njogos\\n para analisar finais de jogos. Essas técnicas decompõem uma posição em suposições que\\npodem ser analisadas separadamente e depois combinadas (Berlekamp e Wolfe, 1994; Muller,\\n2003). As soluções ótimas obtidas dessa forma têm surpreendido muitos jogadores de Go\\nprofissional, que pensavam que estavam jogando otimamente o tempo todo. Os programas atuais para\\nGo funcionam em nível proprietário em tabuleiro 9 × 9 reduzido, mas ainda estão em nível amador\\navançado em um tabuleiro completo.\\nO \\nbridge\\n é um jogo de cartas de informações imperfeitas: as cartas de um jogador ficam ocultas dos\\noutros jogadores. O \\nbridge\\n também é um jogo de \\nvários participantes\\n com quatro jogadores em vez\\nde dois, embora os jogadores formem duas equipes. Como vimos na \\nSeção 5.6\\n, o jogo ótimo em\\njogos parcialmente observáveis como o \\nbridge\\n pode incluir elementos de aquisição de informações,\\ncomunicação, blefe e cuidadosa ponderação de probabilidades. Muitas dessas técnicas são usadas no\\nprograma Bridge Baron\\nTM\\n (Smith \\net al\\n., 1998), que venceu o campeonato de \\nbridge\\n por computador\\nde 1997. Embora não jogue muito bem, o Bridge Baron é um dos poucos sistemas de jogos bem-\\nsucedidos a usar planos hierárquicos complexos (veja o Capítulo 11) que envolvem ideias de alto', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 230}),\n",
       " Document(page_content='nível como \\ntrapacear\\n e \\nforçar o descarte de trunfo\\n, familiares aos jogadores de \\nbridge\\n.\\nO programa GIB (Ginsberg, 1999) venceu o campeonato de \\nbridge\\n de 2000 decisivamente usando\\no método de Monte Carlo. Desde então, outros programas vencedores seguiram a conduta do GIB. A\\nmaior inovação do GIB é utilizar \\ngeneralização baseada em explanação\\n para calcular e armazenar\\nna cache regras gerais para desempenho ótimo em várias classes-padrão de situações, em vez de\\navaliar cada situação individualmente. Por exemplo, em uma situação em que um jogador tem as\\ncartas A-K-Q-J-4-3-2 de um naipe e outro jogador tem 10-9-8-7-6-5, existem 7 × 6 = 42 maneiras\\npara o primeiro jogador encabeçar e o segundo jogador seguir. Mas o GIB trata essas situações\\napenas como duas: o primeiro jogador pode tirar uma carta alta ou uma baixa; as cartas exatas não\\nimportam. Com essa otimização (e algumas outras), o GIB pode resolver as 52 cartas, uma mão\\nplenamente observável \\nexatamente\\n em cerca de um segundo. A precisão tática do GIB contribui para\\nsua inabilidade de raciocinar sobre as informações. Ele terminou em 12\\no\\n lugar em um grupo de 35 no\\nconcurso de pares (envolvendo apenas o jogo da mão, não os lances) no campeonato mundial de\\n1998 para jogadores humanos, superando de longe as expectativas de muitos especialistas.\\nExistem várias razões para o desempenho do GIB em nível especialista com a simulação de Monte\\nCarlo, considerando que os programas do Kriegspiel não o fazem. Primeiro, a avaliação de GIB da\\nversão totalmente observável do jogo é exata, buscando da árvore de jogo completa, enquanto os\\nprogramas Kriegspiel dependem da heurística inexata. Mas muito mais importante é o fato de que, no\\nbridge\\n, a maior parte da incerteza nas informações parcialmente observáveis vem da aleatoriedade\\ndo lance, não do jogo do adversário. A simulação de Monte Carlo trata bem a aleatoriedade, mas\\nnem sempre lida bem com a estratégia, especialmente quando a estratégia envolve o valor da\\ninformação.\\nPalavras cruzadas\\n: A maioria das pessoas acha que a parte mais difícil das palavras cruzadas é vir\\nà baila boas palavras, mas, dado o dicionário oficial, acaba por ser bastante fácil programar um\\ngerador de lance para encontrar o lance de pontuação mais alta (Gordon, 1994). No entanto, isso não\\nsignifica que o jogo seja resolvido: tomar apenas o lance de melhor pontuação a cada vez é resultado\\nde um jogador bom, mas não especialista. O problema é que a palavra cruzada é ao mesmo tempo\\nparcialmente observável e estocástica: você não sabe que letras o outro jogador tem ou quais as\\npróximas letras que você vai puxar. Portanto, jogar palavras cruzadas bem combina as dificuldades\\ndo gamão com o \\nbridge\\n. No entanto, em 2006, o programa QUACKLE derrotou o ex-campeão\\nmundial, David Boys, por 3×2.\\n5.8 ABORDAGENS ALTERNATIVAS\\nTendo em vista que o cálculo de decisões ótimas em jogos é intratável na maioria dos casos, todos\\nos algoritmos devem fazer algumas suposições e aproximações. A abordagem-padrão, baseada em\\nminimax, funções de avaliação e alfa-beta, é apenas uma maneira de fazer isso. Talvez porque tenha\\nfuncionado por tanto tempo, a abordagem-padrão foi desenvolvida intensivamente e domina outros\\nmétodos em jogos de torneios. Alguns especialistas no campo acreditam que isso tenha feito os jogos\\nse divorciarem da parte principal da busca de IA: porque a abordagem-padrão não oferece mais', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 231}),\n",
       " Document(page_content='tanto espaço para novas ideias sobre questões gerais de tomada de decisões. Nesta seção, veremos\\nas alternativas.\\nPrimeiro, vamos considerar a heurística minimax. Ela seleciona um movimento ótimo em dada\\nárvore de busca \\ndesde que as avaliações de nós de folhas sejam exatamente corretas\\n. Na realidade,\\nas avaliações são normalmente estimativas brutas do valor de uma posição e podemos considerar\\nque há grandes erros associados a elas. A \\nFigura 5.14\\n mostra uma árvore de jogo de duas jogadas\\npara a qual o minimax sugere tomar o ramo da direita, porque 100 > 99. Esse é o lance correto se as\\navaliações estiverem todas corretas. Mas é claro que a função de avaliação é apenas aproximada.\\nSuponha que a avaliação de cada nó tenha um erro que é independente de outros nós e aleatoriamente\\ndistribuído com média zero e desvio padrão. Então, quando \\nσ\\n = 5, o ramo esquerdo é realmente\\nmelhor 71% do tempo e 58% do tempo quando \\nσ\\n = 2. A percepção por trás disso é que o ramo do\\nlado direito tem quatro nós que estão próximos de 99; se um erro na avaliação de qualquer um dos\\nquatro fizer com que o ramo da direita deslize abaixo de 99, então o ramo da esquerda é o melhor.\\nFigure 5.14\\n Uma árvore de jogo de duas jogadas para a qual o minimax pode ser inadequado.\\nNa realidade, as circunstâncias são realmente piores do que isso porque o erro na função de\\navaliação \\nnão\\n é independente. Se obtivermos um nó errado, as chances são altas de que os próximos\\nnós na árvore também estarão errados. Porém, o fato de o nó identificado com 99 ter irmãos\\nidentificados com 1.000 sugere que, de fato, ele pode ter um valor verdadeiro mais alto. Podemos\\nusar uma função de avaliação que retorna uma \\ndistribuição de probabilidades\\n sobre valores\\npossíveis, mas é difícil combinar essas distribuições corretamente porque não vamos ter um bom\\nmodelo das dependências muito fortes que existem entre os valores dos nós irmãos.\\nEm seguida, consideramos o algoritmo de busca que gera a árvore. O objetivo do projetista de\\nalgoritmos é especificar uma computação que funcione com rapidez e que gere um bom movimento.\\nOs algoritmos alfa–beta foram projetados não apenas para selecionar um bom movimento, mas\\ntambém para calcular limites sobre os valores de todos os movimentos válidos. Para ver por que\\nessas informações extras são desnecessárias, considere uma posição em que só existe um movimento\\nválido. A busca alfa−-beta ainda irá gerar e avaliar uma árvore de busca grande, dizendo que o único\\nlance é o melhor lance e atribuindo-lhe um valor. Mas, como temos que fazer o movimento de\\nqualquer forma, conhecer o valor do movimento é inútil. Da mesma forma, se houver um lance\\nobviamente bom e vários lances que são legais, mas levam a uma perda rápida, não vamos querer\\nque o alfa-beta desperdice tempo determinando um valor preciso para apenas um bom lance. Melhor\\nfazer apenas o movimento rapidamente e economizar tempo para mais tarde. Isso leva à ideia da\\nutilidade de uma expansão de nó\\n. Um bom algoritmo de busca deve selecionar expansões de nós de\\nutilidade elevada, ou seja, aquelas que deverão levar à descoberta de um movimento\\nsignificativamente melhor. Se não houver nenhuma expansão de nó cuja utilidade seja mais alta que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 232}),\n",
       " Document(page_content='seu custo (em termos de tempo), o algoritmo deve interromper a busca e efetuar um movimento. Note\\nque isso funciona não apenas para situações de claro favoritismo, mas também no caso de\\nmovimentos simétricos\\n, para os quais nenhuma quantidade de busca mostrará que um movimento é\\nmelhor que outro.\\nEsse tipo de raciocínio que trata dos resultados obtidos com a computação é chamado\\nmetarraciocínio\\n (raciocínio sobre o raciocínio). Ele se aplica não apenas aos jogos, mas a qualquer\\nespécie de raciocínio. Todas as computações são feitas com a finalidade de tentar alcançar decisões\\nmelhores, todas têm custos e todas têm alguma probabilidade de resultar em certa melhoria na\\nqualidade da decisão. A alfa-beta incorpora o tipo mais simples de metarraciocínio, ou seja, um\\nteorema para o efeito de que certas ramificações da árvore podem ser ignoradas sem perda. É\\npossível fazer muito melhor. No Capítulo 16, veremos como essas ideias podem se tornar exatas e\\nimplementáveis.\\nFinalmente, vamos reexaminar a natureza da própria busca. Os algoritmos para busca heurística e\\npara jogos funcionam gerando sequências de estados concretos, começando pelo estado inicial e\\ndepois aplicando uma função de avaliação. É claro que não é assim que os seres humanos jogam. No\\nxadrez, com frequência se tem em mente um objetivo específico — por exemplo, preparar uma\\narmadilha para a rainha do oponente — e se pode usar esse objetivo para gerar \\nseletivamente\\n planos\\nplausíveis para alcançá-lo. Esse tipo de raciocínio orientado para objetivos ou planejamento às\\nvezes elimina por completo a busca combinatória. O Paradise de David Wilkins (1980) é o único\\nprograma a usar com sucesso o raciocínio orientado para objetivos no xadrez: ele foi capaz de\\nresolver alguns problemas de xadrez que exigiam uma combinação de 18 movimentos. Até agora não\\nexiste nenhuma compreensão razoável de como \\ncombinar\\n os dois tipos de algoritmos para formar um\\nsistema eficiente e robusto, embora o Bridge Baron possa ser um passo na direção correta. Um\\nsistema totalmente integrado seria uma realização significativa não apenas para a pesquisa na área de\\njogos, mas também para a pesquisa em IA em geral porque seria uma boa base para um agente\\ninteligente geral.\\n5.9 RESUMO\\nExaminamos uma variedade de jogos para entender o que significa um jogo ótimo e para\\ncompreender como jogar bem na prática. As ideias mais importantes são:\\n•  Um jogo pode ser definido pelo \\nestado inicial\\n (a forma como o tabuleiro é configurado), pelas\\nações\\n válidas em cada estado, o \\nresultado\\n de cada ação, um \\nteste de término\\n (que informa\\nquando o jogo é encerrado) e por uma \\nfunção utilidade\\n que se aplica a estados terminais.\\n•  Em jogos de dois jogadores com soma zero e \\ninformações perfeitas\\n, o algoritmo \\nminimax\\n pode\\nselecionar movimentos ótimos usando uma enumeração da árvore de jogo em profundidade.\\n•  O algoritmo de busca \\nalfa-beta\\n calcula o mesmo movimento ótimo que o minimax, mas alcança\\numa eficiência muito maior pela eliminação de subárvores comprovadamente irrelevantes.\\n•  Em geral, não é possível considerar a árvore de jogo inteira (mesmo com alfa-beta) e, assim,\\nprecisamos cortar a busca em algum ponto e aplicar uma \\nfunção de avaliação\\n que fornece uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 233}),\n",
       " Document(page_content='estimativa da utilidade de um estado.\\n•  Muitos programas de jogos pré-calculam tabelas das melhores jogadas no início e no final do\\njogo para que possam consultar uma jogada em vez de buscar.\\n•  Os jogos de azar podem ser tratados por uma extensão do algoritmo minimax que avalia um \\nnó\\nde acaso\\n tomando a utilidade média de todos os seus nós filhos, ponderada pela probabilidade\\nde cada filho.\\n•  O desempenho ótimo emjogos de \\ninformações imperfeitas\\n, como o Kriegspiel e o \\nbridge\\n, exige\\nraciocínio sobre os \\nestados de crença\\n corrente e futura de cada jogador. Uma aproximação\\nsimples pode ser obtida calculando-se a média dos valores de uma ação sobre cada configuração\\npossível de informações omitidas.\\n•  Os programas têm superado até mesmo jogadores humanos que são campeões em jogos, como\\nxadrez, damas e Othello. Os seres humanos mantêm vantagem em vários jogos de informação\\nimperfeita, como \\nbridge\\n, pôquer e Kriegspiel, e em jogos com fatores muito grandes de\\nramificação e pouco conhecimento heurístico bom, como o Go.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nA história inicial dos jogos mecânicos foi marcada por numerosas fraudes. A mais notória dessas\\nfraudes foi a do barão Wolfgang von Kempelen (1734-1804, “o turco”), um suposto autômato jogador\\nde xadrez que derrotou Napoleão antes de ser exposto como um armário de truques de mágica que\\nalojava um especialista humano em xadrez (consulte Levitt, 2000). Ele jogou de 1769 até 1854. Em\\n1846, Charles Babbage (que tinha ficado fascinado com o turco) parece ter colaborado para a\\nprimeira discussão séria sobre a viabilidade dos jogos de xadrez e damas por computador (Morrison\\ne Morrison, 1961). Ele não entendeu a complexidade exponencial das árvores de busca, alegando\\nque “as combinações envolvidas na máquina analítica superavam enormemente qualquer uma\\nrequerida, até mesmo pelo jogo de xadrez”. Babbage também projetou, mas não construiu, uma\\nmáquina de uso especial para jogar o jogo da velha. A primeira máquina para jogos verdadeira foi\\nconstruída por volta de 1890 pelo engenheiro espanhol Leonardo Torres y Quevedo. Ele se\\nespecializou no final do jogode xadrez “KRK” (rei e torre contra rei), garantindo uma vitória com rei\\ne torre a partir de qualquer posição.\\nEm geral, as origens do algoritmo minimax se localizam em um artigo publicado em 1912 por\\nErnst Zermelo, o desenvolvedor da moderna teoria de conjuntos. Infelizmente, o artigo continha\\nvários erros e não descrevia o minimax de forma correta. Por outro lado, ele delineou as ideias da\\nanálise retrógrada e propôs (mas não provou) o que ficou conhecido como teorema de Zermelo: que\\no xadrez é determinado — as brancas ou as pretas podem forçar uma vitória ou é um empate, só não\\nsabemos qual das opções. Zermelo diz que, se eventualmente soubéssemos, “o xadrez certamente\\nperderia completamente o caráter de jogo”. Uma sólida base para a teoria de jogos foi desenvolvida\\nno original trabalho \\nTheory of Games and Economic Behavior\\n (von Neumann e Morgenstern, 1944),\\nque incluía uma análise mostrando que alguns jogos \\nexigem\\n estratégias aleatórias (ou, pelo menos,\\nimprevisíveis). Consulte o Capítulo 17 para obter mais informações.\\nJohn McCarthy concebeu a ideia de busca alfa-beta em 1956, embora não a tivesse publicado. O', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 234}),\n",
       " Document(page_content='programa de xadrez NSS (Newell \\net al\\n., 1958) usava uma versão simplificada de alfa-beta; ele foi o\\nprimeiro programa de xadrez a usá-la. A poda alfa-beta foi descrita por Hart e Edwards (1961) e\\nHart \\net al\\n. (1972). Alfa-beta também foi usada pelo programa de xadrez “Kotok-McCarthy”, escrito\\npor um aluno de John McCarthy (Kotok, 1962). Knuth e Moore (1975) provaram a exatidão de alfa-\\nbeta e analisaram sua complexidade de tempo. Pearl (1982b) demonstra que alfa-beta é\\nassintoticamente ótima entre todos os algoritmos de busca de árvores de jogos de profundidade fixa.\\nVárias tentativas foram feitas para superar os problemas com a “abordagem-padrão” esboçados na\\nSeção 5.8\\n. O primeiro algoritmo de busca heurística não exaustiva com algum embasamento teórico\\nprovavelmente foi o B* (Berliner, 1979), que tentava manter limites intervalares sobre o valor\\npossível de um nó na árvore de jogo, em vez de dar a ele uma única estimativa de valor pontual. Nós\\nfolhas são selecionados para expansão em uma tentativa de aprimorar os limites de nível superior até\\num único movimento se mostrar “claramente melhor”. Palay (1985) estende a ideia de B*, utilizando\\ndistribuições de probabilidades sobre valores no lugar de intervalos. A busca de número de\\nconspiração de David McAllester (1988) expande nós de folhas que, pela alteração de seus valores,\\npoderiam fazer o programa preferir um novo movimento na raiz. O MGSS* (Russell e Wefald, 1989)\\nusa as técnicas de teoria da decisão do Capítulo 16 para estimar o valor da expansão de cada folha\\nem termos da melhoria esperada na qualidade da decisão na raiz. Ele superou um algoritmo alfa-beta\\nem Othello, apesar de buscar um número de nós uma ordem de magnitude menor. Em princípio, a\\nabordagem do MGSS* é aplicável ao controle de qualquer forma de deliberação.\\nEm muitos aspectos, a busca alfa-beta é a análoga para dois jogadores da busca em profundidade\\nramificada e limitada, dominada por A* no caso de um único agente. O algoritmo SSS* (Stockman,\\n1979) pode ser visualizado como um A* de dois jogadores e nunca expande mais nós que alfa-beta\\npara chegar à mesma decisão. Os requisitos de memória e a sobrecarga computacional da fila tornam\\nimpraticável o SSS* em sua forma original, mas foi desenvolvida uma versão que necessita de\\nespaço linear a partir do algoritmo RBFS (Korf e Chickering, 1996). Plaat \\net al\\n. (1996)\\ndesenvolveram uma nova visão do SSS* como uma combinação de alfa-beta e tabelas de\\ntransposição, mostrando como superar as desvantagens do algoritmo original e desenvolvendo uma\\nnova variante chamada MTD(\\nf\\n) que foi adotada por vários programas importantes.\\nD. F. Beal (1980) e Dana Nau (1980, 1983) estudaram as deficiências do minimax aplicado a\\navaliações aproximadas. Eles mostraram que, sob certas suposições de independência sobre a\\ndistribuição de valores de folhas na árvore, o uso do minimax pode gerar valores na raiz que na\\nrealidade são \\nmenos\\n confiáveis que o uso direto da própria função de avaliação. O livro de Pearl,\\nHeuristics\\n (1984), explica parcialmente esse paradoxo aparente e analisa muitos algoritmos de\\njogos. Baum e Smith (1997) propõem um substituto para o minimax baseado em probabilidades,\\nmostrando que ele resulta em escolhas melhores em certos jogos. O algoritmo expectiminimax foi\\nproposto por Donald Michie (1966). Bruce Ballard (1983) estendeu a poda alfa-beta para cobrir\\nárvores com nós de acaso e Hauk (2004) reexaminou esse trabalho e proporcionou resultados\\nempíricos.\\nKoller e Pfeffer (1997) descreveram um sistema para resolver completamente jogos parcialmente\\nobserváveis. O sistema é bastante geral, manipulação de jogos cuja estratégia ótima exige\\nmovimentos aleatórios e jogos que são mais complexos do que aqueles manipulados por qualquer\\nsistema anterior. Ainda assim, não pode manipular jogos tão complexos como pôquer, \\nbridge\\n e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 235}),\n",
       " Document(page_content='Kriegspiel. Franco \\net al.\\n (1998) descreveram diversas variantes da busca de Monte Carlo, incluindo\\numa em que o MIN tem informação completa, mas o MAX, não. Entre os jogos determinísticos,\\nparcialmente observáveis, o Kriegspiel recebeu mais atenção. Ferguson demonstrou estratégias\\nrandomizadas deduzidas à mão (\\nhand-derived\\n) para ganhar do Kriegspiel com um bispo e o cavalo\\n(1992) ou dois bispos (1995) contra um rei. Os primeiros programas Kriegspiel concentravam-se em\\nencontrar xeque-mates de final de jogo e executavam a busca E-OU no espaço do estado de crença\\n(Sakuta e Iida, 2002; Bolognesi e Ciancarini, 2003). Algoritmos de estado de crença incremental\\nhabilitaram xeque-mates de meio de jogo muito mais complexos de ser encontrados (Russell e Wolfe,\\n2005; Wolfe e Russell, 2007), mas a estimativa de estado eficiente continua a ser o principal\\nobstáculo para jogo geral efetivo (Parker \\net al\\n., 2005).\\nO \\nxadrez\\n foi uma das primeiras tarefas realizadas em IA, com esforços iniciais por muitos dos\\npioneiros da computação, incluindo Konrad Zuse em 1945, Norbert Wiener em seu livro\\nCybernetics\\n(1948) e Alan Turing em 1950 (veja Turing \\net al\\n., 1953). Mas foi o artigo de Claude\\nShannon, \\nPrograming a Computer for Playing Chess\\n (1950), que teve o mais completo conjunto de\\nideias, descrevendo uma representação de posições do tabuleiro, uma função de avaliação, a busca\\nde quiescência e algumas ideias de seletiva (não exaustiva) busca de jogo de árvore. Slater (1950) e\\nos comentaristas de seu artigo também exploraram as possibilidades para o jogo de xadrez de\\ncomputador.\\nD.G. Prinz (1952) concluiu um programa que resolvia problemas de final de jogo de xadrez, mas\\nque não jogou um jogo completo. Stan Ulam e um grupo em Los Alamos National Lab produziram um\\nprograma que jogava xadrez em um tabuleiro de 6 × 6 sem bispos (Kister \\net al\\n., 1957). Podia buscar\\nquatro jogadas profundas em cerca de 12 minutos. Alex Bernstein escreveu o primeiro programa\\ndocumentado para jogar um jogo completo de xadrez-padrão (Bernstein e Roberts, 1958).\\n5\\nA primeira partida de xadrez em computador apresentou o programa de Kotok-McCarthy do MIT\\n(Kotok, 1962), e o programa ITEP escrito em meados dos anos 1960 no Institute of Theoretical and\\nExperimental Physics em Moscou (Adelson-Velsky \\net al\\n., 1970). Essa partida intercontinental foi\\nrealizada por telégrafo. Terminou com uma vitória de 3×1 para o programa ITEP, em 1967. O\\nprimeiro programa de xadrez a competir com sucesso com os seres humanos foi o MacHack-6 do\\nMIT (Greenblatt \\net al\\n., 1967). Sua taxa Elo de cerca de 1.400 foi bem acima do nível iniciante de\\n1.000.\\nO Prêmio Fredkin, criado em 1980, ofereceu prêmios por metas progressivas no jogo de xadrez. O\\nBelle, que atingiu uma classificação de 2.250 (Condon e Thompson, 1982), ganhou um prêmio de\\nUS$5.000,00 pelo primeiro programa a conseguir uma classificação \\nmaster\\n. O prêmio de US$10.000\\npara o primeiro programa a conseguir uma classificação USCF (United States Chess Federation) de\\n2.500 (perto do nível \\ngrandmaster\\n) foi atribuído ao DEEP THOUGHT (Hsu \\net al\\n., 1990), em 1989.\\nO Deep Blue (Campbell \\net al\\n., 2002;. Hsu, 2004) recebeu o grande prêmio de US$100.000,00, por\\nsua vitória referencial sobre o campeão mundial Garry Kasparov em um jogo de exibição de 1997.\\nKasparov escreveu:\\nO jogo decisivo da partida foi o jogo 2, que deixou uma cicatriz em minha memória […] vimos\\nalgo que foi bem além de nossas expectativas mais otimistas do quanto um computador seria capaz\\nde prever as consequências posicionais em longo prazo das suas decisões. A máquina recusou-se a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 236}),\n",
       " Document(page_content='se mover para uma posição que tinha uma vantagem decisiva no curto prazo — mostrando um\\nsenso de perigo muito humano. (Kasparov, 1997)\\nFigura 5.15\\n Pioneiros no xadrez de computador: (a) Herbert Simon e Allen Newell, os\\ndesenvolvedores do programa NSS (1958); (b) John McCarthy e o programa Kotok-McCarthy em\\numa IBM 7090 (1967).\\nProvavelmente, a descrição mais completa de um programa de xadrez moderno foi fornecida por\\nErnst Heinz (2000), cujo programa DARKTHOUGHT foi o programa de PC não comercial mais bem\\nclassificado durante o campeonato mundial em 1999.\\nNos últimos anos, os programas de xadrez estão se sobrepondo até mesmo aos melhores seres\\nhumanos do mundo. Entre 2004 e 2005, o HYDRA derrotou o grande mestre Eigen Vladimirov por\\n3,5×0,5, o campeão mundial Ruflam Ponomariov por 2×0, e o sétimo do \\nranking\\n Michael Adams por\\n5,5×0,5. Em 2006, o DEEP FRITZ bateu o campeão mundial Vladimir Kramnik por 4×2 e, em 2007,\\no RYBKA venceu diversos grandes mestres em jogos em que ele deu chances (como um peão) para\\nos jogadores humanos. A partir de 2009, a mais alta classificação Elo já registrada foi de 2.851 por\\nKasparov. O HYDRA (Donninger e Lorenz, 2004) foi classificado em algum lugar entre 2.850 e\\n3.000, principalmente com base em sua derrota por Michael Adams. O programa RYBKA foi\\nclassificado entre 2.900 e 3.100, mas isso foi baseado em um pequeno número de jogos e não é\\nconsiderado confiável. Ross (2004) mostrou como os seres humanos aprenderam a explorar algumas\\ndas fraquezas dos programas de computador.\\nO \\njogo de damas\\n, em vez do xadrez, foi o primeiro dos jogos clássicos disputado inteiramente por\\num computador. Christopher Strachey (1952) escreveu o primeiro programa funcional para jogo de\\ndamas. Com início em 1952, Arthur Samuel, da IBM, trabalhando em seu tempo livre, desenvolveu\\num programa de damas que aprendeu sua própria função de avaliação, jogando consigo mesmo\\nmilhares de vezes (Samuel, 1959, 1967). Descreveremos essa ideia com mais detalhes no Capítulo\\n21. O programa de Samuel começou como um novato, mas depois de apenas alguns dias o autojogo\\ntinha melhorado além do próprio nível de Samuel. Em 1962, derrotou Robert Nealy, campeão em\\n“damas cegas”, através de um erro de sua parte. Quando se considera que os equipamentos de\\ncomputação de Samuel (um IBM 704) tinham 10.000 palavras na memória principal, uma fita\\nmagnética para armazenamento de longo prazo e um processador de 0,000001 GHz, a vitória é', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 237}),\n",
       " Document(page_content='considerada uma grande realização.\\nO desafio iniciado por Samuel foi retomado por Jonathan Schaeffer, da Universidade de Alberta.\\nSeu programa CHINOOK ficou em segundo lugar no Aberto dos Estados Unidos de 1990 e recebeu o\\ndireito de desafio para o campeonato mundial. Em seguida, enfrentou um problema chamado Marion\\nTinsley. O Dr. Tinsley tinha sido campeão do mundo há mais de 40 anos, perdendo apenas três jogos\\nem todo esse tempo. Na primeira partida contra o Chinook, Tinsley sofreu suas quarta e quinta\\nderrotas, mas venceu a partida por 20,5×18,5. Uma revanche no campeonato mundial de 1994\\nterminou prematuramente quando Tinsley teve que se retirar por motivos de saúde. O CHINOOK\\ntornou-se oficialmente o campeão do mundo. Schaeffer continuou construindo seu banco de dados de\\nfinais de jogos e, em 200, “resolveu” o jogo de damas (Schaeffer \\net al\\n., 2007; Schaeffer, 2008). Isso\\ntinha sido previsto por Richard Bellman (1965). No documento que introduziu a abordagem de\\nprogramação dinâmica para análise retrógrada, ele escreveu: “No jogo de damas, o número de\\nmovimentos possíveis em qualquer situação dada é tão pequeno que podemos esperar com confiança\\numa solução digital computacional completa para o problema de jogada ótima.” No entanto, Bellman\\nnão estimou plenamente o tamanho da árvore do jogo de damas. Existem cerca de 500 quatrilhões de\\nposições. Depois de 18 anos de computação em um \\ncluster\\n de 50 ou mais máquinas, a equipe de\\nJonathan Schaeffer completou uma tabela de final de jogo para todas as posições do jogo de damas\\ncom 10 ou menos peças: mais de 39 trilhões de entradas. A partir daí, foram capazes de fazer busca\\nalfa-beta adiantada para derivar uma política que prova que o jogo de damas é de fato um empate\\ncom o melhor jogo de ambos os lados. Observe que esta é uma aplicação de busca bidirecional\\n(\\nSeção 3.4.6\\n). A construção de uma tabela de final de jogo para todos os jogos de damas seria\\nimpraticável: seria necessário um bilhão de gigabytes de armazenamento. A busca sem qualquer\\ntabela também seria impraticável: a árvore de busca tem cerca de 8\\n47\\n posições, e levaria milhares de\\nanos de pesquisa com a tecnologia atual. Só uma combinação de busca inteligente, dados de final de\\njogo e uma queda no preço dos processadores e da memória poderia resolver o jogo de damas.\\nAssim, o jogo de damas juntou-se com o Qubic (Patashnik, 1980), o Connect Four (Allis, 1988) e o\\nNine-Men’s Morris (Gasser, 1998) como jogos que foram resolvidos por análise de computador.\\nO \\ngamão\\n, um jogo de azar, foi analisado matematicamente por Gerolamo Cardano (1663), mas foi\\ntido como jogo de computador apenas no final de 1970, primeiro com o programa BKG (Berliner,\\n1980b); ele usou uma função de avaliação complexa, construída manualmente e pesquisada apenas à\\nprofundidade 1. Foi o primeiro programa a derrotar um campeão mundial humano em um jogo\\nclássico maior (Berliner, 1980a). Berliner reconheceu prontamente que o BKG tinha muita sorte com\\nos dados. O TD-Gammon de Gerry Tesauro (1995) jogou consistentemente em campeonato em nível\\nmundial. O programa BGBLITZ foi o vencedor da Computer Olympiad de 2008.\\nO \\nGo\\n é um jogo determinístico, mas o grande fator de ramificação o torna um desafio. As\\nquestões-chave e a literatura prévia em computação com o Go foram resumidas por Bouzy e\\nCazenave (2001) e Muller (2002). Até 1997 não existiam programas de Go competentes. Hoje, os\\nmelhores programas jogam a \\nmaioria\\n dos seus lances em nível de mestre; o único problema é que no\\ndecorrer de um jogo eles costumam fazer pelo menos um erro grave que permite que um oponente\\nforte vença. Considerando que a busca alfa-beta reina na maioria dos jogos, muitos programas Go\\nrecentes têm adotado os métodos de Monte Carlo com base em esquema UCT (limite de confiança\\nsuperior em árvores) (Kocsis e Szepesvari, 2006). O programa Go mais potente como o de 2009 é o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 238}),\n",
       " Document(page_content='MOGO de Gelly e Silver (Wang e Gelly, 2007; Gelly e Silver, 2008). Em agosto de 2008, o MOGO\\nmarcou uma vitória surpreendente contra o profissional de alto nível Myungwan Kim, embora com o\\nMoGo recebendo uma vantagem de nove pedras (o equivalente a uma vantagem da rainha no xadrez).\\nKim estimou a resistência de MoGo em 2-3 dan, o nível baixo de amador avançado. Para essa\\npartida, o Mogo foi executado em um supercomputador com processador 800 de 15 teraflop (1.000\\nvezes o Deep Blue). Algumas semanas mais tarde, o Mogo, com apenas uma desvantagem de cinco\\npedras, ganhou contra um profissional por 6 dan. Na forma 9 × 9 do Go, o MoGo está\\naproximadamente no nível profissional 1 dan. Os avanços rápidos, provavelmente como\\nexperimentação, continuam com novas formas da busca de Monte Carlo. O \\nBoletim Go Computer\\n,\\npublicado pela Computer Go Association, descreve a evolução atual.\\nBridge\\n: Smith \\net al\\n. (1998) relataram sobre como o seu programa baseado em planejamento\\nganhou o campeonato de \\nbridge\\n por computador de 1998 e descreveram (Ginsberg, 2001) como o\\nseu programa GIB, com base na simulação de Monte Carlo, venceu o campeonato seguinte de\\ncomputador, e surpreendentemente bem, contra jogadores humanos e conjuntos de problemas-padrão\\nde livro. Em 2001-2007, o campeonato de \\nbridge\\n por computador foi vencido cinco vezes por JACK\\ne duas vezes por WBRIDGE. Não existem artigos acadêmicos de nenhum dos dois explicando sua\\nestrutura, mas os rumores é que ambos usaram a técnica de Monte Carlo, que foi proposta pela\\nprimeira vez para o jogo de \\nbridge\\n por Levy (1989).\\nPalavras cruzadas\\n: Brian Sheppard (2002), seu criador, forneceu uma boa descrição de um\\nprograma de topo, o Maven. A geração de movimentos de pontuação mais alta é descrita por Gordon\\n(1994), e a modelagem dos adversários foi coberta por Richards e Amir (2007).\\nFutebol\\n (Kitano \\net al\\n., 1997b; Visser \\net al\\n., 2008) e \\nbilhar\\n (Lam e Greenspan, 2008; Archibald \\net\\nal\\n., 2009) e outros jogos estocásticos com espaço contínuo de ações estão começando a atrair a\\natenção em IA, tanto na simulação como com jogadores robôs físicos.\\nCompetições de jogos de computador ocorrem anualmente, e os artigos aparecem em uma\\nvariedade de locais. Os anais da conferência de nome bastante ilusório, \\nHeuristic Programming in\\nArtificial Intelligence\\n, relatam as Computer Olympiads, que incluem grande variedade de jogos. O\\nGeneral Game Competition (Love \\net al\\n., 2006) testa programas que devem aprender a jogar\\ndeterminado jogo desconhecido apenas com uma descrição lógica das suas regras. Também existem\\ndiversas coleções editadas de artigos importantes sobre pesquisa na área de jogos (Levy, 1988a,\\n1988b; Marsland e Schaeffer, 1990). A International Computer Chess Association (ICCA), fundada\\nem 1977, publica o periódico trimestral \\nICGA Journal\\n (antigamente denominado \\nICCA Journal\\n).\\nForam publicados artigos importantes na antologia em série \\nAdvances in Computer Chess\\n,\\ncomeçando com o artigo de Clarke (1977). O volume 134 do periódico \\nArtificial Intelligence\\n (2002)\\ncontém descrições de programas de última geração para xadrez, Othello, Hex, \\nshogi\\n, Go, gamão,\\npôquer, Scrabble\\nTM\\n e outros jogos. Desde 1998 tem sido realizada uma conferência bienal,\\nComputers and Games\\n.\\nEXERCÍCIOS\\n5.1\\n Suponha que você tenha um oráculo, \\nOM\\n(\\ns\\n), que prevê corretamente o lance do oponente em', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 239}),\n",
       " Document(page_content='qualquer estado. Utilizando isso, formule a definição de um jogo como um problema de busca (agente\\núnico). Descreva um algoritmo para encontrar o lance ótimo.\\n5.2\\n Considere o problema de resolver o quebra-cabeça de oito peças.\\na\\n. Dê uma formulação completa do problema no estilo do Capítulo 3.\\nb\\n. Qual o tamanho do espaço de estados alcançável\\u200b\\u200b? Forneça uma expressão numérica exata.\\nc\\n. Suponha que desenvolvamos um problema adversário da seguinte forma: os dois jogadores se\\nrevezam em lance; uma moeda é arremessada para determinar o quebra-cabeça no qual o\\nmovimento deve ser feito nessa vez; e o vencedor será o primeiro a resolver um quebra-cabeça.\\nQual algoritmo pode ser usado para a escolha de um lance nesse cenário?\\nd\\n. Dê uma prova informal de que eventualmente alguém vai vencer se ambos jogarem\\nperfeitamente.\\n5.3\\n Imagine que, no Exercício 3.3, um dos amigos queira evitar o outro. O problema então se torna\\num jogo de dois jogadores de \\nperseguição e evasão\\n. Assumamos agora que os jogadores se movem\\npor vez. O jogo só termina quando os jogadores estão no mesmo nó; o resultado final para o\\nperseguidor é menos o tempo total necessário (o evasor “ganha” por nunca perder). A \\nFigura 5.16\\nmostra um exemplo.\\nFigura 5.16\\n (a) Um mapa onde o custo de cada aresta é 1. Inicialmente, o perseguidor \\nP\\n está no nó \\nb\\ne o evasor \\nE\\n está no nó \\nd\\n. (b) Uma árvore de jogo parcial para esse mapa. Cada nó é rotulado com as\\nposições \\nP\\n e \\nE\\n. \\nP\\n move-se em primeiro lugar. Ainda não foram explorados os ramos marcados com\\n“?”.\\na\\n. Copie a árvore de jogo e marque os valores dos nós terminais.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 240}),\n",
       " Document(page_content='b\\n. Ao lado de cada nó interno, escreva o fato mais forte que você pode inferir sobre o seu valor\\n(um número, uma ou mais desigualdades, tais como “≥14” ou um “?”).\\nc.\\n Abaixo de cada ponto de interrogação, escreva o nome do nó atingido por esse ramo.\\nd.\\n Explique como um limite sobre o valor dos nós em (c) pode ser derivado da consideração do\\ncomprimento do caminho mais curto no mapa e deduza tais limites para esses nós. Lembre-se do\\ncusto para chegar a cada folha, bem como do custo para resolvê-la.\\ne.\\n Suponha agora que a árvore como dada, com os limites de folha de (d), seja avaliada da\\nesquerda para a direita. Circule os nós “?” que \\nnão\\n precisam mais ser expandidos, dados os\\nlimites da parte (d), e risque aqueles que não precisam ser considerados.\\nf\\n. Você pode provar algo genérico sobre quem vai ganhar o jogo em um mapa que é uma árvore?\\n5.4\\n Descreva ou implemente descrições de estados, geradores de movimentos, testes de término,\\nfunções utilidade e funções de avaliação para um ou mais dos seguintes jogos estocásticos:\\nMonopoly, Scrabble, \\nbridge\\n com determinado acordo ou \\nTexas hold’em poker\\n (variante do pôquer).\\n \\n5.5\\n Descreva e implemente um ambiente de jogos de \\ntempo real\\n, de \\nvários participantes\\n, em\\nque o tempo faça parte do estado do ambiente e no qual os jogadores recebam alocações de tempo\\nfixas.\\n5.6\\n Descreva o quanto a abordagem-padrão para jogos se aplicaria bem a jogos como tênis, bilhar e\\ncroquet\\n, que ocorrem em um espaço de estados físicos contínuo.\\n5.7\\n Prove a seguinte afirmativa: para toda árvore de jogo, a utilidade obtida por MAX usando\\ndecisões de minimax contra um MIN não ótimo nunca será mais baixa que a utilidade obtida no jogo\\ncontra um MIN ótimo. Você poderia apresentar uma árvore de jogo em que MAX pudesse atuar ainda\\nmelhor usando uma estratégia \\nótima\\n contra um MIN não ótimo?\\n5.8\\n Considere o jogo de dois jogadores descrito na \\nFigura 5.17\\n.\\nFigura 5.17\\n Posição inicial de um jogo simples. O jogador \\nA\\n joga primeiro. Os dois jogadores se\\nrevezam na movimentação e cada jogador deve mover sua ficha para um espaço adjacente aberto em\\nqualquer sentido. Se o oponente ocupar um espaço adjacente, um jogador pode saltar sobre um\\noponente até o próximo espaço aberto, se houver (por exemplo, se \\nA\\n estiver em 3 e \\nB\\n estiver em 2, A\\npoderá voltar a 1). O jogo termina quando um jogador chegar à extremidade oposta do tabuleiro. Se o\\njogador \\nA\\n alcançar o espaço 4 primeiro, o valor do jogo para \\nA\\n será +1; se o jogador \\nB\\n alcançar o\\nespaço 1 primeiro, o valor do jogo para \\nA\\n será −1.\\na.\\n Desenhe a árvore de jogo completa, usando as convenções a seguir:\\n–  Escreva cada estado como (\\ns\\nA\\n, \\ns\\nB\\n), onde \\ns\\nA\\n e \\ns\\nB\\n denotam as posições das fichas.\\n–  Coloque cada estado terminal em um quadrado e escreva o valor de seu jogo em um círculo.\\n–  Insira os \\nestados de ciclo\\n (estados que já aparecem no caminho para a raiz) em quadrados\\nduplos. Tendo em vista que o valor não está claro, identifique cada um com um símbolo “?”', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 241}),\n",
       " Document(page_content='dentro de um círculo.\\nb.\\n Agora marque cada nó com seu valor minimax propagado de volta (também em um círculo).\\nExplique como você tratou os valores “?” e por quê.\\nc.\\n Explique por que o algoritmo minimax-padrão falharia nessa árvore de jogo e faça um resumo\\nde como você poderia corrigi-lo, baseando-se em sua resposta ao item (b). Seu algoritmo\\nmodificado oferece decisões ótimas para todos os jogos com ciclos?\\nd.\\n Esse jogo de quatro quadrados pode ser generalizado para \\nn\\n quadrados, para qualquer \\nn\\n > 2.\\nProve que \\nA\\n vence se \\nn\\n é par e perde se \\nn\\n é ímpar.\\n5.9\\n Este problema exercita os conceitos básicos do jogo usando o jogo da velha (zeros e cruzes)\\ncomo exemplo. Nós definimos \\nX\\nn\\n como o número de linhas, colunas ou diagonais com exatamente \\nn\\nX\\n e não \\nO\\n. Da mesma forma, \\nOn\\n é o número de linhas, colunas ou diagonais com apenas \\nn\\n \\nO\\n. A\\nfunção utilidade atribui +1 a qualquer posição com \\nX\\n3\\n = 1 e −1 em qualquer posição com \\nO\\n3\\n = 1.\\nTodas as outras posições terminais têm utilidade 0. Para posições não terminais, utilizamos uma\\nfunção linear de avaliação definida como \\nEval\\n(\\ns\\n) = 3\\nX\\n2\\n(\\ns\\n) + \\nX\\n1\\n(\\ns\\n) − (3\\nO\\n2\\n(\\ns\\n) + \\nO\\n1\\n(\\ns\\n)).\\na.\\n Existem cerca de quantos jogos da velha possíveis?\\nb.\\n Mostre toda a árvore de jogo começando de um tabuleiro vazio até a profundidade 2 (isto é, um\\nX\\n e um \\nO\\n na tabuleiro), levando a simetria em conta.\\nc.\\n Marque em sua árvore as avaliações de todas as posições com profundidade 2.\\nd.\\n Utilizando o algoritmo minimax, marque em sua árvore os valores propagados para as posições\\nà profundidade 1 e 0, e utilize esses valores para escolher a melhor jogada da partida.\\ne.\\n Circule os nós à profundidade 2 que \\nnão\\n seriam avaliados se a poda alfa-beta fosse aplicada,\\nassumindo que os nós são gerados na ordem ótima para a poda alfa-beta.\\n5.10\\n Considere a família de jogos da velha generalizada, definida da seguinte forma. Cada jogo em\\nparticular é especificado por um conjunto \\nS\\n de \\nquadrados\\n e uma coleção \\nW\\n de \\nposições vencedoras\\n.\\nCada posição vencedora é um subconjunto de \\nS\\n. Por exemplo, no jogo da velha padrão, \\nS\\n é um\\nconjunto de nove quadrados e \\nW\\n é uma coleção de oito subconjuntos de \\nW\\n: as três linhas, as três\\ncolunas e as duas diagonais. Em outros aspectos, o jogo é idêntico ao jogo da velha-padrão. A partir\\nde um tabuleiro vazio, os jogadores alternam-se colocando suas marcas em um quadrado vazio. Um\\njogador que marcar cada quadrado em uma posição vencedora ganhará o jogo. Será empate se todos\\nos quadrados forem marcados e ninguém ganhar o jogo.\\na\\n. Seja \\nN\\n = |\\nS\\n| o número de quadrados. Dê um limite superior do número de nós em uma árvore de\\njogo completa para o jogo da velha comum em função de \\nN\\n.\\nb\\n. Dê um limite inferior para o tamanho da árvore de jogo para o pior caso, onde \\nW\\n = { }.\\nc.\\n Proponha uma função de avaliação plausível que possa ser utilizada para qualquer exemplo de\\njogo da velha comum. A função pode depender de \\nS\\n e \\nW\\n.\\nd.\\n Assuma que seja possível gerar um novo tabuleiro e verifique se a instrução de máquina 100\\nN\\n é\\numa posição vencedora, assumindo um processador de 2 gigahertz. Ignore as limitações de\\nmemória. Utilizando a sua estimativa em (a), aproximadamente com que tamanho uma árvore de\\njogo pode ser completamente resolvida por alfa-beta em um segundo de tempo de CPU, em um', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 242}),\n",
       " Document(page_content='minuto, em uma hora?\\n \\n5.11\\n Desenvolva um programa de jogo genérico capaz de jogar uma variedade de jogos.\\na\\n. Implemente geradores de movimentação e funções de avaliação para um ou mais dos seguintes\\njogos: Kalah, Otelo, damas e xadrez.\\nb\\n. Construa um agente de jogo genérico alfa-beta.\\nc.\\n Compare o efeito de aumentar a profundidade da busca melhorando a ordem dos lances e\\nmelhorando a função de avaliação. O quão próximo chegará o seu fator efetivo de ramificação\\npara o caso ideal de ordenação de movimentação perfeita?\\nd\\n. Implemente um algoritmo de busca seletiva, tal como B* (Berliner, 1979), busca de número de\\nconspiração (McAllester, 1988) ou MGSS * (Russell e Wefald, 1989) e compare seu\\ndesempenho para A*.\\n5.12\\n Descreva como os algoritmos minimax e alfa-beta se alteram para \\njogos de soma diferente de\\nzero\\n com dois jogadores, em que cada jogador tem sua própria função utilidade e as funções\\nutilidades são conhecidas pelos dois jogadores. Suponha que cada jogador conheça a função\\nutilidade do outro. Se não houver restrições sobre as duas utilidades terminais, é possível qualquer\\nnó ser podado por alfa-beta? O que acontecerá se as funções utilidade do jogador em qualquer estado\\nfor a soma de um número entre as constantes −k e k, \\u200b\\u200btornando o jogo quase de soma zero?\\n5.13\\n Desenvolva uma prova formal da correção da poda alfa-beta. Para isso, considere a situação\\nmostrada na \\nFigura 5.18\\n. A questão é se devemos podar ou não o nó \\nn\\nj\\n, um nó de máximo\\ndescendente do nó \\nn\\n1\\n. A ideia básica é podá-lo se e somente se for possível mostrar que o valor\\nminimax de \\nn\\n1\\n é independente do valor de \\nn\\nj\\n.\\nFigura 5.18\\n Situação quando se considera se o nó \\nn\\nj\\n deve ser podado.\\na.\\n A Modalidade \\nn\\n1\\n assume o valor mínimo entre seus filhos: \\nn\\n1\\n = min (\\nn\\n2\\n, \\nn\\n21\\n,…,\\nn\\n2\\nb\\n2\\n). Encontre\\numa expressão semelhante para \\nn\\n2\\n e, consequentemente, uma expressão para \\nn\\n1\\n em termos de \\nnj\\n.\\nb.\\n Seja \\nl\\ni\\n o valor mínimo (ou máximo) dos nós à \\nesquerda\\n do nó \\nn\\ni\\n na profundidade \\ni\\n, cujo valor', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 243}),\n",
       " Document(page_content='minimax já é conhecido. De modo semelhante, seja \\nr\\ni\\n o valor mínimo (ou máximo) dos nós não\\nexplorados à direita de \\nn\\ni\\n na profundidade \\ni\\n. Reescreva sua expressão para \\nn\\n1\\n em termos dos\\nvalores \\nl\\ni\\n e \\nr\\ni\\n.\\nc.\\n Agora, reformule a expressão com a finalidade de mostrar que, para afetar \\nn\\n1\\n, o valor de \\nn\\nj\\n não\\ndeve exceder certo limite derivado dos valores de \\nl\\ni\\n.\\nd.\\n Repita o processo para o caso em que \\nn\\nj\\n é um nó de MIN.\\n5.14\\n Prove que a poda alfa-beta leva o tempo de \\nO\\n(2\\nm\\n/2\\n) com ordenação de lance ótimo, onde \\nm\\n é a\\nprofundidade máxima da árvore de jogo.\\n5.15\\n Vamos supor que você tenha um programa de xadrez capaz de avaliar 10 milhões de nós por\\nsegundo. Decida-se por uma representação compacta de um estado de jogo que será armazenada em\\numa tabela de transposição. Quantas entradas aproximadamente você poderá colocar em uma tabela\\nde 2 gigabytes na memória? Isso será suficiente para os três minutos de busca alocados a um único\\nmovimento? Quantos acessos à tabela você poderá efetuar no tempo que levaria para realizar uma\\núnica avaliação? Agora, suponha que a tabela de transposição seja maior do que é possível caber na\\nmemória. Aproximadamente quantas avaliações você poderia efetuar no tempo necessário para\\nrealizar um único acesso a disco com hardware de disco-padrão?\\n5.16\\n Esta questão considera a poda em jogos com nós de acaso. A \\nFigura 5.19\\n mostra a árvore de\\njogo completa para um jogo trivial. Suponha que os nós folha estejam para ser avaliados na ordem da\\nesquerda para a direita e que, antes de um nó folha ser avaliado, não sabemos nada sobre o seu valor\\n— a faixa de valores possíveis é −∞ até ∞.\\nFigura 5.19\\n A árvore de jogo completa para um jogo trivial com nós de acaso.\\na\\n. Copie a figura, marque o valor de todos os nós internos e indique a melhor jogada na raiz com\\numa seta.\\nb\\n. Dados os valores das primeiras seis folhas, precisamos avaliar a sétima e oitava folhas? Dados\\nos valores das sete primeiras folhas, precisamos avaliar a oitava folha? Explique suas\\nrespostas.\\nc\\n. Suponha que os valores do nó folha estejam entre −2 e 2, inclusive. Após as duas primeiras\\nfolhas serem avaliadas, qual é o intervalo de valor para o nó de acaso da esquerda?\\nd.\\n Circule todas as folhas que não precisam ser avaliadas sob o pressuposto em (c).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 244}),\n",
       " Document(page_content='5.17\\n Implemente o algoritmo expectiminimax e o algoritmo *-alfa-beta, descrito por Ballard\\n(1983), para podar árvores de jogo com nós de acaso. Experimente-os em um jogo como o gamão e\\nmeça a eficiência de poda do algoritmo *-alfa-beta.\\n5.18\\n Prove que, com uma transformação linear positiva de valores de folha (isto é, a transformação\\nde um valor \\nx\\n em \\nax\\n + \\nb\\n onde \\na\\n > 0), a escolha do movimento permanece inalterada em uma árvore\\nde jogo, mesmo quando existem nós de acaso.\\n5.19\\n Considere o procedimento a seguir para escolher movimentos em jogos com nós de acaso:\\n•  Gere algumas sequências de lançamentos de dados (digamos, 50) descendo até uma\\nprofundidade apropriada (digamos, 8).\\n•  Com lançamentos de dados conhecidos, a árvore de jogo se torna determinística. Para cada\\nsequência de lançamentos de dados, resolva a árvore de jogo determinística resultante usando\\nalfa-beta.\\n•  Utilize os resultados para estimar o valor de cada movimento e escolher o melhor.\\n•  Esse procedimento funcionará bem? Por quê (ou por que não)?\\n5.20\\n A seguir, uma árvore “max” consiste apenas em nós max, enquanto uma árvore “expectimax”\\nconsiste em um nó max na raiz com camadas alternadas ao acaso e nós max. Nos nós de acaso, todas\\nas probabilidades resultantes são diferentes de zero. O objetivo é \\nencontrar o valor da raiz\\n com uma\\nbusca de profundidade limitada.\\na\\n. Assumindo que os valores da folha são finitos mas ilimitados, será possível a poda (como em\\nalfa-beta) em uma árvore max? Dê um exemplo ou explique por que não.\\nb\\n. A poda é sempre possível em uma árvore expectimax nas mesmas condições? Dê um exemplo\\nou explique por que não.\\nc\\n. Se os valores da folha são não negaivos, a poda é sempre possível em uma árvore max? Dê um\\nexemplo ou explique por que não.\\nd\\n. Se os valores da folha são não negativos, a poda é sempre possível em uma árvore expectimax?\\nDê um exemplo ou explique por que não.\\ne\\n. Se os valores da folha são restritos na faixa [0, 1], a poda é sempre possível em uma árvore\\nmax? Dê um exemplo ou explique por que não.\\nf\\n. Se os valores da folha são restritos na faixa [0, 1], a poda é sempre possível em uma árvore\\nexpectimax?\\ng\\n. Considere os resultados de um nó de acaso em uma árvore expectimax. Qual das seguintes\\nordens de avaliação é mais provável de produzir oportunidades de poda?\\n(i) Menor probabilidade em primeiro lugar\\n(ii) Maior probabilidade em primeiro lugar\\n(iii) Não faz qualquer diferença\\n5.21\\n Quais das seguintes alternativas são verdadeiras e quais são falsas? Dê breves explicações.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 245}),\n",
       " Document(page_content='a\\n. Em um jogo totalmente observável, de revezamento, de soma zero, entre dois jogadores\\nperfeitamente racionais, não ajuda o primeiro jogador saber que estratégia o segundo jogador\\nestá usando, isto é, o lance do segundo jogador é baseado no lance do primeiro jogador.\\nb\\n. Em um jogo totalmente observável, de revezamento, de soma zero, entre dois jogadores\\nperfeitamente racionais, não ajuda o primeiro jogador saber que lance o segundo jogador fará,\\ndado o lance do primeiro jogador.\\nc\\n. Um agente de gamão perfeitamente racional nunca perde.\\n5.22\\n Considere cuidadosamente a interação de eventos de acaso e a informação parcial em cada um\\ndos jogos do Exercício 5.4.\\na.\\n Para qual deles o modelo expectiminimax padrão é apropriado? Implemente o algoritmo e\\nexecute-o em seu agente de jogos, com modificações apropriadas para o ambiente de jogos.\\nb\\n. Para quais deles o esquema descrito no Exercício 5.19 seria apropriado?\\nc\\n. Descreva como você poderia lidar com o fato de que, em alguns jogos, os jogadores não têm o\\nmesmo conhecimento do estado corrente.\\n1\\n Ambientes com muitos agentes são mais bem visualizados como \\neconomias\\n, em vez de jogos.\\n2\\n É óbvio que isso não pode ser realizado com perfeição; caso contrário, a função de ordenação poderia ser utilizada para se jogar um\\njogo perfeito!\\n3\\n Às vezes, o estado de crença vai se tornar muito grande para representar apenas uma lista de estados de tabuleiro, mas vamos ignorar\\nessa questão por ora; os Capítulos 7 e 8 sugerem um método para representar compactamente os estados de crença muito grandes.\\n4\\n Blefar — apostar que uma mão é boa, mesmo quando não é — é uma parte essencial da estratégia do pôquer.\\n5\\n Um programa russo, o BESM, pode ter antecipado o programa Bernstein.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 246}),\n",
       " Document(page_content='O\\nCAPÍTULO\\n \\n6\\nProblemas de satisfação de restrições\\nEm que vemos como o tratamento de estados como algo mais que apenas\\npequenas caixas-pretas nos leva à criação de ampla variedade de novos e\\npoderosos métodos de busca e a uma compreensão mais profunda da estrutura\\ne da complexidade dos problemas.\\ns Capítulos 3 e 4 exploraram a ideia de que os problemas podem ser resolvidos buscando-se em\\num espaço de \\nestados\\n. Esses estados podem ser avaliados por heurísticas específicas de\\ndomínios e testados para se verificar se eles são estados objetivo. Porém, do ponto de vista do\\nalgoritmo de busca, cada estado é \\natômico, ou indivisível —\\n uma caixa-preta, sem estrutura interna.\\nEste capítulo descreve uma maneira de resolver uma grande variedade de problemas de forma\\nmais eficiente. Utilizaremos uma \\nrepresentação fatorada\\n para cada estado: um conjunto de\\nvariáveis, cada qual com um valor. O problema será resolvido quando cada variável tiver um valor\\nque satisfaça todas as restrições sobre a variável. Um problema assim descrito é chamado de\\nproblema de satisfação de restrição\\n ou PSR.\\nOs algoritmos de busca PSR aproveitam a estrutura de estados e utilizam heurísticas de \\npropósito\\ngeral\\n em vez de heurísticas \\nespecíficas de problemas\\n para permitir a solução de problemas\\ncomplexos. A ideia principal é eliminar grande parte do espaço de busca de uma só vez através da\\nidentificação de combinações de variável/valor que violam as restrições.\\n6.1 DEFINIÇÃO DE PROBLEMAS DE SATISFAÇÃO DE RESTRIÇÕES\\nUm problema de satisfação de restrição consiste em três componentes, \\nX\\n, \\nD\\n e \\nC\\n:\\nX\\n é um conjunto de variáveis\\u200b\\u200b, {\\nX\\n1\\n,…, \\nX\\nn\\n}.\\nD\\n é um conjunto de domínios, {\\nD\\n1\\n,…, \\nD\\nn\\n}, um para cada variável.\\nC\\n é um conjunto de restrições que especificam combinações de valores possíveis.\\nCada domínio \\nD\\ni\\n consiste em um conjunto de valores possíveis, {\\nv\\n1\\n,…, \\nv\\nk\\n} para a variável \\nX\\ni\\n.\\nCada restrição \\nC\\ni\\n consiste em um par \\n〈\\nescopo, rel\\n〉\\n, onde \\nescopo\\n é uma tupla de variáveis que\\nparticipam da restrição e \\nrel\\n é uma relação que define os valores que essas variáveis \\u200b\\u200bpodem assumir.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 248}),\n",
       " Document(page_content='Uma relação pode ser representada como uma lista explícita de todas as tuplas de valores que\\nsatisfazem a restrição ou como uma relação abstrata que sustenta duas operações: testar se uma tupla\\né um membro da relação e enumerar os membros da relação. Por exemplo, se \\nX\\n1\\n e \\nX\\n2\\n têm o domínio\\n{A, B}, então a restrição que exprime as duas variáveis deve ter valores diferentes que podem ser\\nescritos como \\n〈\\n(\\nX\\n1\\n, \\nX\\n2\\n), [(\\nA\\n, \\nB\\n), (\\nB\\n, \\nA\\n)]\\n〉\\n ou como \\n〈\\n(\\nX\\n1\\n, \\nX\\n2\\n), \\nX\\n1\\n ≠ \\nX\\n2\\n〉\\n.\\nPara resolver um PSR, precisamos definir um espaço de estados e a noção de solução. Cada\\nestado em um PSR é definido por uma \\natribuição\\n de valores a algumas ou todas as variáveis, {X\\ni\\n =\\nv\\ni\\n, \\nX\\nj\\n = \\nv\\nj\\n…}. Uma atribuição que não viola quaisquer restrições é chamada de atribuição\\nconsistente\\n ou legal. Uma \\natribuição completa\\n é aquela em que cada variável é atribuída, e uma\\nsolução\\n para um PSR é uma atribuição consistente e completa. A \\natribuição parcial\\n é aquela que\\natribui valores para apenas algumas das variáveis.\\n6.1.1 Exemplo de problema: coloração de mapa\\nVamos supor que, cansados da Romênia, estamos observando um mapa da Austrália, que mostra\\ncada um de seus estados e territórios, como o da \\nFigura 6.1\\n(a). Recebemos a tarefa de colorir cada\\nregião de vermelho, verde ou azul, de tal modo que nenhuma região vizinha tenha a mesma cor. Para\\nformular esse problema como um PSR, definimos as variáveis para representar as regiões\\nFigura 6.1\\n (a) Os principais estados e territórios da Austrália. A coloração desse mapa pode ser\\nvista como um problema de satisfação de restrições (PSR). O objetivo é atribuir cores a cada região\\nde modo que não haja regiões vizinhas com a mesma cor. (b) O problema de coloração de mapa\\nrepresentado como um grafo de restrições.\\nO domínio de cada variável é o conjunto D\\ni\\n = {\\nvermelho, verde, azul\\n}. As restrições exigem que\\nregiões vizinhas tenham cores distintas. Como há nove lugares onde as regiões são fronteiriças, há\\nnove restrições:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 249}),\n",
       " Document(page_content='Aqui estamos utilizando abreviaturas; \\nAM ≠ A\\nO é um atalho para \\n〈\\n(\\nAM\\n, \\nAO\\n), \\nAM\\n ≠ \\nAO\\n〉\\n, onde \\nAM\\n≠ AO\\n por sua vez pode ser totalmente enumerado como\\nExistem muitas soluções possíveis para este problema, tais como:\\nÉ útil visualizar um PSR como um \\ngrafo de restrições\\n, como mostra a \\nFigura 6.1\\n(b). Os nós do\\ngrafo correspondem às variáveis do problema, e uma ligação conecta quaisquer duas variáveis que\\nparticipem de uma restrição.\\nPor que formular um problema como um PSR? Uma razão é que os PSRs produzem uma\\nrepresentação natural para uma ampla variedade de problemas; se você já tem um sistema de\\nresolução de PSR, é muitas vezes mais fácil utilizá-lo para resolver um problema do que projetar\\numa solução personalizada utilizando outra técnica de busca. Além disso, solucionadores de PSR\\npodem ser mais rápidos do que buscadores de espaço de estados porque os solucionadores de PSR\\npodem eliminar rapidamente grandes amostras do espaço de busca. Por exemplo, uma vez escolhido\\n{AM = \\nazul\\n} no problema da Austrália, podemos concluir que nenhuma das cinco variáveis vizinhas\\npode assumir o valor \\nazul.\\n Sem tomar partido da propagação de restrições, um procedimento de\\nbusca teria que considerar 3\\n5\\n = 243 atribuições para as cinco variáveis vizinhas; com propagação de\\nrestrições nunca teremos que considerar o \\nazul\\n como um valor, por isso temos apenas 2\\n5\\n = 32\\natribuições para verificar, uma redução de 87%.\\nEm busca de espaço de estados regulares podemos apenas perguntar: esse estado específico é um\\nobjetivo? Não? E esse aqui? Com PSRs, uma vez que descobrimos que uma atribuição parcial não é\\numa solução, podemos descartar imediatamente novos refinamentos de atribuição parcial. Além\\ndisso, podemos ver \\npor que\\n a atribuição não é uma solução — verificamos quais variáveis violam\\numa restrição — para que possamos centrar a atenção sobre as variáveis que importam. Como\\nresultado, muitos problemas que são intratáveis para busca de espaço de estados regular podem ser\\nrapidamente resolvidos quando formulados como um PSR.\\n6.1.2 Problema-exemplo: agendamento de tarefas\\nAs fábricas têm o problema de fixar o valor de um dia de trabalho, sujeito a várias restrições. Na\\nprática, muitos desses problemas são resolvidos com técnicas de PSR. Considere o problema de\\nplanejar a montagem de um carro. Todo o trabalho é composto de tarefas, e podemos modelar cada\\ntarefa como uma variável, em que o valor de cada variável é o tempo em que começa a tarefa,\\nexpresso como um número inteiro de minutos. As restrições podem afirmar que uma tarefa deve\\nocorrer antes da outra, por exemplo, uma roda deve ser instalada antes que a calota seja colocada, e\\nque apenas tais tarefas podem ser simultâneas. As restrições também podem especificar que uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 250}),\n",
       " Document(page_content='tarefa leva certo tempo para ser concluída.\\nConsideraremos uma pequena parte da montagem de automóveis, composta de 15 tarefas: instalar\\neixos (frente e trás), afixar quatro rodas (direita e esquerda, frente e trás), apertar as porcas em cada\\nroda, afixar as calotas e inspecionar a montagem final. Podemos representar as tarefas com 15\\nvariáveis:\\nO valor de cada variável é a hora que a tarefa começa. Em seguida, representaremos as \\nrestrições\\nde precedência\\n entre tarefas individuais. Sempre que uma tarefa \\nT\\n1\\n deve ocorrer antes da tarefa \\nT\\n2\\n e\\na tarefa \\nT\\n1\\n tem duração \\nd\\n1\\n para acabar, adiciona-se uma restrição aritmética da forma\\nNo nosso exemplo, os eixos têm que estar no lugar antes de as rodas serem colocadas, e leva 10\\nminutos para instalar um eixo, de modo que escrevemos\\nEm seguida, dizemos que, para cada roda, devemos afixar a roda (o que leva um minuto), em\\nseguida, apertar as porcas (dois minutos) e, finalmente, colocar a calota (um minuto, mas não está\\nainda representado):\\nSuponha que tenhamos quatro trabalhadores para instalar as rodas, mas eles têm que compartilhar\\numa ferramenta que ajuda a colocar o eixo no lugar. Precisamos de uma \\nrestrição disjuntiva\\n para\\ndizer que o \\nEixoF\\n e o \\nEixoT\\n não devem ser sobrepostos no tempo: ou um ou outro deve vir em\\nprimeiro lugar:\\nParece ser uma restrição mais complicada, combinando aritmética e lógica, mas ainda se reduz a\\num conjunto de pares de valores que o \\nEixo\\nF\\n e o \\nEixo\\nF\\n podem assumir.\\nPrecisamos ainda definir que a inspeção vem por último e leva três minutos. Para cada variável,\\nexceto \\ninspeção,\\n adicionamos uma restrição da forma \\nX + d\\nX\\n ≤ Inspeção. Finalmente, suponha que\\nhaja uma exigência para ter todo o conjunto realizado em 30 minutos. Podemos conseguir isso\\nlimitando o domínio de todas as variáveis:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 251}),\n",
       " Document(page_content='Esse problema em particular é trivial para resolver, mas foram aplicados PSRs para agendamento\\nde tarefas como esse, com milhares de variáveis. Em alguns casos, existem restrições complicadas\\nque são difíceis de especificar no formalismo PSR, e técnicas mais avançadas de planejamento são\\nutilizadas, como as que serão discutidas no Capítulo 11.\\n6.1.3 Variações do formalismo PSR\\nA espécie mais simples de PSR envolvendo variáveis tem \\ndomínios discretos e finitos\\n. Os\\nproblemas de coloração de mapas e de agendamento de prazos são desse tipo. O problema de oito\\nrainhas descrito no Capítulo 3 também pode ser visto como um PSR de domínios finitos, onde as\\nvariáveis \\nQ\\n1\\n, …,\\nQ\\n8\\n são as posições de cada rainha nas colunas\\n1, …, 8, e onde cada variável tem o domínio \\nD\\ni\\n = {1, 2, 3, 4, 5, 6, 7, 8}.\\nUm domínio discreto pode ser \\ninfinito\\n, como o conjunto de números inteiros ou de cadeias de\\ncaracteres (se não colocássemos um prazo para o problema de agendamento de tarefas, haveria um\\nnúmero infinito de horários de início para cada variável). No caso de domínios infinitos, não é mais\\npossível descrever restrições enumerando todas as combinações de valores permitidas. Em vez\\ndisso, deve ser utilizada uma \\nlinguagem de restrições\\n para compreender restrições diretamente, tais\\ncomo \\nT\\n1\\n + \\nd\\n1\\n ≤ \\nT\\n2\\n, sem enumerar o conjunto de pares de valores permitidos para (\\nT\\n1\\n, \\nT\\n2\\n).\\nExistem algoritmos de solução especial (que não discutiremos aqui) para \\nrestrições lineares\\nsobre variáveis inteiras, ou seja, restrições como a que acabamos de mostrar, em que cada variável\\nsó aparece em forma linear. É possível mostrar que não existe nenhum algoritmo para resolver\\nrestrições não lineares\\n sobre variáveis inteiras.\\nOs problemas de satisfação de restrições com \\ndomínios contínuos\\n são muito comuns no mundo\\nreal e amplamente estudados no campo de pesquisa operacional. Por exemplo, o escalonamento de\\nexperimentos no telescópio espacial Hubble exige sincronização muito precisa de observações; o\\ncomeço e o fim de cada observação e a manobra são variáveis de valores contínuos que devem\\nobedecer a uma variedade de restrições astronômicas, de precedência e de energia. A categoria mais\\nconhecida de PSRs de domínios contínuos é a dos problemas de \\nprogramação linear\\n, em que as\\nrestrições devem ser equações ou inequações lineares que formam uma região \\nconvexa\\n. Os\\nproblemas de programação linear podem ser resolvidos em tempo polinomial no número de\\nvariáveis. Também foram estudados problemas com diferentes tipos de restrições e funções objetivo\\n— programação quadrática, programação cônica de segunda ordem, e assim por diante.\\nAlém de examinar os tipos de variáveis que podem aparecer em PSRs, é útil examinar os tipos de\\nrestrições. O tipo mais simples é a \\nrestrição unária\\n, que restringe o valor de uma única variável.\\nPor exemplo, no probema de coloração do mapa, os australianos do sul poderiam não tolerar a cor\\nverde; isso pode ser expresso com a restrição unária \\n〈\\n(\\nAM\\n), \\nAM\\n ≠ \\nverde\\n〉\\n.\\nUma \\nrestrição binária\\n relaciona duas variáveis. Por exemplo, \\nAM ≠\\n \\nNGS\\n é uma restrição binária.\\nUm PSR binário é aquele que só tem restrições binárias; ele pode ser representado como um grafo de\\nrestrições, conforme mostra a \\nFigura 6.1\\n(b).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 252}),\n",
       " Document(page_content='Também podemos descrever restrições de ordem superior, tal como afirmar que o valor de \\nY\\n está\\nentre \\nX\\n e \\nZ\\n, com a restrição ternária \\nEntre\\n(\\nX\\n, \\nY\\n, \\nZ\\n).\\nA restrição que envolve um número arbitrário de variáveis \\u200b\\u200bé chamada \\nde restrição global\\n (o nome\\né tradicional, mas confuso, porque não é necessário envolver todas as variáveis em um problema).\\nUma das restrições globais mais comuns é \\nTodosDiferentes\\n, que determina que todas as variáveis \\nenvolvidas em uma restrição devem ter valores diferentes. Em problemas de Sudoku (veja a \\nSeção\\n6.2.6\\n), todas as variáveis em uma linha ou coluna devem satisfazer uma restrição \\nTodosDiferentes\\n.\\nOutro exemplo é fornecido pelos quebra-cabeças \\ncriptoaritméticos\\n (veja a \\nFigura 6.2\\n(a)). Cada\\nletra em um quebra-cabeça criptoaritmético representa um dígito diferente. No caso da \\nFigura 6.2\\n(a),\\nisso seria representado como restrição global \\nTodosDiferentes\\n(\\nF\\n, \\nT\\n, \\nU\\n, \\nW\\n, \\nR\\n, \\nO\\n). As restrições de\\nadição sobre as quatro colunas do quebra-cabeça também envolvem diversas variáveis e podem ser\\nrepresentadas como as seguintes restrições \\nn\\n-árias:\\nonde \\nC\\n10\\n, \\nC\\n100\\n e \\nC\\n1000\\n são \\nvariáveis auxiliares\\n representando o dígito transportado para a coluna\\ndécima, centésima, milésima. Essas restrições de ordem alta podem ser representadas em um\\nhipergrafo de restrições\\n, como mostra a \\nFigura 6.2\\n(b). Um hipergrafo consiste em nós ordinários\\n(os círculos na figura) e os hipernós (os quadrados), representam restrições \\nn\\n-árias.\\nFigura 6.2\\n (a) Um problema criptoaritmético. Cada letra representa um dígito distinto; o objetivo é\\nencontrar uma substituição de letras por dígitos, tal que a soma aritmética resultante seja correta, com\\na restrição adicional de não se permitir nenhum zero à esquerda. (b) O hipergrafo de restrições para\\no problema criptoaritmético, mostrando a restrição \\nTodosDiferentes\\n (caixa quadrada no topo), bem\\ncomo as restrições de adição de colunas (as quatro caixas quadradas ao centro). As variáveis \\nC\\n1\\n, \\nC\\n2\\ne \\nC\\n3\\n representam os dígitos de transporte para as três colunas.\\nAlternativamente, como o Exercício 6.6 pede que você prove, cada restrição de domínio finito\\npode ser reduzida a um conjunto de restrições binárias se forem introduzidas variáveis auxiliares\\nsuficientes para que possamos transformar qualquer PSR em um com restrições apenas binárias,\\ntornando os algoritmos mais simples. Outra forma de converter um PSR \\nn\\n-ário em um binário é pela\\ntransformação \\ngrafo dual\\n: criar um novo grafo no qual haverá uma variável para cada restrição no', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 253}),\n",
       " Document(page_content='grafo original e uma restrição binária para cada par de restrições no grafo original que partilha as\\nvariáveis.\\nPor exemplo, se o grafo original tiver as variáveis {\\nX\\n, \\nY\\n, \\nZ\\n} e as restrições \\n〈\\n(\\nX\\n, \\nY\\n, \\nZ\\n), \\nC\\n1\\n〉\\n e \\n〈\\n(\\nX\\n,\\nY\\n), \\nC\\n2\\n〉\\n, então o grafo dual teria as variáveis {\\nC\\n1\\n, \\nC\\n2\\n} com a restrição binária \\n〈\\n(\\nX\\n, \\nY\\n), \\nR\\n1\\n〉\\n, onde (\\nX\\n,\\nY\\n) são as variáveis compartilhadas e \\nR\\n1\\n é uma nova relação que define a restrição entre as variáveis \\ncompartilhadas, conforme especificado pelo original \\nC\\n1\\n e \\nC\\n2\\n.\\nNo entanto, existem duas razões pelas quais é preferível uma restrição global, tal como\\nTodosDiferentes,\\n do que um conjunto de restrições binárias. Primeiro, é mais fácil e menos\\nsuscetível a erros escrever a descrição do problema usando \\nTodosDiferentes\\n. Segundo, é possível\\nprojetar algoritmos de inferências de propósitos especiais para restrições globais que não estejam\\ndisponíveis para um conjunto de restrições mais primitivas. Descreveremos esses algoritmos de\\ninferência na \\nSeção 6.2.5\\n.\\nAs restrições que descrevemos até agora foram todas restrições absolutas, cuja violação elimina\\numa solução potencial. Muitos PSRs reais incluem \\nrestrições de preferência\\n, indicando as soluções\\npreferidas. Por exemplo, em um problema de elaboração de horário de aula em uma universidade há\\nrestrições absolutas, como a que nenhum professor pode dar duas aulas ao mesmo tempo. Mas\\npodemos também permitir restrições de preferência: o professor R pode preferir lecionar pela\\nmanhã, enquanto o professor N pode preferir lecionar à tarde. Um agendamento que tenha o professor\\nR lecionando às 14 horas ainda seria uma solução (a menos que o professor R seja o chefe do\\ndepartamento), mas não seria uma solução ótima. As restrições de preferência frequentemente podem\\nser codificadas como custos sobre atribuições de variáveis individuais — por exemplo, a atribuição\\nde um horário de aula à tarde para o professor R custa dois pontos contra a função objetivo global,\\nenquanto um horário pela manhã custa um. Com essa formulação, os PSRs com preferências podem\\nser resolvidos utilizando-se métodos de busca de otimização, baseados em caminhos ou locais.\\nChamamos tal problema de \\nproblema de otimização de restrição\\n, ou POR. Problemas de\\nprogramação linear realizam esse tipo de otimização.\\n6.2 PROPAGAÇÃO DE RESTRIÇÃO: INFERÊNCIA EM PSRs\\nNa busca regular em espaços de estados, um algoritmo pode fazer apenas uma coisa: busca. Em\\nPSRs há uma escolha: um algoritmo pode buscar (escolher uma nova atribuição para a variável de\\nvárias possibilidades) ou fazer um tipo específico de \\ninferência\\n chamada \\npropagação de restrições\\n:\\nutilizando as restrições para reduzir o número de valores válidos para uma variável, o que, por sua\\nvez, pode reduzir os valores válidos para outra variável, e assim por diante. A propagação de\\nrestrição pode ser interligada com a busca ou pode ser feita como uma etapa de pré-processamento,\\nantes que a busca seja iniciada. Às vezes, esse pré-processamento pode resolver todo o problema e,\\nassim, não é requerida nenhuma busca.\\nA ideia-chave é a \\nconsistência local\\n. Se tratarmos cada variável como um nó em um grafo (veja a\\nFigura 6.1\\n (b)) e cada restrição binária como um arco, o processo de aplicar a consistência local em\\ncada parte do grafo faz com que os valores inconsistentes sejam eliminados em todo o grafo. Existem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 254}),\n",
       " Document(page_content='tipos diferentes de consistência local, que cobriremos agora.\\n6.2.1 Consistência de nó\\nA única variável (correspondente a um nó na rede PSR) é \\nnó-consistente\\n se todos os valores no\\ndomínio da variável satisfizerem as restrições unárias da variável. Por exemplo, na variante do\\nproblema de coloração do mapa da Austrália (\\nFigura 6.1\\n), onde os australianos do sul não gostam de\\nverde, a variável AM começa com o domínio {\\nvermelho, verde, azul\\n}, e podemos torná-la nó-\\nconsistente, eliminando o \\nverde\\n, deixando \\nAM\\n com o domínio reduzido {\\nvermelho, azul\\n}. Dizemos\\nque uma rede é nó-consistente se todas as variáveis \\u200b\\u200bda rede forem nó-consistentes.\\nÉ sempre possível eliminar todas as restrições unárias em um PSR executando nó-consistência.\\nTambém é possível transformar todas as restrições \\nn\\n-árias em binárias (veja o Exercício 6.6). Por\\nisso, é comum definir solucionadores de PSR que trabalham apenas com as restrições binárias;\\nfaremos essa suposição no restante deste capítulo, exceto onde indicado.\\n6.2.2 Consistência de arco\\nUma variável em um PSR é \\narco-consistente\\n se todos os valores em seu domínio satisfizerem as\\nrestrições binárias da variável. Mais formalmente, \\nX\\ni\\n é arco-consistente com relação à outra variável\\nX\\nj\\n se separa cada valor no domínio atual \\nD\\ni\\n quando houver algum valor no domínio \\nD\\nj\\n que satisfaça\\na restrição binária sobre o arco (\\nX\\ni\\n, \\nX\\nj\\n). Uma rede é arco-consistente se cada variável for arco-\\nconsistente com todas as outras variáveis. Por exemplo, considere a restrição \\nY\\n = \\nX\\n2\\n, onde o domínio\\nde \\nX\\n e \\nY\\n é o conjunto de dígitos. Podemos escrever essa restrição explicitamente como\\nPara tornar \\nX\\n arco-consistente com relação a \\nY\\n, reduzimos o domínio de \\nX\\n para {0, 1, 2, 3}. Se\\ntornarmos também \\nY\\n arco-consistente com relação a \\nX\\n, o domínio de \\nY\\n torna-se {0, 1, 4, 9} e todo o\\nPSR será arco-consistente.\\nPor outro lado, a consistência de arco não pode fazer nada com respeito ao problema de coloração\\ndo mapa da Austrália. Considere a seguinte restrição de desigualdade em (\\nAM\\n, \\nAO\\n):\\nNão importa o valor escolhido para \\nAM\\n (ou para \\nAO\\n), há um valor válido para a outra variável.\\nAssim, a aplicação de consistência de arco não tem efeito sobre os domínios de qualquer variável.\\nO algoritmo mais popular para a consistência de arco é chamado de AC-3 (veja a \\nFigura 6.3\\n).\\nPara tornar toda a variável arco-consistente, o algoritmo AC-3 mantém uma fila de arcos a\\nconsiderar (na verdade, a ordem de consideração não é importante, por isso a estrutura de dados é\\nrealmente um conjunto, mas a tradição a considera uma fila). Inicialmente, a fila contém todos os\\narcos no PSR. O AC-3, então, saltará de um arco arbitrário (\\nX\\ni\\n, \\nX\\nj\\n) da fila e se tornará \\nX\\ni\\n arco-', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 255}),\n",
       " Document(page_content='consistente com relação a \\nX\\nj\\n. Se deixar \\nD\\ni\\n inalterado, o algoritmo apenas se moverá para o arco\\nseguinte. Mas, se isso modificar \\nD\\ni\\n (torna o domínio menor), adicionamos todos os arcos à fila (\\nX\\nk\\n,\\nX\\ni\\n), onde \\nX\\nk\\n é um vizinho de \\nX\\ni\\n. Precisamos fazer isso porque a alteração em \\nD\\ni\\n pode permitir novas\\nreduções nos domínios de \\nD\\nk\\n, mesmo que tenhamos considerado anteriormente \\nX\\nk\\n. Se \\nD\\ni\\n for\\nmodificado para nada, saberemos que todo o PSR não tem uma solução consistente e o AC-3 poderá\\nretornar falha imediatamente. Caso contrário, continuamos a verificar, tentando remover os valores\\ndos domínios das variáveis até que não haja mais arcos na fila. Nesse ponto, estaremos com um PSR\\nque é equivalente ao PSR original — ambos têm as mesmas soluções, mas, na maioria dos casos, o\\nPSR arco-consistente será mais rápido na busca porque suas variáveis \\u200b\\u200btêm domínios menores.\\nfunção\\n AC-3(\\npsr\\n) \\nretornar\\n falso se uma inconsistência for encontrada e verdadeiro se não for\\n    \\nentradas\\n: \\npsr\\n, um PSR binário com componentes (\\nX\\n, \\nD\\n, \\nC\\n)\\n    \\nvariáveis locais\\n: \\nfila\\n, uma fila de arcos, inicialmente todos os arcos em \\npsr\\n    \\n    \\nenquanto\\n \\nfila\\n não está vazia \\nfaça\\n        (\\nX\\ni\\n, \\nX\\nj\\n) ← REMOVAR-PRIMEIRO(\\nfila\\n)\\n        \\nSe\\n REVISAR(\\npsr\\n, \\nX\\ni\\n, \\nX\\nj\\n) \\nentão\\n            \\nSe\\n tamanho de \\nD\\ni\\n = 0 \\nentão retornar\\n \\nfalso\\n            \\npara cada\\n \\nX\\nk\\n \\nem\\n \\nX\\ni\\n.VIZINHANÇAS - {\\nX\\nj\\n} \\nfaça\\n                adicionar (\\nX\\nk\\n, \\nX\\ni\\n) à fila\\n    \\nretornar\\n verdadeiro\\n_____________________________________________________________________________________________________________\\nfunção\\n REVISAR(\\npsr\\n, \\nX\\ni\\n, \\nX\\nj\\n) \\nretornar\\n verdadeiro se revisarmos o domínio de \\nXi\\n    \\nrevisado\\n ← \\nfalso\\n    \\npara cada\\n \\nx\\n \\nem\\n \\nD\\ni\\n \\nfaça\\n        \\nse\\n nenhum valor \\ny\\n em \\nD\\nj\\n permite (\\nx\\n,\\ny\\n) para satisfazer a restrição entre \\nX\\ni\\n e \\nX\\nj\\n \\nentão\\n            excluir \\nx\\n de \\nD\\ni\\n            \\nrevisado\\n ← \\nverdadeiro\\n    \\nretornar\\n \\nrevisado\\nFigura 6.3\\n Algoritmo de consistência de arco AC-3. Após aplicar AC-3, cada arco fica arco-\\nconsistente ou alguma variável tem um domínio vazio, indicando que o PSR não pode ser resolvido.\\nO nome “AC-3” foi utilizado pelo inventor do algoritmo (Mackworth, 1977) por ser a terceira versão\\ndesenvolvida no documento.\\nA complexidade de AC-3 pode ser analisada como segue. Assumir um PSR com \\nn\\n variáveis, cada\\numa com o tamanho de domínio, no máximo, \\nd\\n, e com \\nc\\n restrições binárias (arcos). Cada arco (\\nX\\nk\\n,\\nX\\ni\\n) pode ser inserido na fila apenas d vezes porque \\nX\\ni\\n tem, no máximo, \\nd\\n valores para excluir. A\\nverificação da consistência de um arco pode ser feita no tempo \\nO\\n(\\nd\\n2\\n), então temos \\nO\\n(\\ncd\\n3\\n) total de\\ncasos de pior tempo.\\n1', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 256}),\n",
       " Document(page_content='É possível estender a noção de consistência de arco para manusear restrições \\nn\\n-árias em vez de\\napenas binárias; isso se chama \\nconsistência de arco generalizada\\n ou, algumas vezes, consistência\\nde hiperarco, dependendo do autor. Uma variável \\nX\\ni\\n é \\narco-consistente generalizada\\n com relação a\\numa restrição \\nn\\n-ária se, para cada valor \\nv\\n no domínio \\nX\\ni\\n, existir uma dupla de valores que seja um\\nmembro da restrição, tenha todos os seus valores retirados dos domínios das variáveis\\ncorrespondentes e tenha seu componente \\nX\\ni\\n igual a \\nv\\n. Por exemplo, se todas as variáveis tiverem o\\ndomínio {0, 1, 2, 3}, então para tornar a variável \\nX\\n consistente com a restrição \\nX\\n < \\nY\\n < \\nZ\\n, teríamos\\nque eliminar 2 e 3 do domínio de \\nX\\n porque a restrição não pode ser satisfeita quando \\nX\\n é 2 ou 3.\\n6.2.3 Consistência de caminho\\nA consistência de arco pode contribuir muito para reduzir os domínios das variáveis, por vezes\\nencontrar uma solução (ao reduzir cada domínio ao tamanho 1) e, por vezes, constatar que o PSR não\\npode ser resolvido (através da redução de algum domínio ao tamanho 0). Mas, para outras redes, a\\nconsistência de arco não faz inferências suficientes. Considere o problema de coloração do mapa da\\nAustrália, mas apenas com duas cores permitidas, vermelho e azul. A consistência de arco não pode\\nfazer nada porque todas as variáveis já são arco-consistentes: cada uma pode estar do outro lado do\\narco vermelho e azul (ou vice-versa). Mas certamente não há solução para o problema porque,\\ndevido ao oeste da Austrália, e os territórios do norte e do sul tocarem um no outro, precisamos de\\npelo menos três cores só para eles.\\nA consistência de arco fixa os domínios para baixo (restrições unárias) utilizando os arcos\\n(restrições binárias). Para progredir com problemas como de coloração de mapa, precisamos de uma\\nnoção forte de consistência. A c\\nonsistência de caminho\\n fixa as restrições binárias utilizando\\nrestrições implícitas que são inferidas pela verificação do triplo de variáveis.\\nUm conjunto de duas variáveis {\\nX\\ni\\n, \\nX\\nj\\n} é consistente de caminho em relação a uma terceira\\nvariável \\nX\\nm\\n se, para cada atribuição {\\nX\\ni\\n = \\na\\n, \\nX\\nj\\n = \\nb\\n} consistente com as restrições em {\\nXi\\n, \\nXj\\n},\\nhouver uma atribuição para \\nX\\nm\\n que satisfaça as restrições em {\\nX\\ni\\n, \\nX\\nm\\n} e {\\nX\\nm\\n, X\\nj\\n}. Isso se chama\\nconsistência de caminho porque se pode cogitar isso ao olhar para um caminho de \\nX\\ni\\n para \\nX\\nj\\n com \\nX\\nm\\nao meio.\\nVejamos como a consistência de caminho se sai ao colorir o mapa da Austrália com duas cores.\\nFaremos o conjunto {\\nAO\\n, \\nAM\\n} consistente de caminho em relação a \\nTN\\n. Começaremos por enumerar\\nas atribuições consistentes para o conjunto. Nesse caso, há apenas duas: {\\nAO\\n = \\nvermelho\\n, \\nAM\\n =\\nazul\\n}e {\\nAO\\n = \\nazul\\n, \\nAM\\n = \\nvermelho\\n}. Podemos ver que nas duas atribuições \\nTN\\n não pode ser nem\\nvermelho nem azul (porque entraria em conflito com \\nAO\\n ou \\nAM\\n). Por não haver uma opção válida\\npara \\nTN\\n, eliminaremos as duas atribuições e finalizaremos sem atribuição válida para {\\nAO\\n, \\nAM\\n}.\\nPortanto, sabemos que não pode haver solução para esse problema. O algoritmo PC-2 (Mackworth,\\n1977) alcança a consistência de caminho da mesma maneira que o AC-3 alcança a consistência de\\narco. Por ser tão semelhante, não o demonstraremos aqui.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 257}),\n",
       " Document(page_content='6.2.4 \\nK\\n-Consistência\\nCom a noção de \\nk\\n-\\nconsistência\\n pode-se definir formas mais fortes de propagação. A PSR é k-\\nconsistente se, para qualquer conjunto de \\nk\\n − 1 variáveis e para qualquer atribuição consistente para\\naquelas variáveis, um valor consistente puder sempre ser atribuído a qualquer variável \\nk\\n-ésima. 1-\\nconsistência determina que, dado o conjunto vazio, podemos tornar qualquer conjunto de uma\\nvariável consistente: isso é o que se chama consistência de nó. 2-consistência é a mesma consistência\\nde arco. Para redes de restrição binária, 3-consistência é a mesma consistência de caminho.\\nA PSR é \\nfortemente\\n \\nk\\n-\\nconsistente\\n se for \\nk\\n-consistente e também (\\nk\\n − 1)-consistente, (\\nk\\n − 2)-\\nconsistente, … até 1-consistente. Agora, suponha que tenhamos um PSR com \\nn\\n nós e o tornamos\\nfortemente \\nn\\n-consistente (ou seja, fortemente \\nk\\n-consistente para \\nk\\n = \\nn\\n). Podemos, então, resolver o\\nproblema da seguinte maneira: primeiro, escolhemos um valor consistente para \\nX\\n1\\n. Estamos então\\ngarantidos de ser capazes de escolher um valor para \\nX\\n2\\n porque o grafo é 2-consistente, para \\nX\\n3\\nporque é 3-consistente, e assim por diante. Para cada variável \\nX\\ni\\n, precisamos apenas buscar através\\nde \\nd\\n valores no domínio para encontrar um valor consistente com X\\n1\\n, …, \\nX\\ni\\n−1\\n. Temos a garantia de\\nencontrar uma solução no tempo \\nO\\n(\\nn\\n2\\nd\\n). Claro, não há almoço grátis: para qualquer algoritmo\\nestabelecer a consistência, \\nn\\n terá que levar \\nn\\n tempo exponencial no pior caso. Pior, a consistência \\nn\\ntambém requer espaço que é exponencial em \\nn\\n. O problema de memória é ainda mais grave do que o\\nde tempo. Na prática, determinar o nível adequado de verificação de consistência, sobretudo, é uma\\nciência empírica. Pode-se dizer que praticantes calculam a 2-consistência comumente, e menos\\ncomumente a 3-consistência.\\n6.2.5 Restrições globais\\nLembre-se de que uma \\nrestrição global\\n é aquela que envolve um número arbitrário de variáveis \\n(mas não necessariamente todas as variáveis). Em problemas reais ocorrem com frequência\\nrestrições globais e podem ser tratadas por algoritmos com propósitos especiais que são mais\\neficientes que os métodos de uso geral descritos até agora. Por exemplo, a restrição \\nTodosDiferentes\\ndetermina que todas as variáveis envolvidas devem ter valores distintos (como no problema\\ncriptoaritmético anterior e nos quebra-cabeças Sudoku adiante). Uma forma simples de detecção de\\ninconsistência para as restrições \\nTodosDiferentes\\n funciona da seguinte forma: se \\nm\\n variáveis \\nestiverem envolvidas na restrição e se tiverem \\nn\\n possíveis valores completamente distintos, e \\nm\\n > \\nn\\n,\\nentão a restrição não poderá ser satisfeita.\\nIsso conduz ao seguinte algoritmo simples: primeiro, retire qualquer variável da restrição que\\ntenha um domínio avulso e exclua o valor dessa variável dos domínios das variáveis restantes.\\nRepita enquanto existirem variáveis avulsas. Se em algum momento for produzido um domínio vazio\\nou restarem mais variáveis \\u200b\\u200bdo que valores de domínio, foi detectada uma inconsistência.\\nEsse método pode detectar a inconsistência na atribuição {\\nAO\\n = \\nvermelho\\n, \\nNGS\\n = \\nvermelho\\n} para\\na \\nFigura 6.1\\n. Observe que as variáveis \\nAM\\n, \\nTN\\n e \\nQ\\n estão efetivamente ligadas por uma restrição\\nTodosDiferentes\\n porque cada par deve ter duas cores diferentes. Após aplicar AC-3 com a restrição', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 258}),\n",
       " Document(page_content='parcial, o domínio de cada variável será reduzido para {\\nverde, azul\\n}. Isto é, temos três variáveis e\\napenas duas cores, por isso a restrição \\nTodosDiferentes\\n foi violada. Assim, um procedimento\\nsimples de consistência de uma restrição de ordem superior é muitas vezes mais eficaz do que\\naplicar a consistência de arco para um conjunto equivalente de restrições binárias. Existem mais\\nalgoritmos de inferência complexos para \\nTodosDiferentes\\n (veja Van Hoeve e Katriel, 2006) que\\npropagam mais restrições, mas computacionalmente a execução é mais cara.\\nOutra restrição importante de ordem superior é a \\nrestrição de recurso\\n, chamada algumas vezes de\\nrestrição \\natmost\\n. Por exemplo, em um problema de programação, façamos \\nP\\n1\\n, …, \\nP\\n4\\n denotar o\\nnúmero de pessoal atribuído a cada uma de quatro tarefas. A restrição de que não mais que 10\\npessoas sejam designadas no total é escrita como \\natmost\\n (10, \\nP\\n1\\n, \\nP\\n2\\n, \\nP\\n3\\n, \\nP\\n4\\n). Podemos detectar uma\\ninconsistência simplesmente verificando a soma dos valores mínimos dos domínios atuais; por\\nexemplo, se cada variável tiver um domínio {3, 4, 5, 6}, a restrição \\natmost\\n não poderá ser satisfeita.\\nPodemos também garantir a consistência, excluindo o valor máximo de qualquer domínio se não for\\nconsistente com os valores mínimos dos outros domínios. Assim, se cada variável em nosso exemplo\\ntiver o domínio {2, 3, 4, 5, 6}, os valores 5 e 6 poderão ser excluídos de cada domínio.\\nPara grandes problemas de recursos limitados a valores inteiros, tais como os problemas de\\nlogística envolvendo a movimentação de milhares de pessoas em centenas de veículos, geralmente\\nnão é possível representar o domínio de cada variável como um grande conjunto de números inteiros\\ne gradualmente reduzir esse conjunto com métodos de verificação de consistência. Em vez disso, os\\ndomínios são representados por limites superiores e inferiores, e são geridos por \\npropagação de\\nlimites\\n. Por exemplo, em um problema de programação de voo, vamos supor que existam dois voos,\\nF\\n1\\n e \\nF\\n2\\n, para os quais a capacidade dos aviões é de 165 e 385, respectivamente. Os domínios\\niniciais para o número de passageiros em cada voo são, então,\\nD\\n1\\n =[0, 165] e \\nD\\n2\\n =[0, 385].\\nAgora, suponha que tenhamos a restrição adicional de que dois voos juntos devem levar 420\\npessoas: \\nF\\n1\\n + \\nF\\n2\\n = 420. Propagando as restrições de limites, reduzimos os domínios para\\nD\\n1\\n =[35, 165] e \\nD\\n2\\n =[255, 385].\\nDizemos que um PSR é \\nde limites consistentes\\n se, para cada variável \\nX\\n, e tanto para os valores\\nde \\nX\\n do limite superior como para do inferior, existir algum valor de \\nY\\n que satisfaça a restrição entre\\nX\\n e \\nY\\n para cada variável Y. Esse tipo de propagação de limite é amplamente utilizado em problemas\\npráticos de restrição.\\n6.2.6 Exemplo: Sudoku\\nO quebra-cabeça popular \\nSudoku\\n apresentou a milhões de pessoas os problemas de satisfação de\\nrestrição, apesar de talvez poderem não reconhecê-los. Uma tábua de Sudoku é composta de 81\\nquadrados, alguns dos quais são preenchidos inicialmente com os dígitos e 1 a 9. O enigma é', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 259}),\n",
       " Document(page_content='preencher todos os quadrados restantes de tal forma que nenhum dígito apareça duas vezes em\\nqualquer linha, coluna ou caixa 3 × 3 (ver a \\nFigura 6.4\\n). A linha, coluna ou caixa é chamada de\\nunidade\\n.\\nFigura 6.4\\n (a) Um quebra-cabeça Sudoku e (b) sua solução.\\nA propriedade dos quebra-cabeças de Sudoku que são impressos em jornais e livros de quebra-\\ncabeça é que existe exatamente apenas uma solução. Apesar de alguns serem complicados de\\nresolver à mão, levando dezenas de minutos, até mesmo os problemas mais difíceis de Sudoku\\npodem ser resolvidos por um solucionador PSR em menos de 0,1 segundo.\\nUm quebra-cabeça Sudoku pode ser considerado um PSR com 81 variáveis, uma para cada\\nquadrado. Utilizamos os nomes das variáveis \\nA1\\n até \\nA9\\n para a linha de cima (da esquerda para a\\ndireita), para a linha de baixo de \\nI1\\n até \\nI9\\n. Os quadrados vazios têm o domínio {1, 2, 3, 4, 5, 6, 7, 8,\\n9} e os quadrados pré-preenchidos têm um domínio que consiste em um único valor. Além disso,\\nexistem 27 restrições \\nTodasDiferentes\\n: uma para cada linha, coluna e caixa de nove quadrados.\\nRestrições \\nTodosDiferentes\\n: um para cada linha, coluna e caixa com 9 quadrados.\\nVamos ver até onde a consistência de arco pode nos levar. Assuma que as restrições\\nTodosDiferentes\\n foram expandidas em restrições binárias (tais como A1 ≠ \\nA2\\n) para que possamos\\naplicar o algoritmo AC-3 diretamente. Considere a variável \\nE6\\n da \\nFigura 6.4\\n (a) — o quadrado\\nvazio entre o 2 e o 8 na caixa do meio. Podemos remover das restrições na caixa, não apenas 2 e 8,\\nmas também 1 e 7 do domínio \\nE6\\n. Das restrições nessa coluna, podemos eliminar 5, 6, 2, 8, 9 e 3.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 260}),\n",
       " Document(page_content='Deixando \\nE6\\n com um domínio de {4}; em outras palavras, sabemos a resposta para \\nE6\\n. Agora\\nconsidere a variável \\nI6\\n — o quadrado na caixa do meio embaixo cercado por 1, 3 e 3. Aplicando a\\nconsistência de arco em sua coluna, eliminamos 5, 6, 2, 4 (já que sabemos agora que \\nE6\\n deve ser 4),\\n8, 9 e 3. Eliminamos 1 por consistência de arco com \\nI5\\n, e restou apenas o valor 7 no domínio de \\nI6\\n.\\nAgora existem oito valores conhecidos na coluna 6, de modo que a consistência de arco pode inferir\\nque \\nA6\\n deve ser 1. A inferência continua ao longo dessas linhas e, eventualmente, AC-3 pode\\nresolver todo o quebra-cabeça — todas as variáveis têm os seus domínios reduzidos a um único\\nvalor, como mostrado na \\nFigura 6.4\\n (b).\\nCertamente o Sudoku perderia o seu apelo se cada quebra-cabeça puder ser resolvido por uma\\naplicação mecânica de AC-3, e realmente o AC-3 só funciona para os quebra-cabeças de Sudoku\\nmais fáceis. Aqueles um pouco mais difíceis podem ser resolvidos por PC-2, mas a um custo\\ncomputacional maior: há 255.960 restrições diferentes de caminho para considerar em um quebra-\\ncabeça Sudoku. Para resolver os quebra-cabeças mais difíceis e fazer progressos eficientes, teremos\\nque ser mais espertos.\\nDe fato, para o solucionador humano, o apelo do quebra-cabeças Sudoku é a necessidade de ser\\ncriativo na aplicação de estratégias de inferência mais complexas. Os aficionados lhes dão nomes\\ncoloridos, tais como triplos nus”. Essa estratégia funciona da seguinte maneira: em qualquer unidade\\n(linha, coluna ou caixa), encontre três quadrados em que cada um tenha um domínio que contenha os\\nmesmos três números ou um subconjunto desses números. Por exemplo, os três domínios podem ser\\n{1, 8}, {3, 8} e {1, 3, 8}. A partir deles não sabemos qual quadrado contém 1, 3 ou 8, mas sabemos\\nque os três números deverão ser distribuídos entre os três quadrados. Portanto, podemos remover 1,\\n3 e 8 dos domínios de todos os \\noutros\\n quadrados na unidade.\\nÉ interessante observar como se pode ir longe sem dizer muito que seja específico ao Sudoku.\\nNaturalmente temos que dizer que existem 81 variáveis, que os seus domínios são os dígitos 1 a 9 e\\nque existem 27 restrições \\nTodosDiferentes\\n. Mas, além disso, todas as estratégias — consistência de\\narco, consistência de caminho etc., geralmente são aplicáveis a todos os PSRs, não apenas para os\\nproblemas de Sudoku. Mesmo os triplos nus são realmente uma estratégia para reforçar a\\nconsistência das restrições de \\nTodosDiferentes\\n e não tem nada a ver com o Sudoku \\nper se\\n. Esse é o\\npoder do formalismo PSR: para cada nova área problemática, precisamos apenas definir o problema\\nem termos de restrições; em seguida os mecanismos gerais de resolução de restrição podem assumir.\\n6.3 BUSCA COM RETROCESSO PARA PSRs\\nOs problemas de Sudoku são projetados para ser resolvidos por inferência sobre as restrições.\\nMas muitos outros PSRs não podem ser resolvidos apenas por inferência; chega um momento em que\\ndevemos procurar uma solução. Nesta seção, veremos os algoritmos de busca com retrocesso que\\nfuncionam com atribuições parciais; na próxima seção veremos algoritmos de busca local sobre\\ntarefas completas.\\nPoderíamos aplicar uma busca em profundidade limitada padrão (do Capítulo 3). Um estado seria\\numa atribuição parcial, e uma ação seria a adição \\nvar = valor\\n para a atribuição. Mas, para um PSR\\ncom \\nn\\n variáveis \\u200b\\u200bde tamanho de domínio \\nd\\n, logo notamos algo terrível: o fator de ramificação no nível', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 261}),\n",
       " Document(page_content='superior é \\nnd\\n porque qualquer valor entre \\nd\\n valores pode ser atribuído a qualquer das \\nn\\n variáveis.\\nNo próximo nível, o fator de ramificação é (\\nn\\n – 1)\\nd\\n, e assim por diante para \\nn\\n níveis. Geramos uma\\nárvore com \\nn\\n! \\n⋅\\n \\nd\\nn\\n folhas, embora existam apenas \\nd\\nn\\n atribuições completas possíveis!\\nNossa formulação de problema aparentemente razoável mas ingênua ignorou uma propriedade\\ncrucial, comum a todo os PSRs: a \\ncomutatividade\\n. Um problema é comutativo se a ordem de\\naplicação de qualquer conjunto de ações dado não tem nenhum efeito sobre o resultado. PSRs são\\ncomutativos, pois ao atribuir valores às variáveis, chegamos à mesma tarefa parcial,\\nindependentemente da ordem. Portanto, basta considerarmos uma \\núnica\\n variável em cada nó na\\nárvore de busca.\\nPor exemplo, no nó raiz de uma árvore de busca para coloração do mapa da Austrália, poderíamos\\nter uma escolha entre \\nAM\\n = \\nvermelho\\n, \\nAM\\n = \\nverde\\n e \\nAM\\n = \\nazul\\n, mas nunca escolheríamos entre \\nAM\\n= \\nvermelho\\n e \\nAO\\n = \\nazul\\n. Com essa restrição, o número de folhas é \\nd\\nn\\n, como seria de esperar.\\nA expressão \\nbusca com retrocesso\\n é utilizada para indicar uma busca em profundidade que\\nescolhe valores para uma variável de cada vez e que efetua o retrocesso quando uma variável não\\ntem valores válidos restantes a serem atribuídos. O algoritmo é mostrado na \\nFigura 6.5\\n. Ele escolhe\\nrepetidamente uma variável não atribuída e depois experimenta todos os valores no domínio da\\nvariável, por vez, tentando encontrar uma solução. Se for detectada uma inconsistência, o\\nRETROCESSO-RECURSSIVO retorna falha, fazendo com que a chamada anterior tente outro valor.\\nParte da árvore de busca para o problema da Austrália é mostrada na \\nFigura 6.6\\n, onde atribuímos\\nvariáveis na ordem \\nAO\\n, \\nTN\\n, \\nQ\\n,… Como a representação de PSRs é padronizada, não há necessidade\\nde prover PESQUISA-COM-RETROCESSO com um estado inicial específico de domínio, função\\nação, modelo de transição ou teste de objetivo.\\nfunção\\n PESQUISA-COM-RETROCESSO(\\npsr\\n) \\nretorna\\n uma solução ou falha\\n    \\nretornar\\n RETROCESSO-RECURSIVO({ }, \\npsr\\n)\\n \\nfunção\\n RETROCESSO-RECURSIVO(\\natribuição\\n, \\npsr\\n) \\nretorna\\n uma solução ou falha\\n    \\nse\\n \\natribuição\\n é completa \\nentão retornar\\n \\natribuição\\n    \\nvar\\n ← SELECIONAR-VARIÁVEL-NÃO-ATRIBUÍDA(\\npsr)\\n    \\npara cada\\n \\nvalor em\\n VALORES-DE-ORDEM-NO-DOMÍNIO(\\nvar\\n, \\natribuição\\n, \\npsr\\n) \\nfaça\\n        \\nse\\n \\nvalor\\n é consistente com \\natribuição\\n \\nentão\\n            adicionar { \\nvar\\n = \\nvalor\\n } a \\natribuição\\n            \\ninferência\\n ← \\nINFERÊNCIA(psr\\n, \\natribuição\\n, \\nvar)\\n            \\nse\\n \\ninferência ≠ falhar\\n \\nentão\\n                adicione \\ninferência\\n para \\natribuição\\n                \\nresultado\\n ← RETROCESSO-RECURSIVO(\\natribuição\\n, \\npsr\\n)\\n                \\nse\\n \\nresultado\\n ≠ \\nfalha\\n \\nentão\\n                    \\nretornar\\n \\nresultado\\n        remover { \\nvar\\n = \\nvalor\\n } de \\natribuição\\n    \\nretornar\\n \\nfalha\\nFigura 6.5\\n Um algoritmo simples com retrocesso para problemas de satisfação de restrições. O', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 262}),\n",
       " Document(page_content='algoritmo é modelado sobre a busca recursiva em profundidade do Capítulo 3. Pela variação das\\nfunções SELECIONAR-VARIÁVEL-NÃO-ATRIBUÍDA e VALORES-DE-ORDEM-NO-DOMÍNIO\\npodemos implementar as heurísticas de uso geral descritas no texto. A função INFERÊNCIA pode\\nser utilizada opcionalmente para impor arco-, caminho- ou \\nk\\n-consistência, conforme desejado. Se\\numa escolha de valor levar ao fracasso (por INFERÊNCIA ou por RETROCESSO-RECURSSIVO),\\nas atribuições de valor (incluindo as realizadas por INFERÊNCIA) são removidas da atribuição e\\num novo valor será experimentado.\\nFigura 6.6\\n Parte da árvore de busca gerada por retrocesso simples para o problema de coloração de\\nmapa da \\nFigura 6.1\\n.\\nNote que a PESQUISA-COM-RETROCESSO mantém apenas uma representação única de um\\nestado e altera essa representação, em vez de criar novas, conforme descrito anteriormente.\\nNo Capítulo 3 melhoramos o fraco desempenho de algoritmos de busca sem informações\\nfornecendo a eles funções heurísticas específicas do domínio, derivadas de nosso conhecimento do\\nproblema. Ocorre que podemos resolver PSRs de maneira eficiente sem tal conhecimento específico\\nde domínio. Em vez disso, podemos acrescentar um pouco de sofisticação para as funções não\\nespecificadas na \\nFigura 6.5\\n utilizando-as para abordar as seguintes questões:\\n1. Que variável deve ser atribuída em seguida (SELECIONAR-VARIÁVEL-NÃO-ATRIBUÍDA),\\ne em que ordem seus valores devem ser experimentados (VALORES-DE-ORDEM-NO-\\nDOMÍNIO)?\\n2. Que inferências devem ser realizadas a cada etapa na busca (INFERÊNCIA)?\\n3. Quando a pesquisa chega a uma atribuição que viola uma restrição, a busca pode evitar a\\nrepetição desse fracasso?\\nAs subseções a seguir respondem a cada uma dessas perguntas.\\n6.3.1 Ordenação de variáveis e valores\\nO algoritmo com retrocesso contém a linha:\\nvar\\n ← SELECIONAR-VARIÁVEL-NÃO-ATRIBUÍDA-VARIÁVEIS(\\npsr\\n)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 263}),\n",
       " Document(page_content='A estratégia mais simples para SELECIONAR-VARIÁVEL-NÃO-ATRIBUÍDA é escolher a\\npróxima variável não atribuída na ordem {\\nX\\n1\\n, \\nX\\n2\\n, …}. Essa ordenação de variáveis estáticas\\nraramente resulta na busca mais eficiente. Por exemplo, depois das atribuições de \\nAO\\n = \\nvermelho\\n e\\nTN\\n = \\nverde\\n na \\nFigura 6.6\\n, só existe um valor possível para \\nAM\\n; então, faz sentido atribuir em seguida\\nAM\\n = \\nazul\\n em lugar de atribuir \\nQ\\n. De fato, depois de \\nAM\\n ser atribuído, as escolhas para \\nQ\\n, \\nNGS\\n e \\nV\\nsão todas forçadas. Essa ideia intuitiva — escolher a variável com o menor número de valores\\n“válidos” — é chamada heurística de \\nvalores restantes mínimos\\n (VRM). Ela também é chamada\\nheurística de “variável mais restrita” ou de “primeira falha”; este último nome é dado porque ela\\nescolhe uma variável que tem a maior probabilidade de provocar uma falha em breve, podando\\nassim a árvore de busca. Se alguma variável \\nX\\n não tem mais valores válidos restantes, a heurística\\nVRM selecionará \\nX\\n e a falha será detectada de imediato — evitando buscas inúteis por outras\\nvariáveis. A heurística VRM geralmente tem desempenho melhor do que uma ordenação ao acaso ou\\nestática, às vezes por um fator de 1.000 ou mais, embora os resultados variem amplamente\\ndependendo do problema.\\nA heurística de VRM não ajuda de modo algum na escolha da primeira região a colorir na\\nAustrália porque inicialmente toda região tem três cores válidas. Nesse caso, a \\nheurística de grau\\n se\\nmostra prática. Ela tenta reduzir o fator de ramificação em escolhas futuras selecionando a variável\\nenvolvida no maior número de restrições sobre outras variáveis não atribuídas. Na \\nFigura 6.1\\n, \\nAM\\n é\\na variável com grau mais alto, 5; as outras variáveis têm grau 2 ou 3, com exceção de \\nT\\n, que tem grau\\n0. De fato, uma vez que \\nAM\\n é escolhida, a aplicação da heurística de grau resolve o problema sem\\nquaisquer etapas falsas — é possível escolher qualquer cor consistente em cada ponto de escolha e\\nainda chegar a uma solução sem retrocesso. A heurística de valores restantes mínimos normalmente é\\num guia mais poderoso, mas a heurística de grau pode ser útil como critério de desempate.\\nUma vez que uma variável foi selecionada, o algoritmo deve decidir-se pela ordem em que seus\\nvalores devem ser examinados. Para isso, a heurística de \\nvalor menos restritivo\\n pode ser efetiva em\\nalguns casos. Ela prefere o valor que elimina o menor número possível de escolhas para as variáveis\\nvizinhas no grafo de restrições. Por exemplo, suponha que na \\nFigura 6.1\\n tenhamos gerado a\\natribuição parcial com \\nAO\\n = \\nvermelho\\n e \\nTN\\n = \\nverde\\n e que nossa próxima escolha seja relativa a \\nQ\\n.\\nAzul seria uma escolha ruim porque elimina o último valor válido restante para \\nAM\\n, vizinho de \\nQ\\n.\\nPortanto, a heurística de valor menos restritivo prefere vermelho a azul. Em geral, a heurística está\\ntentando deixar a máxima flexibilidade para atribuições de variáveis subsequentes. É claro que, se\\nestivermos tentando encontrar todas as soluções para um problema, não apenas a primeira, a\\nordenação não importará, porque, de qualquer maneira, teremos de considerar todos os valores. O\\nmesmo é válido se não houver nenhuma solução para o problema.\\nPor que a seleção de variáveis deveria ser de “primeira falha”, mas a seleção de valor de “última\\nfalha”? Parece que, para uma ampla variedade de problemas, uma ordenação de variável que escolhe\\numa variável com o número mínimo de valores restantes ajuda a minimizar o número de nós na\\nárvore de busca através da poda precoce de grandes partes da árvore. Para a ordenação de valores, o\\ntruque é que precisamos apenas de uma solução, por isso faz sentido procurar pelos valores mais\\nprováveis primeiro. Se quiséssemos enumerar todas as soluções em vez de apenas encontrar uma, a\\nordenação de valores seria irrelevante.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 264}),\n",
       " Document(page_content='6.3.2 Intercalação de baixa inferência\\nAté agora vimos como o AC-3 e outros algoritmos podem inferir reduções no domínio de\\nvariáveis \\nantes\\n de iniciarmos a busca. Mas a inferência pode ser ainda mais poderosa no curso de\\numa busca: cada vez que fazemos uma escolha de um valor para uma variável, temos uma nova\\noportunidade de inferir reduções no domínio novo sobre as variáveis \\u200b\\u200bvizinhas.\\nUma das formas mais simples de inferência é chamada de \\nverificação à frente\\n. Sempre que uma\\nvariável \\nX\\n é atribuída, o processo de verificação à frente estabelece a consistência de arco para ela:\\npara cada variável não atribuída \\nY\\n que está conectada por uma restrição a \\nX\\n, exclui do domínio de \\nY\\nqualquer valor que esteja inconsistente com o valor escolhido para \\nX\\n. Devido à verificação à frente\\nsó fazer inferências de consistência de arco, não há razão para realizar a verificação à frente se a\\nconsistência de arco já foi realizada como uma etapa de pré-processamento.\\nA \\nFigura 6.7\\n mostra o progresso da busca com retrocesso no PSR da Austrália com verificação à\\nfrente. Existem dois pontos importantes a observar sobre esse exemplo. Primeiro, note que, depois de\\nse atribuir \\nAO\\n = \\nvermelho\\n e \\nQ\\n = \\nverde\\n, os domínios de \\nTN\\n e \\nAM\\n são reduzidos a um único valor;\\neliminamos por completo a ramificação nessas variáveis propagando informações a partir de \\nAO\\n e\\nQ\\n. Um segundo ponto a observar é que, depois de \\nV\\n = \\nazul\\n, o domínio de \\nAM\\n está vazio.\\nConsequentemente, a verificação prévia detectou que a atribuição parcial {\\nAO\\n = \\nvermelho\\n, \\nQ\\n =\\nverde\\n, \\nV\\n = \\nazul\\n} é inconsistente com as restrições do problema e, assim, o algoritmo regressará\\nimediatamente.\\nFigura 6.7\\n O progresso de uma busca de coloração de mapa com verificação à frente. \\nAO\\n =\\nvermelho\\n é atribuído primeiro; em seguida, a verificação à frente exclui \\nvermelho\\n dos domínios das\\nvariáveis vizinhas \\nTN\\n e \\nAM\\n. Depois de \\nQ\\n = \\nverde\\n é atribuído, \\nverde\\n é excluído dos domínios de \\nTN\\n,\\nAM\\n e \\nNGS\\n. Depois de \\nV\\n = \\nazul\\n é atribuído, \\nazul\\n é excluído dos domínios de \\nNGS\\n e \\nAM\\n, deixando\\nAM\\n sem valores válidos.\\nPara muitos problemas, a busca será mais eficiente se combinarmos a heurística VRM com a\\nverificação à frente. Considere a \\nFigura 6.7\\n após a atribuição de {\\nAO\\n = \\nvermelho\\n}. Intuitivamente,\\nparece que essa atribuição restringe os seus vizinhos, \\nTN\\n e \\nAM\\n, de modo que devemos tratar as\\npróximas variáveis e, depois, todas as outras variáveis vão pender para o lugar. Isso é exatamente o\\nque acontece com VRM: \\nTN\\n e \\nAM\\n têm dois valores, então um deles é escolhido em primeiro lugar,\\ndepois o outro, então \\nQ\\n, \\nNGS\\n e \\nV\\n em ordem. Finalmente, \\nT\\n ainda tem três valores e qualquer um\\ndeles funciona. Podemos visualizar a verificação à frente como uma maneira eficiente de calcular a\\ninformação de forma incremental, o que a heurística VRM precisa para fazer seu trabalho.\\nEmbora a verificação à frente detecte muitas inconsistências, não detecta todas elas. O problema é\\nque ela torna a variável atual consistente de arco, mas não olha adiante para tornar todas as outras\\nvariáveis consistentes de arco. Por exemplo, considere a terceira linha da \\nFigura 6.7\\n. Ela mostra que,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 265}),\n",
       " Document(page_content='quando \\nAO\\n é \\nvermelho\\n e \\nQ\\n é \\nverde\\n, \\nTN\\n e \\nAS\\n são forçados a ser azuis. A verificação à frente não olha\\nadiante o suficiente para perceber que essa é uma inconsistência: \\nTN\\n e \\nAS\\n são adjacentes e por isso\\nnão podem ter o mesmo valor.\\nO algoritmo chamado MCA para \\nmanutenção da consistência de arcos\\n (\\nMCA\\n) detecta essa\\ninconsistência. Após atribuir um valor para a variável \\nX\\ni\\n, o procedimento INFERÊNCIA chama AC-\\n3, mas em vez de uma fila de todos os arcos no PSR, começamos apenas com os arcos (\\nX\\nj\\n, \\nX\\ni\\n) para\\ntodos os \\nX\\nj\\n que são variáveis não atribuídas vizinhas de \\nX\\ni\\n. Desse ponto, o AC-3 faz a propagação de\\nrestrição da forma habitual e, se qualquer variável tiver o seu domínio reduzido para o conjunto\\nvazio, falha a chamada para AC-3 e sabemos recuar imediatamente. Verificamos que o MCA é\\nestritamente mais poderoso do que a verificação à frente porque a verificação à frente realiza a\\nmesma coisa que o MCA sobre os arcos iniciais na fila do MCA, mas, ao contrário do MCA, a\\nverificação à frente não propaga restrições recursivamente quando são feitas alterações nos domínios\\ndas variáveis.\\n6.3.3 Retrocesso inteligente: olhando para trás\\nO algoritmo PESQUISA-COM-RETROCESSO da \\nFigura 6.5\\n tem uma norma muito simples sobre\\no que fazer quando um ramo da busca falha: voltar até a variável precedente e experimentar um valor\\ndiferente para ela. Isso se chama \\nretrocesso cronológico\\n porque o ponto de decisão \\nmais recente\\n é\\nrevisto. Nesta subseção, consideraremos melhores possibilidades.\\nConsidere o que acontece quando aplicamos o retrocesso simples da \\nFigura 6.1\\n com uma\\nordenação fixa de variáveis \\nQ\\n, \\nNGS\\n, \\nV\\n, \\nT\\n, \\nAM\\n, \\nAO\\n, \\nTN\\n. Vamos supor que geramos a atribuição\\nparcial {\\nQ\\n = \\nvermelho\\n, \\nNGS\\n = \\nverde\\n, \\nV\\n = \\nazul\\n, \\nT\\n = \\nvermelho\\n}. Quando experimentarmos a próxima\\nvariável, \\nAM\\n, veremos que todo valor viola uma restrição. Voltamos até \\nT\\n e experimentamos uma\\nnova cor para Tasmânia! Obviamente, isso é tolice — a mudança da cor atribuída à Tasmânia não\\npode solucionar o problema da Austrália meridional.\\nUma abordagem mais inteligente para retorno é retroceder até uma variável que possa corrigir o\\nproblema, uma variável que foi responsável por tornar um dos valores possíveis de \\nAM\\n impossível.\\nPara fazer isso, vamos acompanhar um conjunto de atribuições que estão em conflito com algum\\nvalor de \\nAM\\n. O conjunto (nesse caso, {\\nQ\\n = \\nvermelho\\n, \\nNGS\\n = \\nverde\\n, \\nV\\n = \\nazul\\n,}), é chamado\\nconjunto de conflito\\n para \\nAM\\n. O método de \\nretorno\\n regressa até a atribuição \\nmais recente\\n no\\nconjunto de conflito; nesse caso, o retorno saltaria sobre a Tasmânia e experimentaria um novo valor\\npara \\nV\\n. Esse método é facilmente implementado pela modificação para RETROCESSO-\\nRECURSSIVO de forma que acumule o conjunto de conflito, ao mesmo tempo que verifica a\\natribuição de um valor válido. Se não for encontrado nenhum valor válido, o algoritmo deve retornar\\no elemento mais recente do conjunto de conflito, juntamente com o indicador de falha.\\nO leitor atento terá notado que a verificação à frente pode fornecer o conjunto de conflito sem\\ntrabalho extra: sempre que a verificação à frente baseada em uma atribuição \\nX\\n = \\nx\\n exclui um valor do\\ndomínio de \\nY\\n, ela deve adicionar \\nX\\n = \\nx\\n ao conjunto de conflito de \\nY\\n. Se o último valor for eliminado\\ndo domínio de \\nY\\n, as atribuições no conjunto de conflito de \\nY\\n serão adicionadas ao conjunto de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 266}),\n",
       " Document(page_content='conflito de \\nX\\n. Então, quando chegarmos a \\nY\\n, saberemos de imediato para onde regressar, se\\nnecessário.\\nO leitor mais atento terá notado algo estranho: o retorno ocorre quando todo valor em um domínio\\nestá em conflito com a atribuição corrente; no entanto, a verificação à frente detecta esse evento e\\nimpede que a busca alcance tal nó! De fato, é possível mostrar que toda ramificação podada por\\nretorno também é podada por verificação à frente. Consequentemente, o retorno simples é redundante\\nem uma busca de verificação à frente ou, na verdade, em uma busca que utilize verificação de\\nconsistência mais forte, como MAC.\\nApesar das observações do parágrafo anterior, a ideia que rege o retorno continua a ser boa:\\nefetuar o retrocesso com base nas razões da falha. O retorno nota a falha quando o domínio de uma\\nvariável se torna vazio, mas, em muitos casos, uma ramificação está condenada muito antes de\\nacontecer isso. Considere mais uma vez a atribuição parcial {\\nAO\\n = \\nvermelho\\n, \\nNGS\\n = \\nvermelho\\n}\\n(que, de acordo com nossa discussão anterior, é inconsistente). Vamos supor que experimentamos \\nT\\n= \\nvermelho\\n em seguida e depois atribuímos \\nTN\\n, \\nQ\\n, \\nV\\n, \\nAM\\n. Sabemos que nenhuma atribuição pode\\nfuncionar para essas quatro últimas variáveis e, assim, eventualmente ficamos sem valores para\\nexperimentar em \\nTN\\n. Agora, a questão é para onde regressar. O retorno não pode funcionar porque\\nTN tem\\n valores consistentes com as variáveis atribuídas precedentes — \\nTN\\n não tem um conjunto de\\nconflito completo de variáveis precedentes que tenham causado sua falha. Entretanto, sabemos que as\\nquatro variáveis \\nTN\\n, \\nQ\\n, \\nV\\n e \\nAM\\n, \\ntomadas em conjunto\\n, falharam devido a um conjunto de variáveis\\nprecedentes, que devem ser as variáveis que entram em conflito direto com as quatro. Isso nos leva a\\numa noção mais profunda do conjunto de conflito para uma variável como \\nTN\\n: é esse conjunto de\\nvariáveis precedentes que fez \\nTN\\n, \\njuntamente com quaisquer variáveis subsequentes\\n, não ter\\nnenhuma solução consistente. Nesse caso, o conjunto é \\nAO\\n e \\nNGS\\n, e assim o algoritmo deve regressar\\naté \\nNGS\\n e saltar sobre Tasmânia. Um algoritmo de retorno que utiliza conjuntos de conflito definidos\\ndesse modo é chamado \\nretorno orientado por conflito\\n.\\nAgora devemos explicar como esses novos conjuntos de conflito são calculados. De fato, o\\nmétodo é muito simples. A falha “terminal” de uma ramificação da busca sempre ocorre porque o\\ndomínio de uma variável se torna vazio; essa variável tem um conjunto de conflito-padrão. Em nosso\\nexemplo, \\nAM\\n falha, e seu conjunto de conflito é (digamos) {\\nAO\\n, \\nTN\\n,\\nQ\\n}. Recuamos até \\nQ\\n, e \\nQ\\nabsorve\\n o conjunto de conflito de \\nAM\\n (com exceção do próprio \\nQ\\n, é claro) em seu próprio conjunto\\nde conflito direto, que é {\\nTN\\n, \\nNGS\\n}; o novo conjunto de conflito é {\\nAM\\n, \\nTN\\n, \\nNGS\\n}. Isto é, não há\\nsolução de \\nQ\\n em diante, dada a atribuição anterior a {\\nAO\\n, \\nTN\\n, \\nNGS\\n}. Portanto, regressamos até \\nTN\\n,\\no mais recente desses elementos. \\nTN\\n absorve {\\nAO\\n, \\nTN\\n, \\nNGS\\n} – {\\nTN\\n} em seu próprio conjunto de\\nconflito direto {\\nAO\\n}, fornecendo {\\nAO\\n, \\nNGS\\n} (como afirmamos no parágrafo anterior). Agora, o\\nalgoritmo recua até \\nNGS\\n, como seria de esperar. Em resumo, seja \\nX\\nj\\n a variável corrente e seja\\nconf\\n(\\nX\\nj\\n) seu conjunto de conflito. Se todo valor possível para \\nXj\\n falhar, recue até a variável mais\\nrecente \\nX\\ni\\n em \\nconf\\n(\\nX\\nj\\n) e defina:\\nQuando chegamos a uma contradição, o retorno pode nos informar até onde se poderia voltar;\\nassim não se perde tempo alterando variáveis que não vão resolver o problema. Mas também', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 267}),\n",
       " Document(page_content='gostaríamos de desembocar no mesmo problema novamente. Quando a busca chega a uma\\ncontradição, sabemos que algum subconjunto do conjunto de conflito é responsável pelo problema. O\\naprendizado de restrição\\n é a ideia de encontrar um conjunto mínimo de variáveis do conjunto de\\nconflito que causa o problema. Esse conjunto de variáveis, juntamente com seus valores\\ncorrespondentes, é chamado de \\nnada bom\\n. Em seguida, registramos o nada bom, quer pela inclusão\\nde uma nova restrição para o PSR, quer mantendo um cache separado de nada bons.\\nPor exemplo, considere o estado {\\nAO\\n = vermelho, \\nTN\\n = \\nverde\\n, \\nQ\\n = \\nazul\\n} na última linha da\\nFigura 6.6\\n. A verificação prévia pode informar que esse estado é um nada bom porque não há uma\\natribuição válida para \\nAM\\n. Nesse caso particular, o registro do nada bom não iria ajudar porque,\\numa vez que esse ramo seja podado da árvore de busca, nunca iremos encontrar essa combinação\\nnovamente. Mas suponha que a árvore de busca da \\nFigura 6.6\\n realmente faizesse parte de uma árvore\\nde busca maior que inicialmente atribuía valores para \\nV\\n e \\nT\\n. Então, valeria a pena registrar {\\nAO\\n =\\nvermelho\\n, \\nTN\\n = \\nverde\\n, \\nQ\\n = \\nazul\\n} como nada bons porque incorreremos no mesmo problema\\nnovamente para cada conjunto possível de atribuições para \\nV\\n e \\nT\\n.\\nEfetivamente pode-se utilizar nada bons por verificação à frente ou por retorno. O aprendizado de\\nrestrição é uma das técnicas mais importantes utilizadas por solucionadores modernos de PSR para\\nalcançar eficiência em problemas complexos.\\n6.4 BUSCA LOCAL PARA PSRs\\nOs algoritmos de busca local (veja a \\nSeção 4.1\\n) se mostram muito eficazes na resolução de vários\\nPSRs. Eles utilizam uma formulação de estados completos: o estado inicial atribui um valor a cada\\nvariável e a busca altera o valor de uma variável de cada vez. Por exemplo, no problema de oito\\nrainhas (veja a \\nFigura 4.3\\n), o estado inicial poderia ser uma configuração aleatória de oito rainhas\\nem oito colunas e cada etapa moveria uma única rainha para uma nova posição em sua coluna.\\nNormalmente, o palpite inicial viola várias restrições. O ponto de busca local é eliminar as\\nrestrições violadas.\\n2\\nNa escolha de um novo valor para uma variável, a heurística mais óbvia é selecionar o valor que\\nresulta no número mínimo de conflitos com outras variáveis — a heurística de \\nconflitos mínimos\\n.\\nO algoritmo é mostrado na \\nFigura 6.8\\n; sua aplicação a um problema de oito rainhas é diagramada\\nna \\nFigura 6.9\\n.\\nfunção\\n CONFLITOS-MÍNIMOS(\\npsr\\n, \\nmax\\n_\\netapas\\n) \\nretorna\\n uma solução ou falha\\n    \\nentradas\\n: \\npsr\\n, um problema de satisfação de restrições\\n            \\nmax\\n_\\netapas\\n, o número de etapas permitidas antes de desistir\\n    \\n    \\ncorrente\\n ← uma atribuição inicial completa para \\npsr\\n    \\npara\\n \\ni\\n = 1 para \\nmax\\n_\\netapas\\n \\nfaça\\n        \\nse\\n \\ncorrente\\n é uma solução para \\npsr\\n \\nentão retornar\\n \\ncorrente\\n        \\nvar\\n ← uma variável em conflito escolhida ao acaso a partir de VARIÁVEIS[\\npsr\\n]\\n        \\nvalor\\n ← o valor \\nv\\n para \\nvar\\n que minimiza CONFLITOS(\\nvar\\n, \\nv\\n, \\ncorrente\\n, \\npsr\\n)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 268}),\n",
       " Document(page_content='definir \\nvar\\n = \\nvalor\\n em \\ncorrente\\n    \\nretornar\\n \\nfalha\\nFigura 6.8\\n O algoritmo CONFLITOS-MÍNIMOS para resolução de PSRs por busca local. O estado\\ninicial pode ser escolhido aleatoriamente ou por meio de um processo de atribuição gulosa que\\nescolhe um valor de conflito mínimo para uma variável de cada vez. A função CONFLITOS conta o\\nnúmero de restrições violadas por um valor específico, dado o restante da atribuição corrente.\\nFigura 6.9\\n Uma solução de duas etapas para um problema de oito rainhas utilizando conflitos\\nmínimos. Em cada fase, é escolhida uma rainha para reatribuição em sua coluna. O número de\\nconflitos (nesse caso, o número de rainhas atacantes) é mostrado em cada quadrado. O algoritmo\\nmove a rainha para o quadrado de conflito mínimo, efetuando os desempates ao acaso.\\nA heurística de conflitos mínimos é surpreendentemente eficaz para muitos PSRs. É incrível\\nobservar no problema de \\nn\\n rainhas que, se não for levado em conta o posicionamento inicial das\\nrainhas, o tempo de execução de conflitos mínimos será aproximadamente \\nindependente do tamanho\\ndo problema\\n. Essa notável observação foi o estímulo que levou a um intenso estudo da busca local\\nna década de 1990 e à distinção entre problemas fáceis e difíceis, que começamos a examinar no\\nCapítulo 7. Em termos gerais, o problema de \\nn\\n rainhas é fácil para a busca local porque as soluções\\nestão densamente distribuídas ao longo do espaço de estados. A heurística de conflitos mínimos\\ntambém funciona bem para problemas difíceis. Por exemplo, ela é empregada na programação de\\nobservações do telescópio espacial Hubble, reduzindo o tempo necessário para programar uma\\nsemana de observações de três semanas (!) para algo ao redor de 10 minutos.\\nTodas as técnicas de busca local a partir da \\nSeção 4.1\\n são candidatas a ser aplicadas em PSRs, e\\nalgumas delas se revelaram especialmente eficazes. O cenário de um PSR sob a heurística de\\nconflitos mínimos geralmente tem uma série de platôs. Pode haver milhões de atribuições de\\nvariáveis que estão apenas um conflito distante de uma solução. A busca de platô — permitir\\nmovimentos de lado para outro estado com a mesma pontuação — pode ajudar a busca local a\\nencontrar o seu caminho fora desse platô. Essa vagueação no platô pode ser orientada com a \\nbusca\\nde tabu\\n: manutenção de uma pequena lista de estados visitados recentemente e proibição do retorno\\ndo algoritmo para esses estados. Pode-se utilizar também têmpera simulada para escapar do platô.\\nOutra técnica, chamada \\nponderação de restrição\\n, pode ajudar a concentrar a busca em restrições\\nimportantes. É dado a cada restrição um peso numérico, \\nWi\\n; inicialmente todos valem 1. Em cada\\netapa da busca, o algoritmo escolhe um par de variáveis/valor para alterar o que resultará no menor\\npeso total de todas as restrições violadas. Os pesos são então ajustados, incrementando o peso de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 269}),\n",
       " Document(page_content='cada restrição que foi violado pela atribuição atual. Isso tem dois benefícios: acrescenta topografia\\nao platô, certificando-se de que é possível melhorar a partir do estado atual, e também, ao longo do\\ntempo, aumenta o peso das restrições que estão provando serem difíceis de resolver.\\nOutra vantagem da busca local é a possibilidade de utilizá-la em uma configuração on-line quando\\no problema se altera. Isso é particularmente importante em problemas de escalonamento. A escala de\\nlinhas aéreas para uma semana pode envolver milhares de voos e dezenas de milhares de atribuições\\nde pessoas, mas o mau tempo em um aeroporto pode tornar a escala inviável. Gostaríamos de reparar\\na escala com um número mínimo de mudanças. Isso pode ser feito com facilidade por meio de um\\nalgoritmo de busca local a partir da escala atual. Uma busca com retrocesso com o novo conjunto de\\nrestrições normalmente exige muito mais tempo e pode encontrar uma solução com muitas mudanças\\na partir da escala atual.\\n6.5 A ESTRUTURA DE PROBLEMAS\\nNesta seção, examinaremos meios pelos quais a \\nestrutura\\n do problema, representada pelo grafo\\nde restrições, pode ser usada para encontrar soluções com rapidez. A maior parte das abordagens\\nutilizadas aqui também se aplica a outros problemas além de PSRs, tais como o raciocínio\\nprobabilístico. Afinal, o único modo de termos esperança de lidar com o mundo real é decompô-lo\\nem muitos subproblemas. Quando observamos mais uma vez a \\nFigura 6.1\\n(b) repetida como \\nFigura\\n6.12\\n(a)), com a finalidade de identificar a estrutura do problema, um fato se destaca: a Tasmânia não\\nestá conectada ao continente.\\n3\\n Intuitivamente, é óbvio que colorir a Tasmânia e colorir o continente\\nsão \\nsubproblemas independentes\\n — qualquer solução para o continente combinada a qualquer\\nsolução para a Tasmânia produz uma solução para o mapa inteiro. A independência pode ser\\naveriguada simplesmente procurando-se por \\ncomponentes conectados\\n do grafo de restrições. Cada\\ncomponente corresponde a um subproblema \\nPSR\\ni\\n. Se a atribuição \\nS\\ni\\n é uma solução de \\nPSR\\ni\\n, então \\ni\\nS\\ni\\n é uma solução de \\ni\\n \\nPSR\\ni\\n. Por que isso é importante? Considere o seguinte: vamos supor que cada\\nPSR\\ni\\n tenha \\nc\\n variáveis do total de \\nn\\n variáveis, onde \\nc\\n é uma constante. Então, existem \\nn\\n/\\nc\\nsubproblemas, cada um dos quais exige no máximo o trabalho \\nd\\nc\\n para ser resolvido, onde \\nd\\n é o\\ntamanho do domínio. Consequentemente, o trabalho total é \\nO\\n(\\nd\\nc\\nn\\n/\\nc\\n), que é \\nlinear\\n em \\nn\\n; sem a\\ndecomposição, o trabalho total é \\nO\\n(\\nd\\nn\\n), que é exponencial em \\nn\\n. Vamos tornar esse caso mais\\nconcreto: a divisão de um PSR booleano com \\nn\\n = 80 variáveis em quatro subproblemas reduz o\\ntempo de solução no pior caso do tempo de duração do universo para menos de um segundo.\\n Então, subproblemas completamente independentes são interessantes, mas raros. Felizmente,\\nalgumas outras estruturas de grafo também são fáceis de resolver. Por exemplo, um grafo de restrição\\né uma \\nárvore\\n quando quaisquer duas variáveis estiverem ligadas por apenas um caminho.\\nMostraremos que \\nqualquer PSR estruturado em árvore pode ser resolvido no tempo linear no\\nnúmero de variáveis\\n.\\n4\\n O fundamento é uma nova noção de consistência, chamada \\nconsistência\\norientada de arco\\n ou COA. A PSR é definida para ser arco orientado consistente sob uma ordenação\\nde variáveis \\nX\\n1\\n, \\nX\\n2\\n,…, \\nX\\nn\\n se e somente se cada \\nX\\ni\\n for arco-consistente com cada \\nX\\nj\\n para \\nj\\n > \\ni\\n.\\nPara resolver um PSR estruturado em árvore, escolha primeiramente qualquer variável para ser a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 270}),\n",
       " Document(page_content='raiz da árvore e escolha uma ordenação das variáveis de tal forma que cada variável apareça após o\\nseu pai na árvore.\\nTal ordenação chama-se \\nclassificação topológica\\n. A \\nFigura 6.10\\n(a) mostra uma amostra de árvore\\ne (b) mostra uma ordenação possível. Qualquer árvore com \\nn\\n nós tem \\nn\\n −1 arcos, então podemos\\nfazer esse grafo arco-orientado consistente em \\nO\\n(\\nn\\n) etapas, cada uma das quais deve comparar com\\naté \\nd\\n possíveis valores de domínio para duas variáveis, para um tempo total \\nO\\n(\\nnd\\n2\\n). Uma vez que\\ntenhamos um grafo arco orientado consistente, podemos proceder diretamente à lista de variáveis e\\nescolher algum valor restante. Desde que cada ligação de um pai com seu filho seja arco-consistente,\\nsabemos que, para qualquer valor que escolhamos para o pai, haverá um valor válido deixado a ser\\nescolhido para o filho. Isso significa que não teremos que retroceder, podemos mover-nos\\nlinearmente através das variáveis. O algoritmo completo é mostrado na \\nFigura 6.11\\n.\\nFigura 6.10\\n (a) O grafo de restrições de um PSR estruturado em árvore. (b) Uma ordenação linear\\ndas variáveis consistentes com a árvore, sendo \\nA\\n a raiz. Isso é conhecido como \\nclassificação\\ntopológica\\n de variáveis.\\nfunção\\n SOLUCIONADOR-ÁRVORE-PSR(\\npsr\\n) \\nretornar\\n uma solução ou falha\\n    \\nentradas\\n: \\npsr\\n, um PSR com componentes \\nX\\n, \\nD\\n, \\nC\\n    \\n    \\nn\\n ← número de variáveis em X\\n    \\natribuição\\n ← uma atribuição vazia\\n    \\nraiz\\n ← qualquer variável em \\nX\\n    \\nX\\n ← CLASSIFICAÇÃO TOPOLÓGICA (\\nX\\n, \\nraiz\\n)\\n    \\npara\\n \\nj\\n = \\nn\\n \\naté\\n 2 \\nfaça\\n        TORNE-ARCO-CONSISTENTE(PAI(\\nX\\nj\\n),\\nX\\nj\\n)\\n        \\nse\\n não puder se tornar consistente \\nentão retornar\\n \\nfalha\\n    \\npara\\n \\ni\\n = 1 \\naté\\n \\nn\\n \\nfaça\\n        \\natribuição\\n[\\nX\\ni\\n] ← qualquer valor consistente de \\nD\\ni\\n        \\nse\\n não houver valor consistente \\nentão retornar\\n \\nfalha\\n    \\nretornar\\n \\natribuição\\nFigura 6.11\\n O algoritmo SOLUCIONADOR-ÁRVORE-PSR para resolver PSRs estruturados em\\nárvore. Se o PSR tiver uma solução, vamos encontrá-la em tempo linear; senão, detectaremos uma\\ncontradição.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 271}),\n",
       " Document(page_content='Figura 6.12\\n (a) Grafo de restrições original da \\nFigura 6.1\\n. (b) Grafo de restrições após a remoção de\\nAM\\n.\\nAgora que temos um algoritmo eficiente para árvores, podemos considerar se grafos de restrições\\nmais gerais podem ser \\nreduzidos\\n de algum modo a árvores. Há duas alternativas principais para\\nfazer isso, uma delas baseada na remoção de nós e outra baseada na condensação de nós.\\nA primeira abordagem envolve a atribuição de valores a algumas variáveis, de modo que as\\nvariáveis restantes formem uma árvore. Considere o grafo de restrições para a Austrália, mostrado\\nnovamente na \\nFigura 6.12\\n(a). Se pudéssemos eliminar Austrália meridional, o grafo se tornaria uma\\nárvore, como em (b). Felizmente, podemos fazer isso (no grafo, não no continente) fixando um valor\\npara \\nAM\\n e excluindo dos domínios das outras variáveis quaisquer valores inconsistentes com o valor\\nescolhido para \\nAM\\n.\\nAgora, qualquer solução para o PSR depois que \\nAM\\n e suas restrições forem removidas será\\nconsistente com o valor escolhido para \\nAM\\n (isso funciona para PSRs binários; a situação é mais\\ncomplicada com restrições de alta ordem). Então, podemos resolver a árvore restante com o\\nalgoritmo dado anteriormente e, desse modo, resolver o problema inteiro. É claro que, no caso geral\\n(em vez de coloração de mapas), o valor escolhido para \\nAM\\n poderia ser o valor errado e, assim,\\nprecisaríamos experimentar cada um deles. O algoritmo geral é:\\n1. Escolha um subconjunto \\nS\\n de variáveis PSR tal que o grafo de restrições se torne uma árvore\\ndepois da remoção de \\nS\\n. \\nS\\n é chamado de \\nconjunto de corte de ciclo\\n.\\n2. Para cada atribuição possível às variáveis de \\nS\\n que satisfaça a todas as restrições sobre \\nS\\n,\\n(a) remova dos domínios das variáveis restantes quaisquer valores que sejam inconsistentes\\ncom a atribuição para \\nS\\n e\\n(b) se o PSR restante tiver uma solução, retorne-a juntamente com a atribuição para \\nS\\n.\\nSe o conjunto de corte de ciclo tiver tamanho \\nc\\n, o tempo de execução total será \\nO\\n(\\nd\\nc\\n \\n⋅\\n (\\nn – c\\n) \\nd\\n2\\n):\\ntemos que experimentar cada uma das combinações \\nd\\nc\\n de valores para as variáveis em \\nS\\n e, para cada\\ncombinação, devemos resolver um problema de árvore de tamanho \\nn\\n − \\nc\\n. Se o grafo for\\n“praticamente uma árvore”, então \\nc\\n será pequeno e as economias em relação ao retrocesso direto\\nserão enormes. Porém, no pior caso, \\nc\\n poderá chegar a (\\nn\\n – 2). Encontrar o \\nmenor\\n conjunto de corte', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 272}),\n",
       " Document(page_content='de ciclo será NP-difícil, mas são conhecidos diversos algoritmos de aproximação eficientes para\\nessa tarefa. A abordagem algorítmica global é chamada \\ncondicionamento de conjunto de corte\\n;\\nsurgirá novamente no Capítulo 14, onde ela é utilizada no raciocínio probabilístico.\\nA segunda abordagem se baseia na construção de uma \\ndecomposição em árvore\\n do grafo de\\nrestrições em um conjunto de subproblemas conectados. Cada subproblema é resolvido\\nindependentemente, e as soluções resultantes são então combinadas. Como a maioria dos algoritmos\\nde dividir e conquistar, isso funciona bem se nenhum subproblema é muito grande. A \\nFigura 6.13\\nmostra uma decomposição em árvore do problema de coloração de mapa em cinco subproblemas.\\nUma decomposição em árvore deve satisfazer os três requisitos a seguir:\\nFigura 6.13\\n Decomposição em árvore do grafo de restrições da \\nFigura 6.12\\n(a).\\n•  Toda variável no problema original aparece em pelo menos um dos subproblemas.\\n•  Se duas variáveis estiverem conectadas por uma restrição no problema original, elas deverão\\naparecer juntas (e juntamente com a restrição) em pelo menos um dos subproblemas.\\n•  Se uma variável aparecer em dois subproblemas na árvore, ela deverá aparecer em todo\\nsubproblema ao longo do caminho que conecta esses dois subproblemas.\\nAs duas primeiras condições garantem que todas as variáveis e restrições estarão representadas na\\ndecomposição. A terceira condição parece bastante técnica, mas simplesmente reflete a restrição de\\nque qualquer variável dada deve ter o mesmo valor em todo subproblema em que aparece; os\\nvínculos que unem subproblemas na árvore impõem essa restrição. Por exemplo, \\nAM\\n aparece em\\ntodos os quatro subproblemas conectados da \\nFigura 6.13\\n. Você poderá verificar pela \\nFigura 6.12\\n que\\nessa decomposição faz sentido.\\nResolvemos cada subproblema independentemente; se qualquer um não tiver solução, saberemos\\nque o problema inteiro não tem solução. Se conseguirmos resolver todos os subproblemas,\\ntentaremos construir uma solução global como a seguir. Primeiro, visualizamos cada subproblema\\ncomo uma “megavariável” cujo domínio é o conjunto de todas as soluções para o subproblema. Por\\nexemplo, o subproblema mais à esquerda na \\nFigura 6.13\\n é um problema de coloração de mapa com\\ntrês variáveis e, consequentemente, tem seis soluções — uma delas é {\\nAO\\n = \\nvermelho\\n, \\nAM\\n = \\nazul\\n,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 273}),\n",
       " Document(page_content='TN\\n = \\nverde\\n}. Em seguida, resolvemos as restrições que conectam os subproblemas com a utilização\\ndo algoritmo eficiente para árvores apresentado antes. As restrições entre subproblemas\\nsimplesmente insistem que as soluções de subproblemas concordem sobre suas variáveis\\ncompartilhadas. Por exemplo, dada a solução {\\nAO\\n = \\nvermelho\\n, \\nAM\\n = \\nazul\\n, \\nTN\\n = \\nverde\\n} para o\\nprimeiro subproblema, a única solução consistente para o próximo subproblema é {\\nAM\\n = \\nazul\\n, \\nTN\\n =\\nverde\\n, \\nQ\\n = \\nvermelho\\n}.\\n Um dado grafo de restrições admite muitas decomposições em árvore; ao se escolher uma\\ndecomposição, o objetivo é tornar os subproblemas tão pequenos quanto possível. A \\nlargura de\\nárvore\\n de uma decomposição em árvore de um grafo é uma unidade menor que o tamanho do maior\\nsubproblema; a largura de árvore do grafo propriamente dito é definida como a mínima largura de\\nárvore entre todas as suas decomposições em árvore. Se um grafo tem largura de árvore \\nw\\n e\\nrecebemos a decomposição em árvore correspondente, então o problema pode ser resolvido no\\ntempo \\nO\\n(\\nnd\\nw\\n+1\\n). Consequentemente, \\nPSRs que têm grafos de restrições com largura de árvore\\nlimitada podem ser resolvidos em tempo polinomial\\n. Infelizmente, encontrar a decomposição em\\nárvore com largura de árvore mínima é um problema NP-difícil, mas existem métodos heurísticos\\nque funcionam bem na prática.\\nAté agora, vimos a estrutura de grafo de restrição. Pode haver também uma estrutura importante\\nnos \\nvalores\\n das variáveis. Considere o problema de coloração do mapa com \\nn\\n cores. Para cada\\nsolução consistente, há realmente um conjunto de \\nn\\n! soluções formadas pela permuta dos nomes das\\ncores. Por exemplo, no mapa da Austrália sabemos que \\nAO\\n, \\nTN\\n e \\nAS\\n devem ter cores diferentes, mas\\nexistem 3! = 6 maneiras de atribuir as três cores para essas três regiões. Isso é chamado de \\nsimetria\\nde valor\\n. Gostaríamos de reduzir o espaço de busca a um fator de \\nn\\n! quebrando a simetria. Fazemos\\nisso através da introdução de uma \\nrestrição de quebra de simetria\\n. Para o nosso exemplo,\\npoderíamos impor uma restrição arbitrária de ordenação, \\nTN\\n < \\nAM\\n < \\nAO\\n, que exige que os três\\nvalores estejam em ordem alfabética. Essa restrição garante que apenas uma das \\nn\\n! soluções seja\\npossível: {\\nTN = azul, AM = verde, AO = vermelho\\n}.\\nPara a coloração do mapa, foi fácil encontrar uma restrição que eliminasse a simetria e, em geral,\\né possível encontrar restrições que eliminam todas, em vez de uma solução simétrica em tempo\\npolinomial, mas é NP-difícil eliminar todas as simetrias entre os conjuntos intermediários de valores\\ndurante a pesquisa. Na prática, quebrar o valor da simetria provou ser importante e eficaz em uma\\nampla gama de problemas.\\n6.6 RESUMO\\n•  Os \\nproblemas de satisfação de restrições\\n (ou PSRs) representam um estado com um conjunto\\nde variáveis/valores pares e representam as condições para uma solução por um conjunto de\\nrestrições sobre as variáveis. Muitos problemas importantes do mundo real podem ser descritos\\ncomo PSRs.\\n•  Várias técnicas de inferência usam as restrições para inferir quais variáveis/pares de valores\\nsão consistentes e quais não são. Elas incluem nó, arco, caminho e \\nk\\n-consistência.\\n•  A \\nbusca com retrocesso\\n, uma forma de busca em profundidade, é comumente usada para', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 274}),\n",
       " Document(page_content='resolver PSRs. A inferência pode ser interligada com a busca.\\n•  As heurísticas de \\nvalores restantes mínimos\\n e de \\ngrau\\n são métodos independentes do domínio\\npara decidir que variável escolher em seguida em uma busca com retrocesso. A heurística de\\nvalor menos restritivo\\n ajuda a decidir que valor se deve experimentar primeiro para\\ndeterminada variável. O retrocesso ocorre quando não é possível encontrar nenhuma atribuição\\nválida para uma variável. O \\nretorno orientado por conflito\\n efetua o retrocesso diretamente para\\na origem do problema.\\n•  A busca local utilizando a heurística de \\nconflitos mínimos\\n tem sido aplicada com grande\\nsucesso a problemas de satisfação de restrições.\\n•  A complexidade da resolução de um PSR está fortemente relacionada à estrutura de seu grafo de\\nrestrições. Problemas estruturados em árvore podem ser resolvidos em tempo linear. O\\ncondicionamento de conjunto de corte\\n pode reduzir um PSR geral a um PSR estruturado em\\nárvore e é muito eficiente no caso de ser possível encontrar um conjunto de corte pequeno. As\\ntécnicas de \\ndecomposição em árvore\\n transformam o PSR em uma árvore de subproblemas e são\\neficientes quando a \\nlargura de árvore\\n do grafo de restrições é pequena.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nO trabalho mais antigo relacionado à satisfação de restrições lidava em grande parte com\\nrestrições numéricas. As restrições de equações com domínios de inteiros foram estudadas pelo\\nmatemático indiano Brahmagupta no século VII; com frequência, elas se denominam \\nequações\\ndiofantinas\\n, em homenagem ao matemático grego Diofanto (c. 200-284), que realmente considerou o\\ndomínio de racionais positivos. Métodos sistemáticos para resolução de equações lineares por\\neliminação de variáveis foram estudados por Gauss (1829); a solução de restrições de desigualdade\\nlineares teve início com Fourier (1827).\\nOs problemas de satisfação de restrições de domínios finitos também têm uma longa história. Por\\nexemplo, a \\ncoloração de grafo\\n (da qual a coloração de mapa é um caso especial) é um problema\\nantigo em matemática. A conjetura das quatro cores (de que todo grafo planar pode ser colorido com\\nquatro cores ou menos) foi elaborada primeiro por Francis Guthrie, aluno do matemático De Morgan,\\nem 1852. Ela resistiu à solução — apesar de diversas afirmações publicadas em contrário — até ser\\ncriada uma prova, por Appel e Haken (1977) [consulte o livro \\nFour Colors Suffice\\n (Wilson, 2004)].\\nOs puristas ficaram desapontados porque parte da prova fiou-se em um computador, assim Georges\\nGonthier (2008), usando o demonstrador de teorema de COQ, derivou uma prova formal de que a\\nprova de Appel e Haken estava correta.\\nClasses específicas de problemas de satisfação de restrições ocorrem em toda a história da\\nciência da computação. Um dos exemplos mais influentes foi o sistema SKETCHPAD (Sutherland,\\n1963), que resolvia restrições geométricas em diagramas e foi o precursor dos modernos programas\\nde desenho e das ferramentas de CAD. A identificação de PSRs como classe \\ngeral\\n se deve a Ugo\\nMontanari (1974). A redução de PSRs de alta ordem a PSRs puramente binários com variáveis\\nauxiliares (veja o Exercício 6.6) foi realizada originalmente pelo lógico do século XIX Charles\\nSanders Peirce. Ela foi introduzida na literatura de PSRs por Dechter (1990b) e elaborada por', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 275}),\n",
       " Document(page_content='Bacchus e Van Beek (1998). PSRs com preferências entre soluções são estudados amplamente na\\nliteratura de otimização; veja em Bistarelli \\net al\\n. (1997) uma generalização da estrutura de PSRs\\npara permitir o uso de preferências. O algoritmo de eliminação de compartimentos (Dechter, 1999)\\ntambém pode ser aplicado a problemas de otimização.\\nMétodos de propagação de restrições foram popularizados pelo sucesso de Waltz (1975) em\\nproblemas de linha de rotulagem poliédrica para visão de computador. Waltz mostrou que, em muitos\\nproblemas, a propagação elimina completamente a necessidade de retrocesso. Montanari (1974)\\nintroduziu a noção de redes de restrição e propagação pela consistência de caminho. Alan\\nMackworth (1977) propôs o algoritmo AC-3 para reforçar a consistência de arco, bem como a ideia\\ngeral de combinação de retrocesso com algum grau de aplicação da consistência. Mohr e Henderson\\n(1986) desenvolveram o AC-4, um algoritmo mais consistente de consistência de arco. Logo depois\\napareceu o trabalho de Mackworth, e os pesquisadores começaram a fazer experiência com a\\ncontrapartida entre o custo da aplicação da consistência e os benefícios em termos de redução de\\nbusca. Haralick e Elliot (1980) favoreceram o algoritmo mínimo de verificação prévia descrito por\\nMcGregor (1979), enquanto Gaschnig (1979) sugeriu total consistência de arco após cada atribuição\\nde variável — um algoritmo chamado mais tarde de MAC por Sabin e Freuder (1994). O último\\ndocumento forneceu evidências convincentes de que em PSRs mais difíceis, cheios de consistência\\nde arcos, a verificação compensa. Freuder (1978, 1982) investigou a noção de \\nk\\n-consistência e sua\\nrelação com a complexidade em resolver PSRs. Apt (1999) descreveu uma estrutura de algoritmo\\ngenérica em que os algoritmos de propagação de consistência podem ser analisados e, antes,\\nBessière (2006) apresentou uma avaliação atualizada.\\nOs métodos especiais para manipulação de restrições de alta ordem ou globais foram\\ndesenvolvidos primeiramente dentro do contexto de \\nprogramação de lógica de restrições\\n. Marriott\\ne Stuckey (1998) fornecem excelente cobertura de buscas nessa área. A restrição \\nTodosDiferentes\\nfoi estudada por Regin (1994), Stergiou e Walsh (1999) e Van Hoeve (2001). As restrições de\\nlimites foram incorporadas à programação de lógica de restrições por Van Hentenryck \\net al\\n. (1998).\\nUma pesquisa de restrições globais foi fornecida por Van Hoeve e Katriel (2006).\\nO Sudoku tornou o PSR mais conhecido e assim foi descrito por Simonis (2005). Agerbeck e\\nHansen (2008) descrevem algumas das estratégias e mostram que o Sudoku em um tabuleiro \\nn\\n2\\n × \\nn\\n2\\nestá na classe dos problemas NP-difíceis. Reeson et al. (2007) fazem uma demonstração iterativa\\nbaseada em técnicas PSR.\\nA ideia de busca por retrocesso remonta a Golomb e Baumert (1965), e sua aplicação para a\\nsatisfação de restrição deve-se a Bitner e Reingold (1975), embora trace o algoritmo básico do\\nséculo XIX. Bitner e Reingold também introduziram a heurística VRM, que eles chamavam de\\nheurística de variável mais restrita. Brelaz (1979) usou a heurística de grau como desempate após a\\naplicação da heurística VRM. O algoritmo resultante, apesar da sua simplicidade, ainda é o melhor\\nmétodo para grafos arbitrários de \\nk\\n-coloração. Haralick e Elliot (1980) propuseram a heurística do\\nvalor menos restritivo.\\nO método básico de retorno (\\nbackjumping\\n) é devido a John Gaschnig (1977, 1979). Kondrak e\\nVan Beek (1997) mostraram que esse algoritmo foi essencialmente incorporado pela verificação\\nprévia. O retorno orientado por conflito foi criado por Prosser (1993). Na realidade, a forma mais\\ngeral e poderosa de retrocesso inteligente foi desenvolvida muito cedo por Stallman e Sussman', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 276}),\n",
       " Document(page_content='(1977). Sua técnica de \\nretrocesso orientado por dependência\\n levou ao desenvolvimento de\\nsistemas de manutenção de verdade\\n (Doyle, 1979), que discutiremos na \\nSeção 12.6.2\\n. A conexão\\nentre as duas áreas é analisada por De Kleer (1989).\\nO trabalho de Stallman e Sussman também introduziu a ideia de \\naprendizagem de restrição\\n, em\\nque resultados parciais obtidos por busca podem ser gravados e reutilizados mais tarde na busca. A\\nideia foi apresentada formalmente na busca com retrocesso formalizada por Dechter (1990a). A\\nmarcação para trás\\n (Gaschnig, 1979) é um método particularmente simples no qual as atribuições\\nconsistentes e inconsistentes são gravadas aos pares e usadas para evitar a repetição de verificações\\nde restrições. A marcação para trás pode ser combinada com o retorno orientado por conflito;\\nKondrak e Van Beek (1997) apresentam um algoritmo híbrido que provavelmente inclui qualquer\\nmétodo tomado separadamente. O método de \\nretrocesso dinâmico\\n (Ginsberg, 1993) retém\\natribuições parciais bem-sucedidas de subconjuntos de variáveis posteriores ao realizar o retrocesso\\nsobre uma escolha anterior que não invalida o sucesso posterior.\\nEstudos empíricos de vários métodos de retrocesso randomizado foram feitos por Gomes \\net al\\n.\\n(2000) e Gomes e Selman (2001). Van Beek (2006) pesquisou o retrocesso.\\nA busca local em problemas de satisfação de restrições foi popularizada pelo trabalho de\\nKirkpatrick \\net al\\n. (1983) sobre têmpera simulada (veja o Capítulo 4), amplamente utilizado em\\nproblemas de escalonamento. A heurística de conflitos mínimos foi proposta inicialmente por Gu\\n(1989) e de forma independente por Minton \\net al\\n. (1992). Sosic e Gu (1994) mostraram como ela\\npoderia ser aplicada para resolver o problema de 3.000.000 de rainhas em menos de um minuto. O\\nespantoso sucesso da busca local utilizando conflitos mínimos de \\nn\\n rainhas levou a uma reavaliação\\nda natureza e da prevalência de problemas “fáceis” e “difíceis”. Peter Cheeseman \\net al\\n. (1991)\\nexploraram a dificuldade de PSRs gerados aleatoriamente e descobriram que quase todos esses\\nproblemas são trivialmente fáceis ou não têm nenhuma solução. Apenas se os parâmetros do gerador\\nde problemas forem definidos em certo intervalo estreito, dentro do qual aproximadamente metade\\ndos problemas é solúvel, encontraremos instâncias de problemas “difíceis”. Discutiremos esse\\nfenômeno com mais detalhes no Capítulo 7. Konolige (1994) mostrou que a busca local é inferior à\\nbusca em retrocesso para problemas com certo grau de estrutura local, o que levou a um trabalho que\\ncombinou busca local e inferência, como o de Pinkas e Dechter (1995). Hoos e Tsang (2006)\\npesquisaram técnicas de busca local.\\nO trabalho relacionado à estrutura e à complexidade de PSRs teve origem em Freuder (1985), que\\nmostrou que a busca em árvores com consistência de arco funciona sem qualquer retrocesso. Um\\nresultado semelhante, com extensões para hipergrafos acíclicos, foi desenvolvido na comunidade de\\nbancos de dados (Beeri \\net al\\n., 1983). Bayardo e Miranker (1994) apresentaram um algoritmo para\\nPSRs estruturado em árvore que executa em tempo linear sem qualquer pré-processamento.\\nDesde que esses artigos foram publicados, houve um grande progresso no desenvolvimento de\\nresultados mais gerais relacionando a complexidade da resolução de um PSR à estrutura de seu grafo\\nde restrições. A noção de largura de árvore foi introduzida pelos teóricos de grafo Robertson e\\nSeymour (1986). Dechter e Pearl (1987, 1989), fundamentados no trabalho de Freuder, aplicaram a\\nmesma noção (que denominaram \\nlargura induzida\\n) a problemas de satisfação de restrições e\\ndesenvolveram a abordagem de decomposição em árvore descrita na \\nSeção 6.5\\n. Com base nesse\\ntrabalho e nos resultados da teoria de bancos de dados, Gottlob \\net al\\n. (1999a, 1999b) desenvolveram', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 277}),\n",
       " Document(page_content='a noção de \\nlargura de hiperárvore\\n, baseada na caracterização do PSR como um hipergrafo. Além\\ndisso, para mostrar que qualquer PSR com largura de hiperárvore \\nw\\n pode ser resolvido no tempo\\nO\\n(\\nn\\nw\\n+1\\nlog \\nn\\n), eles também demonstraram que a largura de hiperárvore inclui todas as medidas\\ndefinidas anteriormente de “largura”, no sentido de que existem casos em que a largura de\\nhiperárvore é limitada, e as outras medidas são ilimitadas.\\nO interesse em rememorar as abordagens anteriores de retrocesso foi reacendido pelo trabalho de\\nBayardo e Schrag (1997), cujo algoritmo RELSAT combinou aprendizagem de restrição e retorno, e\\nmostrou que superava muitos outros algoritmos da época. Isso levou aos algoritmos de busca E/OU\\naplicáveis tanto a PSRs quanto ao raciocínio probabilístico (Dechter e Mateescu, 2007). Brown \\net\\nal\\n. (1988) introduziram a ideia de quebra de simetria em PSR, e Gent \\net al.\\n (2006) ofereceram uma\\npesquisa recente.\\nO campo de \\nsatisfação de restrição distribuída\\n observa a resolução de PSR quando há uma\\ncoleção de agentes, cada qual controlando um subconjunto das variáveis de restrição. Desde 2000\\nrealizam-se \\nworkshops\\n anuais sobre esse problema e existe ampla abordagem por toda parte (Collin\\net al\\n., 1999; Pearce \\net al\\n., 2008; Shoham e Leyton-Brown, 2009).\\nA comparação de algoritmos PSR é principalmente uma ciência empírica: alguns resultados\\nteóricos mostram que um algoritmo domina um outro sobre todos os problemas; em lugar disso,\\nprecisamos executar tentativas para ver quais algoritmos têm melhor desempenho em situações de\\ninstância de problemas típicos. Como Hooker (1995) apontou, precisamos ter cuidado em distinguir\\nentre testes competitivos, como ocorre em competições entre os algoritmos baseados em tempo de\\nexecução, e testes científicos, cujo objetivo é identificar as propriedades de um algoritmo que\\ndeterminam a sua eficácia em uma classe de problemas.\\nOs livros didáticos recentes por Apt (2003) e Dechter (2003), e a coleção de Rossi \\net al.\\n (2006)\\nsão excelentes recursos de processamento de restrição. Existem diversos trabalhos de pesquisa de\\nboa qualidade sobre técnicas de PSRs, incluindo os de Kumar (1992), Dechter e Frost (1999), e\\nBartak (2001), além dos excelentes artigos de Dechter (1992) e Mackworth (1992). Pearson e\\nJeavons (1997) pesquisam classes tratáveis de PSRs, cobrindo tanto os métodos de decomposição\\nestrutural quanto métodos que se baseiam em propriedades dos domínios ou das próprias restrições.\\nKondrak e Van Beek (1997) fornecem um estudo analítico dos algoritmos de busca com\\nretrocesso, e Bacchus e Van Run (1995) apresentam um estudo mais empírico. A programação de\\nrestrição é abordada nos livros de Apt (2003) e Fruhwirth e Abdennadher (2003). Artigos sobre\\nsatisfação de restrições aparecem regularmente em \\nArtificial Intelligence\\n e no periódico\\nespecializado \\nConstraints\\n. A principal conferência é a International Conference on Principles and\\nPractice of Constraint Programming, frequentemente chamada \\nCP\\n.\\nEXERCÍCIOS\\n6.1\\n Quantas soluções existem para o problema de coloração de mapa da \\nFigura 6.1\\n? Quantas\\nsoluções existem se quatro cores forem permitidas? Duas cores?\\n6.2\\n Considere o problema de colocar k cavalos em um tabuleiro de xadrez n x n tal que dois cavalos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 278}),\n",
       " Document(page_content='não se ataquem mutuamente, onde k é dado e k ≤ n\\n2\\n.\\na.\\n Escolha uma formulação PSR. Nessa formulação, quais são as variáveis?\\nb.\\n Quais são os valores possíveis de cada variável?\\nc.\\n Qual o conjunto de variáveis que são restritas e como?\\nd.\\n Agora considere o problema de colocar \\ntantos cavalos quanto possível\\n no tabuleiro sem que\\neles ataquem. Explique como resolver os problemas através de busca local definindo funções\\nAÇÕES e RESULTADO apropriadas e uma função objetivo sensível.\\n6.3\\n Considere o problema de construir (não de resolver) quebra-cabeças de palavras cruzadas:\\n5\\nencaixar palavras em uma grade retangular. A grade, dada como parte do problema, especifica quais\\nquadrados estão vazios e quais deles estão sombreados. Suponha que uma lista de palavras (isto é,\\num dicionário) seja fornecida e que a tarefa seja preencher os quadrados vazios usando qualquer\\nsubconjunto da lista. Formule esse problema de forma exata, de duas maneiras:\\na.\\n Como um problema de busca geral. Escolha um algoritmo de busca apropriado e especifique\\numa função heurística, se achar que é necessário utilizá-la. É melhor preencher os espaços\\nvazios uma letra de cada vez ou uma palavra de cada vez?\\nb.\\n Como um problema de satisfação de restrições. As variáveis devem ser palavras ou letras?\\nNa sua opinião, qual será a melhor formulação? Por quê?\\n6.4\\n Forneça formulações precisas para cada um dos problemas a seguir como problemas de\\nsatisfação de restrições:\\na\\n. Criação de planta-baixa retilínea: encontrar posições não superpostas em um retângulo grande\\npara vários retângulos menores.\\nb\\n. Escalonamento de aulas: existe um número fixo de professores e salas de aula, uma lista de\\naulas a serem oferecidas e uma lista de tempos vagos possíveis para as aulas. Cada professor\\ntem um conjunto de aulas que pode ministrar.\\nc\\n. Ciclo hamiltoniano: dada uma rede de cidades ligadas por estradas, escolha uma ordem para\\nvisitar todas as cidades em um país sem repetir nenhuma.\\n6.5\\n Resolva o problema criptoaritmético da \\nFigura 6.2\\n à mão, utilizando a estratégia de retrocesso\\ncom verificação prévia e de VRM e valor menos restritivo.\\n6.6\\n Mostre que uma única restrição ternária do tipo “\\nA\\n + \\nB\\n = \\nC\\n” pode ser transformada em três\\nrestrições binárias usando-se uma variável auxiliar. Suponha domínios finitos. (\\nSugestão:\\n Considere\\numa nova variável que assume valores que são pares de outros valores e considere restrições como\\n“\\nX\\n é o primeiro elemento do par \\nY\\n”.) Em seguida, mostre que restrições com mais de três variáveis\\npodem ser tratadas de modo semelhante. Finalmente, mostre que restrições unárias podem ser\\neliminadas alterando-se os domínios de variáveis. Isso completa a demonstração de que qualquer\\nPSR pode ser transformado em um PSR apenas com restrições binárias.\\n6.7\\n Considere o seguinte quebra-cabeça lógico: em cinco casas, cada uma com uma cor diferente,\\nmoram cinco pessoas de diferentes nacionalidades, cada uma das quais prefere uma marca de\\ncigarros diferente, uma bebida diferente e um animal de estimação diferente. Dados os fatos a seguir,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 279}),\n",
       " Document(page_content='a pergunta a responder é: “Onde vive a zebra e em que casa se bebe água?”\\nO inglês mora na casa vermelha.\\nO espanhol é o dono do cachorro.\\nO norueguês mora na primeira casa à esquerda.\\nA casa verde é imediatamente à direita da casa marfim.\\nO homem que come barras Hersey vive na casa ao lado do homem com a raposa.\\nKit Kats são consumidos na casa amarela.\\nO norueguês mora ao lado da casa azul.\\nO consumidor de Smarties come a própria unha.\\nO consumidor de Snickers bebe suco de laranja.\\nO ucraniano bebe chá.\\nO japonês come Milky Ways.\\nKit Kats são consumidos na casa ao lado de onde o cavalo é mantido.\\nBebe-se café na casa verde.\\nBebe-se leite na casa do meio.\\nDescreva diferentes representações desse problema como um PSR. Por que seria preferível uma\\nrepresentação em vez de outra?\\n6.8\\n Considere o grafo com oito nós de \\nA\\n1\\n, \\nA\\n2\\n, \\nA\\n3\\n, \\nA\\n4\\n, \\nH\\n, \\nT\\n, \\nF\\n1\\n, \\nF\\n2\\n. \\nA\\ni\\n \\ne\\nstá ligado em \\nA\\ni\\n+1\\n para todo \\ni\\n,\\ncada \\nA\\ni\\n está ligado a \\nH\\n, \\nH\\n está ligado a \\nT\\n e \\nT\\n está ligado a cada \\nF\\ni\\n. Encontre três colorações desse\\ngrafo à mão usando a seguinte estratégia: retrocesso com retorno orientado por conflito, a ordem das\\nvariáveis \\nA\\n1\\n, \\nH\\n, \\nA\\n4\\n, \\nF\\n1\\n, \\nA\\n2\\n, \\nF\\n2\\n, \\nA\\n3\\n, \\nT\\n e a ordem dos valores \\nR\\n, \\nG\\n, \\nB\\n.\\n6.9\\n Explique por que é uma boa heurística escolher a variável \\nmais\\n restrita, mas selecionar o valor\\nmenos\\n restritivo em uma busca de PSR.\\n \\n6.10\\n Gere instâncias aleatórias dos problemas de coloração do mapa da seguinte forma:\\nespalhe \\nn\\n pontos em uma unidade quadrada; selecione um ponto \\nX\\n de forma aleatória, conecte \\nX\\n por\\numa linha reta ao ponto mais próximo de \\nY\\n tal que \\nX\\n não esteja conectado a \\nY\\n e a linha não atravesse\\nnenhuma outra linha; repita a etapa anterior até que não seja possível mais conexões. Os pontos\\nrepresentam as regiões no mapa e as linhas ligam-se aos vizinhos. Agora tente encontrar \\nk\\n-\\ncolorações de cada mapa, para \\nk\\n = 3 e \\nk\\n = 4, utilizando conflitos mínimos, retrocesso, retrocesso\\ncom verificação prévia e retrocesso com MAC. Construa uma tabela de tempos médios de execução\\npara cada algoritmo para valores de \\nn\\n até o maior que você possa gerenciar. Comente sobre seus\\nresultados.\\n6.11\\n Use o algoritmo CA-3 para mostrar que a consistência de arco é capaz de detectar a\\ninconsistência da atribuição parcial {\\nAO\\n = \\nverde\\n, \\nV\\n = vermelho} para o problema mostrado na\\nFigura 6.1\\n.\\n6.12\\n Qual é a complexidade do pior caso da execução de CA-3 sobre um PSR estruturado em\\nárvore?', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 280}),\n",
       " Document(page_content='6.13\\n CA-3 coloca de volta na fila \\ntodo\\n arco (\\nX\\nk\\n, \\nX\\ni\\n) sempre que \\nqualquer\\n valor é excluído do\\ndomínio de \\nX\\ni\\n, mesmo que cada valor de \\nX\\nk\\n seja consistente com diversos valores restantes de \\nX\\ni\\n.\\nVamos supor que, para todo arco (\\nX\\nk\\n, \\nX\\ni\\n), mantemos o controle do número de valores restantes de \\nX\\ni\\nque são consistentes com cada valor de \\nX\\nk\\n. Explique como atualizar esses números de modo eficiente\\ne, consequentemente, mostre que a consistência de arco pode ser imposta no tempo total \\nO\\n(\\nn\\n2\\nd\\n2\\n).\\n6.14\\n O SOLUCIONADOR-ÁRVORE-PSR (\\nFigura 6.10\\n) faz com que a consistência de arco inicie a\\npartir de folhas e volte em direção à raiz. Por que ele faz isso? O que aconteceria se ele fosse para a\\ndireção oposta?\\n6.15\\n Introduzimos o Sudoku como um PSR a ser resolvido por busca sobre atribuições parciais\\nporque essa é a maneira como as pessoas geralmente se comprometem com a resolução de problemas\\nde Sudoku. Também é possível, certamente, atacar esses problemas com busca local\\ncomplementando essas atribuições. Como se sairia um solucionador local usando a heurística de\\nconflitos mínimos em problemas do Sudoku?\\n6.16\\n Defina com suas próprias palavras as expressões problema de satisfação de restrições,\\nrestrição, busca com retrocesso, consistência de arco, retorno e conflitos mínimos.\\n \\n6.17\\n Suponha que se saiba que um grafo tem um conjunto de corte de ciclo de não mais de \\nk\\nnós. Descreva um algoritmo simples para encontrar um conjunto de corte de ciclo mínimo cujo tempo\\nde execução não seja muito maior que \\nO\\n(\\nn\\nk\\n) para um PSR com \\nn\\n variáveis. Pesquise na literatura\\nmétodos para encontrar conjuntos de corte de ciclos aproximadamente mínimos em um tempo\\npolinomial no tamanho do conjunto de corte. A existência de tais algoritmos torna prático o método\\nde conjunto de corte de ciclo?\\n1\\n Um algoritmo AC-4 (Mohr e Henderson, 1986) executa no pior caso de tempo \\nO\\n(\\ncd\\n2\\n), mas pode ser mais lento do que AC-3 na\\nmaioria dos casos. Veja o Exercício 6.13.\\n2\\n A busca local pode ser estendida facilmente para problemas de otimização de restrições PORs. Nesse caso, todas as técnicas de\\nsubida de encosta e têmpera simulada podem ser aplicadas para otimizar a função objetivo.\\n3\\n Um cartógrafo cuidadoso ou um tasmaniano patriota poderia objetar que a Tasmânia não deve ter a mesma cor de seu vizinho.\\n4\\n Infelizmente, bem poucas regiões do mundo têm mapas estruturados em árvore, apesar de Sulawesi chegar perto.\\n5\\n Ginsberg \\net al\\n. (1990) descrevem diversos métodos para construir quebra-cabeças de palavras cruzadas. Littman \\net al\\n. (1999) atacam\\no problema mais difícil de resolvê-los.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 281}),\n",
       " Document(page_content='PARTE III\\nConhecimento, pensamento e planejamento', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 282}),\n",
       " Document(page_content='O\\nCAPÍTULO\\n \\n7\\nAgentes lógicos\\nEm que projetamos agentes que podem formar representações de um mundo\\ncomplexo, usar um processo de inferência para derivar novas representações\\nsobre o mundo e utilizar essas novas representações para deduzir o que fazer.\\ns seres humanos, parece, sabem das coisas; e o que sabem os ajuda a fazer coisas. Essas não são\\ndeclarações vazias. Produzem alegações fortes de como a inteligência dos seres humanos é\\nalcançada — não por mecanismos puramente reflexos, mas por processos de \\nraciocínio\\n que\\noperam em \\nrepresentações\\n internas do conhecimento. Em IA, essa abordagem à inteligência é\\nincorporada em \\nagentes baseados em conhecimento\\n.\\nOs agentes de resolução de problemas dos Capítulos 3 e 4 conhecem as coisas, mas apenas em um\\nsentido muito limitado, inflexível. Por exemplo, o modelo de transição do quebra-cabeça de oito\\npeças — conhecimento do que as ações fazem — está escondido dentro do código de domínio\\nespecífico da função RESULTADO. Pode ser utilizado para prever o resultado das ações, mas não\\npara deduzir que duas peças não podem ocupar o mesmo espaço ou que estados com paridade ímpar\\nnão podem ser alcançados de estados com paridade par. As representações atômicas utilizadas por\\nagentes de resolução de problemas também são muito limitantes. Em um ambiente parcialmente\\nobservável, a única escolha do agente para representar o que sabe sobre o estado atual é listar todos\\nos possíveis estados concretos — uma perspectiva sem esperança em grandes ambientes.\\nO Capítulo 6 introduziu a ideia de representação dos estados como atribuições de valores para as\\nvariáveis; esse é um passo na direção certa, permitindo que algumas partes do agente trabalhem em\\numa forma de domínio independente e permitindo algoritmos mais eficientes. Neste capítulo e\\nnaqueles que se seguem, tomaremos essa etapa na sua conclusão lógica, por assim dizer —\\ndesenvolveremos a \\nlógica\\n como uma classe geral de representações para apoiar agentes baseados no\\nconhecimento. Tais agentes poderão combinar e recombinar informações para atender às finalidades\\ninumeráveis. Muitas vezes, esse processo pode ser bastante distante das necessidades do momento\\n— como quando um matemático demonstra um teorema ou um astrônomo calcula a expectativa de\\nvida da Terra. Os agentes baseados no conhecimento são capazes de aceitar novas tarefas sob a\\nforma de metas descritas de modo explícito, podem alcançar competência rapidamente ao serem\\ninformados ou ao adquirirem novos conhecimentos sobre o ambiente e podem se adaptar a mudanças\\nno ambiente, atualizando o conhecimento relevante.\\nComeçamos na \\nSeção 7.1\\n com o projeto global de agentes. A \\nSeção 7.2\\n introduz um novo ambiente', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 284}),\n",
       " Document(page_content='simples, o mundo de wumpus, e ilustra a operação de um agente baseado em conhecimento sem entrar\\nem qualquer detalhe técnico. Em seguida, explicamos os princípios gerais da \\nlógica\\n na \\nSeção 7.3\\n e o\\ncaso particular da \\nlógica proposicional\\n na \\nSeção 7.4\\n. Embora seja muito menos expressiva que a\\nlógica de primeira ordem\\n (Capítulo 8), a lógica proposicional serve para ilustrar todos os conceitos\\nbásicos de lógica; é também acompanhada de tecnologias de inferência bem desenvolvidas, que\\ndescreveremos nas Seções 7.5 e 7.6. Finalmente, a \\nSeção 7.7\\n combina o conceito de agentes\\nbaseados em conhecimento com a tecnologia de lógica proposicional com a finalidade de construir\\nalguns agentes simples para o mundo de wumpus.\\n7.1 AGENTES BASEADOS EM CONHECIMENTO\\nO componente central de um agente baseado em conhecimento é sua \\nbase de conhecimento\\n, ou\\nKB. Informalmente, uma base de conhecimento é um conjunto de \\nsentenças\\n (aqui, “sentença” é\\nutilizada como um termo técnico; está relacionada mas não é idêntica às sentenças em português e em\\noutros idiomas ou linguagens naturais). Cada sentença é expressa em uma linguagem chamada\\nlinguagem de representação de conhecimento\\n e representa alguma asserção sobre o mundo. Às\\nvezes, ilustramos uma sentença com o nome \\naxioma\\n, quando a sentença for tomada como dada sem\\nser derivada de outras sentenças.\\nDeve haver um modo para adicionar novas sentenças à base de conhecimento e um meio de\\nconsultar o que se conhece. Os nomes-padrão para essas operações são TELL (informe) e ASK\\n(pergunte), respectivamente. Ambas as operações podem envolver \\ninferência\\n, ou seja, a derivação\\nde novas sentenças a partir de sentenças antigas.\\nA inferência deve obedecer ao requisito fundamental de que, quando se formula (com ASK) uma\\npergunta para a base de conhecimento, a resposta deve seguir do que foi informado (com TELL)\\nanteriormente à base de conhecimento. Mais adiante neste capítulo, seremos mais precisos quanto ao\\ntermo fundamental “seguir”. No momento, basta levar em conta que ele significa que o processo de\\ninferência não deve apenas inventar coisas à medida que prossegue.\\nA \\nFigura 7.1\\n mostra o esboço de um programa de agente baseado em conhecimento. Como todos\\nos nossos agentes, ele recebe uma percepção como entrada e retorna uma ação. O agente mantém uma\\nbase de conhecimento, \\nKB\\n, que pode conter inicialmente algum \\nconhecimento inicial\\n.\\nfunção\\n AGENTE-KB(\\npercepção\\n) \\nretorna\\n uma \\nação\\n    \\npersistente:\\n \\nKB\\n, uma base de conhecimento\\nt\\n, um contador, inicialmente igual a 0, indicando tempo\\n    TELL(\\nKB\\n, CRIAR-SENTENÇA-DE-PERCEPÇÃO(\\npercepção\\n, \\nt\\n))\\n    \\nação\\n ← ASK(\\nKB\\n CRIAR-CONSULTA-DE-AÇÃO(\\nt\\n))\\n    TELL(\\nKB\\n, CRIAR-SENTENÇA-DE-AÇÃO(\\nação\\n, \\nt\\n))\\n    \\nt\\n ← \\nt\\n + 1\\n    \\nretornar\\n \\nação\\nFigura 7.1\\n Um agente baseado em conhecimento genérico. Dada uma percepção, o agente adiciona a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 285}),\n",
       " Document(page_content='percepção na sua base de conhecimento, pergunta à base de conhecimento qual a melhor ação e\\ninforma à base de conhecimento que executou de fato essa ação.\\nCada vez que o programa do agente é chamado, ele executa duas ações. Primeiro, informa (com\\nTELL) à base de conhecimento o que percebe. Em segundo lugar, pergunta (com ASK) à base de\\nconhecimento que ação deve executar. No processo de responder a essa consulta, talvez seja\\ndesenvolvido um raciocínio extenso sobre o estado atual do mundo, sobre os resultados de\\nsequências de ações possíveis, e assim por diante. Terceiro, o programa agente INFORMA (TELL)\\npara a base de conhecimento que ação foi escolhida, e o agente executa a ação.\\nOs detalhes da linguagem de representação estão ocultos em duas funções que implementam a\\ninterface entre os sensores e atuadores, de um lado, e entre a representação central e o sistema de\\nraciocínio, do outro. CRIAR-SENTENÇA-DE-PERCEPÇÃO constrói uma sentença afirmando que o\\nagente percebeu a percepção no instante dado. CRIAR-CONSULTA-DE-AÇÃO constrói uma\\nsentença que pergunta que ação deve ser executada nesse instante. Finalmente, CRIAR-SENTENÇA-\\nDE-AÇÃO constrói uma sentença afirmando que a ação escolhida foi executada. Os detalhes dos\\nmecanismos de inferência ficam ocultos dentro de TELL e ASK. As próximas seções revelarão esses\\ndetalhes.\\nO agente da \\nFigura 7.1\\n parece bastante semelhante aos agentes com estado interno descritos no\\nCapítulo 2. Porém, devido às definições de TELL e ASK, o agente baseado em conhecimento não é\\num programa arbitrário para calcular ações. Ele se adapta a uma descrição no \\nnível de\\nconhecimento\\n, em que precisamos especificar apenas o que o agente sabe e quais são suas metas, a\\nfim de corrigir seu comportamento. Por exemplo, um táxi automatizado poderia ter a meta de pegar\\num passageiro em San Francisco para Marin County e talvez soubesse que está em San Francisco e\\nque a ponte Golden Gate é a única ligação entre os dois locais. Então, podemos esperar que ele cruze\\na ponte Golden Gate \\nporque sabe que isso o levará a atingir sua meta\\n. Note que essa análise é\\nindependente de como o táxi funciona no \\nnível de implementação\\n. Não importa se seu conhecimento\\ngeográfico é implementado como listas encadeadas ou mapas de pixels, ou ainda se ele raciocina\\nmanipulando strings de símbolos armazenados em registradores ou propagando sinais com ruído em\\numa rede de neurônios.\\nUm agente baseado em conhecimento pode ser construído simplesmente informando (TELLing) o\\nque é necessário saber. Começando com uma base de conhecimento vazia, o agente projetista pode\\nINFORMAR (TELL) sentenças uma a uma até que o agente saiba como operar em seu ambiente. Isso\\nse chama abordagem \\ndeclarativa\\n para a construção de sistemas. Em contraste, a abordagem\\nprocedural\\n codifica comportamentos desejados diretamente como código de programa. Nas décadas\\nde 1970 e 1980, os defensores das duas abordagens se engajaram em acalorados debates. Agora,\\nentendemos que um agente bem-sucedido sempre deve combinar elementos declarativos e\\nprocedurais em seu projeto e que o conhecimento declarativo muitas vezes pode ser compilado em\\num código procedural mais eficiente.\\nPodemos também fornecer a um agente baseado em conhecimento mecanismos que lhe permitam\\naprender por si mesmo. Esses mecanismos, descritos no Capítulo 18, criam conhecimento geral sobre\\no ambiente a partir de uma série de percepções. Um agente que aprende pode ser totalmente\\nautônomo.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 286}),\n",
       " Document(page_content='7.2 O MUNDO DE WUMPUS\\nNesta seção, vamos descrever um ambiente em que os agentes baseados em conhecimento podem\\nmostrar o seu valor. O \\nmundo de wumpus\\n é uma caverna que consiste em salas conectadas por\\npassagens. À espreita em algum lugar na caverna está o terrível wumpus, um monstro que devora\\nqualquer guerreiro que entrar em sua sala. O wumpus pode ser atingido por um agente, mas o agente\\nsó tem uma flecha. Algumas salas contêm poços sem fundo nos quais cairá qualquer um que vagar por\\nelas (com exceção do wumpus, que é muito grande para cair em um poço). A única característica que\\nabranda esse ambiente desolador é a possibilidade de encontrar um monte de ouro. Embora o mundo\\nde wumpus seja bastante domesticado para os padrões dos modernos jogos de computador, ele\\nilustra alguns pontos importantes sobre a inteligência.\\nUma amostra de mundo de wumpus é apresentada na \\nFigura 7.2\\n. É dada a definição precisa do\\nambiente de tarefa, como sugere a \\nSeção 2.3\\n, de acordo com a descrição de PEAS:\\nFigura 7.2\\n Um mundo de wumpus típico. O agente está no canto inferior esquerdo virado para a\\ndireita.\\n•  \\nMedida de desempenho:\\n +1.000 para sair da caverna com o ouro, –1.000 se cair em um poço\\nou for devorado pelo wumpus, –1 para cada ação executada e –10 pelo uso da flecha. O jogo\\ntermina quando o agente morre ou quando sai da caverna.\\n•  \\nAmbiente:\\n Uma malha 4 × 4 de salas. O agente sempre começa no quadrado identificado como\\n[1,1], voltado para a direita. As posições do ouro e do wumpus são escolhidas ao acaso, com\\numa distribuição uniforme, a partir dos outros quadrados, diferentes do quadrado inicial. Além\\ndisso, cada quadrado com exceção do inicial pode ser um poço, com probabilidade 0,2.\\n•  \\nAtuadores:\\n O agente pode mover-se \\nParaFrente, VirarEsquerda\\n 90° ou V\\nirarDireita\\n 90°. O\\nagente terá uma morte horrível se entrar em um quadrado contendo um poço ou um wumpus vivo\\n(é seguro, embora fedorento, entrar em um quadrado com um wumpus morto). Se um agente tenta\\nmover-se para a frente e esbarra em uma parede, o agente não se move. A ação \\nAgarrar\\n pode ser\\nusada para levantar um objeto que está no mesmo quadrado em que se encontra o agente. A ação\\nAtirar\\n pode ser usada para disparar uma flecha em linha reta diante do agente. A flecha\\ncontinuará até atingir (e, consequentemente, matar) o wumpus ou até atingir uma parede. O agente\\nsó tem uma flecha e, portanto, apenas a primeira ação \\nAtirar\\n tem algum efeito. Finalmente, a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 287}),\n",
       " Document(page_content='ação \\nEscalar\\n pode ser usada para sair da caverna, mas apenas do quadrado [1,1].\\n•  \\nSensores:\\n O agente tem cinco sensores, cada um dos quais fornece um único bit de informação:\\n–  No quadrado contendo o wumpus e nos quadrados diretamente adjacentes (não em diagonal),\\no agente perceberá um \\nFedor\\n.\\n–  Nos quadrados diretamente adjacentes a um poço, o agente perceberá uma \\nBrisa\\n.\\n–  No quadrado onde está o ouro, o agente perceberá um \\nBrilho\\n.\\n–  Quando caminhar para uma parede, o agente perceberá um \\nImpacto\\n.\\n–  Quando o wumpus é morto, ele emite um \\nGrito\\n triste que pode ser percebido em qualquer\\nlugar na caverna.\\nAs percepções serão dadas ao programa do agente sob a forma de uma lista de cinco símbolos;\\npor exemplo, se houver um fedor e uma brisa, mas nenhum brilho, impacto ou grito, o programa\\ndo agente receberá a percepção [\\nFedor\\n, \\nBrisa\\n, \\nNada\\n, \\nNada\\n, \\nNada\\n].\\nPodemos definir o ambiente de wumpus de acordo com as várias dimensões dadas no Capítulo 2.\\nClaramente, é discreto, estático e de agente único (o wumpus não se move, felizmente). É sequencial,\\nporque as recompensas podem vir somente após muitas ações serem tomadas. É parcialmente\\nobservável, porque alguns aspectos do estado não são diretamente perceptíveis: a localização do\\nagente, o estado de saúde do wumpus e a disponibilidade de uma seta. Com relação aos locais dos\\npoços e do wumpus: poderíamos tratá-los como as partes não observáveis do estado que são\\nimutáveis — e, nesse caso, o modelo de transição para o ambiente é completamente conhecido ou\\npoderíamos dizer que o modelo de transição em si é desconhecido porque o agente não sabe quais\\nações \\nParaFrente\\n são fatais — em cada caso, descobrir a localização dos poços e do wumpus\\ncompleta o conhecimento do agente do modelo de transição.\\nPara um agente no ambiente, o principal desafio é a sua ignorância inicial da configuração do\\nambiente; superar essa ignorância parece exigir raciocínio lógico. Na maioria das instâncias do\\nmundo de wumpus, é possível para o agente recuperar o ouro em segurança. Ocasionalmente, o\\nagente deve escolher entre ir para casa de mãos vazias e se arriscar a morrer para encontrar o ouro.\\nCerca de 21% dos ambientes são totalmente injustos porque o ouro está em um poço ou cercado por\\npoços.\\nVamos acompanhar um agente de wumpus baseado em conhecimento em sua exploração do\\nambiente mostrado na \\nFigura 7.2\\n. Usamos uma linguagem de representação do conhecimento informal\\nque consiste em escrever símbolos em uma grade (como nas Figuras 7.3 e 7.4).\\nA base de conhecimento inicial do agente contém as regras do ambiente, como descrito\\nanteriormente; em particular, ele sabe que está em [1,1] e que [1,1] é um quadrado seguro; isso está\\nindicado com um “A” e “OK”, respectivamente, no quadrado [1,1].\\nA primeira percepção é [\\nNada\\n, \\nNada\\n, \\nNada\\n, \\nNada\\n, \\nNada\\n], a partir da qual o agente pode concluir\\nque seus quadrados vizinhos, [1,2] e [2,1], são seguros — estão OK. A \\nFigura 7.3\\n(a) mostra o estado\\nde conhecimento do agente nesse momento.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 288}),\n",
       " Document(page_content='Figura 7.3\\n O primeiro passo dado pelo agente no mundo de wumpus. (a) A situação inicial, depois\\nda percepção [\\nNada\\n, \\nNada\\n, \\nNada\\n, \\nNada\\n, \\nNada\\n]. (b) Depois de um movimento, com a percepção\\n[\\nNada\\n, \\nBrisa\\n, \\nNada\\n, \\nNada\\n, \\nNada\\n].\\nUm agente cauteloso só se moverá para um quadrado se souber que o quadrado está OK. Vamos\\nsupor que o agente decida se mover para a frente até [2,1]. O agente detecta uma brisa (indicada por\\n“B”) em [2,1] e, assim, deve haver um poço em um quadrado vizinho. O poço não pode estar em\\n[1,1], de acordo com as regras do jogo, e, portanto, deve haver um poço em [2,2], [3,1] ou ambos. A\\nnotação “P”? da \\nFigura 7.3\\n(b) indica um possível poço nesses quadrados. Nesse momento, existe\\napenas um quadrado conhecido que está OK e que ainda não foi visitado. Desse modo, o agente\\nprudente se voltará, retornará a [1,1] e depois prosseguirá para [1,2].\\nO agente percebe um fedor em [1,2], resultando no estado de conhecimento mostrado na \\nFigura\\n7.4\\n(a). O fedor em [1,2] significa que deve haver um wumpus por perto. No entanto, o wumpus não\\npode estar em [1,1], pelas regras do jogo, e não pode estar em [2,2] (ou o agente teria detectado um\\nfedor quando estava em [2,1]). Portanto, o agente pode deduzir que o wumpus está em [1,3]. A\\nnotação W! indica essa inferência. Além disso, a falta de uma brisa em [1,2] implica que não existe\\nnenhum poço em [2,2]. O agente já inferiu que deve haver um poço em [2,2] ou [3,1], então isso\\nsignifica que ele tem de estar em [3,1]. Essa inferência é bastante difícil porque combina o\\nconhecimento obtido em diferentes instantes em diferentes lugares e se baseia na falta de uma\\npercepção para dar um passo crucial.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 289}),\n",
       " Document(page_content='Figura 7.4\\n Duas fases posteriores no progresso do agente. (a) Depois do terceiro movimento, com a\\npercepção [\\nFedor\\n, \\nNada\\n, \\nNada\\n, \\nNada\\n, \\nNada\\n]. (b) Depois do quinto movimento, com a percepção\\n[\\nFedor\\n, \\nBrisa\\n, \\nBrilho\\n, \\nNada\\n, \\nNada\\n].\\nO agente agora provou a si mesmo que não existe nem poço nem wumpus em [2,2], então é \\nOK\\nmover-se para lá. Não mostraremos o estado do agente baseado em conhecimento em [2,2]; apenas\\nsupomos que o agente se volta e vai para [2,3], gerando a \\nFigura 7.4\\n(b). Em [2,3], o agente descobre\\num brilho e, assim, deve agarrar o ouro e voltar para casa.\\nObserve que, em cada caso no qual o agente tira uma conclusão a partir das informações\\ndisponíveis, essa conclusão tem a \\ngarantia\\n de ser correta se as informações disponíveis estiverem\\ncorretas. Essa é uma propriedade fundamental do raciocínio lógico. No restante deste capítulo,\\ndescreveremos como construir agentes lógicos que podem representar as informações necessárias e\\ntirar as conclusões tais como as descritas nos parágrafos precedentes.\\n7.3 LÓGICA\\nEsta seção resume os conceitos fundamentais de representação lógica e de raciocínio. Essas ideias\\nbonitas são independentes de qualquer das formas particulares de lógica. Portanto, adiaremos os\\ndetalhes técnicos de qualquer forma específica de lógica até a próxima seção, utilizando em vez\\ndisso o exemplo familiar de aritmética comum.\\nNa \\nSeção 7.1\\n, dissemos que as bases do conhecimento consistem em sentenças. Essas sentenças\\nsão expressas de acordo com a \\nsintaxe\\n da linguagem de representação, que especifica todas as\\nsentenças que são bem formadas. A noção de sintaxe é bastante clara na aritmética comum: “\\nx\\n + \\ny\\n =\\n4” é uma sentença bem formada, enquanto “\\nx\\n4\\ny\\n+ =” não é.\\nUma lógica também deve definir a \\nsemântica\\n ou o significado das sentenças. A semântica define a\\nverdade\\n de cada sentença com relação a cada \\nmundo possível\\n. Por exemplo, a semântica habitual\\nadotada pela aritmética especifica que a sentença “\\nx\\n + \\ny\\n = 4” é verdadeira em um mundo no qual \\nx\\n é\\n2 e \\ny\\n é 2, mas é falsa em um mundo em que \\nx\\n é 1 e \\ny\\n é 1. Em lógicas-padrão, toda sentença deve ser\\nverdadeira ou falsa em cada mundo possível — não existe nenhuma posição “intermediária”.\\n1\\nQuando precisarmos ser exatos, usaremos o termo \\nmodelo\\n em vez de “mundo possível”. Embora\\nmundos possíveis possam ser imaginados como ambientes (potencialmente) reais em que o agente\\npoderia ou não estar, os modelos são abstrações matemáticas, e cada um dos quais simplesmente fixa\\na verdade ou falsidade de cada sentença relevante. Em termos informais, podemos pensar em um\\nmundo possível como, por exemplo, tendo \\nx\\n homens e \\ny\\n mulheres que se sentam em torno de uma\\nmesa para jogar \\nbridge\\n, por exemplo, e a sentença \\nx\\n + \\ny\\n = 4 é verdadeira quando há quatro pessoas\\nao todo. Formalmente, os modelos possíveis são todas as atribuições possíveis de números reais às\\nvariáveis \\nx\\n e \\ny\\n. Cada atribuição fixa a verdade de qualquer sentença da aritmética cujas variáveis\\nsão \\nx\\n e \\ny\\n. Se uma sentença \\nα\\n for verdadeira no modelo \\nm,\\n dizemos que \\nm\\n \\nsatisfaz\\n \\nα\\n ou, por vezes, \\nm\\né um modelo de\\n \\nα\\n. Utilizamos a notação \\nM\\n(\\nα\\n) para indicar o conjunto de todos os modelos de \\nα\\n.\\nAgora, que temos uma noção de verdade, estamos prontos para conversar sobre raciocínio lógico.\\nEle envolve a relação de \\nconsequência lógica\\n entre sentenças — a ideia de que uma sentença', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 290}),\n",
       " Document(page_content='decorre logicamente\\n de outra sentença. Em notação matemática, escrevemos\\nα\\n |= \\nβ\\npara indicar que a sentença \\nα\\n tem como consequência lógica a sentença \\nβ\\n. A definição formal de\\nconsequência lógica é: \\nα\\n |= \\nβ\\n se e somente se, em todo modelo no qual \\nα\\n é verdadeira, \\nβ\\n também é\\nverdadeira. Utilizando a notação recém-apresentada, podemos escrever\\n(Observe a direção de \\n aqui: se \\nα\\n |= \\nβ\\n, então \\nα\\n é uma afirmação \\nmais forte\\n que \\nβ\\n: descarta \\nmais\\nmundos possíveis.) A relação de consequência lógica é familiar em aritmética; ficamos felizes com a\\nideia de que a sentença \\nx\\n = 0 tem como consequência lógica a sentença \\nxy = 0\\n. É óbvio que, em\\nqualquer modelo no qual \\nx é zero, xy\\n será zero (independentemente do valor de \\ny\\n).\\nPodemos aplicar o mesmo tipo de análise ao exemplo de raciocínio do mundo de wumpus dado na\\nseção anterior. Considere a situação da \\nFigura 7.3\\n(b): o agente detectou nada em [1,1] e uma brisa\\nem [2,1]. Essas percepções, combinadas com o conhecimento que o agente tem das regras do mundo\\nde wumpus constituem a BC. O agente está interessado (entre outras coisas) em saber se os\\nquadrados adjacentes [1,2], [2,2] e [3,1] contêm poços. Cada um dos três quadrados pode ou não\\nconter um poço e, assim (para os propósitos deste exemplo), existem 2\\n3\\n = 8 modelos possíveis.\\nEsses modelos são mostrados na \\nFigura 7.5\\n.\\n2\\nFigura 7.5\\n Modelos possíveis para representar a presença de poços nos quadrados [1,2], [2,2] e\\n[3,1]. BC corresponde às observações de nada em [1,1] e brisa em [2,1] é mostrada pela linha\\nsólida. (a) As linhas pontilhadas mostram modelos de \\nα\\n1\\n (nenhum poço em [1,2]). (b) As linhas\\npontilhadas mostram modelos de \\nα\\n2\\n (nenhum poço em [2,2]).\\nA BC pode ser considerada como um conjunto de sentenças ou como uma única sentença que\\nafirma todas as sentenças individuais. A BC é falsa em modelos que contradizem o que o agente sabe\\n— por exemplo, a BC é falsa em qualquer modelo em que [1,2] contém um poço porque não existe\\nnenhuma brisa em [1,1]. Na verdade, há apenas três modelos em que a BC é verdadeira, e esses\\nmodelos são mostrados circundados por uma linha sólida na \\nFigura 7.5\\n. Agora, vamos considerar\\nduas conclusões possíveis:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 291}),\n",
       " Document(page_content='Circundamos os modelos de \\nα\\n1\\n e \\nα\\n2\\n com linhas pontilhadas nas Figuras 7.5(a) e 7.5(b),\\nrespectivamente. Por inspeção, vemos que:\\nem todo modelo no qual \\nBC\\n é verdadeira, \\nα\\n1\\n também é verdadeira.\\nConsequentemente, \\nBC\\n |= \\nα\\n1\\n: não existe nenhum poço em [1,2]. Também podemos ver que:\\nem alguns modelos nos quais \\nBC\\n é verdadeira, \\nα\\n2\\n é falsa.\\nConsequentemente, \\nBC\\n \\n \\nα\\n2\\n: o agente \\nnão pode\\n concluir que não existe nenhum poço em [2,2]\\n(nem pode concluir que \\nexiste\\n um poço em [2,2]).\\n3\\nO exemplo anterior não só ilustra a consequência lógica, mas também mostra como a definição de\\nconsequência lógica pode ser aplicada para derivar conclusões, isto é, para conduzir a \\ninferência\\nlógica\\n. O algoritmo de inferência ilustrado na \\nFigura 7.5\\n é chamado \\nverificação de modelos\\n porque\\nenumera todos os modelos possíveis para verificar que \\nα\\n é verdadeira em todos os modelos em que\\nBC\\n é verdadeira, isto é, que a \\nM\\n(\\nBC\\n) \\n \\nM\\n(\\nα\\n).\\nNa compreensão da consequência lógica e da inferência, talvez ajude pensar no conjunto de todas\\nas consequências de \\nBC\\n como um palheiro e de a como uma agulha. A consequência lógica é como a\\nagulha estar no palheiro; a inferência é como encontrá-la. Essa distinção está corporificada em\\nalguma notação formal: se um algoritmo de inferência \\ni\\n pode derivar a de \\nBC\\n, escrevemos:\\nque lemos como “\\nα\\n é derivável de \\nBC\\n por \\ni\\n” ou “\\ni\\n deriva \\nα\\n de \\nBC\\n”.\\nO algoritmo de inferência que deriva apenas sentenças permitidas é chamado de \\ncorreto\\n ou se diz\\nque ele \\npreserva a verdade\\n. A correção é uma propriedade altamente desejável. Em essência, um\\nprocedimento de inferência não correto inventa coisas à medida que prossegue — ele anuncia a\\ndescoberta de agulhas que não existem. É fácil ver que a verificação de modelos, quando aplicável,\\n4\\né um procedimento correto.\\nA propriedade de \\ncompletude\\n também é desejável: um algoritmo de inferência será completo se\\npuder derivar qualquer consequência lógica. No caso de palheiros reais, que têm extensão finita,\\nparece óbvio que um exame sistemático sempre poderá definir se a agulha está no palheiro. Porém,\\nem muitas bases de conhecimento, o palheiro de consequências é infinito, e a completude se torna\\numa questão importante.\\n5\\n Felizmente, existem procedimentos de inferência completos para lógicas\\nque são suficientemente expressivas para dar conta de muitas bases de conhecimento.\\n Descrevemos um processo de raciocínio cujas conclusões oferecem a garantia de serem\\nverdadeiras em qualquer mundo no qual as premissas são verdadeiras; em particular, \\nse BC é\\nverdadeira no\\n mundo real, \\nqualquer sentença\\n a \\nderivada de BC por um procedimento de inferência\\ncorreto também será verdadeira no mundo real\\n. Portanto, embora um processo de inferência opere', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 292}),\n",
       " Document(page_content='sobre a “sintaxe” — configurações físicas internas como bits em registradores ou padrões de\\nimpulsos elétricos em cérebros — o processo \\ncorresponde\\n ao relacionamento no mundo real, no\\nqual algum aspecto do mundo real é o caso,\\n6\\n em virtude de outros aspectos do mundo real serem o\\ncaso. Essa correspondência entre o mundo e a representação está ilustrada na \\nFigura 7.6\\n.\\nFigura 7.6\\n Sentenças são configurações físicas do agente, e o raciocínio é um processo de construção\\nde novas configurações físicas a partir de configurações antigas. O raciocínio lógico deve assegurar\\nque as novas configurações representam aspectos do mundo que na realidade decorrem dos aspectos\\nque as antigas configurações representam.\\n A questão final a ser considerada é a da \\nfundamentação\\n — a conexão, se houver, entre\\nprocessos de raciocínio lógico e o ambiente real em que o agente existe. Em particular, \\ncomo\\nsabemos que a BC é verdadeira no mundo real\\n? (Afinal, a \\nBC\\n é apenas a “sintaxe” na cabeça do\\nagente.) Essa é uma questão filosófica sobre a qual muitos e muitos livros foram escritos (veja o\\nCapítulo 26). Uma resposta simples é que os sensores do agente criam a conexão. Por exemplo,\\nnosso agente do mundo de wumpus tem um sensor de odor. O programa do agente cria uma sentença\\nadequada sempre que há um odor. Então, sempre que a sentença está na base de conhecimento, ela é\\nverdadeira no mundo real. Desse modo, o significado e a verdade de sentenças de percepções são\\ndefinidos pelos processos de detecção e construção de sentenças que as produzem. E o restante do\\nconhecimento do agente, tal como sua convicção de que um wumpus provoca odores em quadrados\\nadjacentes? Essa não é uma representação direta de uma única percepção, mas uma regra geral —\\ntalvez derivada da experiência perceptiva, mas não idêntica a uma declaração dessa experiência.\\nRegras gerais como essa são produzidas por um processo de construção de sentenças chamado\\naprendizado\\n, que é o assunto da Parte V. O aprendizado é passível de falhas. Poderia ocorrer de um\\nwumpus provocar cheiro, \\nexceto no dia\\n 29 \\nde fevereiro de anos bissexto\\ns, que é o dia em que eles\\ntomam banho. Portanto, a \\nBC\\n pode não ser verdadeira no mundo real, mas há razão para otimismo no\\ncaso de bons procedimentos de aprendizado.\\n7.4 LÓGICA PROPOSICIONAL: UMA LÓGICA MUITO SIMPLES\\nAgora, apresentaremos uma lógica muito simples chamada \\nlógica proposicional\\n. Abordaremos a\\nsintaxe da lógica proposicional e sua semântica — o modo pelo qual a verdade das sentenças é\\ndeterminada. Depois, veremos a \\nconsequência lógica\\n — a relação entre uma sentença e outra\\nsentença que decorre dela — e como isso leva a um algoritmo simples para inferência lógica. É claro\\nque tudo tem lugar no mundo de wumpus.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 293}),\n",
       " Document(page_content='7.4.1 Sintaxe\\nA \\nsintaxe\\n da lógica proposicional define as sentenças permitidas. As \\nsentenças atômicas\\n — os\\nelementos sintáticos indivisíveis — consistem em um único \\nsímbolo proposicional\\n. Cada símbolo\\nproposicional representa uma proposição que pode ser verdadeira ou falsa. Utilizaremos símbolos\\nque começam com letra maiúscula e que podem conter outras letras ou subscritos, por exemplo: \\nP\\n, \\nQ\\n,\\nR\\n, \\nW\\n1,3\\n e \\nNorte.\\n Os nomes são arbitrários, com frequência escolhidos de forma a apresentar algum\\nvalor mnemônico para o leitor — podemos usar \\nW\\n1,3\\n para representar a proposição de que o wumpus\\nestá em [1,3]. (Lembre-se de que símbolos como \\nW\\n1,3\\n são \\natômicos\\n, isto é, \\nW\\n, 1 e 3 não são partes\\nsignificativas do símbolo.) Existem dois símbolos proposicionais com significados fixos:\\nVerdadeiro\\n é a proposição sempre verdadeira e \\nFalso\\n é a proposição sempre falsa.\\nAs \\nsentenças complexas\\n são construídas a partir de sentenças mais simples com a utilização de\\nparênteses e \\nconectivos lógicos\\n. Existem cinco conectivos de uso comum:\\n¬ (não). Uma sentença como ¬\\nW\\n1,3\\n é chamada \\nnegação\\n de \\nW\\n1,3\\n. Um \\nliteral\\n é uma sentença atômica\\n(um \\nliteral positivo\\n) ou uma sentença atômica negada (um \\nliteral negativo\\n).\\n∧\\n (e). Uma sentença cujo principal conectivo é \\n∧\\n, como \\nW\\n1,3\\n \\n∧\\n \\nP\\n3,1\\n, é chamada \\nconjunção\\n; suas\\npartes são os elementos da \\nconjunção\\n. (O símbolo \\n∧\\n é semelhante a “A” para indicar “And”\\n— “E” em inglês.)\\n∨\\n (ou). Uma sentença que utiliza \\n∨\\n, como (\\nW\\n1,3\\n \\n∧\\n \\nP\\n3,1\\n) \\n∨\\n \\nW\\n2,2\\n, é uma \\ndisjunção\\n dos \\ndisjuntos\\n(\\nW\\n1,3\\n \\n∧\\n \\nP\\n3,1\\n) e \\nW\\n2,2\\n. (Historicamente, o símbolo \\n∨\\n vem da palavra latina “vel”, que significa\\n“ou”. Para a maioria das pes\\u200bsoas, é mais fácil memorizá-lo como um símbolo \\n∧\\n invertido.)\\n⇒\\n (implica). Uma sentença como (\\nW\\n1,3\\n \\n∧\\n \\nP\\n3,1\\n) \\n⇒\\n ¬\\nW\\n2,2\\n é chamada \\nimplicação\\n (ou condicional).\\nSua \\npremissa\\n ou \\nantecedente\\n é (\\nW\\n1,3\\n \\n∧\\n \\nP\\n3,1\\n), e sua \\nconclusão\\n ou \\nconsequente\\n é ¬\\nW\\n2,2\\n. As\\nimplicações também são conhecidas como \\nregras\\n ou declarações \\nse–então\\n. O símbolo de\\nimplicação às vezes é escrito em outros livros como \\n⊃\\n ou →.\\n⇔\\n (se e somente se). A sentença \\nW\\n1,3\\n \\n⇔\\n ¬\\nW\\n2,2\\n é uma \\nbicondicional\\n. Alguns livros escrevem como\\n≡.\\nA \\nFigura 7.7\\n apresenta uma gramática formal da lógica proposicional; consulte a página 1060 se\\nnão estiver familiarizado com a notação BNF. A gramática BNF por si só é ambígua; uma sentença\\ncom vários operadores pode ser analisada  de várias maneiras pela gramática. Para eliminar a\\nambiguidade definimos uma precedência para cada operador. O operador “não” (¬) tem a\\nprecedência mais alta, o que significa que na sentença ¬ A \\n∧\\n B o ¬ liga-se mais firmemente, dando-\\nnos o equivalente de (¬A) \\n∧\\n B em vez de ¬(A \\n∧\\n B) (a notação para a aritmética comum é a mesma:\\n−2 + 4 são 2 e não −6). Em caso de dúvida, utilize parênteses para certificar-se da interpretação\\ncorreta. Colchetes quadrados significam a mesma coisa que parênteses; o objetivo da escolha de\\ncolchetes quadrados ou parênteses é apenas tornar mais fácil a leitura da sentença por um ser\\nhumano.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 294}),\n",
       " Document(page_content='Figura 7.7\\n Uma gramática BNF (Backus–Naur Form) de sentenças em lógica proposicional, com\\nprecedências de operadores do mais alto para o mais baixo.\\n7.4.2 Semântica\\nTendo especificado a sintaxe da lógica proposicional, agora especificaremos sua semântica. A\\nsemântica define as regras para determinar a verdade de uma sentença com respeito a um modelo\\nespecífico. Em lógica proposicional, um modelo simplesmente fixa o \\nvalor-verdade\\n — \\nverdadeiro\\nou \\nfalso\\n — para todo símbolo proposicional.\\nPor exemplo, se as sentenças na base de conhecimento fizerem uso dos símbolos proposicionais\\nP\\n1,2\\n, \\nP\\n2,2\\n e \\nP\\n3,1\\n, um modelo possível será:\\nm\\n1\\n = {\\nP\\n1,2\\n = \\nfalsa\\n, \\nP\\n2,2\\n = \\nfalsa\\n, \\nP\\n3,1\\n = \\nverdadeira\\n}.\\nCom três símbolos proposicionais, existem 2\\n3\\n = 8 modelos possíveis — exatamente aqueles que\\nestão representados na \\nFigura 7.5\\n. Porém, note que os modelos são objetos puramente matemáticos,\\nsem qualquer conexão necessária para mundos de wumpus. \\nP\\n1,2\\n é apenas um símbolo; ele poderia\\nsignificar “existe um poço em [1,2]” ou “estarei em Paris hoje e amanhã”.\\nA semântica da lógica proposicional deve especificar como calcular o valor verdade de \\nqualquer\\nsentença, dado um modelo. Isso é feito de forma recursiva. Todas as sentenças são construídas a\\npartir de sentenças atômicas e dos cinco conectivos; assim, precisamos especificar como calcular a\\nverdade de sentenças atômicas e como calcular a verdade de sentenças formadas com cada um dos\\ncinco conectivos. As sentenças atômicas são fáceis:\\n•  \\nVerdadeiro\\n é verdadeiro em todo modelo e \\nFalso\\n é falso em todo modelo.\\n•  O valor-verdade de todos os outros símbolos proposicionais deve ser especificado diretamente\\nno modelo. Por exemplo, no modelo \\nm\\n1\\n dado anteriormente, \\nP\\n1,2\\n é falsa.\\nPara sentenças complexas, temos cinco regras, que valem para quaisquer subsentenças \\nP\\n e \\nQ\\n em\\nqualquer modelo \\nm\\n (aqui “sse” significa “se e somente se”):\\n•  ¬\\nP\\n é verdadeiro sse \\nP\\n for falso em \\nm\\n.\\n•  \\nP\\n \\n∧\\n \\nQ\\n são verdadeiros sse \\nP\\n e \\nQ\\n forem verdadeiros em \\nm\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 295}),\n",
       " Document(page_content='•  \\nP\\n \\n∨\\n \\nQ\\n é verdadeiro sse \\nP\\n ou \\nQ\\n for verdadeiro em \\nm\\n.\\n•  \\nP\\n \\n⇒\\n \\nQ\\n é verdadeiro, a menos que \\nP\\n seja verdadeiro e \\nQ\\n seja falso em \\nm.\\n•  \\nP\\n \\n⇔\\n \\nQ\\n é verdadeiro sse \\nP\\n e \\nQ\\n forem ambos verdadeiros ou ambos falsos em \\nm\\n.\\nAs regras também podem ser expressas em \\ntabelas-verdade\\n que especificam o valor-verdade de\\numa sentença complexa para cada atribuição possível de valores-verdade a seus componentes. As\\ntabelas-verdade para os cinco conectivos lógicos são dadas na \\nFigura 7.8\\n. Dessas tabelas, o valor-\\nverdade de qualquer sentença \\ns\\n pode ser calculado com relação a qualquer modelo \\nm\\n por um\\nprocesso simples de avaliação recursiva. Por exemplo, a sentença ¬ \\nP\\n1,2\\n \\n∧\\n (\\nP\\n2,2\\n \\n∨\\n \\nP\\n3,1\\n), avaliada\\nem \\nm\\n1\\n, resulta em \\nverdadeiro\\n \\n∧\\n (\\nfalso\\n \\n∨\\n \\nverdadeiro\\n) = \\nverdadeiro\\n \\n∧\\n \\nverdadeiro\\n = \\nverdadeiro\\n. O\\nExercício 7.3 pede para escrever o algoritmo VERDADEIRO-LP?(\\ns\\n, \\nm\\n), que calcula o valor-\\nverdade de uma sentença de lógica proposicional \\ns\\n em um modelo \\nm\\n.\\nP\\nQ\\n¬\\nP\\nP\\n \\n∧\\n \\nQ\\nP\\n \\n∨\\n \\nQ\\nP\\n \\n⇒\\n \\nQ\\nP\\n \\n⇔\\n \\nQ\\nfalso\\nfalso\\nverdadeiro\\nverdadeiro\\nfalso\\nverdadeiro\\nfalso\\nverdadeiro\\nverdadeiro\\nverdadeiro\\nfalso\\nfalso\\nfalso\\nfalso\\nfalso\\nverdadeiro\\nfalso\\nverdadeiro\\nverdadeiro\\nverdadeiro\\nverdadeiro\\nverdadeiro\\nfalso\\nverdadeiro\\nverdadeiro\\nfalso\\nfalso\\nverdadeiro\\nFigura 7.8\\n Tabelas-verdade referentes aos cinco conectivos lógicos. Se quiser usar a tabela para\\ncalcular, por exemplo, o valor de \\nP\\n∨\\nQ\\n quando \\nP\\n é verdadeira e \\nQ\\n é falsa, primeiro procure no lado\\nesquerdo a linha em que \\nP\\n é \\nverdadeira\\n e \\nQ\\n é \\nfalsa\\n (a terceira linha). Em seguida, observe nessa\\nlinha sob a coluna \\nP\\n \\n∨\\n \\nQ\\n o resultado: \\nverdadeiro\\n.\\nA tabelas-verdade para “e”, “ou” e “não” estão intimamente relacionadas às nossas intuições\\nsobre as palavras em nosso idioma. O principal ponto de confusão possível é que \\nP\\n \\n∨\\n \\nQ\\n é\\nverdadeira quando \\nP\\n é verdadeira ou \\nQ\\n é verdadeira, \\nou ambas\\n. Existe um conectivo diferente\\nchamado “ou exclusivo” (“xor” para abreviar) que resulta em falso quando ambos os disjuntos são\\nverdadeiros\\n.\\n7\\n Não há nenhum consenso quanto ao símbolo para ou exclusivo; algumas opções são \\n∨\\nou ≠ ou \\n⊕\\n.\\nA tabela-verdade para) \\n⇒\\n pode parecer enigmática à primeira vista, porque talvez não se encaixe\\nmuito bem na compreensão intuitiva de que “\\nP\\n implica \\nQ\\n” ou “se \\nP\\n então \\nQ\\n”. Em primeiro lugar, a\\nlógica proposicional não exige qualquer relação de causa e efeito ou relevância entre \\nP\\n e \\nQ\\n. A\\nsentença “5 é ímpar implica que Tóquio é a capital do Japão” é uma sentença verdadeira da lógica\\nproposicional (sob a interpretação normal), embora seja uma sentença decididamente estranha em\\nportuguês. Outro ponto de confusão é que qualquer implicação é verdadeira sempre que sua\\nantecedente é falsa. Por exemplo, “5 é par implica que Sam é inteligente” é verdadeira,\\nindependentemente de Sam ser ou não inteligente. Isso parece estranho, mas faz sentido se você\\npensar em “\\nP\\n \\n⇒\\n \\nQ\\n” como “se \\nP\\n é verdadeira, então estou afirmando que \\nQ\\n é verdadeira. Caso\\ncontrário, não estou fazendo nenhuma afirmação”. O único modo de essa sentença ser \\nfalsa\\n é \\nP\\n ser\\nverdadeira, mas \\nQ\\n ser falsa.\\nA bicondicional \\nP\\n \\n⇔\\n \\nQ\\n é verdadeira sempre que tanto \\nP\\n \\n⇒\\n \\nQ\\n quanto \\nQ\\n \\n⇒\\n \\nP\\n sejam verdadeiras.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 296}),\n",
       " Document(page_content='Em nosso idioma, isso frequentemente é escrito como “\\nP\\n se e somente se \\nQ\\n”. Muitas das regras do\\nmundo de wumpus são mais bem escritas usando-se \\n⇔\\n. Por exemplo, um quadrado tem uma brisa \\nse\\num quadrado vizinho tem um poço, e um quadrado tem uma brisa \\nsomente se\\n um quadrado vizinho\\ntem um poço. Assim, precisamos de bicondicionais como:\\nonde \\nB\\n1,1\\n significa que existe uma brisa em [1,1].\\n7.4.3 Uma base de conhecimento simples\\nAgora que definimos a semântica para a lógica proposicional, podemos construir uma base de\\nconhecimento para o mundo de wumpus. Vamos concentrar-nos primeiro nos aspectos \\nimutáveis\\n do\\nmundo de wumpus, deixando os aspectos mutáveis para uma seção posterior. Por enquanto,\\nprecisamos dos seguintes símbolos para cada localização [\\nx\\n, \\ny\\n]:\\nP\\nx,y\\n é verdadeiro se existe um poço em [\\nx\\n, \\ny\\n].\\nW\\nx,y\\n é verdadeiro se existe um wumpus em [\\nx\\n, \\ny\\n], vivo ou morto.\\nB\\nx,y\\n é verdadeiro se o agente percebe uma brisa em [\\nx\\n, \\ny\\n].\\nS\\nx,y\\n é verdadeiro se o agente percebe um fedor em [\\nx\\n, \\ny\\n].\\nAs sentenças que escrevemos serão suficientes para derivar ¬\\nP\\n1,2\\n (não há poço em [1,2]), como\\nfeito informalmente na \\nSeção 7.3\\n. Rotularemos cada sentença de \\nR\\ni\\n, para que possamos nos referir a\\nelas:\\n•  Não há nenhum poço em [1,1]:\\n•  Um quadrado tem uma brisa se e somente se existe um poço em um quadrado vizinho. Isso tem de\\nser declarado para cada quadrado; por enquanto, incluímos apenas os quadrados relevantes:\\n•  As sentenças precedentes são verdadeiras em todos os mundos de wumpus. Agora, incluímos as\\npercepções de brisa para os dois primeiros quadrados visitados no mundo específico em que o\\nagente se encontra, levando à situação da \\nFigura 7.3\\n(b).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 297}),\n",
       " Document(page_content='7.4.4 Um procedimento de inferência simples\\nNosso objetivo agora é decidir se \\nBC\\n |= \\nα\\n para alguma sentença \\nα\\n. Por exemplo, ¬\\nP\\n1,2\\n é\\nconsequência lógica da nossa BC? Nosso primeiro algoritmo para inferência é uma abordagem de um\\nmodelo de verificação que é uma implementação direta da definição de consequência lógica:\\nenumere os modelos e verifique se \\nα\\n é verdadeira em todo modelo no qual \\nBC\\n é verdadeira. No caso\\nda lógica proposicional, os modelos são atribuições de \\nverdadeiro\\n ou \\nfalso\\n a todo símbolo\\nproposicional.\\nVoltando ao nosso exemplo do mundo de wumpus, os símbolos proposicionais relevantes são \\nB\\n1,1\\n,\\nB\\n2,1\\n, \\nP\\n1,1\\n, \\nP\\n1,2\\n, \\nP\\n2,1\\n, \\nP\\n2,2\\n e \\nP\\n3,1\\n. Com sete símbolos, existem 2\\n7\\n = 128 modelos possíveis; em três\\ndesses modelos, \\nBC\\n é verdadeira (\\nFigura 7.9\\n). Nesses três modelos, ¬\\nP\\n1,2\\n é verdadeira;\\nconsequentemente, não existe nenhum poço em [1,2]. Por outro lado, \\nP\\n2,2\\n é verdadeira em dois dos\\ntrês modelos e falsa em um, e assim não podemos dizer ainda se existe um poço em [2,2].\\nA \\nFigura 7.9\\n reproduz de forma mais precisa o raciocínio ilustrado na \\nFigura 7.5\\n. Um algoritmo\\ngeral para decidir a consequência lógica em lógica proposicional é mostrado na \\nFigura 7.10\\n. Como\\nno algoritmo BUSCA-COM-RETROCESSO na página 186, CONSEQUÊNCIA-LÓGICA? executa\\numa enumeração recursiva de um espaço finito de atribuições a variáveis. O algoritmo é \\nconsistente\\n,\\nporque implementa diretamente a definição de consequência lógica, e é \\ncompleto\\n, porque funciona\\npara qualquer \\nBC\\n e a, e sempre termina — só existe um número finito de modelos a examinar.\\nB\\n1,1\\nB\\n2,1\\nP\\n1,1\\nP\\n1,2\\nP\\n2,1\\nP\\n2,2\\nP\\n3,1\\nR\\n1\\nfalso\\nfalso\\n.\\n.\\n.\\nfalso\\nfalso\\nfalso\\n.\\n.\\n.\\nverdadeiro\\nfalso\\nfalso\\n.\\n.\\n.\\nfalso\\nfalso\\nfalso\\n.\\n.\\n.\\nfalso\\nfalso\\nfalso\\n.\\n.\\n.\\nfalso\\nfalso\\nfalso\\n.\\n.\\n.\\nfalso\\nfalso\\nverdadeiro\\n.\\n.\\n.\\nfalso\\nverdadeiro\\nverdadeiro\\n.\\n.\\n.\\nverdadeiro\\nfalso\\nfalso\\nfalso\\nverdadeiro\\nverdadeiro\\nverdadeiro\\nfalso\\nfalso\\nfalso\\nfalso\\nfalso\\nfalso\\nfalso\\nfalso\\nfalso\\nfalso\\nverdadeiro\\nverdadeiro\\nverdadeiro\\nfalso\\nverdadeiro\\nverdadeiro\\nverdadeiro\\nverdadeiro\\nfalso\\n.\\n.\\n.\\nverdadeiro\\nverdadeiro\\n.\\n.\\n.\\nverdadeiro\\nfalso\\n.\\n.\\n.\\nverdadeiro\\nfalso\\n.\\n.\\n.\\nverdadeiro\\nverdadeiro\\n.\\n.\\n.\\nverdadeiro\\nfalso\\n.\\n.\\n.\\nverdadeiro\\nfalso\\n.\\n.\\n.\\nverdadeiro\\nverdadeiro\\n.\\n.\\n.\\nfalso\\nFigura 7.9\\n Uma tabela-verdade construída para a base de conhecimento dada no texto. \\nBC\\n é\\nverdadeira se \\nR\\n1 a \\nR\\n5 são verdadeiras, o que acontece em apenas três das 128 linhas (as que estão\\nsublinhados na coluna do lado direito). Em todas as três linhas, \\nP\\n1,2\\n é falsa e, assim, não existe\\nnenhum poço em [1,2]. Por outro lado, pode haver (ou não) um poço em [2,2].', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 298}),\n",
       " Document(page_content='função\\n CONSEQUÊNCIA-LÓGICA-TV?(\\nBC\\n, \\nα\\n) \\ndevolve\\n \\nverdadeiro\\n ou \\nfalso\\n    \\nentradas\\n: \\nBC\\n, a base de conhecimento, uma sentença em lógica proposicional\\nα\\n, a consulta, uma sentença em lógica proposicional\\n    \\n    \\nsímbolos\\n ← uma lista dos símbolos proposicionais em \\nBC\\n e \\nα\\n    \\ndevolver\\n VERIFICAR-TODOS-TV(\\nBC\\n, \\nα\\n, \\nsímbolo\\ns, { })\\n_____________________________________________________________________________________________________________\\nfunção\\n VERIFICAR-TODOS-TV(\\nBC\\n, \\nα\\n, \\nsímbolo\\ns, \\nmodelo\\n) \\ndevolve\\n \\nverdadeiro\\n ou \\nfalso\\n    \\nse\\n VAZIO?(\\nsímbolo\\ns) \\nentão\\n        \\nse\\n VERDADEIRO-LP?(\\nBC\\n, \\nmodelo\\n) \\nentão devolver\\n VERDADEIRO-LP?(\\nα\\n, \\nmodelo\\n)\\n        \\nsenão devolver\\n \\nverdadeiro // quando BC for falso, sempre retornar verdadeiro\\n    \\nsenão faça\\n        \\nP\\n ← PRIMEIRO(\\nsímbolos\\n)\\n        \\nrestante\\n ← RESTO(\\nsímbolo\\ns)\\n        \\ndevolver\\n VERIFICAR-TODOS-TV(\\nBC\\n, \\nα\\n, \\nrestante\\n, \\nmodelo\\n \\n∪\\n {\\nP\\n = verdadeiro})\\ne\\nVERIFICAR-TODOS-TV(\\nBC\\n, \\nα\\n, \\nrestante\\n, \\nmodelo\\n \\n∪\\n {\\nP\\n = falso})\\nFigura 7.10\\n Um algoritmo de enumeração de tabela-verdade para decidir a consequência lógica\\nproposicional. (TV significa tabela-verdade.) VERDADEIRO-LP? retorna \\nverdadeiro\\n se uma\\nsentença é válida dentro de um modelo. A variável \\nmodelo\\n representa um modelo parcial — uma\\natribuição a alguns dos símbolos. A palavra-chave “\\ne\\n” é aqui utilizada como uma operação lógica\\nsobre seus dois argumentos, retornando \\nverdadeiro\\n ou \\nfalso\\n.\\n É claro que “um número finito” nem sempre é o mesmo que “poucos”. Se \\nBC\\n e a contêm \\nn\\nsímbolos ao todo, então existem 2\\nn\\n modelos. Desse modo, a complexidade de tempo do algoritmo é\\nO\\n(2\\nn\\n). (A complexidade de espaço é somente \\nO\\n(\\nn\\n) porque a enumeração é feita em profundidade.)\\nMais adiante neste capítulo, veremos algoritmos que são muito mais eficientes na prática.\\nInfelizmente, a consequência lógica proposicional é co-NP-completa (ou seja, provavelmente não\\nmais fácil que NP-completa — veja o Apêndice A); assim, \\ntodo algoritmo de inferência conhecido\\npara lógica proposicional tem uma complexidade no pior caso que é exponencial em relação ao\\ntamanho da entrada\\n.\\n7.5 PROVA DE TEOREMAS PROPOSICIONAIS\\nAté agora, mostramos como determinar a consequência lógica por \\nverificação de modelos\\n:\\nenumerar modelos e mostrar que a sentença deve valer em todos os modelos. Nesta seção,\\nmostraremos como se pode determinar a consequência lógica através da \\nprova de teoremas\\n — com\\na aplicação direta de regras de inferência nas sentenças em nossa base de conhecimento para\\nconstruir uma prova da sentença desejada sem consultar os modelos. Se o número de modelos for', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 299}),\n",
       " Document(page_content='grande mas o comprimento da prova for curto, a demonstração do teorema pode ser mais eficiente do\\nque a verificação de modelos.\\nAntes de mergulhar nos detalhes dos algoritmos de prova de teoremas, vamos precisar de alguns\\nconceitos adicionais relacionados à consequência lógica.\\nO primeiro conceito é o de \\nequivalência lógica\\n: duas sentenças \\nα\\n e \\nβ\\n são logicamente equivalentes\\nse são verdadeiras no mesmo conjunto de modelos. Escrevemos isso como \\nα\\n ≡ \\nβ\\n. Por exemplo,\\npodemos mostrar facilmente (utilizando tabelas-verdade) que \\nP\\n \\n∧\\n \\nQ\\n e \\nQ\\n \\n∧\\n \\nP\\n são logicamente\\nequivalentes; outras equivalências são mostradas na \\nFigura 7.11\\n. Essas equivalências desempenham\\no mesmo papel em lógica que as identidades aritméticas desempenham na matemática comum. Uma\\ndefinição alternativa de equivalência é: duas sentenças quaisquer \\nα\\n e \\nβ\\n são equivalentes apenas se\\ncada uma delas for a consequência lógica da outra:\\n(\\nα\\n \\n∧\\n \\nβ\\n) ≡ (\\nβ\\n \\n∧\\n \\nα\\n) comutatividade de \\n∧\\n(\\nα\\n \\n∨\\n \\nβ\\n) ≡ (\\nβ\\n \\n∨\\n \\nα\\n) comutatividade de \\n∨\\n((\\nα\\n \\n∧\\n \\nβ\\n) \\n∧\\n \\nγ\\n) ≡ (\\nα\\n \\n∧\\n (\\nβ\\n \\n∧\\n \\nγ\\n)) associatividade de \\n∧\\n((\\nα\\n \\n∨\\n \\nβ\\n) \\n∨\\n \\nγ\\n) ≡ (\\nα\\n \\n∨\\n (\\nβ\\n \\n∨\\n \\nγ\\n)) associatividade de \\n∨\\n¬(¬\\nα\\n) ≡ \\nα\\n eliminação da dupla negação\\n(\\nα\\n \\n⇒\\n \\nβ\\n) ≡ (¬\\nβ\\n \\n⇒\\n ¬\\nα\\n) contraposição\\n(\\nα\\n \\n⇒\\n \\nβ\\n) ≡ (¬\\nα\\n \\n∨\\n \\nβ\\n) eliminação da implicação\\n(\\nα\\n \\n⇔\\n \\nβ\\n) ≡ ((\\nα\\n \\n⇒\\n \\nβ\\n) \\n∧\\n (\\nβ\\n \\n⇒\\n \\nα\\n)) eliminação da bicondicional\\n¬(\\nα\\n \\n∧\\n \\nβ\\n) ≡ (¬\\nα\\n \\n∨\\n ¬\\nβ\\n) De Morgan\\n¬(\\nα\\n \\n∨\\n \\nβ\\n) ≡ (¬\\nα\\n \\n∧\\n ¬\\nβ\\n) De Morgan\\n(\\nα\\n \\n∧\\n (\\nβ\\n \\n∨\\n \\nγ\\n)) ≡ ((\\nα\\n \\n∧\\n \\nβ\\n) \\n∨\\n (\\nα\\n \\n∧\\n \\nγ\\n)) distribuição de \\n∧\\n sobre \\n∨\\n(\\nα\\n \\n∨\\n (\\nβ\\n \\n∧\\n \\nγ\\n)) ≡ ((\\nα\\n \\n∨\\n \\nβ\\n) \\n∧\\n (\\nα\\n \\n∨\\n \\nγ\\n)) distribuição de \\n∨\\n sobre \\n∧\\nFigura 7.11\\n Equivalências lógicas comuns. Os símbolos \\nα\\n, \\nβ\\n e \\nγ\\n representam sentenças arbitrárias de\\nlógica proposicional.\\nα\\n ≡ \\nβ\\n, se e somente se \\nα\\n |= \\nβ\\n e \\nβ\\n |= \\nα\\n.\\nO segundo conceito de que precisaremos é o de \\nvalidade\\n. Uma sentença é válida se é verdadeira\\nem \\ntodos\\n os modelos. Por exemplo, a sentença \\nP\\n \\n∨\\n¬\\nP\\n é válida. As sentenças válidas também são\\nconhecidas como \\ntautologias\\n — elas são \\nnecessariamente\\n verdadeiras. Como a sentença\\nVerdadeiro\\n é verdadeira em todos os modelos, toda sentença válida é logicamente equivalente a\\nVerdadeiro\\n.\\nQual é a utilidade das sentenças válidas? De nossa definição de consequência lógica, podemos\\nderivar o \\nteorema da dedução\\n, conhecido pelos gregos antigos:\\n \\n(O Exercício 7.5 lhe pede uma prova.) Assim, podemos decidir se \\nα\\n |= \\nβ\\n verificando que (\\nα\\n \\n⇒\\n \\nβ\\n) é\\nverdadeiro em cada modelo — o que é essencialmente o que o algoritmo de inferência na \\nFigura 7.10', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 300}),\n",
       " Document(page_content='faz — ou provando que (\\nα\\n \\n⇒\\n \\nβ\\n) equivale a \\nVerdadeiro\\n. Por outro lado, o teorema da dedução\\ndetermina que toda sentença de implicação válida descreve uma inferência legítima.\\nO último conceito de que precisaremos é o de \\nsatisfatibilidade\\n. Uma sentença é satisfatível se for\\nverdadeira em ou satisfeita por \\nalgum\\n modelo. Por exemplo, a base de conhecimento dada\\nanteriormente, (\\nR\\n1\\n \\n∧\\n \\nR\\n2\\n \\n∧\\n \\nR\\n3\\n \\n∧\\n \\nR\\n4\\n \\n∧\\n \\nR\\n5\\n), é satisfatível porque existem três modelos em que ela é\\nverdadeira, como mostra a \\nFigura 7.9\\n. A satisfatibilidade pode ser verificada enumerando-se os\\nmodelos possíveis até ser encontrado um modelo que satisfaça a sentença. O problema de determinar\\na satisfatibilidade de sentenças em lógica proposicional — o problema \\nSAT\\n — foi o primeiro\\nproblema que se comprovou ser NP-completo. Muitos problemas em ciência da computação na\\nverdade são problemas de satisfatibilidade. Por exemplo, todos os problemas de satisfação de\\nrestrições do Capítulo 6 estão essencialmente perguntando se as restrições são satisfatíveis por\\nalguma atribuição.\\nÉ claro que a validade e a satisfatibilidade estão interconectadas: \\nα\\n é válida se e somente se ¬a\\nnão é satisfatível; em contraposição, a é satisfatível se e somente se ¬a não é válida. Também temos\\no seguinte resultado útil:\\n \\nProvar \\nβ\\n a partir de \\nα\\n pela verificação da não satisfatibilidade de (\\nα\\n \\n∧\\n ¬\\nβ\\n) corresponde\\nexatamente à técnica-padrão de prova matemática de \\nreductio ad absurdum\\n (literalmente, “redução\\nao absurdo”). Ela também é chamada prova por \\nrefutação\\n ou prova por \\ncontradição\\n. Supõe-se que\\numa sentença \\nβ\\n seja falsa e se demonstra que ela leva a uma contradição com axiomas conhecidos \\nα\\n.\\nEssa contradição é exatamente o que se quer dizer quando se afirma que a sentença (\\nα\\n \\n∧\\n ¬\\nβ\\n) é não\\nsatisfatível.\\n7.5.1 Inferência e provas\\nEsta seção abrange \\nregras de inferência\\n que podem ser aplicadas para derivar uma \\nprova —\\n uma\\ncadeia de conclusões que conduzem ao objetivo desejado. A regra mais conhecida é chamada \\nModus\\nPonens\\n (do Latim \\nmodo que afirma\\n) e é escrita desta forma:\\nA notação significa que, sempre que quaisquer sentenças da forma \\nα\\n \\n⇒\\n \\nβ\\n e \\nα\\n são dadas, a sentença\\nβ\\n pode ser deduzida. Por exemplo, se (\\nWumpusAdiante\\n \\n∧\\n \\nWumpusVivo\\n)) \\n⇒\\n \\nAtirar\\n e\\n(\\nWumpusAdiante\\n \\n∧\\n \\nWumpusVivo\\n) são dadas, \\nAtirar\\n pode ser deduzida.\\nOutra regra de inferência útil é \\nEliminação do E\\n; a regra que afirma que, a partir de uma\\nconjunção, qualquer um dos elementos da conjunção pode ser deduzido:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 301}),\n",
       " Document(page_content='Por exemplo, a partir de (\\nWumpusAdiante\\n \\n∧\\n \\nWumpusVivo\\n), \\nWumpusVivo\\n pode ser deduzido.\\nConsiderando os valores-verdade possíveis de \\nα\\n e \\nβ\\n, pode-se mostrar facilmente que \\nModus\\nPonens\\n e Eliminação do E são corretas de uma vez por todas. Essas regras podem então ser usadas\\nem quaisquer instâncias específicas a que se apliquem, gerando inferências corretas sem a\\nnecessidade de enumeração de modelos.\\nTodas as equivalências lógicas da \\nFigura 7.11\\n podem ser usadas como regras de inferência. Por\\nexemplo, a equivalência para a eliminação de bicondicional gera as duas regras de inferência:\\nNem todas as regras de inferência funcionam em ambos os sentidos como essa. Por exemplo, não\\npodemos executar \\nModus Ponens\\n no sentido oposto para obter \\nα\\n \\n⇒\\n \\nβ\\n e \\nα\\n a partir de \\nβ\\n.\\nVejamos como essas regras de inferência e equivalências podem ser usadas no mundo de wumpus.\\nComeçamos com a base de conhecimento contendo \\nR\\n1\\n a \\nR\\n5\\n e mostramos como provar ¬\\nP\\n1,2\\n, isto é,\\nnão existe nenhum poço em [1,2]. Primeiro, aplicamos a eliminação de bicondicional a \\nR\\n2\\n para\\nobter:\\nEm seguida, aplicamos a Eliminação do E a \\nR\\n6\\n para obter:\\nA equivalência lógica para contraposição fornece:\\nAgora, podemos aplicar \\nModus Ponens\\n com \\nR\\n8\\n e a percepção \\nR\\n4\\n (isto é, ¬\\nB\\n1,1\\n), para obter:\\nFinalmente, aplicamos a regra de De Morgan, gerando a conclusão:\\nOu seja, nem [1,2] nem [2,1] contêm um poço.\\nEncontramos essa prova manualmente, mas podemos aplicar qualquer um dos algoritmos de busca\\ndo Capítulo 3 para encontrar uma sequência de passos que constitui uma prova. Nós apenas\\nprecisamos definir um problema de prova da seguinte forma:\\n•  ESTADO INICIAL: a base de conhecimento inicial.\\n•  AÇÕES: o conjunto de ações consiste em todas as regras de inferência aplicadas a todas as\\nsentenças que correspondam à metade superior da regra de inferência.\\n•  RESULTADO: o resultado de uma ação é acrescentar a sentença na metade inferior da regra de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 302}),\n",
       " Document(page_content='inferência.\\n•  OBJETIVO: o objetivo é um estado que contém a sentença que estamos tentando provar.\\n Assim, a busca de provas é uma alternativa para a enumeração de modelos. Porém, em muitos\\ncasos práticos, \\nencontrar uma prova pode ser mais eficiente porque a prova pode ignorar\\nproposições irrelevantes\\n, \\nindependentemente de quantas dessas proposições existem\\n. Por exemplo,\\na prova dada anteriormente que leva a ¬\\nP\\n1,2\\n \\n∧\\n ¬\\nP\\n2,1\\n não menciona as proposições \\nB\\n2,1\\n, \\nP\\n1,1\\n, \\nP\\n2,2\\n ou\\nP\\n3,1\\n. Elas podem ser ignoradas porque a proposição objetivo \\nP\\n1,2\\n só aparece na sentença \\nR\\n2\\n; as\\noutras proposições em \\nR\\n2\\n só aparecem em \\nR\\n4\\n e em \\nR\\n2\\n; assim, \\nR\\n1\\n, \\nR\\n3\\n e \\nR\\n5\\n não têm nenhuma influência\\nsobre a prova. O mesmo seria válido ainda que acrescentássemos mais um milhão de sentenças à\\nbase de conhecimento; por outro lado, o algoritmo simples de tabela-verdade seria subjugado pela\\nexplosão exponencial de modelos.\\nUma propriedade final de sistemas lógicos é a \\nmonotonicidade\\n, que afirma que o conjunto de\\nconsequências lógicas permitidas só pode \\naumentar\\n à medida que as informações são acrescentadas\\nà base de conhecimento.\\n8\\n Para quaisquer sentenças \\nα\\n e \\nβ\\n,\\nPor exemplo, suponha que a base de conhecimento contenha a asserção adicional \\nβ\\n afirmando que\\nexistem exatamente oito poços no mundo. Esse conhecimento poderia ajudar o agente a tirar\\nconclusões \\nadicionais\\n, mas não pode invalidar qualquer conclusão \\nα\\n já deduzida — como a\\nconclusão de que não existe nenhum poço em [1,2]. A monotonicidade significa que as regras de\\ninferência podem ser aplicadas sempre que são encontradas premissas adequadas na base de\\nconhecimento — a conclusão da regra deve se seguir \\nindependentemente de outras informações\\nexistentes na base de conhecimento\\n.\\n7.5.2 Prova por resolução\\nAfirmamos que as regras de inferência focalizadas até agora são \\ncorretas\\n, mas não discutimos a\\nquestão de \\ncompletude\\n para os algoritmos de inferência que as utilizam. Os algoritmos de busca\\ncomo a busca por aprofundamento iterativo são completos no sentido de que encontrarão qualquer\\nobjetivo acessível; porém, se as regras de inferência disponíveis forem inadequadas, a meta não será\\nacessível — não existirá nenhuma prova que utilize apenas essas regras de inferência. Por exemplo,\\nse removêssemos a regra de eliminação de bicondicional, a prova apresentada na seção anterior não\\nseria possível. A seção corrente introduz uma regra de inferência única, a \\nresolução\\n, que gera um\\nalgoritmo de inferência completo quando acoplada a qualquer algoritmo de busca completo.\\nComeçaremos usando uma versão simples da regra de resolução no mundo de wumpus. Vamos\\nconsiderar as etapas que conduzem à \\nFigura 7.4\\n(a): o agente retorna de [2,1] para [1,1] e vai para\\n[1,2], onde percebe um fedor, mas nenhuma brisa. Adicionamos os fatos a seguir à base de\\nconhecimento:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 303}),\n",
       " Document(page_content='Pelo mesmo processo que levou a \\nR\\n10 anteriormente, agora podemos derivar a ausência de poços\\nem [2,2] e [1,3] (lembre-se de que já sabemos que [1,1] não tem poços):\\nTambém podemos aplicar a eliminação de bicondicional a \\nR\\n3\\n, seguida por \\nModus Ponens\\n com \\nR\\n5\\n,\\na fim de obter o fato de que existe um poço em [1,1], [2,2] ou [3,1]:\\nAgora, vem a primeira aplicação da regra de resolução: o literal ¬\\nP\\n2,2\\n em \\nR\\n13\\n \\nse resolve com\\n o\\nliteral \\nP\\n2,2\\n em \\nR\\n15\\n para fornecer o \\nresolvente\\n:\\nEm linguagem comum: se existe um poço em [1,1], [2,2] ou [3,1] e não existe poço em [2,2], então\\nele está em [1,1] ou [3,1]. De modo semelhante, o literal ¬\\nP\\n1,1\\n em \\nR\\n1\\n se resolve com o literal \\nP\\n1,1\\n em\\nR\\n16\\n para gerar:\\nEm linguagem comum: se existe um poço em [1,1] ou [3,1] e ele não está em [1,1], então está em\\n[3,1]. Essas duas últimas etapas de inferência são exemplos da regra de inferência de \\nresolução\\nunitária\\n,\\nonde cada \\nl\\n é um literal, e onde \\nl\\ni\\n e \\nm\\n são \\nliterais complementares\\n (isto é, um é a negação do outro).\\nDesse modo, a regra de resolução unitária toma uma \\ncláusula\\n — uma disjunção de literais — e um\\nliteral, e produz uma nova cláusula. Observe que um único literal pode ser visto como uma disjunção\\nde um único literal, também conhecida como \\ncláusula unitária\\n.\\nA regra de \\nresolução\\n unitária pode ser generalizada para a regra de \\nresolução\\n completa,\\nonde \\nl\\ni\\n e \\nm\\nj\\n são literais complementares. Isso quer dizer que a resolução recebe duas cláusulas e\\nproduz uma nova cláusula contendo todos os literais das duas cláusulas originais, \\nexceto\\n os dois\\nliterais complementares. Por exemplo, temos:\\nExiste ainda outro aspecto técnico da regra de resolução: a cláusula resultante deve conter apenas\\numa cópia de cada literal.\\n9\\n A remoção de várias cópias de literais é chamada \\nfatoração\\n. Por', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 304}),\n",
       " Document(page_content='exemplo, se resolvermos (\\nA\\n \\n∨\\n \\nB\\n) com (\\nA\\n \\n∨\\n ¬\\nB\\n), obteremos (\\nA\\n \\n∨\\n \\nA\\n), que será reduzido\\nsimplesmente a \\nA\\n.\\nA \\ncorreção\\n da regra de resolução pode ser vista facilmente considerando-se o literal \\nl\\ni\\n que é\\ncomplementar à literal m\\nj\\n na outra cláusula. Se \\nl\\ni\\n é verdadeiro, então \\nm\\nj\\n é falso e, consequentemente,\\nm\\n1\\n \\n∨\\n … \\n∨\\n \\nm\\nj–1\\n \\n∨\\n \\nm\\nj+1\\n \\n∨\\n … \\n∨\\n \\nm\\nn\\n tem de ser verdadeira, porque \\nm\\n1\\n \\n∨\\n … \\n∨\\n \\nm\\nn\\n é dada. Se \\nl\\ni\\n é\\nfalso, então \\nl\\n1\\n \\n∨\\n … \\n∨\\n \\nl\\nj–1\\n \\n∨\\n \\nl\\ni+1\\n \\n∨\\n … \\n∨\\n \\nl\\nk\\n deve ser verdadeira porque \\nl\\ni\\n \\n∨\\n … \\n∨\\n \\nl\\nk\\n é dada.\\nAgora, \\nl\\ni\\n é verdadeiro ou falso, e então uma ou outra dessas conclusões é válida — exatamente como\\nestabelece a regra de resolução.\\n O fato mais surpreendente sobre a regra de resolução é que ela forma a base para uma família\\nde procedimentos de inferência \\ncompletos\\n. \\nUm demonstrador de teoremas baseado em resolução\\npode, para quaisquer sentenças\\n \\nα\\n \\ne\\n \\nβ\\n \\nem lógica proposicional, decidir se\\n \\nα\\n \\n|=\\n \\nβ\\n.\\n As duas\\nsubseções a seguir explicam como a resolução consegue isso.\\nForma normal conjuntiva\\n A regra de resolução se aplica apenas às cláusulas (isto é, às disjunções de literais); assim, ela\\naparentemente só seria relevante para bases de conhecimento e consultas que consistissem em tais\\ndisjunções. Então, como ela pode levar a um procedimento de inferência completo para toda a lógica\\nproposicional? A resposta é que \\ntoda sentença da lógica proposicional é logicamente equivalente\\na uma conjunção de cláusulas\\n. Dizemos que uma sentença expressa como uma conjunção de\\ncláusulas está em \\nforma normal conjuntiva\\n ou \\nFNC\\n (veja a \\nFigura 7.14\\n). Descreveremos agora um\\nprocedimento para converter para FNC.\\nIlustraremos o procedimento convertendo a sentença \\nB\\n1,1\\n \\n⇔\\n (\\nP\\n1,2\\n \\n∨\\n \\nP\\n2,1\\n) para FNC. As etapas\\nsão:\\n1. Eliminar \\n⇔\\n, substituindo \\nα\\n \\n⇔\\n \\nβ\\n por (\\nα\\n \\n⇒\\n \\nβ\\n) \\n∧\\n (\\nβ\\n \\n⇒\\n \\nα\\n):\\n2. Eliminar \\n⇒\\n, substituindo \\nα\\n \\n⇒\\n \\nβ\\n por ¬\\nα\\n \\n∨\\n \\nβ\\n:\\n3. A FNC exige que ¬ apareça apenas em literais; portanto, “movemos ¬ para dentro” pela\\naplicação repetida das seguintes equivalências da \\nFigura 7.11\\n:\\nNo exemplo, necessitamos apenas de uma aplicação da última regra:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 305}),\n",
       " Document(page_content='4. Agora, temos uma sentença que contém operadores \\n∧\\n e \\n∨\\n aninhados, aplicados a literais.\\nAplicamos a lei de distributividade da \\nFigura 7.11\\n, distribuindo \\n∨\\n sobre \\n∧\\n sempre que\\npossível.\\nAgora, a sentença original está em FNC, como uma conjunção de três cláusulas. É muito mais\\ndifícil ler essa sentença, mas ela pode ser usada como entrada para um procedimento de resolução.\\nUm algoritmo de resolução\\nOs procedimentos de inferência baseados na resolução funcionam pela utilização do princípio de\\nprova por contradição introduzido na pág. 218. Isto é, para mostrar que \\nBC |=\\n \\nα\\n mostramos que (\\nBC\\n∧\\n ¬\\nα\\n) é não satisfatível. Fazemos isso provando uma contradição.\\nUm algoritmo de resolução é mostrado na \\nFigura 7.12\\n. Primeiro, (\\nBC\\n \\n∧\\n ¬\\nα\\n) é convertido em\\nFNC. Em seguida, a regra de resolução é aplicada às cláusulas resultantes. Cada par que contém\\nliterais complementares é resolvido para gerar uma nova cláusula, que é adicionada ao conjunto se\\nainda não estiver presente. O processo continua até acontecer um destes dois fatos:\\nfunção\\n RESOLUÇÃO-LP(\\nBC\\n, a) \\nretorna\\n \\nverdadeiro\\n ou \\nfalso\\n    \\nentradas\\n: \\nBC\\n, a base de conhecimento, uma sentença em lógica proposicional\\na, a consulta, uma sentença em lógica proposicional\\n    \\n    \\ncláusulas\\n ← o conjunto de cláusulas na representação de FNC de \\nBC\\n \\n∧\\n ¬a\\n    \\nnovas\\n ← { }\\n    \\nrepita\\n        \\npara cada\\n par de cláusulas \\nC\\ni\\n, \\nC\\nj\\n \\nem\\n \\ncláusulas\\n \\nfaça\\n            \\nresolventes\\n ← RESOLVER-LP(\\nC\\ni\\n, \\nC\\nj\\n)\\n            \\nse\\n \\nresolventes\\n contém a cláusula vazia \\nentão retornar\\n \\nverdadeiro\\n            \\nnovas\\n ← \\nnovas\\n \\n∪\\n \\nresolventes\\n        \\nse\\n \\nnovas\\n \\n⊆\\n \\ncláusulas\\n \\nentão retornar\\n \\nfalso\\n        \\ncláusulas\\n ← \\ncláusulas\\n \\n∪\\n \\nnovas\\nFigura 7.12\\n Um algoritmo de resolução simples para lógica proposicional. A função RESOLVER-LP\\nretorna o conjunto de todas as cláusulas possíveis obtidas pela resolução de suas duas entradas.\\n•  não há nenhuma cláusula nova que possa ser adicionada, nesse caso BC não tem a como\\nconsequência lógica; ou,\\n•  duas cláusulas resolvem produzindo uma cláusula \\nvazia\\n, nesse caso BC tem como consequência\\nlógica a.\\nA cláusula vazia — uma disjunção de nenhum disjunto — é equivalente a \\nFalso\\n porque uma\\ndisjunção só é verdadeira se pelo menos um de seus disjuntos é verdadeiro. Outra maneira de ver\\nque uma cláusula vazia representa uma contradição é observar que ela só surge da solução de duas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 306}),\n",
       " Document(page_content='cláusulas unitárias complementares como \\nP\\n e ¬\\nP\\n.\\nPodemos aplicar o procedimento de resolução a uma inferência muito simples no mundo de\\nwumpus. Quando o agente está em [1,1], não existe nenhuma brisa e, assim, não pode haver poços em\\nquadrados vizinhos. A base de conhecimento relevante é:\\ne desejamos provar a que é, digamos, ¬\\nP\\n1,2\\n. Quando convertermos (\\nBC\\n \\n∧\\n ¬a) em FNC, obteremos\\nas cláusulas mostradas na parte superior da \\nFigura 7.13\\n. A segunda linha da figura mostra todas as\\ncláusulas obtidas pela resolução de pares na primeira linha. Então, quando \\nP\\n1,2\\n é resolvida com\\n¬\\nP\\n1,2\\n, obtemos a cláusula vazia, mostrada como um quadrado pequeno. A inspeção da \\nFigura 7.13\\nrevela que muitas etapas de resolução não têm sentido. Por exemplo, a cláusula \\nB\\n1,1\\n∨\\n¬\\nB\\n1,1\\n∨\\nP\\n1,2\\n é\\nequivalente a \\nVerdadeiro\\n \\n∨\\n \\nP\\n1,2\\n, que é equivalente a \\nVerdadeiro\\n. A dedução de que \\nVerdadeiro\\n é\\nverdadeira não é muito útil. Portanto, qualquer cláusula em que aparecem dois literais\\ncomplementares pode ser descartada.\\nFigura 7.13\\n Aplicação parcial de RESOLUÇÃO-LP a uma inferência simples no mundo de wumpus.\\nDemonstra-se que ¬\\nP\\n1,2\\n segue das quatro primeiras cláusulas da linha superior.\\nSentença FNC\\n → \\nCláusula\\n1\\n \\n∧\\n· · · \\n∧\\n \\nCláusula\\nn\\nCláusula\\n → \\nLiteral\\n1\\n \\n∨\\n· · · \\n∨\\n \\nLiteral\\nm\\nLiteral\\n → \\nSímbolo\\n | ¬\\nSímbolo\\nSímbolo\\n → \\nP\\n | \\nQ\\n | \\nR\\n | . . .\\nFormaCláusulaHorn\\n → \\nFormaCláusulaDefinida |\\n \\nFormaCláusulaObjetivo\\nFormaCláusulaDefinida\\n → (\\nSímbolo\\n1\\n \\n∧\\n· · · \\n∧\\n \\nSímbolo\\ne\\n) \\n⇒\\n \\nSímbolo\\nFormaCláusulaObjetivo\\n → (\\nSímbolo\\n1\\n \\n∧\\n· · · \\n∧\\n \\nSímbolo\\ne\\n) \\n⇒\\n \\nFalso\\nFigura 7.14\\n Uma gramática para a forma normal conjuntiva, cláusulas de Horn e cláusulas definidas.\\nUma cláusula tal como \\nA\\n \\n∧\\n \\nB\\n => \\nC\\n ainda é uma cláusula definida quando é escrita como ¬ A \\n∨\\n ¬ B\\n∨\\n C, mas apenas a anterior é considerada a forma canônica para as cláusulas definidas. Uma outra\\nclasse é a sentença \\nk\\n-FNC, que é uma sentença de FNC, onde cada cláusula tem no máximo \\nk\\n literais.\\nCompletude de resolução\\nPara concluir nossa discussão da resolução, mostraremos agora por que RESOLUÇÃO-LP é\\ncompleta. Para isso, introduziremos o \\nfecho por resolução\\n \\nFR\\n(\\nS\\n) de um conjunto de cláusulas \\nS\\n, que\\né o conjunto de todas as cláusulas deriváveis pela aplicação repetida da regra de resolução a\\ncláusulas em \\nS\\n ou suas derivadas. O fecho por resolução é o que RESOLUÇÃO-LP calcula como', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 307}),\n",
       " Document(page_content='valor final da variável \\ncláusulas\\n. É fácil ver que \\nFR\\n(\\nS\\n) deve ser finito porque existe apenas um\\nnúmero finito de cláusulas distintas que podem ser construídas a partir dos símbolos \\nP\\n1\\n, …, \\nP\\nk\\n que\\naparecem em \\nS\\n (note que isso não seria verdadeiro sem a etapa de fatoração que remove várias\\ncópias de literais). Consequentemente, RESOLUÇÃO-LP sempre termina.\\nO teorema da completude da resolução em lógica proposicional é chamado \\nteorema básico da\\nresolução\\n:\\nSe um conjunto de cláusulas é não satisfatível, então o fecho por resolução dessas cláusulas\\ncontém a cláusula vazia.\\nProvamos esse teorema demonstrando sua contrapositiva: se o fecho \\nFR\\n(\\nS\\n) \\nnão\\n contém a cláusula\\nvazia, então \\nS\\n é satisfatível. De fato, podemos construir um modelo para \\nS\\n com valores-verdade\\nadequados para \\nP\\n1\\n,…, \\nP\\nk\\n. O procedimento de construção é:\\nPara \\ni\\n de 1 a \\nk\\n,\\n–  Se existe uma cláusula em \\nFR\\n(\\nS\\n) contendo o literal ¬\\nP\\ni\\n e todos os seus outros literais são\\nfalsos sob a atribuição escolhida para \\nP\\n1\\n, …, \\nP\\ni\\n-1\\n, então atribua \\nfalso\\n a \\nP\\ni\\n.\\n–  Caso contrário, atribua \\nverdadeiro\\n a \\nP\\ni\\n.\\nEssa atribuição para \\nP\\n1\\n,…, \\nP\\nk\\n é um modelo de \\nS\\n. Para verificar isso, assuma o oposto — que, em\\nalgum estágio \\ni\\n na sequência, atribuir o símbolo P\\ni\\n faz com que alguma cláusula \\nC\\n torne-se falsa. Para\\nque isso aconteça, todos os \\noutros\\n literais em \\nC\\n já devem ter sido falsificados por atribuições a P\\n1\\n,\\n…, P\\ni-1\\n. Assim, \\nC\\n deve agora parecer como (\\nfalso\\n \\n∨\\n \\nfalso\\n \\n∨\\n… \\nfalso\\n \\n∨\\n P\\ni\\n) ou como (\\nfalso\\n \\n∨\\n \\nfalso\\n∨\\n… \\nfalso\\n \\n∨\\n¬ P\\ni\\n). Se houver apenas um desses dois em FR(\\nS\\n), o algoritmo irá atribuir o valor-\\nverdade adequado para P\\ni\\n tornar \\nC\\n verdadeiro, assim \\nC\\n só poderá ser falsificado se \\nambas\\n as\\ncláusulas estiverem em FR(\\nS\\n). Agora, uma vez que FR(\\nS\\n) é fechado sob resolução, vai conter o\\nresolvente dessas duas cláusulas, e esse resolvente já terá todos os seus literais falsificados pelas\\natribuições a P\\n1\\n,…, P\\ni-1\\n. Isso contradiz a nossa hipótese de que a primeira cláusula falsificada\\naparece no estágio \\ni\\n. Assim, provamos que a construção nunca falsifica uma cláusula em FR(\\nS\\n), ou\\nseja, ela produz um modelo de FR(\\nS\\n) e, assim, um modelo de \\nS\\n em si (já que \\nS\\n está contido em\\nFR(\\nS\\n)).\\n7.5.3 Cláusulas de Horn e cláusulas definidas\\nA completude da resolução a torna um método de inferência muito importante. Em muitas situações\\npráticas, no entanto, o pleno poder de resolução não é necessário. Algumas bases de conhecimento\\ndo mundo real satisfazem certas restrições sobre a forma de sentenças que elas contêm, que permite\\nque elas utilizem um algoritmo de inferência mais restrito e eficiente.\\nUma destas formas restritas é a \\ncláusula definida\\n, que é uma disjunção de literais dos quais\\nexatamente um é positivo\\n. Por exemplo, a cláusula (¬ \\nL\\n1, 1\\n \\n∨\\n¬ \\nBrisa\\n, \\n∨\\n \\nB\\n1,1\\n) é uma cláusula', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 308}),\n",
       " Document(page_content='definida, enquanto (¬ \\nB\\n1, 1\\n \\n∨\\n \\nP\\n1, 2\\n \\n∨\\n \\nP\\n2, 1\\n) não é.\\nA \\ncláusula de Horn\\n é ligeiramente mais geral, uma disjunção de literais \\ndos quais pelo menos um\\né positivo\\n. Assim, todas as cláusulas definidas são cláusulas de Horn, como existem cláusulas sem\\nliteral positivo, que são chamadas cláusulas objetivo. As cláusulas de Horn são fechadas sob\\nresolução: se você resolver duas cláusulas de Horn, receberá de volta uma cláusula de Horn.\\nAs bases de conhecimento que contém apenas cláusulas definidas são interessantes por três razões:\\n1. Toda cláusula definida pode ser escrita como uma implicação cuja premissa é uma conjunção\\nde literais positivos e cuja conclusão é um único literal positivo (veja o Exercício 7.13). Por\\nexemplo, a cláusula definida (¬ \\nL\\n1,1\\n \\n∨\\n ¬ \\nBrisa\\n \\n∨\\n \\nB\\n1,1\\n) pode ser escrita como implicação (\\nL\\n1,1\\n∧\\n \\nBrisa\\n) \\n⇒\\n \\nB\\n1,1\\n. Na forma de implicação, a sentença é mais fácil de entender: informa que, se\\no agente está em [1,1] e há uma brisa, então [1,1] está com brisa. Na forma de Horn, a premissa\\né chamada \\ncorpo\\n, e a conclusão, \\ncabeça\\n. Uma sentença que consiste em um único literal\\npositivo, como \\nL\\n1, 1\\n, é chamada de \\nfato\\n. Também pode ser escrita na forma de implicação como\\nVerdadeiro\\n \\n⇒\\n \\nL\\n1, 1\\n, mas é mais simples escrever apenas \\nL\\n1,1\\n.\\n2. A inferência com cláusulas de Horn pode ser feita através de algoritmos de \\nencadeamento\\npara a frente\\n e \\nencadeamento para trás\\n, que descreveremos a seguir. Ambos os algoritmos\\nsão naturais e, por isso, as etapas de inferência são óbvias e fáceis de os seres humanos\\nseguirem. Esse tipo de inferência é a base para a \\nprogramação lógica\\n, que será discutida no\\nCapítulo 9.\\n3. A decisão da consequência lógica com as cláusulas de Horn pode ser feita em tempo \\nlinear\\n no\\ntamanho da base do conhecimento — uma agradável surpresa.\\n7.5.4 Encadeamento para a frente e para trás\\nO algoritmo de encadeamento para a frente CONSEQUÊNCIA-LÓGICA-LP-EF?(\\nBC\\n, \\nθ\\n) determina\\nse um único símbolo proposicional \\nθ\\n — a consulta — é consequência de uma base de conhecimento\\nde cláusulas definidas. Ele começa a partir de fatos conhecidos (literais positivos) na base de\\nconhecimento. Se todas as premissas de uma implicação forem conhecidas, sua conclusão será\\nacrescentada ao conjunto de fatos conhecidos. Por exemplo, se \\nL\\n1,1\\n e \\nBrisa\\n são conhecidas e (\\nL\\n1,1\\n \\n∧\\nBrisa\\n) \\n⇒\\n \\nB\\n1,1\\n está na base de conhecimento, então \\nB\\n1,1\\n pode ser adicionada. Esse processo continua\\naté a consulta \\nθ\\n ser acrescentada ou até não ser possível fazer inferências adicionais. O algoritmo\\ndetalhado é mostrado na \\nFigura 7.15\\n; o principal ponto a lembrar é que ele funciona em tempo linear.\\nfunção\\n CONSEQUÊNCIA-LÓGICA-LP-EF? (\\nBC\\n, \\nq\\n) \\nretorna\\n \\nverdadeiro\\n ou \\nfalso\\n    \\nentradas:\\n \\nBC\\n, a base de conhecimento, um conjunto de cláusulas definidas proposicionais\\nq\\n, a consulta, um símbolo proposicional\\n    \\ncontagem\\n ← uma tabela, onde contagem [\\nc\\n] é o número de símbolos nas premissas de \\nc\\n    \\ninferido\\n ← uma tabela onde \\ninferido\\n [\\ns\\n] é \\nfalso\\n inicialmente para todos os símbolos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 309}),\n",
       " Document(page_content='agenda\\n ← uma lista de símbolos, inicialmente os símbolos reconhecidos como verdadeiros em\\nBC\\n    \\n    \\nenquanto\\n \\nagenda\\n não é vazia \\nfaça\\n        \\np\\n ← POP(\\nagenda\\n)\\n        \\nse\\n \\np\\n = \\nq\\n \\nentão retornar\\n \\nverdadeiro\\n        \\nse\\n \\ninferido\\n [\\np\\n] = \\nfalso\\n \\nentão\\n            \\ninferido\\n[\\np\\n] ← \\nverdadeiro\\n            \\npara cada\\n cláusula \\nc\\n em \\nBC\\n onde \\np\\n está em \\nc.\\nPREMISSA \\nfaça\\n                decrementar \\ncontagem\\n[\\nc\\n]\\n                \\nse\\n \\ncontagem\\n[\\nc\\n] = 0 \\nentão\\n adicione \\nc.\\nCONCLUSÃO para \\nagenda\\n    \\nretornar\\n \\nfalso\\nFigura 7.15\\n Algoritmo de encadeamento para a frente para lógica proposicional. A \\nagenda\\n controla\\nos símbolos reconhecidos como verdadeiros, mas ainda “não processados”. A tabela \\ncontagem\\ncontrola a quantidade de premissas de cada implicação que ainda são desconhecidas. Sempre que um\\nnovo símbolo \\np\\n da agenda for processado, a contagem será reduzida em uma unidade para cada\\nimplicação em cuja premissa \\np\\n aparece (facilmente identificadas em tempo constante com indexação\\napropriada). Se a contagem chegar a zero, isso significa que todas as premissas da implicação são\\nconhecidas e, assim, sua conclusão pode ser acrescentada à agenda. Finalmente, precisamos\\ncontrolar quais símbolos foram processados; um símbolo que já está no conjunto de símbolos\\ndeduzidos não precisa ser adicionado à agenda novamente. Isso evita trabalho redundante e também\\nprevine repetições infinitas que poderiam ser causadas por implicações como \\nP\\n \\n⇒\\n \\nQ\\n e \\nQ\\n \\n⇒\\n \\nP\\n.\\nO melhor caminho para entender o algoritmo é usar um exemplo e uma figura. A \\nFigura 7.16\\n(a)\\nmostra uma base de conhecimento simples de cláusulas de Horn com \\nA\\n e \\nB\\n como fatos conhecidos. A\\nFigura 7.16\\n(b) mostra a mesma base de conhecimento desenhada como um \\ngrafo E-OU\\n (veja o\\nCapítulo 4). Em grafos E-OU, múltiplas arestas unidas por um arco indicam uma conjunção — toda\\naresta deve ser provada — enquanto múltiplas arestas sem arco indicam uma disjunção — qualquer\\naresta pode ser provada. É fácil ver como o encadeamento para a frente funciona no grafo. As folhas\\nconhecidas (aqui, \\nA\\n e \\nB\\n) são definidas, e a inferência se propaga para cima no grafo, o mais longe\\npossível. Onde quer que apareça uma conjunção, a propagação espera até todos os conjuntos serem\\nconhecidos antes de prosseguir. O leitor deve examinar o exemplo em detalhes.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 310}),\n",
       " Document(page_content='Figura 7.16\\n (a) Um conjunto de cláusulas de Horn. (b) Grafo E-OU correspondente.\\n É fácil ver que o encadeamento para a frente é \\ncorreto\\n: toda inferência é em essência uma\\naplicação de \\nModus Ponens.\\n O encadeamento para a frente também é \\ncompleto\\n: toda sentença\\natômica permitida será derivada. O modo mais fácil de verificar isso é considerar o estado final da\\ntabela \\ninferida\\n (depois que o algoritmo alcança um \\nponto fixo\\n em que nenhuma nova inferência é\\npossível). A tabela contém \\nverdadeiro\\n para cada símbolo inferido durante o processo e \\nfalso\\n para\\ntodos os outros símbolos. Podemos visualizar a tabela como um modelo lógico; além disso, \\ntoda\\ncláusula definida na BC original é verdadeira nesse modelo\\n. Para verificar isso, suponha a\\nafirmação oposta, ou seja, que alguma cláusula \\na\\n1\\n \\n∧\\n … \\n∧\\n \\na\\nk\\n \\n⇒\\n \\nb\\n seja falsa no modelo. Então, \\na\\n1\\n∧\\n … \\n∧\\n \\na\\nk\\n deve ser verdadeira no modelo e \\nb\\n dever ser falsa no modelo. Porém, isso contradiz\\nnossa suposição de que o algoritmo alcançou um ponto fixo! Podemos concluir então que o conjunto\\nde sentenças atômicas deduzidas no ponto fixo define um modelo da BC original. Mais ainda,\\nqualquer sentença atômica \\nθ\\n que é consequência lógica da \\nBC\\n deve ser deduzida pelo algoritmo.\\nO encadeamento para a frente é um exemplo do conceito geral de raciocínio \\norientado a dados\\n —\\nisto é, o raciocínio em que o foco da atenção começa com os dados conhecidos. Ele pode ser usado\\nem um agente para derivar conclusões a partir de percepções de entrada, frequentemente sem uma\\nconsulta específica em mente. Por exemplo, o agente de wumpus poderia informar (com TELL) suas\\npercepções à base de conhecimento, utilizando um algoritmo de encadeamento para a frente\\nincremental em que novos fatos pudessem ser adicionados à agenda para iniciar novas inferências.\\nEm seres humanos, certa quantidade de raciocínio orientado a dados ocorre à medida que chegam\\nnovas informações. Por exemplo, se estou em um ambiente fechado e ouço a chuva começando a cair,\\npode me ocorrer que o piquenique será cancelado. Ainda assim, provavelmente não me ocorrerá que\\na décima sétima pétala da maior rosa no jardim do meu vizinho ficará molhada; os seres humanos\\nmantêm o encadeamento para a frente sob cuidadoso controle, temendo ficar sobrecarregados com o\\nacúmulo de consequências irrelevantes.\\nO algoritmo de encadeamento para trás, como seu nome sugere, funciona no sentido inverso a\\npartir da consulta. Se a consulta \\nθ\\n é reconhecida como verdadeira, não é necessário nenhum trabalho.\\nCaso contrário, o algoritmo encontra as implicações na base de conhecimento cuja conclusão é \\nθ\\n. Se\\nfor possível demonstrar que todas as premissas de uma dessas implicações são verdadeiras (por', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 311}),\n",
       " Document(page_content='encadeamento para trás), então \\nθ\\n é verdadeira. Quando aplicado à consulta \\nQ\\n da \\nFigura 7.16\\n, ele\\npercorre o grafo no sentido inverso até alcançar um conjunto de fatos conhecidos que forme a base\\npara uma prova. O algoritmo é em essência idêntico ao algoritmo de BUSCA-EM-GRAFOS-E-OU\\nna \\nFigura 4.11\\n. Como ocorre no caso do encadeamento para a frente, uma implementação eficiente\\nfunciona em tempo linear.\\nO encadeamento para trás é uma forma de \\nraciocínio orientado por metas\\n. Ele é útil para\\nresponder a perguntas específicas como: “O que devo fazer agora?” e “Onde estão minhas chaves?”.\\nCom frequência, o custo do encadeamento para trás é \\nmuito menor\\n que um custo linear em relação ao\\ntamanho da base de conhecimento porque o processo só toca fatos relevantes.\\n7.6 VERIFICAÇÃO DE MODELOS PROPOSICIONAIS EFICIENTES\\nNesta seção, descrevemos duas famílias de algoritmos eficientes para inferência proposicional\\ngeral, baseados na verificação de modelos: uma abordagem baseada na busca com retrocesso e outra\\nna busca de subida de encosta local. Esses algoritmos fazem parte da “tecnologia” da lógica\\nproposicional. Você poderá preferir folhear rapidamente esta seção no caso de uma primeira leitura\\ndo capítulo.\\nOs algoritmos que descrevemos se destinam à verificação da satisfatibilidade: o problema SAT.\\n(Como anteriormente observado, o teste da consequência lógica \\nα\\n |= \\nβ\\n pode ser realizado testando a\\nnão satisfatibilidade da \\nα\\n \\n∧\\n ¬\\nβ\\n.) Já notamos a conexão entre a localização de um modelo\\nsatisfatório para uma sentença lógica e a descoberta de uma solução para um problema de satisfação\\nde restrições e, assim, talvez não seja surpresa o fato de as duas famílias de algoritmos se\\nassemelharem bastante aos algoritmos de retrocesso da \\nSeção 6.3\\n e aos algoritmos de busca local da\\nSeção 6.4\\n. Porém, eles são extremamente importante por si sós, porque muitos problemas\\ncombinatórios em ciência da computação podem ser reduzidos à verificação da satisfatibilidade de\\numa sentença proposicional. Qualquer melhoria em algoritmos de satisfatibilidade tem enormes\\nconsequências para nossa habilidade de tratar a complexidade em geral.\\n7.6.1 Um algoritmo com retrocesso completo\\nO primeiro algoritmo que examinaremos frequentemente é chamado \\nalgoritmo de Davis-Putnam\\n,\\ndevido ao importante artigo de Martin Davis e Hilary Putnam (1960). De fato, o algoritmo é a versão\\ndescrita por Davis, Logemann e Loveland (1962), e, por essa razão, vamos chamá-lo DPLL, um\\nacrônimo formado pelas iniciais dos quatro autores. O DPLL recebe como entrada uma sentença em\\nforma normal conjuntiva — um conjunto de cláusulas. Como BUSCA-COM-RETROCESSO e\\nCONSEQUÊNCIA-LÓGICA-TV?, ele é em essência uma enumeração recursiva em profundidade de\\nmodelos possíveis. Ele incorpora três melhorias em relação ao esquema simples de\\nCONSEQUÊNCIA-LÓGICA-TV?:\\n•  \\nTerminação prematura\\n: O algoritmo detecta se a sentença tem de ser verdadeira ou falsa,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 312}),\n",
       " Document(page_content='mesmo no caso de um modelo parcialmente concluído. Uma cláusula é verdadeira se \\nqualquer\\nliteral é verdadeiro, mesmo que os outros literais ainda não tenham valores-verdade;\\nconsequentemente, a sentença como um todo pode ser considerada verdadeira, mesmo antes de o\\nmodelo estar completo. Por exemplo, a sentença (\\nA\\n \\n∨\\n \\nB\\n) \\n∧\\n (\\nA\\n \\n∨\\n \\nC\\n) é verdadeira se \\nA\\n é\\nverdadeiro, independentemente dos valores de \\nB\\n e \\nC\\n. De modo semelhante, uma sentença é falsa\\nse \\nqualquer\\n cláusula é falsa, o que ocorre quando cada um de seu literais é falso. Mais uma vez,\\nisso pode ocorrer bem antes de o modelo estar completo. O término prematuro evita o exame de\\nsubárvores inteiras no espaço de busca.\\n•  \\nHeurística de símbolo puro\\n: Um \\nsímbolo puro\\n é um símbolo que sempre aparece com o mesmo\\n“sinal” em todas as cláusulas. Por exemplo, nas três cláusulas (\\nA\\n \\n∨\\n ¬\\nB\\n), (¬\\nB\\n \\n∨\\n ¬\\nC\\n) e (\\nC\\n \\n∨\\n \\nA\\n),\\no símbolo \\nA\\n é puro porque só aparece o literal positivo, \\nB\\n é puro porque só aparece o literal\\nnegativo e \\nC\\n é impuro. É fácil ver que, se uma sentença tem um modelo, ela tem um modelo com\\nos símbolos puros atribuídos de forma a tornar seus literais \\nverdadeiros\\n, porque isso nunca\\npoderá tornar uma cláusula falsa. Observe que, na determinação da pureza de um símbolo, o\\nalgoritmo pode ignorar cláusulas que já são reconhecidas como verdadeiras no modelo\\nconstruído até o momento. Por exemplo, se o modelo contém \\nB\\n = \\nfalso\\n, a cláusula (¬\\nB\\n \\n∨\\n ¬\\nC\\n) já\\né verdadeira, e nas cláusulas \\nC\\n restantes aparece apenas um literal positivo; por essa razão, \\nC\\ntorna-se puro.\\n•  \\nHeurística de cláusula unitária\\n: Uma \\ncláusula unitária\\n foi definida anteriormente como uma\\ncláusula com apenas um literal. No contexto de DPLL, essa expressão também significa cláusulas\\nem que todos os literais com exceção de um já têm o valor \\nfalso\\n atribuído pelo modelo. Por\\nexemplo, se o modelo contém \\nB\\n = \\nverdadeiro\\n, então (¬\\nB\\n \\n∨\\n ¬\\nC\\n) simplifica para ¬\\nC\\n, que é uma\\ncláusula unitária. É óbvio que, para que essa cláusula seja verdadeira, \\nC\\n deve ser definido como\\nfalso\\n. A heurística de cláusula unitária atribui todos esses símbolos antes de efetuar a\\nramificação sobre o restante. Uma consequência importante da heurística é que qualquer tentativa\\nde provar (por refutação) um literal que já está na base de conhecimento terá sucesso imediato\\n(Exercício 7.23). Note também que a atribuição de uma cláusula unitária pode criar outra\\ncláusula unitária — por exemplo, quando \\nC\\n é definido como \\nfalso\\n, (\\nC\\n \\n∨\\n \\nA\\n) se torna uma\\ncláusula unitária, fazendo com que o valor verdadeiro seja atribuído a \\nA\\n. Essa “cascata” de\\natribuições forçadas é chamada \\npropagação unitária\\n. Ela lembra o processo de encadeamento\\npara a frente com cláusulas definidas e, na realidade, se a expressão em FNC contém apenas\\ncláusulas definidas, DPLL essencialmente reproduz o encadeamento para a frente (veja o\\nExercício 7.24).\\nO algoritmo DPLL é mostrado na \\nFigura 7.17\\n, o que oferece o esqueleto essencial do processo de\\nbusca.\\nO que a \\nFigura 7.17\\n não mostra são os truques que tornam os resolvedores SAT escaláveis para\\nproblemas maiores.\\nfunção\\n SATISFATÍVEL-DPLL?(s) \\nretorna\\n \\nverdadeiro\\n ou \\nfalso\\n    \\nentradas:\\n \\ns\\n, uma sentença em lógica proposicional\\n    \\n    \\ncláusulas\\n ← o conjunto de cláusulas na representação em FNC de \\ns', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 313}),\n",
       " Document(page_content='símbolos\\n ← uma lista dos símbolos proposicionais em \\ns\\n    \\nretornar\\n DPLL(\\ncláusulas\\n, \\nsímbolos\\n, { })\\n_____________________________________________________________________________________________________________\\nfunção\\n DPLL(\\ncláusulas\\n, \\nsímbolos\\n, \\nmodelo\\n) \\nretorna\\n \\nverdadeiro\\n ou \\nfalso\\n    \\n    \\nse\\n toda cláusula em \\ncláusulas\\n é verdadeira em \\nmodelo\\n \\nentão retornar\\n \\nverdadeiro\\n    \\nse\\n alguma cláusula em \\ncláusulas\\n é falsa em \\nmodelo\\n \\nentão retornar\\n \\nfalso\\n    \\nP\\n, \\nvalor\\n ← ENCONTRAR-SÍMBOLO-PURO(\\nsímbolos\\n, \\ncláusulas\\n, \\nmodelo\\n)\\n    \\nse\\n \\nP\\n é não nulo \\nentão retornar\\n DPLL(\\ncláusulas\\n, \\nsímbolos\\n – \\nP\\n, \\nmodelo\\n \\n∪\\n {\\nP\\n = valor})\\n    \\nP\\n, \\nvalor\\n ← ENCONTRAR-CLÁUSULA-UNITÁRIA(\\ncláusulas\\n, \\nmodelo\\n)\\n    \\nse\\n \\nP\\n é não nulo \\nentão retornar\\n DPLL(\\ncláusulas\\n, \\nsímbolos\\n – \\nP\\n, \\nmodelo\\n \\n∪\\n {\\nP\\n = valor})\\n    \\nP\\n ← PRIMEIRO(\\nsímbolos\\n); \\nrestantes\\n ← RESTO(\\nsímbolos\\n)\\n    \\nretornar\\n DPLL(\\ncláusulas\\n, \\nrestantes,\\n \\nmodelo\\n \\n∪\\n {\\nP\\n = \\nverdadeiro\\n}) \\nou\\nDPLL(\\ncláusulas\\n, \\nrestantes\\n, \\nmodelo\\n \\n∪\\n {\\nP\\n = \\nfalso\\n})\\nFigura 7.17\\n O algoritmo DPLL para verificar a satisfatibilidade de uma sentença em lógica\\nproposicional. As ideias contidas em ENCONTRAR-SÍMBOLO-PURO e ENCONTRAR-\\nCLÁUSULA-UNITÁRIA são descritas no texto; cada um deles retorna um símbolo (ou nulo) e o\\nvalor-verdade que deve ser atribuído a esse símbolo. Como CONSEQUÊNCIA-LÓGICA-TV?,\\nDPLL opera sobre modelos parciais.\\nÉ interessante que a maioria desses truques na verdade são bastante gerais, e já os vimos em\\noutras formas:\\n1. \\nAnálise de componentes\\n (como visto na Tasmânia em PSRs (ver Capítulo 6)): Como o DPLL\\natribui valores-verdade para variáveis\\u200b\\u200b, o conjunto de cláusulas pode ficar separado em\\nsubconjuntos disjuntos, chamados de \\ncomponentes,\\n que não compartilham as variáveis \\u200b\\u200bnão\\natribuídas. Havendo uma maneira eficiente para detectar quando isso ocorre, um solucionador\\npode ganhar uma velocidade considerável, trabalhando em cada componente separadamente.\\n2. \\nVariável e ordenação de valor\\n (como visto na \\nSeção 6.3.1\\n para PSRs): A nossa\\nimplementação simples de DPLL utiliza uma ordenação de variáveis arbitrárias e sempre tenta\\no valor verdadeiro antes do \\nfalso\\n. A \\nheurística de grau\\n sugere escolher a variável que aparece\\ncom mais frequência sobre todas as demais cláusulas.\\n3. \\nRetrocesso inteligente\\n (como visto na \\nSeção 6.3\\n para PSRs): Muitos problemas que não\\npodem ser resolvidos em horas de tempo de execução com retrocesso cronológico podem ser\\nresolvidos em segundos com retrocesso inteligente que retrocede todo o caminho até o ponto\\nrelevante de conflito. Todos os resolvedores que realizam retrocesso inteligente usam alguma\\nforma de \\naprendizagem de cláusula de conflito\\n para gravar os conflitos de modo que não se\\nrepitam mais tarde na busca. Geralmente um conjunto limitado de tamanho de conflitos é\\nmantido, e raramente os descartados são utilizados.\\n4. \\nReinícios aleatórios\\n: Às vezes parece que uma execução não apresenta progresso. Nesse caso,\\npodemos começar de novo a partir do topo da árvore de busca, em vez de tentar continuar.\\nDepois do reinício são feitas escolhas aleatórias diferentes (na variável e na seleção do valor).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 314}),\n",
       " Document(page_content='As cláusulas que são aprendidas no decorrer da primeira execução são mantidas após o\\nreinício e podem ajudar a podar o espaço de busca. O reinício não garante que uma solução\\nserá encontrada mais rápido, mas reduz a variância em tempo para a solução.\\n5. \\nIndexação inteligente\\n (como visto em muitos algoritmos): Os métodos em si utilizados para\\naceleração em DPLL, bem como os truques utilizados pelos solucionadores modernos, exigem a\\nrápida indexação de coisas como “o conjunto de cláusulas na qual a variável \\nX\\ni\\n aparece como\\num literal positivo”. Essa tarefa é complicada pelo fato de que os algoritmos estão interessados\\n\\u200b\\u200bapenas nas cláusulas que ainda não foram satisfeitas por atribuições a variáveis \\u200b\\u200banteriores,\\nentão as estruturas de indexação devem ser atualizadas dinamicamente à medida que a\\ncomputação prossegue.\\nCom esses avanços, os solucionadores modernos podem lidar com problemas de dezenas de\\nmilhões de variáveis. Eles revolucionaram áreas como a de verificação de hardware e de protocolo\\nde segurança, que antes exigiam provas trabalhosas, feitas à mão.\\n7.6.2 Algoritmos de busca local\\nAté agora vimos vários algoritmos de busca local neste livro, incluindo SUBIDA-DE-ENCOSTA\\ne TÊMPERA-SIMULADA. Esses algoritmos podem ser aplicados diretamente a problemas de\\nsatisfatibilidade, desde que seja escolhida a função de avaliação correta. Como o objetivo é\\nencontrar uma atribuição que satisfaça a toda cláusula, uma função de avaliação que efetue a\\ncontagem do número de cláusulas não satisfeitas fará o trabalho. De fato, essa é exatamente a medida\\nusada pelo algoritmo CONFLITOS-MÍNIMOS para PSRs. Todos esses algoritmos executam etapas\\nno espaço de atribuições completas, invertendo o valor-verdade de um símbolo de cada vez.\\nNormalmente, o espaço contém muitos mínimos locais e são exigidas várias formas de aleatoriedade\\npara escapar desses mínimos locais. Nos últimos anos, houve um grande volume de experimentos\\ncom a finalidade de descobrir um bom equilíbrio entre o caráter ambicioso e a aleatoriedade.\\nUm dos mais simples e mais eficientes algoritmos a emergir de todo esse trabalho é chamado\\nWALKSAT (\\nFigura 7.18\\n). Em toda iteração, o algoritmo seleciona uma cláusula não satisfeita e um\\nsímbolo na cláusula a ser invertido. Ele escolhe ao acaso entre dois modos de selecionar o símbolo a\\nser invertido: (1) uma etapa de “conflitos mínimos”, que minimiza o número de cláusulas não\\nsatisfeitas no novo estado, e (2) uma etapa de “percurso aleatório”, que seleciona o símbolo\\naleatoriamente.\\nfunção\\n WALKSAT(\\ncláusulas\\n, \\np\\n, \\ninversões_max\\n) \\nretorna\\n um modelo satisfatório ou \\nfalha\\n    \\nentradas:\\n \\ncláusulas\\n, um conjunto de cláusulas em lógica proposicional\\np\\n, a probabilidade de optar por realizar um movimento de “percurso aleatório”,\\nnormalmente em torno de 0,5\\ninversões_max\\n, número de inversões permitidas antes de desistir\\n    \\n    \\nmodelo\\n ← uma atribuição aleatória de \\nverdadeiro\\n/\\nfalso\\n aos símbolos de \\ncláusulas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 315}),\n",
       " Document(page_content='para\\n \\ni\\n = 1 \\naté\\n \\ninversões\\n_\\nmax\\n \\nfaça\\n        \\nse\\n \\nmodelo\\n satisfaz \\ncláusulas\\n \\nentão retornar\\n \\nmodelo\\n        \\ncláusula\\n ← uma cláusula selecionada ao acaso de \\ncláusulas\\n que é falsa em \\nmodelo\\n        \\ncom probabilidade\\n \\np\\n, inverter o valor de \\nmodelo\\n de um símbolo selecionado ao acaso de\\ncláusula\\n        \\nsenão\\n inverter qualquer símbolo em \\ncláusula\\n que maximize o número de cláusulas satisfeitas\\n    \\nretornar\\n \\nfalha\\nFigura 7.18\\n Algoritmo WALKSAT para verificar a satisfatibilidade pela inversão aleatória dos\\nvalores de variáveis. Existem muitas versões do algoritmo.\\nQuando o WALKSAT retorna um modelo, a sentença de entrada é realmente satisfatível, mas\\nquando retorna \\nfalha\\n existem duas causas possíveis: ou a sentença é insatisfatível ou precisamos dar\\nmais tempo ao algoritmo. Se inicializarmos \\ninversões_max\\n = ∞ e \\np\\n > 0, o WALKSAT vai retornar\\neventualmente um modelo (se existir) porque as etapas de percurso aleatório acabarão por atingir a\\nsolução. Infelizmente, se \\ninversões_max\\n for infinito e se a sentença for não satisfatível, o algoritmo\\nnunca terminará!\\nPor essa razão, o WALKSAT é mais útil quando esperamos que exista uma solução — por\\nexemplo, os problemas discutidos nos Capítulos 3 e 6 em geral têm soluções. Por outro lado, o\\nWALKSAT nem sempre pode detectar a \\nnão satisfatibilidade\\n, necessária para definir a\\nconsequência lógica. Por exemplo, um agente não pode utilizar o WALKSAT para provar que um\\nquadrado é seguro no mundo de wumpus. Em vez disso, ele pode dizer: “Pensei durante uma hora e\\nnão consegui descobrir um mundo possível em que o quadrado \\nnão fosse\\n seguro.” Esse pode ser um\\nbom indicador empírico de que o quadrado é seguro, mas certamente não é uma prova.\\n7.6.3 O cenário dos problemas SAT aleatórios\\nAlguns problemas são mais difíceis que outros. Problemas \\nfáceis\\n podem ser resolvidos por\\nqualquer algoritmo antigo, mas, por sabermos que SAT é NP-completo, pelo menos algumas\\ninstâncias de problema exigem tempo de execução exponencial. No Capítulo 6, vimos algumas\\ndescobertas surpreendentes sobre alguns tipos de problemas. Por exemplo, o problema de \\nn\\n-rainhas,\\nque se pensava ser bastante complicado para os algoritmos de busca por retrocesso, acabou por ser\\ntrivialmente simples para os métodos de busca local, como de conflitos mínimos. Isso deveu-se às\\nsoluções estarem muito densamente distribuídas no espaço das atribuições e à garantia de que\\nqualquer atribuição inicial teria uma solução nas proximidades. Assim, \\nn\\n-rainhas é fácil por ser \\nsub-\\nrestrito\\n.\\nQuando encaramos problemas de satisfatibilidade na forma normal conjuntiva, um problema sub-\\nrestrito é aquele que tem relativamente \\npoucas\\n cláusulas restringindo as variáveis. Por exemplo,\\nobserve esta sentença 3-FNC gerada aleatoriamente com cinco símbolos e cinco cláusulas:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 316}),\n",
       " Document(page_content='Dezesseis das 32 atribuições possíveis são modelos dessa sentença; assim, em média, seriam\\nnecessárias apenas duas conjeturas aleatórias para encontrar um modelo. Esse é um problema fácil\\nde satisfatibilidade, como é a maioria dos problemas sub-restritos. Por outro lado, um problema\\nsuper-restrito\\n tem muitas cláusulas relativas ao número de variáveis e é provável que não tenha\\nsoluções.\\nPara ir além dessas intuições básicas, é preciso definir exatamente como as sentenças aleatórias\\nsão geradas. A notação \\nFNC\\nk\\n (\\nm\\n, \\nn\\n) indica uma sentença \\nk\\n-FNC com \\nm\\n cláusulas e \\nn\\n símbolos, onde\\nas cláusulas são escolhidas de maneira uniforme, independentemente, e sem substituição dentre todas\\nas cláusulas com literais \\nk\\n diferentes, que são positivos ou negativos aleatoriamente. (Um símbolo\\nnão pode aparecer duas vezes em uma cláusula nem uma cláusula pode aparecer duas vezes em uma\\nsentença.)\\nDada uma fonte de sentenças aleatórias, podemos medir a probabilidade de satisfatibilidade. A\\nFigura 7.19\\n(a) demarca a probabilidade de FNC\\n3\\n (\\nm\\n, 50), isto é, sentenças com 50 variáveis e três\\nliterais por cláusula, como uma função da razão de cláusula/símbolo, \\nm\\n/\\nn\\n. Como esperado, com \\nm\\n/\\nn\\nbaixo, a probabilidade de satisfatibilidade é próximo de 1, e, para um \\nm\\n/\\nn\\n alto, a probabilidade fica\\npróxima de 0. A probabilidade cai acentuadamente em torno de \\nm\\n/\\nn\\n = 4,3. Achamos empiricamente\\nque o “precipício” fica aproximadamente no mesmo lugar (para \\nk\\n = 3) e fica cada vez mais\\npronunciado à medida que \\nn\\n aumenta. Teoricamente, a \\nsuposição do limiar de satisfatibilidade\\nafirma que, para cada \\nk\\n ≥ 3, há uma razão limite de \\nr\\nk\\n de tal forma que, quando \\nn\\n tende ao infinito, a\\nprobabilidade de que \\nFNC\\nk\\n (\\nn\\n, \\nrn\\n) seja satisfatível se torna 1 para todos os valores de \\nr\\n abaixo do\\nlimite e 0 para todos os valores acima. A suposição ainda não foi provada.\\nFigura 7.19\\n (a) Gráfico mostrando a probabilidade de uma sentença 3-FNC aleatória com \\nn\\n = 50\\nsímbolos ser satisfatível, como uma função da razão cláusula/símbolo \\nm\\n/\\nn\\n. (b) Gráfico do tempo\\nmediano de execução (medido em número de chamadas recursivas da DPLL, um bom parâmetro\\nproxy\\n) de 3-FNC sentenças aleatórias. Os problemas mais difíceis têm uma razão cláusula/símbolo\\nde cerca de 4.3.\\nAgora que temos uma boa ideia de onde estão os problemas satisfatíveis e insatisfatíveis, a\\npergunta é a seguinte: onde estão os problemas difíceis? Acontece que eles também estão muitas\\nvezes no valor limite. A \\nFigura 7.19\\n(b) mostra que 50 problemas de símbolo no valor limiar de 4,3\\nsão cerca de 20 vezes mais difíceis de resolver do que aqueles com proporção de 3,3. Os problemas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 317}),\n",
       " Document(page_content='sub-restritos são os mais fáceis de resolver (porque é muito fácil adivinhar uma solução), os\\nproblemas super-restritos não são tão fáceis como os sub-restritos, mas ainda são muito mais fáceis\\ndo que os que estão no limiar.\\n7.7 AGENTES BASEADOS EM LÓGICA PROPOSICIONAL\\nNesta seção, vamos reunir o que aprendemos até agora, a fim de construir agentes do mundo de\\nwumpus que utilizam lógica proposicional. O primeiro passo é permitir que o agente deduza, na\\nmedida do possível, o estado do mundo, dada a sua história de percepção. Isso requer escrever um\\nmodelo lógico completo dos efeitos das ações. Podemos mostrar também como o agente pode\\nacompanhar o mundo de forma eficiente sem voltar na história da percepção para cada inferência.\\nFinalmente, mostraremos como o agente pode utilizar a inferência lógica para a construção de planos\\ngarantidos de atingir os seus objetivos.\\n7.7.1 O estado atual do mundo\\nComo dito no início do capítulo, um agente lógico opera deduzindo o que fazer a partir de uma\\nbase de conhecimento de sentenças sobre o mundo. A base de conhecimento é composta de axiomas\\n— conhecimento geral sobre como o mundo funciona — e sentenças de percepção obtidas da\\nexperiência do agente em um mundo particular. Nesta seção, vamos nos concentrar no problema de\\ndeduzir o estado atual do mundo de wumpus — onde estou, esse quadrado é seguro, e assim por\\ndiante.\\nNa \\nSeção 7.4.3\\n começamos a coletar axiomas. O agente sabe que o quadrado inicial não contém\\npoço (¬\\nP\\n1,1\\n) e nenhum wumpus (¬\\nW\\n1,1\\n). Além disso, para cada quadrado, ele sabe que o quadrado\\nestá com vento se e somente se um quadrado vizinho tiver poço; e um quadrado terá mau cheiro se e\\nsomente se um quadrado vizinho tiver um wumpus. Assim, incluiremos uma grande coleção de\\nsentenças da seguinte forma:\\nO agente também sabe que existe exatamente um wumpus. Isso está expresso em duas partes.\\nPrimeiro, precisamos informar que há pelo menos um wumpus:\\nEntão, informamos que há, \\nno máximo\\n, um wumpus. Para cada par de locais, adicionamos uma\\nsentença informando que pelo menos uma delas deve estar livre do wumpus:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 318}),\n",
       " Document(page_content='Até aí, tudo bem. Agora vamos considerar as percepções do agente. Se houver atualmente mau\\ncheiro, pode-se supor que uma proposição \\nmau cheiro\\n deverá ser adicionada à base de\\nconhecimento. Entretanto, isso não é tão certo: se não havia mau cheiro na etapa de tempo anterior,\\nentão ¬\\nMau cheiro\\n já teria sido reconhecido, e a nova afirmação resultaria simplesmente em uma\\ncontradição. O problema será resolvido quando percebermos que uma percepção afirma algo\\nsomente sobre o tempo atual\\n. Assim, se a etapa do tempo (como provido em CRIAR-SENTENÇA-\\nDE-PERCEPÇAO na \\nFigura 7.1\\n) for 4, então somamos o \\nMau cheiro\\n4\\n à base de conhecimento, em\\nvez do \\nMau cheiro\\n — evitando nitidamente qualquer contradição com ¬\\nMau cheiro\\n3\\n. O mesmo vale\\npara as percepções de brisa, impacto, brilho e gritos.\\nA ideia de associar proposições com etapas de tempo se estende a qualquer aspecto do mundo que\\nmuda ao longo do tempo. Por exemplo, a base de conhecimento inicial inclui \\n — o agente está no\\nquadrado [1,1] no tempo 0 —, bem como \\nOlhandoParaLeste\\n0\\n, \\nTemSeta\\n0\\n e \\nWumpusVivo\\n0\\n. Utilizamos\\na palavra \\nfluente\\n (do latim \\nfluens\\n, fluindo) para nos referir a um aspecto do mundo que muda.\\n“Fluente” é sinônimo de “variável de estado”, no sentido descrito na discussão das representações\\nfatoradas na \\nSeção 2.4.7\\n. Os símbolos associados aos aspectos permanentes do mundo não\\nnecessitam de um sobrescrito de tempo e às vezes são chamados de \\nvariáveis \\u200b\\u200batemporais\\n.\\nPodemos conectar as percepções de mau cheiro e de brisa diretamente às propriedades dos\\nquadrados onde são experimentados através da localização fluente como segue.\\n10\\n Para qualquer\\netapa t e qualquer quadrado [\\nx,\\n \\ny\\n], afirmamos\\nAgora, é claro, precisamos de axiomas que permitam que o agente mantenha o controle de fluentes\\ncomo \\n. Esses fluentes se alteram como resultado de ações tomadas pelo agente; então, na\\nterminologia do Capítulo 3, é preciso anotar o \\nmodelo de transição\\n do mundo de wumpus como um\\nconjunto de sentenças lógicas.\\nPrimeiro, precisamos de símbolos proposicionais para as ocorrências de ações. Tal como\\nacontece com as percepções, esses símbolos são indexados pelo tempo, portanto, \\nParaFrente\\n0\\nsignifica que o agente executa a ação \\nParaFrente\\n no instante 0. Por convenção, a percepção para um\\ndeterminado instante acontece primeiro, seguida pela ação para aquele instante, seguida de uma\\ntransição para o próximo instante.\\nPara descrever como o mundo muda, podemos tentar escrever \\naxiomas de efeito\\n que especificam\\no resultado de uma ação no instante seguinte. Por exemplo, se o agente estiver em um local [1,1]\\nvoltado para o leste no instante 0 e se move \\nParaFrente\\n, o resultado é que o agente estará no\\nquadrado [2,1] e não mais em [1,1]:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 319}),\n",
       " Document(page_content='Precisaríamos de uma sentença dessa para cada instante possível, para cada um dos 16 quadrados\\ne cada uma das quatro orientações. Precisaríamos também de sentenças semelhantes para outras\\nações: \\nAgarrar\\n, \\nAtirar\\n, \\nEscalar\\n, \\nVirarEsquerda\\n e \\nVirarDireita.\\nVamos supor que o agente decida se mover (\\nParaFrente\\n) no tempo 0 e declare esse fato em sua\\nbase de conhecimento. Dado o axioma de efeito na Equação 7.1, combinado com as afirmações\\niniciais sobre o estado no tempo 0, o agente já pode deduzir que está em [2,1]. Ou seja, ASK (\\nBC\\n, \\n) = \\nverdadeiro\\n. Até agora, tudo bem. Infelizmente, a notícia em outros lugares não é tão boa: se\\nASK (perguntarmos) (\\nBC\\n, \\nTemSeta\\n1\\n), a resposta será \\nfalso,\\n isto é, o agente não pode provar que\\nainda tem a seta ou que não a tem! A informação foi perdida devido ao axioma de efeito falhar em\\ndeclarar o que permaneceu \\ninalterado\\n como resultado de uma ação. A necessidade de fazer isso dá\\norigem ao \\nproblema de persistência\\n.\\n11\\n Uma possível solução para o problema de persistência seria\\nadicionar \\naxiomas de persistência\\n afirmando explicitamente todas as proposições que permanecem\\nas mesmas. Por exemplo, para cada tempo \\nt\\n, teríamos\\nonde mencionamos explicitamente cada proposição que permanece inalterada do tempo \\nt\\n para o\\ntempo \\nt\\n + 1, sob a ação \\nParaFrente\\n. Embora o agente agora saiba que ainda tem a flecha depois de\\nmover para a frente e que o wumpus não morreu ou voltou à vida, a proliferação de axiomas de\\npersistência parece notavelmente ineficiente. Em um mundo com \\nm\\n ações diferentes e \\nn\\n fluentes, o\\nconjunto de axiomas de persistência será do tamanho \\nO\\n(\\nmn\\n). Essa manifestação específica do\\nproblema de persistência algumas vezes é chamada de \\nproblema de persistência representacional\\n.\\nHistoricamente, o problema foi um dos mais importantes para os pesquisadores de IA, e ainda será\\nexplorado nas notas no final do capítulo.\\nO problema de persistência representacional é importante porque o mundo real tem muitos\\nfluentes, para dizer o mínimo. Felizmente para nós, seres humanos, tipicamente cada ação não muda\\nmais do que um pequeno número \\nk\\n desses fluentes — o mundo apresenta \\nlocalidade\\n. A solução do\\nproblema de persistência representacional exige a definição do modelo de transição, com um\\nconjunto de axiomas de tamanho \\nO\\n(\\nmk\\n) em vez do tamanho \\nO\\n(\\nmn\\n). Há também um \\nproblema de\\npersistência inferencial\\n: o problema de projetar para a frente os resultados de um plano de ação da\\netapa \\nt\\n em tempo \\nO\\n(\\nkt\\n), em vez de \\nO\\n(\\nnt\\n).\\nA solução para o problema envolve uma mudança de foco de escrever axiomas sobre as \\nações\\npara escrever axiomas sobre \\nfluentes.\\n Assim, para cada fluente \\nF\\n, teremos um axioma que define o\\nvalor verdade de \\nF\\nt\\n+1\\n em termos de fluentes (incluindo o próprio \\nF\\n) no instante \\nt\\n e as ações que\\npossam ter ocorrido no instante \\nt\\n. Agora, o valor-verdade de \\nF\\nt\\n+1\\n pode ser definido em uma das duas\\nformas: ou a ação no instante \\nt\\n faz com que \\nF\\n seja verdade em \\nt\\n + 1 ou \\nF\\n já era verdade no instante \\nt\\ne a ação no instante \\nt\\n não faz com que seja falsa. Um axioma dessa forma é chamado de \\naxioma de\\nestado sucessor\\n e tem este esquema:\\nUm dos axiomas mais simples de estado sucessor é o \\nTemFlecha.\\n Por não haver nenhuma ação\\npara recarregar, a parte \\nAçãoCausaF\\nt\\n vai embora e ficamos com', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 320}),\n",
       " Document(page_content='Para a localização do agente, os axiomas de estado sucessor são mais elaborados. Por exemplo, \\n é verdade se (a) o agente se moveu \\nParaFrente\\n de [1,2], quando voltado para o sul, ou de [2,1],\\nquando voltado para o oeste; ou (b) \\nL\\nt\\n1,1\\n já era verdadeiro e a ação não causou movimento (ou\\nporque a ação não era \\nParaFrente\\n ou porque esbarrou em um muro). Escrito em lógica\\nproposicional, torna-se\\nO Exercício 7.26 pede para você escrever axiomas para os fluentes restantes do mundo wumpus.\\nDado um conjunto completo de axiomas de estado sucessor e os outros axiomas listados no início\\ndesta seção, o agente será capaz de PERGUNTAR (ASK) e responder qualquer pergunta que tenha\\numa resposta sobre o estado atual do mundo. Por exemplo, na \\nSeção 7.2\\n a sequência inicial de\\npercepções e ações é\\nNeste ponto, temos ASK (\\nBC,\\n \\n) = \\nverdadeiro\\n, de modo que o agente sabe onde está. Além\\ndisso, ASK (\\nBC\\n, W\\n1,3\\n) = \\nverdadeiro\\n e ASK (\\nBC\\n, \\nP\\n3,1\\n) = \\nverdadeiro\\n, assim o agente encontrou o\\nwumpus e um dos poços. A questão mais importante para o agente é se um quadrado está OK para\\nentrar, ou seja, o quadrado não contém poço nem wumpus vivo. É conveniente acrescentar os\\naxiomas para isso, tendo a forma de\\nFinalmente, ASK (\\nBC\\n, \\n) = \\nverdadeiro\\n, de modo que o quadrado [2, 2] está OK para entrar. De\\nfato, dado um algoritmo de inferência consistente e completo, como o DPLL, o agente pode responder\\na qualquer questão que seja respondível sobre quais quadrados estão OK — e pode fazê-lo em\\napenas alguns milissegundos para mundos de wumpus pequenos a médios.\\nResolver os problemas representacionais e inferenciais de persistência é um grande passo à frente,\\nmas um problema pernicioso permanece: é preciso confirmar que \\ntodas as\\n precondições necessárias\\nde uma ação empregada sejam satisfeitas para que ela tenha o efeito pretendido. Dissemos que a ação\\nParaFrente\\n move o agente para a frente, a menos que haja um muro no caminho, mas existem muitas\\noutras exceções incomuns que podem causar a falha da ação: o agente pode tropeçar e cair, ser\\nacometido de um ataque cardíaco, ser carregado por morcegos gigantes etc. O \\nproblema de\\nqualificação\\n é a especificação de todas essas exceções. Não há solução completa dentro da lógica;\\nos projetistas de sistema têm que usar o bom-senso para decidir o quanto de detalhe desejam na', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 321}),\n",
       " Document(page_content='especificação de seu modelo e que detalhes querem deixar de fora. Veremos no Capítulo 13 que a\\nteoria da probabilidade nos permite resumir todas as exceções sem nomeá-las explicitamente.\\n7.7.2 Um agente híbrido\\nA capacidade de deduzir vários aspectos do estado do mundo pode ser combinada de forma\\nbastante simples com regras de condição-ação e com os algoritmos de resolução de problemas dos\\nCapítulos 3 e 4 para produzir um \\nagente híbrido\\n para o mundo wumpus. A \\nFigura 7.20\\n mostra uma\\nforma possível de fazer isso. O programa do agente mantém e atualiza uma base de conhecimento,\\nbem como um plano atual. A base de conhecimento inicial contém os axiomas \\natemporais\\n, os que não\\ndependem de \\nt\\n, como o axioma relacionando à falta de brisa dos quadrados com a presença de\\npoços. Em cada instante, a nova sentença percebida é adicionada juntamente com todos os axiomas\\nque dependem de \\nt\\n, como os axiomas de estado sucessor (a próxima seção explica por que o agente\\nnão precisa de axiomas para instantes futuros). Então, o agente utiliza inferência lógica, perguntando\\n(ASKing) sobre a base de conhecimento, para planejar quais quadrados são seguros e quais ainda\\ntêm que ser visitados.\\nfunção\\n AGENTE-WUMPUS-HIBRIDO(\\npercepção\\n) \\nretorna\\n uma ação\\n    \\nentradas\\n: percepção, uma lista, [\\nfedor\\n,\\nbrisa\\n,\\nbrilho\\n,\\nimpacto\\n,\\ngrito\\n]\\n    \\npersistente\\n: \\nBC\\n, uma base de conhecimento, inicialmente o “wumpus físico” atemporal \\nt\\n, um contador, inicialmente 0,\\nindicando o \\nplano\\n de tempo, uma sequência de ação, inicialmente vazia\\n    \\n    \\nTELL\\n(\\nBC\\n,CRIAR-SENTENÇA-DE-PERCEPÇÃO(\\npercepção\\n, \\nt\\n))\\n    \\nTELL\\n a \\nBC\\n as sentenças temporais de “física” para o instante \\nt\\n    \\nsalvar\\n ←{[\\nx\\n, \\ny\\n] : ASK(\\nBC\\n, \\nOK\\nt\\nx,y\\n) = \\nverdadeiro\\n}\\n    \\nse\\n ASK(\\nBC\\n, \\nBrilho\\nt\\n) = \\nverdadeiro\\n \\nentão\\n        \\nplano\\n ←[\\nAgarrar\\n] + PLANO-ROTA(\\natual\\n, {[1,1]}, \\nseguro\\n) + [\\nEscalar\\n]\\n    \\nse\\n \\nplano\\n é vazio \\nentão\\n        \\nnão visitado\\n ←{[\\nx\\n, \\ny\\n] : ASK(\\nBC\\n,\\nL\\nt’\\nx,y\\n) = \\nfalso\\n para todo \\nt\\n′≤ \\nt\\n}\\n        \\nplano\\n ← PLANO-ROTA(\\natual\\n, \\nnão visitado\\n \\x00 \\nseguro\\n, \\nseguro\\n)\\n    \\nse\\n \\nplano\\n é vazio e ASK(\\nBC\\n,\\nTemFlecha\\nt\\n) = \\nverdadeiro\\n \\nentão\\n        \\nwumpus-possível\\n ←{[\\nx\\n, \\ny\\n] : ASK(\\nBC\\n,¬\\nW\\nx,y\\n) = \\nfalso\\n}\\n        \\nplano\\n ←PLANO-ATIRAR(\\natual\\n, \\nwumpus_possível\\n, \\nseguro\\n)\\n    \\nse\\n \\nplano\\n é vazio \\nentão\\n // única chance arriscar\\n        \\nnão_arriscado\\n ←{[\\nx\\n, \\ny\\n] : ASK(\\nBC\\n,¬\\nOK\\nt\\nx,y\\n) = \\nfalso\\n}\\n        \\nplano\\n ← PLANO-ROTA(\\natual\\n, \\nnão visitado\\n \\x00 \\nnão_seguro\\n, \\nseguro\\n)\\n    \\nse\\n \\nplano\\n é vazio \\nentão\\n        \\nplano\\n ← PLANO-ROTA(\\natual\\n, {[1, 1]}, \\nseguro\\n) + [\\nEscalar\\n]\\n    \\nação\\n ← POP(\\nplano\\n)\\n    TELL(\\nBC\\n,CRIAR-SENTENÇA-AÇÃO(\\nação\\n, \\nt\\n))\\n    \\nt\\n ← \\nt\\n + 1', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 322}),\n",
       " Document(page_content='retornar\\n \\nação\\n_____________________________________________________________________________________________________________\\nfunção\\n PLANO-ROTA(\\natual\\n,\\nobjetivo\\n,\\npermitido\\n) \\nretornar\\n uma sequência de ação\\n    \\nentradas\\n: \\natual\\n, posição atual do agente\\nobjetivos\\n, um conjunto de quadrados; tentar planejar uma rota para um deles\\npermitido\\n, um conjunto de quadrados que podem formar parte da rota\\n    \\n    \\nproblema\\n ← PROBLEMA-ROTA(\\natual\\n,\\nobjetivos\\n,\\npermitido\\n)\\n    \\nretornar\\n BUSCA-A*-EM-GRAFOS(\\nproblema\\n)\\nFigura 7.20\\n Um programa de agente híbrido para o mundo de wumpus. Ele utiliza uma base de\\nconhecimento proposicional para inferir o estado do mundo e uma combinação de busca de resolução\\nde problemas e código de domínio específico para decidir que ações tomar.\\nO corpo principal do programa do agente constrói um plano baseado em uma prioridade\\ndecrescente de objetivos. Primeiro, se houver brilho, o programa constrói um plano para agarrar o\\nouro, seguir uma rota de volta ao local inicial e sair da caverna. Caso contrário, se não houver\\nnenhum plano atual, o programa planeja uma rota para o próximo quadrado seguro que ainda não\\nvisitou, certificando-se de que a rota passa apenas por quadrados seguros. O planejamento de rotas é\\nfeito com uma busca A*, não com ASK. Se não houver quadrados seguros para explorar, a próxima\\netapa — se o agente ainda tiver uma flecha — é tentar deixar um quadrado seguro atirando em um\\ndos possíveis locais de wumpus. Isso será determinado perguntando onde ASK (\\nBC\\n, ¬W\\nx, y\\n) é falso,\\nou seja, onde \\nnão\\n se sabe que \\nnão\\n existe um wumpus. A função PLANO-TIRO (não mostrada) utiliza\\nPLANO-ROTA para planejar uma sequência de ações que vai alinhar esse tiro. Se falhar, o\\nprograma vai procurar um quadrado para explorar que não seja comprovadamente inseguro, isto é,\\num quadrado para o qual ASK (\\nBC\\n, \\n) retorne falso. Se não houver tal quadrado, então a missão\\né impossível, e o agente retira-se para [1,1] e sai da caverna.\\n7.7.3 Estimação de estado lógico\\nO programa do agente na \\nFigura 7.20\\n funciona muito bem, mas tem uma grande fragilidade: com o\\npassar do tempo, o custo computacional envolvido nas chamadas ASK aumenta cada vez mais. Isso\\nacontece principalmente porque as inferências necessárias têm de voltar mais e mais no tempo e\\nenvolvem mais e mais símbolos proposicionais. Obviamente, isso é insustentável — não podemos ter\\num agente cujo tempo para processar cada percepção cresce em proporção ao comprimento da sua\\nvida! O que realmente precisamos é de uma atualização de tempo \\nconstante\\n, isto é, independente de\\nt\\n. A resposta óbvia é salvar ou colocar em \\ncache\\n os resultados de inferência, de modo que o\\nprocesso de inferência no próximo instante possa ser construído sobre os resultados das etapas\\nanteriores, em vez de ter de recomeçar novamente do zero.\\nComo vimos na \\nSeção 4.4\\n, a história passada de percepções e todas as suas ramificações pode ser\\nsubstituída pelo \\nestado de crença\\n, isto é, alguma representação do conjunto de todos os estados', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 323}),\n",
       " Document(page_content='atuais possíveis do mundo.\\n12\\n O processo de atualização do estado de crença como novas percepções\\né chamado de \\nestimação de estado\\n. Considerando que, na \\nSeção 4.4\\n, o estado de crença era uma\\nlista explícita de estados, aqui podemos utilizar uma sentença lógica envolvendo os símbolos de\\nproposição associados com a etapa de tempo atual, bem como os símbolos atemporais. Por exemplo,\\na sentença lógica\\nrepresenta o conjunto de todos os estados no tempo 1 em que o wumpus está vivo, o agente está em\\n[2,1], esse quadrado tem brisa e há um poço em [3,1] ou [2, 2], ou ambos.\\nA manutenção de um estado de crença exato como uma fórmula lógica acaba por não ser fácil. Se\\nhouver \\nn\\n símbolos fluentes para o tempo \\nt\\n, então há 2\\nn\\n estados possíveis, ou seja, atribuições de\\nvalores-verdade para aqueles símbolos. Agora, o conjunto de estados de crença é o conjunto das\\npartes (conjunto de todos os subconjuntos) do conjunto de estados físicos. Existem 2\\nn\\n estados físicos,\\nportanto, \\n estados de crença. Mesmo se usássemos a codificação mais compacta possível das\\nfórmulas lógicas, com cada estado de crença representado por um único número binário,\\nprecisaríamos de números com log\\n2\\n(\\n) = 2\\nn\\n bits para rotular o estado de crença atual. Ou seja, a\\nestimativa de estado exata pode exigir fórmulas lógicas cujo tamanho é exponencial no número de\\nsímbolos.\\nUm esquema muito comum e natural para \\naproximar\\n a estimação de estado é representar estados\\nde crença como conjunções de literais, ou seja, fórmulas 1-FNC. Para fazer isso, o programa agente\\nsimplesmente tenta provar X\\nT\\n e ¬X\\nT\\n para cada símbolo X\\nT\\n (assim como cada símbolo atemporal\\ncujo valor-verdade ainda não seja conhecido), dado o estado de crença em \\nt\\n − 1. Uma conjunção de\\nliterais prováveis tornam-se o novo estado de crença, e o estado de crença anterior é descartado.\\n É importante entender que esse esquema pode perder alguma informação à medida que o tempo\\npassa. Por exemplo, se a sentença na Equação 7.4 for o estado de crença verdadeiro, nem \\nP\\n3,1\\n nem\\nP\\n2,2\\n serão individualmente prováveis nem aparecerão no estado de crença 1-FNC (o Exercício 7.27\\nexplora uma solução possível para esse problema). Por outro lado, devido a cada literal do estado\\nde crença 1-FNC ser demonstrado pelo estado de crença anterior, e o estado de crença inicial ser\\numa afirmação verdadeira, sabemos que o estado de crença inteiro 1-FNC deve ser verdadeiro.\\nAssim, \\no conjunto de estados possíveis representado pelo estado de crença 1-FNC inclui todos os\\nestados que são de fato possíveis, dada a história completa da percepção.\\n Como ilustrado na\\nFigura 7.21\\n, o estado de crença 1-FNC age como um simples envelope exterior, ou \\naproximação\\nconservadora\\n, em torno do estado de crença exato. Vemos essa ideia de aproximações\\nconservadoras para conjuntos complicados como um tema recorrente em muitas áreas da IA.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 324}),\n",
       " Document(page_content='Figura 7.21\\n Representação de um estado de crença 1-FNC (contorno em negrito) como uma\\naproximação conservadora fácil de representar do exato (sinuoso) estado de crença (região\\nsombreada com contorno tracejado). Cada mundo possível é mostrado como um círculo; os\\nsombreados são consistentes com todas as percepções.\\n7.7.4 Criar planos por inferência proposicional\\nO agente na \\nFigura 7.20\\n utiliza inferência lógica para determinar quais quadrados são seguros, mas\\nusa uma busca A* para fazer planos. Nesta seção, vamos mostrar como fazer planos por inferência\\nlógica. A ideia básica é muito simples:\\n1. Construir uma sentença que inclua:\\n(a) \\nInit\\n0\\n, uma coleção de afirmações sobre o estado inicial;\\n(b) \\nTransição\\n1\\n,…, \\nTransição\\nt\\n, os axiomas de estado sucessor para todas as ações possíveis em\\ncada instante até algum instante máximo \\nt\\n;\\n(c) a afirmação de que o objetivo seja alcançado no tempo \\nt\\n: \\nTerOuro\\nt\\n \\n∧\\n \\nSair\\nt\\n.\\n2. Apresentar a sentença toda para um resolvedor SAT. Se o resolvedor encontrar um modelo\\nsatisfazendo a sentença, o objetivo será alcançável; se a sentença é insatisfatível, o problema\\nde planejamento é impossível.\\n3. Assumindo que um modelo seja encontrado, extrair do modelo as variáveis \\u200b\\u200bque representam\\nações e a que são atribuídas \\nverdadeiro\\n. Juntas, elas representam um plano para atingir os\\nobjetivos.\\nNa \\nFigura 7.22\\n é mostrado um procedimento de planejamento proposicional, SATPLAN. Ele\\nimplementa a ideia básica recém-fornecida, com uma diferença. Devido ao agente não saber quantas\\netapas serão necessárias para atingir o objetivo, o algoritmo tenta cada número possível de etapas \\nt\\n,\\naté algum plano máximo concebível de comprimento \\nT\\nmax\\n. Dessa forma, é garantido o encontro do\\nplano mais curto, se houver. Devido à forma como o SATPLAN busca uma solução, essa abordagem\\nnão pode ser usada em um ambiente parcialmente observável; o SATPLAN apenas atribuiria às', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 325}),\n",
       " Document(page_content='variáveis \\u200b\\u200bnão observáveis os valores de que necessita para criar uma solução.\\nfunção\\n SATPLAN(init, transição, objetivo , \\nT\\nmax\\n) \\nretorna\\n solução ou falha\\n    \\nentradas\\n: init, transição, objetivo, constituem uma descrição do problema\\nT\\nmax\\n, um limite superior para a extensão do plano\\n    \\npara\\n \\nt\\n = 0 \\naté\\n Tmax \\nfaça\\n        fnc ← TRADUZIR-PARA-SAT(init, transição, objetivo, t)\\n        modelo ← RESOLVEDOR-SAT(\\nfnc\\n)\\n        \\nse\\n \\nmodelo\\n não for nulo \\nentão\\n            \\nretornar\\n EXTRAIR-SOLUÇÃO(\\nmodelo\\n)\\n    \\nretornar\\n \\nfalha\\nFigura 7.22\\n O algoritmo SATPLAN. O problema de planejamento é traduzido em uma sentença FNC\\nna qual é definido que o objetivo mantém-se em uma etapa de tempo fixo \\nt\\n e os axiomas são incluídos\\nem cada etapa de tempo até \\nt\\n. Se o algoritmo de satisfatibilidade encontrar um modelo, é extraído um\\nplano pela observação dos símbolos de proposição que se referem às ações e que são atribuídas\\ncomo \\nverdadeiras\\n no modelo. Se não existir nenhum modelo, o processo é repetido com o objetivo\\nmovido uma etapa adiante.\\nA etapa-chave na utilização do SATPLAN é a construção da base de conhecimento. Pode parecer,\\nem inspeção casual, que os axiomas do mundo de wumpus da \\nSeção 7.7.1\\n sejam suficientes para as\\netapas 1(a) e 1(b) anteriores. Há, no entanto, uma diferença significativa entre os requisitos para a\\nconsequência lógica (como testado por ASK) e os de satisfatibilidade. Considere, por exemplo, a\\nlocalização do agente, inicialmente [1,1], e suponha que objetivo pouco ambicioso do agente é estar\\nem [2,1] no tempo 1. A base de conhecimento inicial contém \\n, e o objetivo é \\n. Utilizando ASK,\\npodemos demonstrar \\n se for afirmado \\nParaFrente\\n0\\n, e, felizmente, não podemos demonstrar \\n se,\\ndigamos, for afirmado \\nAtirar\\n0\\n, no lugar. Agora, o SATPLAN encontrará o plano [\\nParaFrente\\n0\\n]; até\\nagora, tudo certo. Infelizmente o SATPLAN também encontra o plano [\\nAtirar\\n0\\n]. Como pode ser? Para\\ndescobrir, inspecionamos o modelo que o SATPLAN construiu: inclui a atribuição \\n, ou seja, o\\nagente pode estar em [2,1] no tempo 1 por estar lá no tempo 0 e atirar. Alguém poderia perguntar:\\n“Não dissemos que o agente estava em [1,1] no tempo 0?” Sim, mas não informamos ao agente que\\nele não pode estar em dois lugares ao mesmo tempo! Por consequência lógica, \\n é desconhecido e\\nnão pode, portanto, ser usado como prova; por satisfatibilidade, por outro lado, \\n é desconhecido e\\npode, portanto, ser definido com qualquer valor que ajude a tornar o objetivo verdadeiro. Por essa\\nrazão, o SATPLAN é uma boa ferramenta de depuração para bases de conhecimento porque revela\\nlugares onde o conhecimento está em falta. Nesse caso particular, podemos consertar a base de\\nconhecimento afirmando que, em cada instante, o agente está exatamente em um local, utilizando uma\\ncoleção de sentenças semelhantes às utilizadas para afirmar a existência de exatamente um wumpus.\\nAlternativamente, podemos afirmar \\n para todos os outros locais que não seja [1,1]; o axioma de\\nestado sucessor para a localização tomará conta dos instantes subsequentes. As mesmas correções\\ntambém funcionam para garantir que o agente tenha apenas uma orientação.\\nNo entanto, o SATPLAN tem mais surpresas. A primeira é que ele encontra modelos com ações', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 326}),\n",
       " Document(page_content='impossíveis, como atirar sem flecha. Para entender o porquê, precisamos olhar com mais cuidado ao\\nque os axiomas de estado sucessor (como a Equação 7.3) informam sobre as ações cujas\\nprecondições não sejam satisfeitas. Os axiomas \\npreveem\\n corretamente que nada irá acontecer quando\\ntal ação for executada (veja o Exercício 10.14), mas eles \\nnão\\n dizem que a ação não pode ser\\nexecutada! Para evitar a geração de planos com ações ilegais, devemos acrescentar os \\naxiomas\\n de\\nprecondição\\n afirmando que uma ocorrência de ação requer as precondições para ser satisfeita.\\n13\\n Por\\nexemplo, precisamos dizer, para cada instante \\nt\\n, que\\nIsso garante que, se um plano selecionar a ação \\nAtirar\\n a qualquer tempo, o agente deverá ter uma\\nflecha nesse momento.\\nA segunda surpresa do SATPLAN é a criação de planos com múltiplas ações simultâneas. Por\\nexemplo, pode haver um modelo em que \\nParaFrente\\n0\\n e \\nAtirar\\n0\\n sejam verdadeiros, o que não é\\npermitido. Para eliminar esse problema, introduzimos os \\naxiomas de exclusão de ação\\n: para cada\\npar de ações \\n adicionamos o axioma\\nPode ser salientado que andar para a frente e atirar ao mesmo tempo não é tão difícil de fazer,\\nenquanto, digamos, atirar e agarrar ao mesmo tempo é impraticável. Impondo axiomas de exclusão de\\nação somente em pares de ações que realmente interferem umas com as outras, podemos permitir\\nplanos que incluem ações múltiplas e simultâneas — e devido ao SATPLAN encontrar o menor\\nplano permitido, podemos ter certeza de que ele vai aproveitar essa capacidade.\\nPara resumir, o SATPLAN encontra modelos para uma sentença contendo o estado inicial, o\\nobjetivo, os axiomas de estado sucessor, os axiomas de precondição e os axiomas de exclusão de\\nação. Pode-se mostrar que esse conjunto de axiomas é suficiente, no sentido de que não há mais\\nquaisquer “soluções” espúrias. Qualquer modelo que satisfaça a sentença proposicional será um\\nplano válido para o problema original. A moderna tecnologia de solução SAT torna a abordagem\\nbastante prática. Por exemplo, um resolvedor no estilo do DPLL não tem dificuldade em gerar a\\nsolução de 11 etapas para a instância do mundo de wumpus mostrado na \\nFigura 7.2\\n.\\nEsta seção descreveu uma abordagem declarativa para a construção do agente: o agente trabalha\\npor uma combinação de sentenças afirmativas na base do conhecimento e executa inferência lógica.\\nEssa abordagem tem algumas fraquezas escondidas em sentenças como “para cada instante \\nt\\n” e “para\\ncada quadrado [\\nx\\n, \\ny\\n]”. Para qualquer agente prático, essas sentenças devem ser implementadas por\\ncódigo que automaticamente gera instâncias do esquema de sentença geral para inserção na base de\\nconhecimento. Para um mundo de wumpus de tamanho razoável — comparável a um pequeno jogo de\\ncomputador —, pode-se precisar de um tabuleiro 100 × 100 e 1.000 instantes, levando a bases de\\nconhecimento com dezenas ou centenas de milhões de sentenças. Isso não só se torna impraticável,\\nmas também ilustra um problema mais profundo: sabemos algo sobre o mundo de wumpus, ou seja,\\nque a \"física\" funciona da mesma maneira em todas os quadrados e em todas os instantes de tempo —\\no que não podemos expressar diretamente na linguagem da lógica proposicional. Para resolver esse\\nproblema, precisamos de uma linguagem mais expressiva, em que sentenças como “para cada instante\\nt\\n” e “para cada quadrado [\\nx\\n, \\ny\\n]” possam ser escritas de uma forma natural. A lógica de primeira', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 327}),\n",
       " Document(page_content='ordem, descrita no Capítulo 8, é essa linguagem; na lógica de primeira ordem, o mundo de wumpus\\nde qualquer tamanho e duração pode ser descrito em cerca de 10 sentenças, em vez de 10 milhões ou\\n10 trilhões.\\n7.8 RESUMO\\nIntroduzimos o conceito de agentes baseados em conhecimento e mostramos como definir uma\\nlógica com a qual esses agentes podem raciocinar sobre o mundo. Os principais pontos são:\\n•  Agentes inteligentes precisam de conhecimento sobre o mundo, a fim de alcançar boas decisões.\\n•  O conhecimento está contido em agentes sob a forma de \\nsentenças\\n em uma \\nlinguagem de\\nrepresentação do conhecimento\\n que está armazenada em uma \\nbase de conhecimento\\n.\\n•  Um agente baseado em conhecimento é composto por uma base de conhecimento e um\\nmecanismo de inferência. Ele opera armazenando sentenças sobre o mundo em sua base de\\nconhecimento, utilizando o mecanismo de inferência para deduzir novas sentenças e empregando\\nessas sentenças para decidir que ação executar.\\n•  Uma linguagem de representação é definida por sua \\nsintaxe\\n, que especifica a estrutura de\\nsentenças, e por sua \\nsemântica\\n, que define a \\nverdade\\n de cada sentença em cada \\nmodelo\\n ou\\nmundo possível\\n.\\n•  A relação de \\nconsequência lógica\\n entre sentenças é crucial para nossa compreensão do\\nraciocínio. Uma sentença a tem como consequência lógica outra sentença \\nβ\\n se \\nβ\\n é verdadeira em\\ntodos os mundos em que a é verdadeira. Definições equivalentes incluem a \\nvalidade\\n da sentença\\na \\n⇒\\n \\nβ\\n e a \\nnão satisfatibilidade\\n da sentença a \\n∧\\n ¬\\nβ\\n.\\n•  A inferência é o processo de derivação de novas sentenças a partir de sentenças antigas. Os\\nalgoritmos de inferência \\ncorretos\\n derivam \\nsomente\\n consequências lógicas; os algoritmos\\ncompletos\\n derivam \\ntodas\\n as consequências lógicas.\\n•  A \\nlógica proposicional\\n é uma linguagem muito simples que consiste em \\nsímbolos de\\nproposições\\n e \\nconectivos lógicos\\n. Ela pode manipular proposições que são conhecidas como\\nverdadeiras, conhecidas como falsas ou completamente desconhecidas.\\n•  O conjunto de modelos possíveis, dado um vocabulário proposicional fixo, é finito e, assim, a\\nconsequência lógica pode ser verificada pela enumeração de modelos. Algoritmos de inferência\\neficientes de \\nverificação de modelos\\n para lógica proposicional incluem métodos de retrocesso e\\nbusca local e, com frequência, podem resolver grandes problemas com muita rapidez.\\n•  \\nRegras de inferência\\n são padrões de inferência consistente que podem ser usados para\\ndescobrir provas. A \\nregra de resolução\\n gera um algoritmo de inferência completo para bases de\\nconhecimento expressas em \\nforma normal conjuntiva\\n. O \\nencadeamento para a frente\\n e o\\nencadeamento para trás\\n são algoritmos de raciocínio muito naturais para bases de\\nconhecimento na \\nforma de Horn\\n.\\n•  Métodos de \\nbusca local\\n, tal como o WALKSAT, podem ser utilizados para encontrar soluções.\\nTais algoritmos são consistentes, mas não completos.\\n•  A \\nestimação de estado\\n lógico envolve a manutenção de uma sentença lógica que descreve o\\nconjunto de estados possíveis coerentes com o histórico de observação. Cada etapa de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 328}),\n",
       " Document(page_content='atualização exige inferência utilizando o modelo de transição do ambiente, que é construído de\\naxiomas de estados sucessores\\n que especificam como cada \\nfluente\\n se altera.\\n•  As decisões dentro de um agente lógico podem ser realizadas por resolução SAT: encontrar\\nmodelos possíveis especificando sequências de ações futuras que atingem a meta. Essa\\nabordagem funciona apenas para ambientes totalmente observáveis \\u200b\\u200bou sem sensores.\\n•  A lógica proposicional não consegue tratar de ambientes de tamanho ilimitado porque lhe falta a\\ncapacidade de expressão necessária para lidar de forma concisa com tempo, espaço e padrões\\nuniversais de relacionamentos entre objetos.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nO artigo de John McCarthy “Programs with Common Sense” (McCarthy, 1958, 1968) promulgou a\\nnoção de agentes que utilizam raciocínio lógico para atuar como mediadores entre percepções e\\nações. Ele também levantou a bandeira do declarativismo, assinalando que informar a um agente o\\nque ele precisa saber é uma forma muito elegante de criar software. O artigo de Allen Newell\\n(1982), “The Knowledge Level”, argumenta que agentes racionais podem ser descritos e analisados\\nem um nível abstrato definido pelo conhecimento que possuem, e não pelos programas que executam.\\nAs abordagens declarativa e procedural para a IA são comparadas em Boden (1977). O debate foi\\nreavivado por Brooks (1991) e Nilsson (1991) entre outros, e continua até hoje (Shaparau \\net al\\n.,\\n2008). Enquanto isso, a abordagem declarativa se espalhou para outras áreas da ciência da\\ncomputação, tais como redes (Loo \\net al\\n., 2006).\\nA lógica em si teve suas origens na filosofia e na matemática dos antigos gregos. Vários princípios\\nlógicos — os princípios que conectam a estrutura sintática de sentenças com sua verdade e falsidade,\\ncom seu significado ou com a validade de argumentos em que elas figuram — foram difundidos nos\\ntrabalhos de Platão. O primeiro estudo sistemático conhecido de lógica foi desenvolvido por\\nAristóteles, cujo trabalho foi reunido por seus alunos após sua morte, em 322 a.C., sob a forma de um\\ntratado denominado \\nOrganon\\n. Os \\nsilogismos\\n de Aristóteles eram aquilo que chamaríamos agora de\\nregras de inferência. Embora os silogismos incluíssem elementos tanto de lógica proposicional\\nquanto de lógica de primeira ordem, faltaram no sistema como um todo as propriedades de\\ncomposição necessárias para lidar com as sentenças de complexidade arbitrária.\\nAs escolas intimamente relacionadas megárica e estoica (originárias do século V a.C. e que\\ncontinuaram por vários séculos daí em diante) começaram o estudo sistemático dos conectivos\\nlógicos básicos. O uso de tabelas--verdade para definir conectivos lógicos se deve a Filo de\\nMégara. Os estoicos tomavam cinco regras básicas de inferência como válidas sem prova, inclusive\\na regra agora denominada \\nModus Ponens\\n. Eles derivaram muitas outras regras a partir dessas cinco,\\nutilizando entre outros princípios o teorema da dedução (\\nSeção 7.5\\n) e eram muito mais claros em\\nrelação à noção de prova do que Aristóteles. Um bom relato da história da lógica megárica e estoica,\\naté onde ela é conhecida, é apresentado por Benson Mates (1953).\\nA ideia de reduzir a inferência lógica a um processo puramente mecânico aplicado a uma\\nlinguagem formal se deve a Wilhelm Leibniz (1646-1716), apesar de ele ter tido sucesso limitado na\\nimplementação das ideias.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 329}),\n",
       " Document(page_content='George Boole (1847) introduziu o primeiro sistema completo e funcional de lógica formal em seu\\nlivro \\nThe Mathematical Analysis of Logic\\n. A lógica de Boole era fortemente modelada sobre a\\nálgebra comum de números reais e utilizava a substituição de expressões logicamente equivalentes\\ncomo seu principal método de inferência. Embora o sistema de Boole ainda estivesse abaixo da\\nlógica proposicional completa, ele se encontrava próximo o suficiente dessa lógica para que outros\\nmatemáticos pudessem preencher rapidamente as lacunas. Schröder (1877) descreveu a forma normal\\nconjuntiva, enquanto a forma de Horn foi introduzida muito mais tarde por Alfred Horn (1951). A\\nprimeira exposição completa da lógica proposicional moderna (e da lógica de primeira ordem) é\\nencontrada no trabalho de Gottlob Frege (1879), \\nBegriffschrift\\n (“Escrita de conceitos” ou “Notação\\nconceitual”).\\nO primeiro dispositivo mecânico destinado a executar inferências lógicas foi construído pelo\\nterceiro Conde de Stanhope (1753-1816). O Demonstrador de Stanhope podia tratar silogismos e\\ncertas inferências na teoria de probabilidade. William Stanley Jevons, um dos cientistas que\\naperfeiçoaram e estenderam o trabalho de Boole, construiu seu “piano lógico” em 1869 para executar\\ninferências em lógica booleana. Uma divertida e instrutiva história desses e de outros antigos\\ndispositivos mecânicos para raciocínio é apresentada por Martin Gardner (1968). O primeiro\\nprograma de computador publicado para inferência lógica foi o Logic Theorist de Newell, Shaw e\\nSimon (1957). Esse programa foi planejado para modelar processos humanos de pensamento. Martin\\nDavis (1957) realmente projetou um programa que apresentou uma prova em 1954, mas os resultados\\ndo Logic Theorist foram publicados um pouco antes.\\nAs tabelas-verdade como método de teste da validade ou da não satisfatibilidade de sentenças na\\nlinguagem da lógica proposicional foram introduzidas independentemente por Emil Post (1921) e\\nLudwig Wittgenstein (1922). Na década de 1930, foram feitos muitos progressos em métodos de\\ninferência para lógica de primeira ordem. Em particular, Gödel (1930) mostrou que um procedimento\\ncompleto para inferência em lógica de primeira ordem podia ser obtido por meio de uma redução à\\nlógica proposicional, com a utilização do teorema de Herbrand (Herbrand, 1930). Veremos\\nnovamente essa história no Capítulo 9; aqui, é importante ressaltar que o desenvolvimento de\\nalgoritmos proposicionais eficientes nos anos 1960 foi motivado em grande parte pelo interesse dos\\nmatemáticos em um provador de teoremas eficaz para lógica de primeira ordem. O algoritmo de\\nDavis-Putnam (Davis e Putnam, 1960) foi o primeiro algoritmo efetivo para resolução proposicional,\\nmas, na maioria dos casos, era muito menos eficiente que o algoritmo de retrocesso de DPLL\\nintroduzido dois anos mais tarde (1962). A regra de resolução completa e uma prova de sua\\ncompletude apareceram em um importante artigo de J. A. Robinson (1965), que também mostrou\\ncomo realizar o raciocínio de primeira ordem sem recorrer a técnicas proposicionais.\\nStephen Cook (1971) mostrou que o problema de decidir a satisfatibilidade de uma sentença em\\nlógica proposicional (o problema SAT) é NP-completo. Tendo em vista que decidir a consequência\\nlógica é equivalente a decidir a não satisfatibilidade, o problema é co-NP-completo. São conhecidos\\nmuitos subconjuntos da lógica proposicional para os quais o problema de satisfatibilidade é\\nresolvível em tempo polinomial; as cláusulas de Horn formam um desses subconjuntos. O algoritmo\\nde encadeamento para a frente em tempo linear para cláusulas de Horn se deve a Dowling e Gallier\\n(1984), que descrevem seu algoritmo como um processo de fluxo de dados semelhante à propagação\\nde sinais em um circuito.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 330}),\n",
       " Document(page_content='As primeiras investigações teóricas mostraram que o DPLL tem complexidade polinomial no caso\\nmédio para certas distribuições naturais de problemas. Esse fato potencialmente interessante se\\ntornou menos interessante quando Franco e Paull (1983) mostraram que os mesmos problemas\\npodiam ser resolvidos em tempo constante, simplesmente supondo-se atribuições aleatórias. O\\nmétodo de geração aleatória descrito no capítulo gera problemas muito mais difíceis. Motivado pelo\\nsucesso empírico da busca local nesses problemas, Koutsoupias e Papadimitriou (1992) mostraram\\nque um simples algoritmo de subida de encosta pode resolver \\nquase todas\\n as instâncias de\\nproblemas de satisfatibilidade com muita rapidez, sugerindo que problemas difíceis são raros. Além\\ndisso, Schöning (1999) exibiu um algoritmo de subida de encosta aleatório que apresentava um\\ntempo de execução esperado no \\npior caso\\n de execução nos problemas 3-SAT (isto é, a\\nsatisfatibilidade das sentenças 3-FNC) de \\nO\\n(1,333\\nn\\n) — ainda exponencial, embora substancialmente\\nmais rápido que os limites anteriores de pior caso. O recorde atual é \\nO\\n(1,324\\nn\\n) (Iwama e Tamaki,\\n2004). Achlioptas \\net al\\n. (2004) e Alekhnovich \\net al\\n. (2005) apresentaram famílias de instâncias de\\n3-SAT para o qual todos os algoritmos como o DPLL requerem tempo de execução exponencial.\\nPelo lado prático, ganhos de eficiência têm sido obtidos com resolvedores proposicionais. Dados\\n10 minutos de tempo de computação, o algoritmo DPLL original de 1962 só podia resolver\\nproblemas com não mais do que 10 ou 15 variáveis. Em 1995, o solucionador Satz (Li e Anbulagan,\\n1997) podia lidar com mil variáveis, graças às estruturas de dados otimizadas de indexação de\\nvariáveis. Duas contribuições fundamentais foram a técnica de indexação de \\nliteral vigiado\\n de Zhang\\ne Stickel (1996), que tornou a propagação unitária muito eficiente, e a introdução das técnicas de\\naprendizagem de cláusulas (ou seja, restrição) da comunidade PSR por Bayardo e Schrag (1997).\\nUtilizando essas ideias, e estimulados pela perspectiva de solução de problemas de verificação de\\ncircuito em escala industrial, Moskewicz \\net al\\n. (2001) desenvolveram o resolvedor CHAFF, que\\npodia lidar com problemas com milhões de variáveis. A partir de 2002, as competições SAT foram\\nrealizadas regularmente; a maioria dos vencedores eram descendentes de CHAFF ou utilizavam a\\nmesma abordagem geral. O RSAT (Pipatsrisawat e Darwiche, 2007), o vencedor de 2007, entrou na\\núltima categoria. Também digno de nota é o MINISAT (Een e Sorensson, 2003), uma implementação\\nopen-source disponível em \\nhttp://minisat.se\\n, que foi projetada para ser facilmente modificada e\\nmelhorada. O cenário atual dos resolvedores foi examinado por Gomes \\net al.\\n (2008).\\nOs algoritmos de busca local para satisfatibilidade foram experimentados por vários autores em\\ntoda a década de 1980; todos os algoritmos foram baseados na ideia de minimizar o número de\\ncláusulas não satisfeitas (Hansen e Jaumard, 1990). Um algoritmo particularmente eficaz foi\\ndesenvolvido por Gu (1989) e de forma independente por Selman \\net al.\\n (1992), que o chamaram de\\nGSAT e mostraram que ele era capaz de resolver uma ampla gama de problemas difíceis muito\\nrapidamente. O algoritmo WALKSAT descrito no capítulo é devido a Selman \\net al\\n. (1996).\\nA “transição de fase” em satisfatibilidade de problemas \\nk-\\nSAT aleatórios foi observada pela\\nprimeira vez por Simon e Dubois (1989) e deu origem a uma grande quantidade de pesquisas teóricas\\ne empíricas — devida, em parte, à óbvia ligação com o fenômeno da transição de fase em física\\nestatística. Cheeseman \\net al.\\n (1991) observaram transições de fase em vários PSRs e conjecturaram\\nque todos os problemas NP-difíceis têm uma fase de transição. Crawford e Auton (1993) localizaram\\na transição 3-SAT em uma proporção cláusula/variável de cerca de 4,26, observando que isso\\ncoincide com picos acentuados no tempo de execução de seu resolvedor SAT. Cook e Mitchell', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 331}),\n",
       " Document(page_content='(1997) forneceram um resumo excelente de literatura anterior sobre o problema.\\nO estado atual do conhecimento teórico foi resumido por Achlioptas (2009). A \\nconjectura do\\nlimiar da satisfatibilidade\\n afirma que, para cada \\nk\\n, há um limiar nítido de satisfatibilidade \\nr\\nk\\n, tal que\\nquando o número de variáveis \\nn\\n → ∞, as instâncias abaixo do limiar são \\nsatisfatíveis\\n com\\nprobabilidade 1, enquanto aquelas acima do limiar são \\ninsatisfatíveis\\n com probabilidade 1. A\\nsuposição não foi provada completamente por Friedgut (1999): existe um limiar pronunciado, mas\\nsua localização pode depender de \\nn\\n, mesmo quando \\nn\\n → ∞. Apesar dos progressos significativos em\\nanálise assintótica da localização do limite para \\nk\\n grande (Achlioptas e Peres, 2004; Achlioptas \\net\\nal\\n., 2007), tudo o que pode ser provado para \\nk\\n = 3 é que ele está no intervalo [3,52; 4,51]. A teoria\\natual sugere que um pico no tempo de execução de um solucionador SAT não está necessariamente\\nrelacionado com o limiar da satisfatibilidade, mas com uma transição de fase na distribuição de\\nsolução e estrutura das instâncias de SAT. Os resultados empíricos, devidoa a Coarfa \\net al\\n. (2003)\\nsustentam essa visão. De fato, os algoritmos tais como \\npropagação de inspeção\\n (Parisi e Zecchina,\\n2002; Maneva \\net al.\\n, 2007) aproveitam propriedades especiais de instâncias SAT aleatórias\\npróximas ao limiar da satisfatibilidade e superam em muito os solucionadores SAT genéricos em tais\\ninstâncias.\\nAs melhores fontes de informação sobre satisfatibilidade, tanto teóricas como práticas, são o\\nHandbook of Satisfiability\\n (Biere \\net al\\n., 2009) e as \\nInternational Conferences on Theory and\\nApplications of Satisfiability Testing\\n regulares, conhecidas como SAT.\\nA ideia de construir agentes com lógica proposicional pode ser rastreada até o trabalho seminal de\\nMcCulloch e Pitts (1943), que iniciou o campo das redes neurais. Ao contrário da suposição popular,\\no documento estava preocupado com a implementação de um projeto de agente baseado em circuito\\nbooleano no cérebro. No entanto, agentes baseados em circuitos, que realizam a computação por\\npropagação de sinais nos circuitos de hardware em vez de executar algoritmos em computadores de\\nuso geral, receberam pouca atenção em IA. A exceção mais notável foi o trabalho de Stan\\nRosenschein (Rosenschein, 1985; Kaelbling e Rosenschein, 1990), que desenvolveu maneiras para\\ncompilar agentes baseados em circuito a partir de descrições declarativas do ambiente da tarefa (a\\nabordagem de Rosenschein foi descrita com algum pormenor na segunda edição deste livro). O\\ntrabalho de Rod Brooks (1986, 1989) demonstra a eficácia dos projetos baseados em circuito para\\ncontrolar robôs — um tema que ocupa o Capítulo 25. Brooks (1991) argumenta que os projetos com\\nbase em circuito são \\ntudo\\n o que é necessário para IA — que representação e raciocínio são pesados,\\ncaros e desnecessários. Em nossa opinião, nenhuma das abordagens é suficiente por si só. Williams\\net al.\\n (2003) mostram como um projeto de agente híbrido não muito diferente do nosso agente de\\nwumpus tem sido utilizado para controlar a nave espacial da Nasa, o planejamento de sequências de\\nações e o diagnóstico e recuperação das falhas.\\nO problema geral de manter o controle de um ambiente parcialmente observável foi introduzido\\npara representações baseadas em estado no Capítulo 4. Sua instanciação para as representações\\nproposicionais foi estudada por Amir e Russell (2003), que identificaram várias classes de\\nambientes que admitem algoritmos de estimação de estado eficientes e mostraram que, para várias\\noutras classes, o problema é intratável. O problema de \\nprojeção temporal\\n, que envolve determinar\\nque proposições se mantêm verdadeiras depois que uma sequência de ações foi executada, pode ser\\nvisto como um caso especial de estimação de estado com percepção vazia. Muitos autores estudaram', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 332}),\n",
       " Document(page_content='esse problema devido à sua importância em planejamento; alguns resultados sobre complexidade\\nimportantes foram estabelecidos por Liberatore (1997). A ideia de representar um estado de crença\\ncom proposições pode ser atribuída a Wittgenstein (1922).\\nA estimação do estado lógico, é claro, exige uma representação lógica dos efeitos das ações — um\\ndos principais problemas em IA desde o final dos anos 1950. A proposta dominante tem sido o\\nformalismo do \\ncálculo de situações\\n (McCarthy, 1963), que está expresso dentro da lógica de\\nprimeira ordem. Discutiremos o cálculo de situações e várias extensões e alternativas nos Capítulos\\n10 e 12. A abordagem adotada neste capítulo — utilizando índices temporais sobre variáveis \\nproposicionais — é mais restritiva, mas tem a vantagem da simplicidade. A abordagem geral,\\npersonificada no algoritmo SATPLAN, foi proposta por Kautz e Selman (1992). Gerações\\nposteriores de SATPLAN foram capazes de tirar vantagem dos avanços em solucionadores SAT,\\ndescritos anteriormente, e se manter entre as formas mais eficazes de resolver problemas difíceis\\n(Kautz, 2006).\\nO \\nproblema do persistência\\n foi reconhecido pela primeira vez por McCarthy e Hayes (1969).\\nMuitos pesquisadores consideraram o problema insolúvel dentro da lógica de primeira ordem e isso\\ngerou uma grande quantidade de pesquisa em lógicas não monotônicas. Filósofos, de Dreyfus (1972)\\na Crockett (1994), citaram o problema de persistência como um sintoma da falha inevitável de toda\\niniciativa em IA. A solução do problema de persistência com axiomas de estado sucessor é devida a\\nRay Reiter (1991). Thielscher (1999) identificou o problema de persistência inferencial como uma\\nideia separada e forneceu uma solução. Em retrospecto, pode-se observar que os agentes de\\nRosenschein (1985) utilizavam circuitos que implementaram axiomas de estado sucessor, mas\\nRosenschein não percebeu que com isso o problema de persistência estava em grande parte\\nresolvido. Foo (2001) explicou por que os modelos de teoria de controle de evento discreto,\\nnormalmente utilizados pelos engenheiros, não têm que lidar explicitamente com o problema de\\npersistência: porque eles estão lidando com previsão e controle, não com explicação e raciocínio\\nsobre situações contrafactuais.\\nOs resolvedores proposicionais modernos têm ampla aplicabilidade em aplicações industriais. A\\naplicação de inferência proposicional na síntese de hardware do computador é agora uma técnica-\\npadrão com muitas implementações de grande escala (Nowick \\net al\\n., 1993). O verificador de\\nsatisfatibilidade SATMC foi utilizado para detectar uma vulnerabilidade até então desconhecida em\\num protocolo de entrada de usuário de navegador da Web (Armando \\net al\\n., 2008).\\nO mundo de wumpus foi inventado por Gregory Yob (1975). Ironicamente, Yob o desenvolveu\\nporque estava entediado com jogos que se desenrolavam em tabuleiro retangular: a topologia de seu\\nmundo de wumpus original era um dodecaedro, e nós a colocamos de volta no velho e incômodo\\ntabuleiro. Michael Genesereth foi o primeiro a sugerir que o mundo de wumpus fosse usado como\\numa plataforma de testes de agentes.\\nEXERCÍCIOS\\n7.1\\n Suponha que o agente tenha progredido até o ponto mostrado na \\nFigura 7.4\\n(a), tendo percebido\\nnada em [1,1], uma brisa em [2,1] e um fedor em [1,2], e agora está preocupado com o conteúdo de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 333}),\n",
       " Document(page_content='[1,3], [2,2] e [3,1]. Cada uma dessas posições pode conter um poço e, no máximo, uma pode conter\\num wumpus. Seguindo o exemplo da \\nFigura 7.5\\n, construa o conjunto de mundos possíveis (você deve\\nencontrar 32 deles). Marque os mundos em que a BC é verdadeira e aqueles em que cada uma das\\nsentenças a seguir é verdadeira:\\nConsequentemente, mostre que \\n7.2\\n (Adaptado de Barwise e Etchemendy (1993).) Dada a sentença a seguir, você poderia demonstrar\\nque o unicórnio é mítico? E que é mágico? E que tem chifre?\\nSe o unicórnio é mítico, então é imortal; porém, se ele não é mítico, então é um mamífero mortal.\\nSe o unicórnio é imortal ou um mamífero, então ele tem chifre. O unicórnio é mágico se tem\\nchifre.\\n7.3\\n Considere o problema de decidir se uma sentença de lógica proposicional é verdadeira em\\ndeterminado modelo.\\na.\\n Escreva um algoritmo recursivo VERDADEIRO-LP?(\\ns\\n, \\nm\\n) que retorne \\nverdadeiro\\n se e somente\\nse a sentença \\ns\\n for verdadeira no modelo \\nm\\n (onde \\nm\\n atribui um valor-verdade a todo símbolo\\nem \\ns\\n). O algoritmo deve funcionar em tempo linear em relação ao tamanho da sentença. (Como\\nalternativa, use uma versão dessa função obtida no repositório de código on-line.)\\nb.\\n Forneça três exemplos de sentenças que possam ser definidas como verdadeiras ou falsas em\\num modelo \\nparcial\\n que não especifica um valor-verdade para alguns dos símbolos.\\nc.\\n Mostre que o valor-verdade (se houver) de uma sentença em um modelo parcial não pode ser\\ndeterminado de maneira eficiente no caso geral.\\nd.\\n Modifique seu algoritmo VERDADEIRO-LP? de forma que às vezes ele possa julgar a verdade\\na partir de modelos parciais, ao mesmo tempo em que mantém sua estrutura recursiva e seu\\ntempo de execução linear. Forneça três exemplos de sentenças cuja verdade em um modelo\\nparcial \\nnão\\n seja detectada pelo seu algoritmo.\\ne.\\n Investigue se o algoritmo modificado torna CONSEQUÊNCIA-LÓGICA-TV? mais eficiente.\\n7.4\\n Qual dos seguintes está correto?', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 334}),\n",
       " Document(page_content='7.5\\n Demonstre cada uma das asserções a seguir:\\na.\\n \\nα\\n é válida se e somente se \\nVerdadeiro\\n |= \\nα\\n.\\nb.\\n Para qualquer \\nα\\n, \\nFalso\\n |= \\nα\\n.\\nc.\\n \\nα\\n |= \\nβ\\n se e somente se a sentença (\\nα\\n \\n⇒\\n \\nβ\\n) é válida.\\nd.\\n \\nα\\n ≡ \\nβ\\n se e somente se a sentença (\\nα\\n \\n⇔\\n \\nβ\\n) é válida.\\ne.\\n \\nα\\n |= \\nβ\\n se e somente se a sentença (\\nα\\n \\n∧\\n ¬\\nβ\\n) é não satisfatível.\\n7.6\\n Demonstre ou encontre um contraexemplo para cada uma das seguintes asserções:\\n7.7\\n Considere um vocabulário com apenas quatro proposições, \\nA\\n, \\nB\\n, \\nC\\n e \\nD\\n. Quantos modelos existem\\npara as sentenças a seguir?\\na.\\n B \\n∨\\n C.\\nb.\\n ¬A \\n∨\\n ¬B \\n∨\\n ¬C \\n∨\\n ¬D.\\nc.\\n (A \\n⇒\\n B) \\n∧\\n A \\n∧\\n ¬B \\n∧\\n C \\n∧\\n D.\\n7.8\\n Definimos quatro conectivos lógicos binários diferentes.\\na.\\n Existem outros que possam ser úteis?\\nb.\\n Quantos conectivos binários podem existir?\\nc.\\n Por que alguns deles não são muito úteis?\\n7.9\\n Usando um método de sua escolha, verifique cada uma das equivalências da \\nFigura 7.11\\n.\\n7.10\\n Decida se cada uma das sentenças a seguir é válida, não satisfatível ou nenhuma dessas opções.\\nVerifique suas decisões usando tabelas-verdade ou as regras de equivalência da \\nFigura 7.11\\n.\\na.\\n \\nFumaça\\n \\n⇒\\n \\nFumaça\\nb.\\n \\nFumaça\\n \\n⇒\\n \\nFogo\\nc.\\n (\\nFumaça\\n \\n⇒\\n \\nFogo\\n) \\n⇒\\n (¬\\nFumaça\\n \\n⇒\\n \\n¬Fogo\\n)\\nd.\\n \\nFumaça\\n \\n∨\\n \\nFogo\\n \\n∨\\n ¬\\nFogo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 335}),\n",
       " Document(page_content='e.\\n ((\\nFumaça\\n \\n∧\\n \\nCalor\\n) \\n⇒\\n \\nFogo\\n) \\n⇔\\n ((\\nFumaça\\n \\n⇒\\n \\nFogo\\n) \\n∨\\n (\\nCalor\\n \\n⇒\\n \\nFogo\\n))\\nf.\\n (\\nFumaça\\n \\n⇒\\n \\nFogo\\n) \\n⇒\\n ((\\nFumaça\\n \\n∧\\n \\nCalor\\n) \\n⇒\\n \\nFogo\\n)\\ng.\\n \\nGande\\n \\n∨\\n \\nBurro\\n \\n∨\\n (\\nGrande\\n \\n⇒\\n \\nBurro\\n)\\n7.11\\n Qualquer sentença lógica proposicional é logicamente equivalente à asserção de que cada\\nmundo possível em que ela seria falsa não deveria ocorrer. A partir dessa observação, prove que\\nqualquer sentença pode ser escrita em FNC.\\n7.12\\n Utilize resolução para demonstrar a sentença ¬\\nA\\n∧\\n¬\\nB\\n das cláusulas no Exercício 7.20.\\n7.13\\n Este exercício examina o relacionamento entre cláusulas e sentenças de implicação.\\na.\\n Mostre que a cláusula (¬\\nP\\n1\\n∨\\n… \\n∨\\n¬\\nP\\nm\\n∨\\nQ\\n) é logicamente equivalente à sentença de\\nimplicação (\\nP\\n1\\n∧\\n… \\n∧\\n \\nP\\nm\\n) \\n⇒\\n \\nQ\\n.\\nb.\\n Mostre que toda cláusula (independentemente do número de literais positivos) pode ser escrita\\nna forma (\\nP\\n1\\n∧\\n…\\n∧\\n \\nP\\nm\\n) \\n⇒\\n (\\nQ\\n1\\n \\n∨\\n…\\n∨\\n \\nQ\\nn\\n), onde os valores de \\nP\\n e \\nQ\\n são símbolos de\\nproposições. Uma base de conhecimento que consiste em tais sentenças está em \\nforma normal\\nimplicativa\\n ou \\nforma de Kowalski\\n (Kowalski, 1979).\\nc.\\n Escreva a regra de resolução completa para sentenças em forma normal implicativa.\\n7.14\\n De acordo com alguns especialistas políticos, uma pessoa que é radical (\\nR\\n) é elegível (\\nE\\n) se for\\nconservadora (\\nC\\n), mas de oura forma não será elegível.\\na.\\n Quais das seguintes são representações corretas dessa afirmação?\\n(i) (\\nR\\n \\n∧\\n \\nE\\n) \\n⇔\\n \\nC\\n(ii) \\nR\\n \\n⇒\\n (\\nE\\n \\n⇔\\n (\\nC\\n)\\n(iii) \\nR\\n \\n⇒\\n ((\\nC\\n \\n⇒\\n \\nE\\n) \\n∨\\n ¬\\nE\\n)\\nb.\\n Quais das sentenças em (a) podem ser expressas na forma de Horn?\\n7.15\\n Esta questão considera a representação dos problemas de satisfatibilidade (SAT) como PSRs.\\na.\\n Desenhe o grafo de restrição correspondente ao problema SAT\\npara o caso particular de \\nn\\n = 5.\\nb.\\n Quantas soluções existem para este problema SAT geral como função de \\nn\\n?\\nc.\\n Suponha que apliquemos a BUSCA-POR-RETROCESSO para encontrar \\ntodas\\n as soluções para\\num SAT PSR do tipo dado em (a). (Para encontrar todas as soluções para um PSR,\\nsimplesmente modificamos o algoritmo básico de modo que ele continue a busca depois de\\nencontrar cada solução.) Suponha que as variáveis sejam ordenadas de X\\n1\\n,…, X\\nn\\n e \\nfalso\\n é\\nordenado antes de \\nverdadeiro\\n. Quanto tempo levará o algoritmo para terminar? (Escreva uma\\nexpressão \\nO\\n(·) como função de \\nn\\n.)\\nd.\\n Sabemos que os problemas SAT na forma de Horn podem ser resolvidos em tempo linear por\\nencadeamento para a frente (propagação unitária). Sabemos também que todos os PSRs binários', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 336}),\n",
       " Document(page_content='estruturados em árvore com domínios discretos, finitos, podem ser resolvidos em tempo linear\\npelo número de variáveis \\u200b\\u200b(\\nSeção 6.5\\n). Existe ligação entre esses dois fatos? Discuta.\\n7.16\\n Explique por que toda a cláusula proposicional não vazia, por sí só, é satisfatível. Prove\\nacuradamente que cada conjunto de cinco cláusulas 3-SAT é satisfatível, dado que cada cláusula\\nmenciona exatamente três variáveis distintas. Qual o menor conjunto dessas cláusulas que é\\ninsatisfatível? Construa tal conjunto.\\n7.17\\n Uma expressão proposicional 2-FNC é uma conjunção de cláusulas, cada uma contendo\\nexatamente 2 literais, isto é,\\na.\\n Utilizando resolução demonstre que a sentença acima tem como consequência lógica G.\\nb.\\n Duas cláusulas são \\nsemanticamente distintas\\n se não forem logicamente equivalentes. Quantas\\ncláusulas 2-FNC semanticamente distintas podem ser construídas de n símbolos proposicionais?\\nc.\\n Usando a resposta ao item (b), demonstre que a resolução proposicional sempre termina em\\ntempo polinomial em n dada uma sentença 2-FNC contendo não mais que n símbolos distintos.\\nd.\\n Explique por que o argumento no item (c) não se aplica a 3-FNC.\\n7.18\\n Considere a seguinte sentença:\\na.\\n Determine, utilizando enumeração, se essa sentença é válida, satisfatível (mas não válida),\\ninsatisfatível.\\nb.\\n Converta os lados esquerdo e direito da implicação principal em FNC, mostrando cada etapa, e\\nexplique como os resultados confirmam a sua resposta para (a).\\nc.\\n Demonstre a sua resposta para (a) utilizando resolução.\\n7.19\\n Uma sentença está na \\nforma normal disjuntiva\\n (FND), se for uma disjunção de conjunções de\\nliterais. Por exemplo, a sentença (\\nA\\n \\n∧\\n \\nB\\n \\n∧\\n ¬\\nC\\n) \\n∨\\n (¬ \\nA\\n \\n∧\\n \\nC\\n) \\n∨\\n (\\nB\\n \\n∧\\n ¬\\nC\\n) está em FND.\\na.\\n Qualquer sentença lógica proposicional é logicamente equivalente à afirmação de que algum\\nmundo possível no qual a sentença seria verdadeira é de fato o caso. A partir dessa observação,\\ndemonstre que qualquer sentença pode ser escrita em FND.\\nb.\\n Construa um algoritmo que converta qualquer sentença de lógica proposicional em FND. (\\nDica\\n:\\nO algoritmo é similar ao algoritmo de conversão para FNC dado na \\nSeção 7.5.2\\n.)\\nc.\\n Construa um algoritmo simples que tome como entrada uma sentença em FND e retorne uma\\nvaloração que a satisfaz, se existir, ou relate que nenhuma valoração satisfatória existe.\\nd.\\n Aplique os algoritmos em (b) e (c) para o seguinte conjunto de sentenças:\\nA\\n \\n⇒\\n \\nB\\nB\\n \\n⇒\\n \\nC\\nC\\n \\n⇒\\n ¬ \\nA\\n.\\ne.\\n Como o algoritmo em (b) é muito semelhante ao algoritmo de conversão para FNC, e como o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 337}),\n",
       " Document(page_content='algoritmo em (c) é muito mais simples do que qualquer algoritmo para resolver um conjunto de\\nsentenças em FNC, por que essa técnica não é utilizada no raciocínio automatizado?\\n7.20\\n Converta o seguinte conjunto de sentenças para a forma clausal.\\nS1: \\nA\\n \\n⇔\\n (\\nB\\n \\n∨\\n \\nE\\n).\\nS2: \\nE\\n \\n⇒\\n \\nD\\n.\\nS3: \\nC\\n \\n∧\\n \\nF\\n \\n⇒\\n ¬\\nB\\n.\\nS4: \\nE\\n \\n⇒\\n \\nB\\n.\\nS5: \\nB\\n \\n⇒\\n \\nF\\n.\\nS6: \\nB\\n \\n⇒\\n \\nC\\n.\\nApresente um rastreamento (trace) da execução de DPLL sobre o conjunto dessas cláusulas.\\n7.21\\n Uma sentença 4-FNC gerada randomicamente com \\nn\\n símbolos e \\nm\\n cláusulas é mais ou menos\\nprovável de ser resolvida do que uma sentença 3-FNC gerada aleatoriamente com \\nn\\n símbolos e \\nm\\ncláusulas? Explique.\\n7.22\\n Campo Minado, o conhecido jogo de computador, está intimamente relacionado ao mundo de\\nwumpus. Um mundo de campo minado é uma malha retangular de \\nN\\n quadrados com \\nM\\n minas\\ninvisíveis espalhadas entre eles. Qualquer quadrado pode ser sondado pelo agente; se uma mina for\\nsondada, segue-se a morte imediata. Campo Minado indica a presença de minas, revelando, em cada\\nquadrado sondado, o \\nnúmero\\n de minas adjacentes diretamente ou em diagonal. O objetivo é sondar\\ntodo quadrado não minado.\\na.\\n Seja X\\ni,j\\n verdadeira se e somente se o quadrado [\\ni\\n, \\nj\\n] contém uma mina. Anote a asserção de que\\nexatamente duas minas são adjacentes a [1,1] como uma sentença envolvendo alguma\\ncombinação lógica de X\\ni,j\\n proposições.\\nb.\\n Generalize sua asserção de (a) explicando como construir uma sentença FNC afirmando que \\nk\\ndentre \\nn\\n vizinhos contém minas.\\nc.\\n Explique exatamente como um agente pode usar DPLL para provar que determinado quadrado\\ncontém (ou não contém) uma mina, ignorando a restrição global de que existem exatamente \\nM\\nminas ao todo.\\nd.\\n Suponha que a restrição global seja construída por meio do seu método da parte (b). De que\\nmaneira o número de cláusulas depende de \\nM\\n e \\nN\\n? Sugira um modo de modificar DPLL para\\nque a restrição global não precise ser representada de forma explícita.\\ne.\\n Alguma conclusão derivada pelo método da parte (c) é invalidada quando a restrição global é\\nlevada em consideração?\\nf.\\n Forneça exemplos de configurações de valores de sondagem que induzem \\ndependência de longo\\nprazo\\n tais que o conteúdo de um dado quadrado não sondado forneceria informações sobre o\\nconteúdo de um quadrado muito distante. [\\nSugestão\\n: Considere um tabuleiro de \\nN\\n × 1.]\\n7.23\\n Quanto tempo demora para provar que \\nBC\\n |= \\nα\\n usando DPLL quando \\nα\\n é um literal \\njá contido\\nem BC\\n? Explique.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 338}),\n",
       " Document(page_content='7.24\\n Descreva o comportamento de DPLL na base de conhecimento da \\nFigura 7.16\\n quando se tenta\\nprovar \\nQ\\n e compare esse comportamento com o do algoritmo de encadeamento para a frente.\\n7.25\\n Escreva um axioma de estado sucessor para o predicado \\ntrancado\\n que se aplica a portas,\\nassumindo que as únicas ações disponíveis são \\ntrancado\\n e \\ndestrancado\\n.\\n7.26\\n A \\nSeção 7.7.1\\n fornece alguns dos axiomas de estado sucessor necessários para o mundo de\\nwumpus. Escreva os axiomas para todos os símbolos fluentes restantes.\\n \\n7.27\\n Modifique o AGENTE-WUMPUS-HÍBRIDO para utilizar o método de estimação de\\nestado lógico por 1-FCN (\\nSeção 7.7.3\\n). Naquela seção observamos que tal agente não será capaz de\\nadquirir, manter e utilizar crenças mais complexas como a da disjunção P\\n3,1\\n \\n∨\\n P\\n2, 2\\n. Sugira um\\nmétodo para superar esse problema através da definição de símbolos de proposição adicionais e os\\nexperimente no mundo de wumpus. Isso melhorará o desempenho do agente?\\n1\\n \\nLógica difusa\\n, discutida no Capítulo 14, permite graus de verdade.\\n2\\n Embora a figura mostre os modelos como mundos de wumpus parciais, na realidade eles não são nada além de atribuições de valores\\nverdadeiro\\n e \\nfalso\\n às sentenças “existe um poço em [1,2]” etc. Os modelos, em sentido matemático, não precisam conter “horríveis\\nmonstros cabeludos”.\\n3\\n O agente pode calcular a \\nprobabilidade\\n de existir um poço em [2,2]; o Capítulo 13 mostra como fazê-lo.\\n4\\n A verificação de modelos funciona se o espaço de modelos é finito — por exemplo, em mundos de wumpus de tamanho fixo. Por outro\\nlado, no caso da aritmética, o espaço de modelos é infinito: até mesmo se nos limitarmos aos inteiros, haverá infinitamente muitos pares\\nde valores para \\nx\\n e \\ny\\n na sentença \\nx\\n + \\ny\\n = 4.\\n5\\n Compare com o caso dos espaços de busca infinitos do Capítulo 3, em que a busca em profundidade não é completa.\\n6\\n Como define Wittgenstein (1922) em seu famosos \\nTractatus\\n: “O mundo é tudo que é o caso.”\\n7\\n O latim tem uma palavra diferente, \\naut\\n, para indicar o ou exclusivo.\\n8\\n As lógicas \\nnão monotônicas\\n, que violam a propriedade de monotonicidade, captam uma propriedade comum do raciocínio humano: a\\nmudança de ideia. Elas são discutidas na \\nSeção 12.6\\n.\\n9\\n Se uma cláusula for vista como um \\nconjunto\\n de literais, essa restrição será automaticamente respeitada. O uso da notação de\\nconjuntos para cláusulas torna a regra de resolução muito mais clara, ao custo de introduzir uma notação adicional.\\n10\\n A \\nSeção 7.4.3\\n explicou convenientemente sobre esse requisito.\\n11\\n O nome “problema de persistência” vem de “persistência de referência” em física — o segundo plano estacionário assumido em\\nrelação ao movimento que está sendo medido. Ele também faz analogia com os quadros (persistências) de um filme, em que\\nnormalmente a maior parte do segundo plano permanece constante, enquanto as mudanças ocorrem em primeiro plano.\\n12\\n Podemos pensar sobre a própria história da percepção como uma representação do estado de crença, mas que faz com que\\ninferências se tornem cada vez mais caras à medida que a história cresce.\\n13\\n Observe que a adição de axiomas de precondição significa que não precisamos incluir precondições para ações nos axiomas de estado\\nsucessor.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 339}),\n",
       " Document(page_content='N\\nCAPÍTULO\\n \\n8\\nLógica de primeira ordem\\nEm que notamos que o mundo é abençoado com muitos objetos, alguns dos\\nquais estão relacionados a outros objetos e em que nos empenhamos para\\nraciocinar sobre eles.\\no Capítulo 7, mostramos como um agente baseado em conhecimento poderia representar o mundo\\nem que opera e deduzir que ações executar. Usamos a lógica proposicional como nossa\\nlinguagem de representação porque ela foi suficiente para ilustrar os conceitos básicos de lógica\\ne agentes baseados em conhecimento. Infelizmente, a lógica proposicional é uma linguagem muito\\nfraca para representar o conhecimento de ambientes complexos de forma concisa. Neste capítulo,\\nexaminaremos a \\nlógica de primeira ordem\\n,\\n1\\n que é suficientemente expressiva para representar de\\nforma satisfatória nosso conhecimento comum. Ela também compõe ou forma os alicerces de muitas\\noutras linguagens de representação e foi intensivamente estudada por muitas décadas. Começamos na\\nSeção 8.1\\n com uma descrição das linguagens de representação em geral; a \\nSeção 8.2\\n focaliza a\\nsintaxe e a semântica da lógica de primeira ordem; as Seções 8.3 e 8.4 ilustram o uso da lógica de\\nprimeira ordem em representações simples.\\n8.1 UMA REVISÃO DA REPRESENTAÇÃO\\nNesta seção, discutiremos a natureza das linguagens de representação. Nossa discussão motivará o\\ndesenvolvimento da lógica de primeira ordem, uma linguagem muito mais expressiva que a lógica\\nproposicional introduzida no Capítulo 7. Estudaremos a lógica proposicional e outros tipos de\\nlinguagens para entender o que funciona e o que não funciona. Nossa discussão será superficial,\\ncompactando séculos de pensamento, tentativa e erro em alguns parágrafos.\\nAs linguagens de programação (como C++, Java ou Lisp) são sem dúvida a maior classe de\\nlinguagens formais em uso comum. Os programas propriamente ditos representam, em sentido direto,\\napenas processos computacionais. As estruturas de dados dentro de programas podem representar\\nfatos; por exemplo, um programa poderia usar um array 4 × 4 para representar o conteúdo do mundo\\nde wumpus. Desse modo, a declaração de linguagem de programação \\nMundo\\n[2,2] ← \\nPoço\\n é uma\\nforma bastante natural de afirmar que existe um poço no quadrado [2,2]. (Tais representações\\npoderiam ser consideradas \\nad hoc\\n; os sistemas de bancos de dados foram desenvolvidos exatamente', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 341}),\n",
       " Document(page_content='para fornecer um modo mais geral e independente de domínios para armazenar e recuperar fatos.) O\\nque falta às linguagens de programação é algum mecanismo geral para derivar fatos a partir de outros\\nfatos; cada atualização em uma estrutura de dados é feita por um procedimento específico do domínio\\ncujos detalhes são derivados pelo programador a partir de seu próprio conhecimento do domínio.\\nEssa abordagem procedural pode ser comparada com a natureza \\ndeclarativa\\n da lógica\\nproposicional, em que o conhecimento e a inferência estão separados, e a inferência é inteiramente\\nindependente de domínios.\\nUma segunda desvantagem das estruturas de dados em programas (e também dos bancos de dados)\\né a falta de qualquer meio fácil de se dizer, por exemplo, que “existe um poço em [2,2] ou [3,1]” ou\\n“Se o wumpus está em [1,1], então ele não está em [2,2]”. Os programas podem armazenar um valor\\núnico para cada variável, e alguns sistemas permitem que o valor seja “desconhecido”, mas lhes falta\\na capacidade de expressão necessária para manipular informações parciais.\\nA lógica proposicional é uma linguagem declarativa porque sua semântica se baseia em uma\\nrelação-verdade entre sentenças e mundos possíveis. Ela também tem capacidade expressiva\\nsuficiente para lidar com informações parciais, usando disjunção e negação. A lógica proposicional\\ntem uma terceira propriedade, que é interessante em linguagens de representação, isto é, a\\ncomposicionalidade\\n. Em uma linguagem composicional, o significado de uma sentença é uma função\\ndo significado de suas partes. Por exemplo, “\\nS\\n1,4\\n \\n∧\\n \\nS\\n1,2\\n” está relacionado aos significados de “\\nS\\n1,4\\n”\\ne “\\nS\\n1,2\\n”. Seria muito estranho se “\\nS\\n1,4\\n” significasse que existe um fedor no quadrado [1,4] e “\\nS\\n1,2\\n”\\nsignificasse que existe um fedor no quadrado [1,2], mas “\\nS\\n1,4\\n \\n∧\\n \\nS\\n1,2\\n” significasse que a França e a\\nPolônia empataram por 1×1 na partida de classificação do torneio de futebol da semana passada. É\\nclaro que a não omposicionalidade torna muito mais difícil a utilização do sistema de raciocínio.\\nEntreteanto, como vimos no Capítulo 7, a lógica proposicional se ressente da falta de capacidade\\nde expressão para descrever \\nde forma concisa\\n um ambiente com muitos objetos. Por exemplo, fomos\\nforçados a escrever uma regra separada sobre brisas e poços para cada quadrado, como:\\nPor outro lado, em linguagem natural, parece bastante fácil dizer de uma vez por todas que\\n“quadrados adjacentes a poços têm brisa”. A sintaxe e a semântica da linguagem natural tornam\\npossível de algum modo descrever o ambiente de forma concisa.\\n8.1.1 A linguagem do pensamento\\nAs linguagens naturais (como inglês ou espanhol) na realidade são muito expressivas.\\nConseguimos escrever este livro quase todo em linguagem natural, apenas com lapsos ocasionais em\\noutras linguagens (inclusive lógica, matemática e a linguagem dos diagramas). Existe uma longa\\ntradição em linguística e na filosofia da linguagem que visualiza a linguagem natural essencialmente\\ncomo uma linguagem declarativa de representação do conhecimento. Se pudéssemos descobrir as\\nregras para a linguagem natural, poderíamos usá-las nos sistemas de representação e raciocínio e\\nreceber o benefício de milhares de bilhões de páginas que foram escritas em linguagem natural.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 342}),\n",
       " Document(page_content='A visão moderna de linguagem natural é a de que ela serve como um meio de \\ncomunicação\\n em vez\\nde pura representação. Quando um falante aponta e diz “Olhe!”, o ouvinte sabe que, digamos, o\\nSuper-homem finalmente apareceu voando sobre os terraços dos prédios, ainda que não\\npretendêssemos dizer que a sentença “Olhe!” representa esse fato. Em vez disso, o significado da\\nsentença depende tanto da sentença em si quanto do \\ncontexto\\n em que ela foi dada. É claro que não se\\npoderia armazenar uma sentença como “Olhe!” em uma base de conhecimento e esperar recuperar\\nseu significado sem armazenar também uma representação do contexto — o que traz a questão de\\ncomo o próprio contexto pode ser representado. As linguagens naturais também sofrem de\\nambiguidade\\n, um problema para uma linguagem de representação. Conforme Pinker (1995)\\nmencionou: “Quando pensam em \\nbomba\\n, sem dúvida as pessoas não ficam confusas com o fato de\\nestarem pensando em um artefato explosivo, em um doce ou em um aparelho utilizado para bombear\\nágua de uma cisterna — e, se uma palavra pode corresponder a dois ou três pensamentos, então os\\npensamentos não podem ser palavras.”\\nA famosa \\nhipótese de Sapir-Whorf\\n afirma que nossa compreensão do mundo é fortemente\\ninfluenciada pela língua que falamos. Whorf (1956) escreveu: “Dividimos a natureza, organizamos\\nem conceitos e atribuímos os significados que atribuímos, em grande parte, porque somos partes de\\num acordo para organizá-la dessa forma — um acordo que mantém toda a nossa comunidade de fala e\\nestá codificado nos padrões de nossa língua.” É certamente verdade que as diferentes comunidades\\nde fala dividem o mundo de forma diferente. Os franceses têm duas palavras, “\\nchaise\\n” e “\\nfauteuil\\n”,\\npara um conceito para o qual os falantes de inglês têm um: “\\nchair\\n” (cadeira). Mas os falantes de\\ninglês conseguem reconhecer facilmente a categoria \\nfauteuil\\n e dar-lhe um nome — mais ou menos,\\n“cadeira de braço aberto” — então, a linguagem faz diferença realmente? Whorf baseou-se\\nessencialmente na intuição e especulação, mas nos anos seguintes nós realmente tivemos dados reais\\nde estudos antropológicos, psicológicos e neurológicos.\\nPor exemplo, você consegue lembrar-se sobre qual das duas sentenças seguintes compôs a\\nabertura da \\nSeção 8.1\\n?\\n“Nesta seção, discutiremos a natureza das linguagens de representação…”\\n“Esta seção cobre o tema das linguagens de representação do conhecimento…”\\nWanner (1974) fez uma experiência semelhante e constatou que os indivíduos fazem a escolha\\ncerta em um nível de chance — cerca de 50% do tempo —, mas lembram-se do conteúdo que leram\\ncom mais de 90% de precisão. Isso sugere que as pessoas processam as palavras para formar uma\\nespécie de representação \\nnão verbal\\n.\\nMais interessante é o caso de um conceito que está completamente ausente em um idioma. Os\\nfalantes da língua aborígene australiana \\nguugu yimithirr\\n não têm palavras para direções relativas,\\ntais como frente, trás, direita ou esquerda. Em vez disso, utilizam direções absolutas, dizendo, por\\nexemplo, o equivalente a “Tenho dor no meu braço do norte”. Essa diferença na linguagem traz uma\\ndiferença no comportamento: os falantes de \\nguugu yimithirr\\n são melhores para navegar em terreno\\naberto, enquanto os falantes de inglês são melhores em colocar o garfo à direita do prato.\\nA linguagem também parece influenciar o pensamento através de recursos gramaticais\\naparentemente arbitrários, como o gênero dos substantivos. Por exemplo, “ponte” é masculino em', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 343}),\n",
       " Document(page_content='espanhol e feminino em alemão. Boroditsky (2003) pediu aos indivíduos para escolher adjetivos\\ningleses para descrever uma fotografia de uma ponte em particular. Os falantes de espanhol\\nescolheram \\ngrande\\n, \\nperigosa\\n, \\nforte\\n e \\nelevada\\n; os falantes de alemão escolheram \\nbonita\\n, \\nelegante\\n,\\nfrágil\\n e \\ndelgada\\n. As palavras podem servir como pontos de ancoragem que afetam a maneira como\\npercebemos o mundo. Loftus e Palmer (1974) mostraram um filme de um acidente de carro para\\nindivíduos experimentais. Para o questionamento “A que velocidade iam os carros quando houve o\\ncontato?”, a resposta foi 51 km por hora, e quando foi usada a palavra “colisão” em vez de “contato”\\no relato foi uma média de 66 km por hora, para os mesmos carros no mesmo filme.\\nEm um sistema de raciocínio de lógica de primeira ordem que usa FNC, podemos ver que a forma\\nlinguística “¬ (A \\n∨\\n B)” e “¬A \\n∧\\n ¬ B” é a mesma porque podemos olhar para dentro do sistema e\\nver que as duas sentenças são armazenadas com a mesma forma canônica FNC. Podemos fazer isso\\ncom o cérebro humano? Até recentemente, a resposta era “não”, mas agora é “talvez”. Mitchell \\net al.\\n(2008) colocaram indivíduos em uma máquina IRMf (imagem por ressonância magnética funcional),\\nmostraram-lhes palavras como “aipo” e formaram a imagem de seus cérebros. Os pesquisadores\\nforam capazes de treinar um programa de computador que previa, a partir da imagem cerebral, que\\npalavra fora apresentada para o indivíduo. Dadas duas opções (por exemplo, “aipo” ou “avião”), o\\nsistema previu corretamente em 77% das vezes. O sistema pode até mesmo prever em um nível\\nsuperior a 50% palavras que nunca tinha visto em uma imagem IRMf antes (considerando-se as\\nimagens de palavras relacionadas) e de pessoas que nunca havia visto antes (provando que a IRMf\\nrevela algum nível de representação comum entre as pessoas). Esse tipo de trabalho ainda está no\\ninício, mas a IRMf (e outras tecnologias de imagem comoa eletrofisiologia intracraniana (Sahin \\net\\nal.,\\n 2009)) prometem nos dar ideias muito mais concretas de como são as representações do\\nconhecimento humano.\\nDo ponto de vista da lógica formal, a representação do mesmo conhecimento de duas maneiras\\ndiferentes não faz absolutamente nenhuma diferença; os mesmos fatos serão deriváveis de qualquer\\nrepresentação.\\nNa prática, porém, uma representação pode exigir menos etapas para obter uma conclusão, o que\\nsignifica que um raciocinador com recursos limitados poderia chegar à conclusão através de uma\\nrepresentação, mas não através de outra. Para tarefas \\nnão dedutivas\\n, como aprender da experiência,\\nos resultados dependem \\nnecessariamente\\n da forma utilizada de representações. Mostraremos no\\nCapítulo 18 que, quando um programa de aprendizado considera duas teorias do mundo possíveis, as\\nduas compatíveis com todos os dados, a forma mais comum de resolver o empate é escolher a teoria\\nmais sucinta — que depende da linguagem utilizada para representar as teorias. Assim, a influência\\nda linguagem sobre o pensamento é inevitável para qualquer agente que faz aprendizado.\\n8.1.2 Combinando o melhor de linguagens formais e naturais\\nPodemos adotar os fundamentos da lógica proposicional — uma semântica declarativa,\\ncomposicional, independente do contexto e não ambígua — e construir uma lógica mais expressiva\\nsobre esses fundamentos, tomando emprestadas ideias de representação da linguagem natural, ao\\nmesmo tempo em que evitamos suas desvantagens. Quando examinamos a sintaxe da linguagem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 344}),\n",
       " Document(page_content='natural, os elementos mais óbvios são substantivos e sentenças nominais que se referem a \\nobjetos\\n(quadrados, poços, wumpus), além de verbos e sentenças verbais que se referem a \\nrelações\\n entre\\nobjetos (é arejado, é adjacente a, atira). Algumas dessas relações são \\nfunções\\n — relações em que\\nexiste somente um “valor” para uma dada “entrada”. É fácil começar a listar exemplos de objetos,\\nrelações e funções:\\n•  Objetos: pessoas, casas, números, teorias, Ronald McDonald, cores, jogos de beisebol, guerras,\\nséculos…\\n•  Relações: podem ser relações unárias ou \\npropriedades\\n como vermelho, redondo, falso, primo,\\nde vários pavimentos…, ou relações \\nn\\n-árias mais gerais, como irmão de, maior que, interior a,\\nparte de, tem cor, ocorreu depois de, pertence a, fica entre…\\n•  Funções: pai de, melhor amigo, terceiro turno de, uma unidade maior que, início de…\\nNa verdade, praticamente qualquer asserção pode ser considerada uma referência a objetos e\\npropriedades ou relações. Aqui estão alguns exemplos:\\n•  “Um mais dois é igual a três.”\\nObjetos: um, dois, três, um mais dois. Relação: é igual a. Função: mais. (“Um mais dois” é um\\nnome para o objeto obtido pela aplicação da função “mais” aos objetos “um” e “dois”. Três é\\noutro nome para esse objeto.)\\n•  “Quadrados vizinhos ao wumpus são fedorentos.”\\nObjetos: wumpus, quadrados. Propriedade: fedorento. Relação: vizinhos.\\n•  “O perverso rei João governou a Inglaterra em 1200.”\\nObjetos: João, Inglaterra, 1200. Relação: governou. Propriedades: perverso, rei.\\nA linguagem da \\nlógica de primeira ordem\\n, cuja sintaxe e cuja semântica definiremos na próxima\\nseção, é elaborada em torno de objetos e relações. Ela é tão importante para a matemática, a filosofia\\ne a inteligência artificial exatamente porque podemos considerar que esses campos — e, na\\nrealidade, grande parte da existência humana diária — refletem o tratamento de objetos e das\\nrelações entre eles. A lógica de primeira ordem também pode expressar fatos sobre \\nalguns\\n ou \\ntodos\\nos objetos no universo. Isso nos permite representar leis ou regras gerais, como a declaração:\\n“Quadrados vizinhos ao wumpus são fedorentos.”\\nA principal diferença entre a lógica proposicional e a lógica de primeira ordem reside no\\ncompromisso ontológico\\n feito por cada linguagem, isto é, o que ela pressupõe sobre a natureza da\\nrealidade\\n. Matematicamente, esse comprometimento é expresso através da natureza dos \\nmodelos\\nformais em relação a qual verdade das sentenças foi definida. Por exemplo, a lógica proposicional\\npressupõe que existem fatos que são válidos ou não são válidos no mundo. Cada fato pode se\\nencontrar em um destes dois estados, verdadeiro ou falso, e cada modelo determina \\nverdadeiro ou\\nfalso\\n para cada símbolo de proposição (veja a \\nSeção 7.4.2\\n).\\n2\\n A lógica de primeira ordem pressupõe\\nmais do que isso; especificamente, que o mundo consiste em objetos com certas relações entre eles\\nque são ou não são válidas. Os modelos formais são correspondentemente mais complicados que os\\nda lógica proposicional. Lógicas com propósitos especiais criam ainda outros compromissos\\nontológicos; por exemplo, a \\nlógica temporal\\n pressupõe que os fatos são válidos em \\ninstantes', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 345}),\n",
       " Document(page_content='particulares e que esses instantes (que podem ser pontos ou intervalos) estão ordenados. Desse\\nmodo, as lógicas com propósitos especiais dão a certos tipos de objetos (e aos axiomas sobre eles)\\nstatus\\n de “primeira classe” dentro da lógica, em vez de simplesmente definirem esses objetos na\\nbase de conhecimento. A \\nlógica de alta ordem\\n visualiza as relações e funções referidas à lógica de\\nprimeira ordem como objetos em si. Isso permite que se façam asserções sobre \\ntodas\\n as relações —\\npor exemplo, poderíamos desejar definir o que significa o fato de uma relação ser transitiva.\\nDiferentemente da maioria das lógicas com propósitos especiais, a lógica de alta ordem é\\nestritamente mais expressiva que a lógica de primeira ordem, no sentido de que algumas sentenças de\\nlógica de alta ordem não podem ser expressas por qualquer número finito de sentenças de lógica de\\nprimeira ordem.\\nUma lógica também pode ser caracterizada por seus \\ncompromissos epistemológicos\\n — os estados\\npossíveis de conhecimento que ela permite a respeito de cada fato. Tanto na lógica proposicional\\nquanto na lógica de primeira ordem, uma sentença representa um fato, e o agente acredita que a\\nsentença é verdadeira, acredita que ela é falsa ou não tem nenhuma opinião. Então, essas lógicas têm\\ntrês estados possíveis de conhecimento a respeito de qualquer sentença. Por outro lado, os sistemas\\nque utilizam a \\nteoria da probabilidade\\n podem ter qualquer \\ngrau de crença\\n, variando de 0 (descrença\\ntotal) até 1 (crença total).\\n3\\n Por exemplo, um agente probabilístico de mundo de wumpus poderia\\nacreditar que o wumpus está em [1,3] com probabilidade 0,75. Os compromissos ontológicos e\\nepistemológicos de cinco lógicas diferentes estão resumidos na \\nFigura 8.1\\n.\\nLinguagem\\nCompromisso ontológico (o que\\nexiste no mundo)\\nCompromisso epistemológico (a crença de\\num agente sobre os fatos)\\nLógica\\nproposicional\\nLógica de\\nprimeira ordem\\nLógica temporal\\nTeoria da\\nprobabilidade\\nLógica difusa\\nfatos\\nfatos, objetos, relações\\nfatos, objetos, relações, tempo\\nfatos\\nfatos com grau de verdade \\n∊\\n [0,\\n1]\\nverdadeiro/falso/desconhecido\\nverdadeiro/falso/desconhecido\\nverdadeiro/falso/desconhecido\\ngrau de crença \\n∊\\n [0, 1]\\nvalor de intervalo conhecido\\nFigura 8.1\\n Linguagens formais e seus compromissos ontológicos e epistemológicos.\\nNa próxima seção, iniciaremos o estudo dos detalhes da lógica de primeira ordem. Da mesma\\nmaneira que um aluno de física deve ter alguma familiaridade com matemática, um aluno de IA deve\\ndesenvolver um talento para trabalhar com notação lógica. Por outro lado, também é importante \\nnão\\nficar muito preocupado com as \\nparticularidades\\n da notação lógica — afinal, existem dezenas de\\nversões diferentes. Os principais itens a apreender são a forma como a linguagem facilita\\nrepresentações concisas e como sua semântica leva a procedimentos de raciocínio consistentes.\\n8.2 SINTAXE E SEMÂNTICA DA LÓGICA DE PRIMEIRA ORDEM', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 346}),\n",
       " Document(page_content='Iniciaremos esta seção especificando com maior exatidão a ideia de que os mundos possíveis da\\nlógica de primeira ordem refletem o compromisso ontológico com objetos e relações. Em seguida,\\nintroduziremos os vários elementos da linguagem, explicando sua semântica à medida que\\nprosseguirmos.\\n8.2.1 Modelos para lógica de primeira ordem\\nVimos, no Capítulo 7, que os modelos de uma linguagem lógica são as estruturas formais que\\nconstituem os mundos possíveis sob consideração. Cada modelo liga o vocabulário das sentenças\\nlógicas aos elementos do mundo possível, para que a verdade de qualquer sentença possa ser\\ndeterminada. Assim, modelos de lógica proposicional ligam símbolos de proposição com valores-\\nverdade predefinidos. Os modelos para lógica de primeira ordem são muito mais interessantes. Em\\nprimeiro lugar, eles contêm objetos! O \\ndomínio\\n de um modelo é o conjunto de objetos ou \\nelementos\\ndo domínio\\n que ele contém. Exige-se que o domínio seja \\nnão vazio\\n — todos os mundos possíveis\\ndevem conter pelo menos um objeto (veja o Exercício 8.7 para uma discussão de mundos vazios).\\nMatematicamente falando, não importa o \\nque\\n são esses objetos — tudo o que importa é \\nquantos\\n há\\nem cada modelo em particular —, mas, para fins pedagógicos, vamos utilizar um exemplo concreto.\\nA \\nFigura 8.2\\n mostra um modelo com cinco objetos: Ricardo Coração de Leão, rei da Inglaterra de\\n1189 até 1199; seu irmão mais jovem, o perverso rei João, que governou de 1199 até 1215; a perna\\nesquerda de Ricardo e de João; uma coroa.\\nFigura 8.2\\n Modelo contendo cinco objetos, duas relações binárias, três relações unárias (indicadas\\npor rótulos nos objetos) e uma função unária, perna esquerda.\\nOs objetos no modelo podem estar \\nrelacionados\\n de diversas maneiras. Na figura, Ricardo e João\\nsão irmãos. Formalmente falando, uma relação é apenas o conjunto de \\ntuplas\\n de objetos inter-', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 347}),\n",
       " Document(page_content='relacionados. (Uma tupla é uma coleção de objetos organizados em uma ordem fixa e é representada\\npor colchetes angulares em torno dos objetos.) Desse modo, a relação “irmão” nesse modelo é o\\nconjunto\\n(Aqui nos referimos aos objetos em linguagem natural, mas você pode, se desejar, substituir\\nmentalmente os nomes pelas figuras.) A coroa está na cabeça do rei João, então a relação “na\\ncabeça” contém apenas uma tupla, \\n〈\\ncoroa, rei João\\n〉\\n. As relações “irmão” e “na cabeça” são\\nrelações binárias, isto é, relacionam pares de objetos. O modelo também contém relações unárias ou\\npropriedades: a propriedade “pessoa” é verdadeira para Ricardo e para João; a propriedade “rei” é\\nverdadeira apenas para João (presumivelmente porque nesse momento Ricardo está morto); e a\\npropriedade “coroa” é verdadeira apenas para coroa.\\nÉ melhor pensar em certos tipos de relacionamentos como se fossem funções, nas quais\\ndeterminado objeto deve estar relacionado a exatamente um objeto desse modo. Por exemplo, cada\\npessoa tem uma perna esquerda, então o modelo tem uma função unária “perna esquerda” que inclui\\nos seguintes mapeamentos:\\nEstritamente falando, modelos em lógica de primeira ordem exigem \\nfunções totais\\n, isto é, deve\\nhaver um valor para toda tupla de entrada. Desse modo, a coroa deve ter uma perna esquerda assim\\ncomo cada uma das pernas esquerdas deve ter uma perna esquerda. Existe uma solução técnica para\\nesse problema esquisito envolvendo um objeto “invisível” adicional que é a perna esquerda de tudo\\nque não tem perna esquerda, inclusive ele próprio. Felizmente, desde que não se faça nenhuma\\nafirmação sobre as pernas esquerdas de itens que não têm pernas esquerdas, esses detalhes técnicos\\nnão têm nenhuma importância.\\nAté agora, descrevemos os elementos que preenchem modelos de lógica de primeira ordem. Outra\\nparte essencial de um modelo é a ligação entre esses elementos e o vocabulário das sentenças\\nlógicas, que explicaremos a seguir.\\n8.2.2 Símbolos e interpretações\\nVejamos agora a sintaxe da linguagem. O leitor impaciente pode obter uma descrição completa da\\ngramática formal da lógica de primeira ordem na \\nFigura 8.3\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 348}),\n",
       " Document(page_content='Figura 8.3\\n Sintaxe da lógica de primeira ordem com igualdade, especificada na forma de Backus-\\nNaur. A precedência dos operadores é especificada do mais alto para o mais baixo. A precedência\\ndos quantificadores é tal que um quantificador se aplica a tudo à sua direita.\\nOs elementos sintáticos básicos da lógica de primeira ordem são os símbolos que representam\\nobjetos, relações e funções. Por essa razão, os símbolos são de três tipos: \\nsímbolos de constantes\\n,\\nque representam objetos, \\nsímbolos de predicados\\n, que representam relações, e \\nsímbolos de funções\\n,\\nque representam funções. Adotaremos a convenção de que esses símbolos começarão com letras\\nmaiúsculas. Por exemplo, poderíamos usar os símbolos de constantes \\nRicardo\\n e \\nJoão\\n, os símbolos\\nde predicados, \\nIrmão\\n, \\nNaCabeça\\n, \\nPessoa\\n, \\nRei\\n e \\nCoroa\\n e o símbolo de função \\nPernaEsquerda\\n.\\nComo ocorre com os símbolos de proposições, a escolha de nomes cabe inteiramente ao usuário.\\nCada símbolo de predicado e de função vem com uma \\naridade\\n que fixa o número de argumentos.\\nComo na lógica proposicional, cada modelo deve fornecer a informação necessária para\\ndeterminar se dada sentença é verdadeira ou falsa. Assim, além de seus objetos, relações e funções,\\ncada modelo inclui uma \\ninterpretação\\n que especifique exatamente quais objetos, relações e funções\\nsão referidos pelos símbolos de constantes, predicados e funções. Uma interpretação possível para\\nnosso exemplo — que um lógico chamaria de \\ninterpretação pretendida\\n — é:\\n•  \\nRicardo\\n se refere a Ricardo Coração de Leão e \\nJoão\\n se refere ao perverso rei João.\\n•  \\nIrmão\\n se refere à relação de fraternidade, ou seja, o conjunto de tuplas de objetos dado na\\nEquação 8.1; \\nNaCabeça\\n se refere à relação “na cabeça” que é válida entre a coroa e o rei João;\\nPessoa\\n, \\nRei\\n e \\nCoroa\\n se referem aos conjuntos de objetos que são pessoas, reis e coroas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 349}),\n",
       " Document(page_content='•  \\nPernaEsquerda\\n se refe\\nre à função\\n “\\nperna esqu\\nerda”, isto é, ao mapeamento definido pela\\nEquação 8.2.\\nCertamente existem muitas outras interpretações possíveis. Por exemplo, uma interpretação mapeia\\nRicardo\\n à coroa e \\nJoão\\n à perna esquerda do rei João. Existem cinco objetos no modelo; portanto,\\nexistem 25 interpretações possíveis apenas para os símbolos de constantes \\nRicardo\\n e \\nJoão\\n. Note que\\nnem todos os objetos precisam ter um nome — por exemplo, a interpretação pretendida não atribui\\nnomes à coroa ou às pernas. Também é possível um objeto ter vários nomes; existe uma interpretação\\nsob a qual tanto \\nRicardo\\n quanto \\nJoão\\n se referem à coroa.\\n4\\n Se achar essa possibilidade confusa,\\nlembre-se de que, em lógica proposicional, é perfeitamente possível haver um modelo em que\\nNublado\\n e \\nEnsolarado\\n sejam verdadeiros; cabe à base de conhecimento eliminar modelos\\ninconsistentes com nosso conhecimento.\\nEm resumo, um modelo em lógica de primeira ordem consiste em um conjunto de objetos e uma\\ninterpretação que mapeia de símbolos de constantes a objetos, de símbolos de predicados às\\nrelações sobre esses objetos, e de símbolos de função às funções desses objetos. Assim como com a\\nlógica proposicional, a consequência lógica, a validade, e assim por diante, são definidas em termos\\nde \\ntodos os modelos possíveis\\n. Para se ter uma ideia de como se parece o conjunto de todos os\\nmodelos possíveis, veja a \\nFigura 8.4\\n. Ela mostra que os modelos variam dependendo de quantos\\nobjetos contêm — de um até o infinito — e na forma como os símbolos de constantes mapeiam os\\nobjetos. Se houver dois símbolos de constantes e um objeto, ambos os símbolos devem se referir ao\\nmesmo objeto, mas isso ainda pode acontecer até mesmo com mais objetos. Quando houver mais\\nobjetos que símbolos de constantes, alguns dos objetos não terão nomes. Devido ao número de\\nmodelos possíveis ser ilimitado, verificar a consequência lógica pela enumeração de todos os\\nmodelos possíveis não é viável para a lógica de primeira ordem (ao contrário da lógica\\nproposicional). Mesmo se o número de objetos for restrito, o número de combinações pode ser muito\\ngrande (veja o Exercício 8.5). Por exemplo, na \\nFigura 8.4\\n, existem 137.506.194.466 modelos com\\nseis ou menos objetos.\\nFigure 8.4\\n Alguns membros do conjunto de todos os modelos para uma linguagem com dois símbolos\\nde constantes, \\nR e J\\n, e um símbolo de relação binária. A interpretação de cada símbolo de constante\\né mostrada pela seta cinza. Dentro de cada modelo, os objetos relacionados são conectados por\\nsetas.\\n8.2.3 Termos\\nUm \\ntermo\\n é uma expressão lógica que se refere a um objeto. Os símbolos de constantes são', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 350}),\n",
       " Document(page_content='portanto termos, mas nem sempre é conveniente ter um símbolo distinto para identificar todo objeto.\\nPor exemplo, em linguagem natural poderíamos usar a expressão “perna esquerda do rei João” em\\nlugar de dar um nome à perna. Essa é a finalidade dos símbolos de funções: em vez de usar um\\nsímbolo de constante, utilizamos \\nPernaEsquerda\\n(\\nJoão\\n). No caso geral, um termo complexo é\\nformado por um símbolo de função seguido por uma lista entre parênteses de termos como\\nargumentos para o símbolo de função. É importante lembrar que um termo complexo é apenas uma\\nespécie complicada de nome. Não é uma “chamada de sub-rotina” que “retorna um valor”. Não\\nexiste nenhuma sub-rotina \\nPernaEsquerda\\n que receba uma pessoa como entrada e retorne uma perna.\\nPodemos raciocinar sobre pernas esquerdas (por exemplo, enunciando a regra geral de que todo\\nmundo tem uma, e depois deduzindo que João deve ter uma perna esquerda), sem sequer fornecermos\\numa definição de \\nPernaEsquerda\\n. Isso é algo que não pode ser feito com sub-rotinas em linguagens\\nde programação.\\n5\\nA semântica formal dos termos é direta. Considere um termo \\nf\\n(t\\n1\\n,…, \\nt\\nn\\n). O símbolo de função \\nf\\n se\\nrefere a alguma função no modelo (vamos chamá-la \\nF\\n); os termos de argumentos se referem a objetos\\nno domínio (vamos chamá-los \\nd\\n1\\n,…, \\nd\\nn\\n); e o termo como um todo se refere ao objeto que é o valor\\nda função \\nF\\n aplicada a \\nd\\n1\\n,…, \\nd\\nn\\n. Por exemplo, suponha que o símbolo de função \\nPernaEsquerda\\n se\\nrefira à função mostrada na Equação 8.2 e \\nJoão\\n se refira ao rei João; então, \\nPernaEsquerda\\n(\\nJoão\\n) se\\nrefere à perna esquerda do rei João. Desse modo, a interpretação fixa o referente de todo termo.\\n8.2.4 Sentenças atômicas\\nAgora que temos termos para fazer referência a objetos e símbolos de predicados para fazer\\nreferência a relações, podemos reuni-los para formar \\nsentenças atômicas\\n que enunciam fatos.\\nUma \\nsentença atômica\\n (ou \\nátomo\\n, para encurtar) é formada a partir de um símbolo de predicado,\\nseguido por uma lista de termos entre parênteses:\\nIrmão\\n(\\nRicardo\\n, \\nJoão\\n)\\nIsso enuncia, sob a interpretação pretendida apresentada anteriormente, que Ricardo Coração de\\nLeão é o irmão do rei João.\\n6\\n As sentenças atômicas podem ter termos complexos como argumentos.\\nDesse modo,\\nCasado\\n(\\nPai\\n(\\nRicardo\\n), \\nMãe\\n(\\nJoão\\n))\\nenuncia que o pai de Ricardo Coração de Leão é casado com a mãe do rei João (mais uma vez, sob\\numa interpretação apropriada).\\n \\nUma sentença atômica é\\n \\nverdadeira\\n \\nem dado modelo\\n, \\nsob dada interpretação\\n, \\nse a relação\\nreferida pelo símbolo de predicado é válida entre os objetos referidos pelos argumentos\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 351}),\n",
       " Document(page_content='8.2.5 Sentenças complexas\\nPodemos usar \\nconectivos lógicos\\n para construir sentenças mais complexas, com a mesma sintaxe e\\nsemântica que no cálculo proposicional. Aqui estão quatro sentenças que são verdadeiras no modelo\\nda \\nFigura 8.2\\n, sob nossa interpretação pretendida:\\n¬\\nIrmão\\n(\\nPernaEsquerda\\n(\\nRicardo\\n), \\nJoão\\n)\\nIrmão\\n(\\nRicardo\\n, \\nJoão\\n) \\n∧\\n \\nIrmão\\n(\\nJoão\\n, \\nRicardo\\n)\\nRei\\n(\\nRicardo\\n) \\n∨\\n \\nRei\\n(\\nJoão\\n)\\n¬\\nRei\\n(\\nRicardo\\n) \\n⇒\\n \\nRei\\n(\\nJoão\\n)\\n8.2.6 Quantificadores\\nUma vez que temos uma lógica que permite objetos, não deixa de ser natural querer expressar\\npropriedades de coleções inteiras de objetos, em vez de enumerar os objetos pelo nome. Os\\nquantificadores\\n nos permitem fazê-lo. A lógica de primeira ordem contém dois quantificadores-\\npadrão, chamados \\nuniversal\\n e \\nexistencial\\n.\\nQuantificação universal (\\n∀\\n)\\nLembre-se da dificuldade que tivemos no Capítulo 7 com a expressão de regras gerais em lógica\\nproposicional. Regras como “Quadrados vizinhos ao wumpus são fedorentos” e “Todos os reis são\\npessoas” são comuns em lógica de primeira ordem. Lidaremos com a primeira dessas regras na\\nSeção 8.3\\n. A segunda regra, “Todos os reis são pessoas”, é escrita em lógica de primeira ordem\\ncomo\\n∀\\nx Rei\\n(\\nx\\n) \\n⇒\\n \\nPessoa\\n(\\nx\\n).\\nNormalmente, \\n∀\\n é lido como “Para todo…” ou “Para todos…” (lembre-se de que o A invertido\\nrepresenta “todos” ou “\\nall\\n” em inglês). Desse modo, a sentença afirma que “Para todo \\nx\\n, se \\nx\\n é um\\nrei, então \\nx\\n é uma pessoa”.\\nO símbolo \\nx\\n é chamado \\nvariável\\n. Por convenção, as variáveis são letras minúsculas. Uma variável\\né um termo por si só e, como tal, também pode servir como o argumento de uma função — por\\nexemplo, \\nPernaEsquerda\\n(\\nx\\n). Um termo sem variáveis é chamado \\ntermo base\\n (ground term).\\nIntuitivamente, a sentença \\n∀\\nx P\\n, onde \\nP\\n é qualquer expressão lógica, afirma que \\nP\\n é verdadeira\\npara todo objeto \\nx\\n. Mais precisamente, \\n∀\\nx P\\n é verdadeira em dado modelo se \\nP\\n é verdadeira em\\ntodas as \\ninterpretações estendidas\\n possíveis construídas a partir da interpretação dada ao modelo,\\nem que cada interpretação estendida especifica um elemento de domínio ao qual \\nx\\n se refere.\\nIsso parece complicado, mas, na realidade, é apenas um modo cuidadoso de declarar o significado\\nintuitivo da quantificação universal. Considere o modelo mostrado na \\nFigura 8.2\\n e a interpretação\\npretendida que o acompanha. Podemos estender a interpretação de cinco maneiras:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 352}),\n",
       " Document(page_content='x\\n → Ricardo Coração de Leão,\\nx\\n → rei João,\\nx\\n → perna esquerda de Ricardo,\\nx\\n → perna esquerda de João,\\nx\\n → a coroa.\\nA sentença universalmente quantificada \\n∀\\nx Rei\\n (\\nx\\n) \\n⇒\\n \\nPessoa\\n(\\nx\\n) é verdadeira no modelo original\\nse a sentença \\nRei\\n(\\nx\\n) \\n⇒\\n \\nPessoa\\n(\\nx\\n) é verdadeira sob cada uma das cinco interpretações estendidas. Ou\\nseja, a sentença universalmente quantificada é equivalente a afirmar as cinco sentenças a seguir:\\nRicardo Coração de Leão é um rei \\n⇒\\n Ricardo Coração de Leão é uma pessoa.\\nO rei João é um rei \\n⇒\\n O rei João é uma pessoa.\\nA perna esquerda de Ricardo é um rei \\n⇒\\n A perna esquerda de Ricardo é uma pessoa.\\nA perna esquerda de João é um rei \\n⇒\\n A perna esquerda de João é uma pessoa.\\nA coroa é um rei \\n⇒\\n A coroa é uma pessoa.\\nVamos examinar cuidadosamente esse conjunto de asserções. Tendo em vista que em nosso\\nmodelo o rei João é o único rei, a segunda sentença afirma que ele é uma pessoa, como seria de\\nesperar. Porém, e no caso das outras quatro sentenças, que parecem fazer afirmações sobre pernas e\\ncoroas? Isso faz parte do significado de “Todos os reis são pessoas”? De fato, as outras quatro\\nasserções são verdadeiras no modelo, mas não fazem nenhuma afirmação sobre as qualificações\\npessoais de pernas, coroas ou nem mesmo de Ricardo. Isso ocorre porque nenhum desses objetos é\\num rei. Observando a tabela-verdade para \\n⇒\\n (\\nFigura 7.8\\n), vemos que a implicação é verdadeira\\nsempre que sua premissa é falsa, \\nnão importando\\n o valor-verdade da conclusão. Desse modo,\\nafirmando a sentença universalmente quantificada, equivalente a afirmar uma lista inteira de\\nimplicações individuais, acabamos afirmando a conclusão da regra apenas para os objetos para os\\nquais a premissa é verdadeira, e não dizendo absolutamente nada sobre os indivíduos para os quais a\\npremissa é falsa. Portanto, a definição de \\n⇒\\n da tabela-verdade se mostra perfeita para a escrita de\\nregras gerais com quantificadores universais.\\nUm equívoco comum, que ocorre com frequência, mesmo no caso de leitores diligentes que leram\\nesse parágrafo várias vezes, é usar a conjunção em vez da implicação. A sentença\\n∀\\n \\nx Rei\\n(\\nx\\n) \\n∧\\n \\nPessoa\\n(\\nx\\n)\\nseria equivalente a afirmar\\nRicardo Coração de Leão é um rei \\n∧\\n Ricardo Coração de Leão é uma pessoa,\\nRei João é um rei \\n∧\\n Rei João é uma pessoa,\\nA perna esquerda de Ricardo é um rei \\n∧\\n A perna esquerda de Ricardo é uma pessoa,\\ne assim por diante. É óbvio que isso não capta o que queremos.\\nQuantificação existencial (\\n∃\\n)\\nA quantificação universal faz declarações sobre todo objeto. De modo semelhante, podemos fazer', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 353}),\n",
       " Document(page_content='uma declaração sobre \\nalgum\\n objeto no universo sem nomeá-lo, utilizando um quantificador\\nexistencial. Por exemplo, para dizer que o rei João tem uma coroa em sua cabeça, escrevemos:\\n∃\\nx Coroa\\n(\\nx\\n) \\n∧\\n \\nNaCabeça\\n(\\nx\\n, \\nJoão\\n).\\n∃\\nx\\n é lido como “Existe um \\nx\\n tal que…” ou “Para algum \\nx\\n…”.\\nIntuitivamente, a sentença \\n∃\\nx P\\n afirma que \\nP\\n é verdadeira para pelo menos um objeto \\nx\\n. Mais\\nprecisamente, \\n∃\\nx P\\n é verdadeira em dado modelo sob dada interpretação se \\nP\\n é verdadeira em \\npelo\\nmenos uma\\n interpretação estendida que atribua \\nx\\n a um elemento de domínio. Ou seja, pelo menos\\numa das afirmações a seguir deve ser verdadeira:\\nRicardo Coração de Leão é uma coroa \\n∧\\n Ricardo Coração de Leão está na cabeça de João;\\nRei João é uma coroa \\n∧\\n Rei João está na cabeça de João;\\nA perna esquerda de Ricardo é uma coroa \\n∧\\n A perna esquerda de Ricardo está na cabeça de\\nJoão;\\nA perna esquerda de João é uma coroa \\n∧\\n A perna esquerda de João está na cabeça de João;\\nA coroa é uma coroa \\n∧\\n A coroa está na cabeça de João.\\nA quinta afirmação é verdadeira no modelo e, assim, a sentença existencialmente quantificada\\noriginal é verdadeira no modelo. Note que, por nossa definição, a sentença também seria verdadeira\\nem um modelo no qual o rei João estivesse usando duas coroas. Isso é inteiramente consistente com a\\nsentença original “O rei João tem uma coroa em sua cabeça”.\\n7\\nDa mesma maneira que \\n⇒\\n parece ser o conectivo natural a usar com \\n∀\\n, \\n∧\\n é o conectivo natural a\\nusar com \\n∃\\n. O uso de \\n∧\\n como o principal conectivo com \\n∀\\n levou a uma declaração forte demais\\nno exemplo da seção anterior; o uso de \\n⇒\\n com \\n∃\\n em geral conduz a uma declaração muito fraca.\\nConsidere a sentença a seguir:\\n∃\\nx Coroa\\n(\\nx\\n) \\n⇒\\n \\nNaCabeça\\n(\\nx\\n, \\nJoão\\n).\\nÀ primeira vista, talvez ela pareça ser uma apresentação razoável de nossa sentença. Aplicando a\\nsemântica, vemos que a sentença afirma que pelo menos uma das asserções a seguir é verdadeira:\\nRicardo Coração de Leão é uma coroa \\n⇒\\n Ricardo Coração de Leão está na cabeça de João;\\nRei João é uma coroa \\n⇒\\n Rei João está na cabeça de João;\\nA perna esquerda de Ricardo é uma coroa \\n⇒\\n A perna esquerda de Ricardo está na cabeça de\\nJoão;\\ne assim por diante. Agora uma implicação é verdadeira se tanto a premissa quanto a conclusão são\\nverdadeiras \\nou se sua premissa é falsa\\n. Assim, se Ricardo Coração de Leão não é uma coroa, a\\nprimeira afirmação é verdadeira e a existencial é satisfeita. Desse modo, uma sentença de implicação\\nexistencialmente quantificada é verdadeira quando \\nqualquer\\n objeto falhar em satisfazer a premissa;\\npor conseguinte, tais sentenças de fato não dizem muito.\\nQuantificadores aninhados', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 354}),\n",
       " Document(page_content='Com frequência, desejaremos expressar sentenças mais complexas usando vários quantificadores.\\nO caso mais simples é aquele em que os quantificadores são do mesmo tipo. Por exemplo, a sentença\\n“Irmãos são parentes” pode ser escrita como:\\n∀\\nx\\n \\n∀\\ny Irmão\\n(\\nx\\n, \\ny\\n) \\n⇒\\n \\nParente\\n(\\nx\\n, \\ny\\n).\\nQuantificadores consecutivos do mesmo tipo podem ser escritos como um único quantificador com\\ndiversas variáveis. Por exemplo, para dizer que o parentesco é um relacionamento simétrico,\\npodemos escrever:\\n∀\\nx\\n, \\ny Parente\\n(\\nx\\n, \\ny\\n) \\n⇔\\n \\nParente\\n(\\ny\\n, \\nx\\n).\\nEm outros casos, teremos misturas. “Todo mundo ama alguém” quer dizer que, para toda pessoa,\\nexiste alguém que essa pessoa ama:\\n∀\\nx\\n \\n∃\\ny Ama\\n(\\nx\\n, \\ny\\n).\\nPor outro lado, para dizer que “Existe alguém que é amado por todo mundo”, escrevemos:\\n∃\\ny\\n \\n∀\\nx Ama\\n(\\nx\\n, \\ny\\n).\\nPortanto, a ordem de quantificação é muito importante. Ela fica mais clara se inserimos parênteses.\\n∀\\nx\\n (\\n∃\\ny Ama\\n(\\nx\\n, \\ny\\n)) nos diz que \\ntodo mundo\\n tem uma propriedade específica, ou seja, a propriedade\\nde que alguém os ama. Por outro lado, \\n∃\\nx\\n (\\n∀\\ny Ama\\n(\\nx\\n, \\ny\\n)) nos informa que \\nalguém\\n no mundo tem\\numa propriedade específica, isto é, a propriedade de ser amado por todo mundo.\\nÉ possível que surja alguma confusão quando dois quantificadores forem usados com o mesmo\\nnome de variável. Considere a sentença\\n∀\\nx\\n (\\nCoroa\\n(\\nx\\n) \\n∨\\n (\\n∃\\nx Irmão\\n(\\nRicardo, x\\n))).\\nNesse caso, o \\nx\\n em \\nIrmão\\n(\\nRicardo\\n, \\nx\\n) é \\nexistencialmente\\n quantificado. De acordo com a regra, a\\nvariável pertence ao quantificador mais interno que a menciona; então, ela não estará sujeita a\\nqualquer outra quantificação. Outro modo de pensar sobre isso é \\n∃\\nx Irmão\\n(\\nRicardo\\n, \\nx\\n) é uma\\nsentença sobre Ricardo (afirmando que ele tem um irmão) e não sobre \\nx\\n; assim, a colocação de \\n∀\\nx\\ndo lado de fora dos parênteses não tem nenhum efeito.\\nIsso poderia ser escrito igualmente bem como \\n∃\\nz Irmão\\n(\\nRicardo\\n, \\nz\\n). Tendo em vista que isso\\npode ser a origem de alguma confusão, sempre utilizaremos nomes de variáveis diferentes com\\nquantificadores aninhados.\\nConexões entre \\n∀\\n e \\n∃\\nNa realidade, os dois quantificadores estão intimamente conectados um ao outro por meio da\\nnegação. Afirmar que todo mundo detesta cenouras é o mesmo que afirmar que não existe alguém que\\ngoste delas e vice-versa:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 355}),\n",
       " Document(page_content='∀\\nx\\n ¬\\nGosta\\n(\\nx\\n, \\nCenouras\\n) é equivalente a ¬\\n∃\\nx Gosta\\n(\\nx\\n, \\nCenouras\\n).\\nPodemos ir um passo adiante: “Todo mundo gosta de sorvete” significa que não existe ninguém\\nque não goste de sorvete:\\n∀\\nx Gosta\\n(\\nx\\n, \\nSorvete\\n) é equivalente a ¬\\n∃\\nx\\n ¬\\nGosta\\n(\\nx\\n, \\nSorvete\\n).\\nTendo em vista que \\n∀\\n é realmente uma conjunção sobre o universo de objetos e \\n∃\\n é uma\\ndisjunção, não deve surpreender que eles obedeçam às regras de De Morgan. As regras de De\\nMorgan para sentenças quantificadas e não quantificadas são as seguintes:\\nDesse modo, na realidade, não precisamos de ambos \\n∀\\n e de \\n∃\\n, da mesma forma que não\\nprecisamos realmente de \\n∧\\n e \\n∨\\n. Ainda assim, a legibilidade é mais importante que a parcimônia e,\\nportanto, continuaremos utilizando ambos os quantificadores.\\n8.2.7 Igualdade\\nA lógica de primeira ordem inclui mais um meio de criar sentenças atômicas, além de usar um\\npredicado e termos da maneira descrita anteriormente. Podemos usar o \\nsímbolo de igualdade\\nsignificando que dois termos se referem ao mesmo objeto. Por exemplo,\\nPai\\n(\\nJoão\\n) = \\nHenrique\\nnos diz que o objeto referido por \\nPai\\n(\\nJoão\\n) e o objeto referido por \\nHenrique\\n são iguais. Como uma\\ninterpretação fixa o referente de qualquer termo, a determinação da verdade de uma sentença de\\nigualdade é simplesmente uma questão de ver que os referentes dos dois termos são o mesmo objeto.\\nO símbolo de igualdade pode ser usado para enunciar fatos sobre uma dada função, como\\nacabamos de fazer para o símbolo \\nPai\\n. Ele também pode ser empregado com a negação para insistir\\nno fato de que dois termos não são o mesmo objeto. Para dizer que Ricardo tem pelo menos dois\\nirmãos, escreveríamos:\\n∃\\nx\\n, \\ny Irmão\\n(\\nx, Ricardo\\n) \\n∧\\n \\nIrmão\\n(\\ny, Ricardo\\n) \\n∧\\n ¬(\\nx\\n = \\ny\\n).\\nA sentença\\n∃\\nx\\n, \\ny Irmão\\n(\\nx, Ricardo\\n) \\n∧\\n \\nIrmão\\n(\\ny, Ricardo\\n)\\nnão tem o significado pretendido. Em particular, ela é verdadeira no modelo da \\nFigura 8.2\\n, em que\\nRicardo tem apenas um irmão. Para constatar esse fato, considere a interpretação estendida em que\\ntanto \\nx\\n quanto \\ny\\n são atribuídos ao rei João. A adição de ¬(\\nx\\n = \\ny\\n) elimina tais modelos. A notação \\nx\\n ≠', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 356}),\n",
       " Document(page_content='y\\n às vezes é usada como abreviatura para ¬(\\nx\\n = \\ny\\n).\\n8.2.8 Uma semântica alternativa?\\nContinuando o exemplo da seção anterior, suponha que acreditemos que Ricardo tem dois irmãos,\\nJoão e Godofredo.\\n8\\n Podemos capturar esse estado de coisas, afirmando\\nNão é bem assim. Em primeiro lugar, essa afirmação é verdadeira em um modelo em que Ricardo\\ntem apenas um irmão — precisamos adicionar \\nJohn ≠ Godofredo\\n. Segundo, a sentença não descarta\\nmodelos em que Ricardo tenha muito mais irmãos além de Godofrredo e João. Assim, a tradução\\ncorreta de “os irmãos de Ricardo são João e Godofredo” é a seguinte:\\nIrmão\\n(\\nJoão, Ricardo\\n) \\n∧\\n \\nIrmão(Godofredo, Ricardo\\n) \\n∧\\n \\nJoão ≠ Godofredo\\n∧∀\\nx Irmão\\n (\\nx, Ricardo\\n) \\n⇒\\n (\\nx = João\\n \\n∨\\n \\nx = Godofredo).\\nPara muitos propósitos, isso parece muito mais enfadonho do que a expressão em linguagem\\nnatural correspondente. Como consequência, os seres humanos podem cometer erros na tradução do\\nseu conhecimento em lógica de primeira ordem, resultando em comportamentos não intuitivos de\\nsistemas de raciocínio lógico que usam o conhecimento. Podemos conceber uma semântica que\\npermita uma expressão lógica mais simples?\\nUma proposta que é muito popular em sistemas de banco de dados funciona da seguinte forma. Em\\nprimeiro lugar, insistimos que cada símbolo constante refere-se a um objeto distinto — a chamada\\nhipótese de nomes únicos\\n. Em segundo lugar, assumimos que as sentenças atômicas que não\\nsabemos se são verdadeiras são na verdade falsas — a \\nhipótese de mundo fechado\\n. Finalmente,\\ninvocamos o \\nfechamento de domínio\\n, o que significa que cada modelo não contém mais elementos\\nde domínio do que os nomeados pelos símbolos constantes. Sob a semântica resultante, que\\nchamamos de \\nsemântica de banco de dados\\n para distingui-la da semântica-padrão da lógica de\\nprimeira ordem, a equação da sentença 8.3 de fato afirma que os dois irmãos de Ricardo são João e\\nGodofredo. A semântica de banco de dados é também usada em sistemas de lógica de programação,\\ncomo explicado na \\nSeção 9.4.5\\n.\\nÉ instrutivo considerar o conjunto de todos os modelos possíveis sob a semântica de banco de\\ndados para o mesmo caso, como mostrado na \\nFigura 8.4\\n. A \\nFigura 8.5\\n mostra alguns dos modelos,\\nque vai desde o modelo sem tuplas que satisfaçam a relação até o modelo com todas as tuplas que\\nsatisfaçam a relação. Com dois objetos, existem quatro tuplas possíveis de dois elementos, por isso\\nhá 2\\n4\\n = 16 diferentes subconjuntos de tuplas que podem satisfazer a relação. Assim, existem 16\\nmodelos possíveis ao todo — bem menos que a infinita quantidade de modelos para a semântica\\npadrão de primeira ordem. Por outro lado, a semântica de banco de dados requer conhecimento\\npreciso do que o mundo contém.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 357}),\n",
       " Document(page_content='Figura 8.5\\n Alguns membros do conjunto de todos os modelos de uma linguagem com dois símbolos\\nde constantes, \\nR\\n e \\nJ\\n, e um símbolo de relação binária, sob a semântica de banco de dados. A\\ninterpretação dos símbolos de constantes é fixa e há um objeto distinto para cada símbolo de\\nconstante.\\nEsse exemplo traz à tona um ponto importante: não há uma semântica “correta” para a lógica. A\\nutilidade de qualquer semântica proposta depende de quão concisa e intuitiva ela torna a expressão\\ndos tipos de conhecimento que queremos descrever e o quanto é fácil e natural desenvolver as\\nrespectivas regras de inferência. A semântica de banco de dados é mais útil quando temos certeza\\nsobre a identidade de todos os objetos descritos na base de conhecimento e quando temos todos os\\nfatos à mão; em outros casos, é quase impraticável. Para o resto deste capítulo, assumiremos a\\nsemântica-padrão, enquanto observamos casos em que essa escolha leva a expressões desajeitadas.\\n8.3 UTILIZAÇÃO DA LÓGICA DE PRIMEIRA ORDEM\\nAgora que definimos uma linguagem lógica expressiva, é hora de aprender a usá-la. A melhor\\nmaneira de fazer isso é empregar exemplos. Vimos algumas sentenças simples que ilustram os\\ndiversos aspectos da sintaxe lógica; nesta seção, forneceremos representações mais sistemáticas de\\nalguns \\ndomínios\\n simples. Em representação do conhecimento, um domínio é simplesmente alguma\\nparte do mundo sobre a qual desejamos expressar algum conhecimento.\\nComeçaremos com uma breve descrição da interface TELL/ASK para bases de conhecimento de\\nprimeira ordem. Em seguida, examinaremos os domínios de relacionamentos de família, números,\\nconjuntos e listas, e também o mundo de wumpus. A próxima seção contém um exemplo mais\\nsignificativo (circuitos eletrônicos), e o Capítulo 12 aborda tudo o que existe no universo.\\n8.3.1 Asserções e consultas em lógica de primeira ordem\\nAs sentenças são adicionadas a uma base de conhecimento usando-se TELL, exatamente como na\\nlógica proposicional. Tais sentenças são chamadas \\nasserções\\n. Por exemplo, podemos afirmar que\\nJoão é um rei, Ricardo é uma pessoa e que reis são pessoas:\\nTELL(\\nBC\\n, \\nRei\\n(\\nJoão\\n)).\\nTELL(\\nBC\\n, Pessoa(\\nRicardo\\n)).\\nTELL(\\nBC\\n, \\n∀\\n \\nx Rei\\n(\\nx\\n) \\n⇒\\n \\nPessoa\\n(\\nx\\n)).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 358}),\n",
       " Document(page_content='Podemos formular perguntas sobre a base de conhecimento utilizando ASK. Por exemplo,\\nASK(\\nBC\\n, \\nRei\\n(\\nJoão\\n))\\nretorna \\nverdadeiro\\n. Perguntas formuladas com o uso de ASK são chamadas \\nconsultas\\n ou \\nmetas\\n. De\\nmodo geral, qualquer consulta que seja consequência lógica da base de conhecimento deve ser\\nrespondida afirmativamente. Por exemplo, dadas as duas asserções precedentes, a consulta\\nASK(\\nBC\\n, \\nPessoa\\n(\\nJoão\\n))\\ntambém deve retornar \\nverdadeiro\\n. Além disso, podemos formular consultas quantificadas, como:\\nASK(\\nBC\\n, \\n∃\\n \\nx Pessoa\\n(\\nx\\n)).\\nA resposta é \\nverdadeira\\n, mas isso talvez não seja tão útil como gostaríamos. Isso é bem\\nsemelhante a responder à pergunta “Pode me dizer a hora?” com “Sim”. Se quisermos saber que\\nvalor de \\nx\\n torna a sentença verdadeira, vamos precisar de uma função diferente, A\\nSK\\nV\\nARS\\n, que\\nchamamos com\\nA\\nSK\\nV\\nARS\\n (\\nBC\\n, Pessoa (x))\\ne que produz um fluxo de respostas. Nesse caso, haverá duas respostas: {\\nx\\n/ João} e {\\nx\\n/ Ricardo}.\\nTal resposta é chamada de \\nsubstituição\\n ou \\nlista de vinculação\\n. Normalmente, A\\nSK\\nV\\nARS\\n é reservado\\npara bases de conhecimento constituídas exclusivamente por cláusulas de Horn, porque em tais bases\\ntodas as maneiras de tornar a consulta verdadeira irão vincular as variáveis a valores específicos.\\nNão é o caso para a lógica de primeira ordem; se houver, na \\nBC\\n, \\nRei\\n(\\nJoão\\n) \\n∨\\n \\nRei\\n(\\nRicardo\\n), não há\\nnenhuma vinculação para \\nx\\n para a consulta \\n∃\\nx\\n \\nRei\\n(\\nx\\n), mesmo que a consulta seja verdadeira.\\n8.3.2 O domínio de parentesco\\nO primeiro exemplo que iremos considerar é o domínio de relacionamentos familiares ou de\\nparentesco. Esse domínio inclui fatos como “Elizabeth é a mãe de Charles” e “Charles é o pai de\\nWilliam”, e regras como “a avó de uma pessoa é a mãe do pai ou da mãe de uma pessoa”.\\nÉ claro que os objetos em nosso domínio são pessoas. Teremos dois predicados unários,\\nMasculino\\n e \\nFeminino\\n. As relações de parentesco — paternidade, fraternidade, casamento, e assim\\npor diante — serão representadas por predicados binários: \\nPaiOuMãe\\n, \\nIrmãoOuIrmã\\n, \\nIrmão\\n, \\nIrmã\\n,\\nFilhaOuFilho\\n, \\nFilha\\n, \\nFilho\\n, \\nCônjuge\\n, \\nEsposa\\n, \\nMarido\\n, \\nAvôOuAvó\\n, \\nNetoOuNeta\\n, \\nPrimo\\n, \\nTia\\n e \\nTio\\n.\\n9\\nUsaremos funções para representar \\nMãe\\n e \\nPai\\n porque toda pessoa tem exatamente um de cada um\\ndeles (pelo menos de acordo com o projeto da natureza).\\nPodemos acompanhar cada função e predicado anotando o que sabemos em termos dos outros\\nsímbolos. Por exemplo, a mãe de alguém é o pai ou mãe feminino deste alguém:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 359}),\n",
       " Document(page_content='∀\\nm\\n, \\nc Mãe\\n(\\nc\\n) = \\nm\\n \\n⇔\\n \\nFeminino\\n(\\nm\\n) \\n∧\\n \\nPaiOuMãe\\n(\\nm\\n, \\nc\\n).\\nO marido de alguém é o cônjuge masculino de alguém:\\n∀\\nw\\n, \\nh Marido\\n(\\nh\\n, \\nw\\n) \\n⇔\\n \\nMasculino\\n(\\nh\\n) \\n∧\\n \\nCônjuge\\n(\\nh\\n, \\nw\\n).\\nMasculino e feminino são categorias disjuntas:\\n∀\\nx Masculino\\n(\\nx\\n) \\n⇔\\n ¬\\nFeminino\\n(\\nx\\n).\\nPaiOuMãe e FilhoOuFilha são relações inversas:\\n∀\\np\\n, \\nc PaiOuMãe\\n(\\np\\n, \\nc\\n) \\n⇔\\n \\nFilhoOuFilha\\n(\\nc\\n, \\np\\n).\\nUm Avô ou avó é pai ou mãe do pai ou da mãe de alguém:\\n∀\\ng\\n, \\nc AvôOuAvó\\n(\\ng\\n, \\nc\\n) \\n⇔\\n \\n∃\\np PaiOuMãe\\n(\\ng\\n, \\np\\n) \\n∧\\n \\nPaiOuMãe\\n(\\np\\n, \\nc\\n).\\nUm irmão ou irmã é outro filho ou filha dos pais de alguém:\\n∀\\nx\\n, \\ny IrmãoOuIrmã\\n(\\nx\\n, \\ny\\n) \\n⇔\\n \\nx ≠\\n \\ny\\n \\n∧\\n \\n∃\\np PaiOuMãe\\n(\\np\\n, \\nx\\n) \\n∧\\n \\nPaiOuMãe\\n(\\np\\n, \\ny\\n).\\nPoderíamos continuar por várias outras páginas como esse assunto; o Exercício 8.14 lhe pede para\\nfazer exatamente isso.\\nCada uma dessas sentenças pode ser vista como um \\naxioma\\n do domínio de parentesco, como\\nexplicado na \\nSeção 7.1\\n. Em geral, os axiomas estão associados a domínios puramente matemáticos\\n— veremos em breve alguns axiomas referentes a números —, mas eles são necessários em todos os\\ndomínios. Os axiomas fornecem as informações factuais básicas a partir das quais podem ser\\nderivadas conclusões úteis. Nossos axiomas de parentesco também são \\ndefinições\\n; eles têm a forma\\n∀\\nx\\n,\\ny P\\n(\\nx\\n, \\ny\\n) \\n⇔\\n …. Os axiomas definem a função \\nMãe\\n e os predicados \\nMarido\\n, \\nMasculino\\n,\\nPaiOuMãe\\n, \\nAvôOuAvó\\n e \\nIrmãoOuIrmã\\n em termos de outros predicados. Nossas definições se\\nreduzem a um conjunto básico de predicados (\\nFilhoOuFilha\\n, \\nCônjuge\\n e \\nFeminino\\n) em cujos termos\\nos outros são definidos em última instância. Essa é uma forma muito natural de construir a\\nrepresentação de um domínio, e é análoga ao modo como os pacotes de software são elaborados por\\nmeio de definições sucessivas de sub-rotinas a partir de funções primitivas de biblioteca. Note que\\nnão existe necessariamente um conjunto único de predicados primitivos; poderíamos igualmente ter\\nutilizado \\nPaiOuMãe\\n, \\nCônjuge\\n e \\nMasculino\\n. Em alguns domínios, como mostraremos, não há nenhum\\nconjunto básico claramente identificável.\\nNem todas as sentenças lógicas sobre um domínio são axiomas. Algumas são \\nteoremas\\n, isto é, são\\nconsequência lógica dos axiomas. Por exemplo, considere a asserção de que a relação de irmãos é\\nsimétrico:\\n∀\\nx\\n, \\ny IrmãoOuIrmã\\n(\\nx\\n, \\ny\\n) \\n⇔\\n \\nIrmãoOuIrmã\\n(\\ny\\n, \\nx\\n).\\nIsso é um axioma ou um teorema? De fato, é um teorema que decorre logicamente do axioma que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 360}),\n",
       " Document(page_content='define o parentesco. Se formularmos (com ASK) essa sentença à base de conhecimento, ela deverá\\nretornar \\nverdadeiro\\n.\\nDe um ponto de vista puramente lógico, uma base de conhecimento só precisa conter axiomas e\\nnão teoremas, porque os teoremas não aumentam o conjunto de conclusões que se seguem da base de\\nconhecimento. Do ponto de vista prático, os teoremas são essenciais para reduzir o custo\\ncomputacional da derivação de novas sentenças. Sem eles, um sistema de raciocínio tem de começar\\na partir de princípios fundamentais o tempo todo, como se fosse um físico obrigado a redefinir as\\nregras do cálculo a cada novo problema.\\nNem todos os axiomas são definições. Alguns fornecem informações mais gerais sobre certos\\npredicados sem constituir uma definição. Na realidade, alguns predicados não têm nenhuma definição\\ncompleta porque não sabemos o bastante para caracterizá-los plenamente. Por exemplo, não existe\\nnenhuma forma óbvia definitiva de completar a sentença:\\n∀\\nx Pessoa\\n(\\nx\\n) \\n⇔\\n …\\nFelizmente, a lógica de primeira ordem nos permite fazer uso do predicado \\nPessoa\\n sem defini-lo\\ncompletamente. Em vez disso, podemos escrever especificações parciais de propriedades que toda\\npessoa tem e propriedades que tornam algo uma pessoa:\\n∀\\nx Pessoa\\n(\\nx\\n) \\n⇒\\n …\\n∀\\nx\\n … \\n⇐\\n \\nPessoa\\n(\\nx\\n).\\nOs axiomas também podem ser “apenas fatos simples”, como \\nMasculino\\n(\\nJim\\n) e \\nCônjuge\\n(\\nJim\\n,\\nLaura\\n). Tais fatos formam as descrições de instâncias específicas de problemas, permitindo que\\nperguntas específicas sejam respondidas. As respostas a essas perguntas serão então teoremas que\\ndecorrem dos axiomas. Com frequência, descobrimos que as respostas esperadas não estão\\ndisponíveis — por exemplo, de \\nCônjuge\\n(\\nJim, Laura\\n) espera-se (segundo as leis de muitos países)\\npoder inferir ¬\\nCônjuge\\n(\\nGeorge, Laura\\n), mas isso não se origina dos axiomas dados anteriormente\\n— mesmo depois de adicionarmos \\nJim ≠ George\\n, como sugerido na \\nSeção 8.2.8\\n. Esse é um sinal de\\nque está faltando um axioma. O Exercício 8.8 lhe pede para fornecê-lo.\\n8.3.3 Números, conjuntos e listas\\nOs números talvez sejam o exemplo mais vívido de como uma grande teoria pode ser construída a\\npartir de um minúsculo núcleo de axiomas. Descreveremos aqui a teoria dos \\nnúmeros naturais\\n ou\\ninteiros não negativos. Precisaremos de um predicado \\nNumNat\\n que será verdadeiro sobre os\\nnúmeros naturais, de um símbolo de constante, o 0, e ainda de um símbolo de função, \\nS\\n (sucessor).\\nOs \\naxiomas de Peano\\n definem números naturais e a adição.\\n10\\n Os números naturais são definidos\\nrecursivamente:\\nNumNat\\n(0).\\n∀\\nn NumNat\\n(\\nn\\n) \\n⇒\\n \\nNumNat\\n(\\nS\\n(\\nn\\n)).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 361}),\n",
       " Document(page_content='Isto é, 0 é um número natural e, para todo objeto \\nn\\n, se \\nn\\n é um número natural, então \\nS\\n(\\nn\\n) é um\\nnúmero natural. Assim, os números naturais são 0, \\nS\\n(0), \\nS\\n(\\nS\\n(0)), e assim por diante. (Depois de ler a\\nSeção 8.2.8\\n, você vai notar que esses axiomas permitem outros números naturais, além dos usuais;\\nveja o Exercício 8.12.) Também precisamos de axiomas para restringir a função sucessora:\\n∀\\nn\\n 0 \\n≠\\n \\nS\\n(\\nn\\n).\\n∀\\nm\\n, \\nn m\\n \\n≠\\n \\nn\\n \\n⇒\\n \\nS\\n(\\nm\\n) \\n≠\\n \\nS\\n(\\nn\\n).\\nAgora, podemos definir a adição em termos da função sucessora:\\n∀\\nm NumNat\\n(\\nm\\n) \\n⇒\\n + (0, \\nm\\n) = \\nm\\n.\\n∀\\nm\\n, \\nn NumNat\\n(\\nm\\n) \\n∧\\n \\nNumNat\\n(\\nn\\n) \\n⇒\\n + (\\nS\\n(\\nm\\n), \\nn\\n) = \\nS\\n(+(\\nm\\n, \\nn\\n)).\\nO primeiro desses axiomas afirma que a adição de 0 a qualquer número natural \\nm\\n fornece o\\npróprio \\nm\\n. Note o uso do símbolo de função binária “+” no termo +(\\nm\\n, 0); em matemática comum, o\\ntermo seria escrito como \\nm\\n + 0 usando-se a notação \\ninfixa\\n (a notação que usamos na lógica de\\nprimeira ordem é chamada \\nprefixa\\n).\\nPara facilitar a leitura de nossas sentenças sobre números, permitiremos o uso da notação infixa.\\nTambém escreveremos \\nS\\n(\\nn\\n) como \\nn\\n + 1, de forma que o segundo axioma se torne:\\n∀\\nm\\n, \\nn NumNat\\n(\\nm\\n) \\n∧\\n \\nNumNat\\n(\\nn\\n) \\n⇒\\n (\\nm\\n + 1) + \\nn\\n = (\\nm\\n + \\nn\\n) + 1.\\nEsse axioma reduz a adição à aplicação repetida da função sucessora.\\nO uso da notação infixa é um exemplo de \\naçúcar sintático\\n, ou seja, uma extensão para a nossa\\nabreviação da sintaxe-padrão que não altera a semântica. Qualquer sentença que utilize açúcar pode\\nser “desaçucarada” para produzir uma sentença equivalente em lógica de primeira ordem comum.\\nUma vez que temos a adição, é simples definir a multiplicação como a adição repetida, a\\nexponenciação como a multiplicação repetida, a divisão de inteiros e restos, números primos, e\\nassim por diante. Desse modo, toda a teoria dos números (inclusive a criptografia) pode ser\\nelaborada a partir de uma constante, uma função, um predicado e quatro axiomas.\\nO domínio de \\nconjuntos\\n também é fundamental para a matemática, bem como para o raciocínio\\ncomum (de fato, é possível definir a teoria dos números em termos da teoria dos conjuntos).\\nQueremos ter a capacidade de representar conjuntos individuais, inclusive o conjunto vazio.\\nPrecisamos de um modo de construir conjuntos acrescentando um elemento a um conjunto ou tomando\\na união ou interseção de dois conjuntos. Queremos saber se um elemento pertence a um conjunto e\\nqueremos ter a possibilidade de distinguir conjuntos de objetos que não são conjuntos.\\nUtilizaremos o vocabulário normal da teoria dos conjuntos como açúcar sintático. O conjunto\\nvazio é uma constante escrita como { }. Existe um único predicado unário, \\nConjunto\\n, que é\\nverdadeiro no caso de conjuntos. Os predicados binários são \\nx\\n \\n∊\\n \\ns\\n (\\nx\\n pertence ao conjunto \\ns\\n) e \\ns\\n1\\n \\ns\\n2\\n (o conjunto \\ns\\n1\\n é um subconjunto, não necessariamente próprio, do conjunto \\ns\\n2\\n). As funções binárias\\nsão \\ns\\n1\\n \\n \\ns\\n2\\n (a interseção de dois conjuntos), \\ns\\n1\\n \\n \\ns\\n2\\n (a união de dois conjuntos) e {\\nx\\n|\\ns\\n} (o conjunto\\nresultante da adição do elemento \\nx\\n ao conjunto \\ns\\n). Um conjunto possível de axiomas é:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 362}),\n",
       " Document(page_content='1. Apenas são conjuntos o conjunto vazio e os que são formados pela adição de algo a um\\nconjunto:\\n2. O conjunto vazio não tem elementos adicionados a ele; em outras palavras, não há como\\ndecompor { } em um conjunto menor e um elemento:\\n3. A adição de um elemento que já está no conjunto não tem nenhum efeito:\\n4. Os únicos membros de um conjunto são os elementos que foram adicionados a ele. Expressamos\\nesse fato de modo recursivo, afirmando que \\nx\\n é um membro de \\ns\\n (ou pertence a \\ns\\n) se e somente\\nse \\ns\\n é igual a algum conjunto \\ns\\n2\\n adicionado a algum elemento \\ny\\n, onde \\ny\\n é igual a \\nx\\n ou \\nx\\n é um\\nmembro de \\ns\\n2\\n:\\n5. Um conjunto é um subconjunto de outro conjunto se e somente se todos os elementos do\\nprimeiro conjunto pertencem ao segundo conjunto:\\n6. Dois conjuntos são iguais se e somente se cada um deles é um subconjunto do outro:\\n7. Um objeto está na interseção de dois conjuntos se e somente se ele pertence a ambos os\\nconjuntos:\\n8. Um objeto está na união de dois conjuntos se e somente se ele pertence a um ou a ambos os\\nconjuntos:\\nAs \\nlistas\\n são semelhantes aos conjuntos. As diferenças residem no fato de que as listas são\\nordenadas e de que o mesmo elemento pode aparecer mais de uma vez em uma lista. Podemos usar o\\nvocabulário de Lisp para listas:\\nNil\\n é a lista constante, sem elementos; \\nCons\\n, \\nAppend\\n, \\nFirst\\n e \\nRest\\n são funções e \\nFind\\n é o\\npredicado que representa para as listas aquilo que \\nMembro\\n representa para conjuntos. \\nList\\n? é um\\npredicado verdadeiro apenas no caso de listas. Como ocorre com os co\\nn\\njuntos, é comum usar açúcar', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 363}),\n",
       " Document(page_content='sintático em sentenças lógicas que envolvem listas. A lista vazia é representada por [ ]. O termo\\nCons\\n(\\nx\\n, \\ny\\n), onde \\ny\\n é uma lista não vazia, é escrito como [\\nx\\n|\\ny\\n]. O termo \\nCons\\n(\\nx\\n, \\nNil\\n) — isto é, a lista\\nque contém o elemento \\nx\\n — é escrito como [\\nx\\n]. Uma lista de vários elementos, como [\\nA\\n, \\nB\\n, \\nC\\n],\\ncorresponde ao termo aninhado \\nCons\\n(\\nA\\n, \\nCons\\n(\\nB\\n, \\nCons\\n(\\nC\\n, \\nNil\\n))). O Exercício 8.16 lhe pede para\\nrelacionar os axiomas referentes a listas.\\n8.3.4 O mundo de wumpus\\nAlguns axiomas de lógica proposicional para o mundo de wumpus foram dados no Capítulo 7. Os\\naxiomas de primeira ordem desta seção são muito mais concisos, captando de modo muito natural\\nexatamente aquilo que queremos dizer.\\nLembre-se de que o agente de wumpus recebe um vetor de percepções com cinco elementos. A\\nsentença de primeira ordem correspondente armazenada na base de conhecimento deve incluir tanto a\\npercepção quanto a instante em que ela ocorreu; caso contrário, o agente ficará confuso sobre o\\nmomento em que viu cada item. Utilizaremos os inteiros como instantes temporais. Uma sentença de\\npercepções típica seria:\\nPercepção\\n([\\nFedor\\n, \\nBrisa\\n, \\nBrilho\\n, \\nNenhum\\n, \\nNenhum\\n], 5).\\nAqui, \\nPercepção\\n é um predicado binário; \\nFedor,\\n e assim por diante, são constantes inseridas em\\numa lista. As ações no mundo de wumpus podem ser representadas por termos lógicos:\\nVirar\\n(\\nDireita\\n),\\u2002\\u2002\\nVirar\\n(\\nEsquerda\\n),\\u2002\\u2002\\nAvançar\\n,\\u2002\\u2002\\nAtirar\\n,\\u2002\\u2002\\nAgarrar\\n,\\u2002\\u2002\\nSoltar\\n,\\u2002\\u2002\\nEscalar.\\nPara determinar o que é melhor, o programa do agente constrói uma consulta como:\\nASKVARS (\\n∃\\na MelhorAção\\n(\\na\\n, 5)),\\nque retorna uma lista de vinculação como {\\na\\n/\\nAgarrar\\n}. O programa do agente pode então retornar\\nAgarrar\\n como a ação a executar. Os dados brutos da percepção implicam certos fatos sobre o estado\\natual. Por exemplo,\\n∀\\nt, s, g, m, c Percepção\\n([\\ns\\n, \\nBrisa, g, m, c\\n], \\nt\\n) \\n⇒\\n \\nBrisa\\n (\\nt\\n),\\n∀\\nt, s, b, m, c Percepção\\n([\\ns\\n, \\nb\\n, \\nBrilho, m, c\\n], \\nt\\n) \\n⇒\\n \\nBrilho\\n(\\nt\\n),\\ne assim por diante. Essas regras exibem uma forma trivial do processo de raciocínio chamado\\npercepção\\n, que estudaremos em profundidade no Capítulo 24. Note a quantificação sobre o tempo \\nt\\n.\\nEm lógica proposicional, precisaríamos de cópias de cada sentença para cada instante de tempo.\\nO comportamento “reativo” simples também pode ser implementado por sentenças de implicação\\nquantificadas. Por exemplo, temos:\\n∀\\nt Brilho\\n(\\nt\\n) \\n⇒\\n \\nMelhorAção\\n(\\nAgarrar, t\\n).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 364}),\n",
       " Document(page_content='Dadas a percepção e as regras dos parágrafos precedentes, isso produziria a conclusão desejada\\nMelhorAção\\n(\\nAgarrar\\n, 5), ou seja, \\nAgarrar\\n é a ação correta.\\nRepresentamos as entradas e saídas do agente; agora, chegou a hora de representar o próprio\\nambiente. Vamos começar com os objetos. Candidatos óbvios são quadrados, poços e o wumpus.\\nPoderíamos nomear cada quadrado — \\nQuadrado\\n1,2\\n e assim por diante —, entretanto, o fato de\\nQuadrado\\n1,2\\n e \\nQuadrado\\n1,3\\n serem adjacentes teria de ser um fato “extra”, e precisaríamos de um fato\\ndesse tipo para cada par de quadrados. É melhor usar um termo complexo em que a linha e a coluna\\naparecem como inteiros; por exemplo, podemos simplesmente utilizar o termo lista [1, 2]. A\\nadjacência de dois quadrados quaisquer pode ser definida como:\\n∀\\nx, y, a, b Adjacente\\n([\\nx, y\\n], [\\na, b\\n]) \\n⇒\\n(\\nx\\n = \\na\\n \\n∧\\n (\\ny\\n = \\nb\\n − 1 \\n∨\\n \\ny\\n = \\nb\\n + 1)) \\n∨\\n (\\ny\\n = \\nb\\n \\n∧\\n (\\nx\\n = \\na\\n − 1 \\n∨\\n \\nx\\n = \\na\\n + 1)).\\nTambém poderíamos nomear cada poço, mas isso seria inadequado por uma razão diferente: não\\nhá nenhum motivo para fazer distinção entre os poços.\\n11\\n É muito mais simples usar um predicado\\nunário \\nPoço\\n que seja verdadeiro no caso de quadrados contendo poços. Por fim, tendo em vista que\\nhá exatamente um wumpus, uma constante \\nWumpus\\n é um predicado unário muito bom (e talvez mais\\ndigno, do ponto de vista do wumpus).\\nA posição do agente muda com o tempo, e assim escreveremos \\nEm\\n(\\nAgente\\n, \\ns\\n, \\nt\\n) para indicar que o\\nagente está no quadrado \\ns\\n no instante \\nt\\n. Podemos fixar a localização do wumpus com \\n∀\\nt\\nEm\\n(\\nWumpus\\n, [2, 2], \\nt\\n).\\nPodemos então dizer que os objetos só podem estar em um local de cada vez:\\n∀\\nx\\n, \\ns\\n1\\n, \\ns\\n2\\n, \\nt\\n \\nAt\\n(\\nx\\n, \\ns\\n1\\n, \\nt\\n) \\n∧\\n \\nAt\\n(\\nx\\n, \\ns\\n2\\n, \\nt\\n) \\n⇒\\n \\ns\\n1\\n = \\ns\\n2\\n.\\nDada sua posição atual, o agente pode deduzir propriedades do quadrado a partir de propriedades\\nde sua percepção atual. Por exemplo, se o agente estiver em um quadrado e perceber uma brisa,\\nentão esse quadrado é arejado:\\n∀\\ns, t Em\\n(\\nAgente, s, t\\n) \\n∧\\n \\nBrisa\\n(\\nt\\n) \\n⇒\\n \\nArejado\\n(\\ns\\n).\\nÉ útil saber que um \\nquadrado\\n é arejado porque sabemos que os poços não podem se deslocar.\\nNote que \\nArejado\\n não tem nenhum argumento de tempo.\\nTendo descoberto quais são os lugares arejados (ou fedorentos) e, muito importante, os lugares\\nnão\\n arejados (ou \\nnão\\n fedorentos), o agente pode deduzir onde estão os poços (e onde está o\\nwumpus). Enquanto a lógica proposicional necessita de um axioma separado para cada quadrado\\n(veja \\nR\\n2\\n e \\nR\\n3\\n na \\nSeção 7.4.3\\n) e precisaria de um conjunto de axiomas diferentes para cada\\nconfiguração geográfica do mundo, a lógica de primeira ordem precisa apenas de um axioma:\\nDa mesma forma, na lógica de primeira ordem podemos quantificar ao longo do tempo, e assim\\nprecisamos apenas de um axioma de estado sucessor para cada predicado, em vez de uma cópia', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 365}),\n",
       " Document(page_content='diferente para cada instante. Por exemplo, o axioma para Flecha (Equação 7.2) torna-se\\n∀\\nt\\n \\nTemFlecha\\n (\\nt\\n + 1) \\n⇔\\n (\\nTemFlecha\\n(\\nt\\n) \\n∧\\n¬\\nAção\\n (\\nAtirar, t\\n)).\\nA partir dessas duas sentenças de exemplo, podemos ver que a formulação da lógica de primeira\\nordem não é menos concisa do que a descrição original em linguagem natural dada no Capítulo 7. O\\nleitor é convidado a construir axiomas análogos para a localização e orientação do agente; nesses\\ncasos, os axiomas quantificam sobre espaço e tempo. Como no caso da estimação do estado\\nproposicional, um agente pode usar inferência lógica com os axiomas desse tipo para manter o\\ncontrole de aspectos do mundo que não são observados diretamente. No Capítulo 10 nos\\naprofundaremos mais sobre o tema dos axiomas de estado sucessor de primeira ordem e seus usos\\npara a construção de planos.\\n8.4 ENGENHARIA DE CONHECIMENTO EM LÓGICA DE PRIMEIRA\\nORDEM\\nA seção precedente ilustrou o uso da lógica de primeira ordem para representar o conhecimento\\nem três domínios simples. Esta seção descreve o processo geral de construção da base de\\nconhecimento — um processo chamado \\nengenharia de conhecimento\\n. Um engenheiro de\\nconhecimento é alguém que investiga um domínio específico, aprende quais conceitos são\\nimportantes nesse domínio e cria uma representação formal dos objetos e relações no domínio.\\nIlustraremos o processo de engenharia de conhecimento em um domínio de circuito eletrônico que já\\ndeve ser bastante familiar; dessa forma, poderemos nos concentrar nas questões de representação\\nenvolvidas. A abordagem que adotaremos é adequada para o desenvolvimento de bases de\\nconhecimento de \\nuso especial\\n, cujo domínio está cuidadosamente circunscrito e cujo intervalo de\\nconsultas é conhecido com antecedência. As bases de conhecimento de \\nuso geral\\n, destinadas a dar\\nsuporte a consultas em toda a variedade do conhecimento humano e a apoiar tarefas tais como a\\ncompreensão da linguagem natural, serão descritas no Capítulo 12.\\n8.4.1 O processo de engenharia de conhecimento\\nOs projetos de engenharia de conhecimento variam amplamente em conteúdo, escopo e\\ndificuldade, mas todos eles incluem as etapas a seguir:\\n1. \\nIdentificar a tarefa\\n. O engenheiro de conhecimento deve delinear a variedade de questões que\\na base de conhecimento admitirá e os tipos de fatos que estarão disponíveis para cada instância\\nespecífica de problema.\\nPor exemplo, a base de conhecimento do wumpus precisa ser capaz de escolher ações ou ela\\né obrigada a responder a questões apenas sobre o conteúdo do ambiente? Os fatos do sensor\\nincluirão a posição atual? A tarefa determinará que conhecimento deve ser representado, com a\\nfinalidade de conectar instâncias de problemas a respostas. Essa etapa é análoga ao processo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 366}),\n",
       " Document(page_content='PEAS para projetar agentes, que vimos no Capítulo 2.\\n2. \\nAgregar o conhecimento relevante\\n. O engenheiro de conhecimento já deve ser um especialista\\nno domínio ou talvez precise trabalhar com especialistas reais para extrair o que eles conhecem\\n— um processo chamado \\naquisição de conhecimento\\n. Nessa fase, o conhecimento não é\\nrepresentado formalmente. A ideia é compreender o escopo da base de conhecimento,\\ndeterminada pela tarefa, e entender como o domínio realmente funciona.\\nNo caso do mundo de wumpus, definido por um conjunto artificial de regras, é fácil\\nidentificar o conhecimento relevante (contudo, note que a definição de adjacência não foi\\nfornecida explicitamente nas regras do mundo de wumpus). Para domínios reais, a questão de\\nrelevância pode ser bastante difícil — por exemplo, um sistema para simular projetos VLSI\\npode necessitar levar em conta ou não capacitâncias parasitas e efeitos peliculares.\\n3. \\nDefinir um vocabulário de predicados\\n, \\nfunções\\n e \\nconstantes\\n. Ou seja, converter os\\nimportantes conceitos de nível de domínio em nomes no nível de lógica. Isso envolve muitas\\nquestões de \\nestilo\\n da engenharia de conhecimento. Como o estilo de programação, ele pode ter\\num impacto significativo sobre o sucesso final do projeto. Por exemplo, os poços devem ser\\nrepresentados por objetos ou por um predicado unário sobre quadrados? A orientação do\\nagente deve ser uma função ou um predicado? A posição do wumpus deve depender do tempo?\\nUma vez que as escolhas tenham sido feitas, o resultado é um vocabulário conhecido como\\nontologia\\n do domínio. A palavra \\nontologia\\n representa uma teoria específica sobre a natureza\\nde ser ou existir. A ontologia determina os tipos de itens que existem, mas não determina suas\\npropriedades específicas e seus inter-relacionamentos.\\n4. \\nCodificar o conhecimento geral sobre o domínio\\n. O engenheiro de conhecimento escreve os\\naxiomas correspondentes a todos os termos do vocabulário. Isso fixa (na medida do possível) o\\nsignificado dos termos, permitindo ao especialista verificar o conteúdo. Com frequência, essa\\netapa revela concepções erradas ou lacunas no vocabulário que devem ser corrigidas\\nretornando à etapa 3 e repetindo-se todo o processo.\\n5. \\nCodificar uma descrição da instância específica do problema\\n. Se a ontologia estiver bem\\nelaborada, essa etapa será fácil. Ela envolverá a escrita de sentenças atômicas simples sobre\\ninstâncias de conceitos que já fazem parte da ontologia. Para um agente lógico, as instâncias de\\nproblemas são fornecidas pelos sensores, enquanto uma base de conhecimento\\n“desincorporada” é suprida com sentenças adicionais, da mesma forma que os programas\\ntradicionais são supridos com dados de entrada.\\n6. \\nFormular consultas ao procedimento de inferência e obter respostas\\n. Essa é a etapa em que\\nestá a recompensa: podemos deixar o procedimento de inferência operar sobre os axiomas e\\nfatos específicos do problema para derivar os fatos que estamos interessados em conhecer.\\nAssim, evitamos a necessidade de escrever um algoritmo para solução de aplicação específica.\\n7. \\nDepurar a base de conhecimento\\n. Infelizmente, as respostas às consultas poucas vezes estarão\\ncorretas na primeira tentativa. Mais precisamente, as respostas estarão corretas \\npara a base de\\nconhecimento criada\\n, supondo-se que o procedimento de inferência seja consistente, mas não', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 367}),\n",
       " Document(page_content='serão aquelas que o usuário espera. Por exemplo, se um axioma estiver ausente, algumas\\nconsultas não poderão ser respondidas a partir da base de conhecimento. Disso poderia resultar\\num processo de depuração considerável. Falta de axiomas ou axiomas muito fracos pode ser\\nidentificado com facilidade observando-se lugares em que a cadeia de raciocínio se interrompe\\nde forma inesperada. Por exemplo, se a base de conhecimento incluir uma regra de diagnóstico\\n(veja o Exercício 8.13) para encontrar o wumpus,\\n∀\\ns Fedor\\n(\\nr\\n) \\n⇒\\n \\nAdjacente\\n(\\nCasa\\n(\\nWumpus\\n), s),\\nem vez de bicondicional, o agente nunca poderá provar a \\nausência\\n de wumpuses. Os axiomas\\nincorretos podem ser identificados porque são declarações falsas sobre o mundo. Por exemplo,\\na sentença\\n∀\\nx NumDePernas\\n(\\nx\\n, 4) \\n⇒\\n \\nMamífero\\n(\\nx\\n)\\n é falsa para répteis, anfíbios e, mais importante, mesas. \\nA falsidade dessa sentença pode\\nser determinada de forma independente do restante da base de conhecimento\\n. Em contraste,\\num erro típico em um programa é semelhante a:\\ndeslocamento = posição + 1.\\nÉ impossível dizer se essa declaração é correta sem examinar o restante do programa para ver\\nse, por exemplo, o deslocamento é usado para se referir à posição atual ou a uma unidade além\\nda posição atual ou se o valor de posição é alterado por outra declaração e, portanto, se o\\ndeslocamento também deve ser mais uma vez alterado.\\nPara entender melhor esse processo de sete etapas, vamos aplicá-lo agora a um exemplo ampliado\\n— o domínio de circuitos eletrônicos.\\n8.4.2 O domínio de circuitos eletrônicos\\nDesenvolveremos uma ontologia e uma base de conhecimento que nos permitirão raciocinar sobre\\ncircuitos digitais do tipo mostrado na \\nFigura 8.6\\n. Seguiremos o processo de sete etapas da engenharia\\nde conhecimento.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 368}),\n",
       " Document(page_content='Figura 8.6\\n Um circuito digital C1, que deve ser um somador completo de um bit. As duas primeiras\\nentradas são os dois bits a serem somados, e a terceira entrada é um bit de transporte. A primeira\\nsaída é a soma, e a segunda saída é um bit de transporte para o próximo somador. O circuito contém\\nduas portas XOU (ou exclusivo), duas portas E e uma porta OU. mais fácil de ler.\\nIdentificar a tarefa\\nExistem muitas tarefas de raciocínio associadas a circuitos digitais. No nível mais alto,\\nanalisamos a funcionalidade do circuito. Por exemplo, o circuito na \\nFigura 8.6\\n realmente efetua soma\\nde modo apropriado? Se todas as entradas são altas, qual será a saída da porta A2? Perguntas sobre\\na estrutura do circuito também são interessantes. Por exemplo, quais são as portas conectadas ao\\nprimeiro terminal de entrada? O circuito contém laços de realimentação? Essas serão nossas tarefas\\nnesta seção. Existem níveis mais detalhados de análise, incluindo aqueles relacionados a retardos de\\nsincronização, área de circuitos, consumo de energia, custo de produção, e assim por diante. Cada\\num desses níveis exigiria conhecimento adicional.\\nAgregar o conhecimento relevante\\nO que sabemos sobre circuitos digitais? Para nossos propósitos, eles são formados por fios e\\nportas. Os sinais fluem pelos fios até os terminais de entrada das portas, e cada porta produz um sinal\\nno terminal de saída que flui por outro fio. Para determinar quais serão esses sinais, precisamos\\nsaber como as portas transformam seus sinais de entrada. Existem quatro tipos de portas: as portas E,\\nOU e XOU têm dois terminais de entrada, e as portas NÃO têm um. Todas as portas têm um terminal\\nde saída. Os circuitos, como as portas, têm terminais de entrada e de saída.\\nPara raciocinar sobre funcionalidade e conectividade, não precisamos mencionar os próprios fios,\\nos caminhos que eles seguem ou as junções em que eles se unem. Tudo o que importa são as\\nconexões entre terminais — podemos dizer que um terminal de saída está conectado a outro terminal\\nde entrada sem ter de mencionar o fio que realmente os conecta. Outros fatores, tais como tamanho,\\nforma, cor ou o custo dos vários componentes, são irrelevantes para nossa análise.\\nSe nosso propósito fosse algo diferente de verificar projetos no nível de porta, a ontologia seria\\ndiferente. Por exemplo, se estivéssemos interessados em depurar circuitos defeituosos,\\nprovavelmente seria boa ideia incluir os fios na ontologia porque um fio defeituoso pode corromper\\no sinal que flui através dele. Para solucionar falhas de sincronismo, precisaríamos incluir retardos de\\nportas. Se estivéssemos interessados em projetar um produto que fosse lucrativo, o custo do circuito\\ne sua velocidade relativa a outros produtos no mercado seriam fatores importantes.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 369}),\n",
       " Document(page_content='Definir um vocabulário\\nAgora sabemos que desejamos abordar circuitos, terminais, sinais e portas. A próxima etapa é\\nescolher funções, predicados e constantes para representá-los. Primeiro, precisamos ser capazes de\\ndistinguir as portas umas das outras e de outros objetos. Cada porta é representada como um objeto\\ndenominado por uma constante, sobre a qual afirmamos que é uma porta como, digamos, \\nPorta\\n(\\nX\\n1\\n)\\n.\\nO comportamento de cada porta é determinado pelo seu tipo: uma das constantes E, OU, XOU ou\\nNÃO. Devido à porta ter exatamente um tipo, é apropriada uma função: \\nTipo(X\\n1\\n) = XOU\\n. Circuitos,\\ncomo portas, são identificados por um predicado: \\nCircuito(C\\n1\\n).\\nEm seguida, consideraremos os terminais, que estão identificados pelo predicado\\nTerminal\\n(\\nx\\n)\\n.\\nUma porta ou um circuito pode ter um ou mais terminais de entrada e um ou mais\\nterminais de saída. Utilizamos a função \\nEntrada\\n(1\\n, X\\n1\\n) para denotar o primeiro terminal de entrada\\npara a porta \\nX\\n1\\n. Uma função similar \\nSaída\\n é utilizada para terminais de saída. A função \\nAridade\\n(\\nc, i,\\nj\\n) diz que o circuito \\nc\\n tem \\ni\\n terminais de entrada e \\nj\\n terminais de saída. A conectividade entre portas\\npode ser representada pelo predicado \\nConectado\\n, que recebe dois terminais como argumentos, como\\nem \\nConectado\\n(\\nSaída\\n(1, \\nX\\n1\\n), \\nEntrada\\n(1, \\nX\\n2\\n)).\\nFinalmente, precisamos saber se um sinal está ligado ou desligado. Uma possibilidade é usar um\\npredicado unário, \\nOn\\n(\\nt\\n), que é verdadeiro quando o sinal em um terminal está ligado. No entanto,\\nisso torna um pouco difícil a formulação de perguntas como: “Quais são todos os valores possíveis\\ndos sinais nos terminais de saída do circuito C\\n1\\n?” Portanto, introduziremos como objetos dois\\n“valores de sinal”, 1 e 0, e uma função \\nSinal\\n(\\nt\\n) que denota o valor de sinal para o terminal \\nt\\n.\\nCodificar o conhecimento geral do domínio\\nUm sinal de que temos uma boa ontologia é que necessitamos apenas de umas poucas regras\\ngerais, que podem ser expressas clara e concisamente. Esses são os axiomas necessários:\\n1. Se dois terminais estão conectados, eles têm o mesmo sinal:\\n∀\\nt\\n1\\n, \\nt\\n2\\n \\nTerminal\\n (\\nt\\n1\\n) \\n∧\\n \\nTerminal\\n (\\nt\\n2\\n) \\n∧\\n \\nConectado\\n(\\nt\\n1\\n, \\nt\\n2\\n) \\n⇒\\n \\nSinal\\n (\\nt\\n1\\n) = \\nSinal\\n (\\nt\\n2\\n).\\n2. O sinal em todo terminal é ou 1 ou 0:\\n∀\\nt Terminal (t)\\n \\n⇒\\n \\nSinal (t)=\\n1 \\n∨\\n \\nSinal (t)=\\n0.\\n3. Conectado é um predicado comutativo:\\n∀\\nt\\n1\\n, \\nt\\n2\\n \\nConectado\\n(\\nt\\n1\\n, \\nt\\n2\\n) \\n⇔\\n \\nConectado\\n(\\nt\\n2\\n, \\nt\\n1\\n).\\n4. Há quatro tipos de portas:\\n∀\\ng \\nPorta\\n(\\ng\\n) \\n∧\\n \\nk\\n = \\nTipo\\n(\\ng\\n) \\n⇒\\n \\nk\\n = \\nE\\n \\n∨\\n \\nk\\n = \\nOU\\n \\n∨\\n \\nk\\n = \\nXOU\\n \\n∨\\n \\nk\\n = \\nNÃO\\n.\\n5. A saída de uma porta E é 0 se e somente se qualquer de suas entradas for 0:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 370}),\n",
       " Document(page_content='∀\\ng \\nPorta\\n(g) \\n∧\\n \\nTipo\\n(g)= E \\n⇒\\nSinal\\n(\\nSaída\\n(1, \\ng\\n)) = 0 \\n⇔\\n \\n∃\\nn Sinal\\n(\\nEntrada\\n(\\nn, g\\n)) = 0.\\n6. A saída de uma porta OU é 1 se e somente se quaisquer de suas saídas for 1:\\n∀\\ng \\nPorta\\n(\\ng\\n) \\n∧\\n \\nTipo\\n(\\ng\\n)= \\nOU\\n \\n⇒\\nSinal\\n(\\nSaída\\n(1, \\ng\\n)) = 1 \\n⇔\\n \\n∃\\nn Sinal\\n(\\nEntrada(n, g\\n)) = 1.\\n7. A saída de uma porta XOU é 1 se e somente se suas entradas forem diferentes:\\n∀\\ng \\nPorta\\n(\\ng\\n) \\n∧\\n \\nTipo\\n(\\ng\\n)= \\nXOU\\n \\n⇒\\nSinal\\n(\\nSaída\\n(1, \\ng\\n)) = 1 \\n⇔\\n \\nSinal\\n(\\nEntrada\\n(1, \\ng\\n) ≠ \\nSinal\\n(\\nEntrada\\n(2, \\ng\\n)).\\n8. A saída de uma porta NÃO é diferente de sua entrada:\\n∀\\ng \\nPorta\\n(\\ng\\n) \\n∧\\n \\nTipo\\n(\\ng\\n) = \\nNÃO\\n \\n⇒\\nSinal\\n(\\nSaída\\n(1, \\ng\\n)) ≠ \\nSinal\\n(\\nEntrada\\n(1, \\ng\\n)).\\n9. As portas (exceto para NÃO) têm duas entradas e uma saída.\\n∀\\ng \\nPorta\\n(\\ng\\n) \\n∧\\n \\nTipo\\n(\\ng\\n) = \\nNÃO\\n \\n⇒\\n \\nAridade\\n (\\ng\\n,1,1) \\n.\\n∀\\ng \\nPorta\\n(\\ng\\n) \\n∧\\n \\nk\\n = \\nTipo\\n(\\ng\\n) \\n∧\\n (\\nk\\n = \\nE\\n \\n∨\\n \\nk\\n = \\nOU\\n \\n∨\\n \\nk\\n = \\nXOU\\n) \\n⇒\\nAridade\\n (\\ng\\n,2,1) \\n.\\n10. Um circuito tem terminais, até sua aridade de entrada e saída, e nada além de sua aridade:\\n∀\\nc\\n, \\ni\\n, \\nj Circuito\\n(c) \\n∧\\n \\nAridade\\n(\\nc\\n, \\ni\\n, \\nj\\n) \\n⇒\\n∀\\nn\\n (\\nn\\n ≤ \\ni\\n \\n⇒\\n \\nTerminal\\n (\\nEntrada\\n(\\nc\\n, \\nn\\n))) \\n∧\\n (\\nn\\n > \\ni\\n \\n⇒\\n \\nEntrada\\n(\\nc\\n, \\nn\\n) = \\nNada\\n) \\n∧\\n∀\\nn\\n (\\nn\\n ≤ \\nj\\n \\n⇒\\n \\nTerminal\\n (\\nSaída\\n(\\nc\\n, \\nn\\n))) \\n∧\\n (\\nn\\n > \\nj\\n \\n⇒\\n \\nSaída\\n(\\nc\\n, \\nn\\n) = \\nNada\\n).\\n11. Todos são distintos: portas, terminais, signais, tipos de porta e \\nNada\\n.\\n∀\\ng\\n, \\nt\\n \\nPorta\\n(\\ng\\n) \\n∧\\nTerminal\\n (\\nt\\n) \\n⇒\\ng\\n ≠ \\nt\\n ≠ 1 ≠ 0 ≠ \\nOU\\n ≠ \\nE\\n ≠ \\nXOU\\n ≠ \\nNÃO\\n ≠ \\nNada\\n.\\n12. Portas são circuitos.\\n∀\\ng \\nPorta\\n(\\ng\\n) \\n⇒\\n C\\nircuito\\n(\\ng\\n).\\nCodificar a instância específica do problema\\nO circuito mostrado na \\nFigura 8.6\\n é codificado como o circuito \\nC\\n1\\n com a descrição a seguir.\\nPrimeiro, categorizamos o circuito e suas portas componentes:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 371}),\n",
       " Document(page_content='Em seguida, mostramos as conexões entre elas:\\nFormular consultas ao procedimento de inferência\\nQue combinações de entradas fariam a primeira saída de \\nC\\n1\\n (o bit de soma) ser 0 e a segunda\\nsaída de \\nC\\n1\\n (o bit de transporte) ser 1?\\nAs respostas são substituições para as variáveis \\ni\\n1, \\ni\\n2 e \\ni\\n3 tais que a sentença resultante é\\nconsequência lógica da base de conhecimento. ASKVARS vai fornecer três substituições desse tipo:\\nQuais são os conjuntos de valores possíveis de todos os terminais para o circuito somador?\\nEssa consulta final retornará uma tabela completa de entrada/saída para o dispositivo, que poderá\\nser usada para verificar se de fato o circuito soma suas entradas de maneira correta. Esse é um\\nexemplo simples de \\nverificação de circuitos\\n. Também podemos usar a definição de circuito para\\nelaborar sistemas digitais maiores, para os quais é possível executar o mesmo tipo de procedimento\\nde verificação (veja o Exercício 8.26). Muitos domínios são apropriados para o mesmo tipo de\\ndesenvolvimento estruturado de bases de conhecimento, no qual conceitos mais complexos são\\ndefinidos a partir de conceitos mais simples.\\nDepurar a base de conhecimento\\nPodemos perturbar a base de conhecimento de várias maneiras, a fim de verificar que tipos de\\ncomportamentos errôneos emergem. Por exemplo, suponha que deixemos de ler a \\nSeção 8.2.8\\n e,\\nportanto, nos esqueçamos da asserção de que 1 ≠ 0. De repente, o sistema será incapaz de provar', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 372}),\n",
       " Document(page_content='quaisquer saídas para o circuito, com exceção dos casos de entrada 000 e 110. Podemos identificar o\\nproblema solicitando as saídas de cada porta. Por exemplo, podemos solicitar:\\n∃\\ni\\n1\\n, \\ni\\n2\\n, \\no Sinal\\n(\\nEntrada\\n(1, \\nC\\n1\\n)) = \\ni\\n1\\n \\n∧\\n \\nSinal\\n(\\nEntrada\\n(2, \\nC\\n1\\n)) = \\ni\\n2\\n \\n∧\\n \\nSinal\\n(\\nSaída\\n(1, \\nX\\n1\\n)) = \\no\\n,\\no que revela que nenhuma saída é conhecida em X\\n1\\n nos casos de entrada 10 e 01. Em seguida,\\nobservamos o axioma para portas XOU, aplicado a \\nX\\n1\\n:\\nSinal\\n(\\nSaída\\n(1, \\nX\\n1\\n) = 1 \\n⇔\\n \\nSinal\\n(\\nEntrada\\n(1, \\nX\\n1\\n)) ≠ \\nSinal\\n(\\nEntrada\\n(2, \\nX\\n1\\n)).\\nSe sabemos que as entradas são, digamos, 1 e 0, isso se reduz a:\\nSinal\\n(\\nSaída\\n(1, \\nX\\n1\\n)) = 1 \\n⇔\\n 1 ≠ 0.\\nAgora o problema é aparente: o sistema é incapaz de deduzir que \\nSinal\\n(\\nSaída\\n(1, \\nX\\n1\\n)) = 1, e assim\\nprecisamos informá-lo de que 1 ≠ 0.\\n8.5 RESUMO\\nEste capítulo introduziu a \\nlógica de primeira ordem\\n, uma linguagem de representação muito mais\\npoderosa que a lógica proposicional. Os pontos importantes são:\\n•  As linguagens de representação do conhecimento devem ser declarativas, composicionais,\\nexpressivas, independentes do contexto e não ambíguas.\\n•  As lógicas diferem em seus \\ncompromissos ontológicos\\n e \\ncompromissos epistemológicos\\n.\\nEmbora a lógica proposicional só se comprometa com a existência de fatos, a lógica de primeira\\nordem se compromete com a existência de objetos e relações, e, portanto, ganha expressividade.\\n•  A sintaxe da lógica de primeira ordem baseia-se na da lógica proposicional. Acrescenta termos\\npara representar objetos e tem quantificadores universais e existenciais para construir asserções\\nsobre todos ou alguns dos valores possíveis das variáveis \\u200b\\u200bquantificadas.\\n•  Um \\nmundo possível\\n, ou \\nmodelo\\n, para a lógica de primeira ordem inclui um conjunto de objetos\\ne uma \\ninterpretação\\n que projeta símbolos constantes para objetos, símbolos de predicados para\\nas relações entre os objetos e símbolos de função para as funções sobre os objetos.\\n•  Uma sentença atômica será verdadeira apenas quando a relação denominada pelo predicado se\\nmantiver entre os objetos denominados pelos termos. As \\ninterpretações estendidas\\n, que\\nprojetam variáveis  quantificadoras a objetos no modelo, definem a verdade das sentenças\\nquantificadas.\\n•  O desenvolvimento de uma base de conhecimento em lógica de primeira ordem exige um\\nprocesso cuidadoso de análise do domínio, escolha de um vocabulário e codificação dos\\naxiomas necessários para dar suporte às inferências desejadas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 373}),\n",
       " Document(page_content='NOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nEmbora até mesmo a lógica de Aristóteles lide com generalizações a respeito de objetos, ficou\\nmuito aquém do poder expressivo da lógica de primeira ordem. Uma grande barreira ao seu\\ndesenvolvimento posterior foi a sua concentração em predicados unários, excluindo predicados\\nrelacionais de maior aridade. O primeiro tratamento sistemático das relações foi dada por Augustus\\nDe Morgan (1864), que citou o exemplo seguinte para mostrar os tipos de inferências com as quais a\\nlógica de Aristóteles não poderia lidar: “Todos os cavalos são animais; portanto, a cabeça de um\\ncavalo é a cabeça de um animal.” Essa inferência é inacessível para Aristóteles porque qualquer\\nregra válida que possa apoiá-la deve primeiro analisar a sentença utilizando o predicado binário “\\nx\\n é\\na cabeça de \\ny\\n”. A lógica das relações foi estudada em profundidade por Charles Sanders Peirce\\n(1870, 2004).\\nA verdadeira lógica de primeira ordem data da introdução de quantificadores no trabalho de\\nGottlob Frege (1879), \\nBegriffschrift\\n (“Escrita de Conceitos” ou “Notação Conceitual”). Peirce\\n(1883) também desenvolveu a lógica de primeira ordem independentemente de Frege, apesar de um\\npouco mais tarde. A habilidade de Frege para aninhar quantificadores foi um grande passo à frente,\\nmas ele utilizava uma notação desajeitada. A notação atual para a lógica de primeira ordem se deve\\nsubstancialmente a Giuseppe Peano (1889), mas a semântica é virtualmente idêntica à de Frege. Por\\nestranho que pareça, os axiomas de Peano devem ser creditados em grande parte a Grassmann (1861)\\ne Dedekind (1888).\\nLeopold Löwenheim (1915) deu um tratamento sistemático à teoria dos modelos para a lógica de\\nprimeira ordem, incluindo o primeiro tratamento apropriado do símbolo de igualdade. Os resultados\\nde Löwenheim foram estendidos mais ainda por Thoralf Skolem (1920). Alfred Tarski (1935, 1956)\\ndeu uma definição explícita de verdade e de satisfação da teoria de modelos em lógica de primeira\\nordem, utilizando a teoria de conjuntos.\\nMcCarthy (1958) foi o principal responsável pela introdução da lógica de primeira ordem como\\numa ferramenta para a construção de sistemas de IA. As perspectivas da IA baseada em lógica\\ntiveram um avanço significativo a partir do desenvolvimento por Robinson (1965) da resolução, um\\nprocedimento completo para inferência de primeira ordem, descrito no Capítulo 9. A abordagem\\nlogicista criou raízes na Universidade de Stanford. Cordell Green (1969a, 1969b) desenvolveu um\\nsistema de raciocínio de primeira ordem, o QA3, levando às primeiras tentativas de construir um\\nrobô lógico no SRI (Fikes e Nilsson, 1971). A lógica de primeira ordem foi aplicada por Zohar\\nManna e Richard Waldinger (1971) ao raciocínio sobre programas e, mais tarde, por Michael\\nGenesereth (1984) ao raciocínio sobre circuitos. Na Europa, a programação em lógica (uma forma\\nrestrita de raciocínio de primeira ordem) foi desenvolvida para análise linguística (Colmerauer \\net\\nal\\n., 1973) e para sistemas declarativos gerais (Kowalski, 1974). A lógica computacional também foi\\nbem fortalecida em Edimburgo, graças ao projeto LCF (\\nLogic for Computable\\n \\nFunctions\\n) (Gordon\\net al\\n., 1979). Esses desenvolvimentos serão examinados mais profundamente nos Capítulos 9 e 12.\\nAplicações práticas construídas com lógica de primeira ordem incluem um sistema para avaliar os\\nrequisitos de fabricação de produtos eletrônicos (Mannion, 2002), um sistema de raciocínio sobre\\npolíticas de acesso a arquivos e gerenciamento de direitos digitais (Halpern e Weissman, 2008), e\\num sistema para a composição automática de serviços da Web (McIlraith e Zeng, 2001).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 374}),\n",
       " Document(page_content='Reações à hipótese de Whorf (Whorf, 1956) e o problema da linguagem e do pensamento em geral\\naparecem em vários livros recentes (Gumperz e Levinson, 1996; Bowerman e Levinson, 2001;\\nPinker, 2003; Gentner e Goldin-Meadow, 2003). A teoria “teoria” (Gopnik e Glymour, 2002;\\nTenenbaum \\net al\\n., 2007) vê o aprendizado das crianças sobre o mundo como análoga à construção de\\nteorias científicas. Assim como as previsões de um algoritmo de aprendizagem de máquina\\ndependem fortemente do vocabulário fornecido a ele, a formulação de teorias infantis depende do\\nambiente linguístico em que a aprendizagem ocorre.\\nExistem vários textos introdutórios de boa qualidade sobre lógica de primeira ordem incluindo\\nalgumas figuras de destaque na história da lógica: Alfred Tarski (1941), Alonzo Church (1956) e W.\\nV. Quine (1982) (que é um dos mais legíveis). Enderton (1972) apresenta uma perspectiva mais\\norientada para a matemática. Um tratamento altamente formal da lógica de primeira ordem,\\nacompanhado por tópicos muito mais avançados em lógica, é fornecido por Bell e Machover (1977).\\nManna e Waldinger (1985) apresentam uma introdução interessante à lógica, a partir de uma\\nperspectiva da ciência da computação, assim como Huth e Ryan (2004), que se concentram na\\nverificação de programas. Barwise e Etchemendy (2002) consideram uma abordagem semelhante à\\nutilizada aqui. Smullyan (1995) apresenta resultados de forma concisa, usando o formato de tableau.\\nGallier (1986) nos oferece uma exposição matemática extremamente rigorosa da lógica de primeira\\nordem, juntamente com uma grande quantidade de material sobre seu uso em raciocínio automatizado.\\nA obra \\nLogical Foundations of Artificial Intelligence\\n (Genesereth e Nilsson, 1987) fornece tanto\\numa sólida introdução à lógica como apresenta o primeiro tratamento sistemático de agentes lógicos\\ncom percepções e ações, e há dois bons manuais: Van Bentham e Ter Meulen (1997) e Robinson e\\nVoronkov (2001). A revista de registro para o campo da lógica matemática é o \\nJournal of Symbolic\\nLogic\\n, enquanto \\nJournal of Applied Logic\\n ocupa-se com preocupações mais próximas às da\\ninteligência artificial.\\nEXERCÍCIOS\\n8.1\\n Uma base de conhecimento lógico representa o mundo com o uso de um conjunto de sentenças\\nsem estrutura explícita. Por outro lado, uma representação \\nanalógica\\n tem estrutura física que\\ncorresponde diretamente à estrutura do item representado. Considere um mapa rodoviário de nosso\\npaís como uma representação analógica de fatos sobre o país — representa fatos em uma linguagem\\nde mapa. A estrutura bidimensional do mapa corresponde à superfície bidimensional da área.\\na.\\n Forneça cinco exemplos de \\nsímbolos\\n na linguagem do mapa.\\nb.\\n Uma sentença \\nexplícita\\n é uma sentença que o criador da representação realmente escreve. Uma\\nsentença \\nimplícita\\n é uma sentença que resulta de sentenças explícitas devido a propriedades da\\nrepresentação analógica. Forneça três exemplos de \\nsentenças implícitas\\n e três exemplos de\\nsentenças explícitas\\n na linguagem do mapa.\\nc.\\n Forneça três exemplos de fatos sobre a estrutura física de seu país que não possam ser\\nrepresentados na linguagem do mapa.\\nd.\\n Forneça dois exemplos de fatos que sejam muito mais fáceis de expressar na linguagem do mapa\\nque em lógica de primeira ordem.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 375}),\n",
       " Document(page_content='e.\\n Forneça dois outros exemplos de representações analógicas úteis. Quais são as vantagens e as\\ndesvantagens de cada uma dessas linguagens?\\n8.2\\n Considere uma base de conhecimento que contenha apenas duas sentenças: \\nP\\n(\\na\\n) e \\nP\\n(\\nb\\n). Essa base\\nde conhecimento tem como consequência lógica \\n∀\\nx P\\n(\\nx\\n)? Explique sua resposta em termos de\\nmodelos.\\n8.3\\n A sentença \\n∃\\nx\\n, \\ny x\\n = \\ny\\n é válida? Explique.\\n8.4\\n Escreva uma sentença lógica tal que todo mundo no qual ela é verdadeira contenha exatamente um\\nobjeto.\\n8.5\\n Considere um vocabulário de símbolos que contenha \\nc\\n símbolos de constantes, \\np\\nk\\n símbolos de\\npredicados de cada aridade \\nk\\n e \\nf\\nk\\n símbolos de funções de cada aridade \\nk\\n, onde 1 \\n≤\\n \\nk\\n \\n≤\\n \\nA\\n. Seja o\\ntamanho do domínio fixo em \\nD\\n. Para qualquer modelo dado, cada símbolo de predicado ou de função\\né mapeado sobre uma relação ou função, respectivamente, da mesma aridade. Suponha que as\\nfunções do modelo permitam que algumas tuplas de entrada não tenham nenhum valor para a função\\n(isto é, o valor é o objeto invisível). Derive uma fórmula que represente o número de modelos\\npossíveis para um domínio com \\nD\\n elementos. Não se preocupe com a eliminação de combinações\\nredundantes.\\n8.6\\n Quais das seguintes são sentenças válidas (necessariamente verdadeiras)?\\na.\\n (\\n∃\\nx\\n \\nx\\n = \\nx\\n) \\n⇒\\n (\\n∀\\ny\\n \\n∃\\nz y = z\\n).\\nb.\\n \\n∀\\nx\\n P(x) \\n∨\\n ¬P(x).\\nc.\\n \\n∀\\nx\\n Smart (\\nx\\n) \\n∨\\n (\\nx = x\\n).\\n8.7\\n Considere uma versão da semântica para lógica de primeira ordem em que são permitidos\\nmodelos com domínios vazios. Dê pelo menos dois exemplos de sentenças que são válidas de acordo\\ncom a semântica-padrão, mas não de acordo com a nova semântica. Discuta qual resultado dos seus\\nexemplos tem sentido mais intuitivo.\\n8.8\\n Será que o fato ¬\\nCônjuge\\n(\\nGeorge, Laura\\n) resulta do fato de que \\nJim\\n ≠ \\nGeorge\\n e \\nCônjuge\\n(\\nJim,\\nLaura\\n)\\n?\\n Em caso afirmativo, dê uma prova, se não, forneça axiomas adicionais, conforme\\nnecessário. O que acontece se usarmos \\nCônjuge\\n como um símbolo de função unário, em vez de um\\npredicado binário?\\n8.9\\n Este exercício usa a função MapColor e os predicados Em(x,y), Fronteira(x,y) e País(x), cujos\\nargumentos são regiões geográficas junto a símbolos constantes para as várias regiões. Em cada um\\ndos seguintes itens expressamos uma sentença e um número de expressões lógicas candidatas. Para\\ncada uma das expressões lógicas, determine se ela (1) expressa corretamente a sentença; (2) é\\ninvalida sintaticamente e portanto não tem significado; ou (3) é válida sintaticamente mas não\\nexpressa o significado da sentença.\\na.\\n Paris e Marseilles localizam-se na França.\\n(i)\\u2002\\nEm\\n(\\nParis\\n \\n∧\\n \\nMarselha, França\\n).\\n(ii)\\u2002\\nEm\\n(\\nParis, França\\n) \\n∧\\n \\nEm\\n(\\nMarselha, França\\n).\\n(iii)\\u2002\\nEm\\n(\\nParis, França\\n) \\n∨\\n \\nEm\\n(\\nMarselha, França\\n).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 376}),\n",
       " Document(page_content='b.\\n Existe um país que faz fronteira tanto com o Iraque como com o Paquistão.\\n(i)\\u2002\\n∃\\n \\nc\\u2002País\\n(\\nc\\n) \\n∧\\n \\nFronteira\\n(\\nc, Iraque\\n) \\n∧\\n \\nFronteira\\n(\\nc, Paquistão\\n).\\n(ii)\\u2002\\n∃\\n \\nc\\u2002País\\n(\\nc\\n) \\n⇒\\n [\\nFronteira\\n(\\nc, Iraque\\n) \\n∧\\n \\nFronteira\\n(\\nc, Paquistão\\n)].\\n(iii)\\u2002[\\n∃\\n \\nc\\u2002País\\n(\\nc\\n)] \\n⇒\\n [\\nFronteira\\n(\\nc, Iraque\\n) \\n∧\\n \\nFronteira\\n(\\nc, Paquistão\\n)].\\n(iv)\\u2002\\n∃\\n \\nc\\u2002Fronteiras\\n(\\nPaís\\n(\\nc\\n)\\n, Iraque\\n \\n∧\\n \\nPaquistão\\n).\\nc.\\n Todos os países que fazem fronteira com o Equador estão na América do Sul.\\n(i)\\u2002\\n∀\\n \\nc\\u2002País\\n(\\nc\\n) \\n∧\\n \\nFronteira\\n(\\nc, Equador\\n) \\n⇒\\n \\nEm\\n(\\nc, América do Sul\\n).\\n(ii)\\u2002\\n∀\\n \\nc\\u2002País\\n(\\nc\\n) \\n⇒\\n [\\nFronteira\\n(\\nc, Equador\\n) \\n⇒\\n \\nEm\\n(\\nc, América do Sul\\n)].\\n(iii)\\u2002\\n∀\\n \\nc\\u2002\\n[\\nPaís\\n(\\nc\\n) \\n⇒\\n \\nFronteira\\n(\\nc, Equador\\n)] \\n⇒\\n \\nEm\\n(\\nc, América do Sul\\n).\\n(iv)\\u2002\\n∀\\n \\nc\\u2002País\\n(\\nc\\n) \\n∧\\n \\nFronteira\\n(\\nc\\n, \\nEquador\\n) \\n∧\\n \\nEm\\n(\\nc, América do Sul\\n).\\nd.\\n Nenhuma região da América do Sul faz fronteira com qualquer região da Europa.\\n(i)\\u2002¬[\\n∃\\n \\nc, d\\u2002Em\\n(\\nc, América do Sul\\n) \\n∧\\n \\nEm\\n(\\nd, Europa\\n) \\n∧\\n \\nFronteira\\n(\\nc, d\\n)].\\n(ii)\\u2002\\n∀\\n \\nc, d\\u2002\\n[\\nEm\\n(\\nc, América do Sul\\n) \\n∧\\n \\nEm\\n(\\nd, Europa\\n) \\n⇒\\n ¬\\nFronteira\\n(\\nc, d\\n)].\\n(iii)\\u2002¬\\n∀\\n \\nc\\u2002Em\\n(\\nc, América do Sul\\n) \\n⇒\\n \\n∃\\n \\nd Em\\n(\\nd, Europa\\n) \\n∧\\n ¬\\nFronteira\\n(\\nc, d\\n).\\n(iv)\\u2002\\n∀\\n \\nc\\u2002Em\\n(\\nc, América do Sul\\n) \\n⇒\\n \\n∀\\nd Em\\n(\\nd, Europa\\n) \\n⇒\\n ¬\\nFronteira\\n(\\nc, d\\n).\\ne.\\n Não existem dois países adjacentes com a mesma cor dentro do mapa.\\n(i)\\u2002\\n∀\\n \\nx, y\\u2002\\n¬\\nPaís\\n(\\nx\\n) \\n∨\\n ¬\\nPaís\\n(\\ny\\n) \\n∨\\n ¬\\nFronteira\\n(\\nx, y\\n)] \\n∨\\n¬(\\nMapColor\\n(\\nx\\n) \\n=\\n (\\nMapColor\\n(\\ny\\n)).\\n(ii)\\u2002\\n∀\\n \\nx, y\\u2002\\n(\\nPaís\\n(\\nx\\n) \\n∧\\n \\nPaís\\n(\\ny\\n) \\n∧\\n \\nFronteira\\n(\\nx, y\\n) \\n∧\\n ¬(\\nx, y\\n)) \\n⇒\\n¬(\\nMapColor\\n(\\nx\\n) \\n=\\n (\\nMapColor\\n(\\ny\\n)).\\n(iii)\\u2002\\n∀\\n \\nx, y\\u2002País\\n(\\nx\\n) \\n∧\\n \\nPaís\\n(\\ny\\n) \\n∧\\n \\nFronteira\\n(\\nx, y\\n) \\n∧\\n¬(\\nMapColor\\n(\\nx\\n) \\n=\\n (\\nMapColor\\n(\\ny\\n)).\\n(iv)\\u2002\\n∀\\n \\nx, y\\u2002\\n(\\nPaís\\n(\\nx\\n) \\n∧\\n \\nPaís\\n(\\ny\\n) \\n∧\\n \\nFronteira\\n(\\nx, y\\n) \\n⇒\\n \\nMapColor\\n (\\nx\\n ≠ \\ny\\n)\\n8.10\\n Considere um vocabulário com os símbolos seguintes:\\nOcupação\\n (\\np, o\\n): Predicado. A pessoa \\np\\n tem a ocupação o.\\nCliente\\n (\\np\\n1, \\np\\n2): Predicado. A pessoa \\np\\n1 é cliente da pessoa \\np\\n2.\\nChefe\\n(\\np\\n1, \\np\\n2) Predicado. A pessoa \\np\\n1 é chefe da pessoa \\np\\n2.\\nMédico, Cirurgião, Advogado, Ator\\n: Constantes que indicam ocupações.\\nEmília, Joe\\n: constantes que indicam pessoas.\\nUse esses símbolos para escrever as seguintes asserções em lógica de primeira ordem:\\na\\n. Emília é cirurgiã ou advogada.\\nb\\n. Joe é um ator, mas ele também tem outro trabalho.\\nc\\n. Todos os cirurgiões são médicos.\\nd\\n. Joe não tem advogado (ou seja, não é cliente de nenhum advogado).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 377}),\n",
       " Document(page_content='e\\n. Emília tem um chefe que é advogado.\\nf\\n. Há um advogado cujos clientes são todos médicos.\\ng\\n. Todo cirurgião tem um advogado.\\n8.11\\n Complete os exercícios a seguir sobre sentenças lógicas:\\na.\\n Traduzir em português \\nbom\\n, \\nnatural\\n (sem xs e ys!):\\n∀\\n \\nx\\n, \\ny\\n, \\nFalaIdioma\\n (\\nx\\n, \\nl\\n) \\n∧\\n \\nFalaIdioma\\n (\\ny\\n, \\nl\\n)\\n⇒\\n \\nCompreende\\n (\\nx\\n, \\ny\\n) \\n∧\\n \\nCompreende\\n (\\ny\\n, \\nx\\n).\\nb.\\n Explique por que essa sentença é consequência da sentença\\n∀\\n \\nx\\n, \\ny\\n, \\nl\\n \\nFalaIdioma\\n (\\nx\\n, \\nl\\n) \\n∧\\n \\nFalaIdioma\\n (\\ny\\n, \\nl\\n)\\n⇒\\n \\nCompreende\\n (\\nx\\n, \\ny\\n).\\nc.\\n Traduza em lógica de primeira ordem as seguintes sentenças:\\n(i) Compreender leva à amizade.\\n(ii) A amizade é transitiva.\\nLembre-se de definir todos os predicados, funções e constantes que usar.\\n8.12\\n Reescreva os dois primeiros axiomas de Peano da \\nSeção 8.3.3\\n como um único axioma que\\ndefine \\nNumNat\\n(\\nx\\n) de modo a excluir a possibilidade de números naturais, exceto para aqueles\\ngerados pela função sucessor.\\n8.13\\n A Equação 8.4 na página 306 define as condições em que um quadrado está com brisa. Aqui\\nconsideramos duas outras maneiras de descrever esse aspecto do mundo wumpus.\\na\\n. Podemos escrever \\nregras de diagnóstico\\n conduzindo de efeitos observados a causas ocultas.\\nPara encontrar os poços, as regras de diagnóstico óbvias informam que, se um quadrado estiver\\ncom brisa, algum quadrado adjacente deve conter um poço; e, se um quadrado não estiver com\\nbrisa, nenhum quadrado adjacente conterá um poço. Escreva essas duas regras em lógica de\\nprimeira ordem e mostre que sua conjunção é logicamente equivalente à Equação 8.4.\\nb\\n. Podemos escrever \\nregras causais\\n que conduzem da causa para o efeito. Uma regra óbvia causal\\né que um poço faz com que todos os quadrados adjacentes tenham brisa. Escreva essa regra em\\nlógica de primeira ordem, explique por que ela é incompleta em comparação com a Equação 8.4\\ne forneça o axioma faltante.\\n \\n8.14\\n Crie axiomas que descrevam os predicados \\nNetoOuNeta\\n, \\nBisavôOuBisavó\\n, \\nAncestral\\n,\\nIrmão\\n, \\nIrmã\\n, \\nFilha\\n, \\nFilho\\n, \\nPrimoIrmão\\n, \\nCunhado\\n, \\nCunhada, Tia e Tio.\\n Descubra a definição\\nadequada de primo em \\nm\\n-ésimo grau \\nn\\n vezes afastado e escreva a definição em lógica de primeira\\nordem. Agora, anote os fatos básicos representados na árvore genealógica da \\nFigura 8.7\\n. Utilizando\\num sistema de raciocínio lógico adequado, informe (com TELL) a ele todas as sentenças que você\\nanotou e pergunte (com ASK) ao sistema quem são os netos de Elizabeth, os cunhados de Diana, os\\nbisavós de Zara e os ancestrais de Eugenie.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 378}),\n",
       " Document(page_content='Figura 8.7\\n Uma árvore genealógica típica. O símbolo “\\x00\\x00” conecta cônjuges e as setas apontam\\npara filhos.\\n8.15\\n Explique o que está errado com a seguinte definição proposta do predicado “Pertence a” \\n∊\\n:\\n∀\\n \\nx\\n, \\ns\\u2002x\\n \\n∊\\n {\\nx\\n|\\ns\\n}\\n∀\\n \\nx\\n, \\ns\\u2002x\\n \\n∊\\n \\ns\\u2002\\n⇒\\n\\u2002\\n∀\\n \\ny\\u2002x\\n \\n∊\\n {\\ny\\n|\\ns\\n}.\\n8.16\\n Usando os axiomas de conjuntos como exemplos, escreva axiomas para o domínio de lista,\\nincluindo todas as constantes, funções e predicados mencionados no capítulo.\\n8.17\\n Explique o que está errado na definição proposta a seguir de quadrados adjacentes no mundo de\\nwumpus:\\n∀\\n \\nx\\n, \\ny\\n \\nAdjacente\\n ([\\nx\\n, \\ny\\n], [\\nx\\n + 1, \\ny\\n]) \\n∧\\n \\nAdjacente\\n ([\\nx\\n, \\ny\\n], [\\nx\\n, \\ny\\n + 1]).\\n8.18\\n Escreva os axiomas necessários para raciocinar sobre a posição do wumpus, usando um\\nsímbolo de constante \\nWumpus\\n e um predicado binário \\nEm\\n(\\nWumpus\\n, \\nPosição\\n). Lembre-se de que só\\nexiste um wumpus.\\n8.19\\n Assumindo os predicados \\nPaiOuMãe\\n(\\np\\n, \\nθ\\n) e \\nFeminino\\n(\\np\\n) e as constantes \\nJoan\\n e \\nKevin\\n, com os\\nsignificados óbvios, expresse cada uma das seguintes sentenças em lógica de primeira ordem (você\\npode usar a abreviatura1 \\n∃\\n1\\n para significar “existe exatamente um”).\\na.\\n Joan tem uma filha (possivelmente mais do que uma e, possivelmente, filhos também).\\nb.\\n Joan tem exatamente uma filha (mas pode ter filhos também).\\nc.\\n Joan tem exatamente um filho ou filha.\\nd.\\n Joan e Kevin têm exatamente um filho ou filha juntos.\\ne.\\n Joan tem pelo menos um filho ou filha com Kevin e não tem filhos com mais ninguém.\\n8.20\\n Afirmações aritméticas podem ser escritas em lógica de primeira ordem com o símbolo de\\npredicado <, os símbolos de função + e ×, e os símbolos constantes 0 e 1. Predicados adicionais\\npodem ser também definidos com biconditionais.\\na.\\n Represente a propriedade “\\nx\\n é um número par”.\\nb.\\n Represente a propriedade “\\nx\\n é primo”.\\nc.\\n A conjetura de Goldbach é a conjetura (ainda não provada) de que cada número par é igual à\\nsoma de dois primos. Represente essa conjetura como uma sentença lógica.\\n8.21\\n No Capítulo 6, foi utilizada igualdade para indicar a relação entre uma variável e seu valor. Por', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 379}),\n",
       " Document(page_content='exemplo, escrevemos \\nWA\\n = \\nvermelho\\n para significar que a Austrália Ocidental é da cor vermelha.\\nPara representar isso em lógica de primeira ordem, devemos escrever com mais detalhes\\nCorDe\\n(\\nWA\\n) = \\nvermelho\\n. Que inferência incorreta poderia ser estabelecida se escrevêssemos\\nsentenças como \\nWA\\n = \\nvermelho\\n diretamente como afirmações lógicas?\\n8.22\\n Escreva em lógica de primeira ordem a afirmação de que todas as chaves e pelo menos um de\\ncada par de meias serão perdidos eventualmente para sempre usando apenas o seguinte vocabulário:\\nChave(\\nx\\n), \\nx\\n é uma chave; \\nMeia\\n(\\nx\\n), \\nx\\n é uma meia; \\nPar\\n(\\nx\\n, \\ny\\n), \\nx\\n e \\ny\\n são um par; \\nAgora\\n, o instante atual;\\nAntes\\n(\\nt\\n1\\n, \\nt\\n2\\n), o instante \\nt\\n1\\n vem antes do instante \\nt\\n2\\n; \\nPerda\\n(\\nx\\n, \\nt\\n), o objeto \\nx\\n é perdido no instante \\nt\\n.\\n8.23\\n Para cada uma das seguintes sentenças em português, decida se a sentença de primeira ordem\\nque a acompanha é uma boa tradução. Se não, explique por que e a corrija (algumas sentenças podem\\nter mais de um erro).\\na\\n. Não há duas pessoas com o mesmo número do seguro social.\\n¬\\n∃\\n \\nx, y, n\\u2002Pessoa\\n (\\nx\\n) \\n∧\\n \\nPessoa\\n (\\nx\\n) \\n⇒\\n [\\nHasSS\\n # (\\nx, n\\n) \\n∧\\n \\nHasSS\\n # (\\ny, n\\n)].\\nb\\n. O número do seguro social do João é igual ao da Maria.\\n∃\\n \\nn\\u2002HasSS\\n # (\\nJoão, n\\n) \\n∧\\n \\nHasSS\\n # (\\nMaria, n\\n).\\nC\\n. O número do seguro social de todas as pessoas possui nove dígitos.\\n∀\\n \\nx, n\\u2002Pessoa\\n (\\nx\\n) \\n⇒\\n [\\nHasSS\\n # (\\nx, n\\n) \\n∧\\n \\nDígitos\\n (\\nn,\\n 9)].\\nd\\n. Reescreva cada uma das sentenças acima (sem corrigir) usando o símbolo da função SS# em\\nvez do Predicado \\nHasSS#\\n.\\n8.24\\n Represente as sentenças a seguir em lógica de primeira ordem usando um vocabulário\\nconsistente (que você mesmo deve definir):\\na.\\n Alguns alunos cursaram francês na primavera de 2001.\\nb.\\n Todos os alunos que cursam aulas de francês passam.\\nc.\\n Somente um aluno cursou grego na primavera de 2001.\\nd.\\n A melhor pontuação em grego é sempre mais alta que a melhor pontuação em francês.\\ne.\\n Toda pessoa que compra um seguro é inteligente.\\nf.\\n Ninguém compra um seguro caro.\\ng.\\n Existe um agente que só vende seguros às pessoas que não têm seguro.\\nh.\\n Existe um barbeiro que faz a barba de todos os homens na cidade que não fazem a própria\\nbarba.\\ni.\\n Uma pessoa nascida no Reino Unido, que tem como cada um de seus pais um cidadão do Reino\\nUnido ou um residente do Reino Unido, é um cidadão do Reino Unido de nascença.\\nj.\\n Uma pessoa nascida fora do Reino Unido, que tem um de seus pais um cidadão de nascença do\\nReino Unido, é um cidadão do Reino Unido por descendência.\\nk.\\n Os políticos podem enganar algumas pessoas todo o tempo, podem enganar todas as pessoas por\\nalgum tempo, mas não podem enganar todas as pessoas todo o tempo.\\nl.\\n Todos os gregos falam a mesma língua. (Use \\nFala\\n(\\nx\\n, \\nl\\n) para dizer que a pessoa \\nx\\n fala o idioma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 380}),\n",
       " Document(page_content='l\\n.)\\n8.25\\n Escreva um conjunto geral de fatos e axiomas para representar a afirmação “Wellington ouviu\\nfalar sobre a morte de Napoleão” e responder corretamente à pergunta: “Napoleão ouviu falar sobre\\na morte de Wellington?”\\n8.26\\n Estenda o vocabulário da \\nSeção 8.4\\n para definir a adição de números binários de \\nn\\n bits.\\nEm seguida, codifique a descrição do somador de quatro bits da \\nFigura 8.8\\n e formule as consultas\\nnecessárias para verificar se de fato ele é correto.\\nFigura 8.8\\n Um somador de quatro bits. Cada \\nAd\\ni\\n é um somador de um bit, como na \\nFigura 8.6\\n.\\n8.27\\n Obtenha uma solicitação de emissão de passaportes para seu país e identifique as regras que\\ndefinem a elegibilidade para um passaporte, seguindo as etapas delineadas na \\nSeção 8.4\\n.\\n8.28\\n Considere uma base de conhecimento de lógica de primeira ordem que descreve o mundo com\\npessoas, canções, álbuns (ou seja, “\\nMeet the\\n \\nBeatles\\n”) e discos (ou seja, instâncias físicas\\nparticulares de CDs). O vocabulário contém os símbolos seguintes:\\nCopiaDe\\n(\\nd\\n, \\na\\n): Predicado. O disco \\nd\\n é uma cópia do álbum \\na\\n.\\nPossui(p\\n, \\nd\\n): Predicado. A pessoa \\np\\n possui o disco \\nd\\n.\\nCanta\\n(\\np\\n, \\ns\\n, \\na\\n): O álbum \\na\\n inclui uma gravação da música \\ns\\n cantada pela pessoa \\np\\n.\\nEscreveu\\n(\\np\\n, \\ns\\n): A pessoa \\np\\n escreveu a canção \\ns\\n.\\nMcCartney, Gershwin, BHoliday, Joe, EleanorRigby, TheManILove, Revolver:\\nConstantes com os significados óbvios.\\nExpresse as seguintes afirmações em lógica de primeira ordem:\\na.\\n Gershwin escreveu “\\nThe Man I Love\\n”.\\nb.\\n Gershwin não escreveu “Eleanor Rigby”.\\nc.\\n Ou Gershwin ou McCartney escreveu “\\nThe Man I Love\\n”.\\nd.\\n Joe escreveu pelo menos uma canção.\\ne.\\n Joe possui uma cópia de \\nRevolver\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 381}),\n",
       " Document(page_content='f.\\n Cada canção que McCartney canta em \\nRevolver\\n foi escrita por McCartney.\\ng.\\n Gershwin não escreveu qualquer das músicas de \\nRevolver\\n.\\nh.\\n Cada canção que Gershwin escreveu foi gravada em algum álbum. (Possivelmente canções\\ndiferentes foram gravadas em álbuns diferentes.)\\ni.\\n Há um único álbum que contém todas as músicas que Joe escreveu.\\nj.\\n Joe possui uma cópia de um álbum em que Billie Holiday canta “\\nThe Man I Love\\n”.\\nk.\\n Joe possui uma cópia de cada álbum que tem uma canção cantada por McCartney. (É claro que\\ncada álbum diferente é instanciado em um CD físico diferente.)\\nl.\\n Joe possui uma cópia de todo álbum no qual todas as canções são cantadas por Billie Holiday.\\n1\\n Também chamada \\ncálculo de predicados de primeira ordem\\n e, às vezes, abreviada como \\nLPO\\n ou \\nCPPO\\n.\\n2\\n Em contraste, os fatos em \\nlógica difusa\\n têm um \\ngrau de verdade\\n entre 0 e 1. Por exemplo, a sentença “Viena é uma cidade grande”\\npoderia ser verdadeira em nosso mundo apenas até o grau 0,6.\\n3\\n É importante não confundir o grau de crença na teoria da probabilidade com o grau de verdade na lógica difusa. Na realidade, alguns\\nsistemas difusos permitem incerteza (grau de crença) sobre graus de verdade.\\n4\\n Mais à frente, na \\nSeção 8.2.8\\n, examinaremos uma semântica em que cada objeto tem exatamente um nome.\\n5\\n As \\nexpressões\\n \\nλ\\n oferecem uma notação útil em que novos símbolos de funções são construídos “em tempo de execução”. Por\\nexemplo, a função que eleva ao quadrado seu argumento pode ser escrita como (\\nλ\\nx x\\n × \\nx\\n) e pode ser aplicada a argumentos da mesma\\nforma que qualquer outro símbolo de função. Uma expressão \\nλ\\n também pode ser definida e usada como um símbolo de predicado (veja o\\nCapítulo 22). O operador lambda em Lisp desempenha exatamente o mesmo papel. Note que o uso de \\nλ\\n desse modo \\nnão\\n aumenta o\\npoder de expressão formal da lógica de primeira ordem porque qualquer sentença que inclua uma expressão \\nλ\\n pode ser reescrita\\n“unindo-se” seus argumentos para gerar uma sentença equivalente.\\n6\\n Normalmente, seguiremos a convenção de ordenação de argumentos que determina que \\nP\\n(\\nx\\n, \\ny\\n) deve ser interpretada como “\\nx\\n é um \\nP\\nde \\ny\\n”.\\n7\\n Existe uma variante do quantificador existencial, em geral escrita como \\n∃\\n1\\n ou \\n∃\\n!, que significa “Existe exatamente um”. O mesmo\\nsignificado pode ser expresso com a utilização de declarações de igualdade.\\n8\\n Na verdade, ele tinha quatro, sendo os outros Guilherme e Henrique.\\n9\\n N.R.: Optamos por manter o exemplo original da versão em inglês, assim termos que não têm correspondente direto em português\\nforam traduzidos por nomes com desjunção: PaiOuMãe (Parent) IrmãoOuIrmã (Sibling), FilhoOuFilha (Child), AvôOuAvó (Grandparent)\\ne NetoOuNeta (Grndchild).\\n10\\n Os axiomas de Peano também incluem o princípio de indução, que é uma sentença de lógica de segunda ordem, e não de lógica de\\nprimeira ordem. A importância dessa distinção será explicada no Capítulo 9.\\n11\\n De modo semelhante, a maioria das pessoas não identifica cada pássaro que voa sobre sua cabeça à medida que ele migra para\\nregiões mais quentes no inverno. Um ornitologista que deseje estudar padrões de migração, taxas de sobrevivência, e assim por diante,\\nidentificará\\n cada pássaro, usando um anel em sua perna porque pássaros individuais devem ser monitorados.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 382}),\n",
       " Document(page_content='O\\nCAPÍTULO\\n \\n9\\nInferência em lógica de primeira ordem\\nEm que definimos procedimentos efetivos para responder a perguntas\\nformuladas em lógica de primeira ordem.\\nCapítulo 7 mostrou como a inferência correta e completa pode ser alcançada no caso da lógica\\nproposicional. Neste capítulo, estendemos esses resultados para obter algoritmos capazes de\\nresponder a qualquer pergunta enunciada em lógica de primeira ordem que tenha uma resposta\\npossível. A \\nSeção 9.1\\n introduz regras de inferência para quantificadores e mostra como reduzir a\\ninferência de primeira ordem à inferência proposicional, embora a um custo potencialmente elevado.\\nA \\nSeção 9.2\\n descreve a ideia de \\nunificação\\n, mostrando como ela pode ser usada para construir\\nregras de inferência que funcionam diretamente com sentenças de primeira ordem. Em seguida,\\ndescreveremos três importantes famílias de algoritmos de inferência de primeira ordem: o\\nencadeamento para a frente\\n e suas aplicações a \\nbancos de dados dedutivos\\n e \\nsistemas de\\nprodução\\n são abordados na \\nSeção 9.3\\n; o \\nencadeamento para trás\\n e os sistemas de \\nprogramação\\nem lógica\\n são desenvolvidos na \\nSeção 9.4\\n. Encadeamento para a frente e para trás pode ser muito\\neficiente, mas são aplicáveis apenas a bases de conhecimento que podem ser expressas como\\nconjuntos de cláusulas de Horn. Sentenças de primeira ordem genéricas requerem prova de teorema\\nbaseado em resolução, que é descrito na \\nSeção 9.5\\n.\\n9.1 INFERÊNCIA PROPOSICIONAL \\nVERSUS\\n INFERÊNCIA DE PRIMEIRA\\nORDEM\\nEsta seção e a próxima introduzem as ideias subjacentes aos modernos sistemas de inferência\\nlógica. Começaremos com algumas regras de inferência simples que podem ser aplicadas a sentenças\\ncom quantificadores, a fim de obter sentenças sem quantificadores. Essas regras conduzem\\nnaturalmente à ideia de que a inferência \\nde primeira ordem\\n pode ser realizada convertendo-se a base\\nde conhecimento para a lógica \\nproposicional\\n e utilizando-se a inferência \\nproposicional\\n, o que já\\nsabemos como fazer. A próxima seção apresenta um atalho óbvio, que conduz a métodos de\\ninferência que manipulam diretamente sentenças de primeira ordem.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 384}),\n",
       " Document(page_content='9.1.1 Regras de inferência para quantificadores\\nVamos começar com quantificadores universais. Suponha que nossa base de conhecimento\\ncontenha o folclórico axioma-padrão que afirma que todos os reis ambiciosos são perversos:\\nEntão, parece bastante viável deduzir qualquer das sentenças a seguir:\\nA regra de \\ninstanciação universal\\n (\\nIU\\n para abreviar) afirma que podemos deduzir qualquer\\nsentença obtida pela substituição de um \\ntermo básico\\n (um termo sem variáveis) para a variável.\\n1\\nPara escrever formalmente a regra de inferência, utilizamos a noção de \\nsubstituições\\n introduzida na\\nSeção 8.3\\n. Seja SUBST(\\nθ\\n, \\na\\n) o resultado da aplicação da substituição \\nθ\\n à sentença \\na\\n. Então, a regra\\né escrita como\\npara qualquer variável \\nv\\n e termo básico \\ng\\n. Por exemplo, as três sentenças dadas anteriormente são\\nobtidas com as substituições {\\nx\\n/\\nJoão\\n}, {\\nx\\n/\\nRicardo\\n} e {\\nx\\n/\\nPai\\n(\\nJoão\\n)}.\\nNa regra de \\ninstanciação existencial\\n, a variável é substituída por um \\nnovo símbolo de constante\\núnico. A declaração formal é a seguinte: para qualquer sentença \\na\\n, variável \\nv\\n e símbolo de constante\\nk\\n que não aparece em outro lugar na base de conhecimento,\\nPor exemplo, da sentença\\npodemos deduzir a sentença\\ndesde que \\nC\\n1\\n não apareça em outro lugar na base de conhecimento. Basicamente, a sentença\\nexistencial afirma que existe algum objeto que satisfaz a uma condição, e a aplicação da regra de\\ninstanciação existencial está apenas dando um nome a esse objeto. É claro que esse nome não deve\\npertencer ainda a outro objeto. A matemática oferece um exemplo interessante: vamos supor que\\ndescobrimos que existe um número um pouco maior que 2,71828 e que satisfaz a equação \\nd\\n(\\nx\\ny\\n)/\\ndy\\n =\\nx\\ny\\n para \\nx\\n. Podemos dar um nome a esse número, como \\ne\\n, mas seria um equívoco dar a ele o nome de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 385}),\n",
       " Document(page_content='um objeto existente, como p. Em lógica, o novo nome é chamado \\nconstante de Skolem\\n. A\\ninstanciação existencial é um caso especial de um processo mais geral chamado \\nskolemização\\n, que\\ncobriremos na \\nSeção 9.5\\n.\\nEnquanto a instanciação universal pode ser aplicada várias vezes para produzir muitas\\nconsequências diferentes, a instanciação do existencial pode ser aplicada uma vez e depois a\\nsentença existencialmente quantificada pode ser descartada. Por exemplo, não precisamos mais da\\nsentença \\n∃\\nx Matar\\n(\\nx\\n, \\nVítima\\n) uma vez que acrescentamos a sentença \\nMatar\\n(\\nAssassino\\n, \\nVítima\\n). Em\\ntermos estritos, a nova base de conhecimento não é logicamente equivalente à antiga, mas pode se\\nmostrar \\ninferencialmente equivalente\\n no sentido de ser satisfatível exatamente quando a base de\\nconhecimento original é satisfatível.\\n9.1.2 Redução à inferência proposicional\\nUma vez que temos regras para deduzir sentenças não quantificadas a partir de sentenças\\nquantificadas, torna-se possível reduzir a inferência de primeira ordem à inferência proposicional.\\nNesta seção, apresentaremos as ideias principais; os detalhes serão examinados na \\nSeção 9.5\\n.\\nA primeira ideia é que, da mesma forma que uma sentença existencialmente quantificada pode ser\\nsubstituída por uma instanciação, uma sentença universalmente quantificada pode ser substituída pelo\\nconjunto de \\ntodas as instanciações possíveis\\n. Por exemplo, suponha que nossa base de conhecimento\\ncontenha apenas as sentenças\\nEm seguida, aplicamos a IU à primeira sentença, usando todas as substituições de termos básicos\\npossíveis a partir do vocabulário da base de conhecimento — nesse caso, {\\nx\\n/\\nJoão\\n} e {\\nx\\n/\\nRicardo\\n}.\\nObtemos\\ne descartamos a sentença universalmente quantificada. Agora, a base de conhecimento é\\nessencialmente proposicional, se visualizarmos as sentenças atômicas básicas — \\nRei\\n(\\nJoão\\n),\\nAmbicioso\\n(\\nJoão\\n), e assim por diante — como símbolos de proposições. Portanto, podemos aplicar\\nqualquer dos algoritmos proposicionais completos do Capítulo 7 para obter conclusões como\\nPerverso\\n(\\nJoão\\n).\\nEssa técnica de \\nproposicionalização\\n pode se tornar completamente geral, como mostramos na\\nSeção 9.5\\n; ou seja, toda base de conhecimento de primeira ordem e toda consulta podem ser\\nproposicionalizadas de tal modo que a consequência lógica é preservada. Desse modo, temos um\\nprocedimento de decisão completo para consequência lógica… ou talvez não. Há um problema:\\nquando a base de conhecimento inclui um símbolo de função, o conjunto de substituições de termos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 386}),\n",
       " Document(page_content='básicos possíveis é infinito! Por exemplo, se a base de conhecimento menciona o símbolo \\nPai\\n,\\npodem ser construídos infinitamente muitos termos aninhados, como \\nPai\\n(\\nPai\\n(\\nPai\\n(\\nJoão\\n))). Nossos\\nalgoritmos proposicionais terão dificuldade com um conjunto de sentenças infinitamente grande.\\nFelizmente, existe um teorema famoso devido a Jacques Herbrand (1930) afirmando que, se uma\\nsentença é consequência lógica da base de conhecimento de primeira ordem original, então existe\\numa prova envolvendo apenas um subconjunto \\nfinito\\n da base de conhecimento proposicionalizada.\\nTendo em vista que qualquer subconjunto desse tipo tem uma profundidade máxima de aninhamento\\nentre seus termos básicos, podemos encontrar o subconjunto gerando primeiro todas as instanciações\\ncom símbolos de constantes (\\nRicardo\\n e \\nJoão\\n), depois todos os termos de profundidade 1\\n(\\nPai\\n(\\nRicardo\\n) e \\nPai\\n(\\nJoão\\n)), depois todos os termos de profundidade 2, e assim por diante, até\\nsermos capazes de construir uma prova proposicional da sentença que é consequência lógica.\\n Esboçamos uma abordagem para a inferência de primeira ordem através da proposicionalização\\nque é \\ncompleta\\n, isto é, qualquer sentença que é consequência lógica pode ser provada. Essa é uma\\nrealização importante, dado que o espaço de modelos possíveis é infinito. Por outro lado, não\\nsabemos que a sentença \\né\\n consequência lógica até a prova terminar! O que acontece quando a\\nsentença \\nnão\\n é consequência lógica? Podemos ter conhecimento disso? Para a lógica de primeira\\nordem, simplesmente não podemos. Nosso procedimento de prova pode prosseguir indefinidamente,\\ngerando termos cada vez mais profundamente aninhados, mas não saberemos se ele ficou paralisado\\nem um loop sem fim ou se a prova está simplesmente prestes a surgir. Isso é muito semelhante ao\\nproblema de parada das máquinas de Turing. Alan Turing (1936) e Alonzo Church (1936) provaram,\\nde modos bem diferentes, a inevitabilidade dessa situação. \\nA questão de consequência lógica no\\ncaso da lógica de primeira ordem é\\n \\nsemidecidível—\\n \\nisto é\\n, \\nexistem algoritmos que respondem\\n“sim” para toda sentença que é consequência lógica,\\n \\nmas não existe nenhum algoritmo que\\ntambém diga “não” para toda sentença que não é consequência lógica.\\n9.2 UNIFICAÇÃO E “ELEVAÇÃO”\\nA seção precedente descreveu a compreensão da inferência de primeira ordem que existia até o\\ninício da década de 1960. O leitor atento (e certamente os lógicos computacionais dos anos 1960)\\ndevem ter notado que a abordagem de proposicionalização é bastante ineficiente. Por exemplo, dada\\na consulta \\nPerverso\\n(\\nx\\n) e a base de conhecimento da Equação 9.1, parece inconveniente gerar\\nsentenças como \\nRei\\n(\\nRicardo\\n) \\n∧\\n \\nAmbicioso\\n(\\nRicardo\\n) \\n⇒\\n \\nPerverso\\n(\\nRicardo\\n). Na verdade, a dedução\\nde \\nPerverso\\n (\\nJoão\\n) a partir das sentenças\\nparece completamente óbvia para um ser humano. Agora, mostraremos como torná-la completamente\\nóbvia para um computador.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 387}),\n",
       " Document(page_content='9.2.1 Uma regra de inferência de primeira ordem\\nA inferência de que João é perverso — isto é, que {\\nx\\n/\\nJoão\\n} resolve a consulta \\nPerverso\\n(\\nx\\n) —\\nfunciona assim: para utilizar a regra de que reis ambiciosos são perversos, encontre algum \\nx\\n tal que \\nx\\nseja um rei e que \\nx\\n seja ambicioso, e depois deduza que esse \\nx\\n é perverso. De modo mais geral, se\\nhouver alguma substituição \\nθ\\n que torne cada um dos conjuntos da premissa da implicação idêntica a\\nsentenças que já estão na base de conhecimento, poderemos afirmar a conclusão da implicação\\ndepois da aplicação de \\nθ\\n. Nesse caso, a substituição \\nθ\\n = {\\nx\\n/\\nJoão\\n} alcança esse objetivo. Na\\nrealidade, podemos fazer a etapa de inferência realizar um trabalho ainda maior. Vamos supor que,\\nem vez de conhecermos \\nAmbicioso\\n(\\nJoão\\n), sabemos que \\ntodo mundo\\n é ambicioso:\\nEntão, ainda gostaríamos de poder concluir \\nPerverso\\n(\\nJoão\\n), porque sabemos que João é um rei\\n(dado) e que João é ambicioso (porque todo mundo é ambicioso). Para isso funcionar, precisamos\\nencontrar uma substituição, tanto para as variáveis na sentença de implicação quanto para as\\nvariáveis nas sentenças que estão na base de conhecimento. Nesse caso, a aplicação da substituição\\n{\\nx\\n/\\nJoão\\n, \\ny\\n/\\nJoão\\n} às premissas da implicação \\nRei\\n(\\nx\\n) e \\nAmbicioso\\n(\\nx\\n) e às sentenças da base de\\nconhecimento \\nRei\\n(\\nJoão\\n) e \\nAmbicioso\\n(\\ny\\n) as tornará idênticas. Desse modo, podemos deduzir a\\nconclusão da implicação.\\nEsse processo de inferência pode ser captado como uma única regra de inferência que chamamos\\nModusPonens\\n2\\n \\ngeneralizado\\n: para sentenças atômicas \\np\\ni\\n, \\n e \\nθ\\n, onde existe uma substituição \\nθ\\n tal\\nque SUBST(\\nθ\\n, \\np\\ni\\n) = SUBST(\\nθ\\n, \\n), para todo \\ni\\n,\\nExistem \\nn\\n + 1 premissas para essa regra: as \\nn\\n sentenças atômicas \\n e a única implicação. A\\nconclusão é o resultado da aplicação da substituição \\nθ\\n ao consequente \\nθ\\n. Em nosso exemplo:\\nÉ fácil mostrar que o \\nModus Ponens\\n generalizado é uma regra de inferência correta. Primeiro\\nobservamos que, para qualquer sentença \\np\\n (cujas variáveis são consideradas universalmente\\nquantificadas) e para qualquer substituição \\nθ\\n,\\né válida por instanciação universal. Ela é válida em particular para um \\nθ\\n que satisfaz às condições\\nda regra de \\nModus Ponens\\n generalizado. Desse modo, a partir de \\n, podemos deduzir', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 388}),\n",
       " Document(page_content='e, da implicação \\np\\n1\\n \\n∧\\n … \\n∧\\n \\np\\nn\\n \\n⇒\\n \\nθ\\n, podemos deduzir\\nAgora, \\nθ\\n em \\nModus Ponens\\n generalizado é definido de tal forma que SUBST(\\nθ\\n, \\np\\ni\\n′) = SUBST(\\nθ\\n,\\np\\ni\\n), para todo \\ni\\n; portanto, a primeira dessas duas sentenças corresponde exatamente à premissa da\\nsegunda. Consequentemente, SUBST(\\nθ\\n, \\nθ\\n) segue por \\nModus Ponens\\n.\\nO \\nModus Ponens\\n generalizado é uma versão \\nelevada\\n de \\nModus Ponens\\n — ele eleva o \\nModus\\nPonens\\n da lógica básica (livre de variáveis) proposicional à lógica de primeira ordem. Veremos no\\nrestante do capítulo que é possível desenvolver versões elevadas dos algoritmos de encadeamento\\npara a frente, encadeamento para trás e resolução introduzidos no Capítulo 7. A vantagem\\nfundamental das regras de inferência elevadas sobre a proposicionalização é o fato de elas só\\nefetuarem as substituições necessárias para permitir a derivação de inferências específicas.\\n9.2.2 Unificação\\nAs regras de inferência elevadas exigem a descoberta de substituições que façam expressões\\nlógicas diferentes parecerem idênticas. Esse processo é chamado \\nunificação\\n e é um componente\\nfundamental de todos os algoritmos de inferência de primeira ordem. O algoritmo UNIFICAR recebe\\nduas sentenças e retorna um \\nunificador\\n para elas, se existir algum:\\nUNIFICAR(\\np\\n, \\nθ\\n) = \\nθ\\n onde SUBST(\\nθ\\n, \\np\\n) = SUBST(\\nθ\\n, \\nθ\\n)\\nVamos examinar alguns exemplos de como UNIFICAR deve se comportar. Suponha que temos uma\\nconsulta \\nAskVars\\n(\\nConhece\\n(\\nJoão\\n, \\nx\\n)): quem João conhece? Algumas respostas para essa consulta\\npodem ser encontradas descobrindo-se todas as sentenças na base de conhecimento que se unificam\\ncom \\nConhece\\n(\\nJoão\\n, \\nx\\n). Aqui estão os resultados da unificação com quatro diferentes sentenças que\\npoderiam estar na base de conhecimento:\\nA última unificação falha porque \\nx\\n não pode receber os valores \\nJoão\\n e \\nElizabeth\\n ao mesmo\\ntempo. Agora, lembre-se de que \\nConhece\\n(\\nx\\n, \\nElizabeth\\n) significa “Todo mundo conhece Elizabeth” e,\\nassim, \\ndevemos\\n ser capazes de deduzir que João conhece Elizabeth. O problema só surge porque as\\nduas sentenças utilizam o mesmo nome de variável, \\nx\\n. O problema pode ser evitado \\npadronizando\\nseparadamente\\n uma das duas sentenças que estão sendo unificadas, o que significa renomear suas\\nvariáveis para evitar choques entre nomes. Por exemplo, podemos renomear \\nx\\n em \\nConhece\\n(\\nx\\n,\\nElizabeth\\n) como \\nz\\n17\\n (um novo nome de variável) sem alterar seu significado. Agora, a unificação', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 389}),\n",
       " Document(page_content='funcionará:\\nUNIFICAR(\\nConhece\\n(\\nJoão\\n, \\nx\\n), \\nConhece\\n(\\nz\\n17\\n, \\nElizabeth\\n)) = {\\nx\\n/\\nElizabeth\\n, \\nx\\n17\\n/\\nJoão\\n}.\\nO Exercício 9.12 se aprofunda ainda mais na necessidade de padronizar as variáveis\\nseparadamente.\\nExiste mais uma complicação: dissemos que UNIFICAR deve retornar uma substituição que faça\\nos dois argumentos parecerem iguais. Porém, poderia haver mais de um identificador desse tipo. Por\\nexemplo, UNIFICAR(\\nConhece\\n(\\nJoão\\n, \\nx\\n), \\nConhece\\n(\\ny\\n, \\nz\\n)) poderia retornar {\\ny\\n/\\nJoão\\n, \\nx\\n/\\nz\\n} ou {\\ny\\n/\\nJoão\\n,\\nx\\n/\\nJoão\\n, \\nz\\n/\\nJoão\\n}. O primeiro unificador fornece \\nConhece\\n(\\nJoão\\n, \\nz\\n) como resultado da unificação,\\nenquanto o segundo fornece \\nConhece\\n(\\nJoão\\n, \\nJoão\\n). O segundo resultado poderia ser obtido a partir\\ndo primeiro por uma substituição adicional {\\nz\\n/\\nJoão\\n}; dizemos que o primeiro unificador é \\nmais\\ngeral\\n que o segundo porque impõe menos restrições sobre os valores das variáveis. Para todo par de\\nexpressões que pode ser unificado, existe um único \\nunificador mais geral\\n (ou UMG) que é único a\\nmenos de renomear e substituir variáveis (por exemplo, {\\nx\\n/\\nJoão\\n} e {\\ny\\n/\\nJoão\\n} são considerados\\nequivalentes, como também (\\nx\\n/\\nJoão\\n, \\ny\\n/\\nJoão\\n} e {\\nx\\n/\\nJoão\\n, \\ny\\n/\\nx\\n}.) Nesse caso é {\\ny\\n/\\nJoão\\n, \\nx\\n/\\nz\\n}.\\nUm algoritmo para calcular unificadores mais gerais encontra-se na \\nFigura 9.1\\n. O processo é muito\\nsimples: explorar recursivamente as duas expressões de forma simultânea e “lado a lado”,\\nconstruindo um unificador durante o processo, mas falhando se dois pontos correspondentes nas\\nestruturas não coincidirem. Existe uma única etapa dispendiosa: ao comparar uma variável a um\\ntermo complexo, deve-se verificar se a própria variável ocorre dentro do termo; se isso ocorrer, a\\ncorrespondência falhará porque não será possível construir nenhum unificador consistente. Por\\nexemplo, \\nS\\n(\\nx\\n) não pode ser unido com \\nS\\n(\\nS\\n(\\nx\\n)). Esse processo, chamado \\nverificação de ocorrência\\n,\\ntorna a complexidade do algoritmo inteiro quadrática no tamanho das expressões que estão sendo\\nunificadas. Alguns sistemas, inclusive todos os sistemas de programação em lógica, simplesmente\\nomitem a verificação de ocorrência e, como resultado, às vezes fazem inferências incorretas; outros\\nsistemas utilizam algoritmos mais complexos, com complexidade de tempo linear.\\nfunção\\n UNIFICAR(\\nx\\n, \\ny\\n, \\nq\\n) \\nretorna\\n uma substituição para tornar \\nx\\n e \\ny\\n idênticas\\n    \\nentradas:\\n \\nx\\n, uma variável, constante, lista ou expressão composta\\n        \\ny\\n, uma variável, constante, lista ou expressão composta\\n        \\nq\\n, a substituição construída até agora (opcional, o padrão é vazio)\\n    \\n    \\nse\\n \\nq\\n = falha \\nentão retornar\\n falha\\n    \\nsenão se\\n \\nx\\n = \\ny\\n \\nentão retornar\\n \\nq\\n    \\nsenão se\\n VARIÁVEL?(\\nx\\n) \\nentão retornar\\n UNIFICAR-VAR(\\nx\\n, \\ny\\n, \\nq\\n)\\n    \\nsenão se\\n VARIÁVEL?(\\ny\\n) \\nentão retornar\\n UNIFICAR-VAR(\\ny\\n, \\nx\\n, \\nq\\n)\\n    \\nsenão se\\n COMPOSTO?(\\nx\\n) \\ne\\n COMPOSTO?(\\ny\\n) \\nentão\\n        \\nretornar\\n UNIFICAR(ARGS[\\nx\\n], ARGS[y], UNIFICAR(\\nx.\\nOP, \\ny\\n.OP, \\nq\\n))\\n    \\nsenão se\\n LISTA?(\\nx\\n) \\ne\\n LISTA?(\\ny\\n) \\nentão\\n        \\nretornar\\n UNIFICAR(RESTO[\\nx\\n], RESTO[\\ny\\n], UNIFICAR(PRIMEIRO[\\nx\\n], PRIMEIRO[\\ny\\n], \\nq\\n))\\n    \\nsenão retornar\\n falha\\n_____________________________________________________________________________________________________________', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 390}),\n",
       " Document(page_content='função\\n UNIFICAR-VAR(\\nvar\\n, \\nx\\n, \\nq\\n) \\nretorna\\n uma substituição\\n    \\n    \\nse\\n {\\nvar\\n/\\nval\\n} \\n∊\\nq\\n \\nentão retornar\\n UNIFICAR(\\nval\\n, \\nx\\n, \\nq\\n)\\n    \\nsenão se\\n {\\nx\\n/\\nval\\n} \\n∊\\nq\\n \\nentão retornar\\n UNIFICAR(\\nvar\\n, \\nval\\n, \\nq\\n)\\n    \\nsenão se\\n VERIFICAR-OCORRÊNCIA?(\\nvar\\n, \\nx\\n) \\nentão retornar\\n falha\\n    \\nsenão retornar\\n adicionar {var/x} a \\nq\\nFigura 9.1\\n Algoritmo de unificação. O algoritmo funciona comparando as estruturas das entradas,\\nelemento por elemento. A substituição \\nθ\\n, que é o argumento para UNIFICAR, é construída ao longo\\ndo processo e é usada para garantir que comparações posteriores serão consistentes com vinculações\\nestabelecidas anteriormente. Em uma expressão composta, como \\nF\\n(\\nA\\n, \\nB\\n), o campo OP seleciona o\\nsímbolo de função \\nF\\n, e o campo ARGS escolhe a lista de argumentos (\\nA\\n, \\nB\\n).\\n9.2.3 Armazenamento e recuperação\\nSubjacentes às funções TELL e ASK usadas para informar e interrogar uma base de conhecimento,\\nencontram-se as funções mais primitivas ARMAZENAR e RECUPERAR. ARMAZENAR(\\ns\\n)\\narmazena uma sentença \\ns\\n na base de conhecimento e RECUPERAR(\\nθ\\n) retorna todos os unificadores\\ntais que a consulta \\nθ\\n se unifica com alguma sentença na base de conhecimento. O problema que\\nusamos para ilustrar a unificação — encontrar todos os fatos que se unificam com \\nConhece\\n(\\nJoão\\n, \\nx\\n)\\n— é um exemplo de RECUPERAR.\\nO caminho mais simples para implementar ARMAZENAR e RECUPERAR é manter todos os fatos\\nem uma lista longa e unificar cada consulta com cada elemento da lista. Tal processo é ineficiente\\nmas funciona, e é tudo o que você precisa ter para entender o restante do capítulo. O restante desta\\nseção descreve meios de tornar a recuperação mais eficiente e pode ser ignorado em uma primeira\\nleitura.\\nPodemos tornar RECUPERAR mais eficiente assegurando que só serão experimentadas\\nunificações com sentenças que tenham \\nalguma\\n chance de unificação. Por exemplo, não há razão para\\ntentar unificar \\nConhece\\n(\\nJoão\\n, \\nx\\n) com \\nIrmão\\n(\\nRicardo\\n, \\nJoão\\n). Podemos evitar tais unificações pela\\nindexação\\n dos fatos na base de conhecimento.\\nUm esquema simples chamado \\nindexação de predicados\\n coloca todos os fatos de \\nConhece\\n em um\\núnico compartimento, e todos os fatos de \\nIrmão\\n em outro. Os compartimentos podem ser\\narmazenados em uma tabela de hash para garantir acesso eficiente.\\nA indexação de predicados é útil quando existem muitos símbolos de predicados, mas apenas\\nalgumas cláusulas para cada símbolo. Algumas vezes, no entanto, um predicado tem muitas cláusulas.\\nPor exemplo, suponha que as autoridades fiscais queiram controlar quem emprega quem, utilizando\\num predicado \\nEmprega\\n(\\nx\\n, \\ny\\n). Esse seria um compartimento muito grande, talvez com milhões de\\nempregadores e dezenas de milhões de empregados. A resposta a uma consulta como \\nEmprega\\n(\\nx\\n,\\nRicardo\\n) com indexação de predicados exigiria o exame do compartimento inteiro.\\nPara essa consulta em particular, seria útil se os fatos estivessem indexados por predicado e pelo\\nsegundo argumento, talvez com a utilização de uma chave de tabela de hash combinada. Então,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 391}),\n",
       " Document(page_content='poderíamos simplesmente construir a chave a partir da consulta e recuperar exatamente os fatos que\\nse unificam com a consulta. No caso de outras consultas, como \\nEmprega\\n(\\nIBM\\n, \\ny\\n), precisaríamos ter\\nindexado os fatos combinando o predicado com o primeiro argumento. Por essa razão, os fatos\\npodem ser armazenados sob várias chaves de índice, tornando-se instantaneamente acessíveis a\\nvárias consultas com as quais poderiam se unificar.\\nDada uma sentença a ser armazenada, é possível construir índices para \\ntodas as consultas\\npossíveis\\n que se unificam com ela. Para o fato \\nEmprega\\n(\\nIBM\\n, \\nRicardo\\n), as consultas são:\\nEmprega\\n(\\nIBM\\n, \\nRicardo\\n) \\nIBM emprega Ricardo?\\nEmprega\\n(\\nx\\n, \\nRicardo\\n)\\nQuem emprega Ricardo?\\nEmprega\\n(\\nIBM\\n, \\ny\\n)\\nQuem a IBM emprega?\\nEmprega\\n(\\nx\\n, \\ny\\n)\\nQuem emprega quem?\\nEssas consultas formam um \\nreticulado de subordinação\\n, como mostra a \\nFigura 9.2\\n(a). O\\nreticulado tem algumas propriedades interessantes. Por exemplo, o filho de qualquer nó no reticulado\\né obtido a partir de seu pai por uma única substituição; e o “mais alto” descendente comum de dois\\nnós quaisquer é o resultado da aplicação do unificador mais geral. A porção do reticulado acima de\\nqualquer fato básico pode ser construída sistematicamente (Exercício 9.5). Uma sentença com\\nconstantes repetidas tem um reticulado ligeiramente diferente, como mostra a \\nFigura 9.2\\n(b). Símbolos\\nde funções e variáveis nas sentenças a serem armazenadas introduzem estruturas de reticulados ainda\\nmais interessantes.\\nFigura 9.2\\n (a) Reticulado de subordinação cujo nó mais baixo é a sentença \\nEmprega\\n(\\nIBM\\n, \\nRicardo\\n).\\n(b) Reticulado de subordinação para a sentença \\nEmprega\\n(\\nJoão\\n, \\nJoão\\n).\\nO esquema que descrevemos funciona muito bem sempre que o reticulado contém um número\\npequeno de nós. Para um predicado com \\nn\\n argumentos, entretanto, o reticulado contém \\nO\\n(2\\nn\\n) nós. Se\\nforem permitidos símbolos de funções, o número de nós também será exponencial no tamanho dos\\ntermos da sentença a ser armazenada. Isso pode levar a um número enorme de índices. Em certo\\nmomento, os benefícios da indexação são superados em valor pelos custos de armazenamento e\\nmanutenção de todos os índices. Podemos responder adotando uma política fixa, como manter índices\\napenas para chaves compostas de um predicado e cada um de seus argumentos ou usando uma\\npolítica adaptável que crie índices para atender às demandas dos tipos de consultas que estão sendo\\nformuladas. Para a maioria dos sistemas de IA, o número de fatos a serem armazenados é pequeno o\\nbastante para que a indexação eficiente seja considerada um problema resolvido. Para bancos de\\ndados industriais e comerciais, nos quais os fatos quantificam-se na casa dos bilhões, o problema\\ntem sido objeto de estudo intenso e desenvolvimento de tecnologia.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 392}),\n",
       " Document(page_content='9.3 ENCADEAMENTO PARA A FRENTE\\nUm algoritmo de encadeamento para a frente para cláusulas definidas proposicionais foi\\napresentado na \\nSeção 7.5\\n. A ideia é simples: começar com as sentenças atômicas da base de\\nconhecimento e aplicar \\nModus\\n \\nPonens\\n no sentido para a frente, acrescentando novas sentenças\\natômicas até não ser mais possível fazer nenhuma inferência adicional. Aqui, explicamos como o\\nalgoritmo é aplicado a cláusulas definidas de primeira ordem. Cláusulas definidas como \\nSituação\\n \\n⇒\\nResposta\\n são especialmente úteis no caso de sistemas que fazem inferências em resposta a\\ninformações recém-chegadas. Muitos sistemas podem ser definidos desse modo, e o encadeamento\\npara a frente pode ser implementado muito eficientemente.\\n9.3.1 Cláusulas definidas de primeira ordem\\nAs cláusulas definidas de primeira ordem são muito semelhantes às cláusulas definidas\\nproposicionais: elas são disjunções de literais dos quais \\nexatamente um é positivo\\n. Uma cláusula\\ndefinida é atômica ou é uma implicação cujo antecedente é uma conjunção de literais positivos e cujo\\nconsequente é um único literal positivo. As cláusulas a seguir são cláusulas definidas de primeira\\nordem:\\nAo contrário dos literais proposicionais, os literais de primeira ordem podem incluir variáveis e,\\nnesse caso, essas variáveis são consideradas universalmente quantificadas (em geral, omitimos os\\nquantificadores universais quando escrevemos cláusulas definidas).\\nNem toda base de conhecimento pode ser convertida em um conjunto de cláusulas definidas,\\ndevido à restrição de único literal positivo, mas muitas podem. Considere o problema a seguir:\\nA lei diz que é crime um americano vender armas a nações hostis. O país Nono, inimigo da\\nAmérica, tem alguns mísseis, e todos foram vendidos pelo Coronel West, um americano.\\nProvaremos que West é um criminoso. Primeiro, vamos representar esses fatos como cláusulas\\ndefinidas de primeira ordem. A próxima seção mostrará como o algoritmo de encadeamento para a\\nfrente resolve o problema.\\n“… é crime um americano vender armas a nações hostis”:\\n“Nono… tem alguns mísseis.” A sentença \\n∃\\n \\nx Possui\\n(\\nNono\\n, \\nx\\n) \\n∧\\n \\nMíssil\\n(\\nx\\n) é transformada em duas\\ncláusulas definidas por eliminação existencial, introduzindo-se uma nova constante \\nM\\n1\\n:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 393}),\n",
       " Document(page_content='“Todos foram vendidos pelo Coronel West”:\\nTambém precisamos saber que mísseis são armas:\\ne devemos saber que um inimigo da América é considerado “hostil”:\\n“West, um americano…”:\\n“O país Nono, inimigo da América…”:\\nEssa base de conhecimento não contém nenhum símbolo de função e, portanto, é uma instância da\\nclasse Datalog de bases de conhecimento. Datalog é uma linguagem restrita a cláusulas definidas de\\nprimeira ordem sem símbolos de funções. O nome Datalog deve-se a poder representar o tipo de\\nasserções feitas tipicamente em bancos de dados relacionais. Veremos que a ausência de símbolos de\\nfunções torna a inferência muito mais fácil.\\n9.3.2 Um algoritmo de encadeamento para a frente simples\\nO primeiro algoritmo de encadeamento para a frente que examinaremos é muito simples, como\\nmostra a \\nFigura 9.3\\n. Começando pelos fatos conhecidos, ele ativa todas as regras cujas premissas\\nsão satisfeitas, adicionando suas conclusões aos fatos conhecidos. O processo se repete até a\\nconsulta ser respondida (supondo-se que apenas uma resposta seja necessária) ou que nenhum fato\\nnovo seja adicionado. Note que um fato não é “novo” se for apenas uma \\nrenomeação\\n de um fato\\nconhecido. Uma sentença é uma renomeação de outra se elas são sentenças idênticas, exceto pelos\\nnomes das variáveis. Por exemplo, \\nGosta\\n(\\nx\\n, \\nSorvete\\n) e \\nGosta\\n(\\ny\\n, \\nsorvete\\n) são renomeações uma da\\noutra porque diferem apenas na escolha de \\nx\\n ou \\ny\\n; seus significados são idênticos: todo mundo gosta\\nde sorvete.\\nfunção\\n ASK-LPO-EF(\\nBC\\n, a) \\nretorna\\n uma substituição ou \\nfalso\\n    \\nentradas:\\n \\nBC\\n, a base de conhecimento, um conjunto de cláusulas definidas de primeira ordem\\n            a, a consulta, uma sentença atômica\\n    \\nvariáveis locais:\\n \\nnova\\n, as novas sentenças deduzidas em cada iteração', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 394}),\n",
       " Document(page_content='repita até\\n \\nnova\\n seja vazio\\n        \\nnova\\n ← { }\\n        \\npara cada\\n \\nregra\\n \\nem\\n \\nBC\\n \\nfaça\\n            (\\np\\n1 \\n∧\\n … \\n∧\\n \\np\\nn\\n\\u2002\\n⇒\\n\\u2002\\nq\\n) ← PADRONIZAR-VARIÁVEIS(\\nregra\\n)\\n            \\npara cada\\n \\nq\\n tal que SUBST(\\nq\\n, \\np\\n1 \\n∧\\n … \\n∧\\n \\np\\nn\\n) = SUBST(\\nq\\n, \\np\\n′1 \\n∧\\n … \\n∧\\n \\np\\n′\\nn\\n)\\npara algum \\np\\n′1, … \\np\\n′\\nn\\n em \\nBC\\nq\\n′ ← SUBST(\\nq\\n, \\nq\\n)\\nse\\n \\nq\\n′ não unifica com alguma sentença já em \\nBC\\n ou \\nnova\\n \\nentão faça\\nadicionar \\nq\\n′ a \\nnova\\nφ\\n ← UNIFICAR(\\nq\\n′, a)\\nse\\n \\nφ\\n não é \\nfalha\\n \\nentão retornar\\n \\nφ\\n        adicionar \\nnova\\n a \\nBC\\n    \\nretornar\\n \\nfalso\\nFigura 9.3\\n Algoritmo conceitualmente simples, mas muito ineficiente, de encadeamento para a frente.\\nEm cada iteração, ele acrescenta a \\nBC\\n todas as sentenças atômicas que podem ser deduzidas em uma\\núnica etapa das sentenças de implicação e das sentenças atômicas que já estão em \\nBC\\n. A função\\nPADRONIZAR-VARIÁVEIS substitui todas as variáveis em seus argumentos com outras que nunca\\nforam utilizadas antes.\\nUsaremos nosso problema criminal para ilustrar como funciona ASK-LPO-EF. As sentenças de\\nimplicação são 9.3, 9.6, 9.7 e 9.8. Duas iterações são necessárias:\\n•  Na primeira iteração, a regra 9.3 tem premissas não satisfeitas.\\nA regra 9.6 é satisfeita com {\\nx\\n/\\nM\\n1\\n}, e \\nVende\\n(\\nWest\\n, \\nM\\n1\\n, \\nNono\\n) é adicionada.\\nA regra 9.7 é satisfeita com {\\nx\\n/\\nM\\n1\\n}, e \\nArma\\n(\\nM\\n1\\n) é adicionada.\\nA regra 9.8 é satisfeita com {\\nx\\n/\\nNono\\n} e \\nHostil\\n(\\nNono\\n) é adicionada.\\n•  Na segunda iteração, a regra 9.3 é satisfeita com {\\nx\\n/\\nWest\\n, \\ny\\n/\\nM\\n1\\n, \\nz\\n/\\nNono\\n} e \\nCriminoso\\n(\\nWest\\n) é\\nadicionado.\\nA \\nFigura 9.4\\n mostra a árvore de prova gerada. Note que nenhuma nova inferência é possível nesse\\nponto porque toda sentença que poderia ser uma conclusão produzida por encadeamento para a frente\\njá está contida explicitamente na BC. Tal base de conhecimento é chamada \\nponto fixo\\n do processo\\nde inferência. Os pontos fixos alcançados por encadeamento para a frente com cláusulas definidas de\\nprimeira ordem são semelhantes aos do encadeamento para a frente proposicional; a principal\\ndiferença é que um ponto fixo de primeira ordem pode incluir sentenças atômicas universalmente\\nquantificadas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 395}),\n",
       " Document(page_content='Figura 9.4\\n A árvore de prova gerada por encadeamento para a frente no exemplo do crime. Os fatos\\niniciais aparecem no nível inferior, os fatos deduzidos na primeira iteração aparecem no nível\\nintermediário, e os fatos deduzidos na segunda iteração encontram-se no nível superior.\\nÉ fácil analisar ASK-LPO-EF. Em primeiro lugar, ele é \\ncorreto\\n porque toda inferência é apenas\\numa aplicação do \\nModus Ponens\\n generalizado, que é correto. Em segundo lugar, ele é \\ncompleto\\n para\\nbases de conhecimento de cláusulas definidas, ou seja, ele responde a toda consulta cujas respostas\\nsão consequências lógicas de qualquer base de conhecimento de cláusulas definidas. No caso de\\nbases de conhecimento Datalog, que não contêm símbolos de funções, a prova de completude é\\nbastante fácil. Começamos efetuando a contagem do número de fatos possíveis que podem ser\\nadicionados, o que determina o número máximo de iterações. Seja \\nk\\n a \\naridade\\n máxima (o número de\\nargumentos) de qualquer predicado, seja \\np\\n o número de predicados e seja \\nn\\n o número de símbolos de\\nconstantes. É claro que não pode haver mais de \\npn\\nk\\n fatos básicos distintos; assim, após essa\\nquantidade de iterações, o algoritmo deve ter alcançado um ponto fixo. Então, podemos criar um\\nargumento muito semelhante à prova de completude do encadeamento para a frente proposicional. Os\\ndetalhes de como fazer a transição de completude proposicional para compleude de primeira ordem\\nsão dados para o algoritmo de resolução na \\nSeção 9.5\\n.\\nPara cláusulas definidas gerais com símbolos de funções, ASK-LPO-EF pode gerar infinitos novos\\nfatos e, assim, precisamos ser mais cuidadosos. No caso em que uma resposta à sentença da consulta\\nθ\\n é consequência lógica, devemos apelar para o teorema de Herbrand, a fim de estabelecer que o\\nalgoritmo encontrará uma prova (veja na \\nSeção 9.5\\n o caso de resolução). Se a consulta não tivesse\\nnenhuma resposta, o algoritmo poderia não terminar em alguns casos. Por exemplo, se a base de\\nconhecimento incluir os axiomas de Peano\\no encadeamento para a frente adicionará \\nNumNat\\n(\\nS\\n(0)), \\nNumNat\\n(\\nS\\n(\\nS\\n(0))), \\nNumNat\\n(\\nS\\n(\\nS\\n(\\nS\\n(0)))), e\\nassim por diante. Em geral, esse problema é inevitável. Como ocorre no caso da lógica de primeira\\nordem geral, a conse\\u200bquência lógica com cláusulas definidas é semidecidível.\\n9.3.3 Encadeamento para a frente eficiente', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 396}),\n",
       " Document(page_content='O algoritmo de encadeamento para a frente da \\nFigura 9.3\\n foi projetado para facilitar a\\ncompreensão, e não visando à eficiência de operação. Existem três fontes possíveis de\\ncomplexidade. Primeiro, o “laço interno” do algoritmo envolve a localização de todos os\\nunificadores possíveis tais que a premissa de uma regra se unifica com um conjunto adequado de\\nfatos na base de conhecimento. Com frequência, esse processo é chamado \\ncorrespondência de\\npadrões\\n e pode ser muito dispendioso. Em segundo lugar, o algoritmo verifica exaustivamente cada\\nregra em toda iteração para ver se suas premissas são satisfeitas, ainda que muito poucas adições\\nsejam feitas à base de conhecimento em cada iteração. Por fim, o algoritmo poderia gerar muitos\\nfatos irrelevantes para o objetivo. Examinaremos cada uma dessas fontes separadamente.\\nComparação entre regras e fatos conhecidos\\nO problema de comparar a premissa de uma regra contra os fatos na base de conhecimento talvez\\npareça simples. Por exemplo, vamos supor que desejamos aplicar a regra:\\nEm seguida, precisamos encontrar todos os fatos que se unificam com \\nMíssil\\n(\\nx\\n); em uma base de\\nconhecimento indexada de modo adequado, isso pode ser feito em tempo constante por fato. Agora,\\nconsidere uma regra como:\\nNovamente, podemos encontrar todos os objetos que Nono possui em tempo constante por objeto;\\nem seguida, para cada objeto, poderíamos verificar se ele é ou não um míssil. Porém, se a base de\\nconhecimento contiver muitos objetos pertencentes a Nono e muito poucos mísseis, será melhor\\nencontrar todos os mísseis primeiro e depois verificar se eles pertencem a Nono. Esse é o problema\\nda \\nordenação de elementos da conjunção\\n: encontrar uma ordenação para resolver os elementos da\\nconjunção da premissa de regra, de tal forma que o custo total seja minimizado. Ocorre que a\\ndescoberta da ordenação ótima é NP-difícil, mas existem boas heurísticas disponíveis. Por exemplo,\\na heurística de \\nvalores restantes mínimos\\n (VRM) usada para PSRs no Capítulo 6 sugeriria ordenar\\nos elementos da conjunção para procurar primeiro por mísseis, se houvesse menos mísseis que\\nobjetos pertencentes a Nono.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 397}),\n",
       " Document(page_content='Figura 9.5\\n (a) Grafo de restrição para colorir o mapa da Austrália. (b) PSR de coloração de mapas,\\nexpresso como uma única cláusula definida. Cada região do mapa é representada por uma variável\\ncujo valor pode ser uma das constantes \\nvermelho\\n, \\nverde\\n ou \\nazul.\\n A conexão entre a correspondência de padrões e a satisfação de restrições é na realidade muito\\nestreita. Podemos visualizar cada elemento da conjunção como uma restrição sobre as variáveis que\\nele contém — por exemplo, \\nMíssil\\n(\\nx\\n) é uma restrição unária sobre \\nx\\n. Estendendo essa ideia,\\npodemos expressar todo PSR de domínio finito como uma única cláusula definida juntamente com\\nalguns fatos básicos associados\\n. Considere o problema de coloração de mapa da \\nFigura 6.1\\n,\\nmostrado mais uma vez na \\nFigura 9.5\\n(a). Uma formulação equivalente como uma única cláusula\\ndefinida é apresentada na \\nFigura 9.5\\n(b). É claro que a conclusão \\nPodeSerColorido\\n( ) só poderá ser\\ndeduzida se o PSR tiver uma solução. Como os PSRs em geral incluem problemas 3-SAT como\\ncasos especiais, podemos concluir que \\ncomparar uma cláusula definida com um conjunto de fatos é\\nNP\\n-\\ndifícil\\n.\\nTalvez pareça bastante deprimente que o encadeamento para a frente tenha um problema de\\ncorrespondência NP-difícil em seu loop mais interno. Existem três caminhos para nos alegrar:\\n•  Podemos lembrar que a maioria das regras em base de conhecimento reais é pequena e simples\\n(como as regras em nosso exemplo de crime), em vez de serem regras grandes e complexas\\n(como a formulação de PSR da \\nFigura 9.5\\n). É comum, no mundo de bancos de dados, supor que\\ntanto os tamanhos das regras quanto as aridades de predicados são limitadas por uma constante e\\nse preocupar apenas com a \\ncomplexidade de dados\\n, isto é, a complexidade da inferência como\\numa função do número de fatos básicos no banco de dados. É fácil mostrar que a complexidade\\nde dados de encadeamento para a frente é polinomial.\\n•  Podemos considerar subclasses de regras para as quais a correspondência é eficiente. Em\\nessência, toda cláusula Datalog pode ser vista como a definição de um PSR e, assim, a\\ncorrespondência será tratável apenas quando o PSR correspondente for tratável. O Capítulo 6\\ndescreve diversas famílias de PSRs tratáveis. Por exemplo, se o grafo de restrições (o grafo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 398}),\n",
       " Document(page_content='cujos nós são variáveis e cujos vínculos são restrições) formar uma árvore, o PSR poderá ser\\nresolvido em tempo linear. Exatamente o mesmo resultado é válido no caso da correspondência\\nde regras. Por exemplo, se removermos a Austrália Meridional do mapa da \\nFigura 9.5\\n, a\\ncláusula resultante s\\nerá\\nque corresponde ao PSR reduzido mostrado na \\nFigura 6.12\\n. Os algoritmos para resolver PSRs\\nestruturados em árvore podem ser aplicados diretamente ao problema de correspondência de\\nregras.\\n•  Podemos tentar eliminar tentativas redundantes para estabelecer correspondência entre regras no\\nalgoritmo de encadeamento para a frente, como descrevemos a seguir.\\nEncadeamento para a frente incremental\\nQuando mostramos como funciona o encadeamento para a frente no exemplo do crime,\\ntrapaceamos; em particular, omitimos uma parte da correspondência de regras realizada pelo\\nalgoritmo da \\nFigura 9.3\\n. Por exemplo, na segunda iteração, a regra\\n é comparada a \\nMíssil\\n(\\nM\\n1\\n) (mais uma vez) e, é claro, a conclusão \\nArma\\n(\\nM\\n1\\n) já é conhecida, e\\nportanto nada acontece. Tal correspondência de regras redundante pode ser evitada se fizermos a\\nseguinte observação: \\ntodo fato novo deduzido na iteração t deve ser derivado de pelo menos um\\nfato novo deduzido na iteração t\\n – 1. Isso é verdadeiro porque qualquer inferência que não exigisse\\num fato novo da iteração \\nt\\n – 1 poderia já ter sido realizada na iteração \\nt\\n – 1.\\nEssa observação leva naturalmente a um algoritmo de encadeamento para a frente incremental\\nonde, na iteração \\nt\\n, verificamos uma regra apenas se sua premissa inclui um elemento \\np\\ni\\n que se\\nunifica com um fato \\np\\n′\\ni\\n recém-deduzido na iteração \\nt\\n – 1. A etapa de correspondência de regras fixa\\np\\ni\\n para fazê-lo corresponder a \\np\\n′\\ni\\n, mas permite que os outros elementos da conjunção da regra\\ncorrespondam a fatos de qualquer iteração anterior. Esse algoritmo gera exatamente os mesmos fatos\\nem cada iteração que o algoritmo da \\nFigura 9.3\\n, mas é muito mais eficiente.\\nCom a indexação apropriada, é fácil identificar todas as regras que podem ser ativadas por\\nqualquer fato dado e, na verdade, muitos sistemas reais operam em modo de “atualização”, em que\\nocorre o encadeamento para a frente em resposta a cada fato novo que seja informado (com TELL)\\nao sistema. As inferências se propagam em cascata pelo conjunto de regras até ser alcançado o ponto\\nfixo e depois o processo recomeça para o próximo fato novo.\\nEm geral, apenas uma pequena fração das regras na base de conhecimento é de fato ativada pela\\ninclusão de determinado fato. Isso significa que é realizado muito trabalho redundante na construção\\nrepetida de correspondências parciais que têm algumas premissas não satisfeitas. Nosso exemplo de\\ncrime é muito pequeno para mostrar isso de forma efetiva, mas note que uma correspondência parcial\\né construída na primeira iteração entre a regra', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 399}),\n",
       " Document(page_content='e o fato \\nAmericano\\n(\\nWest\\n). Essa correspondência parcial é então descartada e reconstruída na\\nsegunda iteração (quando a regra tem sucesso). Seria melhor reter e completar gradualmente as\\ncorrespondências parciais à medida que novos fatos chegassem, em vez de descartá-las.\\nO algoritmo \\nrete\\n3\\n foi o primeiro a atacar esse problema. O algoritmo efetua o pré-processamento\\ndo conjunto de regras na base de conhecimento para construir uma espécie de rede de fluxo de dados\\nem que cada nó é um literal de uma premissa de regra. As vinculações de variáveis fluem pela rede e\\nsão filtradas quando deixam de corresponder a um literal. Se dois literais de uma regra compartilham\\numa variável — por exemplo, \\nVende\\n(\\nx\\n, \\ny\\n, \\nz\\n) \\n∧\\n \\nHostil\\n(\\nz\\n) em nosso caso do crime —, as vinculações\\nde cada literal são filtradas através de um nó de igualdade. Uma vinculação de variáveis que alcança\\num nó para um literal \\nn\\n-ário como \\nVende\\n(\\nx\\n, \\ny\\n, \\nz\\n) poderia ter de esperar que as vinculações\\ncorrespondentes às outras variáveis fossem estabelecidas, de modo que o processo pudesse\\ncontinuar. Em qualquer instante dado, o estado de uma rede \\nrete\\n capta todas as correspondências\\nparciais das regras, evitando grande quantidade de repetição de cálculos.\\nAs redes \\nrete\\n, bem como diversas melhorias ocorridas a partir delas, constituíram um\\ncomponente-chave dos chamados \\nsistemas de produção\\n, que estavam entre os sistemas de\\nencadeamento para a frente mais antigos de uso difundido.\\n4\\n O sistema XCON (originalmente\\nchamado R1, McDermott, 1982) foi construído com o emprego de uma arquitetura de sistema de\\nprodução. O XCON continha vários milhares de regras para projetar configurações de componentes\\nde computadores destinados aos clientes da Digital Equipment Corporation. Ele se tornou um dos\\nprimeiros sucessos comerciais no campo emergente de sistemas especialistas. Muitos outros sistemas\\nsemelhantes foram construídos com a utilização da mesma tecnologia subjacente, que foi\\nimplementada na linguagem de uso geral OPS-5.\\nOs sistemas de produção também são populares em \\narquiteturas cognitivas\\n — ou seja, modelos\\nde raciocínio humano — como ACT (Anderson, 1983) e SOAR (Laird \\net al\\n., 1987). Em tais\\nsistemas, a “memória de trabalho” do sistema tem como modelo a memória humana de curto prazo, e\\nas produções fazem parte da memória de longo prazo. Em cada ciclo de operação, as produções são\\ncomparadas à memória de trabalho de fatos. Uma produção cujas condições são satisfeitas pode\\nadicionar ou excluir fatos da memória de trabalho. Em contraste com a situação típica em bancos de\\ndados, com frequência os sistemas de produção têm muitas regras e relativamente poucos fatos. Com\\numa tecnologia de comparação otimizada de maneira adequada, alguns sistemas modernos podem\\noperar em tempo real com mais de 10 mihões de regras.\\nFatos irrelevantes\\nA última fonte de ineficiência no encadeamento para a frente parece ser intrínseca à abordagem e\\ntambém surge no contexto proposicional. O encadeamento para a frente faz todas as inferências\\npermissíveis com base nos fatos conhecidos, \\nmesmo que eles sejam irrelevantes para o objetivo\\n.\\nEm nosso exemplo de crime, não havia nenhuma regra capaz de tirar conclusões irrelevantes e,\\nassim, a falta de orientação não era um problema sério. Em outros casos (por exemplo, se muitas\\nregras que descrevem os hábitos alimentares dos americanos e os preços dos mísseis), ASK-LPO-EF\\nvai gerar muitas conclusões irrelevantes.\\nUm modo de se evitar conclusões irrelevantes é usar o encadeamento para trás, como descreve a\\nSeção 9.4\\n. Outra solução é restringir o encadeamento para a frente a um subconjunto selecionado de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 400}),\n",
       " Document(page_content='regras, como na CONSEQUÊNCIA-LÓGICA-LP-EF?. Uma terceira abordagem emergiu no campo\\nde \\nbases de dados dedutivas\\n, que são grandes bases de dados, como bancos de dados relacionais,\\nmas que usam encadeamento para a frente como ferramenta-padrão de inferência em vez de consultas\\nSQL. A ideia é reescrever o conjunto de regras utilizando informações do objetivo, de modo que\\napenas vinculações de variáveis relevantes — aquelas que pertencem a um conjunto denominado\\nconjunto mágico\\n — sejam consideradas durante a inferência para a frente. Por exemplo, se o\\nobjetivo é \\nCriminoso\\n(\\nWest\\n), a regra que conclui \\nCriminoso\\n(\\nx\\n) será reescrita para incluir um\\nelemento extra que limite o valor de \\nx\\n:\\nO fato \\nMágico\\n(\\nWest\\n) também é adicionado a BC. Desse modo, mesmo que a base de\\nconhecimento contenha fatos sobre milhões de americanos, apenas o Coronel West será considerado\\ndurante o processo de inferência para a frente. O processo completo para definir os conjuntos\\nmágicos e reescrever a base de conhecimento é complexo demais para abordamos aqui, mas a ideia\\nbásica é realizar uma espécie de inferência para trás “genérica” a partir do objetivo, a fim de\\ndescobrir quais vinculações de variáveis precisam ser limitadas. A abordagem de conjuntos mágicos\\npode então ser pensada como uma espécie de híbrido entre a inferência para a frente e o pré-\\nprocessamento para trás.\\n9.4 ENCADEAMENTO PARA TRÁS\\nA segunda família importante de algoritmos de inferência lógica utiliza a abordagem de\\nencadeamento para trás\\n introduzida na \\nSeção 7.5\\n para cláusulas definidas. Esses algoritmos\\nfuncionam no sentido inverso a partir do objetivo, encadeando regras até encontrar fatos conhecidos\\nque apoiem a prova. Examinaremos o algoritmo básico e depois descreveremos como ele é usado em\\nprogramação em lógica\\n, que é a forma mais amplamente utilizada de raciocínio automatizado.\\nTambém veremos que o encadeamento para trás tem algumas desvantagens em comparação com o\\nencadeamento para a frente e estudaremos os meios para superá-las. Finalmente, observaremos a\\nestreita conexão entre a programação em lógica e os problemas de satisfação de restrições.\\n9.4.1 Um algoritmo de encadeamento para trás\\nA \\nFigura 9.6\\n mostra um algoritmo de encadeamento para trás para cláusulas definidas. ASK-LPO-\\nET (\\nBC\\n, \\nmeta\\n) será provado se a base de conhecimento contiver uma cláusula da forma \\nle\\n\\u2002\\n⇒\\n\\u2002\\nmeta\\n,\\nonde \\nle\\n (lado esquerdo) é uma lista de conjunções. Um fato atômico como \\nAmericano\\n(\\nWest\\n) é\\nconsiderado como uma cláusula cujo \\nle\\n é a lista vazia. Agora uma consulta que contém variáveis \\npode ser provada de várias maneiras. Por exemplo, a consulta \\nPessoa\\n(\\nx\\n) poderia ser provada com a\\nsubstituição {\\nx\\n/\\nJoão\\n}, bem como com {\\nx\\n/\\nRicardo\\n}. Então implementamos ASK-LPO-ET como um\\ngerador\\n — uma função que retorna várias vezes, a cada vez dando um resultado possível.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 401}),\n",
       " Document(page_content='função\\n ASK-LPO-ET(\\nBC\\n, \\nconsulta\\n) \\nretorna\\n um gerador de substituições\\n    \\nretorna\\n OU-LPO-ET(\\nBC\\n, \\nconsulta\\n,{ })\\n_____________________________________________________________________________________________________________\\ngerador\\n OU-LPO-ET(\\nBC\\n, \\nmeta\\n, \\nθ\\n) \\nproduz\\n uma substituição\\n    \\npara cada\\n regra (\\nle\\n \\n⇒\\n \\nld\\n) em RECUPERA-REGRAS-PARA-META(\\nBC\\n, \\nmeta\\n) \\nfaça\\n        (\\nle\\n, \\nld\\n)←PADRONIZAÇÃO-VARIÁVEIS((\\nle,\\n \\nld\\n))\\n        \\npara cada\\n \\nq′\\n \\nem\\n E-LPO-ET(\\nBC\\n, \\nle\\n, UNIFICAR(\\nld\\n, \\nmeta\\n, \\nq\\n) \\nfaça\\n            \\nproduzir\\n \\nq′\\n_____________________________________________________________________________________________________________\\ngerador\\n E-LPO-ET(\\nBC\\n, \\nmetas\\n, \\nq\\n) \\nproduz\\n substituição\\n    se \\nq\\n = \\nfalha\\n \\nentão retornar\\n    \\nsenão se\\n COMPRIMENTO(\\nmetas\\n) = 0 \\nentão produz\\n \\nq\\n    \\nsenão faça\\n        \\nprimeiro\\n,\\nresto\\n ← PRIMEIRO(\\nmetas\\n), RESTO(\\nmetas\\n)\\n        \\npara cada\\n \\nq′\\n \\nem\\n OU-LPO-ET (\\nBC\\n, SUBST(\\nq\\n, \\nprimeiro\\n), \\nq\\n) \\nfaça\\n            \\npara cada\\n \\nq′′\\n \\nem\\n E-LPO-ET (\\nBC\\n, \\nresto\\n, \\nq′\\n ) \\nfaça\\n                \\nproduzir\\n \\nq′′\\nFigura 9.6\\n Algoritmo de encadeamento para trás simples para bases de conhecimento de primeira\\nordem.\\nO encadeamento para trás é uma espécie de busca E/OU — a parte OU porque a consulta objetivo\\npode ser provada por qualquer regra na base de conhecimento, e a parte E porque todas as\\nconjunções no \\nle\\n de uma cláusula devem ser provadas. OU-LPO-ET funciona buscando todas as\\ncláusulas que possam unificar com o objetivo, padronizando as variáveis na cláusula como variáveis\\nnovas em folha e, então, se o \\nld\\n (lado direito) da cláusula de fato unificar com o objetivo, provando\\ncada conjunto no \\nle\\n, usando E-LPO-ET. Essa função, por sua vez, funciona provando cada um dos\\nconjuntos por vez, guardando a substituição acumulada à medida que avançamos. A \\nFigura 9.7\\n é a\\nárvore de prova para derivação de \\nCriminoso\\n(\\nWest\\n) a partir das sentenças 9.3 a 9.10.\\nFigura 9.7\\n Árvore de prova construída por encadeamento para trás para provar que West é um', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 402}),\n",
       " Document(page_content='criminoso. A árvore deve ser lida primeiro na profundidade, da esquerda para a direita. Para provar\\nCriminoso\\n(\\nWest\\n), temos de provar os quatro elementos da conjunção abaixo dele. Alguns desses\\nelementos estão na base de conhecimento e outros exigem encadeamento para trás adicional. As\\nvinculações correspondentes a cada unificação bem-sucedida são mostradas junto ao subobjetivo\\ncorrespondente. Observe que, uma vez que um subobjetivo em uma conjunção tem sucesso, sua\\nsubstituição é aplicada aos subobjetivos subsequentes. Desse modo, no momento em que ASK-LPO-\\nET chegar ao último elemento da conjunção, originalmente \\nHostil\\n(\\nz\\n), \\nz\\n já estará vinculado a \\nNono\\n.\\nO encadeamento para trás, como o escrevemos, sem dúvida é um algoritmo de busca em\\nprofundidade. Isso significa que seus requisitos de espaço são lineares em relação ao tamanho da\\nprova (negligenciando-se, no momento, o espaço necessário para acumular as soluções). Isso também\\nsignifica que o encadeamento para trás (diferentemente do encadeamento para a frente) se ressente de\\nproblemas com estados repetidos e incompletude. Discutiremos esses problemas e algumas soluções\\npotenciais, mas primeiro veremos como o encadeamento para trás é usado em sistemas de\\nprogramação em lógica.\\n9.4.2 Programação em lógica\\nA programação em lógica é uma tecnologia que se aproxima bastante da incorporação do ideal\\ndeclarativo descrito no Capítulo 7: os sistemas devem ser construídos expressando-se o\\nconhecimento em linguagem formal, e os problemas devem ser resolvidos executando-se processos\\nde inferência sobre esse conhecimento. Esse ideal é resumido na equação de Robert Kowalski,\\nO \\nProlog\\n é de longe a mais amplamente utilizada linguagem de programação em lógica. Ele é\\nusado principalmente como linguagem de prototipação rápida e para tarefas de manipulação de\\nsímbolos, como a criação de compiladores (Van Roy, 1990) e análise de linguagem natural (Pereira\\ne Warren, 1980). Muitos sistemas especialistas foram escritos em Prolog para domínios jurídicos,\\nmédicos, financeiros e outros.\\nOs programas Prolog são conjuntos de cláusulas definidas escritas em uma notação um pouco\\ndiferente da lógica de primeira ordem padrão. Prolog utiliza letras maiúsculas para representar\\nvariáveis e letras minúsculas para representar constantes — o oposto da nossa convenção para a\\nlógica. Vírgulas separam elementos de conjunção em uma cláusula, e a cláusula é escrita “ao\\ncontrário” do que estamos acostumados: em vez de \\nA\\n \\n∧\\n \\nB\\n \\n⇒\\n \\nC\\n, na Prolog temos C: - A, B. Aqui\\nestá um exemplo típico:\\nA notação [E|L] indica uma lista cujo primeiro elemento é E e o resto é L. Aqui está um programa\\nProlog para append(X, Y, Z), que tem sucesso se a lista Z é o resultado da concatenação das listas X\\ne Y:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 403}),\n",
       " Document(page_content='Em português, podemos ler essas cláusulas como (1) a concatenação de uma lista vazia com uma\\nlista Y produz a mesma lista Y e (2) [A|Z] é o resultado da concatenação de [A|X] a Y, desde que Z\\nseja o resultado da concatenação de X a Y. Na maioria das linguagens de alto nível podemos\\nescrever uma função recursiva semelhante que descreve como concatenar duas listas. A definição\\nProlog é realmente muito mais poderosa, no entanto, porque descreve uma \\nrelação\\n que se mantém\\nentre os três argumentos, em vez de uma função computada a partir de dois argumentos.\\nPor exemplo, podemos formular a consulta append(X, Y, [1, 2]): quais são as duas listas que\\npodem ser concatenadas para fornecer [1, 2]? Aqui estão as soluções:\\nA execução de programas Prolog é feita por meio do encadeamento para trás em profundidade,\\nonde as cláusulas são experimentadas na ordem em que são escritas na base de conhecimento. Alguns\\naspectos de Prolog ficam fora da inferência lógica-padrão:\\n•  Prolog usa a semântica do banco de dados da \\nSeção 8.2.8\\n, em vez da semântica de primeira\\nordem, e isso é evidente em seu tratamento de igualdade e negação (consulte a \\nSeção 9.4.5\\n).\\n•  Existe um conjunto de funções internas para aritmética. Literais que utilizam esses símbolos de\\nfunções são “provados” pela execução de código, em vez da realização de inferência adicional.\\nPor exemplo, o objetivo “X é 4+3” tem sucesso com X associado a 7. Por outro lado, o objetivo\\n“5 é X+Y” falha porque as funções internas não realizam a resolução de equações arbitrárias.\\n5\\n•  Existem predicados internos que têm efeitos colaterais quando executados. Entre eles\\nencontramos predicados de entrada/saída e os predicados assert/retract para modificação da\\nbase de conhecimento. Tais predicados não têm nenhum equivalente em lógica e podem produzir\\nalguns resultados confusos — por exemplo, se os fatos forem afirmados em uma ramificação da\\nárvore de prova que no final falha.\\n•  A \\nverificação de ocorrência\\n é omitida do algoritmo de unificação de Prolog. Isso significa que\\nalgumas inferências incorretas podem ser efetuadas; elas quase nunca são um problema na\\nprática.\\n•  Prolog usa encadeamento para trás em profundidade sem verificação de recursão infinita. Isso o\\ntorna muito rápido quando dado o conjunto correto de axiomas, mas incompleto quando dado um\\nconjunto errado.\\nO projeto Prolog representa um compromisso entre declaratividade e eficiência de execução —\\npelo menos da maneira como a eficiência era entendida na época em que a linguagem Prolog foi\\nprojetada.\\n9.4.3 Implementação eficiente de programas em lógica', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 404}),\n",
       " Document(page_content='A execução de um programa Prolog pode acontecer de dois modos: interpretado e compilado. Em\\nessência, a interpretação consiste em executar o algoritmo ASK-LPO-ET da \\nFigura 9.6\\n, tendo o\\nprograma como a base de conhecimento. Dizemos “em essência” porque os interpretadores Prolog\\ncontêm uma variedade de melhorias destinadas a maximizar a velocidade. Aqui, vamos considerar\\napenas duas.\\nPrimeiro, nossa implementação teve que gerenciar explicitamente a iteração sobre os resultados\\npossíveis gerados por cada uma das subfunções. Interpretadores Prolog têm uma estrutura de dados\\nglobal, uma pilha de \\npontos de escolha\\n, para acompanhar as possibilidades múltiplas de escolha que\\nconsideramos em OU-LPO-ET. Essa pilha global é mais eficiente e torna a depuração mais fácil\\nporque o depurador pode se mover para cima e para baixo da pilha.\\nEm segundo lugar, nossa implementação simples de ASK-LPO-ET gasta um bom tempo gerando e\\ncompondo substituições. Em vez de construir substituições explicitamente, a Prolog tem variáveis \\nlógicas que lembram sua vinculação atual. Em qualquer instante, toda variável no programa é não\\nvinculada ou está vinculada a algum valor. Juntos, as variáveis e os valores definem implicitamente a\\nsubstituição da ramificação atual da prova. A extensão do caminho só pode adicionar novas\\nvinculações de variáveis porque uma tentativa de adicionar uma vinculação diferente a uma variável\\njá vinculada resulta em uma falha de unificação. Quando um caminho na busca falhar, Prolog\\nretornará a um ponto de escolha anterior e então poderá ter de desvincular algumas variáveis. Isso é\\nfeito mantendo-se o controle de todas as variáveis que foram vinculadas em uma pilha chamada\\ntrilha\\n. À medida que cada nova variável é vinculada por UNIFICAR-VAR, a variável é empilhada\\nna trilha. Quando um objetivo falha e chega a hora de retornar a um ponto de escolha anterior, cada\\numa das variáveis é desvinculada conforme for removida da trilha.\\nAté mesmo os interpretadores Prolog mais eficientes exigem vários milhares de instruções de\\nmáquina por etapa de inferência, devido ao custo do acesso em tabelas de índices, unificação e\\nconstrução da pilha de chamadas recursivas. Na realidade, o interpretador sempre se comporta como\\nse nunca tivesse visto o programa antes; por exemplo, ele tem de \\nencontrar\\n cláusulas que\\ncorrespondam ao objetivo. Por outro lado, um programa Prolog compilado é um procedimento de\\ninferência para um conjunto específico de cláusulas e, assim, ele \\nsabe\\n quais cláusulas correspondem\\nao objetivo. Basicamente, o Prolog gera um provador de teoremas em miniatura para cada predicado\\ndiferente, eliminando grande parte da sobrecarga de interpretação. Também é possível \\ncodificar de\\nmodo aberto\\n a rotina de unificação para cada chamada diferente, evitando desse modo a análise\\nexplícita da estrutura de termos (para ver detalhes da unificação em código aberto, consulte Warren\\net al\\n., 1977).\\nprocedimento\\n APPEND(\\nax\\n, \\ny\\n, \\naz\\n, \\ncontinuação\\n)\\n    \\ntrilha\\n ← APONTADOR-PARA-TRILHA-GLOBAL( )\\n    \\nse\\n \\nax\\n = [ ] e UNIFICAR(\\ny\\n, \\naz\\n) \\nentão\\n CHAMAR(\\ncontinuação\\n)\\n    RESETAR-TRILHA(\\ntrilha\\n)\\n    \\na,\\nx,z\\n ← NOVA-VARIÁVEL( ), NOVA-VARIÁVEL( ), NOVA-VARIÁVEL( )\\n    \\nse\\n UNIFICAR(\\nax\\n, [\\na\\n | \\nx\\n]) e UNIFICAR(\\naz\\n, [\\na\\n | \\nz\\n]) \\nentão\\n APPEND(\\nx\\n, \\ny\\n, \\nz\\n, \\ncontinuação\\n)\\nFigura 9.8\\n Pseudocódigo que representa o resultado da compilação do predicado Append. A função', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 405}),\n",
       " Document(page_content='NOVA-VARIÁVEL devolve uma nova variável, diferente de todas as outras variáveis usadas até o\\nmomento. O procedimento CHAMAR(\\ncontinuação\\n) retoma a execução com a continuação\\nespecificada.\\nOs conjuntos de instruções dos computadores atuais fornecem uma correspondência fraca com a\\nsemântica de Prolog e, assim, a maioria dos compiladores Prolog efetua a compilação em uma\\nlinguagem intermediária, em vez de fazê-lo diretamente em linguagem de máquina. A linguagem\\nintermediária mais popular é a Warren Abstract Machine, ouWAM, que recebeu esse nome em\\nhomenagem a David H. D. Warren, um dos implementadores do primeiro compilador Prolog. A\\nWAM é um conjunto de instruções abstratas adequado para Prolog e que pode ser interpretada ou\\nconvertida em linguagem de máquina. Outros compiladores convertem o Prolog em uma linguagem de\\nalto nível, como Lisp ou C, e depois utilizam o compilador dessa linguagem para efetuar a conversão\\nem linguagem de máquina. Por exemplo, a definição do predicado Append pode ser compilada no\\ncódigo mostrado na \\nFigura 9.8\\n. Há diversos detalhes que vale a pena mencionar:\\n•  Em vez de ser necessário pesquisar a base de conhecimento em busca de cláusulas Append, as\\ncláusulas se tornam um procedimento e as inferências são executadas simplesmente chamando-se\\no procedimento.\\n•  Como descrevemos antes, as vinculações atuais das variáveis são mantidas em uma trilha. A\\nprimeira etapa do procedimento salva o estado atual da trilha, de modo que ele pode ser\\nrestaurado por RESETAR-TRILHA se a primeira cláusula falhar. Isso vai desfazer quaisquer\\nvinculações geradas pela primeira chamada a UNIFICAR.\\n•  A parte mais complicada é o uso de \\ncontinuações\\n para implementar pontos de escolha. Podemos\\npensar em uma continuação como a conjugação de um procedimento e uma lista de argumentos\\nque juntos definem o que deve ser feito em seguida, sempre que o objetivo corrente tem sucesso.\\nSimplesmente não seria suficiente retornar de um procedimento como APPEND quando o\\nobjetivo tivesse sucesso porque poderia ter sucesso de várias maneiras, e cada uma delas teria\\nde ser explorada. O argumento de continuação resolve esse problema porque pode ser chamado\\ntoda vez que o objetivo tem sucesso. No código de APPEND, se o primeiro argumento for vazio\\ne o segundo argumento unifica com o terceiro, o predicado APPEND teve sucesso. Em seguida,\\nchamamos a continuação (com CHAMAR), usando as vinculações apropriadas na trilha, a fim de\\nfazer o que tiver de ser feito em seguida. Por exemplo, se a chamada a APPEND estivesse no\\nnível superior, a continuação imprimiria as vinculações das variáveis.\\nAntes do trabalho de Warren sobre a compilação de inferência em Prolog, a programação em\\nlógica era lenta demais para uso geral. Os compiladores criados por Warren e outros permitiram que\\no código Prolog alcançasse velocidades capazes de competir com os de C em diversos benchmarks-\\npadrão (Van Roy, 1990). É claro que o fato de ser possível escrever um planejador ou analisador de\\nlinguagem natural em algumas dezenas de linhas de Prolog torna essa linguagem de certa forma mais\\ninteressante que C para a prototipação da maioria dos projetos de pesquisa de IA em pequena escala.\\nA paralelização também pode proporcionar uma aceleração significativa. Existem duas fontes\\nprincipais de paralelismo. A primeira, chamada \\nparalelismo-OU\\n, vem da possibilidade de um\\nobjetivo se unificar com muitas cláusulas diferentes na base de conhecimento. Cada uma gera uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 406}),\n",
       " Document(page_content='ramificação independente no espaço de busca que pode levar a uma solução potencial, e todas essas\\nramificações podem ser resolvidas em paralelo. A segunda, chamada \\nparalelismo-E\\n, vem da\\npossibilidade de se resolver em paralelo cada elemento da conjunção no corpo de uma implicação.\\nO paralelismo-E é mais difícil de se conseguir porque as soluções para a conjunção inteira exigem\\nvinculações consistentes para todas as variáveis. Cada ramificação conjuntiva deve se comunicar\\ncom as outras ramificações para assegurar uma solução global.\\n9.4.4 Inferência redundante e laços infinitos\\nAgora vamos examinar o calcanhar de Aquiles de Prolog: a incompatibilidade entre busca em\\nprofundidade e árvores de busca que incluem estados repetidos e caminhos infinitos. Considere o\\nprograma em lógica a seguir que determina se existe um caminho entre dois pontos em um grafo\\norientado:\\nUm grafo simples de três nós, descrito pelos fatos ligação(a, b) e ligação(b, c), é mostrado na\\nFigura 9.9\\n(a). Com esse programa, a consulta caminho(a, c) gera a árvore de prova mostrada na\\nFigura 9.10\\n(a). Por outro lado, se colocarmos as duas cláusulas na ordem\\nFigura 9.9\\n (a) Encontrar um caminho de \\nA\\n até \\nC\\n pode levar o Prolog a um laço infinito. (b) Um grafo\\nem que cada nó está conectado a dois sucessores aleatórios na camada seguinte. Encontrar um\\ncaminho de \\nA\\n1\\n até \\nJ\\n4\\n exige 877 inferências.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 407}),\n",
       " Document(page_content='Figura 9.10\\n (a) Prova de que existe um caminho de \\nA\\n até \\nC\\n. (b) Árvore de prova infinita gerada\\nquando as cláusulas estão na “ordem errada”.\\no Prolog seguirá o caminho infinito mostrado na \\nFigura 9.10\\n(b). Portanto, Prolog é \\nincompleto\\n como\\nprovador de teoremas para cláusulas definidas — até mesmo no caso de programas Datalog, como\\nmostra esse exemplo — porque, para algumas bases de conhecimento, ele não consegue provar\\nsentenças que são consequências lógicas. Note que o encadeamento para a frente não se ressente\\ndesse problema: uma vez que caminho(a, b), caminho(b, c) e caminho(a, c) são deduzidos, o\\nencadeamento para a frente é suspenso.\\nO encadeamento para trás em profundidade também tem problemas com computações redundantes.\\nPor exemplo, para encontrar um caminho de \\nA\\n1\\n até \\nJ\\n4\\n na \\nFigura 9.9\\n(b), o Prolog executa 877\\ninferências, cuja maior parte envolve encontrar todos os caminhos possíveis até os nós a partir dos\\nquais o objetivo é inacessível. Esse problema é semelhante ao problema de estados repetidos\\ndescrito no Capítulo 3. A quantidade total de inferências pode ser exponencial em relação ao número\\nde fatos básicos que são gerados. Se, em vez disso, aplicarmos o encadeamento para a frente, no\\nmáximo \\nn\\n2\\n fatos caminho(X, Y) poderão ser gerados vinculando-se \\nn\\n nós. Para o problema da \\nFigura\\n9.9\\n(b), são necessárias apenas 62 inferências.\\nO encadeamento para a frente em problemas de busca de grafos é um exemplo de \\nprogramação\\ndinâmica\\n, no qual as soluções para subproblemas são construídas de forma incremental a partir das\\nsoluções de subproblemas menores e são guardadas no cache para evitar a repetição da computação.\\nPodemos obter efeito semelhante em um sistema de encadeamento para trás utilizando a\\nmemoização\\n, isto é, o processo de guardar no cache soluções para subobjetivos à medida que eles\\nsão encontrados e depois reutilizar essas soluções quando o subobjetivo voltar a ocorrer, em vez de\\nrepetir a computação anterior. Essa é a abordagem adotada pelos sistemas de \\nprogramação em\\nlógica tabulada\\n, que utilizam mecanismos eficientes de armazenamento e recuperação para executar\\na memoização. A programação em lógica tabulada combina a orientação para objetivos do\\nencadeamento para trás com a eficiência da programação dinâmica do encadeamento para a frente.\\nEla também é completa para bases de conhecimento Datalog, o que significa que o programador', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 408}),\n",
       " Document(page_content='precisa se preocupar menos com os laços infinitos. (Ainda é possível obter um laço infinito com\\npredicados como pai(X, Y), que se referem a um número potencial ilimitado de objetos.)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 409}),\n",
       " Document(page_content='9.4.5 Semântica do banco de dados do Prolog\\nO Prolog usa a semântica de banco de dados, como discutido na \\nSeção 8.2.8\\n. A suposição de\\nnomes únicos diz que cada constante Prolog e cada termo básico referem-se a um objeto distinto, e o\\npressuposto de mundo fechado diz que as únicas sentenças que são verdadeiras são aquelas\\ndecorrentes da base de conhecimento. Não há como afirmar que uma sentença é falsa em Prolog. Isso\\ntorna o Prolog menos expressivo do que a lógica de primeira ordem, mas é parte do que torna o\\nProlog mais eficiente e mais conciso. Considere as afirmações a seguir em Prolog sobre algumas\\nofertas de cursos:\\nSob a suposição de nomes únicos, \\nCS\\n e \\nEE\\n são diferentes (como são 101, 102 e 106), então isso\\nsignifica que há quatro cursos distintos. Sob a hipótese de mundo fechado não existem outros cursos,\\npor isso há exatamente quatro cursos. Mas, se essas afirmações forem em LPO, em vez de em Prolog,\\ntudo o que poderíamos dizer é que há algo entre um e infinitos cursos. Isso porque as afirmações (em\\nLPO) não negam a possibilidade de que outros cursos não mencionados também sejam oferecidos\\nnem dizem que os cursos mencionados são diferentes uns dos outros. Se quiséssemos traduzir a\\nEquação 9.11 em LPO, obteríamos o seguinte:\\nIsso é chamado \\ncompletamento\\n da Equação 9.11. Ela expressa em LPO a ideia de que existem, no\\nmáximo, quatro cursos. Para expressar em LPO a ideia de que existem pelo menos quatro cursos,\\nprecisamos escrever o completamento do predicado de igualdade:\\nO completamento é útil para a compreensão da semântica de banco de dados, mas, para fins\\npráticos, se seu problema puder ser descrito com a semântica de banco de dados, é mais eficiente\\nraciocinar com Prolog ou algum outro sistema de banco de dados semântico, em vez de traduzir em\\nLPO e raciocinar com um provador de teoremas para LPO completa.\\n9.4.6 Programação em lógica de restrições\\nEm nossa discussão sobre o encadeamento para a frente (\\nSeção 9.3\\n), mostramos que os problemas\\nde satisfação de restrições (PSRs) podem ser codificados como cláusulas definidas. A linguagem\\nProlog padrão resolve esses problemas exatamente do mesmo modo que o algoritmo de retrocesso\\ndado na \\nFigura 6.5\\n.\\nTendo em vista que o retrocesso enumera os domínios das variáveis, ele só funciona para PSRs de\\ndomínios finitos\\n. Em termos de Prolog, deve haver um número finito de soluções para qualquer', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 410}),\n",
       " Document(page_content='objetivo com variáveis não vinculadas. (Por exemplo, o objetivo dif(Q, AM), que informa que\\nQueensland e Austrália Meridional devem ter cores diferentes, tem seis soluções se forem permitidas\\ntrês cores.) Os PSRs de domínios infinitos — por exemplo, com variáveis de valores inteiros ou\\nreais — exigem algoritmos bem diferentes, como o de propagação de limites ou o de programação\\nlinear.\\nConsidere o seguinte exemplo. Definimos o triângulo (X, Y, Z) como um predicado que vale se os\\ntrês argumentos forem números que satisfazem a desigualdade triangular:\\nSe formularmos a consulta de Prolog triângulo(3, 4, 5), ela terá sucesso. Por outro lado, se\\nsolicitarmos triângulo(3, 4, Z), nenhuma solução será encontrada porque o subobjetivo Z > 0 não\\npoderá ser tratado por Prolog; não podemos comparar um valor desvinculado com 0.\\nA \\nprogramação em lógica de restrições\\n (PLR) permite que as variáveis sejam \\nrestringidas\\n, em\\nvez de serem \\nlimitadas\\n. Uma solução PLR é o conjunto mais específico de restrições sobre as\\nvariáveis de consulta que podem ser derivadas da base de conhecimento. Por exemplo, a solução\\npara a consulta triângulo(3, 4, Z) é a restrição 7 >= Z >= 1. Os programas em lógica padrão são\\napenas um caso especial de PLR em que as restrições da solução devem ser restrições de igualdade,\\nou seja, vinculações.\\nOs sistemas de PLR incorporam vários algoritmos de resolução de restrições correspondentes às\\nrestrições permitidas na linguagem. Por exemplo, um sistema que permite desigualdades lineares\\nsobre variáveis de valores reais poderia incluir um algoritmo de programação linear para resolver\\nessas restrições. Os sistemas de PLR também adotam uma abordagem muito mais flexível para\\nresolver consultas de programação em lógica padrão. Por exemplo, em vez de retrocesso em\\nprofundidade da esquerda para a direita, eles poderiam utilizar qualquer dos algoritmos mais\\neficientes descritos no Capítulo 6, inclusive a heurística de ordenação de elementos de conjunção, o\\nsalto para trás (\\nbackjumping\\n), a condicionalização de conjuntos de corte, e assim por diante.\\nPortanto, os sistemas de PLR combinam elementos de algoritmos de satisfação de restrições,\\nprogramação em lógica e bancos de dados dedutivos.\\nForam definidos vários sistemas que permitem mais controle ao programador sobre a ordem de\\nbusca de inferência. A linguagem MRS (Genesereth e Smith, 1981; Russell, 1985) permite ao\\nprogramador escrever \\nmetarregras\\n para determinar que elementos da conjunção serão testados\\nprimeiro. O usuário poderia escrever uma regra afirmando que o objetivo com o menor número de\\nvariáveis deve ser testado primeiro ou poderia escrever regras específicas de domínio para\\ndeterminados predicados.\\n9.5 RESOLUÇÃO\\nA última de nossas três famílias de sistemas lógicos se baseia na \\nresolução\\n. Vimos na \\nSeção 7.5\\nque a resolução proposicional utilizando refutação é um procedimento de inferência completo para a\\nlógica proposicional. Nesta seção, veremos como estender a resolução à lógica de primeira ordem.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 411}),\n",
       " Document(page_content='9.5.1 Forma normal conjuntiva para lógica de primeira ordem\\nComo no caso proposicional, a resolução de primeira ordem exige que as sentenças estejam em\\nforma normal conjuntiva\\n (FNC) — ou seja, em uma conjunção de cláusulas, em que cada cláusula é\\numa disjunção de literais.\\n6\\n Os literais podem conter variáveis, que presumimos ser universalmente\\nquantificadas. Por exemplo, a sentença\\ntorna-se, em FNC,\\n \\nToda sentença de lógica de primeira ordem pode ser convertida em uma sentença FNC\\ninferencialmente equivalente\\n. Em particular, a sentença em FNC será não satisfatível exatamente\\nquando a sentença original for não satisfatível; assim, temos uma base para a elaboração de provas\\npor contradição sobre as sentenças em FNC.\\nO procedimento de conversão para FNC é bem parecido com o caso proposicional, que vimos\\nanteriormente. A principal diferença surge a partir da necessidade de eliminar quantificadores\\nexistenciais. Ilustraremos o procedimento convertendo a sentença “Todo mundo que ama todos os\\nanimais é amado por alguém” ou\\nAs etapas são:\\n•  \\nEliminar implicações:\\n•  \\nMover ¬ para dentro:\\n Além das regras habituais para conectivos negados, precisamos de\\nregras para quantificadores negados. Desse modo, temos:\\nNossa sentença passa pelas seguintes transformações:\\nNote que um quantificador universal (\\n∀\\ny\\n) na premissa da implicação se tornou um quantificador\\nexistencial. A sentença agora é: “Existe algum animal que \\nx\\n não ama ou (se não for esse o caso)\\nalguém ama \\nx\\n.” Sem dúvida, o significado da sentença original foi preservado.\\n•  \\nPadronizar variáveis:\\n No caso de sentenças como \\n(\\n∃\\nxP\\n(\\nx\\n)) \\n∨\\n (\\n∃\\nx Q\\n(\\nx\\n)) que utilizam duas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 412}),\n",
       " Document(page_content='vezes o mesmo nome de variável, altere o nome de uma das variáveis. Isso evitará confusão mais\\ntarde, quando descartarmos os quantificadores. Desse modo, temos:\\n•  \\nSkolemizar:\\n A \\nskolemização\\n é o processo de remover quantificadores existenciais por\\neliminação. No caso simples, é semelhante à regra de instanciação do existencial da \\nSeção 9.1\\n:\\nconverter \\n∃\\n \\nx P\\n(\\nx\\n) em \\nP\\n(\\nA\\n), onde \\nA\\n é uma nova constante. No entanto, não podemos aplicar\\ninstanciação existencial para a nossa sentença anterior porque ela não corresponde ao padrão \\n∃\\nv\\n a apenas partes da sentença correspondem ao padrão. Se aplicarmos a regra à cega para as\\nduas partes correspondentes obteremos\\nque tem significado completamente errado: ela afirma que todo mundo deixa de amar um animal\\nA\\n específico ou é amado por alguma entidade específica \\nB\\n. De fato, nossa sentença original\\npermite que cada pessoa deixe de amar um animal diferente ou seja amada por uma pessoa\\ndiferente. Desse modo, queremos que as entidades de Skolem dependam de \\nx\\n e de \\nz\\n:\\n  Aqui \\nF\\n e \\nG\\n são \\nfunções de Skolem\\n. A regra geral diz que os argumentos da função de Skolem\\nsão todas as variáveis universalmente quantificadas, em cujo escopo aparece o quantificador\\nexistencial. Como ocorre com a instanciação do existencial, a sentença de Skolem é satisfatível\\nexatamente quando a sentença original é satisfatível.\\n•  \\nDescartar quantificadores universais:\\n Nesse momento, todas as variáveis restantes devem ser\\nuniversalmente quantificadas. Além disso, a sentença é equivalente a outra sentença na qual\\ntodos os quantificadores universais são deslocados para a esquerda. Portanto, podemos\\ndescartar os quantificadores universais:\\n•  \\nDistribuir\\n \\n∨\\n \\nsobre\\n \\n∧\\n:\\nEssa etapa também pode exigir o nivelamento de conjunções e disjunções aninhadas. Agora, a\\nsentença está em FNC e consiste em duas cláusulas. Ela é quase ilegível. (Talvez ajude explicar\\nque a função de Skolem \\nF\\n(\\nx\\n) se refere ao animal potencialmente não amado por \\nx\\n, enquanto \\nG\\n(\\nz\\n)\\nse refere a alguém que poderia amar \\nx\\n.) Felizmente, os seres humanos poucas vezes precisam\\nexaminar sentenças FNC — o processo de conversão é automatizado com facilidade.\\n9.5.2 A regra de inferência de resolução\\nA regra de resolução para as cláusulas de primeira ordem é simplesmente uma versão elevada da', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 413}),\n",
       " Document(page_content='regra de resolução proposicional dada. Duas cláusulas, que consideramos padronizadas de forma a\\nnão compartilharem quaisquer variáveis, podem ser resolvidas se contêm literais complementares.\\nOs literais proposicionais são complementares se um deles é a negação do outro; os literais de\\nprimeira ordem são complementares se um deles \\nse unifica com\\n a negação do outro. Desse modo,\\ntemos:\\nonde UNIFICAR(\\nl\\n1\\n, ¬\\nm\\nj\\n) = \\nθ\\n. Por exemplo, podemos resolver as duas cláusulas\\n[\\nAnimal\\n(\\nF\\n(\\nx\\n)) \\n∨\\n \\nAma\\n(\\nG\\n(\\nx\\n), \\nx\\n)] e [¬\\nAma\\n(\\nu\\n, \\nv\\n) \\n∨\\n ¬\\nMata\\n(\\nu\\n, \\nv\\n)]\\neliminando os literais complementares \\nAma\\n(\\nG\\n(\\nx\\n), \\nx\\n) e ¬\\nAma\\n(\\nu\\n, \\nv\\n), com o unificador \\nθ\\n = {\\nu\\n/\\nG\\n(\\nx\\n),\\nv\\n/\\nx\\n}, a fim de produzir a cláusula \\nresolvente\\n[\\nAnimal\\n(\\nF\\n(\\nx\\n)) \\n∨\\n ¬\\nMata\\n(\\nG\\n(\\nx\\n), \\nx\\n)].\\nEssa regra é chamada de \\nresolução binária\\n porque resolve exatamente dois literais. Sozinha, a\\nregra de resolução binária não gera um procedimento de inferência completo. A regra de resolução\\ncompleta resolve subconjuntos de literais de cada cláusula que são unificáveis. Uma abordagem\\nalternativa é estender a \\nfatoração\\n — a remoção de literais redundantes — ao caso de primeira\\nordem. A fatoração proposicional reduz dois literais a um só se eles são \\nidênticos\\n; a fatoração de\\nprimeira ordem reduz dois literais a um só se eles são \\nunificáveis\\n. O unificador deve ser aplicado à\\ncláusula inteira. A combinação de resolução binária e fatoração é completa.\\n9.5.3 Exemplos de provas\\nA resolução prova que \\nBC\\n |= provando que \\nBC\\n \\n∧\\n ¬a é não satisfatível, isto é, derivando a\\ncláusula vazia. A abordagem algorítmica é idêntica ao caso proposicional descrito na \\nFigura 7.12\\n e,\\nportanto, não a repetiremos aqui. Em vez disso, forneceremos duas provas como exemplos. A\\nprimeira é o exemplo de crime da \\nSeção 9.3\\n. As sentenças em FNC são:\\nTambém incluímos o objetivo negado ¬\\nCriminoso\\n(\\nWest\\n). A prova por resolução é mostrada na\\nFigura 9.11\\n. Note a estrutura: a “coluna” única que começa com a cláusula objetivo, utilizando\\ncláusulas da base de conhecimento na resolução até gerar a cláusula vazia. Isso é característico da', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 414}),\n",
       " Document(page_content='resolução sobre bases de conhecimento de cláusulas de Horn. De fato, as cláusulas ao longo da\\ncoluna principal correspondem \\nexatamente\\n aos valores sucessivos da variável \\nobjetivos\\n no\\nalgoritmo de encadeamento para trás da \\nFigura 9.6\\n. Essa é a razão pela qual sempre optamos pela\\nresolução com uma cláusula cujo literal positivo se unificasse com o literal mais à esquerda da\\ncláusula “atual” da coluna; isso é exatamente o que acontece no encadeamento para trás. Desse modo,\\no encadeamento para trás é realmente apenas um caso especial de resolução com uma estratégia de\\ncontrole específica para decidir que resolução executar em seguida.\\nFigura 9.11\\n Uma prova por resolução de que West é um criminoso. Em cada etapa, os literais que\\nunificam estão em negrito.\\nNosso segundo exemplo faz uso da skolemização e envolve cláusulas que não são cláusulas\\ndefinidas. Isso resulta em uma estrutura de prova um pouco mais complexa. O problema é descrito a\\nseguir em linguagem natural:\\nTodo mundo que ama todos os animais é amado por alguém.\\nQualquer um que mata um animal não é amado por ninguém.\\nJoão ama todos os animais.\\nJoão ou a Curiosidade matou o gato, que se chama Atum.\\nA Curiosidade matou o gato?\\nPrimeiro, expressamos as sentenças originais, algum conhecimento prático e o objetivo negado G\\nem lógica de primeira ordem:\\nA. \\n∀\\nx\\n [\\n∀\\ny Animal\\n(\\ny\\n) \\n⇒\\n \\nAma\\n(\\nx\\n, \\ny\\n)] \\n⇒\\n [\\n∃\\ny Ama\\n(\\ny\\n, \\nx\\n)]\\nB. \\n∀\\nx\\n [\\n∃\\nz Animal\\n(\\nz\\n) \\n∧\\n \\nMata\\n(\\nx\\n, \\nz\\n)] \\n⇒\\n [\\n∀\\ny\\n ¬\\nAma\\n(\\ny\\n, \\nx\\n)]\\nC. \\n∀\\nx Animal\\n(\\nx\\n) \\n⇒\\n \\nAma\\n(\\nJoão\\n, \\nx\\n)\\nD. \\nMata\\n(\\nJoão\\n, \\nAtum\\n) \\n∨\\n \\nMata\\n(\\nCuriosidade\\n, \\nAtum\\n)\\nE. \\nGato\\n(\\nAtum\\n)\\nF. \\n∀\\nx Gato\\n(\\nx\\n) \\n⇒\\n \\nAnimal\\n(\\nx\\n)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 415}),\n",
       " Document(page_content='¬G. ¬\\nMata\\n(\\nCuriosidade\\n, \\nAtum\\n).\\nAgora, aplicamos o procedimento de conversão com a finalidade de converter cada sentença para\\nFNC:\\nA1. \\nAnimal\\n(\\nF\\n(\\nx\\n)) \\n∨\\n \\nAma\\n(\\nG\\n(\\nx\\n), \\nx\\n)\\nA2. ¬\\nAma\\n(\\nx\\n, \\nF\\n(\\nx\\n)) \\n∨\\n \\nAma\\n(\\nG\\n(\\nx\\n), \\nx\\n)\\nB. ¬\\nAma\\n(\\ny, x\\n) \\n∨\\n ¬\\nAnimal\\n(\\nz\\n) \\n∨\\n ¬\\nAma\\n(\\nx\\n, \\nz\\n)\\nC. ¬\\nAnimal\\n(\\nx\\n) \\n∨\\n \\nAma\\n(\\nJoão\\n, \\nx\\n)\\nD. \\nMata\\n(\\nJoão\\n, \\nAtum\\n) \\n∨\\n \\nMata\\n(\\nCuriosidade\\n, \\nAtum\\n)\\nE. \\nGato\\n(\\nAtum\\n)\\nF. ¬\\nGato\\n(\\nx\\n) \\n∨\\n \\nAnimal\\n(\\nx\\n)\\n¬G. ¬\\nMata\\n(\\nCuriosidade\\n, \\nAtum\\n).\\nA prova por resolução de que a Curiosidade matou o gato é dada na \\nFigura 9.12\\n. Em linguagem\\nnatural, a prova poderia ser parafraseada como:\\nSuponha que a Curiosidade não houvesse matado Atum. Sabemos que João ou a Curiosidade o\\nmatou; desse modo, João deve ter matado Atum. Agora, Atum é um gato, e gatos são animais, então\\nAtum é um animal. Tendo em vista que qualquer um que mata um animal não é amado por ninguém,\\nsabemos que ninguém ama João. Por outro lado, João ama todos os animais, então alguém o ama;\\nassim, temos uma contradição. Portanto, a Curiosidade matou o gato.\\nFigura 9.12\\n Prova por resolução de que a Curiosidade matou o gato. Note o uso da fatoração na\\nderivação da cláusula \\nAma\\n(\\nG\\n(\\nJoão\\n),\\nJoão\\n). Observe também, no lado superior direito, que a\\nunificação de \\nAma\\n(\\nx\\n, \\nF\\n(\\nx\\n)) e \\nAma\\n(\\nJoão\\n, \\nx\\n) pode apenas ter sucesso depois que as variáveis tiverem\\nsido padronizadas em separado.\\nA prova responde à pergunta: “A Curiosidade matou o gato?” Porém, frequentemente queremos\\nformular perguntas mais gerais, como: “Quem matou o gato?” A resolução pode fazer isso, mas obter\\na resposta exige um pouco mais de trabalho. O objetivo é \\n∃\\nw Mata\\n(\\nw\\n, \\nAtum\\n) que, quando negada,\\nse torna ¬\\nMata\\n(\\nw\\n, \\nAtum\\n) em FNC. Repetindo a prova da \\nFigura 9.12\\n com o novo objetivo negado,\\nobtemos uma árvore de prova semelhante, mas com a substituição {\\nw\\n/\\nCuriosidade\\n} em uma das\\netapas. Então, nesse caso, descobrir quem matou o gato é só uma questão de manter o controle das\\nvinculações para as variáveis de consulta da prova.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 416}),\n",
       " Document(page_content='Infelizmente, a resolução pode produzir \\nprovas não construtivas\\n para objetivos existenciais. Por\\nexemplo, ¬\\nMata\\n(\\nw\\n, \\nAtum\\n) se resolve com \\nMata\\n(\\nJoão\\n, \\nAtum\\n) \\n∨\\n \\nMata\\n(\\nCuriosidade\\n, \\nAtum\\n) para dar\\nMata\\n(\\nJoão\\n, \\nAtum\\n), que se resolve novamente com ¬\\nMata\\n(\\nw\\n, \\nAtum\\n) para produzir a cláusula vazia.\\nNote que \\nw\\n tem duas vinculações diferentes nessa prova; a resolução está nos informando que de fato\\nalguém matou Atum — ou João ou a Curiosidade. Essa não é nenhuma grande surpresa! Uma solução\\né restringir as etapas de resolução permitidas, de forma que as variáveis da consulta possam ser\\nvinculadas apenas uma vez em determinada prova; então, precisamos ter a possibilidade de efetuar o\\nretrocesso sobre as vinculações possíveis. Outra solução é adicionar um \\nliteral resposta\\n especial ao\\nobjetivo negado, que se torna ¬\\nMata\\n(\\nw\\n, \\nAtum\\n) \\n∨\\n \\nResposta\\n(\\nw\\n). Agora, o processo de resolução gera\\numa resposta sempre que é gerada uma cláusula contendo apenas um \\núnico\\n literal resposta. Para a\\nprova da \\nFigura 9.12\\n, esse literal resposta é \\nResposta\\n(\\nCuriosidade\\n). A prova não construtiva geraria\\na cláusula \\nResposta\\n(\\nCuriosidade\\n) \\n∨\\n \\nResposta\\n(\\nJoão\\n), que não constitui de fato uma resposta.\\n9.5.4 Completude da resolução\\nEsta seção fornece uma prova de completude da resolução e pode ser seguramente ignorada pelos\\nleitores que estiverem dispostos a aceitá-la com base na fé.\\nMostraremos que a resolução é \\ncompleta para refutação\\n, o que significa que, \\nse\\n um conjunto de\\nsentenças é não satisfatível, então a resolução sempre será capaz de derivar uma contradição. A\\nresolução não pode ser usada para gerar todas as consequências lógicas de um conjunto de sentenças,\\nmas pode ser usada para estabelecer que dada sentença é consequência lógica do conjunto de\\nsentenças. Consequentemente, ela pode ser utilizada para encontrar todas as respostas para\\ndeterminada pergunta, \\nQ\\n(\\nx\\n), provando que \\nBC\\n \\n∧\\n ¬\\nQ\\n(\\nx\\n) é insatisfatível.\\n Consideraremos dado que qualquer sentença em lógica de primeira ordem (sem igualdade) pode\\nser reescrita como um conjunto de cláusulas em FNC. Isso pode ser provado por indução na forma da\\nsentença, utilizando sentenças atômicas como o caso básico (Davis e Putnam, 1960). Nosso objetivo\\nentão é provar o seguinte: \\nse S é um conjunto de cláusulas não satisfatível\\n, \\nentão a aplicação de\\num número finito de passos de resolução a S produzirá uma contradição\\n.\\nNosso esboço de prova segue a prova original apresentada por Robinson, com algumas\\nsimplificações feitas por Genesereth e Nilsson (1987). A estrutura básica da prova (\\nFigura 9.13\\n) é a\\nseguinte:\\n1. Primeiro observamos que, se \\nS\\n é não satisfatível, então existe determinado conjunto de\\ninstâncias sem variá\\u200bveis\\n das cláusulas de \\nS\\n tais que esse conjunto também é não satisfatível\\n(teorema de Herbrand).\\n2. Em seguida, apelamos para o \\nteorema básico de resolução\\n apresentado no Capítulo 7, que\\ndeclara que a resolução proposicional é completa para sentenças básicas (sem variáveis).\\n3. Depois, usamos um \\nlema de elevação\\n para mostrar que, para qualquer prova por resolução\\nproposicional que utilize o conjunto de sentenças básicas, existe uma prova por resolução de\\nprimeira ordem correspondente que utiliza as sentenças de primeira ordem a partir das quais\\nforam obtidas as sentenças básicas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 417}),\n",
       " Document(page_content='Figura 9.13\\n Estrutura de uma prova de completude para resolução.\\nPara executar a primeira etapa, precisaremos de três novos conceitos:\\n•  \\nUniverso de Herbrand:\\n Se \\nS\\n é um conjunto de cláusulas, então \\nH\\nS\\n, o universo de Herbrand de\\nS\\n, é o conjunto de todos os termos básicos (sem variáveis) que podem ser construídos a partir\\ndos seguintes itens:\\na. Os símbolos de funções em \\nS\\n, se houver.\\nb. Os símbolos de constantes em \\nS\\n, se houver; se não houver nenhum, então o símbolo de\\nconstante \\nA\\n.\\nPor exemplo, se \\nS\\n contém apenas a cláusula ¬\\nP\\n(\\nx\\n, \\nF\\n(\\nx\\n, \\nA\\n)) \\n∨\\n ¬\\nQ\\n(\\nx\\n, \\nA\\n) \\n∨\\n \\nR\\n(\\nx\\n, \\nB\\n), então \\nH\\nS\\n é o\\nconjunto infinito de termos básicos a seguir:\\n{\\nA\\n, \\nB\\n, \\nF\\n(\\nA\\n, \\nA\\n), \\nF\\n(\\nA\\n, \\nB\\n), \\nF\\n(\\nB\\n, \\nA\\n), \\nF\\n(\\nB\\n, \\nB\\n), \\nF\\n(\\nA\\n, F(\\nA, A\\n)),…}.\\n•  \\nSaturação:\\n Se \\nS\\n é um conjunto de cláusulas e \\nP\\n é um conjunto de termos básicos, então \\nP\\n(\\nS\\n), a\\nsaturação de \\nS\\n em relação a \\nP\\n, é o conjunto de todas as cláusulas básicas obtidas pela aplicação\\nde todas as substituições consistente\\ns\\n de termos básicos em \\nP\\n com variáveis em \\nS\\n.\\n•  \\nBase de Herbrand:\\n A saturação de um conjunto \\nS\\n de cláusulas em relação a seu universo de\\nHerbrand é chamada base de Herbrand de \\nS\\n, representada como \\nH\\nS\\n(\\nS\\n)\\n.\\n Por exemplo, se \\nS\\ncontém somente a cláusula que acabamos de apresentar, então \\nH\\nS\\n(\\nS\\n) é o conjunto infinito de\\ncláusulas\\nEssas definições nos permitem enunciar uma forma do \\nteorema de Herbrand\\n (Herbrand, 1930):\\nSe um conjunto \\nS\\n de cláusulas é não satisfatível, então existe um subconjunto finito de \\nH\\nS\\n(S\\n) que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 418}),\n",
       " Document(page_content='também é não satisfatível.\\nSeja \\nS\\n′ esse subconjunto finito de sentenças básicas. Agora, podemos apelar para o teorema básico\\nde resolução para mostrar que o \\nfecho da resolução\\n \\nFR\\n(\\nS\\n′) contém a cláusula vazia. Isto é, a\\nexecução da resolução proposicional até o completamento sobre \\nS\\n′ derivará uma contradição.\\nAgora que estabelecemos que sempre existe uma prova por resolução envolvendo algum\\nsubconjunto finito da base de Herbrand de \\nS\\n, o próximo passo é mostrar que existe uma prova por\\nresolução que utiliza as cláusulas do próprio \\nS\\n, que não são necessariamente cláusulas básicas.\\nComeçamos considerando uma única aplicação da regra de resolução. Robinson enunciou o seguinte:\\nSejam \\nC\\n1\\n e \\nC\\n2\\n duas cláusulas sem variáveis compartilhadas, e sejam \\nC\\n′\\n1\\n e \\nC\\n′\\n2\\n instâncias básicas\\nde \\nC\\n1\\n e \\nC\\n2\\n. Se \\nC\\n′ é um resolvente de \\nC\\n′\\n1\\n e \\nC\\n′\\n2\\n, então existe uma cláusula \\nC\\n tal que (1) \\nC\\n é um\\nresolvente de \\nC\\n1\\n e \\nC\\n2\\n, e (2) \\nC\\n′ é uma instância básica de \\nC\\n.\\nTEOREMA DA INCOMPLETUDE DE GÖDEL\\nEstendendo um pouco a linguagem da lógica de primeira ordem para permitir o uso do \\nesquema\\nde indução matemática\\n em aritmética, Gödel conseguiu mostrar, em seu \\nteorema de\\nincompletude,\\n que existem sentenças aritméticas verdadeiras que não podem ser provadas.\\nA prova do teorema da incompletude está um pouco além do escopo deste livro, ocupando,\\ncomo de fato ocupa, pelo menos 30 páginas; porém, podemos apresentar aqui uma ideia da prova.\\nComeçamos com a teoria lógica dos números. Nessa teoria, existe uma única constante, 0, e uma\\núnica função, \\nS\\n (a função sucessora). No modelo pretendido, \\nS\\n(0) denota 1, \\nS\\n(\\nS\\n(0)) denota 2, e\\nassim por diante; portanto, a linguagem tem nomes correspondentes a todos os números naturais. O\\nvocabulário também inclui os símbolos de funções +, × e \\nExp\\n (exponenciação), além do conjunto\\nhabitual de conectivos e quantificadores lógicos. A primeira etapa é notar que o conjunto de\\nsentenças que podemos escrever nessa linguagem pode ser enumerado. (Imagine definir uma\\nordem alfabética sobre os símbolos e depois organizar em ordem alfabética cada um dos\\nconjuntos de sentenças de comprimento 1, 2, e assim por diante.) Podemos então numerar cada\\nsentença \\nα\\n com um número natural único #\\nα\\n (o \\nnúmero de Gödel\\n). Isso é crucial: a teoria dos\\nnúmeros contém um nome para cada uma de suas sentenças. De modo semelhante, podemos\\nnumerar cada prova possível \\nP\\n com um número de Gödel \\nG\\n(\\nP\\n) porque uma prova é simplesmente\\numa sequência finita de sentenças.\\nAgora, vamos supor que tenhamos um conjunto recursivamente enumerável \\nA\\n de sentenças que\\nsão declarações verdadeiras sobre os números naturais. Lembrando que \\nA\\n pode ser identificado\\npor um dado conjunto de inteiros, podemos imaginar a escrita em nosssa linguagem de uma\\nsentença α(\\nj\\n, \\nA\\n) do seguinte tipo:\\n∀\\ni i\\n não é o número de Gödel de uma prova da sentença cujo número de Gödel é \\nj\\n, onde a\\nprova utiliza apenas premissas existentes em \\nA\\n.\\nEntão, seja \\nσ\\n a sentença \\nα\\n(#\\nσ\\n, \\nA\\n), ou seja, uma sentença que enuncia sua própria não\\ndemonstrabilidade a partir de \\nA\\n (o fato de que essa sentença sempre existe é verdade, mas não', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 419}),\n",
       " Document(page_content='completamente óbvio).\\nAgora, criamos o seguinte argumento engenhoso: suponha que \\nσ\\n possa ser provada a partir de \\nA\\n;\\nentão, \\nσ\\n é falsa (porque \\nσ\\n afirma que ela própria não pode ser provada). Mas então temos uma\\nsentença falsa que é demonstrável a partir de \\nA\\n e, assim, \\nA\\n não pode consistir apenas em sentença\\nverdadeiras — uma violação de nossa premissa. Por conseguinte, \\nσ\\n \\nnão\\n é demonstrável a partir\\nde \\nA\\n. No entanto, isso é exatamente o que a própria \\nσ\\n afirma; consequentemente, \\nσ\\n é uma sentença\\nverdadeira.\\nDesse modo, mostramos (economizando 29 páginas e meia) que, para qualquer conjunto de\\nsentenças verdadeiras da teoria dos números e, em particular, para qualquer conjunto de axiomas\\nbásicos, existem outras sentenças verdadeiras que \\nnão\\n podem ser provadas a partir desses\\naxiomas. Isso estabelece, entre outras coisas, que nunca podemos provar todos os teoremas de\\nmatemática \\ndentro de qualquer sistema de axiomas dado.\\n Sem dúvida, essa foi uma descoberta\\nimportante para a matemática. Seu significado para a IA foi amplamente debatido, a partir de\\nespeculações feitas pelo próprio Gödel. Estudaremos o debate no Capítulo 26.\\nEsse lema é chamado \\nlema de elevação\\n porque eleva uma etapa de prova de cláusulas básicas até\\ncláusulas gerais de primeira ordem. Para provar esse lema básico de elevação, Robinson teve de\\ncriar a unificação e derivar todas as propriedades de unificadores mais gerais. Em vez de repetir a\\nprova aqui, vamos simplesmente ilustrar o lema:\\nVemos que de fato \\nC\\n′ é uma instância básica de \\nC\\n. Em geral, para \\n e \\n terem quaisquer\\nresolventes, elas devem ser construídas pela aplicação inicial a \\nC\\n1\\n e \\nC\\n2\\n do unificador mais geral de\\num par de literais complementares em \\nC\\n1\\n e \\nC\\n2\\n. Do teorema de elevação, é fácil derivar um enunciado\\nsemelhante sobre qualquer sequência de aplicações da regra de resolução:\\nPara qualquer cláusula \\nC\\n′ no fecho da resolução de \\nS\\n′ existe uma cláusula \\nC\\n no fecho da resolução\\nde \\nS\\n, tal que \\nC\\n′ é uma instância básica de \\nC\\n e a derivação de \\nC\\n tem o mesmo comprimento que a\\nderivação de \\nC\\n′.\\nA partir desse fato, segue-se que, se a cláusula vazia aparecer no fecho da resolução de \\nS\\n′, ela\\ntambém deverá aparecer no fecho da resolução de \\nS\\n. Isso ocorre porque a cláusula vazia não pode\\nser uma instância básica de qualquer outra cláusula. Para recapitular: mostramos que, se \\nS\\n é não\\nsatisfatível, então existe uma derivação finita da cláusula vazia que utiliza a regra de resolução.\\nA elevação da demonstração de teoremas das cláusulas básicas para as cláusulas de primeira\\nordem proporciona grande aumento de potencial. Esse aumento provém do fato de que a prova de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 420}),\n",
       " Document(page_content='primeira ordem só precisa instanciar variáveis até onde for necessário para a prova, enquanto os\\nmétodos de cláusulas básicas eram obrigados a examinar enorme número de instanciações\\narbitrárias.\\n9.5.5 Igualdade\\nNenhum dos métodos de inferência descritos até agora neste capítulo trata uma asserção da forma\\nx\\n = \\ny\\n. Existem três abordagens distintas que podem ser adotadas. A primeira abordagem é\\naxiomatizar a igualdade — escrever sentenças sobre a relação de igualdade na base de\\nconhecimento. Precisamos afirmar que a igualdade é reflexiva, simétrica e transitiva, e também temos\\nde afirmar que podemos substituir itens iguais por itens iguais em qualquer predicado ou função.\\nAssim, precisamos de três axiomas básicos e depois de um axioma para cada predicado e função:\\nDadas essas sentenças, um procedimento de inferência padrão como a resolução pode executar\\ntarefas que exigem raciocínio sobre a igualdade, como a resolução de equações matemáticas. No\\nentanto, esses axiomas irão gerar uma porção de conclusões, e a maioria delas não é útil para uma\\nprova. Então, houve uma busca de formas mais eficientes de lidar com a igualdade. Uma alternativa\\nfoi adicionar regras de inferência em vez de axiomas. A regra mais simples, a \\ndemodulação\\n, toma\\numa cláusula unitária \\nx\\n = \\ny\\n e alguma cláusula a que contém o termo \\nx\\n e produz uma nova cláusula\\nformada pela substituição de \\ny\\n por \\nx\\n dentro de a. Funciona se o termo dentro de a unifica com \\nx\\n; não\\nprecisa ser exatamente igual a \\nx\\n.\\nObserve que a demodulação é direcional; dado \\nx\\n = \\ny\\n, o \\nx\\n sempre é substituído por \\ny\\n, nunca o\\ncontrário. Isso significa que a demodulação pode ser usada para simplificar expressões usando\\ndemoduladores, como \\nx\\n + 0 = \\nx\\n ou \\nx\\n1\\n = \\nx\\n. Como outro exemplo, dado\\nPai\\n(\\nPai\\n(\\nx\\n)) \\n= AvoPaterno\\n(\\nx\\n)\\nData de nascimento\\n(\\nPai\\n(\\nPai\\n(\\nBella\\n)), 1926)\\npodemos concluir pela demodulação\\nData de nascimento\\n(\\nAvoPaterno\\n(\\nBella\\n), 1926).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 421}),\n",
       " Document(page_content='Mais formalmente, temos:\\n•  \\nDemodulação:\\n Para quaisquer termos \\nx\\n, \\ny\\n e \\nz\\n, onde \\nz\\n aparece em algum lugar no literal \\nm\\ni\\n e\\nonde UNIFICAR(\\nx\\n, \\nz\\n) = θ,\\nonde SUBST é a substituição usual de uma lista vinculativa e SUB(\\nx\\n, \\ny\\n, \\nm\\n) significa substituir \\nx\\npor \\ny\\n em todos os lugares em que \\nx\\n ocorre dentro de \\nm\\n.\\n  A regra também pode ser estendida para tratar cláusulas não unitárias nas quais aparece um\\nliteral de igualdade:\\n•  \\nParamodulação:\\n Para quaisquer termos \\nx\\n, \\ny\\n e \\nz\\n, onde \\nz\\n aparece em algum lugar no literal \\nm\\ni\\n e\\nonde UNIFICAR(\\nx\\n, \\nz\\n) = \\nθ\\n,\\nPor exemplo, de\\ntemos \\nθ\\n = UNIFICAR(\\nF\\n(\\nA\\n, \\ny\\n), \\nF\\n(\\nx\\n, \\nB\\n))= {\\nx\\n/\\nA\\n, \\ny\\n/\\nB\\n}, e podemos concluir através de paramodulação a\\nsentença:\\nA paramodulação gera um procedimento de inferência completo para lógica de primeira ordem\\ncom igualdade.\\nUma terceira abordagem trata o raciocínio de igualdade inteiramente em um algoritmo de\\nunificação estendido. Isto é, os termos são unificáveis se são \\ncomprovadamente\\n iguais sob alguma\\nsubstituição, onde a palavra “comprovadamente” permite raciocínio com igualdade. Por exemplo, os\\ntermos 1 + 2 e 2 + 1 normalmente não são unificáveis, mas um algoritmo de unificação que saiba que\\nx\\n + \\ny\\n = \\ny\\n + \\nx\\n poderia unificá-los com a substituição vazia. A \\nunificação equacional\\n desse tipo pode\\nser feita com algoritmos eficientes, criados para os axiomas específicos utilizados (comutatividade,\\nassociatividade, e assim por diante), em vez de utilizar a inferência explícita com esses axiomas. Os\\nprovadores de teoremas que empregam essa técnica estão intimamente relacionados aos sistemas\\nPLR descritos na \\nSeção 9.4\\n.\\n9.5.6 Estratégias de resolução\\nSabemos que aplicações repetidas da regra de inferência de resolução eventualmente encontrarão\\numa prova, se existir alguma. Nesta subseção, examinaremos estratégias que ajudam a encontrar', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 422}),\n",
       " Document(page_content='provas de maneira \\neficiente\\n.\\nPreferência unitária:\\n Essa estratégia tem preferência por resoluções em que uma das sentenças é um\\núnico literal (também conhecida como \\ncláusula unitária\\n). A ideia por trás da estratégia é a de que\\nestamos tentando produzir uma cláusula vazia e, assim, poderia ser boa ideia preferir inferências que\\nproduzissem cláusulas mais curtas. A resolução de uma sentença unitária (como \\nP\\n) com qualquer\\noutra sentença (como ¬\\nP\\n∨\\n¬\\nQ\\n∨\\nR\\n) sempre gera uma cláusula (nesse caso, ¬\\nQ\\n∨\\n \\nR\\n) mais curta que a\\noutra cláusula. Quando foi experimentada pela primeira vez na inferência proposicional em 1964, a\\nestratégia de preferência unitária levou a uma aceleração drástica, tornando possível provar\\nteoremas que não podiam ser manipulados sem a preferência. A \\nresolução unitária\\n é uma forma\\nrestrita de resolução, na qual toda etapa de resolução deve envolver uma cláusula unitária. A\\nresolução unitária é incompleta no caso geral, mas é completa para bases de conhecimento de Horn.\\nAs provas de resolução unitária em bases de conhecimento de Horn se assemelham ao encadeamento\\npara a frente.\\nO provador de teorema OTTER (Organhized Techniques for Theorem-proving and Effective\\nResearch — técnicas organizadas para prova de teorema e busca eficaz, McCune, 1992), utiliza uma\\nforma de busca pela melhor escolha. Sua função heurística mede o “peso” de cada cláusula, onde as\\ncláusulas mais leves são as preferidas. A escolha exata da heurística depende do usuário, mas,\\ngeralmente, o peso de uma cláusula deve estar correlacionado com o seu tamanho ou dificuldade. As\\ncláusulas unitárias são tratadas como leves; a busca pode ser vista então como uma generalização da\\nestratégia de preferência pela unidade.\\nConjunto de apoio:\\n As preferências que experimentam primeiro certas resoluções são úteis mas, em\\ngeral, é mais eficiente tentar eliminar por completo algumas resoluções potenciais. Por exemplo,\\npodemos insistir que cada etapa de resolução envolva pelo menos um elemento de um conjunto\\nespecial de cláusulas — o \\nconjunto\\n \\nde apoio\\n. O resolvente é então adicionado ao conjunto de apoio.\\nSe o conjunto de apoio for pequeno em relação à base de conhecimento inteira, o espaço de busca\\nserá drasticamente reduzido.\\nTemos de ser cuidadosos com essa abordagem porque uma escolha ruim para o conjunto de apoio\\ntornará o algoritmo incompleto. Porém, se escolhermos o conjunto de apoio \\nS\\n de forma que as\\nsentenças restantes sejam satisfatíveis em conjunto, a resolução pelo conjunto de apoio será\\ncompleta. Por exemplo, pode-se usar a consulta negada como conjunto de apoio, no pressuposto de\\nque a base de conhecimento original seja consistente (afinal, se ela não for consistente, o fato de que\\na consulta segue dela será vazio). A estratégia de conjunto de apoio tem a vantagem adicional de\\ngerar árvores de prova orientadas para objetivos que frequentemente são fáceis de ser\\ncompreendidas pelos seres humanos.\\nResolução de entrada:\\n Nessa estratégia, toda resolução combina uma das sentenças de entrada (a\\npartir da BC ou da consulta) com alguma outra sentença. A prova da \\nFigura 9.11\\n emprega apenas\\nresoluções de entrada e tem a forma característica de uma única “espinha dorsal” com sentenças\\nisoladas combinando-se com a espinha. É claro que o espaço de árvores de prova com essa forma é\\nmenor que o espaço de todos os grafos de prova. Em bases de conhecimento de Horn, o \\nModus\\nPonens\\n é uma espécie de estratégia de resolução de entrada porque combina uma implicação da BC', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 423}),\n",
       " Document(page_content='original com algumas outras sentenças. Desse modo, não surpreende que a resolução de entrada seja\\ncompleta para bases de conhecimento que estão em forma de Horn, mas seja incompleta no caso\\ngeral. A estratégia de \\nresolução linear\\n é uma ligeira generalização que permite a resolução conjunta\\nde \\nP\\n e \\nQ\\n se \\nP\\n está na \\nBC\\n original ou se \\nP\\n é um ancestral de \\nQ\\n na árvore de prova. A resolução linear\\né completa.\\nSubordinação:\\n O método de \\nsubordinação\\n elimina todas as sentenças que são subordinadas por uma\\nsentença existente na BC (isto é, são mais específicas que ela). Por exemplo, se \\nP\\n(\\nx\\n) está na BC, não\\nhá sentido em adicionar \\nP\\n(\\nA\\n) e faz até mesmo menos sentido adicionar \\nP\\n(\\nA\\n) \\n∨\\n \\nQ\\n(\\nB\\n). A\\nsubordinação ajuda a manter a BC pequena, e isso ajuda a manter pequeno o espaço de busca.\\nUsos práticos de resolução de provadores de teoremas\\nOs provadores de teoremas podem ser aplicados aos problemas envolvidos na \\nverificação\\n e na\\nsíntese\\n de hardware e software. Desse modo, a pesquisa em provas de teoremas se desenvolveu nos\\ncampos de projeto de hardware, linguagens de programação e engenharia de software — não apenas\\nem IA.\\nNo caso do hardware, os axiomas descrevem as interações entre sinais e elementos de circuitos\\n(veja a \\nSeção 8.4\\n.2 para um exemplo). Raciocinadores lógicos projetados especialmente para\\nverificação foram capazes de verificar CPUs inteiras, incluindo suas propriedades de sincronização\\n(Srivas e Bickford, 1990). O provador de teoremas AURA foi aplicado para projetar circuitos que\\nsão mais compactos do que qualquer projeto anterior (Wojciechowski e Wojcik, 1983).\\nNo caso do software, o raciocínio sobre programas é bastante semelhante ao raciocínio sobre\\nações, como no Capítulo 7: axiomas descrevem as precondições e os efeitos de cada declaração. A\\nsíntese formal de algoritmos foi um dos primeiros usos de provadores de teoremas, como descrito\\npor Cordell Green (1969a), que se baseou nas ideias anteriores de Herbert Simon (1963). A ideia é\\nprovar um teorema construtivamente no sentido de que “existe um programa \\np\\n satisfazendo\\ndeterminada especificação”. Embora a \\nsíntese dedutiva\\n totalmente automatizada, como é chamada,\\nnão tenha ainda se tornado viável para programação de propósito geral, as sínteses dedutivas guiadas\\nà mão têm sido bem-sucedidas na concepção de vários algoritmos novos sofisticados. A síntese de\\nprogramas com propósitos especiais também é uma área prática de pesquisa, como o código de\\ncomputação científica.\\nJá estão sendo aplicadas técnicas similares para verificação de software por sistemas como o\\nverificador de modelos SPIN (Holzmann, 1997). Por exemplo, o programa de controle de naves\\nespaciais Remote Agent foi verificado antes e após o voo (Havelund \\net al\\n., 2000). O algoritmo de\\ncriptografia de chave pública RSA e o algoritmo de correspondência de sequências de Boyer-Moore\\nforam verificados dessa maneira (Boyer e Moore, 1984).\\n9.6 RESUMO\\nApresentamos uma análise da inferência lógica em lógica de primeira ordem e uma série de\\nalgoritmos para realizá-la.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 424}),\n",
       " Document(page_content='•  Uma primeira abordagem utiliza regras de inferência (\\ninstanciação universal\\n e \\ninstanciação\\nexistencial\\n) para \\nproposicionalizar\\n o problema de inferência. Em geral, essa abordagem é muito\\nlenta, a menos que o domínio seja pequeno.\\n•  O uso da \\nunificação para i\\ndentificar substituições apropriadas para variáveis elimina a etapa de\\ninstanciação em provas de primeira ordem, tornando o processo muito mais eficiente em muitos\\ncasos.\\n•  Uma versão elevada de \\nModus Ponens\\n usa a unificação para fornecer uma regra de inferência\\nnatural e poderosa, o \\nModus Ponens\\n \\ngeneralizado\\n. Os algoritmos de \\nencadeamento para a\\nfrente\\n e \\nencadeamento para trás\\n aplicam essa regra a conjuntos de cláusulas definidas.\\n•  O \\nModus Ponens\\n generalizado é completo para cláusulas definidas, embora o problema de\\nconsequência lógi\\nca seja\\n \\nsemidecidível\\n. No ca\\ns\\no de bases de conhecimento \\nDatalog\\n que\\nconsistem em cláusulas definidas livres de funções, a consequência lógica é decidível.\\n•  O encadeamento para a frente é usado em \\nbancos de dados dedutivos\\n, onde pode ser combinado\\na operações de bancos de dados relacionais. Ele também é utilizado em \\nsistemas de produção\\nque executam atualizações eficientes com conjuntos de regras muito grandes. O encadeamento\\npara a frente é completo para programas Datalog e funciona em tempo polinomial.\\n•  O encadeamento para trás é usado em \\nsistemas de programação em lógica\\n que empregam\\ntecnologia sofisticada de compiladores para produzir uma inferência muito rápida. O\\nencadeamento para trás se ressente de inferências redundantes e laços infinitos; esses problemas\\npodem ser atenuados por \\nmemoização\\n.\\n•  O Prolog, ao contrário da lógica de primeira ordem, usa um mundo fechado com a suposição de\\nnomes únicos e negação por falha. Isso faz do Prolog uma linguagem de programação mais\\nprática, mas a leva longe da lógica pura.\\n•  A regra de inferência de \\nresolução\\n generalizada produz um sistema de prova completo para a\\nlógica de primeira ordem, utilizando bases de conhecimento em forma normal conjuntiva.\\n•  Existem várias estratégias para reduzir o espaço de busca de um sistema de resolução sem\\ncomprometer a completude. Uma das questões mais importantes é tratar com a igualdade;\\nmostramos como usar a \\ndemodulação\\n e a \\nparamodulação\\n.\\n•  Foram usados provadores de teoremas eficientes baseados em resolução para provar teoremas\\nmatemáticos interessantes e para verificar e sintetizar software e hardware.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nGottlob Frege, que desenvolveu a lógica de primeira ordem completa em 1879, baseou seu sistema\\nde inferência em uma coleção de esquemas logicamente válidos, somada a uma única regra de\\ninferência, o \\nModus Ponens\\n. Whitehead e Russell (1910) expuseram as chamadas \\nregras de\\npassagem\\n (a expressão real se deve a Herbrand (1930)), que são usadas para mover quantificadores\\npara o início das fórmulas. As constantes de Skolem e as funções de Skolem foram introduzidas, de\\nforma apropriada, por Thoralf Skolem (1920). Curiosamente, foi Skolem quem introduziu o universo\\nHerbrand (Skolem, 1928).\\nO teorema de Herbrand (Herbrand, 1930), desempenhou uma função vital no desenvolvimento de\\nmétodos automatizados de raciocínio. Herbrand também é considerado o inventor da unificação.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 425}),\n",
       " Document(page_content='Gödel (1930) se baseou nas ideias de Skolem e Herbrand para mostrar que a lógica de primeira\\nordem tem um procedimento de prova completo. Alan Turing (1936) e Alonzo Church (1936)\\nmostraram simultaneamente, utilizando provas muito diferentes, que a validade em lógica de primeira\\nordem não era decidível. O excelente texto de Enderton (1972) explica todos esses resultados de\\nmodo rigoroso, porém compreensível.\\nFoi Abraham Robinson quem propôs que um raciocinador automático poderia ser construído\\nusando proposicionalização e o teorema de Herbrand, e foi Paul Gilmore (1960) quem escreveu o\\nprimeiro programa. Davis e Putnam (1960) introduziram o método de proposicionalização da \\nSeção\\n9.1\\n. Prawitz (1960) desenvolveu a ideia-chave de permitir que a busca de inconsistência\\nproposicional orientasse o processo de busca e de gerar termos do universo de Herbrand apenas\\nquando fosse necessário estabelecer a inconsistência proposicional. Depois de um desenvolvimento\\nadicional por outros pesquisadores, essa ideia levou J. A. Robinson (sem relação com o outro\\npesquisador) a desenvolver o método de resolução (Robinson, 1965).\\nEm IA, a resolução foi adotada em sistemas de perguntas e respostas por Cordell Green e Bertram\\nRaphael (1968). As primeiras implementações de IA dedicavam um grande esforço a estruturas de\\ndados que permitiriam a recuperação eficiente de fatos; esse trabalho foi abordado em textos de\\nprogramação em IA (Charniak \\net al\\n., 1987; Norvig, 1992; Forbus e de Kleer, 1993). No início da\\ndécada de 1970, o \\nencadeamento para a frente\\n estava bem estabelecido em IA como uma\\nalternativa de fácil compreensão para a resolução. Em geral, as aplicações de IA envolviam grande\\nnúmero de regras; por essa razão, era importante desenvolver uma tecnologia eficiente de\\ncorrespondência de regras, em particular no caso de atualizações incrementais. A tecnologia de\\nsistemas de produção\\n foi desenvolvida para dar suporte a essas aplicações. A linguagem de\\nsistemas de produção OPS-5 (Forgy, 1981; Brownston \\net al\\n., 1985), incorporando o eficiente\\nprocesso de correspondência \\nrete\\n (Forgy, 1982), foi usado para aplicações tal como o sistema\\nespecialista R1 para configuração de minicomputadores (McDermott, 1982).\\nA arquitetura cognitiva do SOAR (Laird \\net al\\n., 1987;. Laird, 2008) foi projetada para lidar com\\nconjuntos de regras muito grandes — até um milhão de regras (Doorenbos, 1994). Exemplos de\\naplicações do SOAR incluem o controle de aviões de combates simulados (Jones \\net al\\n., 1998),\\ngestão do espaço aéreo (Taylor \\net al\\n., 2007), os personagens de IA para jogos de computador\\n(Wintermute \\net al\\n., 2007) e as ferramentas de treinamento para os soldados (Wray e Jones, 2005).\\nO campo de \\nbancos de dados dedutivos\\n começou com um seminário em Toulouse em 1977, que\\nreuniu especialistas em sistemas de inferência lógica e de bancos de dados (Gallaire e Minker,\\n1978).\\nO influente trabalho de Chandra e Harel (1980) e de Ullman (1985) levou à adoção de Datalog\\ncomo linguagem-padrão para bancos de dados dedutivos. O desenvolvimento da técnica de\\nconjuntos mágicos\\n para reescrita de regras por Bancilhon \\net al\\n. (1986) permitiu ao encadeamento\\npara a frente tirar proveito da vantagem da orientação a objetivos do encadeamento para trás. O\\ntrabalho atual inclui a ideia de integração de múltiplos bancos de dados em um espaço de dados\\nconsistente (Halevy, 2007).\\nO \\nencadeamento para trás\\n para inferência lógica surgiu na linguagem PLANNER de Hewitt\\n(1969). Enquanto isso, em 1972, o pesquisador francês Alain Colmerauer havia desenvolvido e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 426}),\n",
       " Document(page_content='implementado o \\nProlog\\n com a finalidade de analisar a linguagem natural — as cláusulas Prolog\\nforam planejadas inicialmente para serem regras de gramática livres de contexto (Roussel, 1975;\\nColmerauer \\net al\\n., 1973).\\nGrande parte da base teórica da programação em lógica foi desenvolvida por Robert Kowalski,\\ntrabalhando em conjunto com Colmerauer; consulte Kowalski (1988) e Colmerauer e Roussel (1993)\\npara uma visão geral histórica. Em geral, compiladores Prolog eficientes se baseiam no modelo de\\ncomputação de máquina abstrata de Warren (WAM — Warren Abstract Machine), desenvolvido por\\nDavid H. D. Warren (1983). Van Roy (1990) mostrou que os programas Prolog podem ser\\ncompetitivos em termos de velocidade com programas C.\\nOs métodos para evitar laços repetitivos desnecessários em programas recursivos de lógica foram\\ndesenvolvidos independentemente por Smith \\net al\\n. (1986) e por Tamaki e Sato (1986). Este último\\nartigo também incluía a memoização para programas em lógica, um método desenvolvido\\nextensivamente como \\nprogramação em lógica tabulada\\n por David S. Warren. Swift e Warren\\n(1994) mostram como estender a WAM para manipular a tabulação, permitindo que programas\\nDatalog funcionem com rapidez uma ordem de magnitude maior que os sistemas de encadeamento\\npara a frente de bancos de dados dedutivos.\\nOs primeiros trabalhos teóricos sobre programação em lógica de restrições foram realizados por\\nJaffar e Lassez (1987). Jaffar \\net al\\n. (1992a) desenvolveram o sistema CLP(R) para tratar restrições\\nde valores reais. Agora existem produtos comerciais para a resolução de problemas de configuração\\ne otimização em larga escala com programação por restrição; um dos mais conhecidos é o ILOG\\n(Juncker, 2003). A programação por conjunto de respostas (Gelson, 2008) estende o Prolog,\\npermitindo disjunção e negação.\\nTextos sobre programação em lógica e Prolog incluem Shoham (1994), Bratko (2001), Clocksin\\n(2003) e Clocksin e Mellish (2003). Antes de 2000, o \\nJournal of Logic Programming\\n foi o\\nperiódico de referência; agora, ele foi substituído por \\nTheory and Practice of Logic Programming\\n.\\nAs conferências sobre programação em lógica incluem a International Conference on Logic\\nProgramming (ICLP) e o International Logic Programming Symposium (ILPS).\\nA pesquisa em \\ndemonstração de teoremas matemáticos\\n se iniciou até mesmo antes do\\ndesenvolvimento dos primeiros sistemas de primeira ordem completos. O Geometry Theorem Prover\\nde Herbert Gelernter (Gelernter, 1959) usava métodos de busca heurística combinados a diagramas\\npara podar falsos subobjetivos e foi capaz de provar alguns resultados bastante complicados de\\ngeometria euclidiana. As regras de demodulação e paramodulação destinadas ao raciocínio com\\nigualdade foram introduzidas por Wos \\net al\\n. (1967) e Wos e Robinson (1968), respectivamente.\\nEssas regras também foram desenvolvidas independentemente no contexto de sistemas de reescrita de\\nexpressões (Knuth e Bendix, 1970). A incorporação do raciocínio com igualdade ao algoritmo de\\nunificação se deve a Gordon Plotkin (1972). Jouannaud e Kirchner (1991) apresentam a unificação\\nequacional de uma perspectiva de reescrita de expressões. Baader e Snyder (2001) apresentaram\\numa visão geral de unificação.\\nForam propostas várias estratégias de controle para resolução, começando com a estratégia de\\npreferência unitária (Wos \\net al\\n., 1964). O conjunto de estratégia de suporte foi proposto por Wos \\net\\nal\\n. (1965), a fim de proporcionar certo grau de orientação a objetivos na resolução. A resolução\\nlinear surgiu primeiro em Loveland (1970). Genesereth e Nilsson (1987, Capítulo 5) oferecem uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 427}),\n",
       " Document(page_content='breve, embora completa, análise de ampla variedade de estratégias de controle.\\nO livro \\nA Computational Logic\\n (Boyer e Moore, 1979) é a referência básica sobre o provador de\\nteoremas de Boyer-Moore. Stickel (1992) focaliza o Prolog Techonogy Theorem Prover (PTTP), que\\ncombina as vantagens da compilação de Prolog com a completude da eliminação de modelos. O\\nSETHEO (Letz \\net al\\n., 1992) é outro provador de teoremas extensamente usado, que se baseia nessa\\nabordagem. O LEANTAP (Beckert e Posegga, 1995) é um provador de teoremas eficiente,\\nimplementado em apenas 25 linhas de Prolog. Weidenbach (2001) descreve o SPASS, um dos\\nprovadores de teoremas mais fortes atualmente. O provador de teorema de maior sucesso nos últimos\\nconcursos anuais foi o VAMPIRE (Riazanov e Voronkov, 2002). O sistema COQ (Bertot \\net al\\n.,\\n2004) e o solucionador equacional E (Schulz, 2004) também se mostraram ferramentas valiosas para\\nprovar correção. Os provadores de teoremas têm sido usados para sintetizar e verificar o software\\nautomaticamente para controle de espaçonaves (Denney \\net al\\n., 2006), incluindo a nova cápsula da\\nNasa, Orion (Lowry, 2008). O projeto do FM9001, microprocessador de 32 bits, foi provado estar\\ncorreto pelo sistema NQTHM (Hunt e Brock, 1992). A Conferência sobre a Dedução Automática\\n(CADE) realiza um concurso anual de provadores de teoremas automatizados. De 2002 a 2008, o\\nsistema mais bem-sucedido foi o VAMPIRE (Riazanov e Voronkov, 2002). Wiedijk (2003) compara\\na força de 15 provadores matemáticos. O TPTP (Milhares de Problemas de Provadores de\\nTeoremas) é uma biblioteca de problemas de provas de teoremas, útil para comparar o desempenho\\ndos sistemas (Sutcliffe e Suttner, 1998; Sutcliffe \\net al\\n., 2006).\\nOs provadores de teoremas aparecem com resultados matemáticos recentes que escaparam da\\natenção de matemáticos humanos por décadas, conforme detalhado no livro \\nAutomated Reasoning\\nand the Discovery of Missing Elegant Proofs\\n (Wos e Pieper, 2003). O programa SAM (matemática\\nsemiautomatizada) foi o primeiro, provando um lema na teoria dos reticulados (Guarda \\net al\\n., 1969).\\nO programa AURA também respondeu questões abertas em diversas áreas da matemática (Wos e\\nWinker, 1983). O provador do teorema de Boyer−Moore (Boyer e Moore, 1979) foi utilizado por\\nNatarajan Shankar para dar a primeira prova formal totalmente rigorosa do Teorema da Incompletude\\nde Gödel (Shankar, 1986). O sistema NUPRL provou o paradoxo de Girard (Howe, 1987) e o Lema\\nde Higman (Murthy e Russell, 1990). Em 1933, Herbert Robbins propôs um conjunto de axiomas\\nsimples — a \\nálgebra de Robbins\\n —, que parecia definir a álgebra booleana, mas nenhuma prova\\npôde ser encontrada (apesar do trabalho sério de Alfred Tarski e outros). Em 10 de outubro de 1996,\\napós oito dias de computação, o EQP (uma versão do OTTER) encontrou uma prova (McCune,\\n1997).\\nMuitos trabalhos em lógica matemática podem ser encontrados em \\nFrom Frege to Gödel: A\\nSource Book in Mathematical Logic\\n (Van Heijenoort, 1967). Os livros didáticos voltados para a\\ndedução automatizada incluem o clássico \\nSymbolic Logic and Mechanical Theorem Proving\\n (Chang\\ne Lee, 1973), bem como trabalhos mais recentes por Duffy (1991), Wos \\net al.\\n (1992), Bibel (1993) e\\nKaufmann \\net al.\\n (2000). A revista principal para prova de teoremas é \\nJournal of Automated\\nReasoning;\\n as conferências principais são as anuais Conference on Automated Reasoning (CADE) e\\nInternational Joint Conference on Automated Reasoning (IJCAR). O \\nHandbook of Automated\\nReasoning\\n (Robinson e Voronkov, 2001) reúne trabalhos na área. \\nMechanizing Proof\\n (2004) de\\nMacKenzie aborda a história e a tecnologia de prova de teoremas para o público leigo.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 428}),\n",
       " Document(page_content='EXERCÍCIOS\\n9.1\\n Prove que a instanciação universal é correta e que a instanciação existencial produz uma base de\\nconhecimento inferencialmente equivalente.\\n9.2\\n A partir de \\nGosta\\n(\\nJerry, Sorvete\\n) parece razoável deduzir \\n∃\\nx Gosta\\n(\\nx\\n, \\nSorvete\\n). Enuncie uma\\nregra de inferência geral, a \\nintrodução do existencial\\n, que sanciona essa inferência. Estabeleça\\ncuidadosamente as condições que devem ser satisfeitas pelas variáveis e os termos envolvidos.\\n9.3\\n Suponha que uma base de conhecimento contenha apenas uma sentença, \\n∃\\nx TãoAltoQuanto\\n(\\nx\\n,\\nEverest\\n). Quais dos resultados a seguir são resultados legítimos da aplicação da instanciação do\\nexistencial?\\na.\\n \\nTãoAltoQuanto\\n(\\nEverest\\n, \\nEverest\\n).\\nb.\\n \\nTãoAltoQuanto\\n(\\nKilimanjaro\\n, \\nEverest\\n).\\nc.\\n \\nTãoAltoQuanto\\n(\\nKilimanjaro\\n, \\nEverest\\n) \\n∧\\n \\nTãoAltoQuanto\\n(\\nBenNevis\\n, \\nEverest\\n) (depois de duas\\naplicações).\\n9.4\\n Para cada par de sentenças atômicas, forneça o unificador mais geral, se existir:\\na.\\n \\nP\\n(\\nA\\n, \\nB\\n, \\nB\\n), \\nP\\n(\\nx\\n, \\ny\\n, \\nz\\n).\\nb.\\n \\nQ\\n(\\ny\\n, \\nG\\n(\\nA\\n, \\nB\\n)), \\nQ\\n(\\nG\\n(\\nx\\n, \\nx\\n), \\ny\\n).\\nc.\\n \\nMaisVelho\\n(\\nPai\\n(\\ny\\n), \\ny\\n), \\nMaisVelho\\n(\\nPai\\n(\\nx\\n), \\nJoão\\n).\\nd.\\n \\nConhece\\n(\\nPai\\n(\\ny\\n), \\ny\\n), \\nConhece\\n(\\nx\\n, \\nx\\n).\\n9.5\\n Considere os reticulados de subordinação mostrados na \\nFigura 9.2\\n. (\\nSeção 9.2.3\\n)\\na.\\n Construa o reticulado correspondente à sentença \\nEmprega\\n(\\nMãe\\n(\\nJoão\\n), \\nPai\\n(\\nRicardo\\n)).\\nb.\\n Construa o reticulado correspondente à sentença \\nEmprega\\n(\\nIBM\\n, \\ny\\n) (“Todo mundo trabalha na\\nIBM”). Lembre-se de incluir toda espécie de consulta que se unifique com a sentença.\\nc.\\n Suponha que ARMAZENAR faça a indexação de cada sentença sob todo nó em seu reticulado\\nde subordinação. Explique como RECUPERAR deve funcionar quando algumas dessas\\nsentenças contiverem variáveis; utilize como exemplos as sentenças de (a) e (b), e a consulta\\nEmprega\\n(\\nx\\n, \\nPai\\n(\\nx\\n)).\\n9.6\\n Anote as representações lógicas para as seguintes sentenças, adequando para uso com \\nModus\\nPonens\\n generalizado:\\n*\\na.\\n Cavalos, vacas e porcos são mamíferos.\\nb.\\n A prole de um cavalo é um cavalo.\\nc.\\n Barba Azul é um cavalo.\\nd.\\n Barba Azul é o pai ou mãe de Charlie.\\ne.\\n Prole e pai ou mãe são relações inversas.\\nf.\\n Todo mamífero tem um pai ou mãe.\\n9.7\\n Estas questões dizem respeito a questões de substituição e skolemização.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 429}),\n",
       " Document(page_content='a\\n. Dada a premissa \\n∀\\nx\\n \\n∃\\ny P\\n (\\nx, y\\n), não é válido concluir que \\n∃\\nqP\\n(\\nθ\\n, \\nθ\\n). Dê um exemplo de\\npredicado \\nP\\n em que o primeiro é verdadeiro, mas o segundo é falso.\\nb\\n. Suponha que um mecanismo de inferência seja escrito incorretamente com a verificação de\\nocorrência omitida, de modo que permite a um literal como \\nP\\n(\\nx\\n, \\nF\\n(\\nx\\n)) ser unificado com \\nP\\n(\\nθ\\n, \\nθ\\n)\\n(como mencionado, a maioria das implementações de Prolog realmente permite isso). Mostre\\nque tal mecanismo de inferência vai permitir a conclusão \\n∃\\ny \\nP\\n(\\nθ\\n, \\nθ\\n) a ser inferida a partir da\\npremissa \\n∀\\nx\\n \\n∃\\ny P\\n (\\nx, y\\n).\\nc.\\n Suponha que um procedimento que converte lógica de primeira ordem para forma clausal\\nincorretamente skolemiza \\n∀\\nx\\n \\n∃\\ny P\\n (\\nx, y\\n) para P(x, Sk0), isto é, substitui \\ny\\n por uma constante\\nSkolem em vez de uma função Skolem de \\nx\\n. Mostre que um mecanismo de inferência que usa tal\\nprocedimento vai permitir igualmente que \\n∃\\nqP\\n(\\nθ\\n, \\nθ\\n) seja inferido da premissa \\n∀\\nx\\n \\n∃\\ny P\\n (\\nx, y\\n).\\nd.\\n Um erro comum entre os estudantes é supor que, na unificação, seja permitido substituir um\\ntermo por uma constante Skolem em vez de uma variável. Por exemplo, eles vão dizer que as\\nfórmulas \\nP\\n(\\nSk\\n1) e \\nP\\n(\\nA\\n) podem ser unificadas sob a substituição {Sk1/A}. Dê um exemplo onde\\nisso leva a uma inferência inválida.\\n9.8\\n Explique como escrever qualquer problema 3-SAT de tamanho arbitrário usando uma única\\ncláusula definida de primeira ordem e não mais de 30 fatos básicos (sem variáveis).\\n9.9\\n Suponha que sejam dados os seguintes axiomas:\\na\\n. Dê uma prova por encadeamento para trás da sentença 7 ≤ 3 + 9. (Certifique-se, é claro, de usar\\napenas os axiomas dados aqui, como se não conhecesse mais nada sobre aritmética.) Mostre\\napenas as etapas que levam ao sucesso, e não as etapas irrelevantes.\\nb.\\n Dê uma prova por encadeamento para frente da sentença 7 ≤ 3 + 9. Mais uma vez, mostre apenas\\nas etapas que levam ao sucesso.\\n9.10\\n Uma charada popular entre as crianças é: “Irmãos e irmãs não tenho nenhum, mas o pai desse\\nhomem é o filho de meu pai.” Utilize as regras do domínio de família (veja a \\nSeção 8.3.2\\n) para\\nmostrar quem é esse homem. Você pode aplicar qualquer dos métodos de inferência descritos neste\\ncapítulo. Por que considera esse enigma difícil?\\n9.11\\n Suponha que inserimos em uma base de conhecimento lógico um segmento de dados do censo\\ndos Estados Unidos listando a idade, a cidade de residência, a data de nascimento e a mãe de toda\\npessoa utilizando os números do seguro social como constantes de identificação para cada uma.\\nDesse modo, a idade de George será dada por \\nIdade\\n(443-65-1282, 56). Quais dos esquemas de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 430}),\n",
       " Document(page_content='indexação S1−S5 seguintes permitirão uma solução eficiente para cada uma das consultas Q1−Q4\\n(supondo-se o encadeamento para trás normal)?\\n•  \\nS1:\\n Um índice para cada átomo em cada posição.\\n•  \\nS2:\\n Um índice para cada primeiro argumento.\\n•  \\nS3:\\n Um índice para cada átomo de predicado.\\n•  \\nS4:\\n Um índice para cada \\ncombinação\\n de predicado e primeiro argumento.\\n•  \\nS5:\\n Um índice para cada \\ncombinação\\n de predicado e segundo argumento, e um índice para\\ncada primeiro argumento.\\n•  \\nQ1:\\n \\nIdade\\n(443-44-4321, \\nx\\n)\\n•  \\nQ2:\\n \\nResideEm\\n(\\nx\\n, \\nHouston\\n)\\n•  \\nQ3:\\n \\nMãe\\n(\\nx\\n, \\ny\\n)\\n•  \\nQ4:\\n \\nIdade\\n(\\nx\\n, 34) \\n∧\\n \\nResideEm\\n(\\nx\\n, \\nPequenaCidadeDosEstadosUnidos\\n)\\n9.12\\n Seria possível supor que podemos evitar o problema de conflito de variáveis na unificação\\ndurante o encadeamento para trás padronizando separadamente todas as sentenças na base de\\nconhecimento de uma vez por todas. Mostre que, para algumas sentenças, essa abordagem não pode\\nfuncionar. (\\nSugestão\\n: Considere uma sentença da qual uma parte se unifica com outra.)\\n9.13\\n Nesta questão, utilizaremos as sentenças que você escreveu no Exercício 9.6 para responder a\\numa pergunta que utiliza um algoritmo de encadeamento para trás.\\na.\\n Desenhe a árvore de prova gerada por um algoritmo de encadeamento para trás exaustivo para a\\nconsulta \\n∃\\nh Cavalo\\n(\\nh\\n), onde as cláusulas são comparadas na ordem dada.\\nb.\\n O que você nota a respeito desse domínio?\\nc.\\n Quantas soluções para \\nh\\n realmente seguem de suas sentenças?\\nd.\\n Você conseguiria imaginar um meio de encontrar todas elas? (\\nSugestão\\n: consulte Smith \\net al\\n.\\n(1986).)\\n9.14\\n Acompanhe a execução do algoritmo de encadeamento para trás da \\nFigura 9.6\\n (\\nSeção 9.4.1\\n),\\nquando ele é aplicado para resolver o problema de crime (\\nSeção 9.3.1\\n). Mostre a sequência de\\nvalores usada pela variável \\nobjetivos\\n e organize esses valores em uma árvore.\\n9.15\\n O código Prolog a seguir define um predicado P (lembre-se de que termos com maiúsculas são\\nvariáveis, não constantes em Prolog).\\nP(X, [X|Y]).\\nP(X, [Y|Z]) :- P(X, Z).\\na.\\n Mostre as árvores de prova e as soluções correspondentes às consultas \\nP(A,[2,1,3])\\n e\\nP(2,[1,A,3])\\n.\\nb.\\n Que operação de lista padrão \\nP\\n representa?\\n9.16\\n Este exercício, refere-se à ordenação em Prolog.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 431}),\n",
       " Document(page_content='a.\\n Escreva cláusulas de Prolog que definam o predicado \\nordenada(L)\\n, verdadeiro se e\\nsomente se a lista \\nL\\n está ordenada em ordem ascendente.\\nb.\\n Escreva uma definição em Prolog para o predicado \\nperm(L,M)\\n, verdadeiro se e somente se \\nL\\né uma permutação de \\nM\\n.\\nc.\\n Defina \\nordenar(L,M)\\n (\\nM\\n é uma versão ordenada de \\nL\\n) utilizando perm e ordenada.\\nd.\\n Execute \\nordenar\\n sobre listas cada vez mais longas até perder a paciência. Qual é a\\ncomplexidade de tempo do seu programa?\\ne.\\n Escreva um algoritmo de ordenação mais rápido, como a ordenação por inserção ou o quicksort\\nem Prolog.\\n9.17\\n Este exercício refere-se à aplicação recursiva de regras de reescrita, utilizando a\\nprogramação em lógica. Uma regra de reescrita (ou \\ndemodulador\\n, na terminologia do OTTER) é uma\\nequação com uma orientação especificada. Por exemplo, a regra de reescrita \\nx\\n + 0, → \\nx\\n sugere a\\nsubstituição de qualquer expressão que corresponda a \\nx\\n + 0 pela expressão \\nx\\n. A aplicação de regras\\nde reescrita é uma parte central dos sistemas equacionais de raciocínio. Usaremos o predicado\\nreescrever(X,Y)\\n para representar regras de reescrita. Por exemplo, a regra de reescrita\\nanterior é representada como \\nreescrever(X+0,X)\\n. Alguns termos são \\nprimitivos\\n e não podem\\nmais ser simplificados; desse modo, escreveremos \\nprimitivo(0)\\n para dizer que 0 é um termo\\nprimitivo.\\na.\\n Escreva uma definição de um predicado \\nsimplificar(X Y)\\n que seja verdadeira quando Y\\nfor uma versão simplificada de X, ou seja, quando não houver regras de reescrita aplicáveis a\\nqualquer subexpressão de Y.\\nb.\\n Escreva uma coleção de regras para a simplificação de expressões que envolvem operadores\\naritméticos e aplique seu algoritmo de simplificação a alguns exemplos de expressões.\\nc.\\n Escreva uma coleção de regras de reescrita para diferenciação simbólica e utilize essas regras\\njuntamente com suas regras de simplificação para diferenciar e simplificar expressões que\\nenvolvam expressões aritméticas, incluindo exponenciação.\\n9.18\\n Este exercício considera a implementação de algoritmos de busca em Prolog. Suponha que\\nsucessor(X, Y)\\nseja verdadeira quando o estado \\nY\\n é um sucessor do estado \\nX\\n e que\\nobjetivo(X)\\n seja verdadeira quando \\nX\\n é um estado objetivo. Escreva uma definição para\\nresolver(X, P)\\n, que significa que \\nP\\n é um caminho (uma lista de estados) que começa com \\nX\\n,\\ntermina em um estado objetivo e consiste em uma sequência de etapas válidas definida por\\nsucessor\\n. Você descobrirá que a busca em profundidade é a maneira mais fácil de realizar essa\\ntarefa. Qual seria o nível de facilidade de se adicionar o controle de busca heurística?\\n9.19\\n Suponha que uma base do conhecimento contenha apenas as seguintes cláusulas Horn de\\nprimeira ordem:\\nAncestral (Mãe (x), x)\\nAncestral (x, y)\\n \\n∧\\n \\nAncestral (y, z)\\n \\n⇒\\n \\nAncestral (x, z)\\nConsidere o algoritmo de encadeamento para frente que na j-ésima iteração, termina quando a BC', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 432}),\n",
       " Document(page_content='contém uma sentença que unifica com a consulta, senão adiciona a BC cada sentença atômica que\\npode ser inferida a partir das sentenças que já estão na BC após a iteração j – 1.\\na.\\n Para cada uma das seguintes consultas, informe se o algoritmo irá (1) dar uma resposta (se sim,\\nescreva essa resposta); ou (2) termina sem nenhuma resposta ou (3) nunca termina.\\n(i) \\nAncestral (Mãe(y), João)\\n(ii) \\nAncestral (Mãe (Mãe(y)), João)\\n(iii) \\nAncestral (Mãe (Mãe (Mãe(y))), Mãe(y))\\n(iv) \\nAncestral (Mãe (João), Mãe (Mãe (João)))\\nb.\\n Um algoritmo de resolução pode provar a sentença ¬\\nAncestral (João, João\\n) a partir da base de\\nconhecimento inicial? Explique como ou por quê não.\\nc.\\n Suponha que adicionemos a asserção que ¬(\\nMãe(x) = x\\n) e aumentemos o algoritmo de resolução\\ncom regras de inferência para igualdade. Qual é a resposta agora para (b)?\\n9.20\\n Seja \\n a linguagem de primeira ordem com um único predicado \\nS\\n(\\np\\n, \\nθ\\n), que significa “\\np\\n barbeia\\nθ\\n”. Assuma um domínio de pessoas.\\na.\\n Considere a sentença: “Existe uma pessoa \\nP\\n que barbeia todos os que não se barbeiam, e\\nsomente as pessoas que não se barbeiam.” Expresse isso em \\n.\\nb.\\n Converta a sentença em (a) para a forma clausal.\\nc.\\n Construa uma prova por resolução para mostrar que as cláusulas em (b) são inerentemente\\ninconsistentes. (Observação: você não precisa de axiomas adicionais.)\\n9.21\\n Como a resolução pode ser usada para mostrar que uma sentença é válida? E não satisfatível?\\n9.22\\n Construa um exemplo com duas cláusulas que possam ser resolvidas de duas maneiras\\ndiferentes dando dois resultados diferentes.\\n9.23\\n A partir de “Cavalos são animais”, segue-se que “A cabeça de um cavalo é a cabeça de um\\nanimal”. Demonstre que essa inferência é válida executando as etapas a seguir:\\na.\\n Converta a premissa e a conclusão na linguagem da lógica de primeira ordem. Utilize três\\npredicados: \\nCabeçaDe\\n(\\nh\\n, \\nx\\n) (significando que “\\nh\\n é a cabeça de \\nx\\n”), \\nCavalo\\n(\\nx\\n) e \\nAnimal\\n(\\nx\\n).\\nb.\\n Negue a conclusão e depois converta a premissa e a conclusão negada para a forma normal\\nconjuntiva.\\nc.\\n Utilize a resolução para mostrar que a conclusão segue da premissa.\\n9.24\\n Aqui estão duas sentenças na linguagem de lógica de primeira ordem:\\n(A)\\n \\n∀\\nx\\n \\n∃\\ny\\n (\\nx\\n ≥ \\ny\\n)\\n(B)\\n \\n∃\\ny\\n \\n∀\\nx\\n (\\nx\\n ≥ \\ny\\n)\\na.\\n Suponha que os valores das variáveis se estendam sobre todo o conjunto dos números naturais\\n0, 1, 2,…, ∞ e que o predicado “≥” signifique “é maior que ou igual a”. Sob essa interpretação,\\nconverta (A) e (B) para linguagem natural.\\nb.\\n (A) é verdadeira sob essa interpretação?\\nc.\\n (B) é verdadeira sob essa interpretação?', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 433}),\n",
       " Document(page_content='d.\\n B é consequência lógica de A?\\ne.\\n A é consequência lógica de B?\\nf.\\n Usando a resolução, tente provar que (A) segue de (B). Faça isso mesmo se achar que A não é\\nconsequência lógica de B; continue até a prova falhar e não ser possível prosseguir (se ela\\nfalhar). Mostre a substituição de unificação para cada etapa de resolução. Se a prova falhar,\\nexplique exatamente onde, como e por que ela falhou.\\ng.\\n Agora tente provar que (B) segue de (A).\\n9.25\\n A resolução pode produzir provas não construtivas para consultas com variáveis e, assim,\\ntivemos de introduzir mecanismos especiais para extrair respostas definidas. Explique por que essa\\nquestão não surge no caso de bases de conhecimento que contêm apenas cláusulas definidas.\\n9.26\\n Dissemos neste capítulo que a resolução não pode ser usada para gerar todas as consequências\\nlógicas de um conjunto de sentenças. Algum algoritmo pode fazer isso?\\n1\\n Não confunda essas substituições com as interpretações estendidas usadas para definir a semântica de quantificadores. A substituição\\ntroca uma variável por um termo (um item de sintaxe) para produzir uma nova sentença, enquanto uma interpretação mapeia uma\\nvariável para um objeto no domínio.\\n2\\n O \\nModus Ponens\\n generalizado é mais geral do que o \\nModus Ponens\\n no sentido de que os fatos conhecidos e a premissa da\\nimplicação precisam corresponder apenas após uma substituição, em vez de exatamente. Por outro lado, o Modus Ponens permite\\nqualquer sentença como premissa, em vez de apenas uma conjunção de sentenças atômicas.\\n3\\n \\nRete\\n é a forma latina de rede.\\n4\\n A palavra \\nprodução\\n em \\nsistemas de produção\\n denota uma regra de condição-ação.\\n5\\n Observe que, se forem fornecidos axiomas de Peano, esses objetivos podem ser resolvidos por inferência dentro de um programa\\nProlog.\\n6\\n Uma cláusula também pode ser representada como uma implicação com uma conjunção de átomos na premissa e uma disjunção de\\nátomos na conclusão (Exercício 7.13). Isso é chamado de \\nforma normal implicativa\\n ou \\nforma de Kowalski\\n [especialmente quando é\\nescrita com um símbolo de implicação da direita para a esquerda (Kowalski, 1979)]e, com frequência, é muito mais fácil de ler.\\n*\\n NR: Novamente optamos por manter o exemplo original do inglês, usando “PaiOuMãe” como tradução de “parent”.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 434}),\n",
       " Document(page_content='D\\nCAPÍTULO\\n \\n10\\nPlanejamento clássico\\nEm que vemos como um agente pode tirar proveito da estrutura de um problema\\npara construir planos de ação complexos.\\nefinimos a IA como o estudo da ação racional, o que significa que o \\nplanejamento\\n — a\\nelaboração de um plano de ação para atingir determinados objetivos — é uma parte crítica da IA.\\nVimos até agora dois exemplos de agentes de planejamento: o agente de resolução de problemas\\nbaseado em busca do Capítulo 3 e o agente lógico híbrido do Capítulo 7. Neste capítulo\\napresentaremos uma representação para problemas de planejamento capaz de descrever problemas\\nque não poderiam ser tratados pelas abordagens anteriores.\\nA \\nSeção 10.1\\n desenvolve uma linguagem expressiva, ainda que cuidadosamente restrita, para\\nrepresentar problemas de planejamento. A \\nSeção 10.2\\n mostra como os algoritmos de busca para a\\nfrente e para trás podem tirar proveito dessa representação, principalmente por meio de heurísticas\\nprecisas que podem ser derivadas automaticamente da estrutura da representação (isso é análogo ao\\nmodo como as heurísticas independentes de domínio foram construídas para problemas de satisfação\\nde restrições no Capítulo 6). A \\nSeção 10.3\\n mostra como uma estrutura de dados chamada de grafo de\\nplanejamento pode fazer a busca mais eficiente por um plano. Em seguida, descrevemos algumas das\\noutras abordagens para planejamento e concluímos comparando as diversas abordagens.\\nEste capítulo aborda ambientes com agentes únicos, totalmente observáveis, determinísticos,\\nestáticos. Os Capítulos 11 e 17 vão abordar ambientes com múltiplos agentes parcialmente\\nobserváveis, estocásticos, dinâmicos.\\n10.1 DEFINIÇÃO DO PLANEJAMENTO CLÁSSICO\\nO agente de resolução de problemas do Capítulo 3 pode encontrar sequências de ações que\\nresultam em um estado objetivo. Mas lida com representações atômicas de estados e, portanto,\\nnecessita de boas heurísticas específicas de domínio para um bom desempenho. O agente lógico\\nproposicional híbrido do Capítulo 7 pode encontrar planos sem heurísticas específicas de domínio\\nporque utiliza heurísticas independentes de domínio baseadas na estrutura lógica do problema. Mas\\nse baseia em inferência proposicional (livre de variável), o que significa que pode ser intratável\\nquando houver muitas ações e estados. Por exemplo, no mundo de wumpus, a simples ação de mover', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 436}),\n",
       " Document(page_content='um passo à frente tem de ser repetida para todas as quatro orientações do agente, por \\nT\\n passos de\\ntempo, e \\nn\\n2\\n localizações atuais.\\nEm resposta a isso, pesquisadores de planejamento determinaram como \\nrepresentação fatorada\\naquela em que o estado do mundo é representado por um conjunto de variáveis. Utilizamos uma\\nlinguagem chamada \\nPDDL\\n, ou seja, \\nPlanning Domain Description Language\\n, que nos permite\\nexpressar todas as ações 4\\nTn\\n2\\n com um esquema de ação. Há várias versões de PDDL; selecionamos\\numa versão simples e alteramos a sua sintaxe para ficar coerente com o resto do livro.\\n1\\n Mostraremos\\nagora como PDDL descreve os quatro itens que precisamos para definir um problema de busca: o\\nestado inicial, as ações que estão disponíveis em um estado, o resultado da aplicação de uma ação e\\no teste de objetivo.\\nCada \\nestado\\n é representado como uma conjunção de fluentes que são instanciados, ou seja, átomos\\nsem função. Por exemplo, \\nPobre\\n \\n∧\\n \\nDesconhecido\\n pode representar o estado de um agente infeliz, e\\num estado em um problema de entrega de pacotes poderia ser \\nEm\\n(\\nCaminhão\\n1\\n, Melbourne\\n) \\n∧\\nEm\\n(\\nCaminhão\\n2\\n, Sydney\\n). A \\nsemântica de banco de dados\\n é utilizada: a suposição de mundo\\nfechado significa que quaisquer fluentes não mencionados são falsos, e a suposição de nomes\\nexclusivos significa que \\nCaminhão\\n1\\n \\ne\\n \\nCaminhão\\n2\\n são distintos. Os fluentes a seguir \\nnão\\n são\\npermitidos em um estado: \\nEm\\n(\\nx, y\\n) (porque não são instanciados), ¬\\nPobre\\n (porque é uma negação) e\\nEm\\n(\\nPai\\n(\\nFred\\n), \\nSydney\\n) (porque utiliza um símbolo de função). A representação dos estados é\\ncuidadosamente projetada de modo que um estado pode ser tratado como uma conjunção de fluentes,\\nque pode ser manipulada por inferência lógica, ou como um \\nconjunto\\n de fluentes, que pode ser\\nmanipulado com operações de conjuntos. Algumas vezes, a \\nsemântica de conjunto\\n é mais fácil de\\ntratar.\\nAs \\nações\\n são descritas por um conjunto de esquemas de ação que implicitamente definem as\\nfunções AÇÕES(\\ns\\n) e RESULTADO(\\ns\\n, \\na\\n) necessárias para fazer uma busca de resolução de\\nproblema. Vimos no Capítulo 7 que qualquer sistema para descrição de ação precisa resolver um\\nproblema de persistência — dizer o que muda e o que permanece o mesmo como resultado da ação.\\nO planejamento clássico se concentra em problemas nos quais a maioria das ações deixa a maioria\\ndas coisas inalteradas. Pense em um mundo que consista em um conjunto de objetos em uma\\nsuperfície plana. A ação de empurrar um objeto faz com que o objeto altere a sua localização por um\\nvetor \\nΔ.\\n Uma descrição concisa da ação deverá mencionar apenas \\nΔ\\n; não deverá mencionar todos os\\nobjetos que permanecem no lugar. PDDL faz isso especificando o resultado de uma ação em termos\\ndo que muda; tudo o que permanece o mesmo não é mencionado.\\nUm conjunto de ações instanciadas (livre de variável) pode ser representado por um \\nesquema de\\nação\\n único. O esquema é uma representação \\nelevada\\n — ele eleva o nível de raciocínio da lógica\\nproposicional a um subconjunto restrito de lógica de primeira ordem. Por exemplo, aqui está um\\nesquema de ação para voar em um avião de um local para outro:\\nO esquema consiste no nome da ação, uma lista de todas as variáveis utilizadas no esquema, uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 437}),\n",
       " Document(page_content='precondição\\n e um \\nefeito\\n. Apesar de não ter dito ainda como o esquema de ação se converte em\\nsentenças lógicas, pense sobre as variáveis como sendo universalmente quantificadas. Somos livres\\npara escolher os valores que quisermos para instanciar as variáveis. Por exemplo, aqui está uma\\nação instanciada que resulta da substituição de valores para todas as variáveis:\\nA precondição e o efeito de uma ação são conjunções de literais (sentenças atômicas positivas ou\\nnegadas). A precondição define os estados em que a ação pode ser executada, e o efeito define o\\nresultado da execução da ação. Uma ação \\na\\n pode ser executada no estado \\ns\\n se a precondição de \\na\\n for\\numa consequência lógica de \\ns\\n. A consequência lógica também pode ser expressa com a semântica de\\nconjunto: \\ns |= q\\n se e somente se cada literal positivo em \\nθ\\n estiver em \\ns\\n e cada literal negado em \\nθ\\nnão estiver. Na notação formal dizemos\\nonde qualquer variável em \\na\\n é universalmente quantificada. Por exemplo,\\nDizemos que a ação \\na\\n é \\naplicável\\n no estado \\ns\\n se as precondições forem satisfeitas por \\ns\\n. Quando\\num esquema de ação \\na\\n contém variáveis, ele pode ter múltiplas instâncias aplicáveis. Por exemplo,\\ncom o estado inicial definido na \\nFigura 10.1\\n, a ação voar pode ser instanciada como \\nVoar\\n(\\nP\\n1\\n, \\nSFO\\n,\\nJFK\\n) ou como \\nVoar\\n(\\nP\\n2\\n, \\nJFK\\n, \\nSFO\\n), ambas aplicáveis no estado inicial. Se uma ação \\na\\n tiver \\nv\\nvariáveis, então, em um domínio com \\nk\\n nomes únicos de objetos, no pior caso levará o tempo \\nO(v\\nk\\n)\\npara encontrar as ações instanciadas aplicáveis.\\n    \\nInício(Em\\n(\\nC\\n1\\n, \\nSFO\\n) \\n∧\\n \\nEm\\n(\\nC\\n2\\n, \\nJFK\\n) \\n∧\\n \\nEm\\n(\\nP\\n1\\n, \\nSFO\\n) \\n∧\\n \\nEm\\n(\\nP\\n2\\n, \\nJFK\\n)\\n            \\n∧\\n \\nCarga\\n(\\nC\\n1\\n) \\n∧\\n \\nCarga\\n(\\nC\\n2\\n) \\n∧\\n \\nAvião\\n(\\nP\\n1\\n) \\n∧\\n \\nAvião\\n(\\nP\\n2\\n)\\n            \\n∧\\n \\nAeroporto\\n(\\nJFK\\n) \\n∧\\n \\nAeroporto\\n(\\nSFO\\n))\\n    \\nObjetivo\\n(\\nEm\\n(\\nC\\n1\\n, \\nJFK\\n) \\n∧\\n \\nEm\\n(\\nC\\n2\\n, \\nSFO\\n))\\n    \\nAção\\n(\\nCarregar\\n(\\nc\\n, \\np\\n, \\na\\n),\\n        PRECOND: \\nEm\\n(\\nc\\n, \\na\\n) \\n∧\\n \\nEm\\n(\\np\\n, \\na\\n) \\n∧\\n \\nCarga\\n(\\nc\\n) \\n∧\\n \\nAvião\\n(\\np\\n) \\n∧\\n \\nAeroporto\\n(\\na\\n)\\n        EFEITO: ¬ \\nEm\\n(\\nc\\n, \\na\\n) \\n∧\\n \\nDentro\\n(\\nc\\n, \\np\\n))\\n    \\nAção\\n(\\nDescarregar\\n(\\nc\\n, \\np\\n, \\na\\n),\\n        PRECOND: \\nDentro\\n(\\nc\\n, \\np\\n) \\n∧\\n \\nEm\\n(\\np\\n, \\na\\n) \\n∧\\n \\nCarga\\n(\\nc\\n) \\n∧\\n \\nAvião\\n(\\np\\n) \\n∧\\n \\nAeroporto\\n(\\na\\n)\\n        EFEITO: \\nEm\\n(\\nc\\n, \\na\\n) \\n∧\\n ¬ \\nDentro\\n(\\nc\\n, \\np\\n))\\n    \\nAção\\n(\\nVoar\\n(\\np\\n, \\nde\\n, \\npara\\n),\\n        PRECOND: \\nEm\\n(\\np\\n, \\nde\\n) \\n∧\\n \\nAvião\\n(\\np\\n) \\n∧\\n \\nAeroporto\\n(\\nde\\n) \\n∧\\n \\nAeroporto\\n(\\npara\\n)\\n        EFEITO: ¬ \\nEm\\n(\\np\\n, \\nde\\n) \\n∧\\n \\nEm\\n(\\np\\n, \\npara\\n))', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 438}),\n",
       " Document(page_content='Figura 10.1\\n Descrição PDDL de um problema de planejamento de transporte de carga.\\nÀs vezes queremos \\nproposicionalizar\\n um problema PDDL — substituir cada esquema de ação por\\num conjunto de ações instanciadas e depois utilizar um solucionador proposicional, como SATPLAN\\npara encontrar uma solução. No entanto, isso é impraticável quando \\nv e k\\n são grandes.\\nO \\nresultado\\n de executar a ação \\na\\n no estado \\ns\\n é definido como um estado \\ns\\n′ que é representado\\npelo conjunto de fluentes formado no início com \\ns\\n, removendo os fluentes que aparecem como\\nliterais negativos nos efeitos da ação (o que chamamos de \\nlista de exclusão\\n ou DEL(\\na\\n)), e\\nadicionando os fluentes que são literais positivos nos efeitos da ação (o que chamamos de \\nlista de\\nadição\\n ou ADD(\\na\\n)):\\nPor exemplo, com a ação \\nVoar\\n(\\nP\\n1\\n, \\nSFO\\n, \\nJFK\\n), removeríamos \\nEm(P\\n1\\n, SFO\\n) e adicionaríamos\\nEm(P\\n1\\n, JFK).\\n É uma exigência dos esquemas de ação que qualquer variável no efeito também deve\\naparecer na precondição. Dessa forma, quando a precondição é comparada com o estado \\ns\\n, todas as\\nvariáveis são unificadas, e o RESULTADO(\\ns\\n, \\na\\n) terá, portanto, apenas átomos instanciados. Em\\noutras palavras, os estados instanciados são fechados sob a operação RESULTADO.\\nObserve também que os fluentes não se referem explicitamente ao tempo, como aconteceu no\\nCapítulo 7. Lá precisávamos de sobrescritos para o tempo e de axiomas de estado sucessor da forma\\nEm PDDL, os tempos e os estados estão implícitos nos esquemas de ação: a precondição sempre\\nse refere ao tempo \\nt\\n e o efeito ao tempo \\nt\\n + 1.\\nUm conjunto de esquemas de ação serve como uma definição de \\ndomínio\\n de planejamento. Um\\nproblema\\n específico dentro do domínio é definido com a adição de um estado inicial e um objetivo.\\nO \\nestado inicial\\n é uma conjunção de átomos instanciados. (Como em todos os estados, utiliza-se a\\nsuposição do mundo fechado, o que significa que quaisquer átomos que não são mencionados são\\nfalsos.) O \\nobjetivo\\n é exatamente como uma precondição: uma conjunção de literais (positivos ou\\nnegativos) que podem conter variáveis, tais como \\nEm\\n(\\np\\n, \\nSFO\\n) \\n∧\\n \\nAvião\\n(\\np\\n). Todas as variáveis são\\ntratadas como existencialmente quantificadas, de modo que esse objetivo é ter qualquer avião em\\nSFO. O problema é resolvido quando podemos encontrar uma sequência de ações que terminam em\\num estado que satisfaz o objetivo. Por exemplo, o estado \\nRico\\n \\n∧\\n \\nFamoso\\n \\n∧\\n \\nMiserável\\n satisfaz o\\nobjetivo \\nRico\\n \\n∧\\n \\nFamoso\\n e o estado \\nAvião\\n(\\nAvião\\n1\\n) \\n∧\\n \\nEm\\n (\\nAvião\\n1\\n, \\nSFO\\n) satisfaz o objetivo \\nEm\\n(\\np\\n,\\nSFO\\n) \\n∧\\n \\nAvião\\n (\\np\\n).\\nDefinimos o planejamento como um problema de busca: temos um estado inicial, uma função\\nAÇÕES, uma função RESULTADO e um teste de objetivo. Veremos alguns exemplos de problemas\\nantes de investigar algoritmos eficientes de busca.\\n10.1.1 Exemplo: transporte de carga aérea', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 439}),\n",
       " Document(page_content='A \\nFigura 10.1\\n mostra um problema de transporte de carga aérea envolvendo carregamento e\\ndescarregamento de carga e o seu transporte aéreo de um local para outro. O problema pode ser\\ndefinido com três ações: \\nCarregar,\\n \\nDescarregar\\n e \\nVoar\\n. As ações afetam dois predicados:\\nDentro\\n(\\nc\\n, \\np\\n) significa que a carga \\nc\\n está dentro do avião \\np\\n, e \\nEm\\n(\\nx\\n, \\na\\n) significa que o objeto \\nx\\n (avião\\nou carga) está no aeroporto \\na\\n. Observe que alguns cuidados devem ser tomados para garantir que os\\npredicados \\nEm\\n são corretamente atualizados. Quando um avião voa de um aeroporto para outro, toda\\na carga no interior do avião vai com ele. Na lógica de primeira ordem seria fácil quantificar sobre\\ntodos os objetos que estão dentro do avião. Mas a PDDL básica não tem um quantificador universal,\\npor isso precisamos de uma solução diferente. A abordagem que utilizamos é dizer que uma unidade\\nde carga deixa de estar \\nEm\\n qualquer lugar quando estiver \\nDendro de\\n um avião; a carga só estará \\nEm\\num novo aeroporto quando for descarregada. Assim, \\nEm\\n significa realmente “disponíveis para uso\\nem um determinado local”. O plano seguinte é uma solução para o problema:\\nFinalmente, há o problema das ações espúrias, como \\nVoar\\n(\\nP\\n1\\n, \\nJFK\\n, \\nJFK\\n), que deveria ser um no-\\nop, mas que tem efeitos contraditórios (de acordo com a definição, o efeito incluiria \\nEm(P\\n1\\n, JFK)\\n∧\\n¬ Em(P\\n1\\n, JFK)).\\n É comum ignorar tais problemas porque eles raramente permitem que planos\\nincorretos sejam produzidos. A abordagem correta é acrescentar precondições de desigualdade\\ndizendo que os aeroportos \\nde\\n e \\npara\\n devem ser diferentes; veja um outro exemplo disso na \\nFigura\\n10.3\\n.\\n10.1.2 Exemplo: o problema do pneu sobressalente\\nConsidere o problema de trocar um pneu furado (\\nFigura 10.2\\n). O objetivo é ter um bom pneu\\nsobressalente adequadamente colocado no eixo do carro, onde no estado inicial havia um pneu\\nfurado no eixo e um bom pneu sobressalente no porta-malas. Para simplificar, a versão do problema\\né abstrata, sem parafusos de roda grudados ou outras complicações. Há apenas quatro ações: retirar\\no pneu sobressalente, retirar o pneu furado do eixo, colocar o pneu sobressalente no eixo e deixar o\\ncarro abandonado durante a noite. Suponhamos que o carro esteja estacionado em um bairro\\nparticularmente ruim, de modo que o resultado de deixá-lo durante a noite é que os pneus vão\\ndesaparecer. Uma solução para o problema é [\\nRemover\\n(\\nFurado, Eixo\\n), \\nRemover\\n(\\nSobressalente,\\nPorta-malas\\n), \\nColocar\\n(\\nSobressalente, Eixo\\n)].\\n    \\nInício\\n(\\nPneu\\n(\\nFurado\\n) \\n∧\\n \\nPneu\\n(\\nSobressalente\\n) \\n∧\\n \\nEm\\n(\\nfurado\\n, \\nEixo\\n) \\n∧\\n \\nEm\\n(\\nsobressalente,\\nPorta-malas\\n))\\n    \\nObjetivo\\n (\\nEm\\n(\\nSobressalente, Eixo\\n))\\n    \\nAção\\n(\\nRemover\\n(\\nobj, loc\\n),\\n        PRECOND: \\nEm\\n(\\nobj, loc\\n)\\n        EFEITO: ¬\\nEm\\n(\\nobj, loc\\n) \\n∧\\n \\nEm\\n(\\nobj, Chão\\n))\\n    \\nAção\\n(\\nColocar\\n(\\nt, Eixo\\n),', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 440}),\n",
       " Document(page_content='PRECOND: \\nPneu\\n(\\nt\\n) \\n∧\\n \\nEm\\n(\\nt, Chão\\n) \\n∧\\n ¬\\nEm\\n(\\nFurado, Eixo\\n)\\n        EFEITO: ¬\\nEm\\n(\\nt, Chão\\n) \\n∧\\n \\nEm\\n(\\nt, Eixo\\n))\\n    \\nAção\\n(\\nDeixarDuranteNoite\\n,\\n        PRECOND:\\n        EFEITO: ¬\\nEm\\n(\\nSobressalente, Chão\\n) \\n∧\\n ¬\\nEm\\n(\\nSobressalente, Eixo\\n) \\n∧\\n ¬\\nEm\\n(\\nSobressalente,\\nPorta-mala\\n)\\n∧\\n ¬\\nEm\\n(\\nFurado, Chão\\n) \\n∧\\n ¬\\nEm\\n(\\nFurado, Eixo\\n) \\n∧\\n ¬\\nEm\\n(\\nFurado, Porta-malas\\n))\\nFigura 10.2\\n O problema simples do pneu sobressalente.\\n10.1.3 Exemplo: o mundo dos blocos\\nUm dos domínios do planejamento mais famoso é conhecido como \\nmundo dos blocos\\n. Esse\\ndomínio consiste em um conjunto de blocos em forma de cubo montados sobre uma mesa.\\n2\\n Os blocos\\npodem ser empilhados, mas apenas um bloco pode estar diretamente sobre o outro. Um braço\\nrobótico pode pegar um bloco e movê-lo para outra posição, na mesa ou em cima de outro bloco. O\\nbraço poderá pegar apenas um bloco de cada vez, por isso não pode pegar um bloco que tenha outro\\nsobre ele. O objetivo será sempre construir uma ou mais pilhas de blocos, especificada em termos de\\nquais blocos estão no topo de quais outros blocos. Por exemplo, um objetivo poderia ser colocar o\\nbloco \\nA\\n sobre o \\nB\\n e o \\nB\\n sobre o \\nC\\n (veja a \\nFigura 10.4\\n).\\n    \\nInício\\n(\\nSobre\\n(\\nA, Mesa\\n) \\n∧\\n \\nSobre\\n(\\nB, Mesa\\n) \\n∧\\n \\nSobre\\n(\\nC,A\\n)\\n        \\n∧\\n \\nBloco\\n(\\nA\\n) \\n∧\\n \\nBloco\\n (\\nB\\n) \\n∧\\n \\nBloco\\n (\\nC\\n) \\n∧\\n \\nLivre\\n(\\nB\\n) \\n∧\\n \\nLivre\\n(\\nC\\n))\\n    \\nObjetivo\\n (\\nSobre\\n(\\nA,B\\n) \\n∧\\n \\nSobre\\n(\\nB,C\\n))\\n    \\nAção\\n(\\nMover\\n(\\nb, x, y\\n),\\n        PRECOND: \\nSobre\\n(\\nb, x\\n) \\n∧\\n \\nLivre\\n(\\nb\\n) \\n∧\\n \\nLivre\\n(\\ny\\n) \\n∧\\n \\nBloco\\n(\\nb\\n) \\n∧\\n \\nBloco\\n (\\ny\\n) \\n∧\\n (\\nb\\n≠\\nx\\n) \\n∧\\n (\\nb\\n≠\\ny\\n)\\n∧\\n (\\nx\\n≠\\ny\\n),\\n        EFEITO: \\nSobre\\n(\\nb, y\\n) \\n∧\\n \\nLivre\\n(\\nx\\n) \\n∧\\n ¬\\nSobre\\n(\\nb, x\\n) \\n∧\\n ¬\\nLivre\\n(\\ny\\n))\\n    \\nAção\\n(\\nMoverParaMesa\\n (\\nb, x\\n),\\n        PRECOND: \\nSobre\\n(\\nb, x\\n) \\n∧\\n \\nLivre\\n(\\nb\\n) \\n∧\\n \\nBloco\\n(\\nb\\n) \\n∧\\n (\\nb\\n≠\\nx\\n),\\n        EFEITO: \\nSobre\\n(\\nb, Mesa\\n) \\n∧\\n \\nLivre\\n(\\nx\\n) \\n∧\\n ¬ \\nSobre\\n(\\nb, x\\n))\\nFigura 10.3\\n Um problema de planejamento no mundo dos blocos: construção de uma torre de três\\nblocos. Uma solução é a sequência [\\nMoverParaMesa\\n(\\nC, A\\n), \\nMover\\n(\\nB, Mesa, C\\n), \\nMover\\n(\\nA, Mesa,\\nB\\n)].', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 441}),\n",
       " Document(page_content='Figura 10.4\\n Diagrama do problema do mundo dos blocos na \\nFigura 10.3\\n.\\nUtilizamos \\nSobre\\n(\\nb, x\\n) para indicar que o bloco \\nb\\n está sobre o bloco \\nx\\n, sendo \\nx\\n o outro bloco ou a\\nmesa. A ação de mover o bloco \\nb\\n do topo de \\nx\\n para o topo de \\ny\\n será \\nMover\\n(\\nb, x, y\\n). Agora, uma das\\nprecondições de mover \\nb\\n é que nenhum outro bloco está sobre ele. Na lógica de primeira ordem\\nseria ¬\\n∃\\nx \\nSobre\\n(\\nx, b\\n) ou, alternativamente, \\n∀\\nx\\n ¬ \\nSobre\\n (\\nx, b\\n). PDDL básico não permite\\nquantificadores, então em vez disso introduzimos um predicado \\nLivre\\n(\\nx\\n) que é verdadeiro quando\\nnão há nada sobre \\nx\\n (a descrição do problema completo está na \\nFigura 10.3\\n).\\nA ação \\nMover\\n move o bloco \\nb\\n de \\nx\\n para \\ny\\n se \\nb\\n e \\ny\\n não tiverem blocos sobre eles. Após a\\nmovimentação, \\nb\\n ainda está livre, mas \\ny\\n não está. A primeira tentativa no esquema \\nMover\\n será\\nInfelizmente, isso não atualiza o fluente \\nLivre\\n adequadamente quando \\nx\\n ou \\ny\\n estiver na mesa.\\nQuando \\nx\\n estiver na \\nMesa\\n, essa ação tem o efeito \\nLivre\\n(\\nMesa\\n), mas a mesa não deve ser removida; e\\nquando \\ny\\n = \\nMesa\\n existe uma precondição \\nLivre\\n(\\nMesa\\n)), mas a mesa não deve estar livre para que\\nmovamos um bloco sobre ela. Para corrigir isso faremos duas coisas. Primeiro, vamos introduzir\\numa outra ação para mover um bloco \\nb\\n de \\nx\\n para a mesa:\\nEm segundo lugar, interpretamos \\nLivre\\n(\\nx\\n) como “há um espaço vago sobre \\nx\\n para sustentar um\\nbloco”. Sob essa interpretação, \\nLivre\\n(\\nMesa\\n) será sempre verdadeiro. O único problema é que nada\\nimpede que o planejador use \\nMover\\n(\\nb, x, Mesa\\n) em vez de \\nMoverParaMesa\\n(\\nb, x\\n). Poderíamos\\nconviver com esse problema — isso conduzirá a um espaço de busca maior do que o necessário, mas\\nnão conduzirá a respostas incorretas — ou poderíamos introduzir o predicado \\nBloco\\n e adicionar\\nBloco\\n (\\nb\\n)\\n∧\\n \\nBloco\\n(\\ny\\n) para a precondição de \\nMover\\n.\\n10.1.4 A complexidade do planejamento clássico', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 442}),\n",
       " Document(page_content='Nesta subseção consideraremos a complexidade teórica do planejamento e a distinção de dois\\nproblemas de decisão. \\nPlanSAT\\n é a questão de saber se há algum plano que resolva um problema de\\nplanejamento. \\nPlanSAT Limitado\\n pergunta se existe uma solução de comprimento \\nk\\n ou menor; isso\\npode ser utilizado para encontrar um plano ótimo.\\nO primeiro resultado é que os dois problemas de decisão são decidíveis para o planejamento\\nclássico. A prova decorre do fato de que o número de estados é finito. Mas, se adicionarmos\\nsímbolos de função na linguagem, o número de estados torna-se infinito, e o PlanSAT torna-se apenas\\nsemidecidível: existe um algoritmo que resultará na resposta correta para qualquer problema\\nsolucionável, mas não poderá terminar em problemas insolúveis. O problema do PlanSAT Limitado\\npermanece decidível mesmo na presença de símbolos de função. Para as provas das afirmações desta\\nseção, consulte Ghallab \\net al\\n. (2004).\\nTanto o PlanSAT como o PlanSAT Limitado estão na classe de complexidade PSPACE, uma\\nclasse que é maior (e, portanto, mais difícil) do que NP e se refere a problemas que podem ser\\nresolvidos por uma máquina de Turing determinística com uma quantidade de espaço polinomial.\\nMesmo se fizermos algumas restrições bastante severas, os problemas permanecem bastante difíceis.\\nPor exemplo, se não permitirmos efeitos negativos, os problemas ainda continuam NP-difíceis. No\\nentanto, se também não permitirmos precondições negativas, o PlanSAT reduz para a classe P.\\nEsses resultados de pior caso podem parecer desanimadores. Podemos nos consolar com o fato de\\nque normalmente não é solicitado que os agentes encontrem planos para quaisquer instâncias de\\nproblemas de pior caso, mas apenas para encontrarem planos em domínios específicos (como\\nproblemas do mundo dos blocos com \\nn\\n blocos), que podem ser muito mais fáceis do que o pior caso\\nteórico. Para muitos domínios (incluindo o mundo dos blocos e o mundo da carga aérea), o PlanSAT\\nLimitado é NP-completo, enquanto o PlanSAT está em P; em outras palavras, o planejamento ótimo é\\ngeralmente difícil, mas o planejamento subótimo algumas vezes é fácil. Para se sair bem em\\nproblemas mais fáceis do que os piores casos, precisaremos de boas heurísticas de busca. Essa é a\\nverdadeira vantagem do formalismo do planejamento clássico: facilita o desenvolvimento de\\nheurísticas independentes de domínio muito precisas, enquanto os sistemas baseados em axiomas de\\nestado sucessor em lógica de primeira ordem têm tido menos êxito na geração de boas heurísticas.\\n10.2 ALGORITMOS DE PLANEJAMENTO COMO BUSCA EM ESPAÇO DE\\nESTADOS\\nAgora voltaremos nossa atenção para os algoritmos de planejamento. Vimos como a descrição de\\num problema de planejamento define um problema de busca: podemos pesquisar a partir do estado\\ninicial através do espaço de estados, à procura de um objetivo. Uma das boas vantagens da\\nrepresentação declarativa dos esquemas de ação é que também podemos retroceder a busca do\\nobjetivo procurando pelo estado inicial. A \\nFigura 10.5\\n compara as buscas para a frente e para trás.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 443}),\n",
       " Document(page_content='Figura 10.5\\n Duas abordagens para a busca de um plano. (a) Busca para a frente no espaço de estados\\n(progressão), começando no estado inicial e utilizando as ações do problema para realizar a busca\\npara a frente de um elemento do conjunto de estados objetivos. (b) Busca para trás (regressão)\\natravés dos conjuntos de estados relevantes, começando pelo conjunto de estados que representa o\\nobjetivo e usando o inverso das ações para procurar para trás pelo estado inicial.\\n10.2.1 Busca em espaço de estados para a frente (progressão)\\nAgora que mostramos como um problema de planejamento mapeia em um problema de busca,\\npodemos resolver problemas de planejamento com qualquer um dos algoritmos de busca heurística\\ndo Capítulo 3 ou um algoritmo de busca local do Capítulo 4 (desde que acompanhemos as ações\\nutilizadas para atingir o objetivo). Desde os primeiros tempos da pesquisa de planejamento (por\\nvolta de 1961) até por volta de 1998, assumiu-se que a busca em espaço de estados para a frente era\\nmuito ineficiente para ser prática. Não é difícil explicar as razões.\\nEm primeiro lugar, a busca para a frente é propensa a explorar ações irrelevantes. Considere a\\ntarefa nobre de comprar uma cópia de \\nAI: A Modern Approach\\n de uma livraria on-line. Suponha que\\nexista um esquema de ação \\nComprar\\n(\\nisbn\\n), com efeito \\nPossui\\n(\\nisbn\\n). Os ISBNs têm 10 dígitos;\\nassim, esse esquema de ação representa 10 bilhões de ações instanciadas. Um algoritmo de busca\\npara a frente desinformado teria que começar a enumerar esses 10 bilhões de ações para encontrar\\numa que leve ao objetivo.\\nSegundo, os problemas de planejamento muitas vezes têm espaço de estados grandes. Considere\\num problema de carga aérea em 10 aeroportos, em que cada aeroporto tenha 5 aviões e 20 peças de\\ncarga. O objetivo é mover toda a carga do aeroporto \\nA\\n para o \\nB\\n. Há uma solução simples para o\\nproblema: carregar as 20 peças de carga em um dos aviões em \\nA\\n, pilotar o avião até \\nB\\n e descarregar\\na carga. A descoberta da solução pode ser difícil porque o fator médio de ramificação é enorme:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 444}),\n",
       " Document(page_content='cada um dos 50 aviões pode voar para nove outros aeroportos, e cada uma das 200 pacotes pode ser\\ndescarregada (se foi carregada) ou carregada em qualquer avião no aeroporto (se foi descarregada).\\nEntão, em qualquer estado existe um mínimo de 450 ações (quando todos os pacotes estão nos\\naeroportos sem aviões) e um máximo de 10.450 (quando todos os pacotes e aviões estão no mesmo\\naeroporto). Digamos, em média, que haja cerca de 2.000 ações possíveis por estado, então o grafo de\\nbusca até a profundidade da solução óbvia tem cerca de 2.000\\n41\\n nós.\\nCertamente, mesmo essa instância de problema relativamente pequena é impossível sem uma\\nheurística precisa. Embora muitas aplicações de planejamento do mundo real tenham contado com\\nheurísticas específicas de domínio, verifica-se (como veremos na \\nSeção 10.2.3\\n) que se pode derivar\\nautomaticamente heurísticas fortes independentes de domínio; isso é o que torna viável a busca para\\na frente.\\n10.2.2 Busca para trás (regressão) de estados relevantes\\nNa busca para trás começamos no objetivo e retrocedemos com as ações até que encontramos uma\\nsequência de passos que alcançam o estado inicial. Chama-se busca de \\nestados relevantes\\n porque\\nconsideramos apenas as ações que são relevantes ao objetivo (ou estado atual). Como na busca de\\nestado de crença (\\nSeção 4.4\\n), existe um \\nconjunto\\n de estados relevantes a considerar em cada passo,\\nnão apenas um único estado.\\nComeçamos com o objetivo, que é uma conjunção de literais formando uma descrição de um\\nconjunto de estados, por exemplo, o objetivo ¬\\nPobre\\n \\n∧\\n \\nFamoso\\n descreve os estados em que \\nPobre\\né falso, \\nFamoso\\n é verdadeiro e qualquer outro fluente pode ter qualquer valor. Se houver \\nn\\n fluentes\\ninstanciados em um domínio, existem 2\\nn\\n estados instanciados (cada fluente pode ser verdadeiro ou\\nfalso), mas 3\\nn\\n descrições de conjuntos de estados objetivos (cada fluente pode ser positivo, negativo\\nou não mencionado).\\nEm geral, a busca para trás só funciona quando sabemos como regredir a partir de uma descrição\\nde estado para a descrição do estado predecessor. Por exemplo, é difícil buscar para trás uma\\nsolução para o problema das \\nn\\n-rainhas porque não há maneira fácil de descrever os estados estão um\\nmovimento distante do objetivo. Felizmente, a representação PDDL foi projetada para facilitar a\\nregressão de ações — se um domínio puder ser expresso em PDDL, podemos fazer uma busca nele\\nem regressão. Dada a descrição de objetivo instanciado \\ng\\n e uma ação instanciada \\na\\n, a regressão a\\npartir de \\ng\\n através de \\na\\n fornece uma descrição do estado \\ng\\n′ definida por\\ng\\n′ = (\\ng\\n − ADD(\\na\\n)) \\n \\nPrecond\\n(\\na\\n).\\nOu seja, os efeitos que foram adicionados pela ação não precisam ter sido verdadeiros\\nanteriormente, e também as precondições devem valer antes ou, então, a ação não poderia ter sido\\nexecutada. Observe que DEL(\\na\\n) não aparece na fórmula porque, enquanto sabemos que os fluentes\\nem DEL(\\na\\n), não são mais verdadeiros após a ação, não sabemos se eram ou não verdadeiros antes,\\nentão não há nada a ser dito sobre eles.\\nPara obter o máximo de proveito da busca para trás, temos que lidar com ações e estados', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 445}),\n",
       " Document(page_content='parcialmente instanciados, não totalmente instanciados. Por exemplo, suponha que o objetivo seja\\nentregar uma peça de carga específica em SFO: \\nEm\\n(\\nC\\n2\\n, SFO\\n). Isso sugere a ação \\nDescarregar\\n(\\nC\\n2\\n,\\np\\n′\\n, SFO\\n):\\n[Observe que \\npadronizamos\\n os nomes das variáveis (mudando \\np\\n para \\np\\n′ nesse caso) para que não\\nhaja confusão entre os nomes de variáveis, se usarmos o mesmo esquema de ação duas vezes em um\\nplano. A mesma abordagem foi usada no Capítulo 9 para inferência lógica de primeira ordem.] Isso\\nrepresenta descarregar o pacote de um avião \\nnão especificado\\n em SFO; pode ser em qualquer avião,\\nnão precisamos dizer agora de qual. Podemos tirar proveito do poder das representações de primeira\\nordem: uma única descrição resume a possibilidade de usar \\nqualquer\\n um dos aviões quantificando\\nimplicitamente sobre \\np\\n′. A descrição do estado de regressão é\\nA última questão é decidir quais ações são candidatas a regredir. Na direção para a frente\\nescolhemos ações que são \\naplicáveis\\n — aquelas ações que poderiam ser o próximo passo no plano.\\nNa busca para trás queremos ações que sejam \\nrelevantes —\\n aquelas ações que poderiam ser o\\núltimo\\n passo em um plano que conduz ao estado objetivo atual.\\nPara uma ação ser relevante para um objetivo, obviamente deve contribuir para o objetivo: pelo\\nmenos um dos efeitos da ação (positivo ou negativo) deve unificar com um elemento do objetivo. O\\nque é menos óbvio é que a ação não deve ter quaisquer efeitos (positivos ou negativos) que negue um\\nelemento do objetivo. Agora, se o objetivo for \\nA\\n \\n∧\\n \\nB\\n \\n∧\\n \\nC\\n e uma ação tiver o efeito \\nA\\n \\n∧\\n \\nB\\n \\n∧\\n ¬\\nC\\n,\\nentão há um sentido coloquial em que essa ação é muito relevante para o objetivo — isso nos leva a\\ndois terços do caminho. Mas ela não é relevante no sentido técnico definido aqui porque essa ação\\nnão poderia ser o \\npasso\\n final de uma solução — precisaríamos sempre de pelo menos mais um passo\\npara alcançar \\nC\\n.\\nDado o objetivo \\nEm\\n(\\nC\\n2\\n, \\nSFO\\n), diversas instanciações de \\nDescarregar\\n são relevantes: poderíamos\\nescolher qualquer avião específico para descarregar ou poderíamos deixar o avião não especificado\\nutilizando a ação \\nDescarregar\\n(\\nC\\n2\\n, p’, SFO\\n). Podemos reduzir o fator de ramificação sem excluir\\nquaisquer soluções, sempre utilizando a ação formada pela substituição do unificador mais geral no\\nesquema de ação (padronizado).\\nComo outro exemplo, considere o objetivo \\nPossui\\n(0136042597), dado um estado inicial com 10\\nbilhões de ISBNs e o esquema de ação único\\nA\\n = \\nAção\\n(\\nComprar\\n(\\ni\\n), PRECOND:\\nISBN\\n(\\ni\\n), EFEITO:\\nPossui\\n(\\ni\\n)).\\nComo mencionamos anteriormente, a busca para a frente sem uma heurística teria de começar\\nenumerando 10 bilhões de ações instanciadas \\nComprar\\n. Mas, com a busca para trás, unificaríamos o\\nobjetivo \\nPossui\\n(0136042597) com o efeito (padronizado) \\nPossui\\n(\\ni’\\n), produzindo a substituição \\nθ\\n =', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 446}),\n",
       " Document(page_content='{\\ni\\n′/0136042597}. Então poderíamos regredir sobre a ação \\nSubst\\n(\\nθ\\n, A’\\n) para produzir a descrição do\\nestado predecessor \\nISBN\\n(0136042597). Isso faz parte do estado inicial e, portanto, é uma\\nconsequência lógica, e assim concluímos a regressão.\\nPodemos tornar isso mais formal. Seja a descrição de um objetivo \\ng\\n que contenha um literal\\nobjetivo \\ng\\ni\\n e um esquema de ação \\nA\\n, padronizado para produzir \\nA’\\n. Se \\nA’\\n tiver um efeito literal \\ne’\\nj\\nonde \\nUnificar\\n(\\ng\\ni\\n, \\ne’\\nj\\n) = \\nθ\\n e onde definimos \\na’\\n = SUBST(\\nθ\\n, A’\\n), e se não houver efeito em \\na’\\n que seja\\na negação de uma literal em \\ng\\n, então \\na’\\n será uma ação relevante em direção a \\ng\\n.\\nA busca para trás mantém o fator de ramificação mais baixo do que a busca para a frente, para a\\nmaioria dos domínios de problemas. No entanto, o fato de que a busca para trás utiliza conjuntos de\\nestado, em vez de estados individuais, torna mais difícil chegar a uma boa heurística. Essa é a\\nprincipal razão pela qual a maioria dos sistemas atuais preferem a busca para a frente.\\n10.2.3 Heurísticas de planejamento\\nNem a busca para a frente ou para trás é eficiente sem uma boa função heurística. Lembre-se do\\nCapítulo 3, em que uma função heurística \\nh\\n(\\ns\\n) estima a distância de um estado \\ns\\n para o objetivo e\\nonde se pode derivar uma heurística \\nadmissível\\n para essa distância — uma que não superestime —.\\nentão podemos utilizar uma busca A* para encontrar as melhores soluções. Uma heurística\\nadmissível pode ser obtida através da definição de um \\nproblema relaxado\\n que é mais fácil de\\nresolver. O custo exato de uma solução para esse problema mais fácil torna-se então a heurística do\\nproblema original.\\nPor definição, não há como analisar um estado atômico e, portanto, requer alguma engenhosidade\\npara um analista humano definir uma boa heurística de domínio específico para problemas de busca\\ncom estados atômicos. Planejamento utiliza uma representação fatorada para os estados e esquemas\\nde ação. Isso torna possível definir uma boa heurística independente do domínio e para os programas\\naplicarem automaticamente uma heurística independente do domínio para um determinado problema.\\nPense em um problema de busca como um grafo onde os nós são estados e as arestas são ações. O\\nproblema é encontrar um caminho que ligue o estado inicial ao estado objetivo. Há duas maneiras de\\nrelaxar esse problema para torná-lo mais fácil: acrescentando mais arestas ao grafo, tornando-o\\nestritamente mais fácil de encontrar um caminho ou agrupando vários nós juntos, formando uma\\nabstração do espaço de estados que tem menos estados e, assim, é mais fácil de fazer a busca.\\nOlharemos primeiro a heurística que adiciona arestas ao grafo. Por exemplo, a \\nheurística ignorar\\nas precondições\\n remove todas as precondições das ações. Toda ação passa a ser aplicável em cada\\nestado, e qualquer fluente objetivo individual pode ser alcançado em um único passo (se houver uma\\nação aplicável; se não, o problema é impossível). Isso quase implica que o número de passos\\nnecessários para resolver um problema relaxado é o número de objetivos não satisfeitos — quase,\\nmas não exatamente, porque (1) alguma ação pode atingir múltiplos objetivos e (2) algumas ações\\npodem desfazer os efeitos de outras. Para muitos problemas obtém-se uma heurística precisa\\nconsiderando (1) e ignorando (2). Primeiro, relaxamos as ações removendo todas as precondições e\\ntodos os efeitos, exceto aqueles que são literais no objetivo. Então, contamos o número mínimo de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 447}),\n",
       " Document(page_content='ações necessárias, tais que a união dos efeitos dessas ações satisfaça o objetivo. Esse é um exemplo\\ndo problema de \\ncobertura de conjuntos\\n. Há um pequeno porém: o problema de cobertura de\\nconjuntos é NP-difícil. Felizmente, um simples algoritmo guloso garante encontrar uma cobertura de\\nconjuntos cujo tamanho está dentro de um fator de log \\nn\\n da cobertura mínima verdadeira, onde \\nn\\n é o\\nnúmero de literais no objetivo. Infelizmente, o algoritmo guloso perde a garantia de admissibilidade.\\nTambém é possível ignorar apenas precondições s\\nelecionadas\\n das ações. Considere o quebra-\\ncabeças das peças deslizantes (quebra-cabeças de oito ou 15 peças) da \\nSeção 3.2\\n. Poderíamos\\ncodificar isso como um problema de planejamento que envolve as peças com um único esquema\\nDeslizar\\n:\\nComo vimos na \\nSeção 3.6\\n, se removermos as precondições \\nVazio\\n(\\ns\\n2\\n) \\n∧\\n \\nAdjacente\\n(\\ns\\n1\\n, s\\n2\\n),\\nqualquer peça pode mover-se em uma ação para qualquer espaço e obteremos a heurística do número\\nde peças fora de lugar. Se remo\\u200bvermos \\nVazio\\n(\\ns\\n2\\n) obteremos a heurística da distância de Manhattan. É\\nfácil verificar como essas heurísticas podem ser derivadas automaticamente a partir da descrição do\\nesquema de ação. A facilidade de manipular os esquemas é a grande vantagem da representação\\nfatorada dos problemas de planejamento, em comparação com a representação atômica dos\\nproblemas de busca.\\nOutra possibilidade é a heurística de \\nignorar listas de exclusão\\n. Assuma por um momento que\\ntodos os objetivos e precondições contêm apenas literais\\n3\\n positivos. Queremos criar uma versão\\nrelaxada do problema original que será mais fácil de resolver e onde o tamanho da solução servirá\\ncomo uma boa heurística. Podemos fazer isso removendo as listas de exclusão de todas as ações (isto\\né, removendo todos os literais negativos dos efeitos). Isso faz com que seja possível fazer progresso\\nmonotônico em direção ao objetivo — nenhuma ação jamais irá desfazer o progresso feito por outra\\nação. Acontece que encontrar a solução ótima para esse problema relaxado ainda é NP-difícil, mas\\npode ser encontrada uma solução aproximada em tempo polinomial por subida de encosta. A \\nFigura\\n10.6\\n diagrama parte do espaço de estados para dois problemas de planejamento utilizando a\\nheurística de ignorar listas de exclusão. Os pontos representam os estados, as arestas, as ações, e a\\naltura de cada ponto acima do plano inferior representa o valor heurístico. Os estados no plano\\ninferior são as soluções. Em ambos esses problemas, há um caminho amplo até o objetivo. Não há\\nbecos sem saída, então não há necessidade de retroceder; uma busca simples de subida de encosta\\nencontrará facilmente uma solução para esses problemas (embora possa não ser uma solução ótima).\\nOs problemas relaxados nos deixam com um problema de planejamento simplificado — mas ainda\\ncaro — apenas para calcular o valor da função heurística. Muitos problemas de planejamento tem\\n10\\n100\\n estados ou mais, e relaxar as ações não contribui para reduzir o número de estados. Portanto,\\ndaremos atenção agora aos relaxamentos que diminuem o número de estados formando uma\\nabstração do estado\\n — um mapeamento muitos-para-um dos estados na representação instanciada\\ndo problema para a representação abstrata.\\nA forma mais fácil de abstração de estado é ignorar alguns fluentes. Por exemplo, considere um', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 448}),\n",
       " Document(page_content='problema de carga aérea em 10 aeroportos, 50 aviões e 200 peças de carga. Cada avião pode estar\\nem um dos 10 aeroportos e cada peça pode estar em um dos aviões ou descarregada em um dos\\naeroportos. Portanto, há 50\\n10\\n × 200\\n50+10\\n ≈ 10\\n155\\n estados. Agora considere um determinado problema\\nnesse domínio em que acontece que todos as peças estão em apenas cinco aeroportos e, todas as\\npeças em um determinado aeroporto têm o mesmo destino. Em seguida, uma abstração útil do\\nproblema é a remoção de todos os fluentes \\nEm\\n exceto os que envolvem um avião e uma peça em cada\\num dos cinco aeroportos. Agora existem apenas 5\\n10\\n × 5\\n5+10\\n ≈ 10\\n17\\n estados. Uma solução nesse\\nespaço de estado abstrato será mais curta do que uma solução no espaço original (e, portanto, será\\numa heurística admissível), e a solução abstrata é fácil de estender ao problema original (através da\\ninclusão de ações \\nCarregar e Descarregar\\n adicionais).\\nFigura 10.6\\n Dois espaços de estados de problemas de planejamento com a heurística ignorar listas\\nde exclusão. A altura acima do plano inferior é a pontuação heurística de um estado; estados na parte\\ninferior do plano são objetivos. Não há mínimos locais; assim, a busca do objetivo é simples. De\\nHoffmann (2005).\\nA ideia-chave na definição da heurística é a \\ndecomposição\\n: dividir um problema em partes,\\nresolvendo cada parte de forma independente e depois combinar as partes. A hipótese da\\nindependência de subobjetivos\\n é que o custo de resolver uma conjunção de subobjetivos é\\naproximado pela soma dos custos de resolver cada subobjetivo de forma independente. A suposição\\nde independência de subobjetivos pode ser otimista ou pessimista. É otimista quando há interações\\nnegativas entre os subplanos para alcançar cada subobjetivo — por exemplo, quando uma ação em\\num subplano exclui um objetivo alcançado por outro subplano. É pessimista e, portanto, não\\nadmissível quando os subplanos contêm ações redundantes — por exemplo, duas ações que poderiam\\nser substituídas por uma única ação no plano composto.\\nSuponha que o objetivo seja um conjunto de fluentes \\nG\\n, os quais dividimos em subconjuntos\\ndisjuntos \\nG\\n1\\n,…, \\nG\\nn\\n. Em seguida, encontramos os planos \\nP\\n1\\n,…, \\nP\\nn\\n, que resolvem os respectivos\\nsubobjetivos. Qual é a estimativa de custo do plano para alcançar todos os \\nG\\n? Podemos pensar em\\ncada \\nCusto\\n(\\nP\\ni\\n) como uma estimativa heurística e sabemos que, se combinarmos as estimativas\\ntomando seus valores máximos, sempre obteremos uma heurística admissível. Então, o \\nmax\\ni', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 449}),\n",
       " Document(page_content='CUSTO(\\nP\\ni\\n) é admissível, e às vezes é exatamente correto: pode ser que, por acaso, \\nP\\n1\\n atinja todos\\nos \\nG\\ni\\n. Mas, na maioria dos casos, na prática a estimativa é muito baixa. Poderíamos somar os custos\\nem vez disso? Para muitos problemas isso é uma estimativa razoável, mas não é admissível. O\\nmelhor caso é quando podemos determinar que \\nG\\ni\\n e \\nG\\nj\\n são \\nindependentes\\n. Se os efeitos de \\nP\\ni\\ndeixarem todas as precondições e objetivos de \\nP\\nj\\n inalterados, a estimativa CUSTO(\\nP\\ni\\n) + CUSTO\\n(\\nP\\nj\\n) é admissível, e mais precisa que a estimativa max. Mostramos, na \\nSeção 10.3.1\\n, que os grafos de\\nplanejamento podem ajudar a fornecer melhores estimativas heurísticas.\\nÉ claro que existe um grande potencial para reduzir o espaço de busca formando abstrações. O\\ntruque é escolher as abstrações corretas e utilizá-las de maneira que faça o custo total — de definir\\numa abstração, fazer uma busca abstrata e mapear a abstração de volta ao problema original —\\nmenor do que o custo de resolver o problema original. A técnica de bancos de dados de padrões da\\nSeção 3.6.3\\n pode ser útil porque o custo de criação de banco de dados de padrões pode ser\\namortizado em múltiplas instâncias de problemas.\\nUm exemplo de um sistema que faz uso de heurísticas eficazes é FF, ou FastForward (Hoffmann,\\n2005), um buscador em espaço de estados para a frente que usa a heurística de ignorar listas de\\nexcluão, estimando a heurística com a ajuda de um grafo de planejamento (veja a \\nSeção 10.3\\n). FF\\nentão utiliza a busca de subida de encosta (modificada para construir o plano) com a heurística para\\nencontrar uma solução. Quando atinge um patamar ou máximo local — quando nenhuma ação leva a\\num estado com melhor pontuação heurística —, o FF utiliza a busca por aprofundamento iterativo até\\nencontrar um estado que seja melhor ou desiste e reinicia a subida de encosta.\\n10.3 GRAFOS DE PLANEJAMENTO\\nTodas as heurísticas que sugerimos podem sofrer de imprecisão. Esta seção mostra como uma\\nestrutura de dados especial chamada \\ngrafo de planejamento\\n pode ser usada para fornecer melhores\\nestimativas de heurísticas. Essas heurísticas podem ser aplicadas a qualquer das técnicas de busca\\nque vimos até agora. Como alternativa, podemos buscar uma solução sobre o espaço formado pelo\\ngrafo de planejamento utilizando um algoritmo chamado Graphplan.\\nA pergunta de um problema de planejamento é se podemos alcançar um estado objetivo do estado\\ninicial. Suponha que seja dada uma árvore de todas as ações possíveis a partir do estado inicial para\\nos estados sucessores, e seus sucessores, e assim por diante. Se indexarmos essa árvore\\nadequadamente, poderemos responder à pergunta de planejamento sobre se “podemos atingir o\\nestado \\nG\\n do estado \\nS\\n0\\n” imediatamente, olhando para essa árvore. Naturalmente, a árvore é de\\ntamanho exponencial, por isso essa abordagem é impraticável. Um grafo de planejamento é uma\\naproximação de tamanho polinomial dessa árvore que pode ser construído rapidamente. O grafo de\\nplanejamento definitivamente não pode responder se \\nG\\n é acessível de \\nS\\n0\\n, mas pode \\nestimar\\n quantos\\npassos levará para chegar a \\nG\\n. A estimativa é sempre correta quando ela relata que o objetivo não é\\nalcançável e nunca superestima o número de passos, por isso é uma heurística admissível.\\nUm grafo de planejamento é um grafo direcionado organizado em \\nníveis\\n: primeiro, o nível \\nS\\n0\\n para', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 450}),\n",
       " Document(page_content='o estado inicial, que consiste de nós que representam cada fluente que é verdadeiro em \\nS\\n0\\n; depois, o\\nnível \\nA\\n0\\n, consistindo de nós para cada ação instanciada que poderia ser aplicável em \\nS\\n0\\n; em seguida,\\nalterna níveis \\nS\\ni\\n seguidos por \\nA\\ni\\n até chegar a uma condição de término (a ser discutida mais adiante).\\nGrosso modo\\n, \\nS\\ni\\n contém todos os literais que \\npoderiam\\n ser verdadeiros no tempo \\ni\\n, dependendo\\ndas ações executadas nos passos de tempo anteriores. Se for possível \\nP\\n ou ¬\\nP\\n ser verdade, ambos\\nserão representados em \\nS\\ni\\n. Também a \\ngrosso modo\\n, \\nA\\ni\\n contém todas as ações que \\npoderiam\\n ter suas\\nprecondições satisfeitas no tempo \\ni\\n. Dizemos a \\ngrosso modo\\n porque o grafo de planejamento registra\\napenas um subconjunto restrito de interações negativas possíveis entre ações e, portanto, um literal\\npoderia aparecer no nível \\nS\\nj\\n quando, na verdade, poderia não ser verdadeiro, até num nível\\nposterior, ou nunca aparecer (um literal nunca vai aparecer muito tarde). Apesar do possível erro,\\nerro o nível \\nj\\n em que um literal aparece a princípio é uma boa estimativa do quão difícil é atingir o\\nliteral a partir do estado inicial.\\nOs grafos de planejamento funcionam apenas para problemas de planejamento proposicional —\\naqueles sem variáveis. Como já mencionamos, é simples proposicionalizar um conjunto de esquemas\\nde ações.\\nApesar do aumento no tamanho da descrição do problema, os grafos de planejamento têm\\nmostrado ser ferramentas eficazes para resolver problemas de planejamento difícil.\\nA \\nFigura 10.7\\n mostra um problema de planejamento simples, e a \\nFigura 10.8\\n mostra seu grafo de\\nplanejamento. Cada ação no nível \\nA\\ni\\n está conectada a suas precondições em \\nS\\ni\\n e seus efeitos em \\nS\\ni+1\\n.\\nAssim, um literal aparece porque uma ação o causou, mas também queremos dizer que um literal\\npode persistir se nenhuma ação negá-lo. Isso é representado pela \\nação de persistência\\n (às vezes\\nchamada \\nno-op\\n). Para cada literal \\nC\\n, adicionamos uma ação de persistência ao problema com\\nprecondição \\nC\\n e efeito \\nC\\n. O nível A0 na \\nFigura 10.8\\n mostra uma ação “real”, C\\nomer\\n(\\nBolo\\n),\\njuntamente com duas ações de persistência desenhadas como pequenas caixas quadradas.\\n    \\nInício\\n(\\nTer\\n(\\nBolo\\n))\\n    \\nObjetivo\\n(\\nTer\\n(\\nBolo\\n) \\n∧\\n \\nComido\\n(\\nBolo\\n))\\n    \\nAção\\n(\\nComer\\n(\\nBolo\\n)\\n        PRECOND: \\nTer\\n(\\nBolo\\n)\\n        EFEITO: ¬\\nTer\\n(\\nBolo\\n) \\n∧\\n \\nComido\\n(\\nBolo\\n))\\n    \\nAção\\n(\\nAssar\\n(\\nBolo\\n)\\n        PRECOND: ¬\\nTer\\n(\\nBolo\\n)\\n        EFEITO: \\nTer\\n(\\nBolo\\n))\\nFigura 10.7\\n Problema de “ter bolo e comer bolo”.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 451}),\n",
       " Document(page_content='Figura 10.8\\n O grafo de planejamento para o problema de “ter bolo e comer bolo” até o nível \\nS\\n2\\n. Os\\nretângulos indicam ações (pequenos quadrados indicam ações de persistência) e linhas retas indicam\\nprecondições e efeitos. As ligações de exclusão mútua (ou mutex) estão representados por linhas\\ncurvas em cor cinza. Nem todos as ligações de exclusão mútua são mostradas porque o grafo seria\\nmuito confuso. Em geral, se dois literais são mutex em \\nS\\ni\\n, as ações de persistência para aqueles\\nliterais serão mutex em \\nA\\ni\\n e não precisamos indicar essa ligação de mutex.\\nO nível \\nA\\n0\\n contém todas as ações que \\npoderiam\\n acontecer no estado \\nS\\n0\\n, mas, quase tão importante\\nquanto isso, ele registra conflitos entre ações que impediriam que essas ações ocorressem juntas. As\\nlinhas em cor cinza na \\nFigura 10.8\\n indicam ligações de \\nexclusão mútua\\n (ou \\nmutex\\n). Por exemplo,\\nComer\\n(\\nBolo\\n) é mutuamente exclusiva com a persistência de \\nTer\\n(\\nBolo\\n) ou ¬\\nComido\\n(\\nBolo\\n). Veremos\\nem breve como as ligações de exclusão mútua são calculados.\\nO nível \\nS\\n1\\n contém todos os literais que poderiam resultar da escolha de qualquer subconjunto das\\nações em \\nA\\n0\\n, bem como as ligações de mutex (linhas em cor cinza) indicando literais que não\\npoderiam aparecer juntos, independentemente da escolha de ações. Por exemplo, \\nTer\\n(\\nBolo\\n) e\\nComido\\n(\\nBolo\\n) são de exclusão mútua: dependendo da escolha de ações em \\nA\\n0\\n, um ou outro, mas não\\nambos, poderia ser o resultado. Em outras palavras, \\nS\\n1\\n representa um estado de crença: um conjunto\\nde estados possíveis. Os membros desse conjunto são todos subconjuntos dos literais de tal forma\\nque não há ligação de exclusão mútua entre quaisquer membros do subconjunto.\\nContinuamos, desse modo, alternando entre o nível de estado \\nS\\ni\\n e o nível de ação \\nA\\ni\\n até chegarmos\\na um nível em que dois níveis consecutivos são idênticos. Nesse momento, dizemos que o grafo \\nse\\nnivelou\\n. O grafo na \\nFigura 10.8\\n se nivela em \\nS\\n2\\n.\\nAcabaremos então com uma estrutura na qual todo nível \\nA\\ni\\n contém todas as ações que são\\naplicáveis em \\nS\\ni\\n, juntamente com restrições que informam que duas ações não podem ser executadas\\njuntas no mesmo nível. Todo nível \\nS\\ni\\n contém todos os literais que poderiam resultar de qualquer\\nescolha possível de ações em \\nA\\ni\\n–1\\n, juntamente com restrições que informam quais pares de literais\\nnão são possíveis. É importante observar que o processo de construção do grafo de planejamento\\nnão\\n requer a escolha entre as ações, o que exigiria uma busca combinatória. Em vez disso, ele\\nregistra apenas a impossibilidade de certas escolhas com a utilização de ligações de exclusão mútua.\\nAgora definimos ligações mutex para as ações e para os literais. Uma relação de mutex existe\\nentre duas \\nações\\n em um determinado nível, se qualquer das três condições a seguir é verdadeira:\\n•  \\nEfeitos inconsistentes\\n: uma ação nega um efeito da outra. Por exemplo, \\nComer\\n(\\nBolo\\n) e a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 452}),\n",
       " Document(page_content='persistência de \\nTer\\n(\\nBolo\\n) têm efeitos inconsistentes porque são discordantes sobre o efeito\\nTer\\n(\\nBolo\\n).\\n•  \\nInterferência\\n: um dos efeitos de uma ação é a negação de uma precondição da outra. Por\\nexemplo \\nComer\\n(\\nBolo\\n) interfere com a persistência de \\nTer\\n(\\nBolo\\n) negando sua precondição.\\n•  \\nNecessidades concorrentes\\n: uma das precondições de uma ação é mutuamente exclusiva com\\numa precondição da outra. Por exemplo, \\nAssar\\n(\\nBolo\\n) e \\nComer\\n(\\nBolo\\n) são mutuamente exclusivas\\nporque competem no valor da precondição \\nTer\\n(\\nBolo\\n).\\nUma relação de exclusão mútua existe entre dois \\nliterais\\n no mesmo nível se uma é a negação da\\noutra ou se cada par possível de ações que alcançariam os dois literais são mutuamente exclusivas.\\nEssa condição é chamada \\nsuporte inconsistente\\n. Por exemplo, \\nTer\\n(\\nBolo\\n) e \\nComido\\n(\\nBolo\\n) são de\\nexclusão mútua em \\nS\\n1\\n porque a única maneira de alcançar \\nTer\\n(\\nBolo\\n), a ação de persistência, é de\\nexclusão mútua com a única maneira de alcançar \\nComido\\n(\\nBolo\\n), ou seja, \\nComer\\n(\\nBolo\\n). Em \\nS\\n2\\n, os\\ndois literais não são de exclusão mútua porque existem novas maneiras de alcançá-los, como\\nAssar\\n(\\nBolo\\n) e a persistência de \\nComido\\n(\\nBolo\\n), que não são de exclusão mútua.\\nUm grafo de planejamento é polinomial no tamanho do problema de planejamento. Para um\\nproblema de planejamento com \\nl\\n literais e \\na\\n ações, todos os S\\ni\\n não têm mais do que \\nl\\n nós e \\nl\\n2\\nligações de exclusão mútua, e cada \\nA\\ni\\n não tem mais do que \\na + l\\n nós (incluindo os no-ops), (\\na + l\\n)\\n2\\nligações de exclusão mútua e 2(\\nal + l\\n) ligações de efeito e precondição. Assim, um grafo inteiro com\\nn\\n níveis tem um tamanho \\nO\\n(\\nn\\n(\\na+l\\n)\\n2\\n). O tempo para construir o grafo tem a mesma complexidade.\\n10.3.1 Grafos de planejamento para avaliação heurística\\nUma vez construído, um grafo de planejamento é uma rica fonte de informações sobre o problema.\\nEm primeiro lugar, se qualquer objetivo literal não aparece no nível final do grafo, o problema é\\ninsolúvel. Em segundo lugar, podemos estimar o custo de alcançar qualquer literal objetivo \\ng\\ni\\n do\\nestado \\ns\\n como sendo o nível no qual \\ng\\ni\\n, aparece pela primeira vez no grafo de planejamento\\nconstruído do estado inicial \\ns\\n. Chamamos esse custo de \\ncusto de nível\\n de \\ng\\n1\\n. Na \\nFigura 10.8\\n,\\nTer\\n(\\nBolo\\n) tem custo de nível 0 e \\nComido\\n(\\nBolo\\n) tem custo de nível 1. É fácil mostrar (Exercício\\n10.10) que essas estimativas são admissíveis para os objetivos individuais. Porém, talvez a\\nestimativa não seja sempre exata porque os grafos de planejamento permitem várias ações em cada\\nnível, enquanto a heurística leva em conta apenas o nível, e não o número de ações. Por essa razão, é\\ncomum se utilizar um \\ngrafo de planejamento serial\\n para calcular heurísticas. Um grafo serial insiste\\nem que apenas uma ação pode realmente acontecer em qualquer passo de tempo dado; isso é feito\\nadicionando-se ligações de exclusão mútua entre cada par de ações de não persistência. Os custos de\\nnível extraídos de grafos seriais são muitas vezes estimativas bastante razoáveis dos custos reais.\\nPara estimar o custo de uma \\nconjunção\\n de objetivos, existem três abordagens simples. A\\nheurística de \\nnível máximo\\n simplesmente considera o custo de nível máximo de qualquer dos\\nobjetivos; isso é admissível, mas não necessariamente muito preciso.\\nA heurística de \\nsoma de níveis\\n, seguindo a hipótese de independência de subobjetivo, devolve a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 453}),\n",
       " Document(page_content='soma dos custos de nível dos objetivos; isso pode ser inadmissível, mas funciona muito bem na\\nprática para problemas amplamente decomponíveis. Ela é muito mais precisa que a heurística de\\nnúmero-de-objetivos-não-satisfeitos da \\nSeção 10.2\\n. Para o nosso problema, a soma de níveis da\\nestimativa da heurística para o objetivo conjuntivo \\nTer\\n(\\nBolo\\n) \\n∧\\n \\nComido\\n(\\nBolo\\n) será 0 + 1 = 1,\\nenquanto a resposta correta é 2, alcançada pelo plano [\\nComer\\n(\\nBolo\\n), \\nAssar\\n(\\nBolo\\n)]\\n.\\n Isso não parece\\ntão ruim. Um erro mais grave é que, se \\nAssar\\n(\\nBolo\\n) não estiver no conjunto de ações, a estimativa\\nainda será 1, quando na verdade o objetivo conjuntivo seria impossível.\\nFinalmente, a heurística de \\nnível de conjunto\\n encontra o nível no qual todos os literais no objetivo\\nconjuntivo aparecem no grafo de planejamento sem que nenhum par seja mutuamente exclusivo. Essa\\nheurística fornece os valores corretos de 2 para o nosso problema original e infinito para o problema\\nsem \\nAssar(Bolo\\n). É admissível, domina a heurística de nível máximo e funciona extremamente bem\\nem tarefas em que há uma boa dose de interação entre os subplanos. Certamente não é perfeito; por\\nexemplo, ignora as interações entre três ou mais literais.\\nComo ferramenta para gerar heurísticas precisas, podemos visualizar o grafo de planejamento\\ncomo um problema relaxado que pode ser resolvido de forma eficiente. Para compreender a natureza\\ndo problema relaxado, precisamos entender exatamente o que significa um literal \\ng\\n aparecer no nível\\nS\\ni\\n no grafo de planejamento. No caso ideal, gostaríamos que ele fosse uma garantia de que existe um\\nplano com \\ni\\n níveis de ações que atinge \\ng\\n, e também que, se \\ng\\n não aparecer, que não existe tal plano.\\nInfelizmente, dar essa garantia é tão difícil quanto resolver o problema de planejamento original.\\nAssim, o grafo de planejamento cuida da segunda metade da garantia (se \\ng\\n não aparecer, não existe\\nnenhum plano), mas, se \\ng\\n aparecer, tudo o que o grafo de planejamento promete é que existe um plano\\nque \\npossivelmente\\n atinge \\ng\\n e não tem nenhuma falha “óbvia”. Uma falha óbvia é definida como uma\\nfalha que pode ser detectada considerando-se duas ações ou dois literais ao mesmo tempo — em\\noutras palavras, examinando-se as relações de exclusão mútua. Poderia haver falhas mais sutis\\nenvolvendo três, quatro ou mais ações, mas a experiência mostrou que não vale a pena o esforço\\ncomputacional para manter o controle dessas possíveis falhas. Isso é semelhante à lição aprendida a\\npartir dos problemas de satisfação de restrições, de que frequentemente vale a pena calcular a 2-\\nconsistência antes de procurar uma solução, mas em geral é menos compensador calcular a 3-\\nconsistência ou maior.\\nUm exemplo de problema insolúvel, que não pode ser reconhecido como tal por um grafo de\\nplanejamento, é o problema do mundo dos blocos onde o objetivo é obter o bloco \\nA\\n sobre o \\nB\\n, \\nB\\nsobre \\nC\\n e \\nC\\n sobre \\nA\\n. Esse é um objetivo impossível; uma torre com base em cima do topo. Mas um\\ngrafo de planejamento não pode detectar porque quaisquer dois dos três subobjetivos são\\ninatingíveis. Não há exclusões mútuas entre qualquer par de literais, apenas entre os três como um\\ntodo. Para detectar que esse problema é impossível, teríamos que fazer busca no grafo de\\nplanejamento.\\n10.3.2 O algoritmo Graphplan\\nEsta subseção mostra como extrair um plano diretamente do grafo de planejamento, em vez de\\napenas utilizar o grafo para fornecer uma heurística. O algoritmo GRAPHPLAN (\\nFigura 10.9\\n)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 454}),\n",
       " Document(page_content='adiciona repetidamente um nível a um grafo de planejamento com EXPANDIR-GRAFO. Uma vez\\nque todos os objetivos aparecem como sendo de não exclusão mútua no grafo, o GRAPHPLAN\\nchama EXTRAIR-SOLUÇÃO para buscar um plano que resolva o problema. Se isso falhar, expande\\noutro nível e tenta de novo, terminando em falha quando não houver razão para continuar.\\nfunção\\n GRAPHPLAN(\\nproblema\\n) \\nretorna\\n solução ou falha\\n    \\ngrafo\\n ← GRAFO-DE-PLANEJAMENT0-INICIAL(\\nproblema\\n)\\n    \\nobjetivos\\n ← CONJUNÇÃO(\\nproblema\\n.OBJETIVO)\\n    \\nnãobons\\n ← uma tabela hash vazia\\n    \\npara\\n \\ntl\\n = 0 \\naté\\n \\x00 \\nfaça\\n        \\nse\\n \\nobjetivos\\n são todos de não exclusão mútua em S\\nt\\n do \\ngrafo\\n \\nentão faça\\n            \\nsolução\\n ← EXTRAIR-SOLUÇÃO(\\ngrafo\\n, \\nobjetivos\\n, NUMNÍVEIS(\\ngrafo),nãobons\\n)\\n            \\nse\\n \\nsolução\\n ≠ \\nfalha\\n \\nentão retornar\\n \\nsolução\\n        \\nse\\n \\ngrafo e nãobons estiverem ambos nivelados\\n \\nentão retornar\\n \\nfalha\\n        \\ngrafo\\n ← EXPANDIR-GRAFO(\\ngrafo\\n, \\nproblema\\n)\\nFigura 10.9\\n O algoritmo GRAPHPLAN chama EXPANDIR-GRAFO para adicionar um nível até que\\nseja encontrada uma solução através de EXTRAIR-SOLUÇÃO ou nenhuma solução seja possível.\\nAgora, vamos acompanhar a operação de GRAPHPLAN no problema do pneu sobressalente da\\nSeção 10.10. O grafo inteiro é mostrado na \\nFigura 10.10\\n. A primeira linha do GRAPHPLAN\\ninicializa o grafo de planejamento como um grafo de um único nível (\\nS\\n0\\n) representando o estado\\ninicial. Os fluentes positivos do estado inicial da descrição do problema são mostrados, assim como\\nos fluentes negativos relevantes. Os literais positivos que não mudam não são mostrados (como\\nPneu\\n(\\nSobressalente\\n)) e os literais negativos irrelevantes. O literal de objetivo \\nEm\\n(\\nSobressalente\\n,\\nEixo\\n) não está presente em \\nS\\n0\\n; então não precisamos da chamada a EXTRAIR-SOLUÇÃO —\\nestamos certos de que ainda não existe nenhuma solução. Em vez disso, EXPANDIR-GRAFO\\nadiciona em A\\n0\\n as três ações cujas precondições existem no nível \\nS\\n0\\n (isto é, todas as ações exceto\\nColocar\\n(\\nSobressalente\\n, \\nEixo\\n)), junto com ações de persistência para todos os literais em \\nS\\n0\\n. Os\\nefeitos das ações são adicionados ao nível \\nS\\n1\\n. Depois disso, EXPANDIR-GRAFO procura por\\nrelações de exclusão mútua e as acrescenta ao grafo.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 455}),\n",
       " Document(page_content='Figura 10.10\\n O grafo de planejamento para o problema de pneu sobressalente, depois da expansão\\naté o nível \\nS\\n2\\n. As ligações de exclusão mútua são mostradas como linhas em cor cinza. Nem todos os\\nmutex são mostrados porque o grafo ficaria muito confuso se mostrássemos todos eles. A solução é\\nindicada por linhas e contornos em negrito.\\nEm\\n(\\nSobressalente\\n, \\nEixo\\n) ainda não está presente em \\nS\\n1\\n, portanto mais uma vez não chamamos\\nEXTRAIR-SOLUÇÃO. Chamamos EXPANDIR-GRAFO novamente, adicionando \\nA\\n1\\n e \\nS\\n1\\n resultando\\nno grafo de planejamento mostrado na \\nFigura 10.10\\n. Agora, que temos o complemento total de ações,\\nvale a pena examinar alguns dos exemplos de relações de exclusão mútua e suas causas:\\n•  \\nEfeitos inconsistentes\\n: \\nRemover\\n(\\nSobressalente\\n, \\nPortaMalas\\n) é mutex com \\nDeixarDuranteNoite\\nporque uma tem o efeito \\nEm\\n(\\nSobressalente\\n, \\nChão\\n) e a outra tem sua negação.\\n•  \\nInterferência\\n: \\nRemover\\n(\\nFurado\\n, \\nEixo\\n) é mutex com \\nDeixarDuranteNoite\\n porque uma ação tem\\na precondição \\nEm\\n(\\nFurado\\n, \\nEixo\\n) e a outra tem sua negação como efeito.\\n•  \\nNecessidades concorrentes\\n: \\nColocar\\n(\\nSobressalente\\n, \\nEixo\\n) é mutex com \\nRemover\\n(\\nFurado\\n,\\nEixo\\n), porque uma tem \\nEm\\n(\\nFurado\\n, \\nEixo\\n) como precondição e a outra tem sua negação.\\n•  \\nSuporte inconsistente\\n: \\nEm\\n(\\nSobressalente\\n, \\nEixo\\n) é mutex com \\nEm\\n(\\nFurado\\n, \\nEixo\\n) em \\nS\\n2\\n porque a\\núnica maneira de alcançar \\nEm\\n(\\nSobressalente\\n, \\nEixo\\n) é através de \\nColocar\\n(\\nSobressalente\\n, \\nEixo\\n),\\ne essa ação é mutex com a ação de persistência que é o único modo de alcançar \\nEm\\n(\\nFurado\\n,\\nEixo\\n). Desse modo, as relações mutex detectam o conflito imediato que surge a partir da\\ntentativa de colocar dois objetos no mesmo lugar ao mesmo tempo.\\nDessa vez, quando voltamos ao início da repetição, todos os literais do objetivo estão presentes\\nem \\nS\\n2\\n, e nenhum deles é mutex com qualquer outro. Isso significa que poderia existir uma solução, e\\nEXTRAIR-SOLUÇÃO tentará descobri-la. Podemos formular, EXTRAIR-SOLUÇÃO como um\\nproblema de satisfação de restrição booleano (CSP) onde as variáveis são as ações em cada nível,\\nos valores para cada variável estão \\ndentro\\n ou \\nfora\\n do plano, as restrições são as exclusões mútuas e\\nhá necessidade de satisfazer cada objetivo e precondição.\\nPodemos definir alternativamente EXTRAIR-SOLUÇÃO como um problema de busca para trás,\\nno qual cada estado na busca contém um ponteiro para um nível no grafo de planejamento e um\\nconjunto de objetivos não satisfeitos. Definimos esse problema de busca assim:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 456}),\n",
       " Document(page_content='•  O estado inicial é o último nível do grafo de planejamento, \\nS\\nn\\n, juntamente com o conjunto de\\nobjetivos do problema de planejamento.\\n•  As ações disponíveis em um estado no nível \\nS\\ni\\n se destinam a selecionar qualquer subconjunto\\nlivre de conflitos das ações em \\nA\\ni\\n–1\\n cujos efeitos cobrem os objetivos do estado. O estado\\nresultante tem nível \\nS\\ni\\n–1\\n e tem como seu conjunto de objetivos as precondições correspondentes\\nao conjunto de ações selecionado. Por “livre de conflitos” queremos dizer um conjunto de ações\\ntais que duas quaisquer dessas ações não sejam mutuamente exclusivas e que duas quaisquer de\\nsuas precondições não sejam mutuamente exclusivas.\\n•  O objetivo é alcançar um estado no nível \\nS\\n0\\n tal que todos os objetivos sejam satisfeitos.\\n•  O custo de cada ação é 1.\\nPara esse problema específico, começamos em \\nS\\n2\\n com o objetivo \\nEm\\n(\\nSobressalente\\n, \\nEixo\\n). A\\núnica escolha que temos para alcançar o conjunto de objetivos é \\nColocar\\n(\\nSobressalente\\n, \\nEixo\\n). Isso\\nnos leva a um estado de busca em \\nS\\n1\\n com os objetivos \\nEm\\n(\\nSobressalente\\n, \\nChão\\n) e ¬\\nEm\\n(\\nFurado\\n,\\nEixo\\n). O primeiro só pode ser alcançado por \\nRemover\\n(\\nSobressalente\\n, \\nPortaMalas\\n), e o último por\\nRemover\\n(\\nFurado\\n, \\nEixo\\n) ou \\nDeixarDuranteNoite\\n. Porém, \\nDeixar-DuranteNoite\\n é mutex com\\nRemover\\n(\\nSobressalente\\n, \\nPortaMalas\\n); então, a única solução é escolher \\nRemover\\n(\\nSobressalente\\n,\\nPortaMalas\\n) e \\nRemover\\n(\\nFurado\\n, \\nEixo\\n). Isso nos leva a um estado de busca em \\nS\\n0\\n com os objetivos\\nEm\\n(\\nSobressalente\\n, \\nPortaMalas\\n) e \\nEm\\n(\\nFurado\\n, \\nEixo\\n). Ambos estão presentes no estado, e então\\ntemos uma solução: as ações \\nRemover\\n(\\nSobressalente\\n, \\nPortaMalas\\n) e \\nRemover\\n(\\nFurado\\n, \\nEixo\\n) no\\nnível \\nA\\n0\\n, seguidas por \\nColocar\\n(\\nSobressalente\\n,\\nEixo\\n) em \\nA\\n1\\n.\\nNo caso em que EXTRAIR-SOLUÇÃO falhar em encontrar uma solução para um conjunto de\\nobjetivos em determinado nível, gravamos o par (\\nnível, objetivos\\n), como um \\nnão-bom\\n, assim como\\nfizemos na restrição de aprendizagem para CSPs. Sempre que EXTRAIR- SOLUÇÃO for chamado\\nnovamente com o mesmo nível e objetivos, podemos encontrar o não-bom registrado e devolver\\nimediatamente a falha em vez de buscar novamente. Vemos logo que não-bons são também utilizados\\nno teste de término.\\nSabemos que o planejamento é PSPACE-completo e que a construção do grafo de planejamento\\ndemora um tempo polinomial; assim, a extração da solução é intratável no pior caso. Por\\nconseguinte, precisaremos de alguma orientação de heurística para escolher entre ações durante a\\nbusca para trás. Uma abordagem que funciona bem na prática é um algoritmo guloso baseado no custo\\nde nível dos literais. Para qualquer conjunto de objetivos, prosseguimos na seguinte ordem:\\n1. Selecionar primeiro o literal com o custo de nível mais alto.\\n2. Para atingir esse literal, escolha ações com precondições fáceis. Isto é, escolher uma ação tal\\nque a soma (ou o máximo) dos custos de nível de suas precondições seja o menor possível.\\n10.3.3 Término do GRAPHPLAN\\nAté agora, evitamos discutir a questão do término. Aqui nós mostramos que o GRAPHPLAN, na', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 457}),\n",
       " Document(page_content='verdade, terminará e devolverá falha quando não houver solução.\\nA primeira coisa a entender é por que não podemos parar de expandir o grafo logo que ele nivela.\\nConsidere um domínio de carga aérea com um avião e \\nn\\n peças de carga no aeroporto \\nA\\n, todos tendo o\\naeroporto \\nB\\n como destino. Nessa versão do problema, apenas uma peça da carga pode caber no\\navião de cada vez. O grafo vai nivelar em 4, refletindo o fato de que, para qualquer peça única de\\ncarga, podemos carregá-la, transportá-la e descarregá-la no local de destino em três passos. Mas\\nisso não significa que uma solução possa ser extraída do grafo no nível 4; de fato, uma solução\\nexigirá 4\\nn\\n − 1 passos: para cada peça de carga que carregamos, transportamos e descarregamos, e\\npara todas, exceto a última peça, teremos que voltar ao aeroporto \\nA\\n para obter a próxima peça.\\nQuanto tempo temos que continuar expandindo depois que o grafo for nivelado? Se a função\\nEXTRAIR-SOLUÇÃO falhar em encontrar uma solução, deve haver pelo menos um conjunto de\\nobjetivos que não foram atingidos e foram marcados como não-bons. Então, se é possível que haja\\npoucos não-bons no próximo nível, devemos continuar. Assim que o grafo em si e os não-bons\\ntiverem nivelados, sem solução encontrada, podemos terminar com falha porque não há possibilidade\\nde uma alteração posterior que poderia adicionar uma solução.\\nAgora tudo o que temos a fazer é provar que o grafo e os não-bons sempre vão nivelar. A chave\\npara essa prova é que certas propriedades de grafos de planejamento são monotonicamente\\ncrescentes ou decrescentes. “X aumenta monotonicamente” significa que o conjunto de valores de X\\nno nível \\ni\\n + 1é um superconjunto (não necessariamente próprio) do conjunto do nível \\ni\\n. As\\npropriedades são as seguintes:\\n•  \\nLiterais aumentam monotonicamente\\n: Depois que um literal aparecer em um dado nível, ele\\naparecerá em todos os níveis subsequentes. Isso ocorre devido às ações de persistência; uma vez\\nque um literal surge, as ações de persistência o fazem permanecer para sempre.\\n•  \\nAções aumentam monotonicamente\\n: Depois que uma ação aparecer em dado nível, ela\\naparecerá em todos os níveis subsequentes. Essa é uma consequência do crescimento monotônico\\ndos literais; se as precondições de uma ação aparecerem em um nível, elas aparecerão em níveis\\nsubsequentes, portanto a ação também aparecerá.\\n•  \\nAs exclusões mútuas diminuem monotonicamente\\n: Se duas ações são de exclusão mútua em um\\ndado nível \\nA\\ni\\n, então elas também são de exclusão mútua em todos os níveis \\nanteriores\\n em que\\nambas aparecem. O mesmo é válido no caso de exclusões mútuas entre literais. Nem sempre\\npode parecer desse modo nas figuras porque as figuras têm uma simplificação: elas não exibem\\nos literais que não podem ser válidos no nível \\nS\\ni\\n nem as ações que não podem ser executadas no\\nnível \\nA\\ni\\n. Podemos observar que “as exclusões mútuas diminuem monotonicamente” é verdadeiro\\nse considerarmos que esses literais e essas ações invisíveis são de exclusão mútua com todos os\\noutros.\\n  A prova pode ser tratada por casos: se as ações \\nA\\n e \\nB\\n são mutex no nível \\nA\\ni\\n, isso ocorre devido\\na um dos três tipos de mutex. Os dois primeiros, efeitos inconsistentes e interferência, são\\npropriedades das próprias ações; assim, se as ações forem mutex em \\nA\\ni\\n, elas serão mutex em\\nqualquer nível. O terceiro caso, necessidades concorrentes, depende das condições no nível \\nS\\ni\\n:\\nesse nível deve conter uma precondição de \\nA\\n que seja de mutex com uma precondição de \\nB\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 458}),\n",
       " Document(page_content='Agora, essas duas precondições podem ser mutex se forem negações uma da outra (em cujo caso\\nseriam mutex em todos os níveis) ou se todas as ações para alcançar uma delas são mutex com\\ntodas as ações para alcançar a outra. Porém, já sabemos que as ações disponíveis estão\\naumentando monotonicamente; então, por indução, as exclusões mútuas devem estar diminuindo.\\n•  \\nNão-bons diminuem monotonicamente\\n: Se um conjunto de objetivos não for atingível em um\\ndeterminado nível, eles não são atingíveis em qualquer nível \\nanterior\\n. A prova é por\\ncontradição: se eles forem atingíveis em algum nível \\nanterior\\n, então poderemos apenas\\nadicionar ações de persistência para torná-los atingíveis em um nível subsequente.\\nPorque as ações e os literais aumentam monotonicamente e também pelo fato de haver apenas um\\nnúmero finito de ações e literais, deve haver um nível que tem o mesmo número de ações e literais\\ncomo no nível anterior. Deve ocorrer um nível que tenha o mesmo número de exclusão mútua e de\\nnão-bons, como no nível anterior, pois os mutuamente exclusivos e os não-bons diminuem, e nunca\\npode haver menos que zero de exclusão mútua ou não-bons. Uma vez que um grafo atinja esse estado,\\nse um dos objetivos estiver ausente ou for de exclusão mútua com outro objetivo, podemos parar o\\nalgoritmo GRAPHPLAN e devolver falha. Isso conclui um esboço da prova; para mais detalhes,\\nconsulte Ghallab \\net al\\n. (2004).\\n10.4 OUTRAS ABORDAGENS CLÁSSICAS DE PLANEJAMENTO\\nAtualmente, as abordagens mais populares e eficazes para o planejamento totalmente automatizado\\nsão:\\n•  Tradução para um problema de satisfatibilidade booleana (SAT)\\n•  Busca em espaço de estados para a frente com heurísticas bem construídas (\\nSeção 10.2\\n)\\n•  Busca utilizando um grafo de planejamento (\\nSeção 10.3\\n)\\nEssas três abordagens não foram os únicas tentativas em 40 anos de história de planejamento\\nautomatizado. A \\nFigura 10.11\\n mostra alguns dos sistemas de topo nas \\nInternational Planning\\nCompetitions\\n, que foram realizados a cada ano, desde 1998. Nesta seção, primeiro descreveremos a\\ntradução para um problema de satisfatibilidade e depois descreveremos três outras abordagens\\ninfluentes: o planejamento como dedução lógica de primeira ordem, como satisfação de restrição e\\ncomo refinamento do plano.\\nAno\\nTrilha\\nSistemas Winning (abordagens)\\n2008\\n2008\\nÓtimo\\nSatisfatório\\nGAMER (verificação do modelo, busca bidirecional)\\nLAMA (busca rápida decrescente com heurística FF)\\n2006\\n2006\\nÓtimo\\nSatisfatório\\nSATPLAN, MAXPLAN (satisfatibilidade booleana)\\nSGPLAN (busca para a frente; partições em subproblemas independentes)\\n2004\\n2004\\nÓtimo\\nSatisfatório\\nSATPLAN (satisfatibilidade booleana)\\nRÁPIDO EM DIAGONAL DECRESCENTE (busca para a frente com', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 459}),\n",
       " Document(page_content='grafo causal)\\n2002\\n2002\\nAutomatizado\\nCodificado à\\nmão\\nGLP (busca local, grafos de planejamento convertido para PSRs)\\nTLPLAN (ação lógica temporal com regras de controle de busca para a\\nfrente)\\n2000\\n2000\\nAutomatizado\\nCodificado à\\nmão\\nFF (busca para a frente)\\nTALPLANNER (ação lógica temporal com regras de controle de busca\\npara a frente)\\n1998\\nAutomatizado\\nIPP (grafos de planejamento); HSP (busca para a frente)\\nFigura 10.11\\n Alguns dos sistemas de alto desempenho na \\nInternational Planning Competition\\n. A\\ncada ano há várias trilhas: “ótimo” significa que os planejadores devem produzir o plano mais curto\\npossível, enquanto “satisfatório” significa que soluções não ótimas são aceitas. “Codificado à mão”\\nsignifica que são permitidas heurísticas de domínio específico; “automatizado” significa que não são.\\n10.4.1 Planejamento clássico como satisfatibilidade booleana\\nNa \\nSeção 7.7.4\\n, vimos como o SATPLAN resolve os problemas de planejamento que são\\nexpressos em lógica proposicional. Aqui mostraremos como traduzir uma descrição PDDL em uma\\nforma que pode ser processada por SATPLAN. A tradução é composta de uma série de etapas\\nsimples:\\n•  Proposicionalizar as ações: substituir cada esquema de ação com um conjunto de ações\\ninstanciadas formadas pela substituição de constantes para cada uma das variáveis. Essas ações\\ninstanciadas não são parte da tradução, mas serão utilizadas nas etapas subsequentes.\\n•  Definir o estado inicial: declarar F\\n0\\n para cada fluente \\nF\\n no estado inicial do problema, e ¬\\nF\\npara cada fluente não mencionado no estado inicial.\\n•  Proposicionalizar o objetivo: para cada variável no objetivo, substituir os literais que contêm\\numa variável com uma disjunção sobre constantes. Por exemplo, o objetivo de ter o bloco \\nA\\nsobre outro bloco, \\nSobre(A, x)\\n \\n∧\\n \\nBloco(x)\\n em um mundo com objetos \\nA\\n, \\nB\\n e \\nC\\n, seria substituído\\npelo objetivo\\n•  Adicionar axiomas de estado sucessor: para cada fluente \\nF\\n, adicionar um axioma da forma\\nonde \\nAçãoCausaF\\n é uma disjunção de todas as ações instanciadas, que tem \\nF\\n em sua lista de\\nadição e \\nAçãoCausaNãoF\\n é uma disjunção de todas as ações instanciadas, que tem \\nF\\n em sua\\nlista de exclusão.\\n•  Adicionar axiomas de precondição: para cada ação fundamentada \\nA\\n, adicionar o axioma \\nA\\nt\\n \\n⇒\\nPRE (\\nA\\n)\\nt\\n, isto é, se for tomada uma ação no tempo \\nt\\n, é porque as precondições eram verdadeiras.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 460}),\n",
       " Document(page_content='•  Adicionar axiomas de exclusão de ação: informa que toda ação é distinta de qualquer outra ação.\\nA tradução resultante estará na forma em que possamos passar ao SATPLAN para encontrar uma\\nsolução.\\n10.4.2 Planejamento como dedução na lógica de primeira ordem: cálculo de\\nsituação\\nPDDL é uma linguagem que equilibra cuidadosamente a expressividade da linguagem com a\\ncomplexidade dos algoritmos que a operam. Mas alguns problemas permanecem difíceis de\\nexpressar em PDDL. Por exemplo, não podemos expressar o objetivo “mover toda a carga de \\nA\\n para\\nB\\n, independentemente de quantas peças de carga existam” em PDDL, mas podemos fazê-lo na lógica\\nde primeira ordem usando um quantificador universal. Da mesma forma, a lógica de primeira ordem\\npode expressar concisamente restrições globais, tais como “não mais que quatro robôs podem estar\\nno mesmo lugar, ao mesmo tempo”. PDDL só pode dizer isso com precondições repetitivas em cada\\nação possível que envolve um movimento.\\nA representação em lógica proposicional de problemas de planejamento também tem limitações,\\ntal como o fato de que a noção de tempo está diretamente ligada aos fluentes. Por exemplo, \\nSul\\n2\\nsignifica “o agente está voltado para o sul no tempo 2”. Com essa representação, não há nenhuma\\nmaneira de dizer “o agente estaria voltado para o sul no tempo 2 se executasse uma curva à direita no\\ntempo 1, caso contrário estaria voltado para leste”. A lógica de primeira ordem nos permite\\ncontornar essa limitação substituindo a noção do tempo linear com uma noção de \\nsituações\\n de\\nramificação, usando uma representação chamada \\ncálculo de situações\\n que funciona assim:\\n•  O estado inicial é chamado de \\nsituação\\n. Se \\ns\\n for uma situação e \\na\\n for uma ação,\\nRESULTADO(\\ns\\n, \\na\\n) também será uma situação. Não há outras situações. Assim, uma situação\\ncorresponde a uma sequência ou histórico de ações. Pode-se também pensar em uma situação\\ncomo o resultado da aplicação de ações, mas observe que duas situações serão as mesmas\\napenas se o seu início e as ações forem os mesmos: (RESULTADO(\\ns, a\\n) = RESULTADO(\\ns’,\\na’\\n)) \\n⇔\\n (\\ns\\n = \\ns’\\n \\n∧\\n \\na\\n = \\na’\\n). Alguns exemplos de ações e situações são mostrados na \\nFigura 10.12\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 461}),\n",
       " Document(page_content='Figura 10.12\\n Situações como resultados de ações no mundo de wumpus.\\n•  A função ou relação que pode variar de uma situação para a próxima é um \\nfluente\\n. Por\\nconvenção, a situação \\ns\\n é sempre o último argumento para o fluente, por exemplo, \\nEm\\n(\\nx, l, s\\n) é\\num fluente relacional que é verdadeiro quando o objeto \\nx\\n estiver na localização \\nl\\n e na situação \\ns\\n,\\ne \\nLocalização\\n é um fluente funcional tal que \\nLocalização\\n(\\nx, s) = l\\n é verdadeiro nas mesmas\\nsituações que \\nEm\\n(\\nx, l, s\\n).\\n•  Cada uma das precondições da ação é descrita com um \\naxioma de possibilidade\\n que informa\\nquando a ação pode ser tomada. Ele tem a forma \\nΦ\\n(\\ns\\n) \\n⇒\\n \\nPossível\\n(\\na\\n, \\ns\\n) onde \\nΦ\\n(\\ns\\n) é alguma\\nfórmula envolvendo \\ns\\n que descreve as precondições. Um exemplo do mundo de wumpus diz que\\né possível atirar se o agente estiver vivo e tiver uma flecha:\\n•  Cada fluente é descrito com um \\naxioma de estado sucessor\\n que diz o que acontece com o\\nfluente, dependendo da ação que for realizada. Esta é semelhante à abordagem que adotamos\\npara a lógica proposicional. O axioma tem a forma\\nPor exemplo, o axioma do fluente relacional \\nSegurar\\n diz que o agente está segurando algum ouro \\ng\\ndepois de executar uma ação possível se e somente se a ação era \\nAgarrar\\n de \\ng\\n ou se o agente já\\nestava segurando \\ng\\n e a ação não o solta:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 462}),\n",
       " Document(page_content='•  Precisamos de \\naxiomas de ação única\\n para que o agente possa deduzir que, por exemplo, \\na\\n ≠\\nSoltar\\n(\\ng\\n). Para cada par de nomes distintos de ação \\nA\\ni\\n e \\nA\\nj\\n temos um axioma que informa que as\\nações são diferentes:\\ne para cada nome da ação \\nA\\ni\\n temos um axioma que informa que dois usos desse nome da ação\\nsão iguais se e somente se todos os seus argumentos forem iguais:\\n•  A solução é uma situação (e, portanto, uma sequência de ações) que satisfaz o objetivo.\\nTrabalhos em cálculo de situações fizeram muito para definir a semântica formal de planejamento\\ne para abrir novas áreas de investigação. Mas até agora não houve um programa prático de\\nplanejamento em larga escala com base em dedução lógica sobre o cálculo de situações. Isso é em\\nparte devido à dificuldade de se fazer inferência eficiente em FOL, mas é principalmente porque o\\ncampo ainda não desenvolveu heurística eficazes de planejamento com cálculo de situações.\\n10.4.3 Planejamento como satisfação de restrição\\nVimos que a satisfação de restrição tem muito em comum com a satisfatibilidade booleana e que as\\ntécnicas de CSP são eficazes para problemas de escalonamento, de modo que não é surpreendente\\nque seja possível codificar um problema de planejamento limitado (ou seja, o problema de encontrar\\num plano de comprimento \\nk\\n) como um problema de satisfação de restrição (CSP). A codificação é\\nsimilar à codificação de um problema SAT (\\nSeção 10.4.1\\n), com uma simplificação importante: em\\ncada etapa precisamos apenas de uma única variável, \\nAção\\nt\\n, cujo domínio é o conjunto de ações\\npossíveis. Não é necessário mais que uma variável para cada ação, e não precisamos dos axiomas de\\nexclusão de ação. É possível também codificar um grafo de planejamento em um CSP. Essa é a\\nabordagem do GP-PSR (Do e Kambhampati, 2003).\\n10.4.4 Planejamento como refinamento de planos parcialmente ordenados\\nTodas as abordagens que vimos até agora constroem planos \\ntotalmente ordenados\\n consistindo em\\numa sequência de ações totalmente ordenada. Essa representação ignora o fato de que muitos\\nsubproblemas são independentes. Uma solução para um problema de carga aérea consiste em uma\\nsequência de ações totalmente ordenadas, mas se 30 peças forem carregadas em um avião em um\\naeroporto e 50 peças forem carregadas em outro avião em outro aeroporto, parece inútil chegar com', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 463}),\n",
       " Document(page_content='uma ordenação completa de 80 ações de carga; os dois subconjuntos de ações deveriam ser pensados\\nde forma independente.\\nUma alternativa é representar planos como estruturas \\nparcialmente ordenadas\\n: um plano é um\\nconjunto de ações e um conjunto de restrições da forma \\nAntes\\n(\\na\\ni\\n, \\na\\nj\\n) informando que uma ação ocorre\\nantes da outra. Na parte inferior da \\nFigura 10.13\\n, vemos um plano parcialmente ordenado que é uma\\nsolução para o problema do pneu sobressalente. As ações são caixas e as restrições de ordenação\\nsão setas. Observe que \\nRemover\\n(\\nSobressalente, Porta-malas\\n) e \\nRemover\\n (\\nFurado, Eixo\\n) podem ser\\nfeitos em qualquer ordem, desde que sejam concluídos antes da ação \\nColocar\\n(\\nSobressalente, Eixo\\n).\\nFigura 10.13\\n (a) O problema do pneu descrito como um plano vazio. (b) Um plano incompleto\\nparcialmente ordenado do problema do pneu. As caixas representam as ações, e as setas indicam que\\numa ação deve ocorrer antes da outra. (c) Uma solução completa parcialmente ordenada.\\nOs planos parcialmente ordenados são criados por uma \\nbusca através do espaço dos planos\\n, em\\nvez de através do espaço de estados. Começamos com o plano vazio consistindo apenas no estado\\ninicial e no objetivo, sem ações entre eles, como na parte superior da \\nFigura 10.13\\n. O procedimento\\nde busca, procura então por uma \\nfalha\\n no plano e faz uma adição ao plano para corrigir a falha (ou,\\nse não puder ser feita nenhuma correção, a busca retrocede e tenta outra coisa). A falha é algo que\\nimpede o plano parcial de ser uma solução. Por exemplo, uma falha no plano vazio é que nenhuma\\nação atinge \\nEm\\n(\\nSobressalente\\n, \\nEixo\\n). Uma forma de corrigir a falha é inserir no plano a ação\\nColocar\\n(\\nSobressalente\\n, \\nEixo\\n). Isso certamente introduz algumas falhas novas: as precondições da\\nnova ação não são alcançadas. A busca continua fazendo adições ao plano (retrocedendo se\\nnecessário) até que todas as falhas sejam resolvidas, como na parte inferior da \\nFigura 10.13\\n. A cada\\netapa, fazemos o \\nmenor compromisso\\n possível para corrigir a falha. Por exemplo, ao adicionar a\\nação \\nRemover\\n(\\nSobressalente, Porta-malas\\n) temos que nos comprometer que ocorra antes de\\nColocar\\n(\\nSobressalente, Eixo\\n), mas não nos comprometemos em colocá-lo antes ou depois de outras\\nações. Se houvesse uma variável no esquema da ação que pudesse ser deixada ilimitada,\\ndeixaríamos.\\nNas décadas de 1980 e 1990, o planejamento de ordem parcial era visto como a melhor maneira\\nde lidar com problemas de planejamento com subproblemas independentes porque, acima de tudo,\\nera a única abordagem que representava explicitamente ramificações independentes de um plano. Por', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 464}),\n",
       " Document(page_content='outro lado, tinha a desvantagem de não ter uma representação explícita dos estados no modelo de\\ntransição de estados. Isso tornava alguns cálculos complicados. Em 2000, os planejadores de busca\\npara a frente desenvolveram excelentes heurísticas que lhes permitiam descobrir eficientemente\\nsubproblemas independentes para os quais o planejamento de ordem parcial foi projetado. Como\\nresultado, os planejadores de ordem parcial não são competitivos em problemas de planejamento\\nclássico totalmente automatizado.\\nNo entanto, o planejamento de ordem parcial continua a ser uma parte importante da área. Para\\nalgumas tarefas específicas, como operações de escalonamento, o planejamento de ordem parcial\\ncom heurística de domínio específico é a tecnologia a ser escolhida. Muitos desses sistemas utilizam\\nbibliotecas de planos de alto nível, como descrito na \\nSeção 11.2\\n. O planejamento de ordem parcial é\\ntambém frequentemente utilizado em domínios em que seja importante que os seres humanos\\ncompreendam os planos. Os planejadores de ordem parcial geram os planos operacionais para naves\\nespaciais e robôs em Marte, que são então verificados por operadores humanos antes de serem\\ncarregados nos veículos para execução. A abordagem de refinamento do plano torna mais fácil para\\nos seres humanos compreender o que os algoritmos de planejamento estão fazendo e verificar se eles\\nestão corretos.\\n10.5 ANÁLISE DAS ABORDAGENS DE PLANEJAMENTO\\nPlanejamento combina as duas principais áreas de IA que estudamos até agora: \\nbusca\\n e \\nlógica\\n.\\nUm planejador pode ser visualizado como um programa que procura por uma solução ou como um\\nprograma que demonstra (construtivamente) a existência de uma solução. O cruzamento de ideias das\\nduas áreas levou a aperfeiçoamentos de desempenho que totalizaram várias ordens de magnitude na\\núltima década e também a um uso crescente de planejadores em aplicações industriais. Infelizmente,\\nainda não temos uma compreensão clara de quais técnicas funcionam melhor em cada um dos tipos de\\nproblemas. É bem possível que venham a emergir novas técnicas que vão superar os métodos\\nexistentes.\\nPlanejamento é antes de tudo um exercício de controle da explosão combinatória. Se houver \\nn\\nproposições em um domínio, existirão 2\\nn\\n estados. Como vimos, o planejamento é PSPACE-difícil.\\nContra esse pessimismo, a identificação de subproblemas independentes pode ser uma arma\\npoderosa. No melhor caso — capacidade de decomposição integral do problema —, temos aumento\\nde desempenho exponencial. No entanto, a decomposição é destruída por interações negativas entre\\nas ações.\\nO GRAPHPLAN registra exclusões mútuas para apontar onde estão as dificuldades de interação.\\nO SATPLAN representa um conjunto semelhante de relações de excluvidade mútua, mas faz isso\\nusando a forma geral FNC, em vez de uma estrutura de dados específica. A busca para a frente\\naborda o problema heuristicamente tentando encontrar padrões (subconjuntos de proposições) que\\ncubram os subproblemas independentes. Uma vez que essa abordagem é heurística, ela pode\\nfuncionar mesmo quando os subproblemas não são completamente independentes.\\nÀs vezes é possível resolver um problema de modo eficiente reconhecendo que interações\\nnegativas podem ser eliminadas. Dizemos que um problema tem \\nsubobjetivos serializáveis\\n se existe', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 465}),\n",
       " Document(page_content='uma ordem de subobjetivos tal que o planejador pode alcançá-los nessa ordem, sem ter de desfazer\\nquaisquer dos subobjetivos alcançados anteriormente. Por exemplo, no mundo de blocos, se o\\nobjetivo é construir uma torre (por exemplo, \\nA\\n sobre \\nB\\n, que por sua vez está sobre \\nC\\n, que por sua vez\\nestá sobre a \\nMesa,\\n como na \\nFigura 10.4\\n), então os subobjetivos são serializáveis de baixo para cima:\\nse alcançarmos primeiro \\nC\\n sobre \\nMesa\\n, nunca teremos de desfazê-lo enquanto estivermos\\nalcançando os outros subobjetivos. Um planejador que utiliza a abordagem de baixo para cima pode\\nresolver qualquer problema no domínio do mundo de blocos sem retrocesso (embora nem sempre\\npossa descobrir o plano mais curto).\\nComo um exemplo mais complexo, para o planejador de Remot Agent que comandou a espaçonave\\nDeep Space One da NASA, determinou-se que as proposições envolvidas no comando de uma\\nespaçonave são serializáveis. Isso talvez não seja surpreendente porque uma espaçonave é projetada\\npor seus engenheiros para ser tão fácil quanto possível de controlar (sujeita a outras restrições).\\nTirando proveito da ordenação serializada de objetivos, o planejador do Remot Agent foi capaz de\\neliminar a maior parte da busca. Isso significa que ele foi rápido o bastante para controlar a\\nespaçonave em tempo real, algo anteriormente considerado impossível.\\nNão há dúvida de que planejadores como GRAPHPLAN, SATPLAN e FF produziram avanços no\\ncampo do planejamento, tanto por elevarem o nível de desempenho de sistemas de planejamento\\nquanto por esclarecerem as questões combinatórias e de representação envolvidas, e pelo\\ndesenvolvimento de heurísticas úteis. No entanto, questiona-se até onde essas técnicas em termos de\\ntamanho de problema. Parece provável que o progresso para problemas maiores não possa contar\\napenas com representações fatorada e proposicional, e vai exigir algum tipo de síntese de\\nrepresentações de primeira ordem e hierárquica com as heurísticas eficientes em uso atualmente.\\n10.6 RESUMO\\nNeste capítulo, definimos o problema do planejamento em ambientes determinísticos\\ncompletamente observáveis e estáticos. Descrevemos as representações PDDL usadas em problemas\\nde planejamento e diversas abordagens algorítmicas para resolvê-los. Os pontos a serem lembrados\\nsão:\\n•  Os sistemas de planejamento são algoritmos de resolução de problemas que operam sobre\\nrepresentações explícitas proposicionais (ou de primeira ordem) de estados e ações. Essas\\nrepresentações tornam possível a derivação de heurísticas efetivas e o desenvolvimento de\\nalgoritmos poderosos e flexíveis para resolução de problemas.\\n•  A PDDL, a linguagem de definição do domínio do planejamento, descreve os estados inicial e\\nobjetivo como combinações de literais, e ações em termos de suas precondições e efeitos.\\n•  A busca no espaço de estados pode operar no sentido para a frente (\\nprogressão\\n) ou no sentido\\npara trás (\\nregressão\\n). Podem ser derivadas heurísticas efetivas adotando-se uma hipótese de\\nindependência de subobjetivos e empregando-se vários relaxamentos do problema de\\nplanejamento.\\n•  Um \\ngrafo de planejamento\\n pode ser construído de forma incremental, partindo-se do estado', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 466}),\n",
       " Document(page_content='inicial. Cada camada contém um superconjunto de todos os literais ou ações que poderiam\\nocorrer nesse passo de tempo e codifica relações de exclusão mútua (\\nmutex)\\n entre literais ou\\nações que não podem ocorrer concomitantemente. Os grafos de planejamento geram heurísticas\\núteis para planejadores de espaço de estados e de ordem parcial e podem ser empregados\\ndiretamente no algoritmo GRAPHPLAN.\\n•  Outras abordagens incluem a dedução de primeira ordem sobre axiomas de cálculo de situações;\\ncodificação de um problema de planejamento como problema de satisfatibilidade booleana ou\\ncomo um problema de satisfação de restrição; e busca explícita através do espaço de planos\\nparcialmente ordenados.\\n•  Cada uma das principais abordagens de planejamento tem seus pontos fortes, e ainda não existe\\nnenhum consenso sobre qual delas é a melhor. A competição e a fertilização cruzada entre as\\nabordagens resultaram em ganhos significativos em eficiência para sistemas de planejamento.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nO planejamento da IA surgiu de investigações em busca no espaço de estados, prova de teoremas e\\nteoria de controle, e das necessidades práticas da robótica, escalonamento e de outros domínios.\\nSTRIPS (Fikes e Nilsson, 1971), o primeiro sistema de planejamento importante, ilustra a interação\\ndessas influências. STRIPS foi projetado como o componente de planejamento do software para o\\nprojeto do robô Shakey na SRI. Sua estrutura de controle global foi modelada sobre a do GPS, o\\nGeneral Problem Solver (Newell e Simon, 1961), um sistema de busca no espaço de estados que\\nutilizava a análise de meios-fins. Bylander (1992) mostra o planejamento simples de STRIPS para se\\ntornar PSPACE-completa. Fikes e Nilsson (1993) apresentam uma retrospectiva histórica sobre o\\nprojeto de STRIPS e seu relacionamento com esforços de planejamento mais recentes.\\nA linguagem de representação usada por STRIPS tem sido muito mais influente que sua abordagem\\nalgorítmica; o que chamamos de linguagem “clássica” se aproxima do que STRIPS usou. A \\nAction\\nDescription Language\\n, ou ADL (Pednault, 1986), relaxou algumas das restrições da linguagem\\nSTRIPS e tornou possível codificar problemas mais realistas. Nebel (2000) explora esquemas para\\ncompilar a ADL em STRIPS. A Problem Domain Description Language ou PDDL (Ghallab \\net al\\n.,\\n1998) foi introduzida como uma sintaxe padronizada e traduzível pelo computador para representar\\nproblemas de planejamento e tem sido usada como a linguagem-padrão da competição internacional\\nde planejamento desde 1998. Houve várias extensões; a versão mais recente, PDDL 3.0, inclui\\nrestrições de plano e preferências (Gerevini e Long, 2005).\\nOs planejadores do início da década de 1970 em geral consideravam sequências de ações\\ntotalmente ordenadas. A decomposição de problemas foi realizada pela computação de um subplano\\npara cada subobjetivo e depois pelo encadeamento dos subplanos em alguma ordem. Essa\\nabordagem, chamada \\nplanejamento linear\\n por Sacerdoti (1975), logo se mostrou incompleta. Ela\\nnão é capaz de resolver alguns problemas muito simples, como a anomalia de Sussman (veja o\\nExercício 10.7), encontrada por Allen Brown durante a experimentação com o sistema HACKER\\n(Sussman, 1975). Um planejador completo deve permitir a \\nintercalação\\n de ações de diferentes\\nsubplanos dentro de uma única sequência. A noção de subobjetivos serializáveis (Korf, 1987)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 467}),\n",
       " Document(page_content='corresponde exatamente ao conjunto de problemas para os quais os planejadores não intercalados\\nsão completos.\\nUma solução para o problema de intercalação foi o planejamento por regressão de objetivo, uma\\ntécnica em que os passos de um plano totalmente ordenado são reordenados para evitar conflitos\\nentre subobjetivos. Essa técnica foi introduzida por Waldinger (1975) e também foi usada pelo\\nWARPLAN de Warren (1974). O WARPLAN também é notável pelo fato de ter sido o primeiro\\nplanejador escrito em uma linguagem de programação lógica (Prolog) e é um dos melhores exemplos\\nda notável economia que às vezes se pode obter pelo uso da programação de lógica: o WARPLAN\\ntem apenas 100 linhas de código, uma pequena fração do tamanho de planejadores comparáveis da\\népoca.\\nAs ideias subjacentes ao planejamento de ordem parcial incluem a detecção de conflitos (Tate,\\n1975a) e a proteção de condições alcançadas de interferências (Sussman, 1975). A construção de\\nplanos parcialmente ordenados (chamados de \\nredes de tarefas\\n) teve como pioneiros o planejador\\nNOAH (Sacerdoti, 1975, 1977) e o sistema NONLIN de Tate (1975b, 1977).\\nO planejamento de ordem parcial dominou os 20 anos de pesquisa seguintes, mas a primeira\\nproposta formal clara foi o TWEAK (Chapman, 1987), um planejador que era simples o suficiente\\npara permitir provas de completeza e intratabilidade (NP-dificuldade e irresolubilidade) de várias\\nformulações do problema de planejamento. O trabalho de Chapman levou a uma descrição simples\\nde um planejador de ordem parcial completo (McAllester e Rosenblitt, 1991), em seguida para as\\nimplementações amplamente distribuídas SNLP (Soderland e Weld, 1991) e UCPOP (Penberthy e\\nWeld, 1992). O planejamento de ordem parcial caiu em desuso na década de 1990 à medida que\\nsurgiram métodos mais rápidos. Nguyen e Kambhampati (2001) sugerem que uma reconsideração é\\nmerecida: com heurísticas exatas derivadas de um grafo de planejamento, seu planejador REPOP\\nescala muito melhor que o GRAPHPLAN em domínios paralelizáveis e é competitivo com os mais\\nrápidos planejadores em espaço de estados.\\nO ressurgimento do interesse no planejamento nos espaços de estados teve como pioneiro o\\nprograma UNPOP de Drew McDermott (1996), que foi o primeiro a sugerir uma heurística de\\nignorar as listas de exclusão. O nome UNPOP foi uma reação à concentração exagerada no\\nplanejamento de ordem parcial existente na época; McDermott suspeitava que outras abordagens não\\nestavam obtendo a atenção que mereciam. O \\nHeuristic Search Planner\\n (HSP) de Bonet e Geffner e\\nseus derivados posteriores (Bonet e Geffner, 1999; Haslum \\net al\\n., 2005; Haslum, 2006) foram os\\nprimeiros a tornar prática a busca em espaços de estados para grandes problemas de planejamento.\\nHSP busca na direção para a frente, enquanto HSPR busca para trás (Bonet e Geffner, 1999). O mais\\nbem-sucedido buscador em espaço de estados até hoje é o FF (Hoffmann, 2001; Hoffmann e Nebel,\\n2001; Hoffmann, 2005), vencedor da competição de planejamento AIPS 2000. O\\nFASTDOWNWARD (Helmert, 2006) é um planejador de busca em espaço de estados para a frente\\nque pré-processa os esquemas de ação em uma representação alternativa que torna algumas das\\nrestrições mais explícitas. O FASTDOWNWARD (Helmert e Richter, 2004; Helmert, 2006) ganhou\\na competição de planejamento de 2004, e o LAMA (Richter e Westphal, 2008), um planejador\\nbaseado em FASTDOWNWARD com heurísticas melhoradas, ganhou a competição de 2008.\\nBylander (1994) e Ghallab \\net al\\n. (2004) discutem a complexidade computacional de diversas\\nvariantes do problema de planejamento. Helmert (2003) prova os limites de complexidade para', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 468}),\n",
       " Document(page_content='muitos dos problemas \\nbenchmark\\n e Hoffmann (2005) analisa o espaço de busca da heurística de\\nignorar as listas de exclusão. Heurísticas para o problema de cobertura de conjuntos para operações\\nde agendamento da ferrovia italiana são discutidas por Caprara \\net al.\\n (1995). Edelkamp (2009) e\\nHaslum \\net al.\\n (2007) descreveram como construir bases de dados-padrão para heurísticas de\\nplanejamento. Como mencionado no Capítulo 3, Felner \\net al.\\n (2004) mostraram resultados\\nencorajadores utilizando bases de dados-padrão para quebra-cabeças de blocos deslizantes, que\\npode ser tido como domínio de planejamento, mas Hoffmann \\net al.\\n (2006) mostraram algumas\\nlimitações de abstração para os problemas de planejamento clássico.\\nAvrim Blum e Merrick Furst (1995, 1997) revitalizaram a área de planejamento com seu sistema\\nGRAPHPLAN, ordens de grandeza mais rápido do que os planejadores de ordem parcial da época.\\nLogo seguiram outros sistemas de grafo de planejamento, como o IPP (Koehler \\net al\\n., 1997), STAN\\n(Fox e Long, 1998), e o SGP (Weld \\net al.\\n, 1998). Um pouco antes, uma estrutura de dados se\\nassemelhando ao grafo de planejamento foi desenvolvida por Ghallab e Laruelle (1994), usada pelo\\nplanejador de ordem parcial IXTET para derivar heurísticas precisas para orientar a busca. Nguyen\\net al.\\n (2001) analisam cuidadosamente as heurísticas derivadas de grafos de planejamento. Nossa\\ndiscussão sobre grafos de planejamento se baseia, em parte, nesse trabalho e em notas de aula e\\nartigos de Subbarao Kambhampati (Bryce e Kambhampati, 2007). Como mencionado no capítulo, um\\ngrafo de planejamento pode ser usado de maneiras muito diferentes para orientar a busca por uma\\nsolução. O vencedor da competição de planejamento AIPS 2002, LGP (Gerevini e Serina, 2002,\\n2003), faz busca nos grafos de planejamento utilizando uma técnica de busca local inspirada no\\nWALKSAT.\\nA abordagem do cálculo de situações para o planejamento foi introduzida por John McCarthy\\n(1963). A versão mostrada aqui foi proposta por Ray Reiter (1991, 2001).\\nKautz \\net al.\\n (1996) pesquisaram várias maneiras de proposicionalizar esquemas de ação,\\nverificando que as formas mais compactas nem sempre conduzem à solução mais rápida. Uma análise\\nsistemática foi realizada por Ernst \\net al\\n. (1997), que também desenvolveram um “compilador”\\nautomático para gerar representações proposicionais a partir de problemas PDDL. O planejador\\nBLACKBOX, que combina ideias de GRAPHPLAN e SATPLAN, foi desenvolvido por Kautz e\\nSelman (1998). O CPLAN, um planejador baseado em satisfação de restrições, foi descrito por Van\\nBeek e Chen (1999).\\nMais recentemente, surgiu o interesse na representação de planos como \\ndiagrama de decisão\\nbinária\\n, estruturas de dados compactas de expressões booleanas, intensamente estudada na\\ncomunidade de verificação de hardware (Clarke e Grumberg, 1987; McMillan, 1993). Existem\\ntécnicas para demonstrar propriedades de diagramas de decisão binária, inclusive a propriedade de\\nser uma solução para um problema de planejamento. Cimatti \\net al\\n. (1998) apresentam um planejador\\nbaseado nessa abordagem. Outras representações também foram usadas; por exemplo, Vossen \\net al\\n.\\n(2001) pesquisam o uso da programação inteira para planejamento.\\nA decisão final ainda não foi tomada, mas já existem algumas comparações interessantes entre as\\ndiversas abordagens para planejamento. Helmert (2001) analisa várias classes de problemas de\\nplanejamento e mostra que as abordagens baseadas em restrições, como GRAPHPLAN e SATPLAN,\\nsão melhores para domínios NP-difíceis, enquanto abordagens baseadas em busca funcionam melhor\\nem domínios nos quais podem ser encontradas soluções possíveis sem retrocesso. O GRAPHPLAN e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 469}),\n",
       " Document(page_content='o SATPLAN têm dificuldades em domínios com muitos objetos porque isso significa que eles têm de\\ncriar muitas ações. Em alguns casos, o problema pode ser retardado ou evitado gerando-se\\ndinamicamente as ações proposicionalizadas, apenas quando necessário, em vez de instanciar todas\\nelas antes do início da busca.\\nReadings in Planning\\n (Allen \\net al\\n., 1990) é uma antologia abrangente dos primeiros trabalhos\\nnesse campo. Weld (1994, 1999) fornece duas excelentes revisões de algoritmos de planejamento\\ndos anos 90. É interessante observar a mudança nos cinco anos entre as duas revisões: a primeira se\\nconcentra no planejamento de ordem parcial, enquanto a segunda introduz o GRAPHPLAN e o\\nSATPLAN. \\nAutomated Planning\\n (Ghallab \\net al\\n., 2004) é um livro excelente sobre todos os aspectos\\ndo planejamento. O livro de LaValle, \\nAlgoritmos de planejamento\\n (2006) abrange tanto o\\nplanejamento clássico como o estocástico, com ampla cobertura do planejamento do movimento de\\nrobô.\\nA pesquisa em planejamento foi central para a IA desde sua concepção, e os artigos sobre\\nplanejamento são frequentes nos principais periódicos e em conferências sobre IA. Também existem\\nconferências especializadas, como a \\nInternational Conference on AI Planning Systems\\n (AIPS), o\\nInternational Workshop on Planning and Scheduling for Space\\n, e a \\nEuropean Conference on\\nPlanning\\n (ECP). A partir de 2003, a \\nInternational Conference on Automated Planning and\\nScheduling\\n (ICAPS) uniu as duas conferências AIPS e ECP.\\nEXERCÍCIOS\\n10.1\\n Descreva as diferenças e as semelhanças entre a resolução de problemas e o planejamento.\\n10.2\\n Dados os esquemas de ação e o estado inicial da \\nFigura 10.1\\n, quais são todas as instâncias\\nconcretas aplicáveis de \\nVoar\\n(\\np\\n, \\nde\\n, \\npara\\n) no estado descrito por:\\nEm\\n(\\nP\\n1\\n, \\nJFK\\n) \\n∧\\n \\nEm\\n(\\nP\\n2\\n, \\nSFO\\n) \\n∧\\n \\nAvião\\n(\\nP\\n1\\n) \\n∧\\n \\nAvião\\n(\\nP\\n2\\n)\\n∧\\n \\nAeroporto\\n(\\nJFK\\n) \\n∧\\n \\nAeroporto\\n(\\nSFO\\n)?\\n10.3\\n O problema do macaco e das bananas é enfrentado por um macaco em um laboratório com\\nalgumas bananas penduradas no teto, fora do alcance. Há uma caixa disponível que permitirá ao\\nmacaco alcançar as bananas se ele subir nela. Inicialmente, o macaco está em \\nA\\n, as bananas em \\nB\\n e a\\ncaixa em \\nC\\n. O macaco e a caixa têm a altura \\nBaixa\\n, mas, se subir na caixa, o macaco terá a altura\\nAlta\\n, a mesma altura das bananas. As ações disponíveis para o macaco incluem \\nIr\\n de um lugar para\\noutro, \\nEmpurrar\\n um objeto de um lugar para outro, \\nSubir\\n em um objeto ou \\nDescer\\n de um objeto, e\\nainda \\nPegar\\n ou \\nSoltar\\n um objeto. O resultado de \\nAgarrar\\n é que o macaco segura o objeto, se o\\nmacaco e o objeto estiverem no mesmo lugar e na mesma altura.\\na.\\n Escreva a descrição do estado inicial.\\nb.\\n Escreva os seis esquemas de ação.\\nc.\\n Suponha que o macaco queira enganar os cientistas que saíram para tomar chá, pegando as\\nbananas, mas deixando a caixa em seu lugar original. Escreva isso como um objetivo geral (ou', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 470}),\n",
       " Document(page_content='seja, não considerando que a caixa esteja necessariamente em \\nC\\n) na linguagem do cálculo de\\nsituações. Esse objetivo pode ser resolvido por um sistema de planejamento clássico?\\nd.\\n Seu esquema para empurrar provavelmente está incorreto porque, se o objeto for pesado\\ndemais, sua posição permanecerá a mesma quando o operador \\nEmpurrar\\n for aplicado. Corrija\\nseu esquema de ação para levar em conta objetos pesados.\\n10.4\\n O planejador STRIPS original foi projetado para controlar o robô Shakey. A \\nFigura 10.14\\nmostra uma versão do mundo de Shakey que consiste em quatro salas dispostas ao longo de um\\ncorredor, onde cada sala tem uma porta e um interruptor de luz. As ações no mundo de Shakey\\nincluem movimentar-se de um lugar para outro, empurrar objetos móveis (como caixas), subir e\\ndescer de objetos rígidos (como caixas) e ligar e desligar interruptores. O robô propriamente dito\\nnão poderia subir em uma caixa ou acionar um interruptor, mas o planejador STRIPS era capaz de\\ndescobrir e imprimir planos que estavam além das habilidades do robô. As seis ações de Shakey são\\nas seguintes:\\n•  \\nIr\\n(\\nx\\n, \\ny, r\\n), que exige que Shakey esteja \\nem\\n \\nx\\n e que \\nx\\n e \\ny\\n sejam posições \\nna\\n mesma sala \\nr\\n. Por\\nconvenção, uma porta entre duas salas está em ambas as salas.\\n•  Empurrar uma caixa \\nb\\n da posição \\nx\\n para a posição \\ny\\n dentro da mesma sala: \\nEmpurrar\\n(\\nb\\n, \\nx\\n, \\ny, r\\n).\\nPrecisaremos do predicado \\nCaixa\\n e de constantes para as caixas.\\n•  Subir em uma caixa de posição \\nx\\n: \\nSubir\\n(\\nx\\n, \\nb\\n); descer de uma caixa para a posição \\nx\\n: \\nDescer\\n(\\nb\\n,\\nx\\n). Precisaremos do predicado \\nSobre\\n e da constante \\nChão\\n.\\n•  Ligar ou desligar um interruptor: \\nLigar\\n(\\ns\\n, \\nb\\n); \\nDesligar\\n(\\ns\\n, \\nb\\n). Para ligar ou desligar um\\ninterruptor de luz, Shakey tem de estar em cima de uma caixa na posição do interruptor de luz.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 471}),\n",
       " Document(page_content='Figura 10.14\\n O mundo de Shakey. O robô Shakey pode se mover entre marcos dentro de uma sala,\\npode passar pela porta entre as salas, pode subir e descer de objetos que permitam essa ação e\\nempurrar objetos que possam ser empurrados, e ainda pode ligar e desligar interruptores de luz.\\nDescreva PDDL sentenças para as seis ações de Shakey e o estado inicial da \\nFigura 10.14\\n. Construa\\num plano para Shakey colocar \\nCaixa\\n2\\n na \\nSala\\n2\\n.\\n10.5\\n Uma máquina de Turing finita tem uma fita de células finita unidimensional, cada célula que\\ncontém um símbolo de um número finito de símbolos. Uma célula tem uma cabeça de leitura e escrita\\nsobre ela. Há um conjunto de estados finito onde a máquina pode estar, um dos quais é o estado de\\naceitação. Em cada passo, dependendo do símbolo na célula sob a cabeça e o estado atual da\\nmáquina, existe um conjunto de ações que podemos escolher. Cada ação envolve escrever um\\nsímbolo na célula sob a cabeça, fazendo a transição da máquina para um estado e opcionalmente o\\nmovimento da cabeça para a esquerda ou para a direita. O mapeamento que determina que ações são\\npermitidas é o programa da máquina de Turing. O objetivo é o controle da máquina no estado de\\naceitação.\\nRepresente o problema de aceitação da máquina de Turing como um problema de planejamento. Se\\nisso pode ser feito, demonstre que determinar se um problema de planejamento tem uma solução é', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 472}),\n",
       " Document(page_content='pelo menos tão difícil como o problema de aceitação de Turing que é PSPACE-difícil.\\n10.6\\n Explique por que descartar efeitos negativos de todo esquema de ação em um problema de\\nplanejamento resulta em um problema relaxado.\\n10.7\\n A \\nFigura 10.4\\n mostra um problema de mundo de blocos conhecido como \\nanomalia de Sussman\\n.\\nO problema foi considerado anômalo porque os planejadores sem intercalações do início da década\\nde 1970 não conseguiram resolvê-lo. Escreva uma definição do problema e resolva-o, manualmente\\nou com um programa de planejamento. Um planejador sem intercalações é um planejador que, ao\\nreceber dois subobjetivos \\nG\\n1\\n e \\nG\\n2\\n, produz um plano para o \\nG\\n1\\n concatenado com um plano para \\nG\\n2\\n ou\\nvice-versa. Explique por que um planejador sem intercalações não consegue resolver esse problema.\\n10.8\\n Prove que a busca para trás é completa com problemas PDDL.\\n10.9\\n Construa níveis 0, 1 e 2 do grafo de planejamento para o problema da \\nFigura 10.1\\n.\\n10.10\\n Prove as asserções a seguir sobre grafos de planejamento:\\na.\\n Um literal que não aparece no último nível do grafo não pode ser alcançado.\\nb.\\n O custo de nível de um literal em um grafo serial não é maior que o custo real de um plano\\nótimo para alcançá-lo.\\n10.11\\n A heurística de nível de conjunto (consulte a \\nSeção 10.3.1\\n) utiliza um grafo de planejamento\\npara estimar o custo de atingir o objetivo conjuntivo a partir do estado corrente. Para qual problema\\nrelaxado a heurística de nível de conjunto é uma solução?\\n10.12\\n Examine a definição de \\nbusca bidirecional\\n no Capítulo 3.\\na.\\n A busca do espaço de estados bidirecional é uma boa ideia para o planejamento?\\nb.\\n E sobre o emprego da busca no espaço de estados bidirecional para planejamento de ordem\\nparcial?\\nc.\\n Imagine uma versão de planejamento de ordem parcial no qual uma ação pode ser acrescentada\\na um plano se suas pré-condições puderem ser atingidas pelo efeito das ações que já estiverem\\nno plano. Explique como lidar com conflitos e ordenação de restrições. O algoritmo é\\nessencialmente idêntico à busca para frente em espaço de estados?\\n10.13\\n Comparamos planejadores de busca para a frente e para trás no espaço de estados a\\nplanejadores de ordem parcial, afirmando que um planejador de ordem parcial é um buscador no\\nespaço de planos. Explique o quanto a busca para a frente e a busca para trás no espaço de estados\\ntambém podem ser consideradas buscadores no espaço de planos e informe quais são os operadores\\nde aprimoramento do plano.\\n10.14\\n Até aqui, supomos que os planos que criamos sempre se certificam de que as precondições de\\numa ação sejam satisfeitas. Vamos agora investigar o que os axiomas proposicionais de estado-\\nsucessor tal como \\nTerSeta\\nt +1\\n \\n⇔\\n (\\nTerSeta\\nt\\n∧\\n \\n¬Atirar\\nt\\n) têm a dizer sobre ações cujas precondições\\nnão forem satisfeitas.\\na.\\n Mostre que os axiomas preveem que nada acontecerá quando uma ação for executada em um\\nestado em que suas precondições não sejam satisfeitas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 473}),\n",
       " Document(page_content='b.\\n Considere um plano \\np\\n que contenha as ações exigidas para alcançar um objetivo, mas também\\ninclua ações inválidas. É possível ocorrer o caso em que\\nestado inicial \\n∧\\n axiomas de estados sucessores \\n∧\\n p |= objetivo ?\\nc.\\n Com axiomas de estados sucessores de primeira ordem no cálculo de situações, é possível\\nprovar que um plano que contenha ações inválidas alcançará o objetivo?\\n10.15\\n Considere como converter um conjunto de esquemas de ações nos axiomas de estado-sucessor\\ndo cálculo de situações.\\na.\\n Considere o esquema para \\nVoar\\n(\\np\\n, \\nde\\n, \\npara\\n). Escreva uma definição lógica para o predicado\\nPossível\\n(\\nVoar\\n(\\np\\n, \\nde\\n, \\npara\\n), \\ns\\n), que é verdadeiro se as precondições para \\nVoar\\n(\\np\\n, \\nde\\n, \\npara\\n)\\nforem satisfeitas na situação \\ns\\n.\\nb.\\n Em seguida, supondo que \\nVoar\\n(\\np\\n, \\nde\\n, \\npara\\n) seja o único esquema de ação disponível para o\\nagente, escreva um axioma de estado-sucessor para \\nEm\\n(\\np\\n, \\nx\\n, \\ns\\n) que capte as mesmas\\ninformações que o esquema de ação.\\nc.\\n Agora, suponha que exista um método adicional de viagem: \\nTeleportar\\n(\\np\\n, \\nde\\n, \\npara\\n). Ele tem a\\nprecondição adicional ¬\\nDanificado\\n(\\np\\n) e o efeito adicional \\nDanificado\\n(\\np\\n). Explique como a\\nbase de conhecimento do cálculo de situações deve ser modificada.\\nd.\\n Por fim, desenvolva um procedimento geral e especificado com precisão para executar a\\nconversão de um conjunto de esquemas STRIPS em um conjunto de axiomas de estado-sucessor.\\n10.16\\n No algoritmo SATPLAN da \\nFigura 7.22\\n, cada chamada ao algoritmo de satisfatibilidade\\nconfirma um objetivo \\ng\\nT\\n, onde \\nT\\n varia de 0 a \\nT\\nmax\\n. Suponha que, em vez disso, o algoritmo de\\nsatisfatibilidade seja chamado apenas uma vez, com o objetivo \\ng\\n0\\n \\n∨\\n \\ng\\n1\\n \\n∨\\n … \\n∨\\n \\ng\\nTmax\\n.\\na.\\n Isso sempre devolverá um plano se existir algum com tamanho menor ou igual a \\nT\\nmax\\n?\\nb.\\n Essa abordagem introduz alguma nova “solução” espúria?\\nc.\\n Discuta como se poderia modificar um algoritmo de satisfatibilidade como WALKSAT, de\\nforma que ele encontre soluções curtas (se elas existirem) ao receber um objetivo disjuntivo\\ncom essa forma.\\n1\\n PDDL foi derivada da linguagem de planejamento original STRIPS (Fikes e Nilsson, 1971), ligeiramente mais restrita que a PDDL: as\\nprecondições e os objetivos do STRIPS não podem conter literais negativos.\\n2\\n O mundo dos blocos utilizado em pesquisa de planejamento é muito mais simples do que a versão SHRDLU, mostrada no capítulo 1.\\n3\\n Muitos problemas são escritos com essa convenção. Para os que não são, substituir todo o literal negativo ¬\\nP\\n em um objetivo ou\\nprecondição com um novo literal positivo \\nP\\n′.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 474}),\n",
       " Document(page_content='O\\nCAPÍTULO\\n \\n11\\nPlanejamento e ação no mundo real\\nEm que vemos como representações mais expressivas e arquiteturas de agentes\\nmais interativas resultam em planejadores que são úteis no mundo real.\\ncapítulo anterior introduziu os conceitos mais básicos, representações e algoritmos para\\nplanejamento. Os planejadores empregados no mundo real para planejar e escalonar as\\noperações de espaçonaves, fábricas e campanhas militares são mais complexos; eles estendem a\\nlinguagem de representação e também o modo como o planejador interage com o ambiente. Este\\ncapítulo mostra como isso é feito. A \\nSeção 11.1\\n estende a linguagem clássica para o planejamento\\npara expressar ações com duração e restrição de recursos. A \\nSeção 11.2\\n descreve métodos para a\\nconstrução de planos organizados hierarquicamente. Isso permite que os especialistas humanos\\ncomuniquem ao planejador o que sabem sobre como resolver o problema. A hierarquia também se\\npresta à construção eficiente do plano porque o planejador pode resolver um problema em nível\\nabstrato, antes de se aprofundar em detalhes. A \\nSeção 11.3\\n apresenta arquiteturas de agente que\\npodem lidar com ambientes incertos e intercalar deliberação com execução, e dá alguns exemplos de\\nsistemas do mundo real. A \\nSeção 11.4\\n mostra como planejar quando o ambiente contém outros\\nagentes.\\n11.1 TEMPO, ESCALONAMENTOS E RECURSOS\\nA representação do planejamento clássico informa \\no que fazer\\n e \\nem que ordem\\n, mas a\\nrepresentação não pode informar sobre o tempo: \\nquanto tempo\\n uma ação leva e \\nquando\\n ela ocorre.\\nPor exemplo, os planejadores do Capítulo 10 podem produzir um cronograma para uma companhia\\naérea que informa quais aviões estão designados a quais voos, mas também precisamos saber\\nrealmente os horários de partida e de chegada. Esse é o tema do \\nescalonamento\\n. O mundo real\\ntambém impõe muitas \\nrestrições de recursos\\n; por exemplo, uma companhia aérea tem número\\nlimitado de pessoal — e o pessoal designado para um voo não pode estar em outro ao mesmo tempo.\\nEsta seção aborda os métodos para representar e resolver problemas de planejamento que incluem\\nrestrições temporais e de recursos.\\nA abordagem que adotamos nesta seção é “planejar primeiro, escalonar mais tarde”, isto é,\\ndividimos o problema global em uma fase de \\nplanejamento\\n, em que as ações são selecionadas com', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 476}),\n",
       " Document(page_content='algumas restrições de ordem para satisfazer aos objetivos do problema, e em uma fase de\\nescalonamento\\n posterior, na qual informações temporais são adicionadas ao plano, a fim de\\nassegurar que ele atenderá às restrições de recursos e de prazos.\\n        \\nProcessos\\n({\\nAdicionarMotor1\\n \\x00 \\nAdicionarRodas1\\n \\x00 \\nInspecionar1\\n},\\n            {\\nAdcionarMotor2\\n \\x00 \\nAdicionarRodas2\\n \\x00 \\nInspecionar2\\n})\\n        \\nRecursos\\n(\\nGuinchoParaMotor\\n(1), \\nEstaçãodeRodas\\n(1), \\nInspetores\\n(2), \\nPorcasDeRoda\\n(500))\\n        \\nAção\\n(\\nAdicionarMotor1\\n, DURAÇÃO:30,\\n            USO: \\nGuinchoParaMotor\\n(1))\\n        \\nAção\\n(\\nAdicionarMotor2\\n, DURAÇÃO:60,\\n            USO: \\nGuinchoParaMotor\\n(1))\\n        \\nAção\\n (\\nAdicionarMotor1\\n, DURAÇÃO:30,\\n            CONSUMO: \\nPorcasDeRoda\\n(20), USO: \\nEstaçãodeRodas\\n(1))\\n        \\nAção\\n(\\nAdicionarMotor2\\n, DURAÇÃO:15,\\n            CONSUMO: \\nPorcasDeRoda\\n(20), USO: \\nEstaçãodeRodas\\n(1))\\n        \\nAção\\n (\\nInspecionar\\ni\\n, DURAÇÃO:10,\\n            USO: \\nInspetores\\n(1))\\nFigura 11.1\\n Um problema de escalonamento de linha de produção para montar dois carros, com\\nrestrições de recursos. A notação A \\n B significa que a ação \\nA\\n deve preceder a ação \\nB\\n.\\nEssa abordagem é comum em configurações do mundo real de manufatura e logística, em que a\\nfase de planejamento é realizada frequentemente por especialistas humanos. Os métodos\\nautomatizados do Capítulo 10 também podem ser utilizados para a fase de planejamento, desde que\\neles produzam planos apenas com o mínimo de ordenação de restrições necessárias para correção. O\\nGRAPHPLAN (\\nSeção 10.3\\n), o SATPLAN (\\nSeção 10.4.1\\n) e os planejadores de ordem parcial (\\nSeção\\n10.4.4\\n) podem fazer isso; os métodos baseados em busca (\\nSeção 10.2\\n) produzem planos totalmente\\nordenados, mas podem ser facilmente convertidos em planos com restrições de ordenação minimais.\\n11.1.1 Representando restrições temporais e de recursos\\nUm \\nproblema\\n típico de \\nescalonamento de linha de produção\\n, como introduzido pela primeira vez\\nna \\nSeção 6.1.2\\n, consiste em um conjunto de processos (jobs), cada um dos quais é composto por um\\nconjunto de \\nações\\n com restrições de ordenação entre elas. Cada ação tem uma \\nduração\\n e um\\nconjunto de restrições de recursos exigidos pela ação. Cada restrição especifica um \\ntipo\\n de recurso\\n(por exemplo, parafusos, chaves de porcas ou pilotos), a quantidade necessária desse recurso e se\\nesse recurso é \\nconsumível\\n (por exemplo, os parafusos não estão mais disponíveis para uso) ou\\nreutilizável \\n(por exemplo, um piloto está ocupado durante um voo, mas ficará disponível quando o\\nvoo terminar). Os recursos também podem ser \\nproduzidos\\n por ações com consumo negativo,\\nincluindo ações de manufatura, crescimento e reabastecimento. Uma solução para um problema de\\nescalonamento de linha de produção deve especificar os horários de início de cada ação e deve\\nsatisfazer todas as restrições de ordenação temporal e as restrições de recursos. Tal como acontece', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 477}),\n",
       " Document(page_content='com problemas de busca e planejamento, soluções podem ser avaliadas de acordo com uma função\\nde custo, o que pode ser bastante complicado, com custos de recursos não lineares, custos\\ndependentes do tempo de atraso, e assim por diante. Para simplificar, assumiremos que a função\\ncusto é a duração total do plano, que é chamado de \\nmakespan.\\nA \\nFigura 11.1\\n mostra um exemplo simples: um problema que envolve a montagem de dois carros.\\nO problema consiste em dois processos, cada um da forma [\\nAdicionarMotor\\n, \\nAdicionarRodas\\n,\\nInspecionar\\n]. Em seguida, a instrução \\nRecursos\\n declara que existem quatro tipos de recursos e dá a\\nquantidade de cada tipo disponível no início: 1 guincho para levantar o motor, 1 estação de rodas, 2\\ninspetores e 500 porcas de roda. Os esquemas de ação fornecem a duração e os recursos necessários\\npara cada ação. As porcas de roda são \\nconsumidas\\n à medida que as rodas são adicionadas ao carro,\\nenquanto os outros recursos são “emprestados” no início de uma ação e liberados no final da ação.\\nA representação de recursos como quantidades numéricas, como \\nInspetores\\n(2), em lugar de\\nentidades no\\u200bmeadas, como \\nInspetor\\n(\\nI\\n1\\n) e \\nInspetor\\n(\\nI\\n2\\n), é um exemplo de técnica muito geral chamada\\nde \\nagregação\\n. A ideia central da agregação é agrupar objetos individuais em quantidade quando os\\nobjetos são todos indistinguíveis no que se refere ao propósito em questão. Em nosso problema de\\nmontagem, não importa \\nqual\\n inspetor inspeciona o carro, e portanto não há necessidade de fazer a\\ndistinção (a mesma ideia funciona no caso do problema dos missionários e canibais do Exercício\\n3.9). A agregação é essencial para reduzir a complexidade. Considere o que acontece quando é\\nproposto um escalonamento que tem 10 ações \\nInspecionar\\n concorrentes, mas há apenas nove\\ninspetores disponíveis. Com os inspetores representados como quantidades, uma falha é detectada de\\nimediato e o algoritmo realiza o retrocesso para tentar outro escalonamento. Com os inspetores\\nrepresentados como indivíduos, o algoritmo efetua o retrocesso para experimentar todas as 10\\nmaneiras de atribuir inspetores para ações.\\n11.1.2 Solução de problemas de escalonamento\\nComeçaremos considerando apenas o problema de escalonamento temporal, ignorando as\\nrestrições de recursos. Para minimizar o makespan (duração do plano), deveremos encontrar os\\ntempos de início de todas as ações consistentes com as restrições de ordem fornecidas com o\\nproblema. É útil visualizar essas restrições de ordem como um grafo direcionado relativo às ações,\\ncomo mostrado na \\nFigura 11.2\\n. Podemos aplicar o \\nmétodo do caminho critico\\n (CPM — \\ncritical\\npath method\\n) para esse grafo, para determinar o tempo inicial e final possível de cada ação. Um\\ncaminho\\n através de um grafo que representa um plano de ordem parcial é uma sequência de ações\\nlinearmente ordenadas começando em \\nInício\\n e terminado em \\nTérmino\\n (por exemplo, existem dois\\ncaminhos no plano de ordem parcial na \\nFigura 11.2\\n).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 478}),\n",
       " Document(page_content='Figura 11.2\\n Parte superior: uma representação das restrições temporais para o escalonamento do\\nproblema da linha de produção \\nFigura 11.1\\n. A duração de cada ação é dada na parte inferior de cada\\nretângulo. Na solução do problema, calculamos o tempos de início mais cedo e mais tardio como o\\npar [\\nES\\n, \\nLS\\n], exibido no canto superior esquerdo. A diferença entre esses dois números é a \\nfolga de\\ntempo\\n de uma ação; as ações com zero de folga estão no caminho crítico, como indica as setas em\\nnegrito. Parte inferior: a mesma solução mostrada na linha do tempo. Os retângulos cinza representam\\nos intervalos de tempo durante os quais uma ação pode ser executada, desde que as restrições de\\nordem sejam respeitadas. A parte desocupada de um retângulo cinza indica uma folga de tempo.\\nO \\ncaminho crítico\\n é aquele cuja duração total é a mais longa; o caminho é “crítico” porque\\ndetermina a duração de todo o plano — encurtar outros caminhos não encurta o plano como um todo,\\nmas o adiamento do início de qualquer ação no caminho crítico retarda o plano todo. As ações que\\nestão fora do caminho crítico têm uma janela de tempo em que podem ser executadas. A janela é\\nespecificada em termos da hora de início mais cedo possível, \\nES\\n (earliest start), e da mais tardia\\npossível, \\nLS\\n (latest start). O intervalo entre \\nES\\n e \\nLS\\n é conhecido como \\nfolga\\n de uma ação. Podemos\\nvisualizar na \\nFigura 11.2\\n que todo o plano vai levar 85 minutos, que cada ação no processo superior\\ntem 15 minutos de folga e que cada ação no caminho crítico não tem folga (por definição). Juntos, o\\nES\\n e o \\nLS\\n determinam o tempo para todas as ações, constituindo o \\nescalonamento\\n (plano com\\nindicação de tempos e recursos) para o problema.\\nAs fórmulas a seguir servem como uma definição para \\nES\\n e \\nLS\\n, e também como o esboço de um\\nalgoritmo de programação dinâmica para calculá-los. \\nA\\n e \\nB\\n são ações, e \\nA\\n \\n \\nB\\n significa que \\nA\\n vem\\nantes de \\nB\\n:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 479}),\n",
       " Document(page_content='A ideia é que comecemos atribuindo \\nES\\n(Início) como 0. Então, logo que obtivermos a ação \\nB\\n tal\\nque todas as ações que vêm imediatamente antes de \\nB\\n tenham valores \\nES\\n atribuídos, estabeleceremos\\nES\\n(\\nB\\n) como o máximo entre os tempos mais cedo de término das ações imediatamente anteriores, em\\nque o tempo de término mais cedo de uma ação é definido como o tempo de início mais cedo, mais a\\nduração. Esse processo é repetido até que tenha sido atribuído um valor \\nES\\n a cada ação. Os valores\\nLS\\n são calculados de maneira semelhante, retrocedendo a partir da ação de \\nTérmino.\\nA complexidade do algoritmo de caminho crítico é apenas \\nO\\n(\\nNb\\n), onde \\nN\\n é o número de ações e \\nb\\né o fator máximo de ramificação entrando ou saindo de uma ação (para observar isso, note que os\\ncálculos de \\nLS\\n e \\nES\\n são efetuados uma vez para cada ação e cada cálculo itera, no máximo, \\nb\\n outras\\nações). Portanto, é bem fácil encontrar um escalonamento de mínima duração, dado um ordenamento\\nparcial das ações e sem restrições de recursos.\\nMatematicamente falando, problemas de caminho crítico são fáceis de resolver porque são\\ndefinidos como uma \\nconjunção\\n de inequações sobre os tempos de início e término. Quando\\nintroduzimos restrições de recursos, as restrições resultantes nos tempos de início e fim se tornam\\nmais complicadas. Por exemplo, as ações \\nAdicionarMotor\\n, que começam ao mesmo tempo na \\nFigura\\n11.2\\n, exigem a mesma \\nGruaParaMotor\\n e, assim, não podem se sobrepor. A restrição “não podem se\\nsobrepor” é uma \\ndisjunção\\n de duas inequações lineares, uma para cada ordenação possível. A\\nintrodução de disjunções acaba por tornar o escalonamento com restrições de recursos NP-difícil.\\nA \\nFigura 11.3\\n mostra a solução com o menor tempo de conclusão, 115 minutos, isto é, 30 minutos\\nmais do que os 85 minutos necessários para um escalonamento sem restrições de recursos. Observe\\nque nenhuma vez é necessário os dois inspetores; assim podemos mover um de nossos dois\\ninspetores imediatamente para uma posição mais produtiva.\\nFigura 11.3\\n Uma solução para o problema de escalonamento de linha de produção da \\nFigura 11.1\\n,\\nlevando em conta a restrição de recursos. A margem à esquerda lista os três recursos reutilizáveis, e\\nas ações são mostradas alinhadas horizontalmente com os recursos que elas utilizam. Há dois\\nescalonamentos possíveis, dependendo de qual montagem utiliza o guincho para motor em primeiro\\nlugar; mostramos a solução de menor duração, que leva 115 minutos.\\nA complexidade do escalonamento com restrições de recurso é sempre vista, tanto na prática\\nquando na teoria. Um problema desafiante proposto em 1963 — encontrar o escalonamento ótimo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 480}),\n",
       " Document(page_content='para um problema envolvendo apenas 10 máquinas e 10 processos de 100 ações cada — permaneceu\\nsem solução por 23 anos (Lawler \\net al\\n., 1993). Muitas abordagens foram experimentadas, inclusive\\nramificar-e-limitar, têmpera simulada, busca tabu, satisfação de restrições e outras técnicas dos\\nCapítulos 3 e 4. Uma heurística simples, mas popular, é o algoritmo de \\nfolga mínima:\\n em cada\\niteração, o escalonamento com o tempo mais cedo possível, é iniciado para qualquer ação não\\nescalonada que tenha todos os seus predecessores escalonados, e com a mínima folga; então,\\natualiza-se os horários de \\nES\\n e \\nLS\\n para cada ação afetada e, em seguida, repete-se a tarefa. A\\nheurística se assemelha à heurística de mínimos valores restantes (MVR) heurísticos na satisfação de\\nrestrição. Com frequência, ela funciona bem na prática, mas, em nosso problema de montagem,\\nproduz uma solução de 130 minutos, e não a solução de 115 minutos da \\nFigura 11.3\\n.\\nAté este ponto, assumimos que o conjunto de ações e de restrições de ordenação é fixo. Sob esse\\npressuposto, todos os problemas de escalonamento podem ser resolvidos por uma sequência sem\\nsobreposição que evita todos os conflitos de recursos, desde que cada ação seja viável por si só. Se\\num problema de escalonamento mostrar-se muito difícil, no entanto, pode não ser uma boa ideia\\nresolvê-lo dessa forma — pode ser melhor reconsiderar as ações e as restrições, caso conduza a um\\nproblema de escalonamento muito mais fácil. Nesse caso, faz sentido \\nintegrar\\n planejamento e\\nescalonamento, levando em conta durações e sobreposições durante a construção de um plano de\\nordem parcial. Vários algoritmos de planejamento do Capítulo 10 podem ser estendidos para lidar\\ncom essas informações. Por exemplo, os planejadores de ordem parcial podem detectar violações de\\nrestrições de recursos de modo quase idêntico à forma como detectam conflitos com vínculos\\ncausais. As heurísticas podem ser projetadas para avaliar o tempo de conclusão total de um plano.\\nEssa é atualmente uma área ativa de busca.\\n11.2 PLANEJAMENTO HIERÁRQUICO\\nOs métodos de resolução de problemas e de planejamento dos capítulos anteriores operam todos\\ncom um conjunto fixo de ações atômicas. As ações podem ser agrupadas em sequências ou em redes\\nramificadas; os algoritmos de ponta podem gerar soluções contendo milhares de ações.\\nPara os planos executados pelo cérebro humano, as ações atômicas são ativações musculares.\\nFazendo um arredondamento, temos cerca de 10\\n3\\n músculos para ativar (alguns contam 639, mas\\nmuitos deles têm múltiplas subunidades); podemos modular a sua ativação, talvez 10 vezes por\\nsegundo; e estamos vivos e despertos por cerca de 10\\n9\\n segundos ao todo. Assim, uma vida humana\\ncontém cerca de 10\\n13\\n ações, tirando ou adicionando uma ou duas ordens de magnitude. Mesmo se nos\\nlimitarmos a planejar para horizontes muito mais curtos de tempo, por exemplo, férias de duas\\nsemanas no Havaí, um plano de movimentação detalhado conterá cerca de 10\\n10\\n ações. Isso é muito\\nmais do que 1.000.\\nPara preencher essas lacunas, os sistemas de IA provavelmente terão que fazer o que os seres\\nhumanos parecem fazer: planejar em níveis mais altos de abstração. Um plano razoável para as férias\\nno Havaí poderia ser “Ir ao aeroporto de San Francisco; tomar o voo 11 da Hawaiian Airlines para\\nHonolulu, fazer o que se faz nas férias durante duas semanas, pegar o voo 12 da Hawaiian Airlines\\nde volta para San Francisco; ir para casa”. Dado um plano desse tipo, a ação “Vá para o aeroporto', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 481}),\n",
       " Document(page_content='de San Francisco” pode ser vista como uma tarefa de planejamento em si, com uma solução, como\\n“Dirija para o estacionamento com pernoite; estacione; pegue o transfer (serviço de transporte do\\naeroporto) para o terminal”. Cada uma dessas ações, por sua vez, pode ser ainda decomposta até\\nchegarmos ao nível de ações que podem ser executadas sem deliberação para gerar as sequências\\nmotoras de controle exigidas.\\nNesse exemplo, vemos que o planejamento pode ocorrer tanto antes quanto durante a execução do\\nplano; por exemplo, provavelmente, poder-se-ia adiar o problema do planejamento da rota da vaga\\nno estacionamento com pernoite para o serviço de transfer até que seja encontrada uma vaga de\\nestacionamento durante a execução. Assim, essa ação em particular permanecerá em um nível\\nabstrato antes da fase de execução. Adiaremos a discussão desse tópico até a \\nSeção 11.3\\n. Aqui nos\\nconcentraremos no aspecto de \\ndecomposição hierárquica\\n, uma ideia que permeia quase todas as\\ntentativas de gerenciar a complexidade. Por exemplo, a criação de um software complexo pode ser\\nfeita a partir de uma hierarquia de sub-rotinas ou classes de objetos; exércitos operam como uma\\nhierarquia de unidades; governos e corporações têm hierarquias de departamentos, subsidiárias e\\nfiliais. O principal benefício da estrutura hierárquica é que, em cada nível da hierarquia, uma tarefa\\ncomputacional, missão militar ou função administrativa é reduzida a um \\npequeno\\n número de\\natividades, no próximo nível abaixo, de modo que o custo computacional de encontrar a maneira\\ncorreta de organizar as atividades para o problema atual é baixo. Os métodos não hierárquicos, por\\noutro lado, reduzem uma tarefa a um número \\ngrande\\n de ações individuais e, para problemas de\\ngrande escala, isso fica completamente impraticável.\\n11.2.1 Ações de alto nível\\nO formalismo básico que adotamos para entender a decomposição hierárquica vem da área das\\nredes hierárquicas de tarefa\\n ou de planejamento HTN. Como no planejamento clássico (Capítulo\\n10), assumimos observabilidade e determinismo total e a disponibilidade de um conjunto de ações,\\nagora chamadas de \\nações primitivas\\n, com esquemas padrão de precondições-efeito. O conceito-\\nchave adicional é a \\nação de alto nível\\n ou HLA (high-level action) — por exemplo, a ação “Vá ao\\naeroporto de San Francisco”, no exemplo dado anteriormente. Cada HLA tem um ou mais\\nrefinamentos\\n possíveis, em uma sequência\\n1\\n de ações, cada uma das quais pode ser uma HLA ou uma\\nação primitiva (que não tem refinamentos por definição). Por exemplo, a ação “Ir ao aeroporto de\\nSan Francisco”, representada formalmente como \\nIr\\n(\\nCasa, SFO\\n), pode ter dois refinamentos\\npossíveis, como mostrado na \\nFigura 11.4\\n. A mesma figura mostra um refinamento \\nrecursivo\\n para a\\nnavegação no mundo do aspirador de pó: para chegar a um destino, dar um passo e depois ir para o\\ndestino.\\nRefinamento\\n(\\nIr\\n (\\nCasa, SFO\\n)\\n,\\n    PASSOS: [\\nDirigir\\n(\\nCasa, SFOEstacionamentoComPernoite\\n)\\n,\\nTransfer\\n(\\nSFOEstacionamentoComPernoite, SFO\\n)])\\nRefinamento\\n(\\nIr\\n(\\nCasa, SFO\\n)\\n,\\n    PASSOS: [\\nTaxi\\n(\\nCasa, SFO\\n)])', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 482}),\n",
       " Document(page_content='_____________________________________________________________________________________________________________\\nRefinamento\\n(\\nNavegar\\n ([\\na, b\\n]\\n,\\n [\\nx, y\\n])\\n,\\n    PRECOND: \\na = x\\n \\n∧\\n \\nb = y\\n    PASSOS: [])\\nRefinamento\\n(\\nNavegar\\n([\\na, b\\n]\\n,\\n [\\nx, y\\n])\\n,\\n    PRECOND: \\nConectado\\n([\\na, b\\n]\\n,\\n [\\na − 1, b\\n])\\n    PASSOS: [\\nEsquerda, Navegar\\n ([\\na − 1, b\\n]\\n,\\n [\\nx, y\\n])])\\nRefinamento\\n(\\nNavegar\\n([\\na, b\\n]\\n,\\n [\\nx, y\\n])\\n,\\n    PRECOND: \\nConectado\\n([\\na, b\\n]\\n,\\n [\\na + 1, b\\n])\\n    PASSOS: [\\nDireito, Navegar\\n([\\na + 1, b\\n]\\n,\\n [\\nx, y\\n])])\\n. . .\\nFigura 11.4\\n Definições de refinamentos possíveis de duas ações de alto nível: ir para o aeroporto de\\nSan Francisco e navegar no mundo do aspirador de pó. Neste último caso, observe a natureza\\nrecursiva do refinamento e a utilização das precondições.\\nEsses exemplos mostram que as ações de alto nível e seus refinamentos incorporam conhecimentos\\nsobre \\ncomo fazer as coisas\\n. Por exemplo, os refinamentos \\nIr\\n(\\nCasa, SFO\\n) diz que, para você chegar\\nao aeroporto, pode dirigir ou tomar um táxi; comprar leite, as ações sentar-se e mover o cavalo para\\ne4 não devem ser considerados.\\n Um refinamento HLA que contém apenas ações primitivas é chamado de \\nimplementação\\n de\\nHLA. Por exemplo, no mundo do aspirador de pó, ambas as sequências [\\nDireita, Direita, Baixo\\n] e\\n[\\nBaixo, Direita, Direita\\n] implementam a HLA \\nNavegar\\n([1, 3], [3 2]). Uma implementação de um\\nplano de alto nível (uma sequência de HLAs) é a concatenação de implementações de cada HLA na\\nsequência. Dadas as definições de precondição-efeito de cada ação primitiva, é simples determinar\\nse qualquer implementação de um plano de alto nível atingiu o objetivo. Podemos dizer, então, \\nque\\num plano de alto nível atingiu o objetivo a partir de um dado estado se pelo menos uma de suas\\nimplementações atingiu o objetivo daquele estado.\\n “\\nPelo menos uma\\n” é crucial nessa definição —\\nnem \\ntodas\\n as implementações precisam alcançar o objetivo porque o agente tem que decidir qual\\nimplementação vai executar. Assim, o conjunto de implementações possíveis no planejamento de\\nHTN — cada um dos quais pode ter um resultado diferente — não é o mesmo que o conjunto de\\nresultados possíveis no planejamento não determinístico. Lá, é necessário que um plano funcione\\npara \\ntodos\\n os resultados e, como o agente não pode escolher o resultado, a natureza o faz.\\nO caso mais simples é uma HLA que tenha exatamente uma implementação. Nesse caso, podemos\\ncomputar as precondições e os efeitos da HLA a partir da implementação (veja o Exercício 11.3) e,\\nem seguida, tratar a HLA exatamente como se fosse uma ação primitiva por si só. Pode ser\\nconstatado que a coleção correta de HLAs pode resultar na complexidade de tempo da busca cega\\ncaindo de exponencial para linear em profundidade da solução, embora a concepção da referida\\ncoleção de HLAs possa não ser uma tarefa trivial em si. Quando as HLAs têm várias implementações\\npossíveis, existem duas opções: uma é buscar entre as implementações uma que funcione, como na\\nSeção 11.2.2\\n; outra é inferir diretamente sobre a HLA — apesar da multiplicidade de\\nimplementações —, como explicado na \\nSeção 11.2.3\\n. O último método permite a derivação de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 483}),\n",
       " Document(page_content='planos abstratos comprovadamente corretos, sem a necessidade de considerar as suas\\nimplementações.\\n11.2.2 Busca por soluções primitivas\\nO planejamento de HTN muitas vezes é formulado com uma única ação de “nível superior”\\nchamada \\nAção\\n, em que o objetivo é encontrar uma implementação da \\nAção\\n que alcance o objetivo.\\nEssa abordagem é inteiramente genérica. Por exemplo, problemas de planejamento clássico podem\\nser definidos da seguinte forma: para cada ação primitiva \\na\\ni\\n, proporcionar um refinamento da \\nAção\\ncom os passos [\\na\\ni\\n, \\nAção\\n]. Isso cria uma definição recursiva de \\nAção\\n que nos permite adicionar\\nações. Mas precisamos de alguma forma de parar a recursão; fazemos isso fornecendo mais um\\nrefinamento da \\nAção\\n, com uma lista vazia de passos e com uma precondição igual ao objetivo do\\nproblema. Isso significa que, se o objetivo já tiver sido alcançado, então a implementação correta é\\nnão fazer nada.\\nA abordagem leva a um algoritmo simples: escolher repetidamente uma HLA no plano atual e\\nsubstituí-la por um de seus refinamentos, até que o plano atinja o objetivo. Uma implementação\\npossível com base em busca em largura em árvore é mostrada na \\nFigura 11.5\\n. Planos são\\nconsiderados em ordem de profundidade da rede de refinamentos, em vez do número de passos\\nprimitivos. É simples projetar uma versão do algoritmo de busca em grafo, bem como da busca em\\nprofundidade e das versões de aprofundamento iterativos.\\nfunção\\n BUSCA-HIERÁRQUICA (\\nproblema, hierarquia\\n) \\nretorna\\n uma solução ou falha\\n    \\nfronteira\\n ← uma fila FIFO com [\\nAção\\n] como elemento único\\n    \\nfim de laço\\n        \\nse\\n VAZIO? (\\nfronteira\\n), \\nentão retornar\\n falha\\n        \\nplano\\n ← POP(\\nfronteira\\n) /*escolhe o plano menos profundo na \\nfronteira\\n*/\\n        \\nHLA\\n ← a primeira HLA no \\nplano\\n ou \\nnulo\\n se nenhuma\\n        \\nprefixo\\n,\\nsufixo\\n ← as subsequências de ações antes e depois da \\nHLA\\n no \\nplano\\n        \\nconsequência\\n ← RESULTADO(\\nproblema\\n.ESTADO-INITIAL, \\nprefixo\\n)\\n        \\nse\\n \\nHLA\\n for nula \\nentão\\n, / * então o \\nplano\\n é primitivo e \\nconsequência\\n e o resultado * /\\n            \\nse\\n \\nconsequência\\n satisfaz \\nproblema\\n.OBJETIVO \\nentão retornar\\n \\nplano\\n        \\nsenão para cada\\n \\nsequência\\n \\nem\\n REFINAMENTOS(\\nHLA, consequência, hierarquia\\n) \\nfaça\\n            \\nfronteira\\n ← INSIRA(CONCATENA(\\nprefixo, sequência, sufixo), fronteira\\n)\\nFigura 11.5\\n Uma implementação de busca em largura de planejamento hierárquico para a frente. O\\nplano inicial fornecido ao algoritmo é [\\nAção\\n]. A função REFINAMENTOS retorna um conjunto de\\nsequências de ação, uma para cada refinamento da HLA cujas precondições são satisfeitas pelo\\nestado especificado, \\nconsequência\\n.\\nEm essência, essa forma de busca hierárquica explora o espaço de sequências que está de acordo\\ncom o conhecimento contido na biblioteca da HLA sobre como as coisas devem ser feitas. Pode ser', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 484}),\n",
       " Document(page_content='codificada uma grande parte do conhecimento, não apenas nas sequências de ação especificadas em\\ncada refinamento, mas também nas precondições dos refinamentos. Para alguns domínios, os\\nplanejadores de HTN foram capazes de gerar grandes planos com muito pouca busca. Por exemplo, o\\nO-PLAN (Bell e Tate, 1985), que combina planejamento HTN com escalonamento, foi utilizado para\\ndesenvolver planos de produção para a Hitachi. Um problema típico envolve uma linha de 350\\nprodutos diferentes, 35 máquinas de montagem e mais de 2.000 operações diferentes. O planejador\\ngera um escalonamento de 30 dias com três turnos de oito horas por dia, envolvendo dezenas de\\nmilhões de passos. Outro aspecto importante dos planos de HTN é que eles são, por definição,\\nhierarquicamente estruturados; geralmente isso torna fácil para os seres humanos entenderem.\\nOs benefícios computacionais da busca hierárquica podem ser notados examinando um caso\\nidealizado. Suponha que um problema de planejamento tenha uma solução com \\nd\\n ações primitivas.\\nPara um planejador não hierárquico, de espaço de estados para a frente com \\nb\\n ações permitidas em\\ncada estado, o custo será \\nO\\n(\\nb\\nd\\n), conforme explicado no Capítulo 3. Para um planejador HTN, vamos\\nsupor uma estrutura de refinamento bem regular: cada ação não primitiva tem \\nr\\n refinamentos\\npossíveis, cada um decompõe a ação em \\nk\\n ações no nível imediatamente inferior. Queremos saber\\nquantas árvores de refinamento diferente existem com essa estrutura. Agora, se há \\nd\\n ações no nível\\nprimitivo, o número de níveis abaixo da raiz é log\\nk\\n \\nd\\n, de modo que o número de nós de refinamento\\ninternos é \\n. Cada nó interno tem \\nr\\n refinamentos possíveis, então\\npoderiam ser construídos \\nr\\n(\\nd\\n−1)/(\\nk\\n−1)\\n árvores de decomposição regulares possíveis. Examinando essa\\nfórmula, vemos que manter \\nr\\n pequeno e \\nk\\n grande pode resultar em grandes economias:\\nessencialmente estaremos extraindo a raiz \\nk\\n-ésima do custo não hierárquico, e \\nb\\n e \\nr\\n são comparáveis.\\nO \\nr\\n pequeno e o \\nk\\n grande significam uma biblioteca de HLAs com um pequeno número de\\nrefinamentos cada um produzindo uma longa sequência de ações (que, todavia, nos permite resolver\\nqualquer problema). Isso nem sempre é possível: longas sequências de ações que são utilizáveis em\\nampla gama de problemas são extremamente preciosas.\\nA chave para o planejamento HTN, então, é a construção de uma biblioteca de planos contendo\\nmétodos conhecidos de implementação complexa, ações de alto nível. Um método de construção\\ndessa biblioteca é \\naprender\\n os métodos a partir da experiência de resolução de problemas. Depois\\nda experiência dolorosa da construção de um plano a partir do zero, o agente pode salvar o plano na\\nbiblioteca como um método de implementação de ação de alto nível definido pela tarefa. Dessa\\nforma, o agente pode se tornar cada vez mais competente ao longo do tempo à medida que sejam\\nconstruídos novos métodos para substituir os métodos antigos.\\nUm aspecto importante desse processo de aprendizagem é a capacidade de \\ngeneralizar\\n os\\nmétodos que são construídos, eliminando detalhes específicos para a instância do problema (por\\nexemplo, o nome do construtor ou o endereço do terreno) mantendo apenas os elementos principais\\ndo plano. No Capítulo 19 há uma descrição dos métodos para atingir esse tipo de generalização.\\nParece-nos inconcebível que os seres humanos possam ser tão competentes como são sem alguns\\ndesses mecanismos.\\n11.2.3 Busca por soluções abstratas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 485}),\n",
       " Document(page_content='O algoritmo de busca hierárquica da seção anterior refina as HLAs por todo o caminho até as\\nsequências de ações primitivas para determinar se um plano é viável. Isso contradiz o senso comum:\\nele deveria ser capaz de determinar que o plano de alto nível com duas HLAs:\\n[\\nDirigir\\n(\\nCasa, SFOEstacionamentoCom Pernoite\\n)\\n,\\nTransfer\\n(\\nSFOEstacionamentoComPernoite, SFO\\n)]\\nchega ao aeroporto sem ter que determinar uma rota precisa, para a escolha de vaga de\\nestacionamento, e assim por diante. A solução parece óbvia: escrever descrições de precondição-\\nefeito das HLAs, da mesma forma que escrevemos o que as ações primitivas fazem. Das descrições,\\ndeveria ser fácil provar que o plano de alto nível atingiu o objetivo. Esse é o Santo Graal, por assim\\ndizer, do planejamento hierárquico porque, se derivamos um plano de alto nível que\\ncomprovadamente atinge o objetivo, trabalhando em um pequeno espaço de busca de ações de alto\\nnível, então podemos nos comprometer com esse plano e trabalhar com o problema do refinamento\\nde cada passo do plano. Isso nos dá a redução exponencial que buscamos. Para que isso funcione,\\ntodo o plano de alto nível que “reivindica” atingir o objetivo (em virtude das descrições de seus\\npassos) de fato deve atingir o objetivo no sentido definido anteriormente: deve ter pelo menos uma\\nimplementação que atinja o objetivo. Essa propriedade chama-se \\npropriedade de refinamento\\ndescendente\\n para descrições HLA.\\nEscrever as descrições de HLA que satisfaçam a propriedade de refinamento descendente é\\nsimples, em princípio: uma vez que as descrições são \\nverdadeiras\\n, qualquer plano de alto nível que\\npretenda alcançar o objetivo deve de fato fazer isso — caso contrário, as descrições estão fazendo\\nalguma reivindicação falsa sobre o que as HLAs fazem. Já vimos como escrever descrições\\nverdadeiras para as HLAs que tenham exatamente uma implementação (Exercício 11.3), surge um\\nproblema quando a HLA tem múltiplas implementações. Como podemos descrever os efeitos de uma\\nação que pode ser implementada de muitas maneiras diferentes?\\nUma resposta segura (pelo menos para os problemas em que todas as precondições e objetivos são\\npositivos) é incluir apenas os efeitos positivos que são alcançados por \\ncada\\n implementação da HLA\\ne os efeitos negativos de \\nqualquer\\n implementação. Em seguida, a propriedade de refinamento\\ndescendente seria satisfeita. Infelizmente, essa semântica para HLAs é muito conservadora.\\nConsidere novamente a \\nHLA\\n \\nIr\\n(\\nCasa, SFO\\n), que tem dois refinamentos, e suponha, para simplificar a\\nexplicação, um mundo simples em que se pode sempre dirigir até o aeroporto e estacionar, mas tomar\\num táxi requer \\nDinheiro\\n como precondição. Nesse caso, \\nIr\\n(\\nCasa, SFO\\n) nem sempre o leva para o\\naeroporto. Em particular, ocorre falha se \\nDinheiro\\n for falso, e por isso não podemos afirmar\\nEm\\n(\\nAgente, SFO\\n) como um efeito da HLA. Isso não faz sentido; no entanto, se o agente não tivesse\\nDinheiro\\n, ele mesmo dirigiria. Exigir que um efeito seja válido para \\ncada\\n implementação é\\nequivalente a assumir que \\nalguém\\n, um adversário, vá escolher a implementação. Isso trata as\\nmúltiplas consequências da HLA exatamente como se a HLA fosse \\nnão determinística\\n, como na\\nSeção 4.3\\n. Para o nosso caso, o próprio agente vai escolher a implementação.\\nAs comunidades de linguagens de programação cunharam a expressão \\nnão determinismo\\ndemoníaco\\n para o caso em que um adversário faz as escolhas, contrastando com o \\nnão\\ndeterminismo angélico,\\n onde o próprio agente faz as escolhas. Tomamos emprestada essa expressão\\npara definir a semântica angélica das descrições da HLA. O conceito básico necessário para a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 486}),\n",
       " Document(page_content='compreensão da semântica angélica é o \\nconjunto alcançável\\n de uma HLA: dado um estado \\ns\\n, o\\nconjunto alcançável de uma HLA \\nh\\n, escrita como ALCANÇAR(\\ns, h\\n), é o conjunto de estados\\nalcançáveis por qualquer uma das implementações da HLA. A ideia fundamental é que o agente\\npossa escolher em \\nqual\\n elemento do conjunto alcançável ele acaba quando executa a HLA; assim,\\numa HLA com refinamentos múltiplos é mais “poderosa” que a mesma HLA com menos\\nrefinamentos. Podemos também definir o conjunto alcançável de uma sequência de HLAs. Por\\nexemplo, o conjunto alcançável de uma sequência [\\nh\\n1\\n, \\nh\\n2\\n] é a união de todos os conjuntos\\nalcançáveis obtidos através da aplicação de \\nh\\n2\\n em cada estado no conjunto alcançável de \\nh\\n1\\n:\\nDadas essas definições, um plano de alto nível — uma sequência de HLAs — atinge o objetivo se\\no seu conjunto alcançável tem interseção o conjunto de estados objetivos (compare isso com uma\\ncondição muito mais forte para a semântica demoníaca, em que cada membro do conjunto alcançável\\ntem de ser um estado objetivo). Por outro lado, se o conjunto alcançável não tem interseção com o\\nobjetivo, definitivamente o plano não funcionará. A \\nFigura 11.6\\n ilustra essas ideias.\\nFigura 11.6\\n Exemplos esquemáticos de conjuntos alcançáveis. O conjunto de estados objetivo está\\nsombreado. As flechas pretas e cinzas indicam possíveis implementações de h1 e h2,\\nrespectivamente. (a) O conjunto alcançável de um HLA h1 em um estado s. (b) O conjunto alcançável\\npara a sequência [h1, h2]. Como ele tem interseção com o conjunto objetivo, a sequência alcança o\\nobjetivo.\\nA noção de conjuntos alcançáveis produz um algoritmo simples: busca entre planos de alto nível,\\nprocurando aquele cujo conjunto alcançável tem interseção com o objetivo; uma vez que isso\\nacontece, o algoritmo pode \\ncomprometer-se\\n com esse plano abstrato, sabendo que ele funciona, e se\\ndedicar em refinar mais o plano. Vamos voltar para as questões algorítmicas mais tarde; em primeiro\\nlugar, consideremos a questão de como os efeitos de uma HLA — o conjunto alcançável para cada', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 487}),\n",
       " Document(page_content='estado inicial possível — são representados. Tal como acontece com os esquemas de ação clássicos\\ndo Capítulo 10, representaremos as \\nmudanças\\n feitas em cada fluente. Pense em um fluente como uma\\nvariável de estado. A ação primitiva pode \\nadicionar\\n ou \\nexcluir\\n uma variável ou deixá-la \\ninalterada\\n(com efeitos condicionais — consulte a \\nSeção 11.3.1\\n —, há uma quarta possibilidade: lançar uma\\nvariável para o seu oposto).\\nUma HLA sob semântica angélica pode fazer mais: pode \\ncontrolar\\n o valor de uma variável,\\ndefinindo-a como verdadeira ou falsa, dependendo de que implementação for escolhida. Na verdade,\\numa HLA pode ter nove efeitos diferentes sobre uma variável: se a variável iniciar em verdadeiro,\\npode mantê-la sempre como verdadeira, sempre torná-la falso ou ter uma escolha; se a variável\\niniciar como falso, pode manter-se sempre como falso, sempre torná-la verdadeiro ou ter uma\\nescolha; e as três opções de cada caso podem ser combinadas arbitrariamente, ficando nove no total.\\nComo notação, isso é um pouco desafiador. Usaremos o símbolo \\n∼\\n para significar “possivelmente, se\\no agente assim o desejar”. Assim, um efeito \\nA\\n significa “possivelmente adicionar \\nA\\n”, isto é, deixe \\nA\\ninalterado ou torne-o verdadeiro. Da mesma forma, \\nA\\n significa “possivelmente excluir \\nA\\n” e \\n \\nA\\nsignifica “possivelmente adicionar ou excluir A”. Por exemplo, a HLA \\nIr\\n(\\nCasa, SFO\\n), com os dois\\nrefinamentos mostrados na \\nFigura 11.4\\n, possivelmente exclui \\nDinheiro\\n (se o agente decidir tomar um\\ntáxi), por isso deveria ter o efeito \\nDinheiro\\n. Assim, verificamos que as descrições das HLAs são\\nderiváveis\\n, em princípio, das descrições de seus refinamentos — na verdade, isso é necessário se\\nquisermos descrições de HLA verdadeiras, de tal forma que a propriedade de refinamento\\ndescendente seja válida. Agora, suponha que tenhamos os esquemas a seguir para as HLAs \\nh\\n1\\n e \\nh\\n2\\n:\\nOu seja, \\nh\\n1\\n adiciona \\nA\\n e é possível que exclua \\nB\\n, enquanto \\nh\\n2\\n possivelmente adiciona \\nA\\n e tem total\\ncontrole sobre \\nC\\n. Agora, se apenas \\nB\\n for verdadeiro no estado inicial e o objetivo for \\nA\\n \\n∧\\n \\nC\\n, então a\\nsequência [\\nh\\n1\\n, \\nh\\n2\\n] alcança o objetivo: escolhemos uma implementação de \\nh\\n1\\n que torna \\nB\\n falso, em\\nseguida escolhemos uma implementação de \\nh\\n2\\n que deixa \\nA\\n verdadeiro e torna C verdadeiro.\\nA discussão anterior assume que os efeitos de uma HLA — o conjunto alcançável para qualquer\\nestado inicial dado — pode ser descrito exatamente descrevendo o efeito de cada variável. Seria\\nbom se isso fosse sempre verdadeiro, mas em muitos casos só podemos aproximar os efeitos porque\\numa HLA pode ter infinitas implementações e pode produzir conjuntos alcançáveis arbitrariamente\\nsinuosos — um pouco como o problema de estado de crença sinuoso ilustrado na \\nFigura 7.21\\n. Por\\nexemplo, dissemos que \\nIr\\n(\\nCasa, SFO\\n) possivelmente exclui \\nDinheiro\\n; mas também adiciona\\npossivelmente \\nEm\\n(\\nCarro, SFOEstacionamentoComPernoite\\n); mas não pode fazer as duas coisas —\\nde fato, deve fazer exatamente uma. Tal como acontece com os estados de crença, talvez seja\\nnecessário escrever \\ndescrições aproximadas\\n. Utilizaremos dois tipos de aproximação: uma\\ndescrição otimista\\n ALCANCE\\n+\\n(\\ns\\n, \\nh\\n) de uma HLA \\nh\\n pode exagerar o conjunto alcançável, enquanto\\numa \\ndescrição pessimista\\n ALCANCE\\n−\\n(\\ns\\n, \\nh\\n) pode subestimar o conjunto alcançável. Assim, temos\\nPor exemplo, uma descrição otimista de \\nIr\\n(\\nCasa, SFO\\n) informa que é possível excluir \\nDinheiro e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 488}),\n",
       " Document(page_content='possivelmente acrescentar \\nEm\\n(\\nCarro, SFOEstacionamentoComPernoite\\n). Outro bom exemplo surge\\ndo quebra-cabeça de oito peças, do qual metade dos estados é inalcançável de qualquer estado dado\\n(consulte o Exercício 3.4): a descrição otimista de \\nAção\\n poderia muito bem incluir o espaço de\\nestados inteiro, uma vez que o conjunto exato alcançável é bastante sinuoso.\\nCom descrições aproximadas, o teste para saber se um plano alcança o objetivo precisa ser um\\npouco modificado. Se o conjunto alcançável otimista do plano não tem interseção com o objetivo, o\\nplano não funciona; se o conjunto alcançável pessimista tem interseção com o objetivo, o plano\\nfunciona (\\nFigura 11.7\\n(a)). Com descrições exatas, um plano pode ou não funcionar, mas, com\\ndescrições aproximadas, há um meio-termo: se o conjunto otimista tem interseção com o objetivo,\\nmas o pessimista não, não podemos dizer se o plano funciona (\\nFigura 11.7\\n(b)). Quando surge essa\\ncircunstância, a incerteza pode ser resolvida através do refinamento do plano. É uma situação muito\\ncomum no raciocínio humano. Por exemplo, no planejamento das duas semanas de férias no Havaí,\\nanteriormente referido, alguém poderia propor passar dois dias em cada uma das sete ilhas. A\\nprudência indicaria que esse plano ambicioso precisa ser refinado acrescentando detalhes de\\ntransporte entre as ilhas.\\nFigura 11.7\\n Realização do objetivo de planos de alto nível com descrições aproximadas. O conjunto\\nde estados objetivo está sombreado. Para cada plano, são mostrados os conjuntos alcançáveis\\npessimista (linhas sólidas) e otimista (linhas tracejadas). (a) O plano indicado pela seta preta\\nalcança o objetivo definitivamente, enquanto o plano indicado pela seta cinza, não. (b) Um plano que\\nteria de ser refinado ainda mais para determinar se realmente atinge o objetivo.\\nUm algoritmo para o planejamento hierárquico com descrições angélicas aproximadas é mostrado\\nna \\nFigura 11.8\\n. Para simplificar, mantivemos o mesmo esquema utilizado anteriormente na \\nFigura\\n11.5\\n, ou seja, uma busca em largura no espaço de refinamentos. Como explicado, o algoritmo pode\\ndetectar planos que vão ou não funcionar, marcando as interseções dos conjuntos alcançáveis\\notimistas e pessimistas com o objetivo (os detalhes de como calcular os conjuntos alcançáveis de um\\nplano, dadas as descrições aproximadas de cada passo, são abordados no Exercício 11.5). Quando', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 489}),\n",
       " Document(page_content='se encontra um plano abstrato viável, o algoritmo \\ndecompõe\\n o problema original em subproblemas,\\num para cada passo do plano. O estado inicial e objetivo de cada subproblema são obtidos\\nregredindo um estado objetivo garantidamente alcançável através de esquemas de ação para cada\\npasso do plano (veja a \\nSeção 10.2.2\\n para uma discussão de como funciona a regressão). A \\nFigura\\n11.6\\n(b) ilustra a ideia básica: o estado marcado por um círculo no lado direito é o estado objetivo\\ngarantidamente alcançável, e o estado marcado por um circulo no lado esquerdo é o objetivo\\nintermediário obtido pela regressão do objetivo por meio da ação final.\\nfunção\\n BUSCA-ANGÉLICA (\\nproblema\\n, \\nhierarquia\\n, \\nPlanoInicial\\n) \\nretorna\\n solução ou \\nfalha\\n    \\nfronteira\\n ← fila FIFO com \\nPlanoInicial\\n como elemento único\\n    \\nfechar laço\\n        \\nse\\n VAZIO? (\\nfronteira\\n) \\nentão retornar\\n \\nfalha\\n        \\nplano\\n ← POP(\\nfronteira\\n) /* escolhe o lugar mais raso da \\nfronteira\\n*/\\n        \\nse\\n ALCANCE\\n+\\n(\\nproblema\\n.ESTADO-INICIAL, \\nplano\\n) interseciona \\nproblema\\n.OBJETIVO \\nentão\\n            \\nse\\n \\nplano\\n é primitivo \\nentão retornar\\n \\nplano\\n /* ALCANCE\\n+\\n é exato para planos primitivos */\\n            \\ngarantido\\n ← ALCANCE\\n−\\n(\\nproblema\\n.ESTADO-INICIAL, \\nplano\\n) > \\nproblema\\n.OBJETIVO\\n            \\nse\\n \\ngarantido\\n ≠ { } e FAZER-PROGRESSO (\\nplano\\n, \\nPlanoInicial\\n), \\nentão\\n                \\nEstadoFinal\\n ← qualquer elemento de \\ngarantido\\n                \\nretornar\\n DECOMPOR(\\nhierarquia\\n, \\nproblema\\n.ESTADO-INICIAL, \\nplano\\n, \\nestadoFinal\\n)\\n            \\nhla\\n ← algumas HLA no \\nplano\\n            \\nprefixo\\n, \\nsufixo\\n ← subsequências de ações antes e depois da \\nhla\\n no \\nplano\\n            \\npara cada\\n \\nsequência\\n \\nem\\n REFINAMENTOS (\\nhla\\n, \\nconsequência\\n, \\nhierarquia\\n) \\nfaça\\n                \\nfronteira\\n ← INSERIR(CONCATENAR(\\nprefixo\\n, \\nsequência\\n, \\nsufixo\\n), \\nfronteira\\n)\\n_____________________________________________________________________________________________________________\\nfunção\\n DECOMPOR(\\nhierarquia, s\\n0\\n, plano, s\\nf\\n) \\nretornar\\n uma solução\\n    \\nsolução\\n ← um plano vazio\\n    \\nenquanto\\n \\nplano\\n não está vazia \\nfaça\\n        \\nação\\n ← REMOVER-ÚLTIMO (\\nplano\\n)\\n        \\nsi\\n ← um estado em ALCANCE\\n−\\n(\\ns\\n0\\n \\nplano,\\n) tal que \\ns\\nf\\n ALCANCE\\n−\\n (\\ns\\ni\\n, ação\\n)\\n        \\nproblema\\n ← problema com ESTADO-INICIAL = \\ns\\ni\\n e OBJETIVO = \\ns\\nf\\n        \\nsolução\\n ← CONCATENAR(BUSCA-ANGÉLICA(problema, hierarquia, ação), solução)\\n        \\ns\\nf\\n ← \\ns\\ni\\n    \\nretornar\\n \\nsolução\\nFigura 11.8\\n Um algoritmo de planejamento hierárquico que usa semântica angélica para identificar e\\nse comprometer com planos de alto nível que funcionam, evitando planos de alto nível que não\\nfuncionam. O predicado FAZER-PROGRESSO realiza verificações para se certificar de que não\\nestamos presos em uma regressão infinita de refinamentos. No nível superior, chama a BUSCA-\\nANGÉLICA com [\\nAção\\n] como o \\nPlanoInicial\\n.\\nA capacidade de comprometer-se ou de rejeitar planos de alto nível pode dar à BUSCA-\\nANGÉLICA uma vantagem computacional significativa sobre a BUSCA-HIERÁRQUICA, que por\\nsua vez pode ter uma grande vantagem sobre a antiga e simples BUSCA-EM-LARGURA. Considere,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 490}),\n",
       " Document(page_content='por exemplo, a limpeza com um grande mundo do aspirador de pó composto de quartos retangulares\\nligados por corredores estreitos. Faz sentido ter uma HLA para \\nNavegar\\n (como mostrado na \\nFigura\\n11.4\\n) e um para \\nLimparQuartoTodo\\n (a limpeza do quarto poderia ser implementada com a aplicação\\nrepetida de outra HLA para limpar cada fileira). Desde que há cinco ações nesse domínio, o custo da\\nBUSCA-EM-LARGURA cresce 5\\nd\\n, onde \\nd\\n é o comprimento da menor solução (cerca de duas vezes\\no número total de quadrados); o algoritmo não pode gerenciar nem mesmo dois quartos 2 × 2. A\\nBUSCA-HIERÁRQUICA é mais eficiente, mas ainda sofre com o crescimento exponencial porque\\ntenta todas as formas de limpar que seja consistente com a hierarquia. A BUSCA-ANGÉLICA\\napresenta escala aproximadamente linear no número de quadrados — compromete-se com uma boa\\nsequência de alto nível e poda as outras opções. Observe que limpar um conjunto de quartos,\\nlimpando um de cada vez não é um bicho de sete cabeças: é fácil para os seres humanos justamente\\npor causa da estrutura hierárquica da tarefa. Quando consideramos como os seres humanos acham\\ndifícil resolver pequenos quebra-cabeças, como o quebra-cabeças de oito peças, parece que a\\ncapacidade dos seres humanos para resolver problemas complexos deriva em grande parte de sua\\nhabilidade em abstrair e decompor o problema para eliminar a análise combinatória.\\nA abordagem angélica pode ser estendida para encontrar soluções de menor custo por generalizar\\na noção de conjunto alcançável. Em vez de um estado ser alcançável ou não, ela tem um custo para a\\nforma mais eficiente de chegar lá (o custo é ∞ para os estados inalcançáveis). As descrições\\notimistas e pessimistas limitam esses custos. Dessa forma, a busca angélica pode comprovadamente\\nencontrar planos abstratos ótimos, sem considerar suas implementações. A mesma abordagem pode\\nser usada para obtenção de \\nalgoritmos lookahead hierárquicos\\n eficazes para busca on-line, no\\nestilo do LRTA*. Em alguns aspectos, tais algoritmos espelham-se em aspectos de deliberação\\nhumana em tarefas tais como o planejamento de férias no Havaí — a consideração de alternativas é\\ninicialmente feita em um nível abstrato em escalas longas de tempo; algumas partes do plano são\\ndeixadas completamente abstratas até o tempo de execução, como a forma de passar dois dias\\npreguiçosos em Molokai, enquanto outras partes são planejadas em detalhes, tais como os voos a\\nserem tomados e a hospedagem a ser reservada — sem esses refinamentos, não há garantia da\\nviabilidade do plano.\\n11.3 PLANEJAMENTO E AÇÃO EM DOMÍNIOS NÃO DETERMINÍSTICOS\\nNessa seção, estenderemos o planejamento para lidar com ambientes parcialmente observáveis,\\nnão determinísticos e desconhecidos. O Capítulo 4 estendeu a busca de forma semelhante, e os\\nmétodos aqui também são similares: \\nplanejamento sem sensores\\n (também conhecido como\\nplanejamento em conformidade\\n) para ambientes sem observações, \\nplanejamento de contingência\\npara ambientes parcialmente observáveis e não determinísticos; e \\nplanejamento on-line\\n e\\nreplanejamento\\n para ambientes desconhecidos.\\nEnquanto os conceitos básicos são os mesmos que no Capítulo 4, há também diferenças\\nsignificativas. Principalmente porque os planejadores lidam com representações fatoradas em vez de\\nrepresentações atômicas. Isso afeta a maneira como representamos a capacidade do agente para a\\nação e observação e a forma como representamos os \\nestados de crença\\n — os conjuntos de estados', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 491}),\n",
       " Document(page_content='físicos possíveis em que o agente possa estar — para ambientes não observáveis e parcialmente\\nobserváveis. Podemos também tirar proveito de muitos dos métodos independentes de domínio dados\\nno Capítulo 10 para calcular heurísticas de busca.\\nConsidere o problema: dada uma cadeira e uma mesa, o objetivo é combiná-las — ter a mesma\\ncor. No estado inicial temos duas latas de tinta, mas as cores da tinta e dos móveis são\\ndesconhecidos. Apenas a mesa está inicialmente no campo de visão do agente:\\nInício\\n(\\nObjeto\\n (\\nMesa\\n) \\n∧\\n \\nObjeto\\n(\\nCadeira\\n) \\n∧\\n \\nLata\\n(\\nC\\n1\\n) \\n∧\\n \\nLata\\n(\\nC\\n2\\n) \\n∧\\n \\nVista\\n(\\nMesa\\n))\\nObjetivo\\n(\\nCor\\n(\\nCadeira, c\\n) \\n∧\\n \\nCor\\n(\\nMesa, c\\n))\\nHá duas ações: remover a tampa de uma lata de tinta e pintar um objeto usando a tinta da lata\\naberta. Os esquemas de ação são simples, com uma exceção: agora permitimos precondições e\\nefeitos para conter variáveis que não são parte da lista de variáveis da ação. Ou seja, \\nTinta\\n(\\nx, lata\\n)\\nnão menciona a variável \\nc\\n, que representa a cor da tinta na lata. No caso totalmente observável, isso\\nnão é permitido — teríamos que denominar a ação \\nPintar\\n(\\nx, lata, c\\n). Mas, no caso parcialmente\\nobservável, podemos ou não saber que cor está na lata (a variável \\nc\\n é universalmente quantificada,\\nassim como todas as outras variáveis \\u200b\\u200bem um esquema de ação).\\nAção\\n(\\nRemoverTampa\\n(\\nlata\\n)\\n,\\nPRECOND: \\nLata\\n(\\nlata\\n)\\nEFFECT: \\nAbrir\\n(\\nlata\\n))\\nAção\\n(\\nPintar\\n(\\nx, lata\\n)\\n,\\nPRECOND: \\nObject\\n(\\nx\\n) \\n∧\\n \\nLata\\n(\\nlata\\n) \\n∧\\n \\nCor\\n(\\nlata, c\\n) \\n∧\\n \\nAbrir\\n(\\nlata\\n)\\nEFFECT: \\nCor\\n(\\nx, c\\n)).\\nPara resolver um problema parcialmente observável, o agente terá que raciocinar sobre as\\npercepções que vai obter quando estiver executando o plano. A percepção será fornecida pelos\\nsensores do agente quando estiver realmente em ação, mas quando estiver planejando será necessário\\num modelo de seus sensores. No Capítulo 4, esse modelo foi dado pela função, PERCEPÇÃO(\\ns\\n).\\nPara o planejamento, que estende a PDDL com um novo tipo de esquema, o \\nesquema percepção\\n:\\nPercepção(Cor (x, c),\\nPRECOND: \\nObjeto(x)\\n \\n∧\\n \\nVista(x)\\nPercepção(Cor (lata, c),\\nPRECOND: \\nLata(lata)\\n \\n∧\\n \\nVista(lata)\\n \\n∧\\n \\nAbrir(lata)\\nO primeiro esquema diz que, sempre que um objeto estiver à vista, o agente vai perceber a cor do\\nobjeto (isto é, para o objeto \\nx\\n, o agente vai aprender o valor verdadeiro da \\nCor\\n(\\nx, c\\n) para todo \\nc\\n). O\\nsegundo esquema informa que, se uma lata aberta estiver à vista, o agente percebe a cor da tinta na\\nlata. Como não há eventos exógenos nesse mundo, a cor de um objeto permanecerá a mesma, mesmo\\nse não estiver sendo percebida, até que o agente execute uma ação para mudar a cor do objeto.\\nCertamente o agente precisará de uma ação que faça com que os objetos (um de cada vez) fiquem à\\nvista:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 492}),\n",
       " Document(page_content='Ação\\n(\\nOlhar\\n(\\nx\\n)\\n,\\nPRECOND: \\nVista\\n(\\ny\\n) \\n∧\\n (\\nx\\n ≠ \\ny\\n)\\nEFFECT: \\nVista\\n(\\nx\\n) \\n∧\\n ¬\\nVista\\n(\\ny\\n)).\\nPara um ambiente totalmente observável, teríamos um axioma \\nPercepção\\n sem precondições para\\ncada fluente. Um agente sem sensores, por outro lado, não tem axiomas de \\nPercepção\\n. Observe que\\nmesmo um agente sem sensores pode resolver o problema da pintura. Uma solução é abrir qualquer\\nlata de tinta e aplicá-la tanto na cadeira como na mesa, \\nforçando-as\\n (coercing), assim, a ser da\\nmesma cor (mesmo que o agente não saiba que cor é).\\nUm agente de planejamento contingente com sensores pode gerar um plano melhor. Primeiro, olha\\npara a mesa e para a cadeira para obter as cores; se elas são as mesmas, o plano está feito. Se não,\\nolha para as latas de tinta; se a tinta na lata for da mesma cor que uma peça do mobiliário, aplicará a\\ntinta na outra peça. Caso contrário, pintará ambas as peças com qualquer cor.\\nFinalmente, um agente de planejamento on-line pode gerar um plano de contingência com menos\\nramificações a princípio — talvez ignorando a possibilidade que nenhuma tinta na lata combine com\\na mobília — e lide com os problemas à medida que surjam, replanejando-os. Também poderia lidar\\ncom erros de seus esquemas de ação. Considerando que um planejador de contingência simplesmente\\nassume que os efeitos de uma ação sempre são bem-sucedidos — que a pintura da cadeira resolve\\n—, um agente de replanejamento verificaria o resultado e faria um plano adicional para corrigir\\nqualquer falha inesperada, tal como uma área sem pintura ou a cor original ainda a mostra.\\nNo mundo real, os agentes usam uma combinação de abordagens. Fabricantes de automóveis\\nvendem pneus sobressalentes e \\nairbags\\n, que são incorporações físicas de ramificações de planos de\\ncontingência projetados para lidar com pneus furados ou batidas de carro. Por outro lado, a maioria\\ndos motoristas nunca considera essas possibilidades; quando surge um problema, respondem como\\nagentes de replanejamento. Em geral, os agentes planejam apenas para contingências que tenham\\nconsequências importantes e uma chance não negligenciável de acontecer. Assim, um motorista de\\ncarro contemplando uma viagem através do deserto do Saara deve fazer planos de contingência\\nexplícitos para falhas, enquanto uma ida ao supermercado exige menos planejamento antecipado. A\\nseguir, veremos cada uma das três abordagens em mais detalhes.\\n11.3.1 Planejamento sem sensores\\nA Secção 4.4.1 introduziu a ideia básica de busca em espaço de estado de crença para encontrar\\numa solução para os problemas sem sensores. A conversão de um problema de planejamento sem\\nsensores para um problema de planejamento de estado de crença funciona da mesma maneira como\\nna \\nSeção 4.4.1\\n; as principais diferenças são que o modelo de transição física subjacente é\\nrepresentado por uma coleção de esquemas de ação e o estado de crença pode ser representado por\\numa fórmula lógica em vez de um conjunto de estados explicitamente enumerados. Para simplificar,\\nvamos supor que o problema de planejamento subjacente seja determinístico.\\nO estado de crença inicial para o problema de pintura sem sensores pode ignorar os fluentes \\nVista\\nporque o agente não tem sensores. Além disso, tomamos como dados os fatos imutáveis', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 493}),\n",
       " Document(page_content='Objeto\\n(\\nMesa\\n) \\n∧\\n \\nObjeto\\n(\\nCadeira\\n) \\n∧\\n \\nLata\\n(\\nC\\n1\\n) \\n∧\\n \\nLata\\n(\\nC\\n2\\n) porque são válidos em cada estado de\\ncrença. O agente não sabe as cores das latas ou objetos, ou se as latas estão abertas ou fechadas, mas\\nsabe que os objetos e as latas têm cores: \\n∀\\nx\\n \\n∃\\nc\\n \\nCor\\n (\\nx, c\\n). Depois de skolemizar (veja a \\nSeção\\n9.5\\n), obtemos o estado de crença inicial:\\nb\\n0\\n \\n= Cor\\n(\\nx, C\\n(\\nx\\n))\\n.\\nNo planejamento clássico, onde se faz a \\nsuposição do mundo fechado\\n, teríamos que assumir que\\nqualquer fluente não mencionado em um estado é falso, mas no planejamento sem sensores (e\\nparcialmente observável) temos que mudar para uma \\nsuposição do mundo aberto\\n, no qual os estados\\ncontêm fluentes positivos e negativos, e, se um fluente não aparecer, seu valor é desconhecido.\\nAssim, o estado de crença corresponde exatamente ao conjunto de mundos possíveis que satisfazem a\\nfórmula. Dado esse estado de crença inicial, a sequência de ação seguinte é uma solução:\\n[\\nRemoverTampa\\n(\\nLata\\n1\\n) \\nPintar\\n(\\nCadeira, Lata\\n1\\n)\\n, Pintar\\n(\\nMesa, Lata\\n1\\n)]\\n.\\nVamos agora mostrar o progresso do estado de crença através da sequência de ação para mostrar\\nque o estado de crença final satisfaz o objetivo.\\nPrimeiro, observe que, em determinado estado de crença \\nb\\n, o agente pode considerar qualquer\\nação cujas precondições sejam satisfeitas por \\nb\\n (as demais ações não podem ser utilizadas porque o\\nmodelo de transição não define os efeitos das ações cujas precondições não possam ser satisfeitas).\\nDe acordo com a Equação 4.4, a fórmula geral para atualizar o estado de crença \\nb\\n dada uma ação\\naplicável \\na\\n em um mundo determinístico é a seguinte:\\nb\\n′\\n = RESULTADO(\\nb, a\\n) = {\\ns\\n′\\n: \\ns\\n′\\n = RESULTADO\\np\\n(\\ns, a\\n) e \\ns\\n \\n∊\\n \\nb\\n}\\nonde RESULTADO\\nP\\n define o modelo de transição física. Por enquanto, vamos supor que o estado de\\ncrença inicial seja sempre uma conjunção de literais, isto é, uma fórmula 1-FNC. Para construir o\\nnovo estado de crença \\nb’\\n, devemos considerar o que acontece com cada literal \\nl\\n em cada estado\\nfísico \\ns\\n em \\nb\\n quando a ação \\na\\n for aplicada. Para literais cujo valor verdadeiro já é conhecido em \\nb\\n, o\\nvalor verdadeiro em \\nb’\\n é calculado a partir do valor atual e da lista de adição e exclusão da ação\\n(por exemplo, se \\nl\\n estiver na lista de exclusão da ação, então ¬\\nl\\n é adicionado a \\nb’\\n). E o que\\naconteceria com um literal cujo valor verdadeiro é desconhecido em \\nb\\n? Há três casos:\\n1. Se a ação adiciona \\nl\\n, então \\nl\\n será verdadeiro em \\nb’\\n, independentemente do seu valor inicial.\\n2. Se a ação exclui \\nl\\n, então \\nl\\n será falso em \\nb’\\n, independentemente do seu valor inicial.\\n3. Se a ação não afeta \\nl\\n, então \\nl\\n vai manter o seu valor inicial (que é desconhecido) e não\\naparecerá em \\nb’\\n.\\nAssim, vemos que o cálculo de \\nb’\\n é quase idêntico ao caso observável, que foi especificado pela\\nEquação 10.1:\\nb\\n′\\n = RESULTADO(\\nb, a\\n) = (\\nb\\n – DEL (\\na\\n)) \\n ADD (\\na\\n).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 494}),\n",
       " Document(page_content='Quase não podemos utilizar o conjunto semântico porque (1) temos de nos certificar de que \\nb’\\n não\\ncontém \\nl\\n ou ¬\\nl\\n e (2) de que os átomos podem conter variáveis  livres. Mas ainda o caso é que o\\nRESULTADO(\\nb\\n, \\na\\n) é calculado começando com \\nb\\n, definindo qualquer átomo que apareça em\\nDEL(\\na\\n) como falso e definindo qualquer átomo que apareça em ADD(\\na\\n) como verdadeiro. Por\\nexemplo, se aplicarmos RemoverTampa(Lata1) para o estado de crença inicial b0, obteremos\\nb\\n1\\n = \\nCor\\n(\\nx\\n, \\nC\\n (\\nx\\n)) \\n∧\\n \\nAbrir\\n(\\nLata\\n1\\n).\\nQuando aplicamos a ação \\nPintar\\n(\\nCadeira, Lata\\n1\\n), a precondição \\nCor\\n(\\nLata\\n1\\n, c\\n) é satisfeita pelo\\nliteral conhecido \\nCor\\n(\\nx, C\\n (\\nx\\n)) com substituição {\\nx\\n/\\nLata\\n1\\n, c\\n / \\nC\\n (\\nLata\\n1\\n)} e o novo estado de crença é\\nb\\n2\\n = \\nCor\\n(\\nx, C\\n (\\nx\\n)) \\n∧\\n \\nAbrir\\n(\\nLata\\n1\\n) \\n∧\\n \\nCor\\n(\\nCadeira\\n, \\nC\\n (\\nLata\\n1\\n)).\\nFinalmente, aplicamos a ação \\nPintar\\n(\\nMesa, Lata\\n1\\n) para obter\\nb\\n3\\n = \\nCor\\n(\\nx\\n, \\nC\\n (\\nx\\n)) \\n∧\\n \\nAbrir\\n(\\nLata\\n1\\n) \\n∧\\n \\nCor\\n(\\nCadeira\\n, \\nC\\n (\\nLata\\n1\\n))\\n∧\\n \\nCor\\n(\\nMesa\\n, C (\\nLata\\n1\\n)).\\nO estado de crença final satisfaz o objetivo, \\nCor\\n(\\nMesa\\n, \\nc\\n) \\n∧\\n \\nCor\\n(\\nCadeira\\n, \\nc\\n), com a variável \\nc\\nlimitada a \\nC\\n(\\nLata\\n1\\n).\\nA análise anterior da regra de atualização mostrou um fato muito importante: \\na família dos estados\\nde crença definida como conjunções de literais é fechada sob as atualizações definidas pelos\\nesquemas de ações PDDL\\n. Ou seja, se o estado de crença começar como uma conjunção de literais,\\nqualquer atualização produzirá uma conjunção de literais. Isso significa que, em um mundo com \\nn\\nfluentes, qualquer estado de crença pode ser representado por uma conjunção de tamanho \\nO\\n(\\nn\\n). Esse\\né um resultado muito reconfortante, considerando que existem 2\\nn\\n estados no mundo. Isso informa que\\npodemos representar compactamente todos os subconjuntos desses 2\\nn\\n estados que vamos precisar.\\nAlém disso, o processo de verificação dos estados de crença que são subconjuntos ou superconjuntos\\nde estados de crença visitados anteriormente também é fácil, pelo menos no caso proposicional.\\nO único senão desse quadro favorável é que só funciona para os esquemas de ação que têm os\\nmesmos efeitos\\n para todos os estados em que suas precondições são satisfeitas. É essa propriedade\\nque permite a preservação da representação do estado de crença 1-FNC. Uma vez que o efeito\\ndepende do estado, as dependências são introduzidas entre os fluentes, e a propriedade 1-FNC é\\nperdida. Considere, por exemplo, o mundo simples do aspirador de pó definido na \\nSeção 3.2.1\\n. Faça\\nos fluentes AtL e AtR para a localização do robô e \\nLimpoL\\n e \\nLimpoR\\n para o estado dos quadrados.\\nSegundo a definição do problema, a ação \\nAspirar\\n não tem precondição — pode sempre ser feita. A\\ndificuldade é que seu efeito depende da localização do robô: quando o robô está em AtL, o resultado\\né \\nLimpoL\\n, mas quando está em \\nAtR\\n, o resultado é \\nLimpoR\\n. Para essas ações, nossos esquemas de\\nação vão precisar de algo novo: um \\nefeito condicional\\n. A sintaxe é “\\nquando\\n \\ncondição\\n: efeito”, onde\\ncondição\\n é uma fórmula lógica a ser comparada com o estado atual e \\nefeito\\n é uma fórmula que\\ndescreve o estado resultante. Para o mundo do aspirador de pó, temos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 495}),\n",
       " Document(page_content='Ação\\n(\\nAspirar,\\nEFEITO: \\nquando\\n \\nAtL\\n: \\nLimpoL\\n \\n∧\\n \\nquando\\n \\nAtR\\n: \\nLimpoR\\n).\\nQuando for aplicado ao estado de crença inicial \\nVerdadeiro\\n, o estado de crença resultante é (\\nAtL\\n∧\\n \\nLimpoL\\n) \\n∨\\n (\\nAtR\\n \\n∧\\n \\nLimpoR\\n), que não é mais uma 1-FNC (essa transição pode ser vista na \\nFigura\\n4.14\\n). Em geral, os efeitos condicionais podem induzir a dependências arbitrárias entre os fluentes\\nem um estado de crença, levando a estados de crença de tamanho exponencial no pior caso.\\nÉ importante entender a diferença entre precondições e efeitos condicionais. \\nTodos\\n os efeitos\\ncondicionais, cujas condições são satisfeitas, têm os seus efeitos aplicados para gerar o estado\\nresultante; se nenhum for satisfeito, o estado resultante permanece inalterado. Por outro lado, se uma\\nprecondição\\n não for satisfeita, a ação é inaplicável e o estado resultante é indefinido. Do ponto de\\nvista do planejamento sem sensores, é melhor ter efeitos condicionais que uma ação inaplicável. Por\\nexemplo, poderíamos dividir \\nAspirar\\n em duas ações com efeitos incondicionais, da seguinte forma:\\nAção\\n(\\nAspirarL,\\nPRECOND: \\nAtL\\n; EFEITO: \\nLimpoL\\n)\\nAção\\n(\\nAspirarR\\n,\\nPRECOND: \\nAtR\\n; EFEITO: \\nLimpoR\\n).\\nAgora temos apenas esquemas incondicionais, por isso todos os estados de crença permanecem em\\n1-FNC, mas, infelizmente, não podemos determinar a aplicabilidade de \\nAplicarL\\n e \\nAplicarR\\n no\\nestado de crença inicial.\\nParece inevitável, então, que os problemas não triviais vão envolver estados de crença sinuosos,\\ncomo aqueles encontrados quando se considerou o problema de estimativa de estado para o mundo\\nde wumpus (consulte a \\nFigura 7.21\\n). A solução então sugerida foi utilizar \\naproximação\\nconservativa\\n para o estado de crença exato, por exemplo, o estado de crença pode permanecer em 1-\\nFNC se contiver todos os literais cujos valores verdadeiros possam ser determinados e tratar todos\\nos outros literais como desconhecidos. Embora essa abordagem seja \\nboa\\n, por nunca gerar um plano\\nincorreto, é i\\nncompleta\\n, pois pode ser incapaz de encontrar soluções para problemas que envolvem\\nnecessariamente interações entre literais. Para dar um exemplo corriqueiro, se o objetivo for que o\\nrobô esteja em um quadrado limpo, então [\\nAspirar\\n] é uma solução, mas um agente sem sensor que\\ninsiste em encontrar um estado de crença 1-FNC, não vai encontrá-lo.\\nTalvez a melhor solução seja procurar sequências de ações que mantenham o estado de crença o\\nmais simples possível. Por exemplo, no mundo do aspirador de pó sem sensor, a sequência de ação\\n[\\nDireita\\n, \\nAspirar\\n, \\nEsquerda\\n, \\nAspirar\\n] gera a seguinte sequência de estados crença:\\nb\\n0\\n = \\nVerdadeiro\\nb\\n1\\n = \\nAtR\\nb\\n2\\n = \\nAtR\\n \\n∧\\n \\nLimpoR\\nb\\n3\\n = \\nAtL\\n \\n∧\\n \\nLimpoR\\nb\\n4\\n = \\nAtL\\n \\n∧\\n \\nLimpoR\\n \\n∧\\n \\nLimpoL.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 496}),\n",
       " Document(page_content='Ou seja, o agente \\npode\\n resolver o problema enquanto mantém um estado de crença 1-FNC, embora\\nalgumas sequências (por exemplo, as que começam com \\nAspirar\\n) saiam da forma 1-FNC. A lição\\ngeral não foi perdida sobre os seres humanos: estamos sempre realizando pequenas ações\\n(verificando a hora, batendo nos bolsos para ter certeza de que temos as chaves do carro, lendo\\nplacas de rua à medida que rodamos pela cidade) para eliminar a incerteza e manter o nosso estado\\nde crença gerenciável.\\nHá uma outra abordagem bem diferente para o problema de estados de crença sinuosos: não é\\nnecessário calculá-los. Suponha que o estado de crença inicial seja b\\n0\\n e que gostaríamos de conhecer\\no estado de crença resultante da sequência de ação [\\na\\n1\\n,…, \\na\\nm\\n]. Em vez de calculá-lo explicitamente,\\napenas represente-o como “b\\n0\\n então [\\na\\n1\\n,…, \\na\\nm\\n].” Essa é uma representação preguiçosa mas\\ninequívoca do estado de crença, e é bastante concisa — \\nO\\n(\\nn\\n + \\nm\\n), onde \\nn\\n é o tamanho do estado de\\ncrença inicial (que se assume estar em 1-FNC) e \\nm\\n é o tamanho máximo de uma sequência de ações.\\nComo uma representação do estado de crença ela sofre de uma desvantagem: determinar se o\\nobjetivo foi satisfeito ou se uma ação é aplicável pode exigir muito cálculo.\\nO cálculo pode ser implementado como um teste de consequência lógica: se \\nA\\nm\\n representa a\\ncoleção dos axiomas de estado sucessor necessária para definir as ocorrências das ações \\na\\n1\\n,… \\na\\nm\\n —\\ncomo foi explicado para o SATPLAN na \\nSeção 10.4.1\\n — e \\nG\\nm\\n afirma que o objetivo é verdadeiro\\ndepois de \\nm\\n etapas, então o plano atingirá o objetivo se \\nb\\n0\\n \\n∧\\n \\nA\\nm\\n |= \\nG\\nm\\n, isto é, se \\nb\\n0\\n \\n∧\\n \\nA\\nm\\n \\n∧\\n ¬ \\nG\\nm\\nfor insatisfatível. Dado um solucionador moderno SAT, pode ser possível fazer isso muito mais\\nrapidamente do que pelo cálculo do estado de crença total. Por exemplo, se nenhuma das ações na\\nsequência tiver um fluente objetivo em particular na sua lista de adição, o solucionador vai detectar\\nisso imediatamente. Também ajuda se os resultados parciais sobre o estado de crença — por\\nexemplo, fluentes que se sabe serem verdadeiros ou falsos — são armazenados em cache para\\nsimplificar os cálculos subsequentes.\\nA última peça do quebra-cabeça de planejamento sem sensor é uma função heurística para orientar\\na busca. O significado da função heurística é o mesmo que no planejamento clássico: uma estimativa\\n(talvez admissível) do custo de alcançar o objetivo de um determinado estado de crença. Com\\nestados de crença, temos um fato adicional: resolver qualquer subconjunto de um estado de crença é\\nnecessariamente mais fácil do que resolver o estado de crença:\\nPortanto, qualquer heurística admissível calculada para um subconjunto é admissível para o estado\\nde crença em si. Os candidatos mais óbvios são os subconjuntos unitários, ou seja, estados físicos\\nindividuais. Podemos tomar qualquer conjunto aleatório de estados \\ns\\n1\\n,…, \\ns\\nN\\n que estiverem no estado\\nde crença \\nb\\n, aplicar qualquer heurística admissível \\nh\\n do Capítulo 10 e devolver\\nH\\n (\\nb\\n) = max {\\nh\\n (\\ns\\n1\\n),…, \\nh\\n (\\ns\\nN\\n)}\\ncomo estimativa heurística para resolver \\nb\\n. Poderíamos também utilizar um grafo de planejamento\\ndiretamente sobre o próprio \\nb\\n: se for uma conjunção de literais (1-FNC), basta definir os literais\\npara ser a camada de estado inicial do grafo. Se \\nb\\n não estiver em 1-FNC, pode ser possível', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 497}),\n",
       " Document(page_content='encontrar conjuntos de literais que, juntos, tem como consequência lógica \\nb\\n. Por exemplo, se \\nb\\nestiver na forma normal disjuntiva (FND), cada termo da fórmula FND será uma conjunção de\\nliterais que permite \\nb\\n e pode formar a camada inicial de um grafo de planejamento. Como antes,\\npodemos tirar o máximo das heurísticas obtidas de cada conjunto de literais. Podemos utilizar\\ntambém heurísticas inadmissíveis, como a heurística de ignorar a lista de exclusão, que parece\\nfuncionar muito bem na prática.\\n11.3.2 Planejamento contingente\\nVimos no Capítulo 4 que o planejamento contingente — a geração de planos com ramificação\\ncondicional baseada em percepções — é apropriado para ambientes com observabilidade parcial,\\nnão determinismo ou ambos. Para o problema da tinta parcialmente observável com os axiomas de\\npercepção, dado anteriormente, a solução de contingência possível é a seguinte:\\nAs variáveis desse plano devem ser consideradas existencialmente quantificadas; a segunda linha\\ninforma que, se existe alguma cor \\nc\\n que seja a cor da mesa e da cadeira, então o agente não precisa\\nfazer nada para atingir o objetivo. Ao executar esse plano, um agente de planejamento contingente\\npode manter o seu estado de crença como uma fórmula lógica e avaliar cada condição de ramificação\\ndeterminando se o estado de crença permite a fórmula de condição ou sua negação. (É\\nresponsabilidade do algoritmo de planejamento contingente certificar--se de que o agente nunca\\ntermine em um estado de crença onde a condição do valor verdadeiro da fórmula seja desconhecido.)\\nObserve que, com as condições de primeira ordem, a fórmula pode ser satisfeita de mais de uma\\nmaneira; por exemplo, a condição \\nCor\\n(\\nMesa, c\\n) \\n∧\\n \\nCor\\n(\\nlata, c\\n) pode ser satisfeita por {\\nlata\\n/\\nLata\\n1\\n}\\ne por {\\nlata\\n/\\nLata\\n2\\n} se ambas as latas forem da mesma cor que a mesa. Nesse caso, o agente pode\\nescolher qualquer substituição satisfatória para aplicar ao resto do plano.\\nConforme mostrado na \\nSeção 4.4.2\\n, calcular o novo estado de crença após uma ação e subsequente\\npercepção, é feito em duas etapas. A primeira etapa calcula o estado de crença após a ação, assim\\ncomo para o agente sem sensor:\\nonde, como antes, assumimos um estado de crença representado como uma conjunção de literais. A\\nsegunda etapa é um pouco mais complicada. Suponha que os literais de percepção \\np\\n1\\n,…, \\np\\nk\\n sejam\\nrecebidos. Pode-se pensar que seja simplesmente necessário adicioná-los ao estado de crença; de\\nfato, pode-se também inferir que as precondições de atividade sensorial estão satisfeitas. Agora, se', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 498}),\n",
       " Document(page_content='uma percepção \\np\\n tem exatamente um axioma de percepção, \\nPercepção\\n(\\np\\n, PRECOND:\\nc\\n), onde \\nc\\n é\\numa conjunção de literais, então esses literais podem ser jogados no estado de crença juntamente\\ncom \\np\\n. Por outro lado, se \\np\\n tiver mais que um axioma de percepção cujas precondições podem ser\\nválidas de acordo com o estado de crença predito \\n, então teremos que adicioná-los na \\ndisjunção\\n das\\nprecondições. Obviamente, isso leva o estado de crença não estar em 1-FNC e traz à tona as mesmas\\ncomplicações dos efeitos condicionais, com as mesmas classes de soluções.\\nDado um mecanismo para o cálculo exato ou aproximado dos estados de crença, podemos gerar\\nplanos contingentes, com uma extensão da busca para a frente E-OU sobre os estados de crença\\nutilizados na \\nSeção 4.4\\n. Ações com efeitos não determinísticos — que são definidos simplesmente\\nusando uma disjunção no EFEITO do esquema de ação — podem ser acomodados com pequenas\\nalterações para o cálculo de atualização do estado de crença e nenhuma mudança para o algoritmo de\\nbusca.\\n2\\n Para a função heurística, muitos dos métodos sugeridos para o planejamento sem sensor\\ntambém são aplicáveis \\u200b\\u200bnos casos parcialmente observáveis, não determinísticos.\\n11.3.3 Replanejamento on-line\\nImagine assistir a um robô de soldagem por pontos em uma fábrica de automóveis. Os movimentos\\nrápidos e precisos do robô são repetidos inúmeros vezes à medida que cada carro passa pela linha.\\nEmbora tecnicamente impressionante, o robô provavelmente não parece de todo \\ninteligente\\n porque o\\nmovimento é uma sequência fixa, pré-programada; o robô obviamente não “sabe o que está fazendo”\\nem qualquer sentido significativo. Agora, suponha que uma porta mal colocada caia do carro quando\\no robô está prestes a aplicar um ponto de solda. O robô rapidamente substitui seu atuador de solda\\ncom uma pinça, pega a porta, verifica se há arranhões, recoloca-a no carro, envia um e-mail para o\\nsupervisor da fábrica, volta para o atuador de solda e retoma seu trabalho. De repente, o\\ncomportamento do robô parece \\nintencional\\n, em vez de mecânico; assumimos que ele não resulta de\\num plano contingente amplo e pré-calculado, mas de um processo de replanejamento on-line — o que\\nsignifica que o robô precisa saber o que está tentando fazer.\\nO replanejamento pressupõe alguma forma de monitoramento de execução para determinar a\\nnecessidade de um plano novo. Tal necessidade surge quando um agente de planejamento se cansa de\\nplanejar todas as pequenas contingências, como se o céu pudesse cair em sua cabeça.\\n3\\n Algumas\\nramificações de um plano contingente parcialmente construído podem dizer simplesmente\\nReplanejar\\n; se tal ramificação for atingida durante a execução, o agente reverte para o modo de\\nplanejamento. Como mencionamos anteriormente, a decisão sobre o quanto o problema deve ser\\nresolvido por antecipação e o quanto deve ser deixado para replanejamento é a que envolve\\nnegociação entre os eventos possíveis com custos diferentes e probabilidade de ocorrer. Ninguém\\nquer que seu carro quebre no meio do deserto do Saara para só então pensar em ter água suficiente.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 499}),\n",
       " Document(page_content='Figura 11.9\\n Antes da execução, o planejador vem com um plano, chamado de \\nplano total\\n, para ir de\\nS\\n para \\nG\\n. O agente executa as etapas do plano até que espera estar no estado \\nE\\n, mas observa que na\\nverdade está em \\nO\\n. O agente então replaneja o reparo mínimo mais a continuação para alcançar \\nG\\n.\\nO replanejamento também pode ser necessário se o modelo do mundo do agente estiver incorreto.\\nO modelo de uma ação pode ter uma \\nprecondição ausente\\n — por exemplo, o agente pode não saber\\nque muitas vezes é necessário uma chave de fenda para remover a tampa de uma lata de tinta; o\\nmodelo pode ter um \\nefeito ausente\\n — por exemplo, a pintura de um objeto pode também significar\\ntinta no chão; ou o modelo pode ter uma \\nvariável de estado ausente\\n — por exemplo, o modelo dado\\nanteriormente não tinha noção da quantidade de tinta em uma lata, de como suas ações afetam esse\\nvalor ou da necessidade da quantidade ser diferente de zero. O modelo pode também não ter\\nprovisão para \\neventos exógenos\\n, como alguém derrubar a lata de tinta. Os eventos exógenos podem\\ntambém incluir mudanças no objetivo, como a adição do requisito de que a mesa e a cadeira não\\nsejam pintadas de preto. Sem a capacidade de monitorar e replanejar, o comportamento de um agente\\né suscetível de ser extremamente frágil se confiar na correção absoluta de seu modelo.\\nO agente on-line tem a escolha de como monitorar o ambiente cuidadosamente. Distinguimos três\\nníveis:\\n•  \\nMonitoramento da ação\\n: antes de executar uma ação, o agente verifica se todas as precondições\\nsão válidas.\\n•  \\nMonitoramento do plano\\n: antes de executar uma ação, o agente verifica se o restante do plano\\nainda vai ter sucesso.\\n•  \\nMonitoramento do objetivo\\n: antes de executar uma ação, o agente verifica se há um conjunto\\nmelhor de objetivos que poderia tentar alcançar.\\nNa \\nFigura 11.9\\n, observamos um esquema de monitoramento de ações. O agente mantém o controle\\nde ambos os planos originais, o \\nplano total\\n, e a parte do plano que não foi executada ainda, a qual é\\nindicada por \\nplano\\n. Depois de executar as primeiros passos do plano, o agente espera estar no\\nestado \\nE\\n. Mas o agente observa que está na verdade no estado \\nO\\n. Então precisa reparar o plano\\nencontrando algum ponto \\nP\\n no plano original para o qual possa voltar (pode ser que \\nP\\n seja o estado\\nobjetivo, \\nG\\n). O agente tenta minimizar o custo total do plano: a parte de reparo (de \\nO\\n para \\nP\\n) além\\nda continuação (de \\nP\\n para \\nG\\n).\\nAgora vamos voltar para o problema do exemplo de conseguir uma cadeira e mesa da mesma cor.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 500}),\n",
       " Document(page_content='Suponha que o agente venha com esse plano:\\nAgora, o agente está pronto para executar o plano. Suponha que o agente observe que a mesa e a\\nlata de tinta são brancos e a cadeira é preta. Então executa \\nPintar\\n(\\nCadeira, Lata\\n1\\n). Nesse ponto, um\\nplanejador clássico declararia sucesso, o plano foi executado. Mas uma execução on-line\\nmonitorando o agente precisa verificar as precondições dos planos vazios restantes — que a mesa e\\na cadeira são da mesma cor. Suponha que o agente perceba que elas não têm a mesma cor — de fato,\\na cadeira agora tem um cinza manchado porque a tinta preta está aparecendo. O agente, então, precisa\\ndescobrir uma posição no \\nplano total\\n a atingir e uma sequência de ações de reparo para chegar lá. O\\nagente percebe que o estado atual é idêntico à precondição antes da ação \\nPintar\\n(\\nCadeira, Lata\\n1\\n),\\nentão escolhe uma sequência vazia para \\nreparo\\n e faz com que seu \\nplano\\n seja a mesma sequência\\n[\\nPintura\\n] que ele tinha acabado de tentar. Com esse novo plano em prática, reinicia o controle da\\nexecução, e a ação \\nPintar\\n é repetida. Esse comportamento se repetirá até que seja percebido que a\\ncadeira está totalmente pintada. Mas note que o laço foi criado por um processo de planejar-\\nexecutar-replanejar, em vez de por um laço explícito em um plano. Observe também que o plano\\noriginal não precisa tratar cada contingência. Se o agente atingir o passo marcada como\\nREPLANEJAR, ele pode gerar um novo plano (talvez envolvendo \\nLata\\n2\\n).\\nO monitoramento de ações é um método simples de monitoramento de execução, mas às vezes\\npode conduzir a um comportamento menos inteligente. Por exemplo, suponha que não haja tinta preta\\nou branca, e o agente construa um plano para resolver o problema da pintura pintando a mesa e a\\ncadeira de vermelho. Suponha que haja apenas tinta vermelha suficiente para a cadeira. Com o\\nmonitoramento de ação, o agente poderia ir em frente e pintar a cadeira de vermelho; em seguida,\\nperceberia que a tinta tinha acabado e não poderia pintar a mesa, nesse ponto teria que replanejar um\\nreparo — talvez pintando tanto a cadeira como a mesa de verde. Um agente de monitoramento de\\nplano pode detectar falha sempre que o estado atual é tal que o plano restante não funciona mais.\\nAssim, não vai perder tempo pintando a cadeira de vermelho. O controle de plano consegue isso\\nverificando o sucesso das precondições de todo o plano restante, isto é, as precondições de cada\\npasso no plano, exceto as que são atingidas por outro passo do plano restante. O monitoramento do\\nplano corta a execução de um plano condenado o mais rapidamente possível, em vez de continuar até\\nque a falha realmente ocorra.\\n4\\n O monitoramento do plano também permite \\ndescobertas ao acaso\\n —\\nsucesso acidental. Se alguém chega e pinta a mesa de vermelho ao mesmo tempo em que o agente está\\npintando a cadeira de vermelho, então as precondições do plano final são satisfeitas (o objetivo foi\\nalcançado), e o agente pode ir para casa mais cedo.\\nÉ fácil modificar um algoritmo de planejamento para que cada ação no plano seja anotada com as\\nprecondições da ação, possibilitando assim o monitoramento da ação. É um pouco mais complexo\\npermitir o monitoramento do plano. Planejadores de ordem parcial e planejamento em grafo têm a\\nvantagem de já ter construído estruturas que contêm as relações necessárias para o monitoramento do', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 501}),\n",
       " Document(page_content='plano. Os planejadores estendidos com anotações necessárias podem ser feitos com um\\narmazenamento cuidadoso à medida que o fluente objetivo é regredido através do plano.\\nAgora que descrevemos um método para monitoramento e replanejamento, é necessário perguntar:\\n“Isso funciona?” Essa é uma pergunta surpreendentemente complicada. Se quisermos dizer “Pode-se\\ngarantir que o agente sempre atingirá o objetivo?”, a resposta é não, porque o agente poderia chegar\\ninadvertidamente a um beco sem saída, do qual não há reparo. Por exemplo, o agente do aspirador de\\npó pode ter um modelo defeituoso de si mesmo e não saber que suas baterias podem esgotar-se. Uma\\nvez esgotadas, não é possível reparar quaisquer planos. Se descartarmos os becos sem saída —\\nsuponha que exista um plano para alcançar o objetivo de \\nqualquer\\n estado no ambiente — e suponha\\nainda que o ambiente é realmente não determinístico, no sentido de que tal plano tem sempre \\nalguma\\nchance de sucesso em qualquer tentativa de execução dada, então eventualmente o agente vai atingir o\\nobjetivo.\\nO problema ocorre quando uma ação não é realmente não determinística, mas depende de alguma\\nprecondição que o agente não conhece. Por exemplo, às vezes, uma lata de tinta pode estar vazia,\\nentão a tinta dessa lata não tem efeito. Nenhuma quantidade de novas tentativas vai modificar isso.\\n5\\nUma solução é escolher aleatoriamente entre o conjunto de planos de reparo possível, em vez de\\ntentar o mesmo a cada vez. Nesse caso, o plano de reparo de abrir outra lata poderá funcionar. Uma\\nabordagem melhor é \\naprender\\n um modelo melhor. Toda previsão de falha é uma oportunidade de\\naprendizagem; um agente deveria ser capaz de modificar seu modelo do mundo de acordo com sua\\npercepção. A partir de então, o replanejador será capaz de chegar a um reparo que chegue à raiz do\\nproblema, em vez de confiar na sorte para escolher um bom reparo. Esse tipo de aprendizagem será\\ndescrito nos Capítulos 18 e 19.\\n11.4 PLANEJAMENTO MULTIAGENTE\\nAté agora, assumimos que apenas um agente está fazendo a percepção, o planejamento e a ação.\\nQuando existem múltiplos agentes no ambiente, cada agente enfrenta um \\nproblema de planejamento\\nmultiagente\\n no qual tenta alcançar seus próprios objetivos com a ajuda ou o impedimento de outros.\\nEntre o agente puramente único e os casos verdadeiramente de multiagentes existe um amplo\\nespectro de problemas que exibem vários graus de decomposição do agente monolítico. Um agente\\ncom múltiplos atuadores que podem operar simultaneamente — por exemplo, um humano que\\nconsegue digitar e falar ao mesmo tempo — necessita fazer \\nplanejamento multi-atuador\\n para gerir\\ncada atuador enquanto trata interações positivas e negativas entre os atuadores. Quando os atuadores\\nestão dissociados fisicamente em unidades separadas — como em uma frota de robôs de entrega em\\numa fábrica —, o planejamento multi-atuador torna-se o \\nplanejamento multicorpo\\n. Um problema\\nmulticorpo ainda é um problema de agente único “padrão”, desde que as informações relevantes\\nsensoriais obtidas por cada corpo possam ser agrupadas — centralmente ou em cada corpo — para\\nformar uma estimativa comum do estado do mundo que então informa a execução do plano global;\\nnesse caso, os múltiplos corpos atuam como um único corpo. Quando as restrições de comunicação\\ntornam isso impossível, temos o que é chamado às vezes de problema de \\nplanejamento\\ndescentralizado\\n; este é talvez um equívoco porque a fase de planejamento é centralizada, mas a fase', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 502}),\n",
       " Document(page_content='de execução é, pelo menos parcialmente, dissociada. Nesse caso, o subplano construído para cada\\ncorpo pode necessitar incluir ações de comunicação explícitas com outros corpos. Por exemplo, os\\nrobôs de reconhecimento múltiplo que cobrem uma área ampla podem estar muitas vezes fora de\\ncontato por rádio com os outros e devem compartilhar suas descobertas durante as vezes em que a\\ncomunicação é viável.\\nQuando uma única entidade está fazendo o planejamento, há realmente apenas um objetivo que\\ntodos os corpos compartilham necessariamente. Quando os corpos são agentes distintos que fazem\\nseu próprio planejamento, eles ainda podem compartilhar objetivos idênticos, por exemplo, dois\\ntenistas humanos que formam uma dupla compartilham o objetivo de ganhar a partida. Mesmo com\\nobjetivos comuns, no entanto, os casos de multicorpos e multiagentes são bastante diferentes. Em uma\\nequipe de duplas multicorpo robótico, um plano único dita que corpo vai para qual lugar na quadra e\\nque corpo vai bater na bola. Em times de duplas multiagentes, por outro lado, cada agente decide o\\nque fazer; sem um método de \\ncoordenação\\n, ambos os agentes podem decidir cobrir a mesma parte da\\nquadra e cada um pode deixar a bola para o outro bater.\\nO caso mais claro de um problema multiagente, certamente, é quando os agentes têm objetivos\\ndiferentes. No tênis, os objetivos de dois times opostos estão em conflito direto, levando à situação\\nde soma zero do Capítulo 5. Os espectadores poderão ser vistos como agentes se seu apoio ou\\nindiferença for um fator significativo e puder ser influenciado pela conduta dos jogadores; caso\\ncontrário, eles podem ser tratados como um aspecto da natureza — assim como o clima —, que se\\npresume ser indiferente às intenções dos jogadores.\\n6\\nFinalmente, alguns sistemas são uma mistura de planejamento centralizado e multiagentes. Por\\nexemplo, uma empresa de entrega pode fazer um planejamento centralizado e \\noff-line\\n para as rotas de\\nseus caminhões e aviões a cada dia, mas deixar alguns aspectos abertos para decisões autônomas por\\nmotoristas e pilotos que possam responder individualmente às situações de tráfego e às condições\\nmeteorológicas. Além disso, os objetivos da empresa e de seus funcionários são ajustados, até certo\\nponto, mediante o pagamento de \\nincentivos\\n (salários e bônus) — um sinal claro de que esse é um\\nsistema multiagente de verdade.\\nAs questões envolvidas no planejamento multiagente podem ser divididas basicamente em dois\\nconjuntos. O primeiro, abrangido na \\nSeção 11.4.1\\n, envolve questões de representação e planejamento\\npara múltiplas ações simultâneas; esses problemas ocorrem em todas as configurações de\\nplanejamento multi-atuadores e multiagente. O segundo, abrangido na \\nSeção 11.4.2\\n, envolve questões\\nde cooperação, coordenação e concorrência resultantes de ambientes multiagentes de verdade.\\n11.4.1 Planejamento com várias ações simultâneas\\nPor enquanto, vamos tratar as configurações multi-atuadores, multicorpo e multiagente da mesma\\nforma, rotulando genericamente como configurações \\nmultiatores\\n, utilizando o termo genérico \\natores\\npara abranger atuadores, corpos e agentes. O objetivo desta seção é desenvolver como definir\\nmodelos de transição, planos corretos e algoritmos eficientes de planejamento para a configuração\\nmultiatores. Um plano correto é aquele que, se executado por atores, alcança o objetivo (certamente,\\nna configuração multiagente verdadeira, os agentes não podem concordar em executar qualquer plano', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 503}),\n",
       " Document(page_content='particular, mas pelo menos sabem que planos funcionariam se concordassem em executá-los). Para\\nsimplificar, assumimos a \\nsincronização\\n perfeita: cada ação leva a mesma quantidade de tempo, e\\nações em cada ponto do plano conjunto são simultâneas.\\nComeçamos com o modelo de transição; para o caso determinístico, essa é a função\\nRESULTADO(\\ns\\n, \\na\\n). No cenário de agente único, pode haver \\nb\\n escolhas diferentes para a ação; \\nb\\npode ser muito grande, especialmente para as representações de primeira ordem com muitos objetos\\npara influenciar; no entanto, os esquemas de ação fornecem uma representação concisa. No cenário\\nmultiatores com \\nn\\n atores, a única ação \\na\\n é substituída por uma \\nação conjunta\\n <\\na\\n1\\n,…, \\na\\nn\\n>, onde a\\ni\\n é a\\nação tomada pelo \\ni-\\nésimo ator. Imediatamente, vemos dois problemas: primeiro, temos que\\ndescrever o modelo de transição para \\nb\\nn\\n diferentes ações conjuntas; em segundo lugar, temos um\\nproblema de planejamento conjunto com um fator de ramificação de \\nb\\nn\\n.\\nAo colocar atores juntos em um sistema multiator com um enorme fator de ramificação, o foco\\nprincipal da pesquisa sobre planejamento multiatores tem sido \\ndesacoplar\\n os atores na medida do\\npossível, para que a complexidade do problema cresça linearmente com \\nn\\n, em vez de\\nexponencialmente. Se os atores \\nnão têm interação\\n uns com os outros — por exemplo, \\nn\\n atores, cada\\num jogando paciência —, então podemos simplesmente resolver \\nn\\n problemas distintos. Se os atores\\nforem de \\nbaixo acoplamento,\\n podemos conseguir algo próximo a essa melhoria exponencial?\\nNaturalmente, essa é uma questão central em muitas áreas de IA. Vimos isso explicitamente no\\ncontexto de CSPs, onde os grafos de restrição do “tipo árvore” renderam métodos de solução\\neficientes, bem como o contexto de bancos de dados-padrão disjuntos e a heurística aditiva de\\nplanejamento.\\nA abordagem-padrão para os problemas de baixo acoplamento é fingir que os problemas são\\ncompletamente dissociados e, em seguida, arrumar as interações. Para o modelo de transição, isso\\nsignifica escrever esquemas de ação, como se os atores atuassem de forma independente. Vamos ver\\ncomo isso funciona para o problema das duplas de tênis. Vamos supor que, em um ponto do jogo, o\\nobjetivo da equipe seja devolver a bola que foi jogada para ela e garantir que pelo menos um deles\\nestará cobrindo a rede.\\nA primeira passagem para uma definição multiatores poderia parecer como na \\nFigura 11.10\\n. Com\\nessa definição, é fácil verificar que o seguinte \\nplano conjunto\\n funciona:\\n    \\nAtores\\n(\\nA, B\\n)\\n    \\nInício\\n(\\nEm\\n (\\nA, LinhaDeFundoEsquerda\\n) \\n∧\\n \\nEm\\n(\\nB, RedeDireita\\n) \\n∧\\n        \\nAproximando\\n(\\nBola, LinhaDeFundoDireita\\n)) \\n∧\\n \\nParceiro\\n(\\nA, B\\n) \\n∧\\n \\nParceiro\\n(\\nB, A\\n)\\n    \\nObjetivo\\n(\\nRetornada\\n(\\nBola\\n) \\n∧\\n (\\nEm\\n(\\na, RedeDireita\\n) \\n∧\\n \\nEm\\n(\\na, RedeEsquerda\\n))\\n    \\nAção\\n (\\nBater\\n((\\nator, Bola\\n))\\n,\\n        PRECOND: \\nAproximando\\n(\\nBola, loc\\n) \\n∧\\n \\nEm\\n(\\nator, loc\\n)\\n        EFEITO: \\nDevolvida\\n(\\nBola\\n))\\n    \\nAção\\n(\\nIr\\n(\\nator, para\\n)\\n,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 504}),\n",
       " Document(page_content='PRECOND: \\nEm\\n(\\nator, loc\\n) \\n∧\\n \\npara ≠ loc,\\n        EFEITO: \\nEm\\n(\\nator, para\\n) \\n∧\\n \\n¬Em\\n(\\nator, loc\\n))\\nFigura 11.10\\n O problema de duplas no tênis. Dois atores \\nA\\n e \\nB\\n estão jogando juntos e podem estar\\nem um de quatro locais: \\nLinhaDeFundoEsquerda\\n, \\nLinhaDeFundoDireita\\n, \\nRedeEsquerda\\n e\\nRedeDireita\\n. A bola só poderá ser retornada se o jogador estiver no lugar certo. Note que cada ação\\ndeve incluir o ator como um argumento.\\nEntretanto, os problemas surgem quando um plano tem os dois agentes batendo na bola, ao mesmo\\ntempo. No mundo real, isso não vai funcionar, mas o esquema de ação para \\nBater\\n diz que a bola será\\ndevolvida com sucesso. Tecnicamente, a dificuldade é que as precondições restringem o \\nestado\\n em\\nque uma ação pode ser executada com êxito, mas não restringem outras ações que podem atrapalhar.\\nResolvemos isso aumentando os esquemas de ação com um novo recurso: a \\nlista de ação\\nconcorrente\\n indicando quais ações devem ou não ser executadas simultaneamente. Por exemplo, a\\nação \\nBater\\n poderia ser descrita da seguinte forma:\\nEm outras palavras, a ação \\nBater\\n tem seu efeito expresso apenas se não ocorrer por outro agente\\noutra ação \\nBater\\n ao mesmo tempo (na abordagem SATPLAN, seria manipulado por um \\naxioma de\\nexclusão de ação\\n parcial). Para algumas ações, o efeito desejado é alcançado \\nsomente\\n quando outra\\nação ocorre simultaneamente. Por exemplo, são necessários dois agentes para transportar uma\\ngeladeira cheia de bebidas para a quadra de tênis:\\nCom esses tipos de esquemas de ação, qualquer um dos algoritmos de planejamento descritos no\\nCapítulo 10 pode ser adaptado com apenas pequenas modificações para gerar planos multiatores. Na\\nmedida em que o acoplamento entre os subplanos está solto — o que significa que as restrições de\\nconcorrência são considerados apenas raramente durante a busca do plano —, espera-se que as\\nvárias heurísticas derivadas do planejamento de agente único sejam também eficazes no contexto\\nmultiator. Poderíamos estender essa abordagem com os refinamentos dos dois últimos capítulos —\\nHTNs, observabilidade parcial, condicionais, monitoramento de execução e replanejamento —, mas\\nisso está fora do escopo deste livro.\\n11.4.2 Planejamento com múltiplos agentes: cooperação e coordenação', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 505}),\n",
       " Document(page_content='Agora vamos considerar o verdadeiro cenário multiagente em que cada agente faz o seu próprio\\nplano. Para começar, vamos supor que os objetivos e a base do conhecimento sejam compartilhados.\\nPode-se pensar que isso se reduz ao caso de multicorpo — cada agente simplesmente calcula a\\nsolução conjunta e executa sua própria parte dessa solução. Infelizmente, o “\\na\\n” em “\\na solução\\nconjunta\\n” é enganoso. Para a nossa equipe de duplas, existe mais do que uma solução conjunta:\\nSe ambos os agentes podem concordar com o plano 1 ou o plano 2, o objetivo será alcançado.\\nMas, se \\nA\\n escolher o plano 2 e \\nB\\n escolher o plano 1, ninguém vai devolver a bola. Por outro lado, se\\nA\\n escolher 1 e \\nB\\n escolher 2, ambos vão tentar acertar a bola. Os agentes podem perceber isso, mas\\ncomo podem coordenar isso para se certificar de que concordam com o plano?\\nUma opção é adotar uma \\nconvenção\\n antes de se envolver em atividade conjunta. A convenção é\\nqualquer restrição sobre a seleção de planos conjuntos. Por exemplo, a convenção “permanecer em\\num lado da quadra” descartaria o plano 1, fazendo com que os parceiros de duplas escolhessem o\\nplano 2. Os motoristas em uma estrada enfrentam o problema de não colidir uns com os outros, o que\\né (parcialmente) resolvido adotando a convenção “ficar no lado direito da estrada”; na maioria dos\\npaíses, a alternativa, “ficar no lado esquerdo” funciona igualmente bem desde que todos os agentes\\nestejam de acordo em um ambiente. No desenvolvimento da linguagem humana aplicam-se\\nconsiderações similares, onde o importante não é qual idioma cada indivíduo deve falar, mas o fato\\nde toda uma comunidade falar o mesmo idioma. Quando as convenções são comuns, são chamadas de\\nleis sociais\\n.\\nNa ausência de uma convenção, os agentes podem utilizar a \\ncomunicação\\n para atingir\\nconhecimentos comuns de um plano conjunto viável. Por exemplo, um jogador de tênis poderia gritar\\n“Meu!” ou “Seu!” para indicar a preferência de um plano conjunto. Vamos cobrir os mecanismos de\\ncomunicação com mais profundidade no Capítulo 22, onde observaremos que a comunicação não\\nenvolve necessariamente uma troca verbal. Por exemplo, um jogador pode comunicar a preferência\\nde um plano conjunto com o outro simplesmente ao executar a primeira parte dele. Se o agente \\nA\\n for\\npara a rede, o agente \\nB\\n será obrigado a ir para a linha de fundo para bater a bola porque o plano 2 é\\no único plano conjunto que começa com \\nA\\n indo para a rede. Essa abordagem de coordenação, às\\nvezes chamada de \\nreconhecimento do plano\\n, funciona quando uma única ação (ou uma curta\\nsequência de ações) é suficiente para determinar um plano conjunto de forma inequívoca. Observe\\nque a comunicação pode funcionar tão bem com agentes competitivos como com os cooperativos.\\nAs convenções podem também surgir através de processos evolutivos. Por exemplo, formigas\\nceifadeiras comedoras de sementes são criaturas sociais que evoluíram a partir das vespas, que são\\nmenos sociais. As colônias de formigas executam planos conjuntos muito elaborados sem qualquer\\ncontrole centralizado — o trabalho da rainha é de reproduzir, não de fazer planejamento centralizado\\n— e com cada formiga com capacidade limitada de cálculo, comunicação e memória (Gordon, 2000,\\n2007). A colônia tem muitos papéis, incluindo os trabalhadores do interior, patrulheiros e\\nexploradores que buscam as sementes. Cada formiga escolhe desempenhar um papel de acordo com\\nas condições locais que ela observa. Por exemplo, as exploradoras viajam para longe do ninho, em', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 506}),\n",
       " Document(page_content='busca de uma semente, e, quando encontram uma, trazem-na de volta imediatamente. Assim, a taxa\\npela qual as exploradoras retornam ao ninho é uma aproximação da disponibilidade de alimentos\\ndiária. Quando a taxa é alta, outras formigas abandonam sua função atual e assumem o papel de\\nescavadeiras. As formigas parecem ter uma convenção sobre a importância dos papéis — o\\nexplorador é o mais importante —, e as formigas facilmente alternam nos papéis mais importantes,\\nmas não nos menos importantes. Existe algum mecanismo de aprendizagem: uma colônia aprende a\\nfazer ações mais bem-sucedidas e prudentes ao longo do curso de sua vida de décadas, embora as\\nformigas individuais vivam apenas cerca de um ano.\\nUm último exemplo de comportamento multiagente cooperativo aparece no comportamento de um\\nbando de aves. Podemos obter uma simulação razoável de um bando se cada agente ave (algumas\\nvezes chamado de \\nboid\\n) observar as posições dos seus vizinhos mais próximos e depois escolher a\\ndireção e a aceleração que maximizam a soma ponderada desses três componentes:\\n1. Coesão: uma pontuação positiva por se aproximar da posição média dos vizinhos\\n2. Separação: uma pontuação negativa por chegar muito perto de qualquer vizinho\\n3. Alinhamento: uma pontuação positiva por se aproximar da direção média dos vizinhos\\nSe todos os \\nboids\\n executarem essa política, o bando apresentará o \\ncomportamento emergente\\n de\\nvoar como um corpo pseudorrígido com densidade mais ou menos constante que não se dispersa ao\\nlongo do tempo e que, ocasionalmente, faz movimentos repentinos de arremesso. Você pode ver uma\\nimagem na \\nFigura 11.11\\n(a) e compará-la com um rebanho real em (b). Tal como acontece com as\\nformigas, não há necessidade de cada agente possuir um plano conjunto que modele as ações de\\noutros agentes.\\nOs problemas multiagentes mais difíceis envolvem tanto a cooperação com os membros da própria\\nequipe como a competição com os membros de equipes adversárias, tudo sem controle centralizado.\\nVemos isso em jogos, como futebol robótico ou no jogo NERO, mostrado na \\nFigura 11.11\\n(c), em que\\nduas equipes de agentes de software competem para capturar as torres de controle. Os métodos de\\nplanejamento eficaz nesse tipo de ambientes — por exemplo, tirar vantagem de acoplamentos fracos\\n— estão ainda engatinhando.\\nFigura 11.11\\n (a) Um bando de aves simulado, utilizando o modelo \\nboids\\n de Reynold. Cortesia da\\nimagem de Giuseppe Randazzo, novastructura.net. (b) Um bando de estorninhos reais. Imagem de\\nEduardo (\\npastaboy sleeps on a flickr\\n). (c) Duas equipes competitivas de agentes tentando capturar as\\ntorres no jogo NERO. Imagem cedida por Risto Miikkulainen.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 507}),\n",
       " Document(page_content='11.5 RESUMO\\nEste capítulo examinou algumas das complicações do planejamento e da ação no mundo real. Os\\npontos mais importantes são:\\n•  Muitas ações consomem \\nrecursos\\n, como dinheiro, gás ou matérias-primas. É conveniente tratar\\nesses recursos como medidas numéricas em um \\npool\\n, em vez de tentar raciocinar, digamos, sobre\\ncada moeda e cada cédula individual existente no mundo. As ações podem gerar e consumir\\nrecursos, e normalmente é econômico e eficiente verificar se os planos parciais satisfazem as\\nrestrições de recursos, antes de tentar realizar aprimoramentos adicionais.\\n•  O tempo é um dos recursos mais importantes. Ele pode ser manipulado por algoritmos\\nespecializados de escalonamento ou o escalonamento pode ser integrado ao planejamento.\\n•  O planejamento de \\nrede de tarefas hierárquicas\\n (HTN) permite ao agente receber conselhos do\\nprojetista de domínio, sob a forma de ações de alto nível (HLAs), que podem ser implementadas\\nde várias formas por sequências de ações de baixo nível. Os efeitos das HLAs podem ser\\ndefinidos com \\nsemânticas angélicas\\n, permitindo provavelmente que sejam derivados planos\\ncorretos de alto nível sem considerar as implementações de mais baixo nível. Métodos HTN\\npodem criar os planos realmente grandes exigidos por muitas aplicações do mundo real.\\n•  Algoritmos de planejamento-padrão assumem informações completas e corretas em ambientes\\ndeterminísticos totalmente observáveis. Muitos domínios violam essa suposição.\\n•  Os \\nplanos contingentes\\n permitem que o agente sinta o mundo durante a execução para decidir\\nque ramo do plano seguir. Em alguns casos, o \\nplanejamento sem sensor ou de conformidade\\npode ser utilizado para construir um plano que funcione sem a necessidade de percepção. Tanto\\no plano de conformidade como de contingência podem ser construídos pela busca no espaço de\\nestados de crença\\n. A representação ou a computação eficiente dos estados de crença é um\\nproblema-chave.\\n•  Um \\nagente de planejamento on-line\\n utiliza monitoramento de execução e reparos quando\\nnecessário para se recuperar de situações inesperadas que podem ser devidas a ações não\\ndeterminísticas, eventos exógenos ou modelos incorretos do meio ambiente.\\n•  O planejamento \\nmultiagente\\n é necessário quando existem outros agentes no ambiente com os\\nquais cooperar ou competir. Podem ser construídos planos conjuntos, mas devem ser aumentados\\ncom alguma forma de coordenação se dois agentes tiverem que concordar sobre qual plano\\nconjunto executar.\\n•  Este capítulo estende o planejamento clássico para abranger ambientes não determinísticos (em\\nque os resultados das ações são incertos), mas não é a última palavra em planejamento. O\\nCapítulo 17 descreve as técnicas para ambientes estocásticos (em que os resultados das ações\\ntêm probabilidades associadas a elas): processos markovianos de decisão, parcialmente\\nobserváveis e teoria dos jogos. No Capítulo 21, mostraremos que o aprendizado por reforço\\npermite a um agente aprender como se comportar com os sucessos e fracassos do passado.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 508}),\n",
       " Document(page_content='O planejamento com restrição de tempo foi tratado inicialmente pelo DEVISER (Vere, 1983). A\\nrepresentação de tempo em planos foi tratada por Allen (1984) e por Dean \\net al\\n. (1990) no sistema\\nFORBIN. O NONLIN+ (Tate e Whiter, 1984) e o SIPE (Wilkins, 1988, 1990) eram capazes de\\nraciocinar sobre a alocação de recursos limitados para vários passos de plano. O O-PLAN (Bell e\\nTate, 1985), um planejador de HTN, tinha uma representação uniforme e geral para restrições sobre\\ntempo e recursos. Além da aplicação da Hitachi mencionada no texto, o O-PLAN tem sido aplicado\\nao planejamento de compra de software na Price Waterhouse e ao planejamento da montagem do eixo\\ntraseiro dos automóveis da Jaguar Cars.\\nOs dois planejadores SAPA (Do e Kambhampati, 2001) e T4 (Haslum e Geffner, 2001) utilizam a\\nbusca direta em espaço de estados com heurísticas sofisticadas para manipular ações com durações\\nde tempo e recursos. Uma alternativa é usar linguagens de ação muito expressivas, mas orientá-las\\npor heurísticas específicas de domínios escritas por seres humanos, como foi feito no caso do\\nASPEN (Fukunaga \\net al\\n., 1997), do HSTS (Jonsson \\net al\\n., 2000) e do IxTeT (Ghallab e Laruelle,\\n1994).\\nVários sistemas híbridos de planejamento e escalonamento foram implantados: o ISIS (Fox \\net al\\n.,\\n1982;. Fox, 1990) tem sido usado para escalonamento de linha de produção na Westinghouse, o\\nGARI (Descotte e Latombe, 1985) planejou a construção de partes mecânicas, o Forbin foi usado\\npara o controle da fábrica e o NONLIN+ foi usado para o planejamento de logística naval.\\nEscolhemos apresentar planejamento e escalonamento como dois problemas distintos; Cushing \\net al\\n.\\n(2007) mostram que isso pode levar a incompletude sobre determinados problemas. Existe um longo\\nhistórico de escalonamento na indústria aeroespacial. O T-SCHED (Drabble, 1990) foi usado para\\nescalonar sequências de comandos de missões para o satélite UOSAT-II. O OPTIMUM-AIV (Aarup\\net al\\n., 1994) e o PLAN-ERS 1 (Fuchs \\net al\\n., 1990), ambos baseados no O-PLAN, foram usados na\\nmontagem de naves espaciais e em planejamento de observação, respectivamente, na agência\\nespacial europeia. O SPIKE (Johnston e Adorf, 1992) foi empregado para planejamento de\\nobservação na Nasa para o telescópio espacial Hubble, enquanto o Space Shuttle Ground Processing\\nScheduling System (Deale \\net al\\n., 1994) realiza o escalonamento de linha de produção de até 16.000\\ndeslocamentos de trabalhadores. O Remote Agent (Muscettola \\net al\\n., 1998) se tornou o primeiro\\nplanejador-escalonador autônomo a controlar uma nave espacial quando voou a bordo da sonda\\nDeep Space One em 1999. As aplicações espaciais impulsionaram o desenvolvimento de algoritmos\\npara alocação de recursos; consulte Laborie (2003) e Muscettola (2002). A literatura sobre\\nescalonamento é apresentada em um artigo de revisão clássico (Lawler \\net al\\n., 1993), um livro\\nrecente (Pinedo, 2008) e em uma coletânea editada (Blazewicz \\net al\\n., 2007).\\nA capacidade do programa STRIPS para aprendizado de \\nmacrops\\n — “macro-operadores” que\\nconsistiam em uma sequência de passos primitivos — pode ser considerado o primeiro mecanismo\\npara planejamento hierárquico (Fikes \\net al\\n., 1972). A hierarquia também foi usada no sistema\\nLAWALY (Siklossy e Dreussi, 1973). O sistema ABSTRIPS (Sacerdoti, 1974) introduziu a ideia de\\numa \\nhierarquia de abstração\\n, por meio da qual o planejamento em níveis mais altos podia ignorar\\nprecondições de ações de nível mais baixo com a finalidade de derivar a estrutura geral de um plano\\nviável. A tese de doutorado de Austin Tate (1975b) e o trabalho de Earl Sacerdoti (1977)\\ndesenvolveram as ideias básicas do planejamento de HTN em sua forma moderna. Muitos\\nplanejadores práticos, incluindo o O-PLAN e o SIPE, são planejadores de HTN. Yang (1990)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 509}),\n",
       " Document(page_content='descreve propriedades de ações que tornam eficiente o planejamento de HTN. Erol, Hendler e Nau\\n(1994, 1996) apresentam um planejador de decomposição hierárquica completo, bem como uma\\nvariedade de resultados de complexidade para planejadores de HTN puros.\\nNossa apresentação de HTNs e semântica angélica deve-se a Marthi \\net al.\\n (2007, 2008).\\nKambhampati \\net al\\n. (1998) propuseram uma abordagem em que decomposições são apenas outra\\nforma de refinamento do plano, semelhante aos refinamentos de planejamento de ordem parcial não\\nhierárquica.\\nA partir do trabalho em macro-operadores em STRIPS, uma das metas do planejamento\\nhierárquico foi a reutilização da experiência de planejamento anterior, sob a forma de planos\\ngeneralizados. A técnica de \\naprendizado baseado na explicação\\n, descrita em profundidade no\\nCapítulo 19, foi aplicada a vários sistemas como um meio de generalizar planos anteriormente\\ncomputados, inclusive o SOAR (Laird \\net al\\n., 1986) e o PRODIGY (Carbonell \\net al\\n., 1989). Uma\\nabordagem alternativa é armazenar planos anteriormente computados em sua forma original e depois\\nreutilizá-los para resolver por analogia novos problemas semelhantes ao problema original. Essa é a\\nabordagem adotada pelo campo chamado \\nplanejamento baseado em casos\\n (Carbonell, 1983;\\nAlterman, 1988; Hammond, 1989). Kambhampati (1994) argumenta que o planejamento baseado em\\ncasos deve ser analisado como uma forma de planejamento de refinamento e fornece um fundamento\\nformal para o planejamento de ordem parcial baseado em casos.\\nOs primeiros planejadores, não incluem condicionais e laços, mas podiam usar a coerção para\\nformar planos conformantes. O Noah de Sacerdoti resolveu o problema de “chaves e caixas”, um\\ndesafiante problema de planejamento em que o planejador conhece pouco sobre o estado inicial\\nutilizando coerção. Mason (1993) argumenta que, com frequência, o sensoriamento em geral pode e\\ndeve ser dispensada no planejamento de robótica, e descreveu um plano sem sensores capaz de\\nmover uma ferramenta para uma posição específica sobre uma mesa por meio de uma sequência de\\nações, \\nindependentemente\\n da posição inicial.\\nGoldman e Boddy (1996) introduziram o termo \\nconformant planning\\n (planejamento conformante)\\npara planejadores sem sensores que tratam a incerteza pela coerção do mundo em estados\\nconhecidos, observando que os planos sem sensores frequentemente são efetivos, ainda que o agente\\ntenha sensores. O primeiro planejador conformante moderadamente eficiente foi o Conformant\\nGraphplan ou CGP de Smith e Weld (1998). Ferraris e Giunchiglia (2000) e Rintanen (1999)\\ndesenvolveram de forma independente planejadores com conformação baseados no SATPlan. Bonet\\ne Geffner (2000) descrevem um planejador conformante fazendo busca heurística no espaço de\\nestados de crença, com base em ideias iniciais desenvolvidas na década de 1960 para processos\\ndecisórios de Markov parcialmente observáveis, ou POMDPs (veja o Capítulo 17).\\nAtualmente, existem três abordagens principais do planejamento conformante. As duas primeiras\\nutilizam busca heurística no espaço do estado de crença: o HSCP (Bertoli \\net al\\n., 2001a) utiliza\\ndiagramas de decisão binária (BDDs) para representar estados de crença, enquanto Hoffmann e\\nBrafman (2006) adotam a abordagem preguiçosa de cálculo das precondições e dos testes objetivos\\nsobre demanda utilizando solucionadores SAT. A terceira abordagem, defendida principalmente por\\nJussi Rintanen (2007), formula todo o problema de planejamento sem sensores como uma fórmula\\nbooleana quantificada (QBF) e a resolve usando um solucionador QBF de propósito geral. Os\\nplanejadores conformantes atuais têm cinco ordens de grandeza mais rápido do que a do CGP. Em', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 510}),\n",
       " Document(page_content='2006, o vencedor da categoria de planejamento conformante na \\nInternational Planning Competition\\nfoi o \\nT\\n0\\n (Palacios e Geffner, 2007), que usou busca heurística em espaço de estado de crença,\\nenquanto manteve a simples representação do estado de crença pela definição de literais derivados\\nque abrangem efeitos condicionais. Bryce e Kambhampati (2007) discutiram como um grafo de\\nplanejamento pode ser generalizado para gerar uma boa heurística para planejamento conformante e\\ncontingente.\\nTem havido alguma confusão na literatura entre os termos planejamento “condicional” e\\n“contingente”. Seguindo Majercik e Littman (2003), usamos “condicional” para nos referir a um\\nplano (ou ação) que tem efeitos diferentes dependendo do estado atual do mundo, e “contingente”\\npara significar um plano no qual o agente pode escolher diferentes ações dependendo dos resultados\\nda detecção. O problema de planejamento contingente recebeu mais atenção após a publicação do\\nartigo influente de Drew McDermott (1978a), \\nPlanning and Acting\\n.\\nA abordagem do planejamento contingente descrita nesse capítulo foi baseada em Hoffmann e\\nBrafman (2005), influenciada pelos algoritmos de busca eficientes para grafos cíclicos E-OU\\ndesenvolvidos por Jimenez e Torras (2000) e Hansen e Zilberstein (2001). Bertoli \\net al.\\n (2001b)\\ndescreveram o MBP (planejamento baseado em modelo), que utiliza diagramas de decisão binária\\npara fazer planejamento conformante e contingente.\\nEm resumo, agora é possível ver como os principais algoritmos clássicos de planejamento\\nlevaram a versões estendidas de domínios incertos. A busca heurística rápida para a frente através\\ndo espaço de estados conduziu à busca para a frente no espaço de crença (Bonet e Geffner, 2000;\\nHoffman e Brafman, 2005); o SATPLAN resultou no SATPLAN estocástico (Majercik e Littman,\\n2003) e no planejamento com a lógica booleana quantificada (Rintanen, 2007); o planejamento de\\nordem parcial levou ao UWL (Etzioni \\net al\\n., 1992) e ao CNLP (Peot e Smith, 1992). O\\nGRAPHPLAN conduziu ao Sensory Graphplan ou SGP (Weld \\net al\\n., 1998).\\nO primeiro planejamento on-line com monitoramento de execução foi o PLANEX (Fikes \\net al\\n.,\\n1972), que funcionava com o planejador STRIPS para controlar o robô Shakey. O planejador NASL\\n(McDermott, 1978a) tratava um problema de planejamento simplesmente como uma especificação\\npara a execução de uma ação complexa, de forma que a execução e o planejamento ficassem\\ncompletamente unificados.\\nO SIPE (\\nSystem for Interactive Planning and Execution monitoring\\n) (Wilkins, 1988, 1990) foi o\\nprimeiro planejador a lidar sistematicamente com o problema de replanejamento. Ele foi utilizado\\nem projetos de demonstração em vários domínios, inclusive operações de planejamento no convés de\\nvoo de um porta-aviões e no escalonamento de linha de produção de uma fábrica da cerveja\\naustraliana, e planejando a construção de edifícios com várias lojas (Kartam e Levitt, 1990).\\nEm meados da década de 1980, o pessimismo sobre os tempos lentos de execução de sistemas de\\nplanejamento levou à proposta de agentes reflexos chamados sistemas de \\nplanejamento reativo\\n(Brooks, 1986; Agre e Chapman, 1987). O PENGI (Agre e Chapman, 1987) foi capaz de jogar um\\nvideogame (completamente observável) usando circuitos booleanos combinados a uma representação\\n“visual” de objetivos correntes e do estado interno do agente. Os “planos universais” (Schoppers,\\n1987, 1989) foram desenvolvidos como um método de busca em tabelas para planejamento reativo,\\nmas acabaram por se tornar uma redescoberta da ideia de \\npolíticas\\n que foi usada por longo tempo em', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 511}),\n",
       " Document(page_content='processos de decisão de Markov (veja o Capítulo 17). Um plano universal (ou uma política) contém\\num mapeamento de qualquer estado para a ação que deve ser executada nesse estado. Koenig (2001)\\npesquisa técnicas de planejamento on-line sob o nome de \\nAgent-Centered Search\\n.\\nO planejamento multiagente teve um salto de popularidade nos últimos anos, embora tenha uma\\nlonga história. Konolige (1982) formalizou o planejamento multiagente em lógica de primeira ordem,\\nenquanto Pednault (1986) apresentou uma descrição no estilo de STRIPS. A noção de intenção\\nconjunta, essencial se os agentes tiverem de executar um plano conjunto, vem do trabalho em ações\\nde comunicação (Cohen e Levesque, 1990; Cohen \\net al\\n., 1990). Boutilier e Brafman (2001)\\nmostraram como adaptar o planejamento de ordem parcial para um cenário multiator. Brafman e\\nDomshlak (2008) elaboraram um algoritmo de planejamento multiator cuja complexidade cresce\\napenas linearmente com o número de atores, desde que o grau de acoplamento (medido em parte,\\npela \\nlargura da árvore\\n do grafo de interações entre os agentes) é limitado. Petrik e Zilberstein\\n(2009) mostraram que uma abordagem baseada em programação bilinear supera a abordagem \\ncover-\\nset\\n que delineamos nesse capítulo.\\nApenas tocamos a superfície do trabalho sobre negociação em planejamento multiagente. Durfee e\\nLesser (1989) discutem como as tarefas podem ser compartilhadas entre agentes por negociação.\\nKraus \\net al\\n. (1991) descrevem um sistema para jogar Diplomacy, um jogo de tabuleiro que exige\\nnegociação, formação e dissolução de alianças e desonestidade. Stone (2000) mostra como agentes\\npodem cooperar como participantes de equipes no ambiente competitivo, dinâmico e parcialmente\\nobservável do futebol de robôs. Em um artigo posterior, Stone (2003) analisa dois ambientes\\nmultiagentes competitivo — RoboCup, uma competição de futebol de robôs, e TAC, o Trading\\nAgents Competition baseado em leilão —, e descobre que a intratabilidade computacional de nossas\\nabordagens atuais, teoricamente bem fundamentadas, fez com que muitos sistemas multiagentes\\nfossem projetados por métodos \\nad hoc\\n.\\nEm sua teoria altamente influente, \\nSociety of Mind\\n, Marvin Minsky (1986, 2007) expôs que as\\nmentes humanas são construídas de um conjunto de agentes. Livnat e Pippenger (2006) provaram que,\\npara o problema de encontrar o melhor caminho, e dada uma limitação da quantidade total dos\\nrecursos de computação, a melhor arquitetura para um agente é um conjunto de subagentes, cada um\\ndos quais tenta otimizar seu próprio objetivo, e todos estão em conflito uns com os outros.\\nO modelo \\nboid\\n se deve a Reynolds (1987), que ganhou um prêmio da academia por sua aplicação\\na bandos de morcegos e de pinguins no filme \\nBatman, o retorno\\n. O jogo NERO e os métodos de\\nestratégias de aprendizagem são descritos por Bryant e Miikkulainen (2007).\\nLivros recentes sobre sistemas multiagentes incluem os de Weiss (2000a), Young (2004), Vlassis\\n(2008) e Shoham e Leyton-Brown (2009). Existe uma conferência anual sobre agentes autônomos e\\nsistemas multiagentes (AAMAS).\\nEXERCÍCIOS\\n11.1\\n Todos os objetivos que consideramos até aqui solicitam ao planejador que o mundo satisfaça o\\nobjetivo em apenas um passo. Nem todos os objetivos podem ser expressos dessa forma: não se\\natinge o objetivo de suspender um lustre jogando-o no ar. Falando mais sério, ninguém desejaria que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 512}),\n",
       " Document(page_content='o sistema de apoio à vida de uma nave fornecesse oxigênio em um dia e em outro não. O \\nobjetivo de\\nmanutenção\\n é atingido quando o plano do agente causa uma condição verdadeira contínua de um\\ndeterminado estado em diante. Descreva como estender o formalismo desse capítulo para tratar\\nobjetivos de manutenção.\\n11.2\\n Você tem uma quantidade de caminhões com os quais quer entregar um conjunto de pacotes.\\nCada pacote começa em algum local em uma grade e tem um destino em outro lugar. Cada caminhão é\\ncontrolado diretamente para mover-se para a frente e virar. Construa uma hierarquia de ações de alto\\nnível para esse problema. Que conhecimento sobre a solução a sua hierarquia codifica?\\n11.3\\n Suponha que uma ação de alto nível tenha exatamente uma implementação como uma sequência\\nde ações primitivas. Dê um algoritmo para calcular as suas precondições e efeitos, dada a hierarquia\\ncompleta de refinamento e os esquemas das ações primitivas.\\n11.4\\n Suponha que o conjunto otimista alcançável de um plano de alto nível seja um superconjunto do\\nconjunto objetivo; algo pode ser concluído sobre se o plano atinge o objetivo? E se o conjunto\\npessimista alcançável não tiver interseção com o conjunto objetivo? Explique.\\n11.5\\n Escreva um algoritmo que tome um estado inicial (especificado por um conjunto de literais\\nproposicionais) e uma sequência de HLAs (cada um definido por precondições e especificações\\nangélicas de conjuntos alcançáveis otimistas e pessimistas) e compute as descrições otimista e\\npessimista do conjunto alcançável da sequência.\\n11.6\\n Na \\nFigura 11.2\\n, mostramos como descrever ações em um problema de escalonamento usando\\ncampos separados para DURAÇÃO, USO e CONSUMO. Agora, suponha que desejássemos\\ncombinar o escalonamento com o planejamento não determinístico, que exige efeitos não\\ndeterminísticos e condicionais. Considere cada um dos três campos e explique se eles devem\\npermanecer separados ou se devem tornar-se efeitos da ação. Dê um exemplo para cada um dos três.\\n11.7\\n Algumas operações em linguagens de programação-padrão podem ser modeladas como ações\\nque alteram o estado do mundo. Por exemplo, a operação de atribuição altera o conteúdo de uma\\nposição de memória, enquanto a operação de impressão muda o estado do fluxo de saída. Um\\nprograma que consiste nessas operações também pode ser considerado um plano cujo objetivo é\\ndado pela especificação do programa. Por conseguinte, algoritmos de planejamento podem ser\\nusados para construir programas que alcançam uma determinada especificação.\\na.\\n Escreva um esquema de ação para o operador de atribuição (atribuindo o valor de uma variável\\na outra). Lembre-se de que o valor original será sobrescrito!\\nb.\\n Mostre como a criação de objetos pode ser utilizada por um planejador para produzir um plano\\nque vai trocar os valores de duas variáveis usando uma variável temporária.\\n11.8\\n Suponha que a ação \\nTroca\\n sempre altere o valor verdadeiro de \\nL\\n. Mostre como definir os seus\\nefeitos usando um esquema de ação com efeitos condicionais. Mostre que, apesar do uso de efeitos\\ncondicionais, a representação do estado de crença 1-FNC permanece em 1-FNC após \\nTroca\\n.\\n11.9\\n No mundo de blocos, fomos forçados a introduzir dois esquemas de ações de STRIPS, \\nMover\\n e\\nMoverParaMesa\\n, a fim de manter o predicado \\nLivre\\n de forma correta. Mostre como os efeitos\\ncondicionais podem ser usados para representar ambos os casos com uma única ação.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 513}),\n",
       " Document(page_content='11.10\\n Os efeitos condicionais foram ilustrados para a ação \\nAspirar\\n no mundo de aspirador de pó —\\no quadrado que fica limpo depende do quadrado em que o robô se encontra. Você poderia imaginar\\num novo conjunto de variáveis proposicionais para definir estados do mundo de aspirador de pó, tais\\nque \\nAspirar\\n tenha uma descrição \\nincondicional\\n? Represente as descrições de \\nAspirar\\n, \\nEsquerda\\n e\\nDireita\\n usando suas proposições e demonstre que elas bastam para descrever todos os estados\\npossíveis do mundo.\\n11.11\\n Encontre um tapete apropriadamente sujo, livre de obstáculos, e limpe-o com o aspirador.\\nDesenhe o caminho feito pelo aspirador o mais preciso que puder. Explique o resultado fazendo\\nreferência às formas de planejamento discutidas neste capítulo.\\n11.12\\n Adicione ao problema do medicamento um \\nTeste\\n de ação que tenha o efeito condicional\\nCrescimentoCultura\\n quando \\nDoença\\n for verdadeira e que em qualquer caso tenha o efeito\\nperceptivo \\nConhecido\\n(\\nCrescimentoCultura).\\n Esboce um plano condicional que resolva o problema\\ne minimize o uso da ação \\nMedicar.\\n1\\n Planejadores HTN muitas vezes permitem refinamento em planos parcialmente ordenados, e permitem refinamentos de duas HLAs\\ndiferentes em um plano para \\ncompartilhar\\n ações. Omitimos essas complicações importantes no interesse do entendimento dos conceitos\\nbásicos de planejamento hierárquico.\\n2\\n Se, para um problema não determinístico, são necessárias soluções cíclicas, a busca E-OU deve ser generalizada para uma versão de\\nlaço como LAO* (Hansen e Zilberstein, 2001).\\n3\\n Em 1954, a Sra. Hodges do Alabama foi atingida por um meteorito que caiu através de seu telhado. Em 1992, um pedaço do meteorito\\nMbale atingiu um menino na cabeça; felizmente, sua descida foi amortecida por folhas de bananeira (Jenniskens \\net al\\n., 1994). Em 2009,\\num menino alemão alegou ter sido atingido na mão por um meteorito do tamanho de uma ervilha. Esses incidentes não resultaram em\\nnenhuma lesão grave, sugerindo que a necessidade de pré-planejamento contra tais contingências às vezes é exagerada.\\n4\\n Monitoramento de plano significa que finalmente, depois de 371 páginas, temos um agente que é mais esperto do que um besouro de\\nesterco. Um agente de monitoramento de plano notaria que uma bola de esterco estava faltando do seu alcance e iria replanejar para\\nobter outra bola e tampar o buraco.\\n5\\n Repetição inútil do reparo de um plano é exatamente o comportamento exibido pela vespa Sphex.\\n6\\n Pedimos desculpas aos residentes do Reino Unido, onde o simples ato de contemplar uma partida de tênis é garantia de chuva.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 514}),\n",
       " Document(page_content='O\\nCAPÍTULO\\n \\n12\\nRepresentação de conhecimento\\nEm que mostramos como usar a lógica de primeira ordem para representar os\\naspectos mais importantes do mundo real, como ação, espaço, tempo,\\npensamentos e compras.\\ns capítulos anteriores descreveram a tecnologia dos agentes baseados em conhecimento: a\\nsintaxe, a semântica e a teoria de prova da lógica proposicional e da lógica de primeira ordem, e\\nainda a implementação de agentes que utilizam essas lógicas. Neste capítulo, examinaremos a\\nquestão do \\nconteúdo\\n que deve ser colocado na base de conhecimento de tal agente, ou seja, como\\nrepresentar fatos sobre o mundo.\\nA \\nSeção 12.1\\n introduz a ideia de uma ontologia geral, que organiza tudo no mundo em uma\\nhierarquia de categorias. A \\nSeção 12.2\\n abrange as categorias de objetos, substâncias e medidas; a\\nSeção 12.3\\n abrange eventos, e a \\nSeção 12.4\\n discute o conhecimento sobre crenças. Então voltamos a\\nconsiderar a tecnologia para raciocínio com este conteúdo: a \\nSeção 12.5\\n discute sistemas de\\nraciocínio projetados para inferência eficiente com categorias e a \\nSeção 12.6\\n discute o raciocínio\\ncom informação default. A \\nSeção 12.7\\n junta todo o conhecimento no contexto de um ambiente de\\ncompra pela Internet.\\n12.1 ENGENHARIA ONTOLÓGICA\\nEm domínios em “miniatura”, a escolha da representação não é tão importante; muitas escolhas\\nvão funcionar. Por outro lado, domínios complexos como compras na Internet ou dirigir um carro no\\ntrânsito exigem representações mais gerais e flexíveis. Este capítulo mostra como criar essas\\nrepresentações, concentrando-se em conceitos gerais — como \\nEventos\\n, \\nTempo\\n, \\nObjetos Físicos\\n e\\nCrenças\\n — que ocorrem em muitos domínios diferentes. A representação desses conceitos abstratos\\né chamada às vezes de \\nengenharia ontológica\\n.\\nA perspectiva de representar \\ntudo\\n no mundo é assustadora. É claro que não escreveremos\\nrealmente uma descrição completa de tudo — isso seria demais até mesmo para um livro didático de\\n1.000 páginas —, mas deixaremos espaços vazios onde poderá ser colocado conhecimento sobre\\nqualquer domínio. Por exemplo, definiremos o que significa ser um objeto físico, mas os detalhes de\\ndiferentes tipos de objetos — robôs, televisores, livros ou qualquer outro objeto — poderão ser', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 516}),\n",
       " Document(page_content='preenchidos mais tarde. Isso é análogo à forma como os projetistas de uma estrutura de programação\\norientada a objetos (como a estrutura gráfica Java Swing) definem conceitos gerais como \\nJanela\\n,\\nesperando que os usuários o utilizem para definir conceitos mais específicos como\\nSpreadsheetWindow\\n. A estrutura geral de conceitos é chamada \\nontologia superior\\n, devido à\\nconvenção de desenhar grafos com os conceitos gerais na parte superior e os conceitos mais\\nespecíficos abaixo deles, como na \\nFigura 12.1\\n.\\nFigura 12.1\\n A ontologia superior do mundo, mostrando os tópicos a serem cobertos mais adiante\\nneste capítulo. Cada aresta indica que o conceito inferior é uma especialização do conceito superior.\\nAs especializações não são necessariamente disjuntas: um ser humano é animal e agente, por\\nexemplo. Veremos, na \\nSeção 12.3.3\\n, por que os objetos físicos aparecem sob eventos generalizados.\\nAntes de considerarmos a ontologia com mais detalhes, devemos fazer uma importante\\nadvertência. Optamos por utilizar a lógica de primeira ordem para discutir o conteúdo e a\\norganização do conhecimento, apesar de que certos aspectos do mundo real são difíceis de captar em\\nLPO. A principal dificuldade é que a maioria das generalizações têm exceções ou só são válidas até\\ncerto ponto. Por exemplo, embora “tomates são vermelhos” seja uma regra útil, alguns tomates são\\nverdes, amarelos ou alaranjados. Exceções semelhantes podem ser encontradas em quase todas as\\nregras gerais deste capítulo. A habilidade de tratar exceções e a incerteza é extremamente importante,\\nmas é ortogonal à tarefa de compreender a ontologia geral. Por essa razão, adiaremos a discussão de\\nexceções até a \\nSeção 12.5\\n deste capítulo e, a do tópico mais geral de raciocínio com incerteza, até o\\nCapítulo 13.\\nQual é a utilidade de uma ontologia superior? Considere novamente a ontologia dos circuitos da\\nSeção 8.4.2\\n. Ela faz muitas suposições simplificadoras. Por exemplo, o tempo é completamente\\nomitido, sinais são fixos e não de propagam, a estrutura do circuito permanece constante. Uma\\nontologia mais geral consideraria sinais em instantes particulares e incluiria os comprimentos dos\\nfios e retardos de propagação. Isso nos permitiria simular as propriedades de sincronização do\\ncircuito e, na verdade, tais simulações são executadas com frequência por projetistas de circuitos.\\nTambém poderíamos introduzir classes mais interessantes de portas, descrevendo por exemplo a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 517}),\n",
       " Document(page_content='tecnologia (TTL, CMOS, e assim por diante), bem como a especificação de entrada/saída. Se\\nquiséssemos discutir a confiabilidade ou o diagnóstico, incluiríamos a possibilidade de a estrutura\\ndo circuito ou as propriedades das portas poderem se alterar espontaneamente. Para levar em conta\\ncapacitâncias espúrias, precisaríamos representar onde os fios estão na placa.\\nSe observarmos o mundo de wumpus, veremos que se aplicam considerações semelhantes. Embora\\nseja incluído o tempo, ele tem uma estrutura muito simples: nada acontece exceto quando o agente\\nage, e todas as mudanças são instantâneas. Uma ontologia mais geral, mais bem adaptada ao mundo\\nreal, permitiria que mudanças simultâneas se estendessem ao longo do tempo. Também usamos um\\npredicado \\nPoço\\n para dizer que quadrados têm poços. Poderíamos ter permitido tipos diferentes de\\npoços, fazendo com que diversos indivíduos pertencessem à classe de poços, cada um com\\npropriedades diferentes. De modo semelhante, poderíamos permitir outros animais além de wumpus.\\nNão seria possível definir as espécies exatas das percepções disponíveis e, assim, precisaríamos\\nconstruir uma taxonomia biológica do mundo de wumpus para ajudar o agente a prever o\\ncomportamento de moradores de caverna a partir de pistas escassas.\\nPara qualquer ontologia de uso específico, é possível fazer mudanças como essas com a finalidade\\nde obter uma generalidade maior. Uma questão óbvia surge então: todas essas ontologias convergem\\npara uma ontologia de uso geral? Depois de séculos de investigação filosófica e computacional, a\\nresposta é “talvez”. Nesta seção apresentaremos uma ontologia de propósito geral que sintetiza as\\nideias daqueles séculos. Existem duas características importantes das ontologias de uso geral que as\\ndistinguem das coleções de ontologias de uso específico:\\n•  Uma ontologia de uso geral deve ser aplicável em quase todo domínio de uso específico (com a\\ninclusão de axiomas específicos do domínio). Isso significa que, nenhuma questão de\\nrepresentação pode ser tratada com artimanhas nem pode ser empurrada para debaixo do tapete.\\n•  Em qualquer domínio suficientemente exigente, áreas distintas de conhecimento devem ser\\nunificadas\\n porque o raciocínio e a resolução de problemas poderiam envolver diversas áreas\\nsimultaneamente. Por exemplo, um sistema robô para reparação de circuitos precisa raciocinar\\nsobre circuitos em termos de conectividade elétrica e leiaute físico, e também sobre o tempo,\\ntanto para realizar a análise de sincronização de circuitos quanto para avaliar os custos do\\ntrabalho. Portanto, as sentenças que descrevem o tempo devem ser capazes de se combinar com\\nas que descrevem o leiaute espacial e devem funcionar igualmente bem para nanossegundos e\\nminutos, e para angstrons e metros.\\nDeveríamos dizer de antemão que o empreendimento da engenharia ontológica geral tem tido até\\nagora sucesso limitado. Nenhum dos aplicativos \\ntop\\n de IA (conforme listado no Capítulo 1) utiliza\\numa ontologia compartilhada — todos utilizam a engenharia do conhecimento para fins específicos.\\nAs considerações sociais/políticas podem tornar difícil para os grupos concorrentes chegar a um\\nacordo sobre uma ontologia. Como Tom Gruber (2004) diz: “Cada ontologia é um tratado — um\\nacordo social — entre pessoas que têm um motivo comum para compartilhar.” Quando o interesse da\\nconcorrência supera a motivação para compartilhar, não pode haver ontologia comum. As ontologias\\nque já existem foram criadas ao longo de quatro rotas:\\n1. Por uma equipe de ontologistas/lógicos treinados, que arquitetaram a ontologia e escreveram', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 518}),\n",
       " Document(page_content='axiomas. O sistema CYC foi quase todo construído dessa forma (Lenat e Guha, 1990).\\n2. Através da importação de categorias, atributos e valores de um banco de dados existente ou\\nbancos de dados. O DBPedia foi construído através da importação de fatos estruturados da\\nWikipedia (Bizer \\net al\\n., 2007).\\n3. Ao analisar os documentos de texto e extrair informações deles. O TextRunner foi construído\\npela leitura de um grande \\ncorpus\\n de páginas da Web (Banko e Etzioni, 2008).\\n4. Ao estimular os amadores não qualificados para fornecer conhecimento do senso comum. O\\nsistema OPENMIND foi construído por voluntários que propuseram fatos em inglês (Singh \\net\\nal\\n., 2002.; Chklovski e Gil, 2005).\\n12.2 CATEGORIAS E OBJETOS\\n A organização de objetos em \\ncategorias\\n é uma parte vital da representação de conhecimento.\\nEmbora a interação com o mundo ocorra no nível de objetos individuais, \\numa grande parte do\\nraciocínio ocorre no nível de categorias\\n. Por exemplo, um consumidor teria normalmente o objetivo\\nde comprar uma bola de basquete, e não \\ndeterminada\\n bola de basquete, como a \\nBB\\n9\\n. As categorias\\ntambém servem para fazer previsões sobre objetos, uma vez que eles estão classificados. Pode-se\\ndeduzir a presença de certos objetos a partir de percepções, deduzir a pertinência a uma categoria a\\npartir das propriedades percebidas dos objetos e depois utilizar as informações a respeito da\\ncategoria para fazer previsões sobre os objetos. Por exemplo, a partir de seu grande tamanho, da\\ncasca verde e amarela e da forma ovoide, carne vermelha, sementes pretas e a presença no corredor\\nde frutas, pode-se deduzir que um objeto é uma melancia; a partir disso, é possível deduzir que seria\\nútil em uma salada de frutas.\\nHá duas opções para representar categorias em lógica de primeira ordem: predicados e objetos.\\nIsto é, podemos usar o predicado \\nBolaDeBasquete\\n(\\nb\\n) ou podemos \\nreificar\\n1\\n a categoria sob a forma\\nde um objeto \\nBolasDeBasquete\\n. Então, poderíamos afirmar: \\nElemento\\n(\\nb\\n, \\nBolasDeBasquete\\n) (que\\nabreviaremos como \\nb\\n \\n∊\\n \\nBolasDeBasquete\\n) para dizer que \\nb\\n é um elemento da categoria de bolas de\\nbasquete. Afirmamos: \\nSubconjunto\\n(\\nBolasDeBasquete\\n, \\nBolas\\n), abreviado como \\nBolasDeBasquete\\n \\n⊂\\nBolas\\n, para dizer que \\nBolasDeBasquete\\n é uma \\nsubcategoria\\n de \\nBolas\\n. Utilizaremos subcategoria,\\nsubclasse e subconjunto indistintamente.\\nAs categorias servem para organizar e simplificar a base de conhecimento por \\nherança\\n. Se\\ndissermos que todas as instâncias da categoria \\nAlimento\\n são comestíveis e se afirmarmos que \\nFruta\\né uma subclasse de \\nAlimento\\n e que \\nMaçãs\\n é uma subclasse de \\nFruta\\n, então saberemos que toda maçã\\né comestível. Dizemos que as maçãs individuais \\nherdam\\n a propriedade de serem comestíveis, nesse\\ncaso de sua condição de elemento da categoria \\nAlimento\\n.\\nAs relações de subclasses organizam as categorias em uma \\ntaxonomia\\n ou \\nhierarquia taxonômica\\n.\\nAs taxonomias foram usadas explicitamente durante séculos em campos técnicos. A maior destas\\ntaxonomias organiza cerca de 10 milhões de espécies vivas e extintas, muitas delas besouros,\\n2\\n em\\numa única hierarquia; a biblioteconomia desenvolveu uma taxonomia de todos os campos do\\nconhecimento, codificada como sistema decimal de Dewey; e as autoridades tributárias e outros', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 519}),\n",
       " Document(page_content='departamentos governamentais desenvolveram taxonomias extensas de ocupações e produtos\\ncomerciais. As taxonomias também constituem um aspecto importante do conhecimento comum em\\ngeral.\\nA lógica de primeira ordem facilita a declaração de fatos sobre categorias, seja relacionando\\nobjetos a categorias ou pela quantificação de seus elementos. Apresentamos alguns tipos de fatos,\\ncom exemplos:\\n•  Um objeto é um elemento de uma categoria.\\nBB\\n9\\n \\n∊\\n \\nBolasDeBasquete\\n•  Uma categoria é uma subclasse de outra categoria.\\nBolasDeBasquete\\n \\n⊂\\n \\nBolas\\n•  Todos os elementos de uma categoria têm algumas propriedades.\\n(\\nx\\n \\n∊\\n \\nBolasDeBasquete\\n) \\n⇒\\n \\nEsférica\\n(\\nx\\n)\\n•  Os elementos de uma categoria podem ser reconhecidos por algumas propriedades.\\nLaranja\\n(\\nx\\n) \\n∧\\n \\nRedonda\\n(\\nx\\n) \\n∧\\n \\nDiâmetro\\n(\\nx\\n) = 23,75 cm \\n∧\\n \\nx\\n \\n∊\\n \\nBolas\\n \\n⇒\\n \\nx\\n \\n∊\\n \\nBolasDeBasquete\\n•  Uma categoria é um conjunto que tem algumas propriedades.\\nCães\\n \\n∊\\n \\nEspéciesDomesticadas\\nNote que, pelo fato de \\nCães\\n ser uma categoria e ser um elemento de \\nEspéciesDomesticadas\\n, esta\\núltima deve ser uma categoria de categorias.\\nClaro que há exceções a muitas dessas regras (a bola de basquete furada não é esférica);\\nlidaremos com essas exceções mais tarde.\\nEmbora as relações de subclasse e elemento sejam as mais importantes para categorias, também\\nqueremos ter a possibilidade de enunciar relações entre categorias que não são subclasses umas das\\noutras. Por exemplo, se afirmássemos simplesmente que \\nMachos\\n e \\nFêmeas\\n são subclasses de\\nAnimais\\n, não teríamos dito que o macho não pode ser uma fêmea. Dizemos que duas ou mais\\ncategorias são \\ndisjuntas\\n se elas não têm elementos (ou membros) em comum. Além disso, mesmo se\\nsoubermos que machos e fêmeas são disjuntos, não saberemos que um animal que não é um macho\\ntem de ser uma fêmea, a menos que digamos que machos e fêmeas constituem uma \\ndecomposição\\nexaustiva\\n dos animais. Uma decomposição exaustiva desjunta é chamada \\npartição\\n. Os exemplos a\\nseguir ilustram esses três conceitos:\\nDisjuntos\\n({\\nAnimais\\n, \\nVegetais\\n})\\nDecomposiçãoExaustiva\\n({\\nAmericanos\\n, \\nCanadenses\\n, \\nMexicanos\\n}, \\nNorteAmericanos\\n)\\nPartição\\n({\\nMachos\\n, \\nFêmeas\\n}, \\nAnimais\\n).\\n(Observe que a \\nDecomposiçãoExaustiva\\n de \\nNorteAmericanos\\n não é uma \\nPartição\\n porque algumas\\npessoas têm dupla cidadania.) Os três predicados são definidos como:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 520}),\n",
       " Document(page_content='Disjuntos\\n(\\ns\\n) \\n⇔\\n (\\n∀\\nc\\n1\\n, \\nc\\n2\\n \\nc\\n1\\n \\n∊\\n \\ns\\n \\n∧\\n \\nc\\n2\\n \\n∊\\n \\ns\\n \\n∧\\n \\nc\\n1\\n ≠ \\nc\\n2\\n \\n⇒\\n \\nInterseção\\n(\\nc\\n1\\n, \\nc\\n2\\n) = {})\\nDecomposiçãoExaustiva\\n(\\ns\\n, \\nc\\n) \\n⇔\\n (\\n∀\\ni i\\n \\n∊\\n \\nc\\n \\n⇔\\n \\n∃\\nc\\n2\\n \\nc\\n2\\n \\n∊\\n \\ns\\n \\n∧\\n \\ni\\n \\n∊\\n \\nc\\n2\\n)\\nPartição\\n(\\ns\\n, \\nc\\n) \\n⇔\\n \\nDisjuntos\\n(\\ns\\n) \\n∧\\n \\nDecomposiçãoExaustiva\\n(\\ns\\n, \\nc\\n).\\nAs categorias também podem ser \\ndefinidas\\n fornecendo-se condições necessárias e suficientes para\\npertinência. Por exemplo, um solteiro é um macho adulto não casado:\\nx\\n \\n∊\\n \\nSolteiros\\n \\n⇔\\n \\nNãoCasado\\n(\\nx\\n) \\n∧\\n x \\n∊\\n \\nAdultos\\n \\n∧\\n x \\n∊\\n \\nMachos.\\nComo discutimos no quadro sobre espécies naturais mais adiante, as definições lógicas estritas\\npara categorias nem sempre são possíveis e nem sempre são necessárias.\\n12.2.1 Composição física\\nA ideia de que um objeto pode fazer parte de outro é bastante familiar. O nariz de uma pessoa faz\\nparte da cabeça de uma pessoa, a Romênia faz parte da Europa, e este capítulo faz parte deste livro.\\nUsamos a relação geral \\nParteDe\\n para dizer que alguma coisa faz parte de outra. Os objetos podem\\nser agrupados em hierarquias de \\nParteDe\\n, uma reminiscência da hierarquia de \\nSubconjunto\\n:\\nParteDe\\n(\\nBucareste\\n, \\nRomênia\\n)\\nParteDe\\n(\\nRomênia\\n, \\nEuropaOriental\\n)\\nParteDe\\n(\\nEuropaOriental\\n, \\nEuropa\\n)\\nParteDe\\n(\\nEuropa\\n, \\nTerra\\n).\\nA relação \\nParteDe\\n é transitiva e reflexiva, ou seja:\\nParteDe\\n(\\nx\\n, \\ny\\n) \\n∧\\n \\nParteDe\\n(\\ny\\n, \\nz\\n) \\n⇒\\n \\nParteDe\\n(\\nx\\n, \\nz\\n).\\nParteDe\\n(\\nx\\n, \\nx\\n).\\nPortanto, podemos concluir: \\nParteDe\\n(\\nBucareste\\n, \\nTerra\\n).\\nAs categorias de \\nobjetos compostos\\n frequentemente são caracterizadas por relações estruturais\\nentre partes. Por exemplo, um bípede tem duas pernas presas a um corpo:\\nA notação correspondente a “exatamente dois” é um pouco confusa; somos forçados a afirmar que\\nexistem duas pernas, que elas não são iguais e que, se alguém propuser uma terceira perna, ela terá\\nde ser igual a uma das outras duas. Na \\nSeção 12.5.2\\n, veremos que um formalismo chamado \\nlógica de\\ndescrições\\n facilita a representação de restrições como “exatamente dois”.\\nPodemos definir uma relação \\nPartiçãoDeParte\\n análoga à relação \\nPartição\\n para categorias (veja o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 521}),\n",
       " Document(page_content='Exercício 12.8). Um objeto é composto das partes de sua \\nPartiçãoDeParte\\n e pode ser visualizado\\ncomo derivando algumas propriedades dessas partes. Por exemplo, a massa de um objeto composto é\\na soma das massas das partes. Note que isso não ocorre no caso de categorias, que não têm massa,\\nembora seus elementos possam ter.\\nTambém é útil definir objetos compostos com partes definidas mas sem estrutura específica. Por\\nexemplo, poderíamos dizer: “As maçãs deste pacote pesam 900 gramas.” A tentação seria atribuir\\nesse peso ao \\nconjunto\\n de maçãs do pacote, mas isso seria um erro porque o conjunto é um conceito\\nmatemático abstrato que tem elementos, mas não tem peso. Em vez disso, precisamos de um novo\\nconceito, que chamaremos de \\ngrupo\\n. Por exemplo, se as maçãs são \\nMaçã\\n1\\n, \\nMaçã\\n2\\n e \\nMaçã\\n3\\n, então:\\nGrupoDe\\n({\\nMaçã\\n1\\n, \\nMaçã\\n2\\n, \\nMaçã\\n3\\n})\\ndenota o objeto composto com as três maçãs como partes (não como elementos). Podemos então usar\\no grupo como um objeto normal, embora não estruturado. Note que \\nGrupoDe\\n({\\nx\\n}) = \\nx\\n. Além disso,\\nGrupoDe\\n(\\nMaçãs\\n) é o objeto composto que consiste em todas as maçãs — não devemos confundi-lo\\ncom \\nMaçãs\\n, a categoria ou o conjunto de todas as maçãs.\\nESPÉCIES NATURAIS\\nAlgumas categorias têm definições estritas: um objeto é um triângulo se e somente se é um\\npolígono com três lados. Por outro lado, a maioria das categorias no mundo real não tem nenhuma\\ndefinição clara; essas são as chamadas categorias de \\nespécies naturais\\n. Por exemplo, tomates\\ntendem a ser vermelhos, aproximadamente esféricos, com uma depressão na parte superior em que\\nfica o talo, têm cerca de 5-10 cm de diâmetro, apresentam pele fina mas resistente e têm polpa,\\nsementes e suco em seu interior. Porém, há variações: alguns tomates são amarelos, tomates não\\nmaduros são verdes, alguns são menores ou maiores que a média, e tomates cereja são\\nuniformemente pequenos. Em vez de uma definição completa de tomates, temos um conjunto de\\ncaracterísticas que serve para identificar objetos que são claramente tomates típicos, mas que não\\npermite decidir para outros objetos (é possível existir um tomate com a casca aveludada como um\\npêssego?).\\nIsso representa um problema para um agente lógico. O agente não pode ter certeza de que um\\nobjeto que ele percebeu é um tomate e, mesmo que tivesse certeza disso, poderia não estar certo\\nde quais das propriedades de tomates típicos esse objeto apresenta. Esse problema é uma\\nconsequência inevitável da operação em ambientes parcialmente observáveis.\\nUma abordagem útil é separar o que é verdadeiro para todas as instâncias de uma categoria\\ndaquilo que é verdadeiro apenas para instâncias típicas. Assim, além da categoria \\nTomates\\n,\\ntambém teremos a categoria \\nTípica\\n(\\nTomates\\n)\\n.\\n Aqui, a função \\nTípica\\n mapeia uma categoria como a\\nsubclasse que contém apenas as instâncias típicas:\\nTípica (c)\\n \\n c.\\nA maior parte do conhecimento sobre tipos naturais será na realidade o conhecimento sobre', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 522}),\n",
       " Document(page_content='suas instâncias típicas:\\nx \\n∊\\n \\nTípica (Tomates)\\n \\n⇒\\n \\nVermelho (x)\\n \\n∧\\n \\nRedondo (x).\\nDesse modo, podemos anotar fatos úteis sobre categorias sem definições exatas. A dificuldade\\nde fornecer definições exatas para a maioria das categorias naturais foi explicada em\\nprofundidade por Wittgenstein (1953)\\n.\\n Ele utilizou o exemplo de \\njogos\\n para mostrar que\\nelementos de uma categoria compartilham “semelhanças familiares”, em vez de características\\nnecessárias e suficientes. Que definição estrita engloba xadrez, pega-pega, paciência e queimada?\\nA utilidade da noção de definição estrita também foi contestada por Quine (1953). Ele destacou\\nque até mesmo a definição “solteiro” como um macho adulto não casado é suspeita; por exemplo,\\nalguém poderia questionar uma declaração como “o papa é solteiro”. Embora não seja\\nestritamente falso, esse uso é sem dúvida pouco feliz porque induz inferências involuntárias por\\nparte do ouvinte. A tensão talvez pudesse ser resolvida distinguindo entre definições lógicas\\napropriadas para representação interna do conhecimento e os critérios mais ricos em nuanças do\\nuso linguístico adequado. Este último pode ser alcançado “filtrando-se” as asserções derivadas do\\nprimeiro. Também é possível que as falhas do uso linguístico sirvam como \\nfeedback\\n para a\\nmodificação de definições internas, de modo que a filtragem se torne desnecessária.\\nPodemos definir \\nGrupoDe\\n em termos da relação \\nParteDe\\n. É óbvio que cada elemento de \\ns\\n é parte\\nde \\nGrupo-De\\n(\\ns\\n):\\n∀\\nx x\\n \\n∊\\n \\ns\\n \\n⇒\\n \\nParteDe\\n(\\nx\\n, \\nGrupoDe\\n(s)).\\nAlém disso, \\nGrupoDe\\n(\\ns\\n) \\né o menor objeto que satisfaz essa condição\\n. Em outras palavras,\\nGrupoDe\\n(\\ns\\n) deve fazer parte de qualquer objeto que tenha todos os elementos de \\ns\\n como partes:\\n∀\\ny\\n [\\n∀\\nx x\\n \\n∊\\n \\ns\\n \\n⇒\\n \\nParteDe\\n(\\nx, y\\n)] \\n⇒\\n \\nParteDe\\n(\\nGrupoDe\\n(\\ns\\n), \\ny\\n).\\nEsses axiomas são um exemplo de uma técnica geral chamada \\nminimização lógica\\n, que significa\\ndefinir um objeto como o menor que satisfaz certas condições.\\n12.2.2 Medições\\nTanto na teoria científica quanto na teoria de senso comum do mundo, os objetos têm altura, massa,\\ncusto, e assim por diante. Os valores que atribuímos para essas propriedades são chamados \\nmedidas\\n.\\nAs medidas quantitativas comuns são bastante fáceis de representar. Imaginamos que o universo\\ninclui “objetos de medida” abstratos, como o \\ncomprimento\\n, que é o comprimento deste segmento de\\nlinha: |––––––––––––––––|. Podemos chamar esse comprimento de 1,5 polegada ou 3,81 centímetros.\\nDesse modo, o mesmo comprimento tem diferentes nomes em nossa linguagem. Representamos o\\ncomprimento com uma \\nfunção de unidade\\n que recebe um número como argumento (um esquema\\nalternativo é explorado no Exercício 12.9). Se o segmento de linha for chamado de \\nL\\n1\\n, poderemos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 523}),\n",
       " Document(page_content='escrever:\\nComprimento\\n(\\nL\\n1\\n) = \\nPolegadas\\n(1,5) = \\nCentímetros\\n(3,81).\\nA conversão entre unidades é feita igualando-se os múltiplos de uma unidade aos de outra:\\nCentímetros\\n(2,54 × \\nd\\n) = \\nPolegadas\\n(\\nd\\n).\\nAxiomas semelhantes podem ser escritos para libras e quilogramas, segundos e dias, e ainda\\ndólares e centavos. As medidas podem ser usadas para descrever objetos como:\\nDiâmetro\\n(\\nBolaDeBasquete\\n12\\n) = \\nCentímetros\\n(23,75).\\nPreço\\n(\\nBolaDeBasquete\\n12\\n) = $(19).\\nd\\n \\n∊\\n \\nDias\\n \\n⇒\\n \\nDuração\\n(\\nd\\n) = \\nHoras\\n(24).\\nObserve que $(1) \\nnão\\n é uma nota de um dólar! Podemos ter duas notas de um dólar, mas só existe\\num objeto denominado $(1). Observe também que, embora \\nPolegadas\\n(0) e \\nCentímetros\\n(0) se\\nrefiram ao mesmo comprimento zero, eles não são idênticos a outras medidas de zero, como\\nSegundos\\n(0).\\nMedidas simples e quantitativas são fáceis de representar. Outras medidas representam um\\nproblema maior porque não têm nenhuma escala de valores estabelecida. Os exercícios têm\\ndificuldade, sobremesas são deliciosas e os poemas têm beleza, embora não se possa atribuir aos\\nnúmeros essas qualidades. Em um momento de puro caráter contábil, alguém poderia desprezar tais\\npropriedades como inúteis para o propósito do raciocínio lógico ou, pior ainda, tentar impor uma\\nescala numérica sobre a beleza. Isso seria um equívoco grave porque é desnecessário. O aspecto\\nmais importante das medidas não é o dos valores numéricos específicos, mas o fato de que as\\nmedidas podem ser \\nordenadas\\n.\\nEmbora as medidas não sejam números, ainda podemos compará-las usando um símbolo de\\nordenação como >. Por exemplo, poderíamos muito bem acreditar que os exercícios de Norvig são\\nmais trabalhosos que os de Russell e isso daria uma pontuação menor aos exercícios mais\\ntrabalhosos:\\nIsso é suficiente para permitir que alguém decida que exercícios fazer, embora nenhum valor\\nnumérico referente à dificuldade tenha sido usado (porém, alguém teria de descobrir quem escreveu\\ncada um dos exercícios).\\nEsses tipos de relacionamentos monotônicos entre medidas formam a base para o campo da \\nfísica\\nqualitativa\\n, um subcampo da IA que investiga como raciocinar sobre sistemas físicos sem mergulhar\\nem equações detalhadas e simulações numéricas. A física qualitativa é discutida na seção de notas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 524}),\n",
       " Document(page_content='históricas.\\n12.2.3 Objetos: materiais e coisas\\nO mundo real pode ser visto como a reunião de objetos primitivos (por exemplo, partículas\\natômicas) e objetos compostos construídos a partir deles. Raciocinando no nível de grandes objetos\\ncomo maçãs e carros, podemos superar a complexidade envolvida no trato individual com imenso\\nnúmero de objetos primitivos. No entanto, existe uma parte significativa da realidade que parece\\ndesafiar qualquer \\nindividuação\\n óbvia — a divisão em objetos distintos. Daremos a essa parte o\\nnome genérico de \\nmaterial\\n. Por exemplo, vamos supor que eu tenha um pouco de manteiga e um\\ntamanduá na minha frente. Posso dizer que existe um tamanduá, mas não existe nenhum número óbvio\\nde “objetos manteiga” porque qualquer parte de um objeto manteiga também é um objeto manteiga,\\npelo menos até chegarmos a partes muito pequenas. Essa é a principal distinção entre o material e os\\nobjetos. Se cortarmos um tamanduá ao meio, não obteremos dois tamanduás (infelizmente).\\nA linguagem natural faz uma clara distinção entre \\nmaterial e coisas.\\n Dizemos “um tamanduá”, mas,\\nexceto em restaurantes da pretensiosa Califórnia, não se pode dizer “uma manteiga”. Os linguistas\\nfazem distinção entre \\nsubstantivos contáveis\\n, como tamanduás, poços e teoremas, e \\nsubstantivos de\\nmassa\\n, como manteiga, água e energia. Várias ontologias concorrentes afirmam poder tratar essa\\ndistinção. Descreveremos apenas uma; as outras serão abordadas na seção de notas históricas.\\nPara representar corretamente um \\nmaterial\\n, começamos com o óbvio. Precisaremos ter como\\nobjetos em nossa ontologia pelo menos as “massas” brutas de \\nmaterial\\n com que interagimos. Por\\nexemplo, poderíamos reconhecer uma massa de manteiga como a mesma manteiga que foi deixada\\nsobre a mesa na noite anterior; poderíamos pegá-la, pesá-la e vendê-la ou ainda realizar qualquer\\noutra ação. Nesse sentido, ela é um objeto semelhante ao tamanduá. Vamos chamá-lo \\nManteiga\\n3\\n.\\nTambém definiremos a categoria \\nManteiga\\n. Informalmente, seus elementos serão itens sobre os quais\\nse poderia dizer “é manteiga” inclusive \\nManteiga\\n3\\n. Com algumas advertências sobre partes muito\\npequenas que omitiremos por enquanto, qualquer parte de um objeto manteiga também é um objeto\\nmanteiga:\\nb\\n \\n∊\\n \\nManteiga\\n \\n∧\\n \\nParteDe\\n(\\np, b\\n) \\n⇒\\n \\np\\n \\n∊\\n \\nManteiga.\\nAgora, podemos dizer que a manteiga derrete a aproximadamente 30 graus Celsius:\\nb\\n \\n∊\\n \\nManteiga\\n \\n⇒\\n \\nPontoDeFusão\\n(\\nb\\n, \\nCelsius\\n(30)).\\nPoderíamos continuar a dizer que a manteiga é amarela, menos densa que a água, é mole à\\ntemperatura ambiente, tem alto conteúdo de gordura, e assim por diante. Por outro lado, a manteiga\\nnão tem nenhum tamanho específico nem forma, nem peso. Podemos definir categorias mais\\nespecializadas de manteiga como \\nManteigaSemSal\\n, que também é uma espécie de \\nmaterial.\\n Por\\noutro lado, a categoria \\nPacoteDeManteiga\\n, que inclui como elementos todos os objetos manteiga\\ncom o peso de 250 gramas, não é uma espécie de \\nmaterial\\n. Se cortarmos um pacote de manteiga ao\\nmeio, infelizmente não teremos dois pacotes de manteiga.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 525}),\n",
       " Document(page_content='Na realidade, o que temos é que existem algumas propriedades que são \\nintrínsecas\\n: elas são\\npertinentes à substância do objeto, e não ao objeto como um todo. Quando se corta uma instância do\\nmaterial\\n ao meio, as duas partes retêm o mesmo conjunto de propriedades intrínsecas — itens como\\ndensidade, ponto de ebulição, sabor, cor, e assim por diante. Por outro lado, propriedades\\nextrínsecas —\\n peso, sabor e assim por diante — não são mantidas sob subdivisão. Uma categoria de\\nobjetos que inclui em sua definição apenas propriedades \\nintrínsecas\\n é então uma substância ou\\nsubstantivo de massa; uma classe que inclui \\nquaisquer\\n propriedades extrínsecas em sua definição é\\num substantivo contável. A categoria \\nMaterial\\n é a categoria mais geral de substâncias, que não\\nespecifica nenhuma propriedade intrínseca. A categoria \\nCoisa\\n é a categoria mais geral de objetos\\ndiscretos, e não especifica nenhuma propriedade extrínseca.\\n12.3 EVENTOS\\nNa \\nSeção 10.4.2\\n, mostramos como o cálculo de situações representa as ações e seus efeitos. O\\ncálculo de situações é limitado em sua aplicabilidade: foi projetado para descrever um mundo em\\nque as ações são discretas, instantâneas e acontecem uma de cada vez. Considere uma ação contínua,\\ncomo o enchimento de uma banheira. O cálculo de situações pode informar que a banheira está vazia\\nantes da ação e cheia quando a ação é concluída, mas não pode informar o que acontece \\ndurante\\n a\\nação. Ele também não pode descrever duas ações acontecendo ao mesmo tempo, tais como escovar\\nos dentes enquanto espera a banheira encher. Para lidar com tais casos, apresentamos um formalismo\\nalternativo conhecido como \\ncálculo de eventos\\n, que se baseia em pontos de tempo em vez de\\nsituações.\\n3\\nO cálculo de evento reifica fluentes e eventos. O fluente \\nEm\\n(\\nShankar, Berkeley\\n) é um objeto que\\nse refere ao fato de Shankar estar em Berkeley, mas por si só não indica se é verdadeiro. Para\\nafirmar que um fluente é realmente verdadeiro em algum ponto no tempo usamos o predicado \\nT\\n, como\\nem \\nT\\n(\\nEm\\n(\\nShankar\\n, \\nBerkeley\\n), \\nt\\n)\\n.\\nOs eventos são descritos como instâncias de categorias de eventos.\\n4\\n O evento \\nE\\n1\\n de Shankar voar\\nde São Francisco para Washington, D.C., é descrito como\\nE\\n1\\n \\n∊\\n \\nVoos\\n \\n∧\\n \\nPiloto (E\\n1\\n, Shankar)\\n \\n∧\\n \\nOrigem (E\\n1\\n, SF)\\n \\n∧\\n \\nDestino (E\\n1\\n, DC).\\nSe estiver muito detalhado, podemos definir uma versão alternativa de três argumentos da\\ncategoria dos eventos de voos e dizer\\nE\\n1\\n \\n∊\\n \\nVoos (Shankar, SF, DC).\\nEm seguida, usamos \\nAcontece\\n(\\nE\\n1\\n, \\ni\\n) para dizer que o evento \\nE\\n1\\n aconteceu no intervalo de tempo \\ni\\n,\\ne dizemos a mesma coisa de forma funcional com \\nExtensão\\n(\\nE\\n1\\n) = \\ni\\n. Representamos os intervalos de\\ntempo pelo par de instantes (início, fim), isto é, \\ni\\n = (\\nt\\n1\\n, \\nt\\n2\\n) é o intervalo que começa em \\nt\\n1\\n e termina\\nem \\nt\\n2\\n. O conjunto completo de predicados para uma versão do cálculo de evento é', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 526}),\n",
       " Document(page_content='T\\n(\\nf, t\\n)\\nFluente \\nf\\n é verdadeiro no instante \\nt\\nAcontece\\n(\\ne\\n, \\ni\\n)\\nEvento \\ne\\n acontece no intervalo de tempo \\ni\\nInicia(e, f, t)\\nEvento \\ne\\n faz com que o fluente \\nf\\n passe a valer no instante \\nt\\nTermina\\n(\\ne, f, t\\n)\\nEvento \\ne\\n faz com que o fluente \\nf\\n deixe de valer no instante \\nt\\nCortado\\n(\\nf, i\\n)\\nFluente \\nf\\n deixa de ser verdadeiro em algum ponto durante o intervalo de tempo \\ni\\nRestaurado (f, i)\\nFluente \\nf\\n torna-se verdadeiro em algum momento durante o intervalo de tempo \\ni\\nAssumimos um evento distinto, \\nInício\\n, que descreve o estado inicial informando quais fluentes são\\niniciados ou terminados no instante inicial. Definimos \\nT\\n dizendo que um fluente é válido em um ponto\\nno tempo se o fluente foi iniciado por um evento em algum momento no passado e não foi tornado\\nfalso (cortado) por um evento interveniente. Um fluente não é válido se for terminado por um evento\\ne não se tornou verdadeiro (restaurado) por outro evento. Formalmente, os axiomas são:\\nAcontece\\n(\\ne\\n, (\\nt\\n1\\n, \\nt\\n2\\n)) \\n∧\\n \\nInicia\\n(\\ne, f, t\\n1\\n) \\n∧\\n ¬\\nCortado\\n(\\nf\\n (t\\n1\\n, t)) \\n∧\\n \\nt\\n1\\n < \\nt\\n \\n⇒\\n \\nT\\n(\\nf, t\\n)\\nAcontece\\n(\\ne\\n, (\\nt\\n1\\n, \\nt\\n2\\n)) \\n∧\\n \\nTermina\\n(\\ne, f, t\\n1\\n) \\n∧\\n ¬\\nRestaurado\\n(\\nf\\n (\\nt\\n1\\n, \\nt\\n)) \\n∧\\n \\nt\\n1\\n < t \\n⇒\\n ¬\\nT\\n(\\nf, t\\n)\\nonde \\nCortado\\n e Restaurado são definidos por\\nCortado\\n(\\nf\\n, (\\nt\\n1\\n, \\nt\\n2\\n)) \\n⇔\\n∃\\ne, t,\\n \\nt\\n3\\n Acontece (e, (\\nt, t\\n3\\n)) \\n∧\\n \\nt\\n1\\n ≤ \\nt\\n < \\nt\\n2\\n \\n∧\\n \\nTermina\\n (\\ne, f, t\\n)\\nRestaurado (\\nf\\n (\\nt\\n1\\n, \\nt\\n2\\n)) \\n⇔\\n∃\\ne\\n, \\nt,\\n \\nt\\n3\\n Acontece (e, (\\nt\\n, \\nt\\n3\\n)) \\n∧\\n \\nt\\n1\\n ≤ \\nt\\n < \\nt\\n2\\n \\n∧\\n \\nInicia\\n (\\ne, f, t\\n).\\nÉ conveniente estender \\nT\\n para trabalhar em intervalos, bem como em pontos no tempo; um fluente\\né válido em um intervalo se for válido em todos os pontos dentro do intervalo:\\nT (f (t\\n1\\n, t\\n2\\n))\\n \\n⇔\\n \\n[\\n∀\\nt (t\\n1\\n ≤ \\nt < t\\n2\\n)\\n \\n⇒\\n \\nT (f, t)].\\nOs fluentes e as ações são definidos com axiomas de domínio específico que são semelhantes aos\\naxiomas de estados sucessores. Por exemplo, podemos dizer que a única maneira de um agente do\\nmundo de wumpus receber uma seta é no início, e a única maneira de usar uma seta é atirá-la:\\nInicia (e, TemFlecha (a), t)\\n \\n⇔\\n \\ne = Início\\nTermina (e, TemFlecha (a), t)\\n \\n⇔\\n \\ne\\n \\n∊\\n \\nAto de atirar (a).\\nReificando eventos tornamos possível adicionar qualquer montante de informações arbitrárias\\nsobre eles. Por exemplo, podemos dizer que o voo de Shankar foi acidentado com \\nAcidentado\\n(\\nE\\n1\\n).\\nEm uma ontologia onde os eventos são predicados \\nn\\n-ários não haveria maneira de adicionar\\ninformação extra como essa; mover para um predicado \\nn\\n + 1-ário não é uma solução escalável.\\nPodemos estender o cálculo de eventos para tornar possível representar eventos simultâneos (tal\\ncomo duas pessoas que são necessárias para montar uma gangorra), os eventos exógenos (tais como o\\nvento soprando e alterando a localização de um objeto), eventos contínuos (tais como o nível de água', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 527}),\n",
       " Document(page_content='na banheira continuamente crescente) e outras complicações.\\n12.3.1 Processos\\nOs eventos que vimos até agora são o que chamamos \\neventos discretos\\n — eles têm uma estrutura\\ndefinida. A viagem de Shankar tem início, meio e fim. Se fosse interrompido no meio caminho, o\\nevento seria algo diferente — não seria uma viagem de San Francisco para Washington, mas uma\\nviagem de San Francisco até algum lugar no Kansas. Por outro lado, a categoria de eventos\\ndenotados por \\nVoos\\n tem uma qualidade diferente. Se tomarmos um intervalo pequeno do voo de\\nShankar, digamos, o terceiro período de 20 minutos (enquanto ele espera ansiosamente por um\\nsegundo pacote de amendoins), esse evento ainda será um elemento de \\nVoo\\n. De fato, isso é\\nverdadeiro para qualquer subintervalo.\\nAs categorias de eventos com essa propriedade são chamadas categorias de \\nprocesso\\n ou\\ncategorias de \\neventos líquidos\\n. Qualquer processo \\ne\\n que aconteça em um intervalo também acontece\\nsobre qualquer subintervalo.\\n(e\\n \\n∊\\n \\nProcessos)\\n \\n∧\\n \\nAcontece (e, (t\\n1\\n, t\\n4\\n))\\n \\n∧\\n \\n(t\\n1\\n \\n< t\\n2\\n \\n< t\\n3\\n \\n< t\\n4\\n)\\n \\n⇒\\n \\nAcontece (e, (t\\n2\\n, t\\n3\\n)).\\nA distinção entre eventos líquidos e não líquidos é exatamente análoga à diferença entre\\nsubstâncias, ou \\nmaterial\\n, e objetos individuais, \\nou coisas\\n. De fato, algumas pessoas chamavam os\\ntipos de eventos líquidos de \\nsubstâncias temporais\\n, enquanto itens como manteiga são \\nsubstâncias\\nespaciais\\n.\\n12.3.2 Intervalos de tempo\\nO cálculo de evento abre a possibilidade de falar sobre o tempo e intervalos de tempo. Vamos\\nconsiderar dois tipos de intervalos de tempo: instantes e intervalos estendidos. A distinção é que\\napenas instantes têm duração zero:\\nPartição\\n({\\nInstantes, IntervalosEstendidos\\n}, \\nIntervalos\\n)\\ni\\n \\n∊\\n \\nInstantes\\n \\n⇔\\n \\nDuração\\n(\\ni\\n) = \\nSegundos\\n(0).\\nEm seguida, criamos uma escala de tempo e pontos associados nessa escala a instantes, o que nos\\nfornece tempos absolutos. A escala de tempo é arbitrária; vamos medi-la em segundos e dizer que o\\ninstante referente à meia-noite (GMT) em 1\\no\\n de janeiro de 1900 tem tempo 0. As funções \\nInício\\n e\\nFim\\n escolhem os instantes mais antigos e mais recentes em um intervalo, e a função \\nInstante\\n entrega\\no ponto na escala de tempo correspondente a um instante. A função \\nDuração\\n fornece a diferença\\nentre a hora final e a hora inicial.\\nIntervalo\\n(\\ni\\n) \\n⇒\\n \\nDuração\\n(\\ni\\n) = (\\nHora\\n(\\nFim\\n(\\ni\\n)) – \\nHora\\n(\\nInício\\n(\\ni\\n))).\\nInstante\\n(\\nInício\\n(\\nDC\\n1900)) = \\nSegundos\\n(0).\\nInstante\\n(\\nInício\\n (\\nDC\\n2001)) = \\nSegundos\\n(3187324800).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 528}),\n",
       " Document(page_content='Instante(Início (DC2001)) = Segundos(3187324800).\\nInstante\\n(\\nFim\\n(\\nDC\\n2001)) = \\nSegundos\\n(3218860800).\\nDuração\\n(\\nDC\\n2001) = \\nSegundos\\n(31536000).\\nPara tornar mais fácil a leitura desses números, também introduzimos uma função \\nData\\n, que recebe\\nseis argumentos (horas, minutos, segundos, dia, mês e ano) e retorna um ponto no tempo (um\\ninstante):\\nTempo\\n(\\nInício\\n(\\nDC\\n2001)) = \\nData\\n(0, 0, 0, 1, \\njaneiro\\n, 2001)\\nData\\n(0, 20, 21, 24, 1, 1995) = \\nSegundos\\n(3000000000).\\nDois intervalos \\nEncontram\\n se o instante final do primeiro é igual ao instante inicial do segundo. O\\nconjunto de relações de intervalo completo, como proposto por Allen (1983), é mostrado\\ngraficamente na \\nFigura 12.2\\n e a seguir logicamente:\\nEncontram(i, j)\\n⇔\\nFim(i)=Início(j)\\nAntes(i, j)\\n⇔\\nFim(i) < Início(j)\\nDepois(j, i)\\n⇔\\nAntes(i, j)\\nDurante(i, j)\\n⇔\\nInício(j) < Início(i) < Fim(i) < Fim(j)\\nSobrepõe(i, j)\\n⇔\\nInício(i) < Início(j) < Fim(i) < Fim(j)\\nInicia(i, j)\\n⇔\\nInício(i) = Início(j)\\nTermina(i, j)\\n⇔\\nFim(i) = Fim(j)\\nIguala(i, j)\\n⇔\\nInício(i) = Início(j)\\n \\n∧\\n \\nFim(i) = Fim(j)\\nFigura 12.2\\n Predicados em intervalos de tempo.\\nTodos eles têm seu significado intuitivo, com exceção de \\nSobrepõe\\n: tendemos a pensar em\\nsobrepor como simétrico (se \\ni\\n se sobrepõe a \\nj\\n, então \\nj\\n se sobrepõe a \\ni\\n), mas nessa definição,\\nSobrepõe\\n(\\ni\\n, \\nj\\n) só será válido se \\ni\\n iniciar antes de \\nj\\n. Para dizer que o reinado de Elizabeth II seguiu o\\nde George VI, e o reinado de Elvis se sobrepôs aos anos 1950, podemos escrever:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 529}),\n",
       " Document(page_content='Encontram\\n(\\nReinadoDe\\n(\\nGeorge VI\\n), \\nReinadoDe\\n(\\nElizabethII\\n)).\\nSobrepõe\\n(\\nCinquenta\\n, \\nReinadoDe\\n(\\nElvis\\n)).\\nInício\\n(\\nCinquenta\\n) = \\nInício\\n(\\nDC\\n1950).\\nFim\\n(\\nCinquenta\\n) = \\nFim\\n(\\nDC\\n1959).\\n12.3.3 Fluentes e objetos\\nObjetos físicos podem ser visualizados como eventos generalizados, no sentido de que um objeto\\nfísico é um bloco de espaço-tempo. Por exemplo, \\nEstados Unidos\\n pode ser considerado um evento\\nque começou em, digamos, 1776 como uma união de 13 estados e ainda está em desenvolvimento\\nhoje como uma união de 50 estados. Podemos descrever as mudanças de propriedades dos \\nEstados\\nUnidos\\n usando fluentes de estados, tal como \\nPopulação\\n(\\nEstados Unidos\\n). Outra propriedade dos\\nEstados Unidos que muda a cada quatro ou oito anos, exceto quando ocorre algum infortúnio, é seu\\npresidente. Alguém poderia propor que \\nPresidente\\n(\\nEstados Unidos\\n) fosse um termo lógico que\\ndenotasse um objeto diferente em tempos diferentes. Infelizmente, isso não é possível porque um\\ntermo denota exatamente um objeto em dada estrutura de modelo. (O termo \\nPresidente\\n(\\nEstados\\nUnidos\\n, \\nt\\n) pode denotar objetos diferentes, dependendo do valor de \\nt\\n, mas nossa ontologia mantém\\níndices de tempo separados de fluentes.) A única possibilidade é que \\nPresidente\\n(\\nEstados Unidos\\n)\\ndenote um único objeto que consiste em diferentes pessoas em diferentes tempos. Esse objeto é\\nGeorge Washington de 1789 até 1797, John Adams de 1797 até 1801, e assim por diante, como na\\nFigura 12.3\\n. Para dizer que George Washington foi presidente ao longo de 1790, podemos escrever\\nT\\n(\\nIguala\\n(\\nPresidente\\n(\\nEstados Unidos\\n), \\nGeorge Washington\\n), \\nDC\\n1790).\\nUsamos o símbolo da função \\nIgual a\\n em vez do predicado lógico padrão = porque não podemos\\nter um predicado como um argumento para \\nT\\n e porque a interpretação \\nnão\\n é a de que \\nGeorge\\nWashington\\n e \\nPresidente\\n(\\nEstados Unidos\\n) são logicamente idênticos em 1790; a identidade lógica\\nnão é algo que possa mudar com o passar do tempo. A identidade está entre os subeventos de cada\\nobjeto que são definidos pelo período 1790.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 530}),\n",
       " Document(page_content='Figura 12.3\\n Uma visão esquemática do objeto \\nPresidente\\n(\\nEstados Unidos\\n) para os primeiros 15\\nanos de sua existência.\\n12.4 EVENTOS MENTAIS E OBJETOS MENTAIS\\nOs agentes que construímos até agora têm crenças e podem deduzir novas crenças. Ainda assim\\nnenhum deles tem qualquer conhecimento \\nsobre\\n crenças ou \\nsobre\\n dedução. O conhecimento sobre o\\npróprio conhecimento e sobre os processos de raciocínio é útil para controlar a inferência. Por\\nexemplo, suponha que Alice pergunte “Qual é a raiz quadrada de 1764” e Bob responda: “Eu não\\nsei.” Se Alice insiste, “Pense um pouco mais”, Bob deve perceber que, com um pouco mais de\\nraciocínio, essa questão pode de fato ser respondida. Por outro lado, se a questão fosse “Sua mãe\\nestá sentada agora?”, Bob perceberia que raciocinar mais profundamente não deve ajudar.\\nConhecimento sobre o conhecimento de outros agentes também é importante; Bob deverá perceber\\nque sua mãe sabe se está sentada ou não, e uma forma de descobrir isso seria lhe perguntando.\\nO que precisamos ter é um modelo dos objetos mentais que estão na cabeça de alguém (ou na base\\nde conhecimento de alguma coisa) e dos processos mentais que manipulam esses objetos mentais. O\\nmodelo não precisa ser detalhado. Não precisamos ter a capacidade de prever quantos milissegundos\\ndeterminado agente vai demorar para fazer uma dedução. Ficaremos felizes apenas em ser capazes de\\nconcluir que a mãe sabe se está sentada ou não.\\nComeçamos com as \\natitudes proposicionais\\n que um agente pode ter em direção aos objetos\\nmentais: atitudes tais como \\nAcredita\\n, \\nSabe\\n, \\nQuer\\n, \\nPretende\\n e \\nInforma.\\n A dificuldade é que essas\\natitudes não se comportam como predicados “normais”. Por exemplo, suponha que nós tentamos\\nafirmar que Lois sabe que o Super-Homem pode voar:\\nSabe\\n(\\nLois, PodeVoar\\n(\\nSuperHomem\\n)).\\nUma questão menor sobre isso é que normalmente pensamos \\nPodeVoar (SuperHomem\\n) como uma\\nsentença, mas aqui aparece como um termo. Essa questão pode ser remendada apenas reificando\\nPodeVoar\\n(\\nSuperHomem\\n), tornando-o um fluente. Um problema mais grave é que, se for verdade que\\no Super-Homem é o Clark Kent, devemos concluir que Lois sabe que Clark pode voar:\\n(SuperHomem = Clark)\\n \\n∧\\n \\nSabe(Lois, PodeVoar (SuperHomem))\\n|= \\nSabe (Lois, PodeVoar (Clark)).\\nEssa é uma consequência do fato de que o raciocínio com igualdade é parte da lógica.\\nNormalmente isso é uma coisa boa, se o nosso agente souber que 2 + 2 = 4 e 4 < 5, então queremos\\nque o nosso agente saiba que 2 + 2 < 5. Essa propriedade é chamada de \\ntransparência referencial\\n—\\n não importa que termo uma lógica use para se referir a um objeto, o que importa é o objeto ao\\nqual o termo dá nome. Mas, para atitudes proposicionais, como \\nacredita e sabe\\n, gostaríamos de ter\\nopacidade referencial — os termos usados importam porque nem todos os agentes sabem que termos\\nsão correferenciais.\\nA \\nlógica modal\\n foi projetada para resolver esse problema. A lógica regular está preocupada com', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 531}),\n",
       " Document(page_content='uma única modalidade, a da verdade, que nos permite expressar “\\nP\\n é verdadeiro”. A lógica modal\\ninclui operadores modais especiais que levam sentenças (em vez de termos) como argumentos. Por\\nexemplo, “\\nA\\n sabe \\nP\\n” é representado com a notação \\nK\\nA\\nP\\n, onde \\nK\\n é o operador modal para\\nconhecimento. Ele recebe dois argumentos, um agente (escrito como subscrito) e uma sentença. A\\nsintaxe da lógica modal é a mesma que a da lógica de primeira ordem, exceto que as sentenças\\ntambém podem ser formadas com operadores modais.\\nA semântica da lógica modal é mais complicada. Na lógica de primeira ordem, \\num modelo\\n contém\\num conjunto de objetos e uma interpretação que mapeia cada nome para o objeto apropriado, relação\\nou função. Na lógica modal queremos ser capazes de considerar tanto a possibilidade que a\\nidentidade secreta do Super-Homem seja Clark como que não seja. Portanto, vamos precisar de um\\nmodelo mais complicado, que consista em uma coleção de \\nmundos possíveis\\n em vez de apenas um\\nmundo verdadeiro. Os mundos estão ligados em um grafo por \\nrelações de acessibilidade\\n, uma\\nrelação para cada operador modal. Dizemos que o mundo w\\n1\\n é acessível do mundo w\\n0\\n em relação ao\\noperador modal \\nK\\nA\\n se tudo em w\\n1\\n for consistente com o que \\nA\\n sabe em w\\n0\\n, e escrevemos como\\nAcc(\\nK\\nA\\n, w\\n0\\n, w\\n1\\n). Em diagramas como o da \\nFigura 12.4\\n, mostramos a acessibilidade como uma seta\\nentre os mundos possíveis. Como exemplo, no mundo real, Bucareste é a capital da Romênia, mas,\\npara um agente que não sabia disso, outros mundos possíveis são acessíveis, inclusive onde a capital\\nda Romênia seja Sibiu ou Sofia. Presumivelmente, um mundo onde 2 + 2 = 5 não seria acessível a\\nqualquer agente.\\nFigura 12.4\\n Mundos possíveis com relações de acessibilidade \\nK\\nSuper-homem\\n (setas sólidas) e \\nK\\nLois\\n(setas pontilhadas). A proposição \\nR\\n significa que “o boletim do tempo para amanhã é de chuva” e \\nI\\nsignifica “a identidade secreta do Super-Homem é Clark Kent”. Todos os mundos são acessíveis a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 532}),\n",
       " Document(page_content='eles mesmos; as setas de um mundo para si mesmo não são mostradas.\\nEm geral, um átomo de conhecimento \\nK\\nA\\nP\\n é verdadeiro no mundo \\nw\\n se e somente se \\nP\\n for\\nverdadeiro em todo mundo acessível de \\nw\\n. A verdade de sentenças mais complexas é derivada pela\\naplicação recursiva dessa regra e pelas regras normais da lógica de primeira ordem. Isso significa\\nque a lógica modal pode ser usada para raciocinar sobre sentenças de conhecimento aninhadas: o que\\num agente sabe sobre o conhecimento do outro. Por exemplo, podemos dizer que, apesar de Lois não\\nsaber se a identidade secreta do Super-Homem é Clark Kent, ela sabe que Clark sabe:\\nK\\nLois\\n \\n[\\nK\\nClark\\n \\nIdentidade (SuperHomem, Clark)\\n \\n∨\\n \\nK\\nClark\\n \\n¬ Identidade (SuperHomem,\\nClark)].\\nA \\nFigura 12.4\\n mostra alguns mundos possíveis para esse domínio, com relações de acessibilidade\\npara Lois e Super-Homem.\\nNo diagrama superior esquerdo, é do conhecimento comum que o Super-Homem conhece sua\\nprópria identidade, e nem ele ou Lois viram o boletim meteorológico. Assim, em w\\n0\\n os mundos w\\n0\\n e\\nw\\n2\\n são acessíveis ao Super--Homem; talvez a previsão seja de chuva, talvez não. Para Lois, os\\nquatro mundos são acessíveis uns aos outros; ela não sabe nada sobre o boletim ou se Clark é o\\nSuper-Homem. Mas ela sabe que o Super-Homem sabe se ele é Clark porque em cada mundo que é\\nacessível a Lois ou o Super-Homem conhece \\nI\\n ou conhece ¬\\nI.\\n Lois não sabe qual seria o caso, mas\\nde qualquer forma sabe que o Super-Homem sabe.\\nNo diagrama superior direito, é de conhecimento comum que Lois viu o boletim meteorológico.\\nAssim, em \\nw\\n4\\n ela sabe que está previsto chuva e em \\nw\\n6\\n sabe que não está previsto chuva. O Super-\\nHomem não conhece o boletim, mas ele sabe que Lois conhece, porque, em cada mundo acessível\\npara ele, ou ela conhece \\nR\\n ou ¬\\nR\\n.\\nNo diagrama inferior representamos o cenário em que é de conhecimento comum que o Super-\\nHomem conhece sua identidade, e Lois poderia ou não ter visto o boletim meteorológico.\\nRepresentamos isso combinando os dois cenários de cima e acrescentando setas para mostrar que o\\nSuper-Homem não sabe que cenário realmente é válido. Lois sabe, por isso não precisamos\\nadicionar nenhuma seta para ela. Em w\\n0\\n, o Super--Homem ainda sabe \\nI\\n mas não \\nR\\n, e agora ele não\\nsabe se Lois conhece \\nR\\n. Pelo que o Super-Homem sabe, ele poderia estar em w\\n0\\n ou w\\n2\\n, e, neste caso\\nLois não sabe se \\nR\\n é verdadeiro, ou poderia estar em w\\n4\\n, caso ela conheça \\nR\\n, ou w\\n6\\n, caso conheça\\n¬\\nR\\n.\\nHá um número infinito de mundos possíveis, então o truque é apresentar apenas os que você\\nprecisa para representar o que está tentando modelar. Um novo mundo possível é necessário para\\nfalar sobre os diferentes fatos possíveis (por exemplo, a chuva está prevista ou não) ou para falar\\nsobre os diferentes estados de conhecimento (por exemplo, Lois sabe que a chuva está prevista). Isso\\nsignifica que dois mundos possíveis, tais como w\\n4\\n e w\\n0\\n na \\nFigura 12.4\\n, podem ter os mesmos fatos-\\nbase sobre o mundo, mas diferem em suas relações de acessibilidade e, portanto, em fatos sobre o\\nconhecimento.\\nA lógica modal resolve alguns problemas complicados com a interação dos quantificadores e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 533}),\n",
       " Document(page_content='conhecimento. A sentença “Bond sabe que alguém é um espião” é ambígua. A primeira leitura é que\\nexiste alguém em especial que Bond sabe que é um espião; podemos escrever isso como\\n∃\\nx\\n \\nK\\nBond\\nEspião\\n(\\nx\\n),\\nque na lógica modal significa que existe um \\nx\\n que, em todos os mundos acessíveis, Bond sabe ser um\\nespião. A segunda leitura é que Bond só sabe que há pelo menos um espião:\\nK\\nBond\\n \\n∃\\nx\\n \\nEspião\\n(\\nx\\n).\\nA interpretação lógica modal é que em cada mundo acessível há um \\nx\\n que é um espião, mas não\\nprecisa ser o mesmo \\nx\\n em cada mundo.\\nAgora que temos um operador modal para o conhecimento, podemos escrever axiomas para ele.\\nEm primeiro lugar, podemos dizer que os agentes são capazes de fazer deduções; se um agente sabe\\nP\\n e sabe que \\nP\\n implica \\nQ\\n, então o agente sabe \\nQ\\n:\\n(\\nK\\nA\\nP\\n \\n∧\\n \\nK\\nA\\n (\\nP\\n \\n⇒\\n \\nQ\\n)) \\n⇒\\nK\\nA\\nQ\\n.\\nA partir daí (e de algumas outras regras sobre identidades lógicas), podemos estabelecer que \\nK\\nA\\n(\\nP\\n∨\\n ¬ \\nP\\n) é uma tautologia; cada agente sabe que cada proposição \\nP\\n é verdadeira ou falsa. Por outro\\nlado, (\\nK\\nA\\nP\\n)\\n∨\\n (\\nK\\nA\\n ¬ \\nP\\n) não é uma tautologia; em geral, haverá um monte de proposições que um\\nagente não sabe se são verdadeiras e não sabe se são falsas.\\nDiz-se (voltando a Platão) que o conhecimento é uma crença verdadeira justificada. Ou seja, se for\\nverdadeiro, se você acreditar e se tiver uma boa razão que não possa ser contestada, então você\\nsabe. Isso significa que, se você souber alguma coisa, deve ser verdadeira, e temos o axioma:\\nK\\nA\\nP\\n \\n⇒\\n \\nP\\n.\\nAlém disso, agentes lógicos devem ser capazes de olhar para o seu próprio conhecimento. Se\\nsouberem algo, então eles sabem que sabem disto:\\nK\\nA\\nP\\n \\n⇒\\n \\nK\\nA\\n(\\nK\\nA\\nP\\n).\\nPodemos definir axiomas semelhantes para a crença (muitas vezes denotada por \\nB\\n) e outras\\nmodalidades. No entanto, um problema com a abordagem da lógica modal é que ele assume a\\nonisciência lógica na parte dos agentes. Ou seja, se um agente sabe um conjunto de axiomas, então\\nele sabe todas as consequências desses axiomas. Essa é uma área instável, mesmo para a noção um\\ntanto abstrata de conhecimento, mas parece ainda pior para a crença porque a crença tem mais\\nconotação de se referir a coisas que são representadas fisicamente no agente, e não apenas\\npotencialmente derivável. Houve tentativas de definir uma forma de racionalidade limitada dos\\nagentes para dizer que os agentes acreditam nas afirmações que podem ser derivadas com a\\naplicação de não mais do que \\nk\\n etapas de raciocínio ou não mais que \\ns\\n segundos de computação.\\nEssas tentativas têm sido geralmente insatisfatórias.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 534}),\n",
       " Document(page_content='12.5 SISTEMAS DE RACIOCÍNIO PARA CATEGORIAS\\nVimos que as categorias são os principais blocos de construção de qualquer esquema de\\nrepresentação de conhecimento em grande escala. Esta seção descreve sistemas especialmente\\nprojetados para organizar e raciocinar com categorias. Existem duas famílias de sistemas\\nintimamente relacionadas: as \\nredes semânticas\\n oferecem auxílios gráficos para visualização de uma\\nbase de conhecimento e algoritmos eficientes para dedução de propriedades de um objeto, de acordo\\ncom sua pertinência a uma categoria; as \\nlógicas de descrição\\n fornecem uma linguagem formal para\\nconstrução e combinação de definições de categorias e algoritmos eficientes para definir\\nrelacionamentos de subconjuntos e superconjuntos entre categorias.\\n12.5.1 Redes semânticas\\nEm 1909, Charles S. Peirce propôs uma notação gráfica de nós e arcos, denominada \\ngrafos\\nexistenciais\\n, que ele chamou de “lógica do futuro”. Desse modo, teve início um longo debate entre\\ndefensores da “lógica” e defensores de “redes semânticas”. Infelizmente, o debate obscureceu o fato\\nde que as redes semânticas — pelo menos aquelas que têm semânticas bem definidas — \\nsão\\n uma\\nforma de lógica. A notação que as redes semânticas fornecem para certos tipos de sentenças com\\nfrequência é mais conveniente, mas, se abstrairmos as questões de “interface humana”, os conceitos\\nsubjacentes — objetos, relações, quantificação, e assim por diante — serão os mesmos.\\nExistem muitas variantes de redes semânticas, mas todas são capazes de representar objetos\\nindividuais, categorias de objetos e relações entre objetos. Uma notação gráfica típica exibe nomes\\nde objetos ou categorias em elipses ou retângulos e os conecta por meio de arcos rotulados. Por\\nexemplo, a \\nFigura 12.5\\n tem um arco \\nElementoDe\\n entre \\nMaria\\n e \\nPessoasFemininas\\n, que corresponde\\nà asserção lógica \\nMaria\\n \\n∊\\n \\nPessoasFemininas\\n; de modo semelhante, o arco \\nIrmãDe\\n entre \\nMaria\\n e\\nJoão\\n corresponde à asserção \\nIrmãDe\\n(\\nMaria\\n, \\nJoão\\n). Podemos conectar categorias usando arcos\\nSubconjuntoDe\\n, e assim por diante. É tão divertido desenhar bolhas e setas, que podemos nos\\nempolgar. Por exemplo, sabemos que pessoas têm pessoas femininas como mães e, assim, podemos\\ntraçar um arco \\nTemMãe\\n de \\nPessoas\\n para \\nPessoasFemininas\\n? A resposta é não, porque \\nTemMãe\\n é\\numa relação entre uma pessoa e sua mãe, e categorias não têm mães.\\n5\\nFigura 12.5\\n Uma rede semântica com quatro objetos (João, Maria, 1 e 2) e quatro categorias. As', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 535}),\n",
       " Document(page_content='relações são denotadas por arcos rotulados.\\nPor essa razão, usamos uma notação especial — o arco identificado por retângulo de aresta dupla\\n— na \\nFigura 12.5\\n. Esse arco assegura que:\\n∀\\nx x\\n \\n∊\\n \\nPessoas\\n \\n⇒\\n [\\n∀\\ny TemMãe\\n(\\nx, y\\n) \\n⇒\\n \\ny\\n \\n∊\\n \\nPessoasFemininas\\n].\\nTambém queremos afirmar que as pessoas têm duas pernas, isto é,\\n∀\\nx x\\n \\n∊\\n \\nPessoas\\n \\n⇒\\n \\nPernas\\n(\\nx\\n, 2).\\nComo antes, precisamos ser cuidadosos para não afirmar que uma categoria tem pernas; o arco de\\nretângulo com arestas simples da \\nFigura 12.5\\n é usado para afirmar propriedades de todos os\\nelementos de uma categoria.\\nA notação de rede semântica torna muito conveniente executar o raciocínio de \\nherança\\n do tipo\\nintroduzido na \\nSeção 12.2\\n. Por exemplo, pelo fato de ser uma pessoa, Maria herda a propriedade de\\nter duas pernas. Desse modo, para descobrir quantas pernas Maria tem, o algoritmo de herança segue\\no arco \\nElementoDe\\n desde Maria até a categoria a que ela pertence e depois segue arcos\\nSubconjuntoDe\\n pela hierarquia, até encontrar uma categoria para a qual exista um arco \\nPernas\\nidentificado por um retângulo — nesse caso, a categoria \\nPessoas\\n. A simplicidade e a eficiência\\ndesse mecanismo de inferência, comparado à prova de teoremas lógicos, foi um dos principais\\nfatores de atração das redes semânticas.\\nA herança fica complicada quando um objeto pode pertencer a mais de uma categoria ou quando\\numa categoria pode ser um subconjunto de mais de uma outra categoria; isso se chama \\nherança\\nmúltipla\\n. Em tais casos, o algoritmo de herança pode encontrar dois ou mais valores conflitantes que\\nrespondem à consulta. Por essa razão, a herança múltipla foi banida de algumas linguagens de\\nprogramação orientada a objetos\\n (POO), como Java, que utilizam a herança em uma hierarquia de\\nclasses. Em geral, isso é permitido em redes semânticas, mas adiaremos a discussão do assunto até a\\nSeção 12.6\\n.\\nO leitor deve ter notado uma desvantagem óbvia da notação de rede semântica, em comparação\\ncom a lógica de primeira ordem: o fato de que arcos entre bolhas representam apenas relações\\nbinárias\\n. Por exemplo, a sentença \\nVoar\\n(\\nShankar\\n, \\nNova York\\n, \\nNovaDéli\\n, \\nOntem\\n) não pode ser\\ndeclarada diretamente em uma rede semântica. Todavia, \\npodemos\\n obter o efeito de asserções \\nn\\n-árias\\nreificando a proposição em si como um evento pertencente a uma categoria de eventos apropriada. A\\nFigura 12.6\\n mostra a estrutura de rede semântica para esse evento específico. Note que a restrição\\npara relações binárias força a criação de uma rica ontologia de conceitos reificados.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 536}),\n",
       " Document(page_content='Figura 12.6\\n Um fragmento de uma rede semântica mostrando a representação da asserção lógica\\nVoar\\n(\\nShankar\\n, \\nNovaYork\\n, \\nNovaDéli\\n, \\nOntem\\n).\\nA reificação de proposições torna possível representar toda sentença atômica básica livre de\\nfunções de lógica de primeira ordem na notação de rede semântica. Certos tipos de sentenças\\nuniversalmente quantificadas podem ser declaradas com o uso de arcos inversos e com as setas\\nidentificadas por retângulos de arestas simples e de arestas duplas aplicadas a categorias, mas isso\\nainda nos deixa bem longe da lógica de primeira ordem completa. Negação, disjunção, símbolos de\\nfunções aninhadas e quantificação existencial — todos estão faltando. Contudo, é \\npossível\\n estender a\\nnotação para torná-la equivalente à lógica de primeira ordem — como nos grafos existenciais de\\nPeirce —, mas isso nega uma das principais vantagens das redes semânticas: a simplicidade e a\\ntransparência dos processos de inferência. Os projetistas podem construir uma grande rede e ainda\\nter uma boa ideia sobre que consultas serão eficientes porque (a) é fácil visualizar as etapas pelas\\nquais o procedimento de inferência vai passar e (b) em alguns casos, a linguagem de consulta é tão\\nsimples que consultas difíceis não podem ser formuladas. Em casos em que a capacidade de\\nexpressão se mostra excessivamente limitante, muitos sistemas de redes semânticas fornecem a\\nconexão procedural\\n para preencher as lacunas. A conexão procedural é uma técnica por meio da\\nqual uma consulta sobre (ou, às vezes, uma asserção de) certa relação resulta em uma chamada a um\\nprocedimento especial projetado para essa relação, e não a um algoritmo de inferência geral.\\nUm dos aspectos mais importantes das redes semânticas é sua habilidade para representar \\nvalores\\ndefault\\n correspondentes a categorias. Examinando a \\nFigura 12.5\\n cuidadosamente, notamos que João\\ntem uma perna, apesar do fato de ser uma pessoa e de todas as pessoas terem duas pernas. Em uma\\nBC estritamente lógica, isso seria uma contradição; porém, em uma rede semântica, a afirmação de\\nque todas as pessoas têm duas pernas apresenta apenas um \\nstatus\\n default; ou seja, supõe-se que uma\\npessoa tenha duas pernas, a não ser que isso seja contestado por informações mais específicas. A\\nsemântica default é naturalmente imposta pelo algoritmo de herança porque segue arcos ascendentes\\ndesde o próprio objeto (João, nesse caso) e para tão logo encontra um valor. Dizemos que o default é\\nredefinido\\n pelo valor mais específico. Observe que também poderíamos redefinir o número default\\nde pernas criando uma categoria \\nPessoasComUmaPerna\\n, um subconjunto de \\nPessoas\\n ao qual \\nJoão\\npertence.\\nPodemos conservar uma semântica estritamente lógica para a rede se dissermos que a asserção\\nPernas\\n para \\nPessoas\\n inclui uma exceção referente a João:\\n∀\\nx x\\n \\n∊\\nPessoas\\n \\n∧\\n \\nx\\n ≠ \\nJoão\\n \\n⇒\\n \\nPernas\\n(\\nx\\n, 2).\\nPara uma rede \\nfixa\\n, isso é semanticamente adequado, mas será muito menos conciso que a própria\\nnotação de rede, no caso de haver um grande número de exceções. Porém, para uma rede que será\\natualizada com outras asserções, uma abordagem desse tipo falhará — na realidade, queremos dizer\\nque todas as pessoas com uma única perna, ainda que desconhecidas, também serão exceções. A\\nSeção 12.6\\n examina com mais profundidade essa questão e o raciocínio default em geral.\\n12.5.2 Lógicas de descrição', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 537}),\n",
       " Document(page_content='A sintaxe da lógica de primeira ordem foi projetada para facilitar a tarefa de descrever objetos.\\nAs \\nlógicas de descrição\\n são notações projetadas para tornar mais fácil descrever definições e\\npropriedades de categorias. Os sistemas de lógica de descrição evoluíram a partir das redes\\nsemânticas em resposta à pressão para formalizar o que as redes significam enquanto é mantida a\\nênfase na estrutura taxonômica como um princípio de organização.\\nAs principais tarefas de inferência para lógicas de descrição são a \\nsubordinação (\\nverificar se uma\\ncategoria é um subconjunto de outra pela comparação de suas definições) e a \\nclassificação (\\nverificar\\nse um objeto pertence a uma categoria). Alguns sistemas também incluem a \\nconsistência\\n de uma\\ndefinição de categoria — se os critérios de pertinência são logicamente satisfatíveis.\\nA linguagem CLASSIC (Borgida \\net al\\n., 1989) é uma lógica de descrição típica. A sintaxe de\\ndescrições de CLASSIC é mostrada na \\nFigura 12.7\\n.\\n6\\n Por exemplo, para dizer que solteiros são\\nhomens adultos não casados, escreveríamos:\\nSolteiro\\n = \\nAnd\\n(\\nNãoCasado\\n, \\nAdulto\\n, \\nHomem\\n).\\nO equivalente em lógica de primeira ordem seria:\\nSolteiro\\n(\\nx\\n) \\n⇔\\n \\nNãoCasado\\n(\\nx\\n) \\n∧\\n \\nAdulto\\n(\\nx\\n) \\n∧\\n \\nHomem\\n(\\nx\\n).\\n        \\nConceito\\n → \\nThing\\n | \\nNomeConceito\\n                          | \\nAnd\\n(\\nConceito\\n,...)\\n                          | \\nAll\\n(\\nNomePapel\\n, \\nConceito\\n)\\n                          | \\nAtLeast\\n(\\nInteiro\\n, \\nNomePapel\\n)\\n                          | \\nAtMost\\n(\\nInteiro\\n, \\nNomePapel\\n)\\n                          | \\nFills\\n(\\nNomePapel\\n, \\nNomeIndivíduo\\n,...)\\n                          | \\nSameAs\\n(\\nCaminho\\n, \\nCaminho\\n)\\n                          | \\nOneOf\\n(\\nNomeIndivíduo\\n,...)\\n        \\nCaminho\\n → [\\nNomePapel\\n,...]\\nFigura 12.7\\n A sintaxe de descrições em um subconjunto da linguagem CLASSIC.\\nNote que a lógica de descrição tem uma álgebra de operações sobre predicados que certamente\\nnão é possível em lógica de primeira ordem. Qualquer descrição em CLASSIC pode ser traduzida\\nem uma sentença equivalente de primeira ordem, mas algumas descrições são mais simples em\\nCLASSIC. Por exemplo, para descrever o conjunto de homens com pelo menos três filhos que estão\\ndesempregados e que são casados com médicas e que têm no máximo duas filhas que são todas\\nprofessoras em departamento de física ou matemática, descreveríamos:\\nAnd\\n(\\nHomem\\n, \\nAtLeast\\n(3, \\nFilho\\n), \\nAtMost\\n(2, \\nFilha\\n),\\nAll\\n(\\nFilho\\n, \\nAnd\\n(\\nDesempregado\\n, \\nCasado\\n, \\nAll\\n(\\nEsposa\\n, \\nMédica\\n))),\\nAll\\n(\\nFilha\\n, \\nAnd\\n(\\nProfessora\\n, \\nFills\\n(\\nDepartamento\\n, \\nFísica\\n, \\nMatemática\\n))))\\nDeixamos como exercício a conversão dessa expressão para lógica de primeira ordem.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 538}),\n",
       " Document(page_content='Talvez o aspecto mais importante das lógicas de descrição seja sua ênfase na tratabilidade da\\ninferência. Uma instância de problema é resolvida descrevendo-se a instância e depois indagando-se\\nse ela está subordinada a uma das diversas categorias de soluções possíveis. Em sistemas comuns de\\nlógica de primeira ordem, com frequência, é impossível prever o tempo da solução. Muitas vezes,\\ncabe ao usuário criar a representação necessária para contornar conjuntos de sentenças que parecem\\nestar fazendo o sistema demorar várias semanas para resolver um problema. Por outro lado, a ênfase\\nem lógicas de descrição é assegurar que os testes de subordinação possam ser resolvidos em tempo\\npolinomial em relação ao tamanho das descrições.\\n7\\nIsso parece maravilhoso em princípio, até se perceber que só se pode ter uma dentre duas\\nconsequências: ou problemas difíceis não podem ser enunciados de modo algum ou eles exigem\\ndescrições exponencialmente extensas! Porém, os resultados de tratabilidade esclarecem que tipos de\\nconstruções causam problemas e, desse modo, ajudam o usuário a compreender o comportamento de\\ndiferentes representações. Por exemplo, normalmente, as lógicas de descrição não têm a \\nnegação\\n e a\\ndisjunção\\n. Cada uma força os sistemas de lógica de primeira ordem a passar por uma análise de\\ncasos potencialmente exponencial, a fim de assegurar completude. CLASSIC permite apenas uma\\nforma limitada de disjunção nas construções \\nFills\\n e \\nOneOf\\n, que tornam possível a disjunção sobre\\nindivíduos explicitamente enumerados, mas não sobre descrições. Com descrições disjuntivas,\\ndefinições aninhadas podem levar facilmente a um número exponencial de rotas alternativas pelas\\nquais uma categoria pode subordinar outra.\\n12.6 RACIOCÍNIO COM INFORMAÇÕES DEFAULT\\nNa seção precedente, vimos um exemplo simples de asserção com \\nstatus\\n de default: as pessoas\\ntêm duas pernas. Esse default pode ser anulado por informações mais específicas, como Long John\\nSilver (o pirata) tem uma perna. Vimos que o mecanismo de herança em redes semânticas implementa\\na redefinição de valores default de uma forma simples e natural. Nesta seção, estudaremos valores\\ndefault de maneira mais geral, com uma visão voltada para a compreensão da semântica de valores\\ndefault, e não apenas visando fornecer um mecanismo procedural.\\n12.6.1 Circunscrição e lógica default\\nVimos dois exemplos de processos de raciocínio que violam a propriedade de \\nmonotonicidade\\n da\\nlógica que foi provada no Capítulo 7.\\n8\\n Nesse capítulo vimos que uma propriedade herdada por todos\\nos membros de uma categoria em uma rede semântica podia ser anulada por informação mais\\nespecífica relativa a uma categoria. Na \\nSeção 9.4.5\\n, vimos que, sob a hipótese do mundo fechado, se\\numa proposição não for mencionada em \\nBC\\n então \\nBC\\n |= ¬\\nα\\n mas \\nBC\\n \\n∧\\n \\nα\\n |= \\nα\\n.\\nA introspecção simples sugere que essas falhas de monotonicidade são muito comuns no\\nraciocínio comum. Parece que os seres humanos frequentemente “saltam para conclusões”. Por\\nexemplo, quando alguém vê um carro estacionado na rua, normalmente fica predisposto a acreditar\\nque o automóvel tem quatro rodas, embora só três estejam visíveis. Agora, a teoria da probabilidade', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 539}),\n",
       " Document(page_content='pode sem dúvida fornecer uma conclusão de que a quarta roda existe com probabilidade elevada,\\nainda que, para a maioria das pessoas, a possibilidade de o carro não ter quatro rodas \\nnão se\\nmanifeste, a menos que apareça alguma nova evidência\\n. Desse modo, parece que a conclusão de\\nhaver quatro rodas é alcançada \\npor default\\n, na ausência de qualquer razão para colocá-la em dúvida.\\nSe surgirem novas evidências — por exemplo, se alguém vir o proprietário transportando uma roda e\\nnotar que o carro está levantado —, então a conclusão poderá ser contestada. Dizemos que essa\\nespécie raciocínio exibe \\nnão monotonicidade\\n porque o conjunto de crenças não cresce\\nmonotonicamente com o tempo à medida que chegam novas evidências. As \\nlógicas não monotônicas\\nforam criadas com noções modificadas de verdade e consequência lógica, a fim de captar tal\\ncomportamento. Examinaremos duas dessas lógicas que foram extensivamente estudadas: a\\ncircunscrição e a lógica default.\\nA \\ncircunscrição\\n pode ser vista como uma versão mais poderosa e precisa da hipótese de mundo\\nfechado. A ideia é especificar determinados predicados que consideramos “tão falsos quanto\\npossíveis”, isto é, falsos para todo objeto, exceto aqueles para os quais se sabe que eles são\\nverdadeiros. Por exemplo, suponha que desejamos afirmar a regra default de que os pássaros voam.\\nIntroduziríamos um predicado, digamos \\nAnormal\\n1\\n(\\nx\\n), e escreveríamos:\\nPássaro\\n(\\nx\\n) \\n∧\\n ¬\\nAnormal\\n1\\n(\\nx\\n) \\n⇒\\n \\nVoa\\n(\\nx\\n).\\nSe dissermos que \\nAnormal\\n1\\n deve ser \\ncircunscrito\\n, um mecanismo de inferência circunscritivo será\\nlevado a supor ¬\\nAnormal\\n1\\n(\\nx\\n), a menos que \\nAnormal\\n1\\n(\\nx\\n) seja conhecido como verdadeiro. Isso\\npermite que a conclusão \\nVoa\\n(\\nTweety\\n) seja tirada da premissa \\nPássaro\\n(\\nTweety\\n), mas a conclusão não\\nserá mais válida se \\nAnormal\\n1\\n(\\nTweety\\n) for afirmada.\\nA circunscrição pode ser visualizada como um exemplo de lógica de \\nmodelo preferencial\\n. Em\\ntais lógicas, uma sentença é consequência lógica (com \\nstatus\\n default) se é verdadeira em todos os\\nmodelos \\npreferenciais\\n da BC, em oposição ao requisito de verdade em \\ntodos\\n os modelos da lógica\\nclássica. No caso da circunscrição, um modelo é preferencial a outro se tem menor número de\\nobjetos anormais.\\n9\\n Vejamos como essa ideia funciona no contexto de herança múltipla em redes\\nsemânticas. O exemplo-padrão em que a herança múltipla é problemática denomina-se “diamante de\\nNixon” (ou “\\nNixon diamond\\n”). Ele surge a partir da observação de que Richard Nixon era ao mesmo\\ntempo um quacre do inglês “quaker” (e, consequentemente, um pacifista por default) e um\\nrepublicano (e, consequentemente, um não pacifista por default). Isso pode ser representado da\\nseguinte maneira:\\nRepublicano\\n(\\nNixon\\n) \\n∧\\n \\nQuacre\\n(\\nNixon\\n).\\nRepublicano\\n(\\nx\\n) \\n∧\\n ¬\\nAnormal\\n2\\n(\\nx\\n)) \\n⇒\\n ¬\\nPacifista\\n(\\nx\\n).\\nQuacre\\n(\\nx\\n) \\n∧\\n ¬\\nAnormal\\n3\\n(\\nx\\n) \\n⇒\\n \\nPacifista\\n(\\nx\\n).\\nSe circunscrevermos \\nAnormal\\n2\\n e \\nAnormal\\n3\\n, haverá dois modelos preferenciais: um modelo em que\\nAnormal\\n2\\n(\\nNixon\\n) e \\nPacifista\\n(\\nNixon\\n) são válidas e outro em que \\nAnormal\\n3\\n(\\nNixon\\n) e\\n¬\\nPacifista\\n(\\nNixon\\n) são válidas. Desse modo, o mecanismo de inferência circunscritivo permanece\\ncorretamente agnóstico sobre o fato de Nixon ser ou não pacifista. Se desejarmos, além disso,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 540}),\n",
       " Document(page_content='afirmar que as crenças religiosas devem ter precedência sobre as crenças políticas, poderemos\\nempregar um formalismo chamado \\ncircunscrição priorizada\\n para dar preferência a modelos em que\\nAnormal\\n3\\n é minimizada.\\nA \\nlógica default\\n é um formalismo em que podem ser escritas \\nregras default\\n para gerar\\nconclusões contingentes e não monotônicas. Uma regra default é semelhante a:\\nPássaro\\n(\\nx\\n) : \\nVoa\\n(\\nx\\n)/\\nVoa\\n(\\nx\\n).\\nEssa regra significa que, se \\nPássaro\\n(\\nx\\n) é verdadeira e se \\nVoa\\n(\\nx\\n) é consistente com a base de\\nconhecimento, então \\nVoa\\n(\\nx\\n) pode ser concluída por default. Em geral, uma regra default tem a forma:\\nP\\n : \\nJ\\n1\\n,…, \\nJ\\nn\\n/\\nC\\nonde \\nP\\n é chamado pré-requisito, \\nC\\n é a conclusão e \\nJ\\ni\\n são as justificativas — se for possível provar\\nque qualquer uma delas é falsa, então a conclusão não poderá ser derivada. Qualquer variável que\\naparecer em \\nJ\\ni\\n ou \\nC\\n também terá de aparecer em \\nP\\n. O exemplo do dilema de Nixon pode ser\\nrepresentado em lógica default com um fato e duas regras default:\\nRepublicano\\n(\\nNixon\\n) \\n∧\\n \\nQuacre\\n(\\nNixon\\n).\\nRepublicano\\n(\\nx\\n) : ¬\\nPacifista\\n(\\nx\\n) / ¬\\nPacifista\\n(\\nx\\n).\\nQuacre\\n(\\nx\\n) : \\nPacifista\\n(\\nx\\n) / \\nPacifista\\n(\\nx\\n).\\nPara interpretar o que significam as regras default, definimos a noção de \\nextensão\\n de uma teoria\\ndefault como um conjunto máximo de consequências da teoria. Isto é, uma extensão \\nS\\n consiste nos\\nfatos conhecidos originais e em um conjunto de conclusões das regras default, tais que nenhuma\\nconclusão adicional possa ser obtida de \\nS\\n e que as justificativas de toda conclusão default em \\nS\\nsejam consistentes com \\nS\\n. Como no caso dos modelos preferidos na circunscrição, temos duas\\nextensões possíveis para o dilema de Nixon: uma em que ele é pacifista e uma em que ele não é\\npacifista. Existem esquemas de priorização nos quais algumas regras default podem ter precedência\\nsobre outras, permitindo que algumas ambiguidades sejam resolvidas.\\nDesde 1980, quando as lógicas não monotônicas foram propostas pela primeira vez, houve um\\ngrande progresso na compreensão de suas propriedades matemáticas. Porém ainda existem questões\\nnão resolvidas. Por exemplo, se “Os carros têm quatro rodas” é falso, o que significa ter essa\\nasserção em uma base de conhecimento? Que conjunto de regras default seria interessante ter? Se não\\npudermos decidir, para cada regra separadamente, se ela pertence à nossa base de conhecimento,\\nentão teremos um sério problema de falta de modularidade. Por fim, como as crenças que têm \\nstatus\\nde default podem ser usadas na tomada de decisões? Provavelmente, essa é a questão mais difícil\\npara o raciocínio default. Com frequência, decisões envolvem compromissos, e portanto é necessário\\ncomparar as \\nintensidades\\n de crença nos resultados de diferentes ações e o custo de tomar uma\\ndecisão errada. Nos casos em que as mesmas espécies de decisões estão sendo tomadas\\nrepetidamente, é possível interpretar regras default como declarações de “probabilidade de limiar”.\\nPor exemplo, a regra default “Meus freios estão sempre OK” na realidade significa “A probabilidade\\nde que meus freios estejam OK, não sendo dada nenhuma outra informação, é suficientemente alta', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 541}),\n",
       " Document(page_content='para que a decisão ótima no meu caso seja dirigir sem verificá-los”. Quando o contexto de decisão\\nse altera — por exemplo, quando se está dirigindo um caminhão pesadamente carregado montanha\\nabaixo em uma estrada íngreme —, a regra default se torna repentinamente inadequada, embora não\\nexista nenhuma evidência a sugerir que os freios estão defeituosos. Essas considerações levaram\\nalguns pesquisadores a refletir sobre como incorporar o raciocínio com defaults dentro da teoria da\\nprobabilidade ou da utilidade.\\n12.6.2 Sistemas de manutenção de verdade\\nVimos que muitas das inferências derivadas por um sistema de representação de conhecimento só\\nterão \\nstatus\\n de default, em vez de estarem absolutamente certas. Inevitavelmente, alguns desses fatos\\ndeduzidos se mostrarão incorretos e terão de ser reconsiderados em face de novas informações. Esse\\nprocesso é chamado \\nrevisão de crenças\\n.\\n10\\n Suponha que uma base de conhecimento \\nBC\\n contenha uma\\nsentença \\nP\\n — talvez uma conclusão default registrada por um algoritmo de encadeamento para a\\nfrente ou talvez apenas uma asserção incorreta — e queremos executar \\nTELL\\n(\\nBC\\n, ¬\\nP\\n). Para evitar\\ncriar uma contradição, primeiro devemos executar \\nRETRACT\\n(\\nBC\\n, \\nP\\n). Parece bem fácil.\\nNo entanto, surgiriam problemas se quaisquer sentenças \\nadicionais\\n fossem deduzidas a partir de \\nP\\ne afirmadas na BC. Por exemplo, a implicação \\nP\\n \\n⇒\\n \\nQ\\n poderia ter sido usada para adicionar \\nQ\\n. A\\n“solução” óbvia — reconsiderar todas as sentenças deduzidas a partir de \\nP\\n — falhará porque tais\\nsentenças podem ter outras justificativas além de \\nP\\n. Por exemplo, se \\nR\\n e \\nR\\n \\n⇒\\n \\nQ\\n também estiverem na\\nBC, então \\nQ\\n não terá de ser removida. Os \\nsistemas de manutenção de verdade\\n, ou TMSs (do inglês\\n“Truth Maintenance Systems”), foram projetados para manipular exatamente esses tipos de\\ncomplicações.\\nUma abordagem muito simples para manutenção de verdade é manter o controle da ordem em que\\nas sentenças são apresentadas à base de conhecimento, numerando-as de \\nP\\n1\\n até \\nP\\nn\\n. Quando a\\nchamada RETRACT(\\nBC\\n, \\nP\\ni\\n) é feita, o sistema reverte ao estado imediatamente anterior à adição de\\nP\\ni\\n, removendo tanto \\nP\\ni\\n quanto quaisquer inferências que tenham sido derivadas de \\nP\\ni\\n. As sentenças\\nP\\ni\\n+1\\n até \\nP\\nn\\n podem então ser novamente adicionadas. Isso é simples e garante que a base de\\nconhecimento será consistente, mas a reconsideração de \\nP\\ni\\n exige a retirada e a reafirmação de \\nn\\n – \\ni\\nsentenças, além de ser preciso desfazer e refazer todas as inferências obtidas a partir dessas\\nsentenças. Em sistemas aos quais estão sendo adicionados muitos fatos — como grandes bancos de\\ndados comerciais —, isso é impraticável.\\nUma abordagem mais eficiente é o sistema de manutenção de verdade baseado em justificativa, ou\\nJTMS\\n. Em um JTMS, cada sentença na base de conhecimento é anotada com uma \\njustificativa\\n que\\nconsiste no conjunto de sentenças a partir das quais ela foi deduzida. Por exemplo, se a base de\\nconhecimento já contém \\nP\\n \\n⇒\\n \\nQ\\n, então TELL(\\nP\\n) fará \\nQ\\n ser adicionada com a justificativa {\\nP\\n, \\nP\\n \\n⇒\\nQ\\n}. Em geral, uma sentença pode ter qualquer número de justificativas. As justificativas tornam a\\nretração eficiente. Dada a chamada RETRACT(\\nP\\n), o JTMS eliminará exatamente as sentenças para\\nas quais \\nP\\n é um elemento de toda justificativa. Assim, se uma sentença \\nQ\\n tivesse a única justificativa\\n{\\nP\\n, \\nP\\n \\n⇒\\n \\nQ\\n}, ela seria removida; se tivesse a justificativa adicional {\\nP\\n, \\nP\\n \\n∨\\n \\nR\\n \\n⇒\\n \\nQ\\n}, ela ainda', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 542}),\n",
       " Document(page_content='seria removida; mas, se também tivesse a justificativa {\\nR\\n, \\nP\\n \\n∨\\n \\nR\\n \\n⇒\\n \\nQ\\n}, ela seria poupada. Desse\\nmodo, o tempo necessário para a retração de \\nP\\n depende apenas do número de sentenças derivadas de\\nP\\n, e não do número de outras sentenças adicionadas desde que \\nP\\n entrou na base de conhecimento.\\nO JTMS pressupõe que as sentenças que são consideradas uma vez provavelmente serão\\nconsideradas de novo; assim, em vez de eliminar inteiramente uma sentença da base de conhecimento\\nquando ela perder todas as justificativas, simplesmente marcamos a sentença para indicar que ela\\nestá \\nfora\\n da base de conhecimento. Se uma asserção subsequente restaurar uma das justificativas,\\nmarcaremos a sentença indicando que ela está \\ndentro\\n outra vez. Desse modo, o JTMS preserva todas\\nas cadeias de inferência que utiliza e não precisa derivar novamente as sentenças quando uma\\njustificativa se torna válida de novo.\\nAlém de manipular a retirada de informações incorretas, os TMSs podem ser usados para acelerar\\na análise de várias situações hipotéticas. Por exemplo, suponha que o comitê olímpico da Romênia\\nesteja escolhendo locais para os eventos de natação, atletismo e equitação dos jogos de 2048 a serem\\nrealizados na Romênia. Por exemplo, seja a primeira hipótese \\nLocal\\n(\\nNatação\\n, \\nPitesti\\n),\\nLocal\\n(\\nAtletismo\\n, \\nBucareste\\n) e \\nLocal\\n(\\nEquitação\\n, \\nArad\\n). É necessário bastante raciocínio para\\ndeterminar as consequências logísticas e, portanto, o interesse dessa seleção. Se, em vez disso,\\nquisermos considerar \\nLocal\\n(\\nAtletismo\\n, \\nSibiu\\n), o TMS evitará a necessidade de começar de novo\\ndesde o início. Nesse caso, simplesmente iremos retirar \\nLocal\\n(\\nAtletismo\\n, \\nBucareste\\n) e afirmar\\nLocal\\n(\\nAtletismo\\n, \\nSibiu\\n), e o TMS cuidará das revisões necessárias. As cadeias de inferência geradas\\na partir da escolha de Bucareste poderão ser reutilizadas com Sibiu, desde que as conclusões sejam\\nas mesmas.\\nUm sistema de manutenção de verdade baseado em hipóteses, ou \\nATMS\\n, foi projetado para tornar\\nparticularmente eficiente esse tipo de troca de contexto entre mundos hipotéticos. Em um JTMS, a\\nmanutenção de justificativas permite a rápida movimentação de um estado para outro fazendo-se\\nalgumas retiradas e asserções, mas, em qualquer instante, apenas um estado é representado. Um\\nATMS representa ao mesmo tempo \\ntodos\\n os estados que já foram considerados. Enquanto um JTMS\\nsimplesmente identifica cada sentença como \\ndentro\\n ou \\nfora\\n, um ATMS controla, para cada sentença,\\nque hipóteses tornariam a sentença verdadeira. Em outras palavras, cada sentença tem um rótulo que\\nconsiste em um conjunto de conjuntos de hipóteses. A sentença é válida apenas nos casos em que\\ntodas as hipóteses de um dos conjuntos de hipóteses são válidas.\\nOs sistemas de manutenção de verdade também fornecem um mecanismo para gerar \\nexplicações\\n.\\nTecnicamente, uma explicação de uma sentença \\nP\\n é um conjunto de sentenças \\nE\\n tal que \\nE\\n tem \\nP\\n como\\nconsequência lógica. Se já soubermos que as sentenças contidas em \\nE\\n são verdadeiras, então \\nE\\nsimplesmente fornecerá uma base suficiente para provar que \\nP\\n deve ocorrer. Porém, as explicações\\ntambém podem incluir \\nhipóteses\\n — sentenças que não sabemos se são verdadeiras, mas que seriam\\nsuficientes para provar \\nP\\n se fossem verdadeiras. Por exemplo, poderíamos não ter informações\\nsuficientes para provar que o carro de alguém não dá partida, mas uma explicação razoável poderia\\nincluir a hipótese de a bateria estar descarregada. Essa hipótese, combinada com o conhecimento de\\ncomo os carros operam, explica o não comportamento observado. Na maioria dos casos,\\npreferiremos uma explicação \\nE\\n que seja minimal, significando que não existe nenhum subconjunto\\npróprio de \\nE\\n que também seja uma explicação. Um ATMS pode gerar explicações para o problema\\ndo “carro que não dá partida” fazendo suposições (como “carro tem gasolina” ou “bateria', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 543}),\n",
       " Document(page_content='descarregada”) em qualquer ordem que desejarmos, mesmo que algumas hipóteses sejam\\ncontraditórias. Em seguida, examinaremos o rótulo correspondente à sentença “carro não dá partida”\\npara examinar os conjuntos de hipóteses que justificariam a sentença.\\nOs algoritmos exatos utilizados para implementar os sistemas de manutenção de verdade são um\\npouco complicados, e não os abordaremos aqui. A complexidade computacional do problema de\\nmanutenção de verdade é pelo menos tão grande quanto a da inferência proposicional, isto é, NP-\\ndifícil. Portanto, você não deve esperar que a manutenção de verdade seja uma panaceia. Porém,\\nquando utilizado com cuidado, um TMS pode proporcionar aumento substancial na habilidade de um\\nsistema lógico para tratar ambientes e hipóteses complexas.\\n12.7 O MUNDO DE COMPRAS DA INTERNET\\nNesta seção final juntamos tudo o que aprendemos para codificar o conhecimento para um agente\\nde pesquisa de compras que ajuda um comprador a encontrar ofertas de produtos na Internet. O\\nagente de compras recebe uma descrição do produto feita pelo comprador e tem a tarefa de produzir\\numa lista de páginas da Web que oferecem tal produto à venda classificando quais ofertas são\\nmelhores. Em alguns casos, a descrição do produto do comprador será precisa, como em \\ncâmera\\ndigital\\n \\nCanon Rebel XTi\\n, e a tarefa será descobrir a(s) loja(s) com a melhor oferta. Em outros casos,\\na descrição será especificada apenas parcialmente, como em câmera digital por menos de \\n$300\\n, e o\\nagente terá de comparar diferentes produtos.\\nO ambiente do agente de compras é a World Wide Web em toda a sua complexidade — não um\\nminiambiente simulado. As percepções do agente são páginas Web mas, enquanto um usuário humano\\nda Web veria páginas exibidas como um array de pixels na tela, o agente de compras perceberá uma\\npágina como uma cadeia de caracteres que consiste em palavras comuns entremeadas com comandos\\nde formatação na linguagem de marcação HTML. A \\nFigura 12.8\\n mostra uma página da Web e uma\\ncadeia de caracteres HTML correspondente. O problema de percepção para o agente de compras\\nenvolve a extração de informações úteis de percepções desse tipo.\\nExemplo de Loja On-line\\nSelecione\\n em nossa excelente linha de produtos:\\n• Computadores\\n• Câmeras\\n• Livros\\n• Vídeos\\n• Música\\n_____________________________________________________________________________________________________________\\n \\n<h1>Exemplo de Loja On-line</h1>\\n<i>Selecione</i> em nossa excelente linha de produtos:\\n<ul>\\n<li> <a href=”http://example.com/compu”>Computadores</a>', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 544}),\n",
       " Document(page_content='<li> <a href=”http://example.com/camer”>Câmeras</a>\\n<li> <a href=”http://example.com/livros”>Livros</a>\\n<li> <a href=”http://example.com/video”>Vídeos</a>\\n<li> <a href=”http://example.com/music”>Música</a>\\n</ul>\\nFigura 12.8\\n A página da Web de uma loja on-line genérica na forma percebida pelo usuário humano\\nde um navegador (parte superior) e a cadeia de texto em HTML correspondente conforme é\\npercebida pelo navegador ou pelo agente de compras (parte inferior). Em HTML, caracteres entre <\\ne > são diretivas de marcação que especificam como a página é exibida. Por exemplo, a cadeia\\n<i>Selecione</i> significa alternar para fonte em itálico, exibir a palavra \\nSelecionar\\n e depois\\nencerrar o uso da fonte em itálico. Um identificador de página como \\nhttp://example.com/livros\\n é\\nchamado URL (Uniform Resource Locator — localizador de recursos uniforme). A marcação <a\\nhref= “url\">\\nLivros\\n</a> significa criar um link de hipertexto para \\nurl\\n com o \\ntexto de âncora\\n \\nLivros.\\nSem dúvida, a percepção nas páginas da Web é mais fácil que, digamos, a percepção enquanto se\\ndirige um táxi no Cairo. Todavia, existem complicações na tarefa de percepção na Internet. A página\\nWeb da \\nFigura 12.8\\n é muito simples em comparação com sites de compras reais, que podem incluir\\nCSS, cookies, Java, JavaScript, Flash, protocolos de exclusão de robôs, HTML mal formada,\\narquivos de som, filmes e texto que só aparece como parte de uma imagem JPEG. Um agente que\\npode lidar com toda a Internet é quase tão complexo quanto um robô que pode se mover no mundo\\nreal. Vamos nos concentrar em um agente simples que ignora a maior parte dessas complicações.\\nA primeira tarefa do agente é encontrar ofertas de produtos relevantes para a consulta. Se a\\nconsulta for “notebooks”, uma página da Web com uma resenha dos notebooks mais recentes de\\ntecnologia de ponta seria relevante, mas, se não fornecer uma maneira de comprar, não é uma oferta.\\nPor ora, podemos dizer que uma página é uma oferta se contiver as palavras “comprar” ou “preço”\\nou “adicionar ao carrinho” dentro de um link HTML ou formulário na página. Por exemplo, se a\\npágina contiver uma cadeia da forma “<a… adicionar ao carrinho… </ a”, é uma oferta. Isso poderia\\nser representado em lógica de primeira ordem, mas é mais simples codificá-lo em código de\\nprograma. Mostraremos como fazer a extração de informações mais sofisticadas na \\nSeção 22.4\\n.\\n12.7.1 Seguindo links\\nA estratégia é começar na homepage de uma loja on-line e examinar todas as páginas que podem\\nser alcançadas seguindo-se links relevantes.\\n11\\n O agente terá conhecimento de várias lojas, por\\nexemplo:\\nAmazon\\n \\n∊\\n \\nLojasOn-line\\n \\n∧\\n \\nHomepage\\n(\\nAmazon, “amazon.com\\n”)\\nEbay\\n \\n∊\\n \\nLojasOn-line\\n \\n∧\\n \\nHomepage\\n(\\nEbay, “\\nebay.com\\n”\\n)\\nLojaExemplo\\n \\n∊\\n \\nLojasOn-line\\n \\n∧\\n \\nHomepage\\n (\\nLojaExemplo, “\\nexemplo.com\\n”\\n).\\nEssas lojas classificam suas mercadorias em categorias de produtos e fornecem links para as', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 545}),\n",
       " Document(page_content='categorias importantes a partir de sua homepage. As categorias secundárias podem ser alcançadas\\nseguindo-se uma cadeia de links relevantes e, eventualmente, chegaremos a ofertas. Em outras\\npalavras, uma página é relevante para a consulta se pode ser alcançada por meio de uma cadeia de\\nzero ou mais links de categorias relevantes a partir da homepage de uma loja, e depois seguindo-se\\nmais um link para a oferta do produto. Podemos definir a relevância:\\nAqui, o predicado \\nLink\\n(\\nde\\n, \\npara\\n) significa que existe um hiperlink do URL de até o URL \\npara\\n.\\nPara definir o que é considerado uma \\nCadeiaRelevante\\n, precisamos seguir não apenas hiperlinks\\nantigos, mas somente os links cujo texto de âncora associado indicam que o link é relevante para a\\nconsulta de produtos. Para isso, usaremos \\nTextoLink\\n(\\nde\\n, \\npara\\n, \\ntexto\\n) para indicar que existe um link\\nentre \\nde\\n e \\npara\\n contendo \\ntexto\\n como texto de âncora. Uma cadeia de links entre dois URLs, início e\\nfim, é relevante para uma descrição \\nd\\n se o texto de âncora de cada link é um nome de categoria\\nrelevante para \\nd\\n. A existência da própria cadeia é determinada por uma definição recursiva, com a\\ncadeia vazia (\\ninício\\n = \\nfim\\n) sendo o caso básico:\\nAgora, devemos definir o que significa o fato de o \\ntexto\\n ser um \\nNomeCategoriaRelevante\\n para\\nconsulta\\n. Primeiro, precisamos relacionar as cadeias às categorias que elas identificam. Isso é feito\\nusando-se o predicado \\nNome\\n(\\ns\\n, \\nc\\n), que nos informa que a cadeia \\ns\\n é um nome para a categoria \\nc\\n —\\npor exemplo, poderíamos afirmar que \\nNome\\n(“\\nlaptops\\n”, Laptops). Temos mais alguns exemplos do\\npredicado Nome na \\nFigura 12.9\\n(b). Em seguida, definimos a relevância. Suponha que a \\nconsulta\\n seja\\n“laptops”. Então, \\nNomeCategoriaRelevante\\n(\\nconsulta\\n, \\ntexto\\n) é verdadeira quando um dos itens a\\nseguir é válido:\\n•  O \\ntexto\\n e a \\nconsulta\\n identificam a mesma categoria — por exemplo, “notebooks” e “laptops”.\\n•  O \\ntexto\\n identifica uma supercategoria como “computadores”.\\n•  O \\ntexto\\n identifica uma subcategoria, tal como “notebooks ultraleves”.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 546}),\n",
       " Document(page_content='Figura 12.9\\n (a) Taxonomia de categorias de produtos. (b) Nomes para essas categorias.\\nA definição lógica de \\nNomeCategoriaRelevante\\n é:\\nCaso contrário, o texto de âncora é irrelevante porque identifica uma categoria fora dessa linha,\\ncomo “roupas” ou “gramado & jardim”.\\nEntão, para seguir links relevantes é essencial ter uma hierarquia rica de categorias de produtos. A\\nparte superior dessa hierarquia poderia ser semelhante à da \\nFigura 12.9\\n(a). Não será possível listar\\ntodas as categorias de compras possíveis porque um comprador sempre poderia externar algum novo\\ndesejo e os fabricantes sempre lançarão novos produtos para satisfazer esses desejos (aquecedores\\nelétricos para os joelhos?). Todavia, uma ontologia de cerca de mil categorias servirá como uma\\nferramenta muito útil para a maioria dos compradores.\\nAlém da hierarquia de produtos em si, também precisamos ter um rico vocabulário de nomes para\\ncategorias. A vida seria muito mais fácil se houvesse uma correspondência de um para um entre as\\ncategorias e as cadeias de caracteres que as identificam. Já vimos o problema da \\nsinonímia\\n — dois\\nnomes para a mesma categoria, como “computadores laptops” e “laptops”. Também existe o\\nproblema da \\nambiguidade\\n — um único nome para duas ou mais categorias distintas. Por exemplo, se\\nadicionarmos a sentença\\nNome\\n(\\n“CDs”, CertificadosDeDepósito\\n)\\nà base de conhecimento da \\nFigura 12.9\\n(b), “CDs” vai identificar duas categorias diferentes.\\nA sinonímia e a ambiguidade podem provocar um aumento significativo no número de caminhos\\nque o agente tem de seguir e, às vezes, podem tornar difícil definir se determinada página é de fato\\nrelevante. Um problema muito mais sério é o fato de existir uma variedade muito ampla de\\ndescrições que um usuário pode digitar e de nomes de categorias que uma loja pode usar. Por\\nexemplo, o link poderia informar “laptop” quando a base de conhecimento tem apenas “laptops” ou,\\nentão, talvez o usuário quisesse procurar “um computador que eu possa colocar na mesinha retrátil de\\num assento da classe econômica de um avião”. É impossível enumerar com antecedência todos os\\npossíveis modos de identificar uma categoria e, assim, o agente terá de ser capaz de efetuar certo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 547}),\n",
       " Document(page_content='raciocínio adicional em alguns casos para determinar se a relação \\nNome\\n é válida. No pior caso, isso\\nexigirá compreensão completa de linguagem natural, um tópico que adiaremos até o Capítulo 22. Na\\nprática, algumas regras simples — como permitir que “laptop” corresponda a uma categoria\\ndenominada “laptops” — alcançam bons resultados. O Exercício 12.10 lhe pede para desenvolver\\num conjunto de tais regras depois de fazer alguma pesquisa em lojas on-line.\\nDadas as definições lógicas dos parágrafos precedentes e bases de conhecimentos adequadas de\\ncategorias de produtos e convenções de nomenclatura, estamos prontos para aplicar um algoritmo de\\ninferência para obter um conjunto de ofertas relevantes para nossa consulta? Não exatamente! O\\nelemento que falta é a função \\nConteúdo\\n(\\nurl\\n), que se refere à página HTML em dado URL.O agente\\nnão tem o conteúdo da página de todo URL em sua base de conhecimento; ele também não tem regras\\nexplícitas para deduzir qual poderia ser esse conteúdo. Em vez disso, podemos organizar tudo para\\nque o procedimento de HTTP correto seja executado sempre que um subobjetivo envolver a função\\nConteúdo\\n. Dessa maneira, para o mecanismo de inferência será como se a Web inteira estivesse\\ndentro da base de conhecimento. Esse é um exemplo de técnica geral chamada \\nconexão procedural\\n,\\npor meio da qual predicados e funções específicos podem ser tratados por métodos de uso especial.\\n12.7.2 Comparação entre ofertas\\nVamos supor que os processos de raciocínio da seção precedente tenham produzido um conjunto\\nde páginas de ofertas para nossa consulta “laptops”. Para comparar essas ofertas, o agente deve\\nextrair as informações relevantes — preço, velocidade, tamanho de disco, peso, e assim por diante\\n— das páginas de ofertas. Essa pode ser uma tarefa difícil no caso das páginas da Web reais, por\\ntodas as razões mencionadas anteriormente. Um modo comum de lidar com esse problema é usar\\nprogramas chamados \\nenvoltórios\\n (“wrappers”) para extrair informações de uma página. A\\ntecnologia de extração de informações é discutida na \\nSeção 22.4\\n. No momento, supomos que os\\nenvoltórios existem e, quando são dadas uma página e uma base de conhecimento, eles acrescentam\\nasserções à base de conhecimento. Em geral, uma hierarquia de envoltórios seria aplicada a uma\\npágina: um envoltório muito geral para extrair datas e preços, outro mais específico para extrair\\natributos referentes a produtos relacionados a computadores e, se necessário, um envoltório\\nespecífico do site que conheça o formato de determinada loja. Dada uma página no site \\nexemplo.com\\ncom o texto\\nIBM ThinkBook 970. Nosso preço: US$399,00\\nseguido por diversas especificações técnicas, gostaríamos de ter um envoltório para extrair\\ninformações como as seguintes:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 548}),\n",
       " Document(page_content='Esse exemplo ilustra várias questões que surgem quando levamos a sério a tarefa de engenharia de\\nconhecimento para transações comerciais. Por exemplo, note que o preço é um atributo da \\noferta\\n, não\\ndo produto em si. Isso é importante porque a oferta em determinada loja pode mudar a cada dia, até\\npara o mesmo laptop individual; para algumas categorias — como casas e pinturas —, o mesmo\\nobjeto individual pode ser até oferecido ao mesmo tempo por diferentes intermediários com preços\\ndistintos. Existem ainda outras complicações de que não tratamos, como a possibilidade de o preço\\ndepender do método de pagamento e das qualificações do comprador para obter certos descontos. A\\ntarefa final é comparar as ofertas que foram extraídas. Por exemplo, considere estas três ofertas:\\nA\\n : 1.4 GHz CPU, 2GB RAM, 250 GB disk, US$299,00.\\nB\\n : 1.2 GHz CPU, 4GB RAM, 350 GB disk, US$500,00.\\nC\\n : 1.2 GHz CPU, 2GB RAM, 250 GB disk, US$399,00.\\nC\\n é \\ndominado\\n por \\nA\\n; isto é, \\nA\\n é mais barato e mais rápido e, fora isso, eles são idênticos. Em\\ngeral, \\nX\\n domina \\nY\\n se \\nX\\n tem um valor melhor em pelo menos um atributo e não é pior em qualquer\\natributo. Porém, nem \\nA\\n nem \\nB\\n dominam um ao outro. Para decidir qual deles é melhor, precisamos\\nsaber como o comprador avalia a velocidade da CPU e o preço em comparação com memória e\\nespaço em disco. O tópico geral de preferências entre vários atributos é examinado na \\nSeção 16.4\\n;\\npor enquanto, nosso agente de compras simplesmente retornará uma lista de todas as ofertas não\\ndominadas que satisfazem à descrição do comprador. Nesse exemplo, \\nA\\n e \\nB\\n são não dominados. Note\\nque esse resultado se baseia na suposição de que todo mundo prefere preços mais baixos,\\nprocessadores mais rápidos e mais espaço de armazenamento. Alguns atributos, como tamanho de\\ntela em um notebook, dependem da preferência específica do usuário (portabilidade \\nversus\\nvisibilidade); nesses casos, o agente de compras simplesmente terá de perguntar ao usuário.\\nO agente de compras que descrevemos aqui é simples; são possíveis muitos refinamentos. Ainda\\nassim, ele tem capacidade suficiente para poder, com o conhecimento de domínios específicos\\ncorreto, ser de grande utilidade para um comprador. Devido à sua construção declarativa, ele se\\nestende com facilidade a aplicações mais complexas. O principal objetivo desta seção é mostrar que\\nalguma representação de conhecimento — em particular, a hierarquia de produto — é necessária\\npara um agente como esse e que, uma vez que temos algum conhecimento nessa forma, o resto vem\\nnaturalmente.\\n12.8 RESUMO\\nFocalizando os detalhes de como se representa uma variedade de formas de conhecimento,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 549}),\n",
       " Document(page_content='esperamos ter dado ao leitor uma ideia de como são construídas as bases de conhecimentos reais e\\num sentimento para as questões filosóficas interessantes que surgem. Os principais pontos são:\\n•  A representação de conhecimento em grande escala exige uma ontologia de uso geral para\\norganizar e reunir os vários domínios específicos do conhecimento.\\n•  Uma ontologia de uso geral precisa cobrir ampla variedade de tipos de conhecimento e deve ser\\ncapaz, em princípio, de manipular qualquer domínio.\\n•  A construção de uma ontologia ampla de propósito geral é um desafio significativo que ainda\\nprecisa ser plenamente realizado, apesar das estruturas atuais parecerem ser bastante robustas.\\n•  Apresentamos uma \\nontologia superior\\n baseada em categorias e no cálculo de eventos.\\nFocalizamos categorias, subcategorias, partes, objetos estruturados, medidas, substâncias,\\neventos, tempo e espaço, mudança e crenças.\\n•  As espécies naturais não podem ser completamente definidas na lógica, mas as suas\\npropriedades podem ser representadas.\\n•  Ações, eventos e tempo podem ser representados em um cálculo de situações ou em\\nrepresentações mais expressivas, como o cálculo de eventos. Tais representações permitem a um\\nagente construir planos por inferência lógica.\\n•  Apresentamos uma análise detalhada do domínio de compras da Internet, exercitando a ontologia\\ngeral e mostrando como o conhecimento do domínio pode ser utilizado por um agente de\\ncompras.\\n•  Sistemas de representação de uso especial, como \\nredes semânticas\\n e \\nlógicas de descrição\\n,\\nforam elaborados para ajudar na organização de uma hierarquia de categorias. A \\nherança\\n é uma\\nforma importante de inferência, permitindo que as propriedades de objetos sejam deduzidas a\\npartir de sua pertinência a categorias.\\n•  A \\nhipótese de mundo fechado\\n, implementada em programas em lógica, fornece um meio\\nsimples de evitar a necessidade de especificar grande quantidade de informações negativas. É\\nmelhor interpretá-la como um \\ndefault\\n que pode ser anulado por informações adicionais.\\n•  \\nLógicas não monotônicas\\n, como \\ncircunscrição\\n e \\nlógica default\\n, se destinam a captar o\\nraciocínio default em geral.\\n•  Os \\nsistemas de manutenção de verdade\\n manipulam atualizações e revisões do conhecimento de\\nforma eficiente.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nBriggs (1985) alega que a representação de conhecimento formal teve início com a clássica\\nteorização indiana sobre a gramática de sânscrito (Shastric Sanskrit), que data do primeiro milênio\\na.C. No Ocidente, o uso de definições de termos em matemática grega antiga pode ser considerado\\ncomo a primeira ocorrência: \\nMetafísica\\n de Aristóteles (literalmente, o que vem depois do livro em\\nfísica) é quase um sinônimo de ontologia. Na realidade, o desenvolvimento de terminologia técnica\\nem qualquer campo pode ser visto como uma forma de representação de conhecimento.\\nAs primeiras discussões sobre a representação em IA tendiam a se concentrar na “representação\\nde \\nproblemas\\n”, e não na “representação de \\nconhecimento\\n” [veja, por exemplo, a discussão de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 550}),\n",
       " Document(page_content='Amarel (1968) do problema dos missionários e canibais]. Na década de 1970, a IA enfatizava o\\ndesenvolvimento de “sistemas especialistas” (também chamados “sistemas baseados em\\nconhecimento”) que podiam, se fosse dado o conhecimento de domínio apropriado, equiparar ou\\nsuperar o desempenho de especialistas humanos em tarefas específicas bem definidas. Por exemplo,\\no primeiro sistema especialista, o DENDRAL (Feigenbaum \\net al\\n., 1971; Lindsay \\net al\\n., 1980),\\ninterpretava a saída de um espectrômetro de massa (um tipo de instrumento usado para analisar a\\nestrutura de compostos químicos orgânicos) com tanta precisão quanto químicos especialistas.\\nEmbora o sucesso do DENDRAL tenha ajudado a convencer a comunidade de pesquisa em IA sobre\\na importância da representação de conhecimento, os formalismos de representação que foram\\nutilizados no DENDRAL são altamente específicos para o domínio da química. Com o passar do\\ntempo, os pesquisadores ficaram interessados em formalismos e ontologias padronizadas de\\nrepresentação de conhecimento que podiam simplificar o processo de criação de novos sistemas\\nespecialistas. Fazendo isso, eles se aventuraram em um território antes explorado por filósofos da\\nciência e da linguagem. A disciplina imposta à IA pela necessidade de fazer “funcionarem” as teorias\\nde alguém levou a um progresso mais rápido e mais profundo do que ocorreu quando esses\\nproblemas faziam parte do domínio exclusivo da filosofia (embora ele às vezes também tenha levado\\nà repetida reinvenção da roda).\\nA criação de taxonomias ou classificações abrangentes remonta a tempos antigos. Aristóteles\\n(384-322 a.C.) enfatizava fortemente esquemas de classificação e divisão em categorias. A obra\\nOrganon\\n, uma coleção de trabalhos sobre lógica montada por seus alunos depois da morte do\\nfilósofo, incluiu um tratado chamado \\nCategorias\\n, em que ele tentou construir o que agora\\ndenominaríamos ontologia superior. Aristóteles também introduziu as noções de \\ngênero\\n e \\nespécie\\npara classificação de nível mais baixo. Nosso sistema atual de classificação biológica, incluindo o\\nuso da “nomenclatura binomial” (classificação por gênero e espécie, no sentido técnico), foi criada\\npelo biólogo sueco Carolus Linnaeus, ou Carl von Linne (1707-1778). Os problemas associados a\\nespécies naturais e a limites imprecisos entre categorias foram tratados por Wittgenstein (1953),\\nQuine (1953), Lakoff (1987) e Schwartz (1977), entre outros.\\nO interesse em ontologias de grande escala está crescendo, como documentado pelo \\nHandbook on\\nOntologies\\n (Staab, 2004). O projeto OpenCyc (Lenat e Guha, 1990; Matuszek \\net al\\n,. 2006) lançou\\numa ontologia com 150.000 conceitos, com uma ontologia superior semelhante à da \\nFigura 12.1\\n, bem\\ncomo conceitos específicos como “OLED Display” e “iPhone”, que é um tipo de “telefone celular”,\\nque por sua vez é um tipo de “eletrônica de consumo”, “telefone”, “dispositivo de comunicação sem\\nfio” e outros conceitos. O projeto DBPedia extrai dados estruturados da Wikipedia, especificamente\\ndos Infoboxes: as caixas de pares de atributo/valor que acompanham muitos artigos da Wikipedia\\n(Wu e Weld, 2008;. Bizer \\net al.,\\n 2007). Em meados de 2009, a DBPedia continha 2,6 milhões de\\nconceitos, com cerca de 100 fatos por conceito. O grupo de trabalho IEEE P1600.1 criou a Suggested\\nUpper Merged Ontology (SUMO) (Niles e Pease, 2001; Pease e Niles, 2002), que contém cerca de\\n1.000 termos de ontologia superior e links para mais de 20.000 termos de domínio específico. Stoffel\\net al.\\n (1997) descreveram algoritmos para gerenciar eficientemente uma ontologia muito grande. Uma\\npesquisa de técnicas para a extração de conhecimento a partir de páginas Web é dada por Etzioni \\net\\nal.\\n (2008).\\nNa Web estão surgindo linguagens de representação. A RDF (Brickley e Guha, 2004) permite', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 551}),\n",
       " Document(page_content='afirmações a serem feitas na forma de triplas relacionais e fornece alguns meios para a evolução do\\nsignificado de nomes ao longo do tempo. A OWL (Smith \\net al\\n., 2004) é uma lógica de descrição que\\nsuporta inferências sobre essas triplas. Até agora, o uso parece ser inversamente proporcional à\\ncomplexidade de representação: os formatos tradicionais HTML e CSS representam mais de 99% do\\nconteúdo da Web, seguido pelos esquemas mais simples de representação, como microformatos\\n(Khare, 2006) e RDFa (Adida e Birbeck, 2008), que utilizam marcação HTML e XHTML para\\nadicionar atributos ao texto literal. O uso de ontologias sofisticadas RDF e OWL ainda não está\\ngeneralizado, e a visão completa da Web Semântica (Berners-Lee \\net al\\n., 2001) ainda não é\\nextensamente utilizada. As conferências \\nFormal Ontology in Information Systems\\n (FOIS) contêm\\nmuitos artigos interessantes sobre ontologias gerais e também sobre ontologias específicas de\\ndomínios.\\nA taxonomia usada neste capítulo foi desenvolvida pelos autores; parte dela se baseia em nossa\\nexperiência no projeto CYC e parte no trabalho realizado por Hwang e Schubert (1993) e por Davis\\n(1990, 2005). Uma discussão inspiradora sobre o projeto geral da representação de conhecimento de\\nsenso comum aparece na obra de Hayes (1978, 1985b) \\nThe Naive Physics Manifesto\\n.\\nOntologias profundas de sucesso em uma área específica incluem o projeto Gene Ontology\\n(Consortium, 2008) e CML, a Chemical Markup Language (Murray-Rust \\net al\\n., 2003).\\nDúvidas sobre a viabilidade de uma ontologia única para \\ntodos\\n os conhecimentos foram expressas\\npor Doctorow (2001), Gruber (2004), Halevy \\net al\\n. (2009) e Smith (2004), que afirmou: “O projeto\\ninicial de construção de uma ontologia única (…) foi (…) em grande parte abandonado.”\\nO cálculo de eventos foi introduzido por Kowalski e Sergot (1986) para tratar o tempo contínuo, e\\nhouve muitas variações (Sadri e Kowalski, 1995; Shanahan, 1997) e apresentações (Shanahan, 1999;\\nMueller, 2006). Van Lambalgen e Hamm (2005) mostram como a lógica de eventos é mapeada dentro\\nda linguagem que usamos para falar sobre eventos. Uma alternativa para o cálculo de eventos e de\\nsituações é o cálculo de fluentes (Thielscher, 1999). James Allen introduziu intervalos de tempo pela\\nmesma razão (Allen, 1983, 1984), argumentando que intervalos eram muito mais naturais que\\nsituações para se raciocinar sobre eventos estendidos e concorrentes. Peter Ladkin (1986a, 1986b)\\nintroduziu intervalos de tempo “côncavos” (intervalos com lacunas; em essência, uniões de\\nintervalos de tempo “convexos” comuns) e aplicou as técnicas da álgebra matemática abstrata à\\nrepresentação do tempo. Allen (1991) investiga sistematicamente a ampla variedade de técnicas\\ndisponíveis para representação do tempo; Van Beek e Manchak (1996) analisam algoritmos para\\nraciocínio temporal.\\nExistem significativos pontos comuns entre a ontologia baseada em eventos dada neste capítulo e\\numa análise de eventos criada pelo filósofo Donald Davidson (1980). As \\nhistórias\\n na ontologia de\\nlíquidos de Pat Hayes (1985a) e as \\ncrônicas\\n na teoria dos planos de McDermott (1985) também\\nconstituíram influências importantes para a área e para este capítulo.\\nA questão do \\nstatus\\n ontológico de substâncias tem uma longa história. Platão afirmou que as\\nsubstâncias eram entidades abstratas completamente distintas de objetos físicos; ele diria\\nFeitoDe\\n(\\nManteiga\\n3\\n, \\nManteiga\\n) em vez de \\nManteiga\\n3\\n \\n∊\\n \\nManteiga\\n. Isso leva a uma hierarquia de\\nsubstâncias na qual, por exemplo, \\nManteigaSemSal\\n é uma substância mais específica que \\nManteiga\\n.\\nA posição adotada neste capítulo, em que substâncias são categorias de objetos, foi defendida por', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 552}),\n",
       " Document(page_content='Richard Montague (1973). Ela também foi adotada no projeto CYC. Copeland (1993) elaborou um\\nsério, mas não invencível, ataque. A abordagem alternativa mencionada no capítulo, em que a\\nmanteiga é um objeto que consiste em todos os objetos amanteigados do universo, foi proposta\\noriginalmente pelo lógico polonês Lésniewski (1916). Sua \\nmereologia\\n (o nome deriva da palavra\\ngrega que significa “parte”) utilizava a relação parte-todo em substituição à teoria de conjuntos da\\nmatemática, com o objetivo de eliminar entidades abstratas como conjuntos. Uma exposição mais\\nlegível dessas ideias foi dada por Leonard e Goodman (1940), e o trabalho de Goodman, \\nThe\\nStructure of Appearance\\n (1977), aplica as ideias a vários problemas de representação de\\nconhecimento. Embora alguns aspectos da abordagem mereológica sejam desajeitados — por\\nexemplo, a necessidade de um mecanismo de herança separado, baseado em relações parte-todo — a\\nabordagem ganhou o apoio de Quine (1960). Harry Bunt (1985) apresentou uma extensa análise de\\nseu uso em representação de conhecimento. Casati e Varzi (1999) cobriram as partes, o todo e as\\nlocalizações espaciais.\\nOs objetos mentais têm sido objeto de estudo intensivo em filosofia e em IA. Há três abordagens\\nprincipais. A utilizada neste capítulo, baseada na lógica modal e mundos possíveis, é a abordagem\\nclássica da filosofia (Hintikka, 1962; Kripke, 1963; Hughes e Cresswell, 1996). O livro \\nReasoning\\nabout Knowledge\\n (Fagin \\net al\\n., 1995) fornece uma introdução completa. A segunda abordagem é uma\\nteoria de primeira ordem em que os objetos mentais são fluentes. Davis (2005) e Davis e\\nMorgenstern (2005) descrevem essa abordagem. Ela se baseia no formalismo dos mundos possíveis\\ne no trabalho de Robert Moore (1980, 1985). A terceira abordagem é uma \\nteoria sintática\\n, em que\\nos objetos mentais são representados por cadeias de caracteres. Uma cadeia de caracteres é apenas\\num termo complexo que denota uma lista de símbolos, de modo que \\nPodeVoar\\n(Clark) pode ser\\nrepresentado pela lista de símbolos [\\nP\\n, \\no\\n, \\nd\\n, \\ne\\n, \\nV\\n, \\no\\n, \\na\\n, \\nr,\\n (, \\nC\\n, \\nl\\n, \\na\\n, \\nr\\n, \\nk,\\n)]. A teoria sintática de\\nobjetos mentais foi inicialmente estudada em profundidade por Kaplan e Montague (1960), que\\nmostraram que levava a paradoxos se não fosse tratada com cuidado. Ernie Davis (1990) fornece\\numa comparação excelente das teorias sintática e modal do conhecimento.\\nO filósofo grego Porfírio (c. 234-305 d.C.), comentando as \\nCategorias\\n de Aristóteles, estabeleceu\\no que se poderia qualificar como a primeira rede semântica. Charles S. Peirce (1909) desenvolveu\\ngrafos existenciais como o primeiro formalismo de rede semântica a utilizar a lógica moderna. Ross\\nQuillian (1961), guiado por um interesse na memória humana e no processamento de linguagens,\\niniciou o trabalho em redes semânticas dentro da IA. Um influente artigo de Marvin Minsky (1975)\\napresentou uma versão de redes semânticas chamadas \\nframes\\n; um frame era uma representação de\\num objeto ou categoria, com atributos e relações para outros objetos ou categorias. A questão da\\nsemântica surgiu de forma bastante intensa com relação às redes semânticas de Quillian (e as de\\noutros que seguiram sua abordagem), com seus onipresentes e muito vagos “arcos É-UM”. O famoso\\nartigo de Woods (1975), “What’s in a link?”, despertou a atenção dos pesquisadores de IA para a\\nnecessidade de uma semântica precisa em formalismos de representação de conhecimento. Brachman\\n(1979) desenvolveu esse ponto e propôs soluções. O trabalho de Patrick Hayes (1979), “The Logic\\nof Frames”, foi um corte ainda mais profundo, ao afirmar que “a maioria dos ‘frames’ é\\nsimplesmenteuma nova sintaxe para certas partes da lógica de primeira ordem”. No ensaio de Drew\\nMcDermott (1978b), “Tarskian Semantics, or No Notation without Denotation!”, o autor argumentava\\nque a abordagem da teoria de modelos para semântica usada em lógica de primeira ordem deveria', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 553}),\n",
       " Document(page_content='McDermott (1978b), “Tarskian Semantics, or No Notation without Denotation!”, o autor argumentava\\nque a abordagem da teoria de modelos para semântica usada em lógica de primeira ordem deveria\\nser aplicada a todos os formalismos de representação de conhecimento. Essa continua a ser uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 553}),\n",
       " Document(page_content='ideia controversa; devemos observar que o próprio McDermott reviu sua posição em “A Critique of\\nPure Reason” (McDermott, 1987). Selman e Levesque (1993) discutem a complexidade da herança\\ncom exceções, mostrando que, na maioria das formulações, ela é NP-completa.\\nO desenvolvimento de lógicas de descrição é a fase mais recente em uma longa linha de pesquisa\\norientada para a descoberta de subconjuntos úteis de lógica de primeira ordem, para os quais a\\ninferência é computacionalmente tratável. Hector Levesque e Ron Brachman (1987) mostraram que\\ncertas construções lógicas — em especial certos usos da disjunção e da negação — foram os\\nprincipais responsáveis pela intratabilidade da inferência lógica. Com base no sistema KL-ONE\\n(Schmolze e Lipkis, 1983), muitos pesquisadores desenvolveram sistemas que incorporam análise de\\ncomplexidade teórica, sendo os de maior destaque o KRYPTON (Brachman \\net al\\n., 1983) e o Classic\\n(Borgida \\net al\\n., 1989). O resultado foi um visível aumento na velocidade de inferência e uma\\ncompreensão muito melhor da interação entre complexidade e expressividade em sistemas de\\nraciocínio. Calvanese \\net al\\n. (1999) resumem o estado da arte, e Baader \\net al\\n. (2007) apresentam um\\nmanual abrangente de lógicas de descrição. Contra essa tendência, Doyle e Patil (1991)\\nargumentaram que a restrição da expressividade de uma linguagem torna impossível resolver certos\\nproblemas ou encoraja o usuário a evitar as restrições da linguagem por meios não lógicos.\\nOs três principais formalismos para lidar com a inferência não monotônica — circunscrição\\n(McCarthy, 1980), lógica default (Reiter, 1980) e lógica não monotônica modal (McDermott e Doyle,\\n1980) — foram todos introduzidos em uma única edição especial do \\nAI Journal\\n. Delgrande e Schaub\\n(2003) discutem os méritos das variantes, dados 25 anos de retrospectiva. A programação de\\nconjuntos-resposta pode ser vista como uma extensão da negação por falha ou como um\\naprimoramento da circunscrição; a teoria subjacente da semântica de modelos estáveis foi\\nintroduzida por Gelfond e Lifschitz (1988), e os principais sistemas de programação de conjuntos-\\nresposta são o DLV (Eiter \\net al\\n., 1998) e o SMODELS (Niemelä \\net. al\\n., 2000). O exemplo da\\nunidade de disco vem do manual do usuário do SMODELS (Syrjänen, 2000). Lifschitz (2001) discute\\no uso da programação de conjuntos-resposta em planejamento. Brewka \\net al\\n. (1997) apresentam uma\\nboa visão geral das diversas abordagens para lógica não monotônica. Clark (1978) examina a\\nabordagem de negação por falha para a programação em lógica e a completação de Clark. Van\\nEmden e Kowalski (1976) mostram que todo programa Prolog sem negação tem um modelo minimal\\núnico. Nos últimos anos houve um interesse renovado em aplicações de lógicas não monotônicas a\\nsistemas de representação de conhecimento em grande escala. Os sistemas BENINQ para\\nmanipulação de investigações de benefícios de seguros talvez tenham sido a primeira aplicação\\ncomercialmente bem-sucedida de um sistema de herança não monotônico (Morgenstern, 1998).\\nDiversos sistemas de raciocínio não monotônicos baseados em programação em lógica estão\\ndocumentados nos anais das conferências sobre \\nLogic Programming and Nonmonotonic Reasoning\\n(LPNMR).\\nO estudo de sistemas de manutenção de verdade começou com os sistemas TMS (Doyle, 1979) e\\nRUP (McAllester, 1980), ambos essencialmente JTMS. Forbus e Kleer (1993) explicam em\\nprofundidade como TMSs podem ser usados em aplicações de IA. Nayak e Williams (1997) mostram\\ncomo um TMS incremental eficience chamado ITMS torna possível planejar as operações de uma\\nespaçonave da Nasa em tempo real.\\nPor motivos óbvios, este capítulo não poderia abordar em profundidade \\ntodas\\n as áreas de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 554}),\n",
       " Document(page_content='representação de conhecimento. Os três principais tópicos omitidos são:\\nFísica qualitativa:\\n A física qualitativa é um subcampo da representação de conhecimento que se\\npreocupa especificamente com a construção de uma teoria lógica não numérica de objetos e\\nprocessos físicos. A expressão foi cunhada por Johan de Kleer (1975), embora se possa dizer que o\\nempreendimento teve início no BUILD de Fahlman (1974), um sofisticado planejador para\\nconstrução de torres complexas de blocos. Fahlman descobriu no processo de projeto que a maior\\nparte do esforço (em sua estimativa, 80%) se destinava à modelagem dos aspectos físicos do mundo\\nde blocos para calcular a estabilidade de vários subconjuntos de blocos, em vez do planejamento em\\nsi. Ele esboçou um processo hipotético semelhante ao da física ingênua para explicar por que\\ncrianças pequenas podem resolver problemas como o BUILD sem acesso à aritmética de ponto\\nflutuante em alta velocidade utilizada na modelagem física do BUILD. Hayes (1985a) utiliza\\n“histórias” — fatias quadridimensionais de espaço-tempo semelhante aos eventos de Davidson —\\npara construir uma física elementar bastante complexa de líquidos. Hayes foi o primeiro a provar que\\num banho com a banheira tampada eventualmente provocará transbordamento se a torneira continuar\\naberta e que uma pessoa que cair em um lago ficará completamente molhada. Davis (2008) atualiza a\\nontologia de líquidos que descreve o derramamento de líquidos em recipientes.\\nDe Kleer e Brown (1985), Ken Forbus (1985) e Benjamin Kuipers (1985) independente e quase\\nsimultaneamente desenvolveram sistemas que podem raciocinar sobre o sistema físico com base em\\nabstrações qualitativas de equações subjacentes. A física qualitativa se desenvolveu até chegar ao\\nponto em que se tornou possível analisar uma impressionante variedade de sistemas físicos\\ncomplexos (Yip, 1991). As técnicas qualitativas foram usadas para construir projetos inovadores de\\nrelógios, limpadores de para-brisa e andadores de seis pernas (Subramanian e Wang, 1994). A\\ncoleção \\nReadings in Qualitative Reasoning about Physical Systems\\n (Weld e de Kleer, 1990), um\\nartigo de enciclopédia por Kuipers (2001) e um artigo de handbook por Davis (2007) introduzem a\\nárea.\\nRaciocínio espacial:\\n O raciocínio necessário para navegar no mundo de wumpus e no mundo de\\ncompras é trivial em comparação à rica estrutura espacial do mundo real. A primeira tentativa séria\\nde captar o raciocínio comum sobre o espaço aparece no trabalho de Ernest Davis (1986, 1990). O\\ncálculo de conexão de regiões de Cohn \\net al\\n. (1997) admite uma forma de raciocínio espacial\\nqualitativo e leva a novos tipos de sistemas de informações geográficas; consulte também Davis\\n(2006). Como ocorre com a física qualitativa, um agente pode percorrer um longo caminho, por\\nassim dizer, sem recorrer a uma representação métrica completa. Quando tal representação é\\nnecessária, podem ser usadas técnicas desenvolvidas em robótica (veja o Capítulo 25).\\nRaciocínio psicológico:\\n O raciocínio psicológico envolve o desenvolvimento de uma \\npsicologia\\nfuncional para uso por agentes artificiais no raciocínio sobre si mesmos e sobre outros agentes. Com\\nfrequência, esse raciocínio se baseia na chamada psicologia popular, que — acredita-se — os seres\\nhumanos em geral utilizam no raciocínio sobre si mesmos e sobre outros seres humanos. Quando\\npesquisadores de IA fornecem a seus agentes artificiais teorias psicológicas para raciocinar sobre\\noutros agentes, as teorias frequentemente se baseiam na descrição dos pesquisadores do próprio\\nprojeto dos agentes lógicos. Atualmente, o raciocínio psicológico é mais útil no contexto da', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 555}),\n",
       " Document(page_content='compreensão da linguagem natural, na qual prever as intenções do falante é de grande importância.\\nMinker (2001) reúne artigos de pesquisadores de liderança na representação do conhecimento,\\nresumindo 40 anos de trabalho de campo. Os anais das conferências internacionais sobre \\nPrinciples\\nof Knowledge Representation and Reasoning\\n fornecem as fontes mais atualizadas de pesquisa nessa\\nárea. \\nReadings in Knowledge Representation\\n (Brachman e Levesque, 1985) e \\nFormal Theories of\\nthe Commonsense World\\n (Hobbs e Moore, 1985) são excelentes antologias sobre representação de\\nconhecimento; a primeira se concentra mais em documentos historicamente importantes sobre\\nlinguagens de representação e formalismos, e a outra se concentra na acumulação do próprio\\nconhecimento. Davis (1990), Stefik (1995) e Sowa (1999) apresentam introduções à representação\\nde conhecimento de forma didática, Van Harmelen \\net al.\\n (2007) contribuiem com um manual e uma\\nedição especial do \\nAI Journal\\n abrange o progresso recente (Davis e Morgenstern, 2004). A\\nconferência bienal \\nTheoretical Aspects of Reasoning About Knowledge\\n (TARK) abrange aplicações\\nda teoria do conhecimento em IA, economia e sistemas distribuídos.\\nEXERCÍCIOS\\n12.1\\n Defina uma ontologia na lógica de primeira ordem para o jogo da velha. A ontologia deve\\nconter situações, ações, quadrados, jogadores, marcações (X, O ou em branco) e a noção de ganhar,\\nperder ou empatar o jogo. Defina também a noção de vitória forçada (ou empate): uma posição da\\nqual um jogador pode forçar uma vitória (ou empate) com a sequência correta de ações. Escreva\\naxiomas para o domínio. (Nota: os axiomas que enumeram quadrados diferentes e que caracterizam\\nas posições vencedoras são bastante longos. Você não precisa escrevê-los na íntegra, mas indicar\\nclaramente com o que se parecem.)\\n12.2\\n A \\nFigura 12.1\\n mostra os níveis superiores de uma hierarquia para tudo. Estenda-a para incluir\\ntantas categorias reais quanto possível. Uma boa forma de fazer isso é considerar todos os itens da\\nsua vida cotidiana. Isso inclui objetos e eventos. Inicie ao acordar e prossiga de maneira ordenada\\nanotando tudo o que você vê, toca, faz e pensa. Por exemplo, uma amostra aleatória produz música,\\nnotícias, leite, caminhada, direção, gasolina, Soda Hall, tapete, conversa, Professor Fateman, frango\\nao curry, $7, sol, jornal diário e assim por diante.\\nProduza um gráfico de hierarquia simples (em uma folha grande de papel) e uma lista de objetos e\\ncategorias com as relações satisfeitas pelos membros de cada categoria. Todo objeto deve\\npertencer a uma categoria e toda categoria deve estar na hierarquia.\\n12.3\\n Desenvolva um sistema de representação para o raciocínio sobre janelas em uma interface de\\ncomputador baseada em janelas. Em especial, a representação deve ser capaz de descrever:\\n•  O estado de uma janela: minimizada, exibida ou inexistente.\\n•  Qual janela (se houver) é a janela ativa.\\n•  A posição de cada janela em determinado momento.\\n•  A ordem (de frente para trás) das janelas sobrepostas.\\n•  As ações de criar, destruir, redimensionar e mover janelas; alterar o estado de uma janela; e\\ntrazer uma janela para a frente. Tratar essas ações como atômicas, ou seja, não lidar com a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 556}),\n",
       " Document(page_content='questão de relacioná-las com as ações do mouse. Forneça axiomas descrevendo os efeitos das\\nações em fluentes. Você pode usar cálculo de eventos ou cálculo de situações.\\nSuponha uma ontologia \\ncontendo situações\\n, \\nações\\n, \\ninteiros\\n (coordenadas para \\nx\\n e \\ny\\n) e \\njanelas\\n.\\nDefina uma linguagem sobre essa ontologia, isto é, uma lista de constantes, símbolos de função e\\npredicados com uma descrição de cada. Se precisar adicionar mais categorias para a ontologia\\n(por exemplo, pixels), poderá fazê-lo, mas não se esqueça de especificá-las no seu exercício.\\nVocê pode (e deve) usar símbolos definidos no texto, mas não se esqueça de listá-los\\nexplicitamente.\\n12.4\\n Exponha o seguinte na linguagem que você desenvolveu para o exercício anterior:\\na\\n. Na situação S\\n0\\n, a janela W\\n1\\n está por trás da W\\n2\\n, mas está visível nas partes esquerda e direita.\\nNão declare as coordenadas exatas para elas; descreva a situação \\ngeral.\\nb\\n. Se uma janela for exibida, a sua borda superior é maior do que a sua borda inferior.\\nc\\n. Depois de criar uma janela \\nw\\n, ela será exibida.\\nd.\\n Uma janela só poderá ser minimizada se for exibida.\\n12.5\\n (Adaptada de um exemplo de Doug Lenat.) Sua missão é captar, em forma lógica, conhecimento\\nsuficiente para responder a uma série de perguntas sobre o cenário simples a seguir:\\nOntem, John foi ao supermercado Safeway, de North Berkeley, e comprou dois quilos de tomates e\\num quilo de carne moída.\\nComece tentando representar o conteúdo da sentença como uma série de asserções. Você deve\\nescrever sentenças que tenham estrutura lógica simples (por exemplo, declarações de que os objetos\\ntêm certas propriedades, de que os objetos estão relacionados de determinada maneira, de que todos\\nos objetos que satisfazem uma propriedade satisfazem outra). Os itens a seguir devem ajudá-lo a\\ncomeçar:\\n•  Que classes, objetos e relações você precisaria ter? Quais são seus pais, irmão, e assim por\\ndiante? (Você precisará de eventos e ordenação temporal, entre outros itens.)\\n•  Onde eles caberiam em uma hierarquia mais geral?\\n•  Quais são as restrições e os inter-relacionamentos entre eles?\\n•  Que detalhes você deve mostrar sobre cada um dos diversos conceitos?\\nPara responder às perguntas a seguir, sua base de conhecimento deve incluir conhecimento do\\ndomínio. Você terá de lidar com os tipos de itens que existem em um supermercado, o que está\\nenvolvido na compra dos itens selecionados, qual será a utilidade dos itens comprados, e assim por\\ndiante. Tente fazer sua representação tão geral quanto possível. Aqui está um exemplo trivial: não\\ndiga “As pessoas compram comida no Safeway” porque isso não o ajudará no caso daqueles que\\ncompram em outro supermercado. Também não transforme as perguntas em respostas; por exemplo, a\\npergunta (c) é “João comprou alguma carne?”, e não “João comprou um quilo de carne moída?”.\\n  Esboce as cadeias de raciocínio que responderiam às perguntas. Se possível, use um sistema de\\nraciocínio lógico para demonstrar a suficiência de sua base de conhecimento. Na realidade, muitos\\nitens que você anotar talvez só estejam aproximadamente corretos, mas não se preocupe demais; a\\nideia é extrair o senso comum que o levará a responder a essas perguntas. Uma resposta', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 557}),\n",
       " Document(page_content='verdadeiramente completa para essa pergunta é \\nextremamente\\n difícil e talvez esteja além do estado\\nda arte da representação de conhecimento atual. Porém, você deve ser capaz de reunir um conjunto\\nconsistente de axiomas para as perguntas limitadas formuladas aqui.\\na.\\n João é uma criança ou um adulto? [Adulto]\\nb.\\n João agora tem pelo menos dois tomates? [Sim]\\nc.\\n João comprou alguma carne? [Sim]\\nd.\\n Se Maria estava comprando tomates ao mesmo tempo que João, ele a viu? [Sim]\\ne.\\n Os tomates são produzidos no supermercado? [Não]\\nf.\\n O que João vai fazer com os tomates? [Comê-los]\\ng.\\n O Safeway vende desodorante? [Sim]\\nh.\\n João trouxe algum dinheiro ou o cartão de crédito para o supermercado? [Sim]\\ni.\\n João tem menos dinheiro depois de ir ao supermercado? [Sim]\\n12.6\\n Faça os acréscimos ou as alterações necessárias em sua base de conhecimento do exercício\\nanterior, de forma que as perguntas a seguir possam ser respondidas. Inclua em seu relatório uma\\ndiscussão das alterações, explicando por que elas foram necessárias, se foram secundárias ou\\nimportantes e que tipos de questões necessecitariam de outras alterações.\\na.\\n Há outras pessoas no Safeway enquanto João está lá? [Sim — os funcionários!]\\nb.\\n João é vegetariano? [Não]\\nc.\\n Quem é o dono do desodorante que está no Safeway? [Safeway Corporation]\\nd.\\n João tinha cerca de 30 gramas de carne moída? [Sim]\\ne.\\n O posto Shell vizinho ao supermercado tem gasolina? [Sim]\\nf.\\n Os tomates cabem no porta-malas de João? [Sim]\\n12.7\\n Represente as sete sentenças a seguir utilizando e ampliando as representações desenvolvidas\\nno capítulo:\\na.\\n A água é um líquido entre 0 e 100 graus.\\nb.\\n A água ferve a 100 graus.\\nc.\\n A água na garrafa de água de João está congelada.\\nd.\\n Perrier é uma espécie de água.\\ne.\\n João tem Perrier em sua garrafa de água.\\nf.\\n Todos os líquidos têm um ponto de congelamento.\\ng.\\n Um litro de água pesa mais que um litro de álcool.\\n12.8\\n Escreva definições para os seguintes itens:\\na.\\n \\nDecomposiçãoExaustivaEmPartes\\nb.\\n \\nPartiçãoDeParte\\nc.\\n \\nDisjuntoPorParte', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 558}),\n",
       " Document(page_content='Essas definições devem ser análogas às definições para \\nDecomposiçãoExaustiva\\n, \\nPartição\\n e\\nDisjunto\\n. Ocorre \\nPartiçãoDeParte\\n(\\ns\\n, \\nGrupoDe\\n(\\ns\\n))? Em caso afirmativo, prove; se não, forneça um\\ncontraexemplo e defina condições suficientes sobre as quais isso é válido.\\n12.9\\n Um esquema alternativo para representar medidas envolve a aplicação da função unidades a um\\nobjeto de comprimento abstrato. Em tal esquema, seria possível escrever\\nPolegadas\\n(\\nComprimento\\n(\\nL\\n1\\n)) = 1,5. Como esse esquema se compara com o esquema deste capítulo?\\nAs questões incluem axiomas de conversão, nomes para quantidades abstratas (como “50 dólares”) e\\ncomparações entre medidas abstratas em diferentes unidades (50 polegadas é maior que 50\\ncentímetros).\\n12.10\\n Adicione sentenças para estender a definição do predicado \\nNome\\n(\\ns\\n, \\nc\\n), de forma que uma\\ncadeia como “computador laptop” seja comparada com os nomes de categorias apropriados de\\ndiversas lojas. Procure tornar sua definição geral. Teste-a examinando 10 lojas on-line e os nomes\\nde categorias que elas fornecem para três categorias diferentes. Por exemplo, para a categoria de\\nlaptops, encontramos os nomes “Notebooks”, “Laptops”, “Computadores Notebook”, “Notebook”,\\n“Laptops e Notebooks” e “PCs Notebooks”. Alguns desses nomes podem ser cobertos por fatos\\nexplícitos sobre \\nNome\\n, enquanto outros podem ser cobertos por regras para tratamento de plurais,\\nconjunções etc.\\n12.11\\n Escreva axiomas do cálculo de eventos para descrever as ações no mundo de wumpus.\\n12.12\\n Declare a relação da álgebra de intervalos que seja válida entre cada par dos seguintes\\neventos do mundo real:\\nVK\\n: A vida do presidente Kennedy.\\nIK\\n: A infância do presidente Kennedy.\\nPK\\n: A presidência do Presidente Kennedy.\\nVJ\\n: A vida do presidente Johnson.\\nPJ\\n: A presidência do presidente Johnson.\\nVO\\n: A vida do presidente Obama.\\n \\n12.13\\n Investigue maneiras de estender o cálculo de eventos para manipular eventos\\nsimultâneos\\n. É possível evitar uma explosão combinatória de axiomas?\\n12.14\\n Construa uma representação para taxas de câmbio entre moedas que permita flutuações diárias.\\n12.15\\n Defina o predicado \\nFixo\\n, onde \\nFixo\\n(\\nPosição\\n(\\nx\\n)) significa que a posição do objeto \\nx\\n é fixa ao\\nlongo do tempo.\\n12.16\\n Descreva o evento de trocar algo por qualquer outra coisa. Descreva a compra como uma\\nespécie de troca em que um dos objetos trocados é uma quantia em dinheiro.\\n \\n12.17\\n Os dois exercícios anteriores pressupõem uma noção bastante primitiva de\\npropriedade. Como exemplo, observe que o comprador começa \\npossuindo\\n as cédulas de dinheiro.\\nEsse quadro começa a se quebrar quando, por exemplo, o dinheiro de alguém está no banco porque', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 559}),\n",
       " Document(page_content='não existe mais nenhuma coleção específica de cédulas que alguém possua. O quadro se complica\\nainda mais quando ocorrem empréstimos, arrendamentos, aluguel e custódia. Investigue os diversos\\nconceitos comuns e legais de propriedade, e proponha um esquema pelo qual eles possam ser\\nformalmente representados.\\n12.18\\n (Adaptada de Fagin \\net al.\\n, 1995.) Considere um jogo com um baralho de apenas oito cartas,\\nquatro ases e quatro reis. Distribuem-se duas cartas para cada um dos três jogadores, Alice, Bob e\\nCarlos. Sem olhar para elas, eles colocam as cartas na testa, para que os outros jogadores possam\\nvê-las. Em seguida, os jogadores se revezam anunciando que sabem que cartas estão na sua própria\\ntesta, assim ganhando o jogo, ou dizendo: “Eu não sei.” Todo mundo sabe que os jogadores são\\nhonestos e perfeitos no raciocínio sobre as crenças.\\na\\n. Jogo 1. Alice e Bob disseram “Não sei”. Carlos vê que Alice tem dois Ases (A-A) e Bob tem\\ndois reis (K-K). O que deveria Carlos dizer? (\\nDica\\n: Considere todos os três casos possíveis\\npara Carlos: A-A, K-K, A-K.)\\nb\\n. Descreva cada etapa do Jogo 1 usando a notação da lógica modal.\\nc\\n. Jogo 2. Carlos, Alice e Bob disseram “Não sei” em seu primeiro turno. Alice tem K-K e Bob\\ntem A-K. O que Carlos deveria dizer em seu segundo turno?\\nd\\n. Jogo 3. Alice, Carlos e Bob todos dizem “Não sei” em seu primeiro turno, assim como Alice em\\nseu segundo turno. Alice e Bob têm A-K. O que Carlos deveria dizer?\\ne.\\n Prove que sempre deverá haver um ganhador para esse jogo.\\n12.19\\n A suposição da \\nonisciência lógica\\n, discutida no final da \\nSeção 12.4\\n, naturalmente, não é\\nverdadeira sobre qualquer pensador real. Pelo contrário, é uma \\nidealização\\n do processo de\\nraciocínio que pode ser mais ou menos aceitável, dependendo das aplicações. Discuta a\\nrazoabilidade do pressuposto para cada uma das seguintes aplicações de raciocínio sobre o\\nconhecimento:\\na.\\n Jogos de conhecimento parcial com adversários, tal como os jogos de cartas. Aqui um jogador\\nquer inferir sobre o que o seu oponente sabe sobre o estado do jogo.\\nb.\\n Xadrez com um relógio. Aqui o jogador pode desejar raciocinar sobre os limites do seu\\noponente ou a sua própria capacidade de encontrar a melhor jogada no tempo disponível. Por\\nexemplo, se o jogador A tem muito mais tempo do que o jogador B, então A, às vezes, faz um\\nmovimento que complica muito a situação, na esperança de obter uma vantagem porque ele tem\\nmais tempo para elaborar a estratégia adequada.\\nc.\\n Um agente de compras em um ambiente no qual existem custos de coleta de informações.\\nd.\\n Raciocínio sobre criptografia de chave pública, que se baseia na intratabilidade de certos\\nproblemas compu\\u200btacionais.\\n12.20\\n Traduza a descrição da expressão lógica seguinte (da \\nSeção 12.5.2\\n) em lógica de primeira\\nordem e comente o resultado:\\nAnd\\n(\\nHomem\\n, \\nAtLeast\\n(3, \\nFilho\\n), \\nAtMost\\n(2, \\nFilha\\n),\\nAll\\n(\\nFilho\\n, \\nAnd\\n(\\nDesempregado\\n, \\nCasado\\n, \\nAll\\n(\\nEsposa\\n, \\nMédica\\n))),\\nAll\\n(\\nFilha\\n, \\nAnd\\n(\\nProfessora\\n, \\nFills\\n(\\nDepartamento\\n, \\nFísica\\n, \\nMatemática\\n))))', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 560}),\n",
       " Document(page_content='12.21\\n Lembre-se de que as informações de herança em redes semânticas podem ser captadas\\nlogicamente por sentenças de implicação adequadas. Este exercício investiga a eficiência de usar tais\\nsentenças para herança.\\na.\\n Considere o conteúdo de informações em um catálogo de automóveis usados como o de um\\ngrande jornal americano — por exemplo, que as vans Dodge 1973 valem US$ 575,00 (ou talvez\\nvaleram algum dia). Suponha que todas essas informações (referentes a 11.000 modelos)\\nestejam codificadas sob a forma de sentenças lógicas, como sugerimos no capítulo. Escreva três\\ndessas sentenças, incluindo a das vans Dodge 1973. De que maneira você utilizaria as sentenças\\npara descobrir o valor de um carro \\nespecífico\\n, dado um provador de teoremas de encadeamento\\npara trás como o Prolog?\\nb.\\n Compare a eficiência de tempo do método de encadeamento para trás para resolver esse\\nproblema com o método de herança utilizado em redes semânticas.\\nc.\\n Explique como o encadeamento para a frente permite a um sistema baseado em lógica resolver o\\nmesmo problema de modo eficiente, supondo-se que o jornal contenha apenas as 11.000\\nsentenças sobre preços.\\nd.\\n Descreva uma situação em que nem o encadeamento para a frente nem o encadeamento para trás\\nsobre as sentenças permitirão que a consulta de preço referente a um carro individual seja\\ntratada de modo eficiente.\\ne.\\n Você poderia sugerir uma solução que permita resolver esse tipo de consulta de modo eficiente\\nem todos os casos em sistemas lógicos? [\\nSugestão\\n: Lembre-se de que dois carros do mesmo\\nano e modelo têm o mesmo preço.]\\n12.22\\n Alguém poderia supor que a distinção sintática entre arcos sem retângulos e arcos com\\nretângulos de aresta única em redes semânticas fosse desnecessária porque arcos com retângulos de\\naresta única sempre estão associados a categorias; um algoritmo de herança poderia simplesmente\\nsupor que um arco sem retângulo associado a uma categoria pretendesse se aplicar a todos os\\nelementos dessa categoria. Mostre que esse argumento é uma falácia, dê exemplos de erros que\\nsurgiriam em consequência dele.\\n12.23\\n Uma parte do processo de compras que não foi abrangido nesse capítulo é a verificação da\\ncompatibilidade entre itens. Por exemplo, se for solicitada uma câmera digital, que acessórios,\\nbaterias, cartão de memória e estojos são compatíveis com a câmera? Escreva uma base de\\nconhecimento que possa determinar a compatibilidade de um conjunto de itens e sugira substituições\\nou itens adicionais se o comprador fizer uma escolha que não seja compatível. A base de\\nconhecimento deve funcionar pelo menos com uma linha de produtos e se estender facilmente para\\noutras linhas.\\n12.24\\n Uma solução completa para o problema de correspondências inexatas com a descrição do\\ncomprador em compras é muito difícil e exige uma série completa de técnicas de processamento de\\nlinguagem natural e recuperação de informações (veja os Capítulos 22 e 23). Um pequeno passo\\nconsiste em permitir que o usuário especifique valores mínimos e máximos para diversos atributos.\\nO comprador deve usar a gramática a seguir nas descrições de produto:\\nDescrição\\n→\\nCategoria\\n [\\nConector Modificador\\n] *', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 561}),\n",
       " Document(page_content='Conector\\n→\\ncom\\n” | “\\ne\\n” | “,”\\nModificador\\n→\\nAtributo\\n | \\nAtributo Op Valor\\nOp\\n→\\n“=” | “>” | “<”\\nAqui, \\nCategoria\\n denomina uma categoria de produtos, \\nAtributo\\n é alguma característica como “CPU”\\nou “preço” e \\nValor\\n é o valor de destino para o atributo. Então, a consulta “computador com pelo\\nmenos uma CPU de 2,5 GHz e preço abaixo de US$ 500,00” deve ser expressa novamente como\\n“computador com CPU >2,5 GHz e preço US$ 500,00”. Implemente um agente de compras que aceite\\ndescrições nessa linguagem.\\n12.25\\n Nossa descrição de compras na Internet omitiu a importante etapa de realmente \\ncomprar\\n o\\nproduto. Forneça uma descrição lógica formal de comprar, usando cálculo de eventos. Isto é, defina a\\nsequência de eventos que ocorre quando um comprador envia um pedido de compra por cartão de\\ncrédito e eventualmente paga a fatura e recebe o produto.\\n1\\n Transformar uma proposição em um objeto é chamado de \\nreificação\\n, da palavra latina \\nres\\n, ou “coisa”. JohnMcCarthy propôs o termo\\n“coisificação”, mas nunca pegou.\\n2\\n O famoso biólogo J.B.S. Haldane deduziu “Um carinho desmedido por besouros” por parte do Criador.\\n3\\n Os termos “evento” e “ação” podem ser utilizados de forma intercambiável. Informalmente, “ação” conota um agente, enquanto\\n“evento” conota a possibilidade de ações sem agente.\\n4\\n Algumas versões do cálculo de eventos não distinguem categorias de evento de instâncias das categorias.\\n5\\n Vários sistemas antigos falharam na tentativa de distinguir entre propriedades de elementos de uma categoria e propriedades da\\ncategoria como um todo. Isso pode levar diretamente a inconsistências, como destacou Drew McDermott (1976) em seu artigo\\n“Artificial Intelligence Meets Natural Stupidity”. Outro problema comum foi o uso de arcos \\nÉUm\\n para relações de subconjuntos e de\\npertinência, em correspondência com o uso em linguagem natural: “Um gato é um mamífero” e “Fifi é um gato”. Veja o Exercício 12.22\\npara examinar essas questões com mais detalhes.\\n6\\n Note que a linguagem \\nnão\\n permite simplesmente declarar que um conceito ou uma categoria é um subconjunto de outro. Essa é uma\\npolítica deliberada: a subsunção entre categorias deve ser derivável a partir de alguns aspectos das descrições das categorias. Se não,\\nalgo estará faltando nas descrições.\\n7\\n CLASSIC fornece testes práticos de subordinação eficientes, mas o tempo de execução no pior caso é exponencial.\\n8\\n Lembre-se de que a monotonicidade exige que todas as sentenças que são consequências lógicas permaneçam consequências lógicas\\ndepois que novas sentenças forem adicionadas à BC. Isto é, se \\nBC\\n |=\\nα\\n então \\nBC\\n \\n∧\\n \\nβ\\n |= \\nα\\n.\\n9\\n No caso da hipótese de mundo fechado, um modelo é preferível em relação a outro se ele tem um número menor de átomos\\nverdadeiros, isto é, os modelos preferidos são modelos \\nminimais\\n. Existe uma conexão natural entre a Hipótese de Mundo Fechado\\n(HMF) e BCs de cláusulas definidas porque o ponto fixo alcançado pelo encadeamento para a frente em tais BCs é o único modelo\\nminimal. Veja a \\nSeção 7.5.4\\n para mais detalhes.\\n10\\n A revisão de crenças frequentemente é comparada com a \\natualização de crenças\\n, que ocorre quando uma base de conhecimento é\\nrevisada para refletir uma mudança no mundo, em vez de novas informações sobre um mundo fixo. A atualização de crenças combina a\\nrevisão de crenças com o raciocínio sobre o tempo e a mudança; ela também está relacionada ao processo de \\nfiltragem\\n descrito no\\nCapítulo 15.\\n11\\n Uma alternativa para a estratégia de seguir links é usar um mecanismo de pesquisa na Internet; a tecnologia por trás da pesquisa na\\nInternet, chamada recuperação de informações, será examinada na \\nSeção 22.3\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 562}),\n",
       " Document(page_content='PARTE IV\\nConhecimento incerto e pensamento', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 563}),\n",
       " Document(page_content='CAPÍTULO\\n \\n13\\nQuantificando a incerteza\\nEm que vemos como um agente pode domar a incerteza com graus de crença.\\n13.1 COMO AGIR EM MEIO À INCERTEZA\\nOs agentes podem precisar lidar com a \\nincerteza\\n, seja devido à observabilidade parcial, ao não\\ndeterminismo ou a uma combinação dos dois. Um agente pode não saber ao certo em que estado está\\nou onde terminará após uma sequência de ações.\\nVimos agentes de resolução de problemas (Capítulo 4) e agentes lógicos (Capítulos 7 e 11)\\nprojetados para lidar com a incerteza, mantendo o controle de um \\nestado de crença\\n — uma\\nrepresentação do conjunto de todos os estados possíveis do mundo em que possam estar — e gerando\\num plano de contingência que trate de qualquer eventualidade possível que seus sensores possam\\nrelatar durante a execução. Entretanto, apesar de suas muitas virtudes, essa abordagem tem\\ndesvantagens significativas quando tomada literalmente como uma receita para a criação de\\nprogramas do agente:\\n•  Ao interpretar a informação parcial do sensor, um agente lógico deve considerar cada\\nexplanação \\nlogicamente possível\\n das observações, não importa o quão improvável seja. Isso\\nleva a representações de estados de crença impossivelmente grandes e complexos.\\n•  Um plano de contingência correto que lida com toda eventualidade pode crescer arbitrariamente\\ne deve considerar as contingências arbitrariamente improváveis.\\n•  Às vezes, não há um plano garantido de alcançar o objetivo — mesmo assim o agente deve agir.\\nDeve ter alguma maneira de comparar os méritos dos planos que não são garantidos.\\nSuponha, por exemplo, que um táxi automatizado tenha o objetivo de entregar um passageiro no\\naeroporto a tempo. O agente faz um plano, \\nA\\n90\\n, que envolve sair de casa 90 minutos antes da partida\\ndo voo e dirigir a uma velocidade razoável. Mesmo que o aeroporto seja apenas a oito quilômetros\\nde distância, o agente lógico do táxi não será capaz de concluir com certeza se o “Plano \\nA\\n90\\n vai\\nconduzir ao aeroporto a tempo”. Em vez disso, chegará à conclusão mais fraca de que o “Plano A\\n90\\nvai conduzir ao aeroporto a tempo se o carro não quebrar ou ficar sem combustível, e não se\\nenvolver em um acidente, e não houver acidentes na ponte e o avião não decolar mais cedo, e nenhum', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 565}),\n",
       " Document(page_content='meteorito bater no carro, e…” Nenhuma dessas condições pode ser deduzida com certeza, assim o\\nsucesso do plano não pode ser inferido. Esse é o \\nproblema de qualificação\\n, para o qual até agora\\nnão vimos nenhuma solução real.\\n Todavia, vamos supor que \\nA\\n90\\n \\nseja\\n de fato a alternativa correta. O que queremos dizer com\\nisso? Como vimos no Capítulo 2, queremos dizer que, de todos os planos que poderiam ser\\nexecutados, espera-se que o plano \\nA\\n90\\n maximize a medida de desempenho do agente (onde a\\nexpectativa é relativa ao conhecimento do agente sobre o ambiente). A medida de desempenho inclui\\nchegar ao aeroporto a tempo para o voo, evitando uma longa e improdutiva espera no aeroporto, e\\nevitando multas por excesso de velocidade ao longo do caminho. As informações que o agente tem\\nnão podem garantir quaisquer desses resultados para \\nA\\n90\\n, mas podem fornecer algum grau de crença\\nde que os resultados serão alcançados. Outros planos, como \\nA\\n180\\n, poderiam aumentar a crença do\\nagente de que ele chegará ao aeroporto a tempo, mas também aumentarão a probabilidade de uma\\nlonga espera. \\nEntão, a alternativa correta\\n — \\na\\n \\ndecisão racional\\n — \\ndepende tanto da importância\\nrelativa de várias metas quanto da probabilidade de que elas serão alcançadas e em que grau\\n. O\\nrestante desta seção apura essas ideias como preparação para o desenvolvimento das teorias gerais\\nde raciocínio incerto e decisões racionais que apresentaremos neste capítulo e em capítulos\\nsubsequentes.\\n13.1.1 Resumindo a incerteza\\nVamos considerar um exemplo de raciocínio incerto: o diagnóstico de dor de dente de um\\npaciente. Diagnóstico — seja em medicina, conserto de automóveis ou qualquer outra atividade — é\\numa tarefa que quase sempre envolve a incerteza. Vamos tentar definir regras para diagnóstico\\nodontológico utilizando a lógica proposicional, de forma que possamos ver como a abordagem\\nlógica se desenvolve. Considere a regra simples a seguir:\\nDorDeDent\\ne\\n \\n⇒\\n \\nCárie.\\nO problema é que essa regra está errada. Nem todos os pacientes com dores de dentes têm cáries;\\nalguns deles têm gengivite, abscessos ou algum dentre vários outros problemas:\\nDorDeDente\\n \\n⇒\\n \\nCárie\\n \\n∨\\nGengivite\\n \\n∨\\nAbscessos…\\nInfelizmente, a fim de tornar a regra verdadeira, temos de adicionar uma lista quase ilimitada de\\ncausas possíveis. Poderíamos tentar transformar a regra em uma regra causal:\\nCárie\\n \\n⇒\\n \\nDorDeDente.\\nNo entanto, essa regra também não é correta; nem todas as cáries causam dor. O único modo de\\ncorrigir a regra é torná-la logicamente exaustiva: aumentar o lado esquerdo com todas as\\nqualificações exigidas para que uma cárie cause dor de dente. Tentar usar a lógica de primeira ordem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 566}),\n",
       " Document(page_content='para lidar com um domínio como diagnóstico médico é uma abordagem falha, por três razões\\nprincipais:\\n•  \\nPreguiça:\\n É trabalhoso demais listar o conjunto completo de antecedentes ou consequentes\\nnecessários para assegurar uma regra sem exceções, e é muito difícil usar tais regras.\\n•  \\nIgnorância teórica:\\n A ciência médica não tem nenhuma teoria completa para o domínio.\\n•  \\nIgnorância prática:\\n Ainda que todas as regras sejam conhecidas, poderíamos estar inseguros\\nquanto a um paciente específico porque nem todos os testes necessários foram ou podem ser\\nexecutados.\\n A conexão entre dores de dentes e cáries não é apenas uma consequência lógica, em um sentido\\nou no outro. Isso é típico do domínio médico, bem como da maioria dos outros domínios de\\njulgamento: jurídicos, de negócios, de projeto, de consertos de automóveis, de jardinagem, de\\nencontros, e assim por diante. O conhecimento do agente pode, na melhor das hipóteses, fornecer\\napenas um \\ngrau de crença\\n nas sentenças relevantes. Nossa principal ferramenta para lidar com graus\\nde crença será a \\nteoria da probabilidade\\n. Na terminologia da \\nSeção 8.1\\n, os \\ncompromissos\\nontológicos\\n da teoria da lógica e da probabilidade são os mesmos — que o mundo é composto de\\nfatos que são ou não válidos em qualquer caso particular —, mas os \\ncompromissos epistemológicos\\nsão diferentes: um agente lógico acredita que cada sentença seja verdadeira ou falsa ou não tem\\nopinião, enquanto um agente probabilístico pode ter um grau de crença numérico entre 0 (para\\nsentenças que são certamente falsas) e 1 (certamente verdadeiras).\\nA probabilidade proporciona um meio para\\n \\nresumir\\n \\na incerteza que vem de nossa preguiça e\\nignorância\\n, resolvendo assim o problema de qualificação. Talvez não saibamos com certeza o que\\naflige determinado paciente, mas acreditamos que exista, digamos, uma chance de 80% — isto é, uma\\nprobabilidade igual a 0,8 — de que o paciente tenha uma cárie, caso ele esteja sentindo dor de dente.\\nOu seja, esperamos que, de todas as situações indistinguíveis da situação atual, até onde vai o nosso\\nconhecimento, o paciente terá uma cárie em 80% delas. Essa crença poderia ser derivada de dados\\nestatísticos — 80% dos pacientes com dor de dente vistos até agora tinham cáries — ou de algumas\\nregras gerais, ou ainda de uma combinação de fontes de evidências.\\nUm ponto confuso é que, no momento do nosso diagnóstico, não há incerteza no mundo real: o\\npaciente tem uma cárie ou não. Então, o que significa dizer que a probabilidade de uma cárie é de\\n0,8? Não deveria ser 0 ou 1? A resposta é que as declarações de probabilidade são feitas com\\nrespeito a um estado de conhecimento, não com relação ao mundo real. Dizemos: “A probabilidade\\nde a paciente ter uma cárie, uma \\nvez que tem dor de dente\\n, é de 0,8.” Se soubermos depois que o\\npaciente tem um histórico de doenças da gengiva, podemos fazer uma declaração diferente: “A\\nprobabilidade de que o paciente tenha uma cárie, uma vez que tem uma dor de dente e um histórico\\nde doença da gengiva, é de 0,4.” Se reunirmos evidências mais conclusivas contra a cárie, podemos\\ndizer: “A probabilidade de que a paciente tenha uma cárie, dado tudo o que sabemos agora, é quase\\n0.” Observe que essas declarações não se contradizem mutuamente, cada uma é uma afirmação\\nseparada sobre um diferente estado do conhecimento.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 567}),\n",
       " Document(page_content='13.1.2 Incerteza e decisões racionais\\nConsidere novamente o plano \\nA\\n90\\n para chegar ao aeroporto. Suponha que ele apresente uma chance\\nde 97% de pegar o voo. Isso significa que é uma escolha racional? Não necessariamente: pode haver\\noutros planos, como o \\nA\\n180\\n, com maiores probabilidades. Se for vital não perder o voo, valerá a pena\\nse arriscar a uma espera mais longa no aeroporto. O que dizer do plano \\nA\\n1440\\n, que envolve sair de\\ncasa com 24 horas de antecedência? Na maioria das circunstâncias, essa não é uma boa escolha\\nporque, embora garanta a chegada a tempo, envolve uma espera intolerável — sem mencionar a\\npossibilidade pouco agradável da comida do aeroporto.\\nPara fazer tais escolhas, primeiro um agente deve ter \\npreferências\\n entre os diferentes \\nresultados\\ndos vários planos. Um resultado específico é um estado completamente especificado, incluindo\\nfatores como o agente chegar a tempo ou não e a duração da espera no aeroporto. Empregaremos a\\nteoria da utilidade\\n para representar e raciocinar com preferências. A teoria da utilidade diz que todo\\nestado tem determinado grau de utilidade (ou seja, ele tem certa utilidade) para um agente e que o\\nagente preferirá estados com utilidade mais alta.\\nA utilidade de um estado é relativa ao agente. Por exemplo, a utilidade de um estado em uma\\npartida de xadrez em que a peça branca colocou a preta em xeque é obviamente alta para o agente\\nque joga com a branca, mas baixa para o agente que joga com a preta. Mas não podemos ir\\nestritamente pelo número de pontos 1, 1/2 e 0 ditados pelas regras do torneio de xadrez — alguns\\njogadores (incluindo os autores) podem ficar excitados em empatar com o campeão mundial de\\nxadrez, enquanto outros jogadores (incluindo o campeão mundial anterior) talvez não tenham tanto\\nprazer. Não existe nenhuma maneira de medir o gosto ou as preferências: você pode pensar que um\\nagente que prefere sorvete de açaí a biscoito de chocolate é estranho ou mesmo mal orientado, mas\\nnão se pode dizer que o agente é irracional. Uma função utilidade pode contar com qualquer conjunto\\nde preferências — peculiar ou típico, nobre ou perverso. Observe que as utilidades podem levar em\\nconta o altruísmo simplesmente incluindo o bem-estar de outras pessoas como um dos fatores.\\nPreferências, sendo expressas por utilidades, são combinadas com as probabilidades na teoria\\ngeral de decisões racionais chamada \\nteoria da decisão\\n:\\nTeoria da decisão\\n = \\nteoria da probabilidade\\n + \\nteoria da utilidade\\n.\\nA ideia fundamental da teoria da decisão é que \\num agente é racional se e somente se escolhe a\\nação que resulta na mais alta utilidade esperada\\n, \\ncalculada como a média sobre todos os\\nresultados possíveis da ação\\n. Isso é chamado princípio de \\nutilidade máxima esperada\\n (UME).\\nObserve que “esperada” pode parecer um termo vago e hipotético, mas como é utilizado aqui tem um\\nsignificado preciso: significa a “média” ou “média estatística” dos resultados ponderada pela\\nprobabilidade do resultado. Vimos esse princípio em ação no Capítulo 5 quando focalizamos de\\nforma resumida decisões ótimas em partidas de gamão; é de fato um princípio completamente geral.\\nA \\nFigura 13.1\\n esboça a estrutura de um agente que usa a teoria da decisão para selecionar ações.\\nO agente é idêntico, em um nível abstrato, ao agente lógico descrito nos Capítulos 4 e 7 que mantém\\num estado de crença refletindo a história da percepção atual. A principal diferença é que a decisão\\nteórica do estado de crença do agente não representa apenas as \\npossibilidades\\n dos estados do', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 568}),\n",
       " Document(page_content='mundo, mas também suas \\nprobabilidades.\\n Dado o estado de crença, o agente pode fazer prognósticos\\nprobabilísticos de resultados de ações e, consequentemente, selecionar a ação com a mais alta\\nutilidade esperada. Este capítulo e o próximo se concentram na tarefa de representar e efetuar\\ncálculos com informações probabilísticas em geral. O Capítulo 15 lida com métodos\\ncorrespondentes às tarefas específicas de representar e atualizar o estado de crença e de prognosticar\\no ambiente. O Capítulo 16 aborda a teoria da utilidade em maior profundidade, e o Capítulo 17\\ndesenvolve algoritmos para as sequências de planejamento de ações em ambientes incertos.\\nfunção\\n AGENTE-TD(\\npercepção\\n) \\nretorna\\n uma \\nação\\n    \\nvariáveis estáticas:\\n \\nestado_de_crença\\n, crenças probabilísticas sobre o estado atual do mundo\\nação\\n, a ação do agente\\n    \\n    atualizar \\nestado_de_crença\\n com base em \\nação\\n e \\npercepção\\n    calcular probabilidades de resultados de ações,\\n        dadas descrições de ações e o \\nestado_de_crença\\n atual\\n    selecionar \\nação\\n com utilidade esperada mais alta\\n        dadas as probabilidades de resultados e informações de utilidade\\n    \\nretornar\\n \\nação\\nFigura 13.1\\n Um agente de teoria da decisão que seleciona ações racionais.\\n13.2 NOTAÇÃO BÁSICA DE PROBABILIDADE\\nPara que o nosso agente represente e utilize a informação probabilística, precisamos de uma\\nlinguagem formal. A linguagem da teoria da probabilidade tem sido tradicionalmente informal,\\nescrita por matemáticos humanos a outros matemáticos humanos. O Apêndice A inclui uma\\nintrodução-padrão para a teoria da probabilidade elementar; aqui, tomamos uma abordagem mais\\nadequada às necessidades da IA e mais consistente com os conceitos de lógica formal.\\n13.2.1 Sobre o que versam as probabilidades\\nComo as afirmações lógicas, as afirmações probabilísticas são acerca de mundos possíveis.\\nConsiderando que as afirmações lógicas dizem que os mundos possíveis são estritamente\\ndescartáveis (todos aqueles em que a afirmação é falsa), as afirmações probabilísticas versam sobre\\no quão prováveis são os vários mundos. Na teoria da probabilidade, o conjunto de todos os mundos\\npossíveis é chamado de \\nespaço amostral\\n. Os mundos possíveis são \\nmutuamente exclusivos e\\nexaustivos\\n — dois mundos possíveis não podem coexistir, e um mundo possível deve ser sempre\\nválido. Por exemplo, se jogamos dois dados (distintos), existem 36 mundos possíveis a considerar:\\n(1,1), (1,2),…, (6,6). A letra grega \\nΩ\\n (ômega maiúsculo) é usada para se referir ao espaço amostral,\\ne ω (ômega minúsculo) refere-se aos elementos do espaço, isto é, aos mundos possíveis particulares.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 569}),\n",
       " Document(page_content='Um \\nmodelo de probabilidade\\n totalmente especificado associa uma probabilidade numérica \\nP\\n(\\nω\\n) a\\ncada mundo possível.\\n1\\n Os axiomas básicos da teoria da probabilidade dizem que todo mundo\\npossível tem uma probabilidade entre 0 e 1 e que a probabilidade total do conjunto de mundos\\npossíveis é 1:\\nPor exemplo, se assumirmos que os dois dados não são “viciados” e um lançamento não interfere\\nno outro, cada um dos mundos possíveis (1,1), (1,2),…, (6,6) tem probabilidade 1/36. Por outro\\nlado, se os dados conspirarem para produzir o mesmo número, os mundos (1,1), (2,2), (3,3) etc.\\npoderão ter probabilidades maiores, deixando os outros com probabilidades menores.\\nAfirmações probabilísticas e consultas geralmente não são sobre mundos possíveis particulares,\\nmas sobre os seus conjuntos. Por exemplo, poderíamos estar interessados nos casos em que os dois\\ndados chegam ao resultado 11, os casos em que são jogados em duplas, e assim por diante. Em teoria\\nda probabilidade, esses conjuntos são chamados \\neventos\\n — um termo já usado extensivamente no\\nCapítulo 12 para um conceito diferente. Em IA, os conjuntos são sempre descritos por \\nproposições\\nem uma linguagem formal (tal linguagem será descrita na \\nSeção 13.2.2\\n). Para cada proposição, o\\nconjunto correspondente contém apenas aqueles mundos possíveis onde a proposição é válida. A\\nprobabilidade associada a uma proposição é definida como sendo a soma das probabilidades dos\\nmundos nos quais é válida:\\nPor exemplo, ao jogar dados que não são viciados, temos \\nP\\n(\\nTotal\\n = 11) = \\nP\\n((5, 6)) + \\nP\\n((6, 5)) =\\n1/36 + 1/36 = 1/18. Observe que a teoria da probabilidade não requer conhecimento completo das\\nprobabilidades de cada mundo possível. Por exemplo, se acreditamos que os dados conspiram para\\nproduzir o mesmo número, podemos \\nafirmar\\n que \\nP\\n (\\nduplas\\n) = 1/4 sem saber se os dados preferem a\\ndupla de 6 à de 2. Tal como aconteceu com asserções lógicas, essa asserção \\nrestringe\\n o modelo\\nprobabilístico subjacente sem determiná-lo totalmente.\\nProbabilidades, tais como \\nP\\n(\\nTotal\\n = 11) e \\nP\\n(\\nduplas\\n) são chamadas \\nprobabilidades incondicionais\\nou \\nanteriores\\n (e, às vezes, abreviado apenas como “anteriores”); elas se referem a graus de crença\\nem proposições \\nna ausência de qualquer outra informação\\n. Na maioria das vezes, no entanto, temos\\nalguma informação, geralmente chamada \\nevidência\\n, que já foi revelada. Por exemplo, o primeiro\\ndado pode já estar mostrando um 5 e estamos esperando ansiosamente que o outro pare de girar.\\nNesse caso, não estamos interessados na probabilidade incondicional do lançamento em duplas, mas\\nna probabilidade \\ncondicional\\n ou \\nposterior\\n (ou apenas “posterior”) de lançamento em duplas\\nconsiderando que o valor do primeiro dado é 5\\n. Essa probabilidade é escrita como \\nP\\n(\\nduplas\\n |\\nDado\\n1\\n = 5), onde o “|” é pronunciado como “considerando que”. Da mesma forma, se eu estou indo\\nao dentista para um \\ncheck-up\\n regular, a probabilidade \\nP\\n(\\ncárie\\n) = 0,2 pode ser interessante, mas se\\nestou indo ao dentista porque tenho uma dor de dente, é \\nP\\n(\\ncárie\\n | \\ndor de dente\\n) = 0,6 que importa.\\nObserve que a precedência de “|” é tal que qualquer expressão da forma \\nP\\n(…|…) sempre significa\\nP\\n((…) | (…)).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 570}),\n",
       " Document(page_content='É importante compreender que \\nP\\n(\\ncárie\\n) = 0,2 ainda é \\nválido\\n após a \\ndor de dente\\n ter sido\\nobservada; ela simplesmente não é especialmente útil. Ao tomar decisões, um agente precisa\\nestipular sobre \\ntodas\\n as evidências que tem observado. Também é importante entender a diferença\\nentre condicionar e implicação lógica. A afirmação de que \\nP\\n(\\ncárie\\n | \\ndor de dente\\n) = 0,6 não significa\\nque “sempre que \\ndor de dente\\n for verdadeiro, concluir que \\ncárie\\n é verdadeiro com probabilidade\\n0,6”, em vez disso significa: “Sempre que \\ndor de dente\\n for verdadeiro \\ne não temos mais\\ninformações\\n, concluir que \\ncárie\\n é verdadeiro com probabilidade 0,6.” A condição extra é\\nimportante; por exemplo, se tivéssemos a informação adicional de que o dentista não encontrou\\ncáries, definitivamente não desejaríamos concluir que \\ncárie\\n é verdadeiro com probabilidade 0,6; em\\nvez disso, precisaríamos utilizar \\nP\\n(\\ncárie\\n | \\ndor de dente\\n \\n∧\\n ¬\\ncárie\\n) = 0.\\nMatematicamente falando, as probabilidades condicionais são definidas em termos de\\nprobabilidades incondicionais como segue: para quaisquer proposições \\na\\n e \\nb\\n, temos\\nque é válido sempre que \\nP\\n(\\nb\\n) > 0. Por exemplo,\\nA definição faz sentido se você lembrar de observar que \\nb\\n descarta todos os mundos possíveis\\nonde \\nb\\n é falso, deixando um conjunto cuja probabilidade total é apenas \\nP\\n(\\nb\\n). Dentro desse conjunto,\\no \\na\\n-mundo satisfaz \\na\\n \\n∧\\n \\nb\\n e constitui uma fração de \\nP\\n(\\na\\n \\n∧\\n \\nb\\n)/\\nP\\n(\\nb\\n).\\nA definição de probabilidade condicional, Equação 13.3, pode ser escrita de uma forma diferente\\nchamada de \\nregra do produto\\n:\\nP\\n(\\na\\n \\n∧\\n \\nb\\n) = \\nP\\n(\\na\\n | \\nb\\n) \\nP\\n(\\nb\\n).\\nA regra do produto é talvez mais fácil de lembrar: ela vem do fato de que, para \\na\\n e \\nb\\n ser\\nverdadeiro, é necessário que \\na\\n seja verdadeiro, dado \\nb\\n.\\n13.2.2 A linguagem das proposições em afirmações de probabilidade\\nNeste capítulo e no próximo, as proposições que descrevem conjuntos de mundos possíveis são\\nescritas com uma notação que combina elementos de lógica proposicional e notação de satisfação de\\nrestrição. A terminologia da \\nSeção 2.4.7\\n é uma \\nrepresentação fatorada\\n, em que o mundo possível é\\nrepresentado por um conjunto de variável/pares de valor.\\nAs variáveis, na teoria da probabilidade, são chamadas de \\nvariáveis aleatórias\\n e seus nomes\\ncomeçam com letra maiúscula. Assim, no exemplo do dado, \\nTotal\\n e \\nDado\\n1\\n são variáveis aleatórias.\\nCada variável aleatória tem um \\ndomínio\\n — o conjunto de valores possíveis que pode assumir. O\\ndomínio de \\nTotal\\n para dois dados é o conjunto {2,…, 12} e o domínio de \\nDado\\n1\\n é {1,…, 6}. Uma\\nvariável aleatória booleana tem o domínio {\\nverdadeiro\\n, \\nfalso\\n} (note que os valores estão sempre', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 571}),\n",
       " Document(page_content='com letras minúsculas); por exemplo, a proposição de que as duplas são lançadas pode ser escrita\\ncomo \\nDuplas\\n = \\nverdadeiro\\n. Por convenção, as proposições da forma \\nA\\n = \\nverdadeiro\\n são abreviadas\\nsimplesmente como \\na\\n, enquanto \\nA\\n = \\nfalso\\n é abreviado como ¬\\na\\n (\\nduplas\\n, \\ncárie\\n e \\ndor de dente\\n na\\nseção anterior são abreviaturas desse tipo). Como em PSR, os domínios podem ser conjuntos de\\nsímbolos arbitrários; poderíamos escolher o domínio de \\nIdade\\n como {\\njuvenil\\n, \\nadolescente\\n, \\nadulto\\n}\\ne o domínio de \\nTempo\\n como {\\nensolarado\\n, \\nchuvoso\\n, \\nnublado\\n, nevando}. Quando nenhuma\\nambiguidade é possível, é comum usar um valor por si só para representar a proposição de que\\ndeterminada variável tem aquele valor; assim, ensolarado pode representar \\nTempo\\n = \\nensolarado\\n.\\nOs exemplos anteriores têm domínios finitos. As variáveis podem ter domínios infinitos também\\n— discretos (como os inteiros) ou contínuos (como os reais). Para qualquer variável com domínio\\nordenado, as desigualdades também são permitidas, como \\nNúmeroDeAtomosNoUniverso\\n ≥ 10\\n70\\n.\\nFinalmente, podemos combinar esses tipos de proposições elementares (incluindo as formas\\nabreviadas das variáveis booleanas) usando os conectivos da lógica proposicional. Por exemplo,\\npodemos expressar que “a probabilidade que o paciente tenha uma cárie, uma vez que é um\\nadolescente, sem dor de dente, é de 0,1” como segue:\\nP\\n (\\ncárie\\n | ¬ \\ndor de dente\\n \\n∧\\n \\nadolescente\\n) = 0,1.\\nÀs vezes vamos desejar falar sobre as probabilidades de \\ntodos\\n os valores possíveis de uma\\nvariável aleatória. Podemos escrever:\\nP\\n (\\nTempo = ensolarado\\n) = 0,6\\nP\\n (\\nTempo = chuvoso\\n) = 0,1\\nP\\n (\\nTempo = nublado\\n) = 0,29\\nP\\n (\\nTempo = neve\\n) = 0,01,\\nmas, abreviando, teremos\\nP\\n(\\nTempo\\n) = < 0,6; 0,1; 0,29; 0,01>,\\nonde o \\nP\\n em negrito indica que o resultado é um vetor de números e onde assumimos uma ordenação\\npredefinida \\n〈\\nensolarado\\n, \\nchuvoso\\n, \\nnublado\\n, nevando\\n〉\\n no domínio do \\nTempo\\n. Dizemos que a\\ndeclaração \\nP\\n define uma \\ndistribuição de probabilidade\\n para a variável aleatória \\nTempo\\n. A notação\\nP\\n também é utilizada para distribuições condicionais: \\nP\\n(\\nX\\n | \\nY\\n), que dá os valores de \\nP\\n(\\nX\\n = \\nx\\ni\\n | \\nY\\n = \\ny\\nj\\n)\\npara cada par possível \\ni\\n, \\nj\\n.\\nPara variáveis contínuas, não é possível escrever toda a distribuição como um vetor porque há um\\nnúmero infinito de valores. Em vez disso, podemos definir a probabilidade de que uma variável\\naleatória assume algum valor de \\nx\\n como uma função parametrizada de \\nx\\n. Por exemplo, a sentença\\nP\\n (\\nTempMeioDia = x\\n) = \\nUniforme\\n[18C, 26\\nC\\n]\\n(\\nx\\n)\\nexpressa a crença de que a temperatura ao meio-dia é distribuída uniformemente entre 18-26 graus\\nCelsius. Chamamos isso de \\nfunção densidade de probabilidade\\n.\\nFunções densidade de probabilidade (às vezes chamadas de \\nfdps\\n) diferem em significado de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 572}),\n",
       " Document(page_content='distribuições discretas. Dizer que a densidade de probabilidade é uniforme a partir de 18\\nC\\n até 26\\nC\\nsignifica que há uma chance de 100% de que a temperatura vai cair em algum lugar naquela região\\ncom amplitude 8\\nC\\n e 50% de chance de cair em qualquer região com amplitude 4\\nC\\n, e assim por\\ndiante. Escrevemos a probabilidade de densidade de uma variável aleatória contínua \\nX\\n ao valor \\nx\\ncomo \\nP\\n(\\nX = x\\n) ou simplesmente \\nP\\n(\\nx\\n); a definição intuitiva de \\nP\\n(\\nx\\n) é a probabilidade de que \\nX\\n cai\\ndentro de uma pequena região arbitrariamente iniciando em \\nx\\n, dividido pela largura da região:\\nPara \\nTempMeioDia\\n temos\\nonde \\nC\\n representa centígrados. Em \\nP\\n(\\nTempMeioDia\\n= 20,18\\nC\\n) = \\n, observe que \\n não é uma\\nprobabilidade, é uma densidade de probabilidade. A probabilidade de que \\nTempMeioDia\\n seja\\nexatamente 20,18\\nC\\n é zero porque 20,18\\nC\\n é uma região de largura 0. Alguns autores utilizam\\nsímbolos diferentes para distribuições discretas e funções de densidade; nós utilizamos \\nP\\n em ambos\\nos casos, uma vez que raramente surge confusão e as equações são geralmente idênticas. Observe que\\nas probabilidades são números que não têm unidade, enquanto as funções de densidade são medidas\\ncom uma unidade, nesse caso graus recíprocos.\\nAlém de distribuições sobre variáveis simples, precisamos de uma notação para distribuições\\nsobre variáveis múltiplas. Para isso é utilizado a vírgula. Por exemplo, \\nP\\n (\\nTempo\\n, \\nCárie\\n) indica as\\nprobabilidades de todas as combinações de valores de \\nTempo\\n e de \\nCárie\\n. Essa é uma tabela de\\nprobabilidades 4 × 2 chamada de \\ndistribuição de probabilidade conjunta\\n de \\nTempo\\n e de \\nCárie\\n.\\nPodemos também misturar as variáveis com e sem valores; \\nP\\n (\\nensolarado\\n, \\nCárie\\n) seria um vetor de\\ndois elementos dando as probabilidades de um dia ensolarado com cárie e um dia ensolarado sem\\ncárie. A notação \\nP\\n torna certas expressões muito mais concisas do que poderiam ser. Por exemplo,\\nas regras dos produtos para todos os valores possíveis de \\nTempo\\n e \\nCárie\\n podem ser escritas como\\numa equação única:\\nP\\n (\\nTempo, Cárie\\n) = \\nP\\n (Tempo | \\nCárie\\n) \\nP\\n (\\nCárie\\n),\\nem vez das 4 × 2 = 8 equações (utilizando abreviaturas \\nW\\n e \\nC\\n):\\nComo um caso degenerado, \\nP\\n(\\nensolarado\\n, \\ncárie\\n) não tem variáveis e, portanto, é um vetor de um\\nelemento que é a probabilidade de um dia ensolarado com uma cárie, que também poderia ser escrito', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 573}),\n",
       " Document(page_content='como \\nP\\n(\\nensolarado\\n, \\ncárie\\n) ou \\nP\\n(\\ncárie\\n \\n∧\\n \\nensolarado\\n). Utilizaremos por vezes a notação \\nP\\n para\\nobter resultados sobre valores individuais de \\nP\\n e, quando dizemos que “\\nP\\n(\\nensolarado\\n) = 0,6” é\\nrealmente uma abreviatura para “\\nP\\n(\\nensolarado\\n), é o vetor de um elemento <0,6>, que significa que\\nP\\n(\\nensolarado\\n) = 0,6”.\\n Agora definimos uma sintaxe para proposições e afirmações de probabilidade e temos parte da\\nsemântica dada: a Equação 13.2 define a probabilidade de uma proposição como a soma das\\nprobabilidades de mundos nos quais é válida. Para completar a semântica, é preciso dizer quais são\\nos mundos e como determinar se uma proposição é válida no mundo. Tomamos emprestada essa\\nparte diretamente da semântica da lógica proposicional, como segue. \\nUm mundo possível é definido\\npara ser uma atribuição de valores a todas as variáveis aleatórias consideradas.\\n É fácil verificar\\nque essa definição satisfaz o requisito básico de que os mundos possíveis são mutuamente exclusivos\\ne exaustivos (Exercício 13.5). Por exemplo, se as variáveis aleatórias são \\nCárie\\n, \\nDor de dente\\n e\\nTempo\\n, então existem 2 × 2 × 4 = 16 mundos possíveis. Além disso, a verdade de qualquer\\nproposição dada, não importa o quanto seja complexa, pode ser facilmente determinada em tais\\nmundos utilizando a mesma definição recursiva de verdade, como de fórmulas em lógica\\nproposicional.\\nA partir da definição anterior dos mundos possíveis, segue que um modelo de probabilidade é\\ncompletamente determinado pela distribuição conjunta de todas as variáveis aleatórias — a chamada\\ndistribuição de probabilidade conjunta completa\\n. Por exemplo, se as variáveis são \\nDor de dente\\n,\\nCárie\\n e \\nTempo\\n, a distribuição conjunta completa é dada por \\nP\\n(\\nCárie\\n, \\nDor de dente\\n, \\nTempo\\n). Essa\\ndistribuição conjunta pode ser representada como uma tabela 2 × 2 × 4 com 16 entradas. Como cada\\nprobabilidade da proposição é a soma dos mundos possíveis, uma distribuição conjunta completa é,\\nem princípio, suficiente para calcular a probabilidade de qualquer proposição.\\n13.2.3 Axiomas de probabilidade e sua razoabilidade\\nOs axiomas básicos da probabilidade (Equações 13.1 e 13.2) implicam certas relações entre os\\ngraus de crença que podem ser atribuídos às proposições logicamente relacionadas. Por exemplo,\\npodemos derivar a relação familiar entre a probabilidade de uma proposição e a probabilidade de\\nsua negação:\\nPodemos também derivar a bem conhecida fórmula da probabilidade de uma disjunção, às vezes\\nchamada de \\nprincípio de inclusão-exclusão\\n:\\nEssa regra é facilmente lembrada observando que os casos em que \\na\\n é válido, junto com os casos\\nem que \\nb\\n é válido, certamente envolvem todos os casos em que \\na\\n \\n∨\\n \\nb\\n é válido, mas, somando os', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 574}),\n",
       " Document(page_content='dois conjuntos de casos, conta sua interseção duas vezes, por isso precisamos subtrair \\nP\\n(\\na\\n \\n∧\\n \\nb\\n). A\\ndemonstração é deixada como exercício (Exercício 13.6).\\nAs Equações 13.1 e 13.4 são frequentemente chamadas de \\naxiomas de Kolmogorov\\n, em honra ao\\nmatemático russo Andrei Kolmogorov, que mostrou como construir o restante da teoria da\\nprobabilidade a partir desse fundamento simples e como lidar com as dificuldades causadas pelas\\nvariáveis contínuas.\\n2\\n Enquanto a Equação 13.2 tem um sabor de definição, a Equação 13.4 revela que\\nos axiomas realmente restringem os graus de crença que um agente pode ter sobre as proposições\\nlogicamente relacionadas. Isso é análogo ao fato de que um agente lógico não pode acreditar\\nsimultaneamente em \\nA\\n, \\nB\\n e ¬(\\nA\\n \\n∧\\n \\nB\\n) porque não existe um mundo possível no qual todos os três\\nsejam verdadeiros. Com probabilidades, no entanto, as declarações não se referem ao mundo\\ndiretamente, mas ao próprio estado de conhecimento do agente. Por que, então, um agente não pode\\nmanter o seguinte conjunto de crenças (mesmo que elas violem os axiomas de Kolmogorov)?\\nEsse tipo de pergunta tem sido objeto de décadas de intenso debate entre aqueles que defendem o\\nuso de probabilidades como a única forma legítima de graus de crença e aqueles que defendem\\nabordagens alternativas.\\nUm argumento para os axiomas de probabilidade, exposto pela primeira vez em 1931 por Bruno\\nde Finetti [e traduzido para o inglês em Finetti (1993)], é o seguinte: se um agente tem algum grau de\\ncrença na proposição \\na\\n, então o agente deveria ser capaz de exprimir as probabilidades em que é\\nindiferente apostar a favor ou contra \\na\\n.\\n3\\n Pense nisso como um jogo entre dois agentes: o agente 1\\nafirma: “Meu grau de crença no evento \\na\\n é de 0,4.” O Agente 2 está então livre para escolher se quer\\napostar a favor ou contra em jogos que são consistentes com o grau de crença declarado. Ou seja, o\\nAgente 2 pode optar por aceitar a aposta do Agente 1 de que \\na\\n vai ocorrer, oferecendo $6 contra $4\\ndo Agente 1. Ou o Agente 2 pode aceitar a aposta do Agente 1 de que ¬\\na\\n vai ocorrer, oferecendo $4\\ncontra $6 do Agente 1. Então observamos que o resultado de \\na\\n e de quem estiver certo recolhe o\\ndinheiro. Se os graus de crença de um agente não refletirem o mundo exatamente, é de se esperar que\\ntendam a perder dinheiro em longo prazo em relação ao agente oponente cujas crenças refletem mais\\nprecisamente o estado do mundo.\\n De Finetti provou algo muito mais forte: \\nse o Agente 1 expressa um conjunto de graus da\\ncrença que violam os axiomas da teoria da probabilidade, há uma combinação de apostas pelo\\nAgente 2, que garante que o Agente 1 vai perder dinheiro toda vez.\\n Por exemplo, suponha que o\\nAgente 1 tenha o conjunto de graus de crença da Equação 13.5. A \\nFigura 13.2\\n mostra que, se o\\nAgente 2 escolhe apostar $4 em \\na\\n, $3 em \\nb\\n e $2 em ¬(\\na\\n \\n∨\\n \\nb\\n), então o Agente 1 sempre perderá\\ndinheiro, independentemente dos resultados de \\na\\n e \\nb\\n. O teorema de de Finetti implica que nenhum\\nagente racional pode ter crenças que violem os axiomas da probabilidade.\\nAgente 1\\nAgente 2\\nResultados e pagamentos para o Agente 1\\nProposição\\nCrença\\nAposta\\nDinheiro apostado\\na, b\\na,¬b\\n¬a, b\\n¬a,¬b\\na\\n0,4\\na\\n4 a 6\\n–6\\n–6\\n4\\n4', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 575}),\n",
       " Document(page_content='b\\na\\n \\n∨\\n \\nb\\n0,3\\n0,8\\nb\\n¬(\\na\\n \\n∨\\n \\nb\\n)\\n3 a 7\\n2 a 8\\n–7\\n2\\n3\\n2\\n–7\\n2\\n3\\n–8\\n \\n \\n \\n \\n–11\\n–1\\n–1\\n–1\\nFigura 13.2\\n Devido ao Agente 1 ter crenças inconsistentes, o Agente 2 é capaz de conceber um\\nconjunto de apostas que garante a perda para o Agente 1, não importa o resultado de \\na\\n e \\nb\\n.\\nUma objeção comum ao teorema de De Finetti é que esse jogo de apostas é um pouco artificial.\\nPor exemplo, o que acontece se alguém se recusa a apostar? Isso acaba com a disputa? A resposta é\\nque o jogo de apostas é um modelo abstrato para a situação de tomada de decisão em que cada agente\\nestá \\ninevitavelmente\\n envolvido em cada momento. Cada ação (incluindo inatividade) é uma espécie\\nde aposta, e cada resultado pode ser visto como um desenlace da aposta. Recusar-se a apostar é\\ncomo se recusar a permitir que o tempo passe.\\nOutros argumentos filosóficos fortes têm sido apresentados pelo uso das probabilidades,\\nprincipalmente os de Cox (1946), Carnap (1950) e Jaynes (2003). Cada um construiu um conjunto de\\naxiomas para o raciocínio com graus de crenças: não há contradições, correspondência com lógica\\ncomum (por exemplo, se a crença em \\nA\\n sobe, a crença, em ¬\\nA\\n deve baixar), e assim por diante. O\\núnico item controverso com relação ao axioma é que os graus de crença devem ser números ou pelo\\nmenos agir como números, e devem ser transitivos (se a crença em \\nA\\n for maior do que a crença em \\nB\\n,\\nque é maior do que a crença em \\nC\\n, então a crença em \\nA\\n deve ser maior que em \\nC\\n) e comparáveis (a\\ncrença em \\nA\\n deve ser igual, maior ou menor do que a crença em \\nB\\n). Então poderá ser provado que a\\nprobabilidade é a única abordagem que satisfaz esses axiomas.\\nNo entanto, sendo o mundo do jeito que é, às vezes as demonstrações práticas falam mais alto do\\nque as evidências. O sucesso dos sistemas de raciocínio baseados na teoria da probabilidade tem\\nsido muito eficaz para atrair seguidores. Veremos agora como os axiomas podem ser implantados\\npara fazer inferências.\\n13.3 INFERÊNCIA COM O USO DE DISTRIBUIÇÕES CONJUNTAS\\nTOTAIS\\nNesta seção, descreveremos um método simples de \\ninferência probabilística\\n, isto é, a computação\\nde probabilidades posteriores de proposições de consulta dada uma evidência observada.\\nUtilizaremos a distribuição conjunta total como a “base de conhecimento” a partir da qual poderão\\nser derivadas respostas para todas as perguntas. Ao longo do caminho, também introduziremos várias\\ntécnicas úteis para manipular equações que envolvem probabilidades.\\n \\ndordedente\\n¬\\ndordedente\\n \\nboticão\\n¬\\nboticão\\nboticão\\n¬\\nboticão\\ncárie\\n0,108\\n0,012\\n0,072\\n0,008\\n¬\\ncárie\\n0,016\\n0,064\\n0,144\\n0,576', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 576}),\n",
       " Document(page_content='Figura 13.3\\n Uma distribuição conjunta total para o mundo de \\nDorDeDente\\n, \\nCárie\\n, \\nBoticão\\n.\\nComeçaremos com um exemplo muito simples: um domínio que consiste apenas nas três variáveis\\nbooleanas \\nDorDeDente\\n, \\nCárie\\n e \\nBoticão\\n (a horrível tenaz de aço com que o dentista agarra meu\\ndente para extraí-lo). A distribuição conjunta total é uma tabela 2 × 2 × 2, como mostra a \\nFigura\\n13.3\\n.\\nNote que as probabilidades na distribuição conjunta têm a soma 1, conforme exigem os axiomas de\\nprobabilidade. Note também que a Equação 13.2 fornece um caminho direto para calcular a\\nprobabilidade de qualquer proposição, simples ou complexa: simplesmente identificamos os mundos\\npossíveis nos quais a proposição é verdadeira e somamos suas probabilidades. Por exemplo, existem\\nseis eventos atômicos em que \\ncárie\\n \\n∨\\n \\ndordedente\\n é válida:\\nP\\n(\\ncárie\\n \\n∨\\n \\ndordedente\\n) = 0,108 + 0,012 + 0,072 + 0,008 + 0,016 + 0,064 = 0,28.\\nUma tarefa particularmente comum é extrair a distribuição sobre algum subconjunto de variáveis\\nou sobre uma única variável. Por exemplo, a adição das entradas da primeira linha produz a\\nprobabilidade incondicional ou \\nprobabilidade marginal\\n4\\n de \\ncárie\\n:\\nP\\n(\\ncárie\\n) = 0,108 + 0,012 + 0,072 + 0,008 = 0,2.\\nDE ONDE VÊM AS PROBABILIDADES?\\nExiste um debate sem fim sobre a origem e o \\nstatus\\n de valores de probabilidade. A posição\\nfrequentista\\n afirma que os números só podem vir de \\nexperimentos\\n: se testarmos 100 pessoas e\\ndescobrirmos que 10 delas têm cáries, poderemos afirmar que a probabilidade de uma cárie é\\naproximadamente 0,1. Segundo essa visão, a asserção “a probabilidade de uma cárie é 0,1”\\nsignifica que 0,1 é a fração que seria observada no limite de infinitamente muitas amostras. A\\npartir de qualquer amostra finita, podemos estimar a fração verdadeira e também calcular a\\nprobabilidade de exatidão de nossa estimativa.\\nA visão \\nobjetivista\\n afirma que as probabilidades são aspectos reais do universo — tendências\\nde objetos a se comportarem de determinadas maneiras —, em vez de serem apenas descrições do\\ngrau de crença de um observador. Por exemplo, o fato de o lançamento de uma moeda comum dar\\ncara com probabilidade 0,5 é uma tendência da própria moeda. Segundo essa visão, as medições\\nfrequentistas são tentativas de observar essas tendências. A maior parte dos físicos concorda com\\no fato de que os fenômenos quânticos são objetivamente probabilísticos, mas a incerteza na escala\\nmacroscópica — por exemplo, no lançamento de uma moeda — em geral surge da ignorância das\\ncondições iniciais e não parece consistente com a visão de propensão.\\nA visão \\nsubjetivista\\n descreve probabilidades como um modo de caracterizar as crenças de um\\nagente, em vez de ter qualquer significado físico externo. A visão subjetiva \\nbayesiana\\n permite\\nqualquer atribuição autoconsistente de probabilidades anteriores a proposições, mas insiste na\\nprópria atualização bayesiana à medida que a evidência chega.\\nNo final, até mesmo uma posição frequentista rígida envolve análise subjetiva, por causa da', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 577}),\n",
       " Document(page_content='classe de referência\\n: na tentativa de determinar a probabilidade de resultado de uma experiência\\nparticular\\n, o frequentista tem de colocá-la em uma classe de referência de experimentos\\n“similares” com frequências de resultados conhecidos. I. J. Good (1983, p. 27) escreveu: “Todos\\nos eventos na vida são únicos, e toda probabilidade da vida real que estimamos na prática é a de\\num evento que nunca ocorreu antes.” Por exemplo, dado um paciente em particular, um frequentista\\nque deseja estimar a probabilidade de uma cárie, vai considerar uma classe de referência de\\noutros pacientes que são semelhantes em itens importantes — idade, sintomas, dieta — e verificar\\nque proporção deles tem uma cárie. Se o médico considerar tudo o que se conhece sobre o\\npaciente — o peso aproximado até o grama mais próximo, cor do cabelo, nome de solteira da mãe\\netc. —, o resultado será a inexistência de outros pacientes exatamente iguais e, portanto, não\\nhaverá nenhuma classe de referência a partir da qual coletar dados experimentais. Esse foi um\\nproblema constrangedor na filosofia da ciência.\\nO \\nprincípio da indiferença\\n atribuído a Laplace (1816) declara que as proposições\\nsintaticamente “simétricas” com relação à evidência devem ser consideradas proposições de igual\\nprobabilidade. Vários aprimoramentos foram propostos, culminando na tentativa de Carnap e\\noutros de desenvolver uma rigorosa \\nlógica indutiva\\n, capaz de calcular a probabilidade correta\\npara qualquer proposição a partir de qualquer coleção de observações. Atualmente, acredita-se\\nque não existe nenhuma lógica indutiva única; em vez disso, qualquer lógica desse tipo se baseia\\nem uma distribuição subjetiva de probabilidade \\na priori\\n cujo efeito é reduzido à medida que são\\ncoletados resultados de outras observações.\\nEsse processo é chamado \\nmarginalização\\n ou \\ntotalização\\n porque totalizamos as probabilidades\\npara cada valor possível de outras variáveis, assim excluindo-as da equação. Podemos escrever a\\nregra geral de marginalização a seguir para quaisquer conjuntos de variáveis \\nY\\n e \\nZ\\n:\\nonde \\nΣ\\nz\\n∊\\nZ\\n significa a soma sobre todas as combinações possíveis de valores do conjunto de\\nvariáveis \\nZ\\n. Por vezes, abreviamos como Σ\\nz\\n, deixando \\nZ\\n implícito. Apenas utilizamos a regra como\\nUma variante dessa regra envolve probabilidades condicionais em vez de probabilidades\\nconjuntas, usando-se a regra do produto:\\nEssa regra é chamada \\ncondicionamento\\n. Marginalização e condicionamento se mostrarão regras\\núteis para todos os tipos de derivações que envolverem expressões de probabilidade.\\nNa maioria dos casos, estaremos interessados em calcular probabilidades \\ncondicionais\\n de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 578}),\n",
       " Document(page_content='algumas variáveis, dada alguma evidência sobre outras. As probabilidades condicionais podem ser\\ndescobertas usando-se primeiro a Equação 13.3 para obter uma expressão em termos de\\nprobabilidades não condicionais, e então avaliando-se a expressão a partir da distribuição conjunta\\ntotal. Por exemplo, podemos calcular a probabilidade de uma cárie, dada a evidência de uma dor de\\ndente, como a seguir:\\nSó para conferir, também podemos calcular a probabilidade de não haver nenhuma cárie, dada\\numa dor de dente:\\nConforme esperado, as duas variáveis somam 1. Note que, nesses dois cálculos, a expressão\\n1/\\nP\\n(\\ndordedente\\n) permanece constante, não importando que valor de \\nCárie\\n calculamos. De fato, ela\\npode ser visualizada como uma constante de \\nnormalização\\n para a distribuição \\nP\\n(\\nCárie\\n |\\ndordedente\\n), assegurando que a soma será 1. Ao longo dos capítulos que lidam com probabilidade,\\nusaremos \\nα\\n \\npara\\n denotar tais constantes. Com essa notação, podemos transformar as duas equações\\nprecedentes em uma:\\nP\\n(\\nCárie\\n | \\ndordedente\\n) = α\\nP\\n(\\nCárie\\n, \\ndordedente\\n)\\n= \\nα\\n [\\nP\\n(\\nCárie\\n, \\ndordedente\\n, \\nboticão\\n) + \\nP\\n(\\nCárie\\n, \\ndordedente\\n, ¬\\nboticão\\n)]\\n= \\nα\\n [\\n〈\\n0,108, 0,016\\n〉\\n + \\n〈\\n0,012, 0,064\\n〉\\n] = \\nα\\n \\n〈\\n0,12, 0,08\\n〉\\n = \\n〈\\n0,6, 0,4\\n〉\\n.\\nEm outras palavras, podemos calcular \\nP\\n(\\nCárie\\n | \\ndor de dente\\n) mesmo se não soubermos o valor\\nde \\nP\\n(\\ndor de dente\\n)! Esquecemos temporariamente o fator 1/\\nP\\n(\\ndor de dente\\n) e somamos os valores\\nde cárie e ¬\\ncárie\\n, obtendo 0,12 e 0,08. Essas são as proporções relativas corretas, mas não perfazem\\n1, de modo que as normalizamos, dividindo cada uma por 0,12 + 0,08, ficando com as\\nprobabilidades verdadeiras de 0,6 e 0,4. A normalização acaba por ser um atalho útil em muitos\\ncálculos de probabilidade, tanto para tornar a computação mais fácil como para permitir-nos\\ncontinuar quando alguma avaliação de probabilidade (como \\nP\\n(\\ndor de dente\\n)) não estiver disponível.\\nA partir do exemplo, podemos extrair um procedimento de inferência geral. Começamos com o\\ncaso em que a consulta envolve uma única variável, \\nX\\n (\\nCárie\\n no exemplo). Seja \\nE\\n o conjunto de\\nvariáveis de evidência (apenas \\nDorDeDente\\n no exemplo), seja \\ne\\n o conjunto de valores observados\\npara elas e seja \\nY\\n as variáveis restantes não observadas (apenas \\nBoticão\\n no exemplo). A consulta é\\nP\\n(\\nX\\n | \\ne\\n) e pode ser avaliada como:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 579}),\n",
       " Document(page_content='onde o somatório é efetuado sobre todos os valores \\ny\\n possíveis (isto é, todas as combinações\\npossíveis de valores das variáveis não observadas \\nY\\n). Note que, juntas, as variáveis \\nX\\n, \\nE\\n e \\nY\\nconstituem o conjunto completo de variáveis para o domínio; assim, \\nP\\n(\\nX\\n, \\ne\\n, \\ny\\n) é simplesmente um\\nsubconjunto de probabilidades a partir da distribuição conjunta total.\\nDada a distribuição conjunta total de trabalho, a Equação 13.9 pode responder a consultas\\nprobabilísticas referentes a variáveis discretas. Porém, ele não aumenta de escala muito bem: para\\num domínio descrito por \\nn\\n variáveis booleanas, o algoritmo exige uma tabela de entrada com o\\ntamanho \\nO\\n(2\\nn\\n) e demora o tempo \\nO\\n(2\\nn\\n) para processar a tabela. Em um problema realista, podemos\\nter facilmente \\nn\\n > 100, tornando \\nO\\n(2\\nn\\n) impraticável. Por essas razões, a distribuição conjunta total\\nem forma tabular não é uma ferramenta prática para construir sistemas de raciocínio.\\nEm vez disso, devemos visualizá-la como o fundamento teórico sobre o qual podem ser\\nelaboradas abordagens mais efetivas, assim como as tabelas de verdade formaram um fundamento\\nteórico para os algoritmos mais práticos como DPLL. O restante deste capítulo introduz algumas das\\nideias básicas necessárias na preparação para o desenvolvimento de sistemas realistas, no Capítulo\\n14.\\n13.4 INDEPENDÊNCIA\\nVamos expandir a distribuição conjunta total da \\nFigura 13.3\\n, adicionando uma quarta variável,\\nTempo\\n. A distribuiçao conjunta total então se torna \\nP\\n(\\nDorDeDente\\n, \\nBoticão\\n, \\nCárie\\n, \\nTempo\\n), que tem\\n2 × 2 × 2 × 4 = 32 entradas. Ela contém quatro “edições” da tabela mostrada na \\nFigura 13.3\\n, uma\\npara cada espécie de tempo. Parece natural indagar que relacionamento essas edições mantêm umas\\ncom as outras e com a tabela original de três variáveis. Por exemplo, como \\nP\\n(\\ndordedente\\n, \\nboticão\\n,\\ncárie\\n, \\nnublado\\n) e \\nP\\n(\\ndordedente\\n, \\nboticão\\n, \\ncárie\\n) estão relacionadas? Podemos utilizar a regra do\\nproduto:\\nP\\n(\\ndordedente, boticão\\n, \\ncárie\\n, \\nnublado\\n)\\n= \\nP\\n(\\nnublado\\n | \\ndordedente, boticão\\n, \\ncárie\\n) \\nP\\n(\\ndordedente, boticão\\n, \\ncárie\\n).\\nAgora, a menos que se esteja no ramo comercial de divindade, não se deve imaginar que os\\nproblemas dentários de alguém influenciam as condições do tempo. E, para a odontologia em\\nconsultório, pelo menos, parece seguro dizer que o tempo não influencia as variáveis dentárias.\\nPortanto, a asserção a seguir parece razoável:\\nA partir disso, podemos deduzir:\\nP\\n(\\ndordedente, boticão\\n, \\ncárie\\n, \\nnublado\\n) = \\nP\\n(\\nnublado\\n) \\nP\\n(\\ndordedente, boticão\\n, \\ncárie\\n).\\nExiste uma equação semelhante para \\ntoda entrada\\n em \\nP\\n(\\nDorDeDente, Boticão\\n, \\nCárie\\n, \\nTempo\\n).\\nDe fato, podemos escrever a equação geral:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 580}),\n",
       " Document(page_content='P\\n(\\nDorDeDente, Boticão\\n, \\nCárie\\n, \\nTempo\\n) = \\nP\\n(\\nDorDeDente, Boticão\\n, \\nCárie\\n)\\nP\\n(\\nTempo\\n).\\nDesse modo, a tabela de 32 elementos para quatro variáveis pode ser construída a partir de uma\\ntabela de oito elementos e uma tabela de quatro elementos. Essa decomposição é ilustrada\\nesquematicamente na \\nFigura 13.4\\n(a).\\nFigura 13.4\\n Dois exemplos de fatoração de uma grande distribuição conjunta em distribuições\\nmenores, com a utilização da independência absoluta. (a) As condições do tempo e os problemas\\ndentários são independentes. (b) Lançamentos de moedas são independentes.\\nA propriedade que empregamos para escrever a Equação 13.10 é chamada \\nindependência\\n(também \\nindependência marginal\\n e \\nindependência absoluta\\n). Em particular, o tempo é independente\\ndos problemas dentários de alguém. A independência entre as proposições \\na\\n e \\nb\\n pode ser escrita\\ncomo:\\nTodas essas formas são equivalentes (Exercício 13.12). A independência entre as variáveis \\nX\\n e \\nY\\npode ser escrita como a seguir (mais uma vez, essas formas são todas equivalentes):\\nP\\n(\\nX\\n | \\nY\\n) = \\nP\\n(\\nX\\n) ou \\nP\\n(\\nY\\n | \\nX\\n) = \\nP\\n(\\nY\\n) ou \\nP\\n(\\nX\\n, \\nY\\n) = \\nP\\n(\\nX\\n)\\nP\\n(\\nY\\n).\\nAs asserções de independência em geral se baseiam no conhecimento do domínio. Como o\\nexemplo do tempo na dor de dente ilustra, elas podem reduzir drasticamente a quantidade de\\ninformações necessárias para especificar a distribuição conjunta total. Se o conjunto completo de\\nvariáveis puder ser dividido em subconjuntos independentes, então a distribuição conjunta total\\npoderá ser \\nfatorada\\n em distribuições conjuntas separadas sobre esses subconjuntos. Por exemplo, a\\ndistribuição conjunta total sobre o resultado de \\nn\\n lançamentos de moedas independentes, \\nP\\n(\\nC\\n1, …,\\nCn\\n), tem 2\\nn\\n entradas, mas pode ser representada como o produto de \\nn\\n distribuições de variáveis\\nP\\n(\\nC\\ni\\n). De modo mais prático, a independência entre a odontologia e a meteorologia é algo bom\\nporque, do contrário, a prática da odontologia poderia exigir o conhecimento íntimo da meteorologia\\ne \\nvice-versa\\n.\\nPortanto, quando estão disponíveis, as asserções de independência podem ajudar na redução do', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 581}),\n",
       " Document(page_content='tamanho da representação do domínio e da complexidade do problema de inferência. Infelizmente, a\\nseparação clara e completa de conjuntos de variáveis por independência é bastante rara. Sempre que\\nexistir uma conexão, ainda que indireta entre duas variáveis, a independência deixará de ser válida.\\nAlém disso, até mesmo subconjuntos independentes podem ser bastante grandes — por exemplo, a\\nodontologia pode envolver dezenas de doenças e centenas de sintomas, todos inter-relacionados.\\nPara tratar de tais problemas, precisaremos de métodos mais sutis que o simples conceito de\\nindependência.\\n13.5 A REGRA DE BAYES E SEU USO\\nAnteriormente, definimos a \\nregra do produto.\\n Ela pode ser escrita de duas formas:\\nIgualando os dois membros da direita e dividindo por \\nP\\n(\\na\\n), obtemos:\\nEssa equação é conhecida como \\nregra de Bayes\\n (e também como lei de Bayes ou teorema de\\nBayes). Essa equação simples é a base de todos os sistemas modernos de IA para inferência\\nprobabilística.\\nO caso mais geral de variáveis multivaloradas pode ser escrito na notação de \\nP\\n como segue:\\nComo antes, essa equação deve ser considerada a representação de um conjunto de equações, cada\\numa lidando com valores específicos das variáveis. Também teremos a oportunidade de usar uma\\nversão mais geral condicionalizada em alguma evidência prática \\ne\\n:\\n13.5.1 Aplicação da regra de Bayes: o caso simples\\nÀ primeira vista, a regra de Bayes não parece muito útil. Ela nos permite calcular o único termo\\nP\\n(\\nb\\n | \\na\\n) em termos de três termos: \\nP\\n(\\na\\n | \\nb\\n), \\nP\\n(\\nb\\n) e \\nP\\n(\\na\\n). Isso parece como a duas etapas atrás, mas a\\nregra de Bayes é útil na prática porque existem muitos casos em que fazemos boas estimativas de\\nprobabilidade para esses três números e precisamos calcular o quarto número. Muitas vezes,\\npercebemos o \\nefeito\\n como evidência de alguma \\ncausa\\n desconhecida e gostaríamos de determinar\\nessa causa. Nesse caso, a regra de Bayes torna-se', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 582}),\n",
       " Document(page_content='A probabilidade condicional \\nP\\n(\\nefeito\\n|\\ncausa\\n) quantifica a relação na direção \\ncausal\\n, enquanto\\nP\\n(\\ncausa\\n|\\nefeito\\n) descreve a direção do \\ndiagnóstico\\n. Em uma tarefa como o diagnóstico médico com\\nfrequência temos probabilidades condicionais sobre relacionamentos causais (isto é, o médico\\nconhece \\nP\\n(\\nsintomas\\n|\\ndoenças\\n)) e quer derivar um diagnóstico \\nP\\n(\\ndoenças\\n|\\nsintomas\\n). Por exemplo, um\\nmédico sabe que a meningite faz o paciente ter uma rigidez no pescoço, digamos, durante 70\\n%\\n do\\ntempo. O médico também conhece alguns fatos incondicionais: a probabilidade \\na priori\\n de um\\npaciente ter meningite é 1/50.000, e a probabilidade \\na priori\\n de qualquer paciente ter rigidez no\\npescoço é 1%. Sendo \\ns\\n a proposição de que o paciente tem rigidez no pescoço e \\nm\\n a proposição de\\nque o paciente tem meningite, temos:\\nOu seja, esperamos que apenas um em 5.000 pacientes com rigidez no pescoço tenha meningite.\\nNote que, embora a rigidez no pescoço seja uma indicação bastante forte de meningite (com\\nprobabilidade 0,7), a probabilidade de o paciente estar acometido de meningite permanece pequena.\\nIsso ocorre porque a probabilidade \\na priori\\n sobre rigidez no pescoço é muito mais alta que a\\nprobabilidade \\na priori\\n sobre meningite.\\nA \\nSeção 13.3\\n ilustrou um processo pelo qual é possível evitar a avaliação da probabilidade da\\nevidência (aqui, \\nP\\n(\\ns\\n)), calculando-se em vez disso uma probabilidade posterior para cada valor da\\nvariável de consulta (nesse caso, \\nm\\n e ¬\\nm\\n) e depois normalizando-se os resultados. O mesmo\\nprocesso pode ser aplicado quando se utiliza a regra de Bayes. Temos:\\nP\\n(\\nM\\n | \\ns\\n) = a \\n〈\\nP\\n(\\ns\\n | \\nm\\n)\\nP\\n(\\nm\\n), \\nP\\n(\\ns\\n | \\n¬\\nm\\n)\\nP\\n(\\n¬\\nm\\n)\\n〉\\n.\\nDesse modo, para utilizar essa abordagem, precisamos fazer uma estimativa de \\nP\\n(\\ns\\n | ¬\\nm\\n) em vez\\nde \\nP\\n(\\ns\\n). Não existe almoço grátis — às vezes é mais fácil, às vezes mais difícil. A forma geral da\\nregra de Bayes com normalização é:\\nonde \\nα\\n é a constante de normalização necessária para fazer as entradas de \\nP\\n(\\nY\\n | \\nX\\n) terem soma igual a\\n1.\\n Uma pergunta óbvia sobre a regra de Bayes é por que a probabilidade condicional pode estar\\ndisponível em um sentido, mas não no outro. No domínio de meningite, talvez o médico saiba que a\\nrigidez no pescoço implica meningite em um entre 5.000 casos; isto é, o médico tem informações\\nquantitativas no sentido do \\ndiagnóstico\\n de sintomas para causas. Tal médico não tem necessidade de\\nusar a regra de Bayes. Infelizmente, \\no conhecimento do diagnóstico frequentemente é mais frágil\\nque o conhecimento causal\\n. Se houver uma súbita epidemia de meningite, a probabilidade', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 583}),\n",
       " Document(page_content='incondicional de meningite, \\nP\\n(\\nm\\n), crescerá. O médico que derivou a probabilidade de diagnóstico\\nP\\n(\\nm\\n | \\ns\\n) diretamente da observação estatística de pacientes antes da epidemia não terá ideia de como\\natualizar o valor, mas o médico que calcular \\nP\\n(\\nm\\n | \\ns\\n) a partir dos outros três valores verá que \\nP\\n(\\nm\\n |\\ns\\n) deve subir proporcionalmente com \\nP\\n(\\nm\\n). Mais importante ainda, as informações causais \\nP\\n(\\ns\\n | \\nm\\n)\\nnão são afetadas\\n pela epidemia porque simplesmente refletem o modo como a meningite atua. O uso\\ndessa espécie de conhecimento causal ou baseado em modelos fornece a robustez crucial necessária\\npara tornar os sistemas probabilísticos viáveis no mundo real.\\n13.5.2 Utilização da regra de Bayes: combinação de evidências\\nVimos que a regra de Bayes pode ser útil para responder a consultas probabilísticas\\ncondicionadas sobre uma única peça de evidência — por exemplo, a rigidez no pescoço. Em\\nparticular, argumentamos que as informações probabilísticas com frequência estão disponíveis sob a\\nforma \\nP\\n(\\nefeito\\n|\\ncausa\\n). O que acontece quando temos duas ou mais peças de evidência? Por exemplo,\\no que um dentista pode concluir se seu terrível boticão agarrar o dente dolorido de um paciente? Se\\nconhecermos a distribuição conjunta total (\\nFigura 13.3\\n), poderemos representar a resposta:\\nP\\n(\\nCárie\\n|\\ndordedente\\n \\n∧\\n \\nboticão\\n) = \\nα\\n \\n〈\\n0,108, 0,016\\n〉\\n ≈ \\n〈\\n0,871, 0,129\\n〉\\n.\\nPorém, sabemos que tal abordagem não poderá aumentar de escala até quantidades maiores de\\nvariáveis. Podemos tentar utilizar a regra de Bayes para reformular o problema:\\nPara essa reformulação funcionar, precisamos conhecer as probabilidades condicionais da\\nconjunção \\ndordedente\\n \\n∧\\n \\nboticão\\n para cada valor de \\nCárie\\n. Isso poderia ser viável para apenas duas\\nvariáveis de evidência, mas de novo não aumentará de escala. Se houvessem \\nn\\n variáveis de\\nevidência possíveis (raios X, dieta, higiene oral etc.), então haveria 2\\nn\\n combinações possíveis de\\nvalores observados para os quais precisaríamos conhecer probabilidades condicionais. Também\\npoderíamos voltar a usar a distribuição conjunta total. Isso foi o que primeiro afastou os\\npesquisadores da teoria da probabilidade, levando-os a estudar métodos aproximados para\\ncombinação de evidências que, embora forneçam respostas incorretas, exigem menor quantidade de\\nnúmeros para fornecer alguma resposta.\\nEm vez de seguir esse caminho, precisamos encontrar algumas asserções adicionais sobre o\\ndomínio que nos permitirão simplificar as expressões. A noção de \\nindependência\\n da \\nSeção 13.4\\nfornece uma pista, mas precisa de refinamento. Seria bom se \\nDorDeDente\\n e \\nBoticão\\n fossem\\nindependentes, mas não são: se a ferramenta agarrar o dente, isso significa que o dente tem uma cárie\\nque deve provocar uma dor de dente. No entanto, essas variáveis \\nsão\\n independentes, \\ndada a\\npresença ou a ausência de uma cárie\\n. Cada uma é diretamente causada pela cárie, mas nenhuma\\ndelas tem efeito direto sobre a outra: a dor de dente depende do estado dos nervos do dente, enquanto\\na precisão da ferramenta depende da habilidade do dentista, para o qual a dor de dente é irrelevante.\\n5\\nMatematicamente, essa propriedade é escrita como:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 584}),\n",
       " Document(page_content='Essa equação expressa a \\nindependência condicional\\n de \\ndordedente\\n e \\nboticão\\n dada \\nCárie\\n.\\nPodemos inseri-la na Equação 13.16 para obter a probabilidade de uma cárie:\\nAgora, os requisitos de informações são idênticos aos da inferência, utilizando cada item de\\nevidência separadamente: a probabilidade \\na priori\\n \\nP\\n(\\nCárie\\n) para a variável de consulta e a\\nprobabilidade condicional de cada efeito, dada sua causa.\\nA definição geral de \\nindependência condicional\\n de duas variáveis \\nX\\n e \\nY\\n, dada uma terceira\\nvariável \\nZ,\\n é:\\nP\\n(\\nX, Y | Z\\n) = \\nP\\n(\\nX | Z\\n)\\nP\\n(\\nY | Z\\n).\\nPor exemplo, no domínio de dentista, é razoável assumir a independência condicional das\\nvariáveis \\nDorDeDente\\n e \\nboticão\\n, dada \\nCárie\\n:\\nNote que essa asserção é um pouco mais forte que a Equação 13.17, que afirma a independência\\napenas para valores específicos de \\nDorDeDente\\n e \\nBoticão\\n. Como ocorre com a independência\\nabsoluta na Equação 13.11, as formas equivalentes\\nP\\n(\\nX | Y, Z\\n) = \\nP\\n(\\nX |Z\\n) e \\nP\\n(\\nY | X, Z\\n) = \\nP\\n(\\nY | Z\\n)\\ntambém podem ser usadas (veja o Exercício 13.17). A Seção 13.17 mostrou que as asserções de\\nindependência absoluta permitem uma decomposição da distribuição conjunta total em itens muito\\nmenores. Ocorre que o mesmo é verdadeiro para asserções de independência condicional. Por\\nexemplo, dada a Equação 13.19, podemos derivar uma decomposição como:\\nP\\n(\\nDorDeDente, Boticão\\n, \\nCárie\\n)\\n= \\nP\\n(\\nDorDeDente\\n, \\nBoticão\\n | \\nCárie\\n)\\nP\\n(\\nCárie\\n) (regra do produto)\\n= \\nP\\n(\\nDorDeDente\\n | \\nCárie\\n)\\nP\\n(\\nBoticão\\n | \\nCárie\\n)\\nP\\n(\\nCárie\\n) (usando 13.19).\\n (Na \\nFigura 13.3\\n, o leitor pode verificar que realmente essa equação é válida.) Desse modo, a\\ngrande tabela original é decomposta em três tabelas menores. A tabela original tem sete números\\nindependentes (2\\n3\\n = 8 entradas na tabela, mas elas devem somar 1, então 7 são independentes). As\\ntabelas menores contêm cinco números independentes (para distribuições de probabilidade\\ncondicional como o \\nP\\n(\\nT\\n | \\nC\\n), há duas linhas de dois números, e cada linha soma 1, de modo que são\\ndois números independentes; para uma distribuição \\na priori\\n, como \\nP\\n(\\nC\\n), há somente um número\\nindependente.) Ir de 7 até 5 pode não parecer um grande triunfo, mas a verdade é que, para \\nn\\nsintomas que são condicionalmente independentes dada \\nCárie\\n, o tamanho da representação cresce\\ncomo \\nO\\n(\\nn\\n) e não como \\nO\\n(2\\nn\\n). Isso significa que \\nas asserções de independência condicional podem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 585}),\n",
       " Document(page_content='permitir o aumento da escala de sistemas probabilísticos\\n; \\nalém disso\\n, \\nelas são muito mais comuns\\nque as asserções de independência absoluta\\n. Conceitualmente, \\nCárie\\n \\nsepara\\n \\nDorDeDente\\n e\\nBoticão\\n porque é uma causa direta de ambas. A decomposição de grandes domínios probabilísticos\\nem subconjuntos conectados livremente por meio de independência condicional é um dos\\ndesenvolvimentos mais importantes na história recente da IA.\\nO exemplo de odontologia ilustra um padrão que ocorre comumente, no qual uma única causa\\ninfluencia de maneira direta vários efeitos, todos condicionalmente independentes, dada a causa. A\\ndistribuição conjunta total pode ser escrita como:\\nTal distribuição de probabilidade é chamada modelo bayesiano \\ningênuo\\n — “ingênuo” porque é\\nusado com frequência (como uma hipótese simplificadora) em casos nos quais as variáveis “efeito”\\nnão\\n são na realidade condicionalmente independentes dada a variável causa. (Algumas vezes, o\\nmodelo de Bayes ingênuo é chamado \\nclassificador de Bayes\\n, um uso um tanto descuidado que levou\\nos verdadeiros seguidores de Bayes a denominá-lo modelo de \\nBayes idiota\\n.) Na prática, sistemas de\\nBayes ingênuos podem funcionar surpreendentemente bem, mesmo quando a hipótese de\\nindependência não é verdadeira. O Capítulo 20 descreve métodos para aprendizado de distribuições\\nde Bayes ingênuas a partir de observações.\\n13.6 DE VOLTA AO MUNDO DE WUMPUS\\nPodemos combinar muitas das ideias deste capítulo para resolver problemas de raciocínio\\nprobabilístico no mundo de wumpus (veja no Capítulo 7 uma descrição completa do mundo de\\nwumpus). A incerteza surge no mundo de wumpus porque os sensores do agente fornecem apenas\\ninformações parciais locais sobre o mundo. Por exemplo, a \\nFigura 13.5\\n mostra uma situação em que\\ncada um dos três quadrados acessíveis — [1,3], [2,2] e [3,1] — poderia conter um poço. A\\ninferência lógica pura não pode concluir nada sobre qual quadrado tem maior probabilidade de ser\\nseguro e, assim, um agente lógico poderia ser forçado a escolher ao acaso.\\nFigura 13.5\\n (a) Depois de encontrar uma brisa em[1,2] e [2,1], o agente está paralisado — não existe', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 586}),\n",
       " Document(page_content='lugar seguro para explorar. (b) Divisão dos quadrados em \\nConhecido\\n, \\nFranja\\n e \\nOutro\\n, para uma\\nconsulta sobre [1,3].\\nVeremos que um agente probabilístico pode fazer muito melhor que o agente lógico.\\nNosso objetivo será calcular a probabilidade de que cada um dos três quadrados contenha um\\npoço (para os propósitos deste exemplo, ignoraremos o wumpus e o ouro). As propriedades\\nrelevantes do mundo de wumpus são: (1) um poço causa brisas em todos os quadrados vizinhos e (2)\\ncada quadrado diferente de [1,1] contém um poço com probabilidade 0,2. O primeiro passo é\\nidentificar o conjunto de variáveis aleatórias de que necessitamos:\\n•  Como no caso da lógica proposicional, queremos usar uma variável booleana \\nP\\nij\\n para cada\\nquadrado, o que é verdadeiro se e somente se o quadrado [\\ni\\n, \\nj\\n] realmente contém um poço.\\n•  Também temos variáveis booleanas \\nB\\nij\\n que são verdadeiras se e somente se o quadrado [\\ni\\n, \\nj\\n] for\\narejado; incluímos essas variáveis apenas para os quadrados observados — nesse caso, [1,1],\\n[1,2] e [2,1].\\nO próximo passo é especificar a distribuição conjunta total, \\nP\\n(\\nP\\n1,1\\n,…, \\nP\\n4,4\\n, \\nB\\n1,1\\n, \\nB\\n1,2\\n, \\nB\\n2,1\\n).\\nAplicando a regra do produto, temos:\\nP\\n(\\nP\\n1,1\\n,…, \\nP\\n4,4\\n, \\nB\\n1,1\\n, \\nB\\n1,2\\n, \\nB\\n2,1\\n) =\\nP\\n(\\nB\\n1,1\\n, \\nB\\n1,2\\n, \\nB\\n2,1\\n |\\nP\\n1,1\\n,…, \\nP\\n4,4\\n) \\nP\\n(\\nP\\n1,1\\n,…, \\nP\\n4,4\\n).\\nEssa decomposição torna muito fácil ver quais devem ser os valores de probabilidade conjunta. O\\nprimeiro termo é a probabilidade condicional de uma configuração de brisa, dada uma configuração\\nde poço; seus valores são 1 se as brisas são adjacentes aos poços e 0 em caso contrário. O segundo\\ntermo é a probabilidade \\na priori\\n de uma configuração de poço. Cada quadrado contém um poço com\\nprobabilidade 0,2, independentemente dos outros quadrados; por conseguinte,\\nPara uma configuração com \\nn\\n poços, \\nP\\n(\\nP\\n1,1\\n,\\n…\\n,\\nP\\n4,4\\n) = 0,2\\nn\\n 0,81\\n6–\\nn\\n.\\nNa situação da \\nFigura 13.5\\n(a), a evidência consiste na brisa observada (ou em sua ausência) em\\ncada quadrado visitado, combinada com o fato de que cada quadrado não contém nenhum poço.\\nAbreviaremos esses fatos como \\nb\\n = ¬\\nb\\n1,1\\n \\n∧\\n \\nb\\n1,2\\n \\n∧\\n \\nb\\n2,1\\n e \\nconhecido\\n = ¬\\np\\n1\\n, 1 \\n∧\\n ¬\\np\\n1,2\\n \\n∧\\n ¬\\np\\n2, 1\\n.\\nEstamos interessados em responder a consultas tais como \\nP\\n(\\nP\\n1,3\\n |\\nconhecido\\n, \\nb\\n): qual é a\\nprobabilidade de que [1,3] contenha um poço, dadas as observações até agora?\\nPara responder a essa consulta, podemos seguir a abordagem-padrão da Equação 13.9, ou seja,\\nefetuar o somatório sobre todas as entradas da distribuição conjunta total. Seja \\nDesconhecido\\n uma\\nvariável composta que consiste nas \\nP\\ni,j\\n variáveis correspondentes a outros quadrados que não os\\nquadrados assinalados com \\nConhecido\\n e no quadrado de consulta [1,3]. Então, pela Equação 13.9,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 587}),\n",
       " Document(page_content='temos:\\nAs probabilidades conjuntas totais já foram especificadas e, portanto, terminamos — isto é, a não\\nser que estejamos preocupados com a computação. Existem 12 quadrados desconhecidos;\\nconsequentemente, o somatório contém 2\\n12\\n = 4.096 termos. Em geral, o somatório cresce\\nexponencialmente com o número de quadrados.\\nPoderíamos perguntar se os outros quadrados certamente não são irrelevantes. Como [4,4] afetaria\\no fato de [1,3] ter um poço? Na realidade, essa intuição está correta. Façamos a \\nFronteira\\n ser as\\nvariáveis (diferentes da variável de consulta) que são adjacentes a quadrados visitados, nesse caso\\napenas [2,2] e [3,1]. Além disso, sejam \\nOutro\\n as variáveis para os outros quadrados desconhecidos;\\nnesse caso, existem 10 outros quadrados, como mostra a \\nFigura 13.5\\n(b). A ideia-chave é que as\\nbrisas observadas são \\ncondicionalmente independentes\\n das outras variáveis, dados conhecido,\\nfronteira e variáveis de consulta. Para usar essa ideia, manipulamos a fórmula de consulta em uma\\nforma na qual as brisas são condicionadas sobre todas as outras variáveis e depois aplicamos a\\nindependência condicional:\\nonde a última etapa utiliza independência condicional: \\nb\\n é independente de \\noutro\\n dado \\nconhecido\\n,\\nP\\n1,3\\n, e \\nfronteira\\n. Agora, o primeiro termo nessa expressão não depende das outras variáveis; então\\npodemos mover o somatório para o interior:\\nPor independência, como na Equação 13.20, a expressão anterior pode ser fatorada e, portanto, é\\npossível reordenar os termos:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 588}),\n",
       " Document(page_content='onde o último passo incorpora \\nP\\n(\\nconhecido\\n) à constante de normalização e utiliza o fato de que \\nP\\n(\\noutro\\n) é igual a 1.\\nAgora, só existem quatro termos no somatório sobre as variáveis de franja \\nP\\n2,2\\n e \\nP\\n3,1\\n. O uso da\\nindependência e da independência condicional eliminou completamente de consideração os outros\\nquadrados.\\nObserve que a expressão \\nP\\n(\\nb\\n | \\ndesconhecido\\n, \\nP\\n1,3\\n, \\nfranja\\n) é igual a 1 quando a franja é consistente\\ncom as observações de brisa e é igual a 0 em caso contrário. Desse modo, para cada valor de \\nP\\n1,3\\n,\\nefetuamos o somatório sobre os \\nmodelos\\n lógicos para as variáveis de franja que são consistentes\\ncom os fatos conhecidos (compare com a enumeração sobre modelos ilustrada na \\nFigura 7.5\\n). Os\\nmodelos e suas probabilidades \\na priori\\n associadas — \\nP\\n(\\nfronteira\\n) — são mostrados na \\nFigura 13.6\\n.\\nTemos:\\nFigura 13.6\\n Modelos consistentes para as variáveis de fronteira \\nP\\n2,2\\n e \\nP\\n3,1\\n, mostrando P(fronteira)\\npara cada modelo: (a) três modelos com \\nP\\n1,3\\n = \\nverdadeiro\\n mostrando dois ou três poços e (b) dois\\nmodelos com \\nP\\n1,3\\n = \\nfalso\\n mostrando um ou dois poços.\\nP\\n(\\nP\\n1,3\\n | \\nconhecido\\n, \\nb\\n) = a′ \\n〈\\n0,2(0,04 + 0,16 + 0,16), 0,8(0,04 + 0,16)\\n〉\\n ≈ \\n〈\\n0,31, 0,69\\n〉\\n.\\nIsto é, [1,3] (e [3,1], por simetria) contém um poço com aproximadamente 31% de probabilidade.\\nUm cálculo semelhante, que o leitor talvez deseje realizar, mostra que [2,2] contém um poço com\\naproximadamente 86% de probabilidade. Definitivamente, o agente de wumpus deve evitar [2,2]!\\nObserve que o nosso agente lógico do Capítulo 7 não sabia que [2,2] era pior do que os outros\\nquadrados. A lógica pode nos informar que não se sabe se existe um poço em [2, 2], mas precisa da\\nprobabilidade para nos informar isso.\\nEsta seção mostrou que até mesmo problemas aparentemente complicados podem ser formulados\\ncom precisão em teoria da probabilidade e resolvidos com a utilização de algoritmos simples. Para\\nse obterem soluções \\neficientes\\n, os relacionamentos de independência e de independência', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 589}),\n",
       " Document(page_content='condicional podem ser empregados com a finalidade de simplificar os somatórios exigidos. Com\\nfrequência, esses relacionamentos correspondem à nossa compreensão natural de como o problema\\ndeve ser decomposto. No próximo capítulo, desenvolveremos representações formais para tais\\nrelações, bem como algoritmos que operam sobre essas representações para executar a inferência\\nprobabilística de modo eficiente.\\n13.7 RESUMO\\nEste capítulo sugeriu que a teoria da probabilidade é uma base adequada para o raciocínio incerto\\ne forneceu uma introdução suave à sua utilização.\\n•  A incerteza surge como consequência da preguiça e da ignorância. Ela é inevitável em mundos\\ncomplexos, dinâmicos ou inacessíveis.\\n•  As probabilidades expressam a inabilidade do agente para alcançar uma decisão definida com\\nrelação à verdade de uma sentença. As probabilidades resumem as crenças do agente relativas à\\nevidência.\\n•  A teoria da decisão combina as crenças do agente e desejos, definindo a melhor ação como a\\nque maximiza a utilidade esperada.\\n•  As declarações básicas de probabilidade incluem \\nprobabilidades\\n \\na priori\\n e \\nprobabilidades\\ncondicionais\\n sobre proposições simples e complexas.\\n•  Os axiomas da probabilidade restringem as atribuições possíveis de probabilidades a\\nproposições. Um agente que viola os axiomas deve se comportar irracionalmente em alguns\\ncasos.\\n•  A \\ndistribuição de probabilidade conjunta total\\n especifica a probabilidade de cada atribuição\\ncompleta de valores a variáveis aleatórias. Em geral, ela é grande demais para ser criada ou\\nutilizada em sua forma explícita, mas quando está disponível pode ser utilizada para responder a\\nconsultas simplesmente adicionando entradas para os mundos possíveis correspondentes às\\nproposições de consulta.\\n•  A \\nindependência absoluta\\n entre subconjuntos de variáveis aleatórias permitiu que a distribuição\\nconjunta total fosse fatorada em distribuições conjuntas menores, reduzindo a sua complexidade.\\nA independência absoluta raramente ocorre na prática.\\n•  A \\nregra de Bayes\\n permite que probabilidades desconhecidas sejam calculadas a partir de\\nprobabilidades condicionais conhecidas, em geral no sentido causal. Normalmente, a aplicação\\nda regra de Bayes com muitas peças de evidência resultará nos mesmos problemas de ampliação\\nda escala que encontramos na distribuição conjunta total.\\n•  A \\nindependência condicional\\n provocada por relacionamentos causais diretos no domínio\\npoderia permitir a fatoração da distribuição conjunta total em distribuições condicionais\\nmenores. O modelo de \\nBayes ingênuo\\n pressupõe a independência condicional de todas as\\nvariáveis de efeito, dada uma única variável de causa, e cresce de forma linear com o número de\\nefeitos.\\n•  Um agente de mundo de wumpus pode calcular probabilidades relativas a aspectos não\\nobservados do mundo, melhorando assim as decisões de um agente puramente lógico. A', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 590}),\n",
       " Document(page_content='independência condicional torna esses cálculos tratáveis.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nA teoria da probabilidade foi inventada como uma forma de analisar os jogos de azar. Em 850\\nd.C., o matemático indiano Mahaviracarya descreveu como organizar um conjunto de apostas para\\nnão perder (o que hoje chamamos de livro holandês). Na Europa, as primeiras análises sistemáticas\\nsignificativas foram produzidas por Girolamo Cardano, por volta de 1565, embora de publicação\\npóstuma (1663). Nessa época, a probabilidade foi estabelecida como disciplina matemática, devido\\na uma série de resultados estabelecidos em uma famosa correspondência entre Blaise Pascal e Pierre\\nde Fermat em 1654. Tal como acontece com a probabilidade em si, os resultados foram motivados\\ninicialmente por problemas de jogo (veja o Exercício 13.9). O primeiro livro publicado sobre a\\nprobabilidade foi \\nDe Ratiociniis in Ludo Aleae\\n (Huygens, 1657). A visão da incerteza “da preguiça\\ne da ignorância” foi descrita por John Arbuthnot no prefácio de sua tradução de Huygens (Arbuthnot,\\n1692): “É impossível para um dado, com força e direção determinada, não cair de um lado\\ndeterminado, só não conheço a força e a direção que o faz cair de tal lado e, portanto, eu chamo isso\\nacaso, que nada mais é do que a falta de arte…”\\nLaplace (1816) forneceu uma visão geral excepcionalmente precisa e moderna de probabilidade,\\nsendo o primeiro a utilizar o exemplo “tomar duas urnas, A e B, a primeira contendo quatro bolas\\nbrancas e duas bolas pretas…” O reverendo Thomas Bayes (1702-1761) introduziu a regra de\\nraciocínio sobre probabilidades condicionais que foi denominada em homenagem a Bayes (1763).\\nBayes considerou apenas o caso uniforme, \\na priori\\n, e foi Laplace quem desenvolveu\\nindependentemente o caso geral. Kolmogorov (1950, publicado pela primeira vez em alemão em\\n1933) apresentou pela primeira vez a teoria da probabilidade em um quadro rigorosamente\\naxiomático. Rényi (1970), mais tarde, forneceu uma apresentação axiomática que considerou a\\nprobabilidade condicional, em vez da probabilidade absoluta, como primitiva.\\nPascal utilizou a probabilidade de formas que exigiam tanto a interpretação objetiva como uma\\npropriedade do mundo baseada em simetria ou frequência relativa, quanto à interpretação subjetiva,\\nbaseada no grau de crença — a primeira em suas análises de probabilidades em jogos de azar, e a\\noutra no famoso argumento “aposta de Pascal” sobre a possível existência de Deus. Porém, Pascal\\nnão percebeu claramente a distinção entre essas duas interpretações. A distinção foi primeiro\\npercebida de maneira clara por James Bernoulli (1654-1705).\\nLeibniz introduziu a noção “clássica” de probabilidade como uma proporção de casos enumerados\\nigualmente prováveis, que também foi utilizada por Bernoulli, embora tenha alcançado proeminência\\ngraças a Laplace (1749-1827). Essa noção é ambígua entre a interpretação de frequência e a\\ninterpretação subjetiva. Os casos podem ser considerados igualmente prováveis devido a uma\\nsimetria física natural entre eles ou simplesmente porque não temos qualquer conhecimento que nos\\nleve a considerar um deles mais provável que o outro. O uso desta última consideração subjetiva\\npara justificar a atribuição de probabilidades iguais é conhecido como \\nprincípio da indiferença\\n. O\\nprincípio é frequentemente atribuído a Laplace, mas ele nunca o isolou explicitamente. George Boole\\ne John Venn referiram-se a ele como \\nprincípio da insuficiência da razão\\n; o nome moderno deve-se a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 591}),\n",
       " Document(page_content='Keynes (1921).\\nO debate entre objetivistas e subjetivistas se tornou mais acirrado no século XX. Kolmogorov\\n(1963), R. A. Fisher (1922) e Richard von Mises (1928) defenderam a interpretação de frequência\\nrelativa. A interpretação de “propensão” de Karl Popper (1959, publicada primeiro em alemão em\\n1934) segue as frequências relativas até uma simetria física subjacente. Frank Ramsey (1931), Bruno\\nde Finetti (1937), R. T. Cox (1946), Leonard Savage (1954), Richard Jeffrey (1983) e E. T. Jaynes\\n(2003) interpretaram as probabilidades como graus de crença de indivíduos específicos. Suas\\nanálises de grau de crença estavam intimamente ligadas a utilidades e a comportamento —\\nespecificamente, à disposição para apostar. Rudolf Carnap, seguindo o trabalho de Leibniz e\\nLaplace, ofereceu uma espécie diferente de interpretação subjetiva da probabilidade — não como o\\ngrau de crença de qualquer indivíduo real, mas como o grau de crença que um indivíduo \\nidealizado\\ndeve ter em determinada proposição \\na\\n, dado um corpo de evidências específico \\ne\\n. Carnap tentou ir\\nalém de Leibniz ou Laplace, tornando essa noção de grau de \\nconfirmação\\n matematicamente precisa,\\ncomo uma relação lógica entre \\na\\n e \\ne\\n. O estudo dessa relação foi planejado para constituir uma\\ndisciplina matemática chamada \\nlógica indutiva\\n, análoga à lógica dedutiva comum (Carnap, 1948,\\n1950). Carnap não foi capaz de estender sua lógica indutiva muito além do caso proposicional, e\\nPutnam (1963) mostrou que algumas dificuldades fundamentais impediriam uma extensão rígida a\\nlinguagens capazes de expressar a aritmética.\\nO teorema de Cox (1946) mostra que qualquer sistema de raciocínio incerto que atenda seu\\nconjunto de hipóteses é equivalente à teoria da probabilidade. Isso deu confiança renovada aos que\\njá favoreciam a probabilidade, mas outros não estavam convencidos, apontando para os pressupostos\\n(principalmente que a crença deve ser representada por um único número e, portanto, a crença em ¬\\np\\ndeve ser uma função da crença em \\np\\n). Halpern (1999) descreveu as premissas e mostrou algumas\\nlacunas na formulação original de Cox. Horn (2003) mostrou como remediar as dificuldades. Jaynes\\n(2003) tinha um argumento semelhante que é mais fácil de ler.\\nA questão de classes de referência está estreitamente ligada à tentativa de descobrir uma lógica\\nindutiva. A abordagem de escolher a classe de referência “mais específica” de tamanho suficiente foi\\nproposta formalmente por Reichenbach (1949). Várias tentativas foram feitas, notavelmente por\\nHenry Kyburg (1977, 1983), para formular normas mais sofisticadas com a finalidade de evitar\\nalgumas falácias óbvias que surgem com a regra de Reichenbach, mas tais abordagens permanecem\\num tanto \\nad hoc\\n. O trabalho mais recente de Bacchus, Grove, Halpern e Koller (1992) estende os\\nmétodos de Carnap às teorias de primeira ordem, evitando assim muitas das dificuldades associadas\\ncom o método direto de classe de referência. Kyburg e Teng (2006) contrastaram a inferência\\nprobabilística com a lógica não monotônica.\\nO raciocínio probabilístico de Bayes foi usado em IA desde a década de 1960, especialmente em\\ndiagnóstico médico. Ele foi empregado não apenas para fazer um diagnóstico a partir da evidência\\ndisponível, mas também para selecionar questões e testes adicionais utilizando a teoria do valor da\\ninformação (\\nSeção 16.6\\n) quando a evidência disponível era inconclusiva (Gorry, 1968; Gorry \\net al.\\n,\\n1973). Um sistema superou os especialistas humanos no diagnóstico de enfermidades abdominais\\nagudas (Dombal \\net al.\\n, 1974). Lucas \\net al.\\n (2004) apresentou um panorama. Entretanto, esses\\nprimeiros sistemas de Bayes se ressentiam de diversos problemas. Pelo fato de não terem qualquer\\nmodelo teórico das condições em que estavam efetuando os diagnósticos, eles eram vulneráveis a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 592}),\n",
       " Document(page_content='dados não representativos que ocorrem em situações nas quais somente uma pequena amostra estava\\ndisponível (Dombal \\net al.\\n, 1981). Um problema ainda mais fundamental surgiu porque lhes faltavam\\num formalismo conciso (como o que descrevemos no Capítulo 14) para representar e utilizar\\ninformações de independência condicional e, por essa razão, eles dependiam da aquisição, do\\narmazenamento e do processamento de enormes tabelas de dados probabilísticos. Devido a essas\\ndificuldades, os métodos probabilísticos para lidar com a incerteza foram os preferidos em IA, desde\\na década de 1970 até a metade da década de 1980. Os desenvolvimentos ocorridos no final dos anos\\n1980 serão descritos no próximo capítulo.\\nO modelo de Bayes ingênuo para distribuições conjuntas foi extensivamente estudado na literatura\\nde reconhecimento de padrões desde a década de 1950 (Duda e Hart, 1973). Também foi utlizado,\\nmuitas vezes de forma inconsciente, na recuperação de informação, começando com o trabalho de\\nMaron (1961). Os fundamentos probabilísticos dessa técnica, descrita mais adiante no Exercício\\n13.22, foram elucidados por Robertson e Sparck Jones (1976). Domingos e Pazzani (1997)\\napresentam uma explicação para o surpreendente sucesso do raciocínio de Bayes ingênuo, até mesmo\\nem domínios nos quais as hipóteses de independência são claramente violadas.\\nExistem muitos livros didáticos introdutórios de boa qualidade sobre teoria da probabilidade,\\ninclusive os de Bertsekas e Tsitsiklis (2008) e Grinstead e Snell (1997). DeGroot e Schervish (2001)\\noferece uma introdução combinada à probabilidade e à estatística de um ponto de vista bayesiano. O\\nlivro didático de Richard Hamming (1991) fornece uma introdução matematicamente sofisticada à\\nteoria da probabilidade, sob o ponto de vista de uma interpretação de propensão baseada na simetria\\nfísica. Hacking (1975) e Hald (1990) focalizam a história inicial do conceito de probabilidade.\\nBernstein (1996) apresenta uma interessante história popular sobre o risco.\\nEXERCÍCIOS\\n13.1\\n Mostre, a partir de princípios básicos, que \\nP\\n(\\na\\n | \\nb\\n \\n∧\\n \\na\\n) = 1.\\n13.2\\n Usando os axiomas de probabilidade, prove que qualquer distribuição de probabilidade sobre\\numa variável aleatória discreta deve ter a soma 1.\\n13.3\\n Para cada uma das seguintes afirmações, prove que é verdade ou dê um contraexemplo.\\na\\n. Se \\nP\\n(\\na\\n | \\nb\\n, \\nc\\n) = \\nP\\n(\\nb\\n | \\na\\n, \\nc\\n), então \\nP\\n(\\na\\n | \\nc\\n) = \\nP\\n(\\nb\\n | \\nc\\n)\\nb\\n. Se \\nP\\n(\\na\\n | \\nb\\n, \\nc\\n) = \\nP\\n(\\na\\n), então \\nP\\n(\\nb\\n | \\nc\\n) = \\nP\\n(\\nb\\n)\\nc\\n. Se \\nP\\n(\\na\\n | \\nb\\n) = \\nP\\n(\\na\\n), então \\nP\\n(\\na\\n | \\nb\\n, \\nc\\n) = \\nP\\n(\\na\\n | \\nc\\n)\\n13.4\\n Seria racional para um agente conter as três crenças \\nP\\n(\\nA\\n) = 0,4, \\nP\\n(\\nB\\n) = 0,3 e \\nP\\n(\\nA\\n \\n∨\\n \\nB\\n) = 0,5?\\nNesse caso, que intervalo de probabilidades seria racional o agente conter para \\nA\\n \\n∧\\n \\nB\\n? Componha\\numa tabela semelhante à da \\nFigura 13.2\\n e mostre como ela apoia seu argumento sobre a\\nracionalidade. Em seguida, elabore outra versão da tabela, onde \\nP\\n(\\nA\\n \\n∨\\n \\nB\\n) = 0,7. Explique por que é\\nracional ter essa probabilidade, embora a tabela mostre um caso de perda e três que simplesmente\\nindicam equilíbrio. (\\nSugestão\\n: Qual é o compromisso do Agente 1 com a probabilidade de cada um\\ndos quatro casos, em especial com o caso que representa uma perda?)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 593}),\n",
       " Document(page_content='13.5\\n Esta questão lida com as propriedades dos mundos possíveis, definida como atribuições para\\ntodas as variáveis aleatórias. Vamos trabalhar com proposições que correspondam a exatamente um\\nmundo possível porque ela compromete as atribuições de todas as variáveis. Em teoria da\\nprobabilidade, tais proposições são chamados de \\neventos atômicos\\n. Por exemplo, com as variáveis\\nbooleanas \\nX\\n1\\n, \\nX\\n2\\n, \\nX\\n3\\n, a proposição \\nx\\n1\\n \\n∧\\n¬\\nx\\n2\\n \\n∧\\n¬\\nx\\n3\\n fixa a atribuição das variáveis; na linguagem da\\nlógica proposicional, diríamos que ela tem exatamente um modelo.\\na.\\n Prove, para o caso de \\nn\\n variáveis booleanas, que quaisquer dois eventos distintos atômicos são\\nmutuamente exclusivos, ou seja, sua conjunção é equivalente a \\nfalso\\n.\\nb\\n. Prove que a disjunção de todos os eventos atômicos possíveis é logicamente equivalente a\\nverdadeiro\\n.\\nc.\\n Prove que qualquer proposição é logicamente equivalente à disjunção dos eventos atômicos que\\nimpõem sua verdade.\\n13.6\\n Prove a Equação 13.4 pelas Equações 13.1 e 13.2.\\n13.7\\n Considere o conjunto de cinco cartas possíveis da mão do jogo de pôquer tratadas de forma\\nhonesta de um baralho-padrão de 52 cartas.\\na.\\n Quantos eventos atômicos existem na distribuição de probabilidade conjunta (isto é, quantas\\nmãos de cinco cartas existem)?\\nb.\\n Qual é a probabilidade de cada evento atômico?\\nc.\\n Qual é a probabilidade de ser distribuído um \\nroyal straight flush\\n? E quatro cartas de um mesmo\\nnaipe?\\n13.8\\n Dada a distribuição conjunta total mostrada na \\nFigura 13.3\\n, calcule:\\na. P\\n(\\ndordedente.\\n)\\nb. P\\n(\\nCárie\\n).\\nc. P\\n(\\nDorDeDente\\n | \\ncárie\\n).\\nd. P\\n(\\nCárie\\n | \\ndordedente\\n \\n∨\\n \\nBoticão\\n).\\n13.9\\n Em sua carta de 24 de agosto de 1654, Pascal estava tentando mostrar como um pote de dinheiro\\ndeveria ser distribuído quando um jogo de apostas terminasse prematuramente. Imagine um jogo que\\nconsista no lançamento de um dado de cada vez, o jogador \\nE\\n ganha um ponto quando o dado for par,\\ne o jogador \\nO\\n ganha um ponto quando o dado for ímpar. O primeiro jogador a receber sete pontos\\nganha o pote. Suponha que o jogo tenha sido interrompido quando estava 4 × 2 para \\nE\\n. Como o\\ndinheiro deverá ser dividido de forma justa nesse caso? Qual é a fórmula geral? (Fermat e Pascal\\ncometeram vários erros antes de resolver o problema, mas você deverá ser capaz de acertar na\\nprimeira vez.)\\n13.10\\n Ao decidir colocar nosso conhecimento de probabilidade para bom uso, deparamo-nos com\\numa máquina caça-níqueis com três bobinas girando de forma independente, cada uma produzindo um\\ndos quatro símbolos, BAR, SINO, LIMÃO ou CEREJA com igual probabilidade. A máquina caça-\\nníqueis tem o seguinte esquema de pagamento para aposta com uma moeda (onde “?” indica que não\\ninteressa o que aparece naquela bobina):', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 594}),\n",
       " Document(page_content='BAR/ BAR/BAR paga 20 moedas\\nSINO/SINO/SINO paga 15 moedas\\nLIMÃO/LIMÃO/LIMÃO paga 5 moedas\\nCEREJA/CEREJA/CEREJA paga 3 moedas\\nCEREJA/CEREJA/? paga 2 moedas\\nCEREJA/? /? paga 1 moeda\\na.\\n Calcule a porcentagem de “recuperação de investimento” esperado pela máquina. Em outras\\npalavras, para cada moeda jogada, qual o retorno de moeda esperado?\\nb.\\n Calcule a probabilidade de uma única jogada na máquina caça-níqueis resultar em vitória.\\nc.\\n Estime o número de jogadas média e mediana que você pode esperar fazer até quebrar, se\\ncomeçar com oito moedas. Você pode executar uma simulação para estimar isso, em vez de\\ntentar calcular a resposta exata.\\n13.11\\n Desejamos transmitir uma mensagem de \\nn\\n bits para um agente receptor. Os bits da mensagem\\npodem ser corrompidos (invertidos) independentemente durante a transmissão, com \\n∊\\n probabilidade\\ncada. Com um bit de paridade extra enviado junto com a informação original, uma mensagem pode\\nser corrigida pelo receptor se, no máximo, um bit na mensagem inteira (incluindo o bit de paridade)\\nfoi corrompido. Suponha que queiramos garantir que a mensagem correta seja recebida com\\nprobabilidade pelo menos 1 − \\nδ\\n. Qual o valor máximo possível de \\nn\\n? Calcule esse valor para o caso\\n∊\\n = 0,002, \\nδ\\n = 0,01.\\n13.12\\n Mostre que as três formas de independência na Equação 13.11 são equivalentes.\\n13.13\\n Considere dois testes médicos, A e B, de um vírus. O teste A tem 95% de chance de\\nreconhecer o vírus quando estiver presente, mas tem uma proporção de 10% de falso positivo\\n(indicando que o vírus está presente quando não está). O teste B é 90% eficaz em reconhecer o vírus,\\nmas tem uma proporção de 5% de falso positivo. Os dois testes utilizam métodos independentes de\\nidentificação do vírus. Um por cento de todas as pessoas são portadoras do vírus. Digamos que\\nutilizemos em uma pessoa apenas um dos testes para detectar o vírus e que o teste resulte positivo\\npara portadores do vírus. Qual dos dois testes, retornando positivo, é mais indicativo de que alguém\\nseja realmente portador do vírus? Justifique sua resposta matematicamente.\\n13.14\\n Suponha que seja dada uma moeda com a probabilidade \\nx\\n de dar cara e a probabilidade 1− \\nx\\nde dar coroa. Os resultados dos arremessos sucessivos da moeda são independentes um do outro se\\nvocê conhecer o valor de \\nx\\n? Os resultados dos arremessos sucessivos da moeda são independentes\\num do outro se você não conhecer o valor de \\nx\\n? Justifique sua resposta.\\n13.15\\n Depois de seu \\ncheckup\\n anual, o médico tem notícias boas e ruins. As notícias ruins são que\\nvocê teve um resultado positivo no exame referente a uma doença séria e que o exame é 99% preciso\\n(isto é, a probabilidade de o exame ser positivo quando você tem a doença é 0,99, pois essa é a\\nprobabilidade de resultado negativo no exame quando você não tem a doença). A boa notícia é que\\nessa é uma doença rara, atingindo apenas uma em 10.000 pessoas da sua idade. Por que é uma boa\\nnotícia o fato de a doença ser rara? Quais são suas chances de ter realmente a doença?\\n13.16\\n Com muita frequência, é útil considerar o efeito de algumas proposições específicas no', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 595}),\n",
       " Document(page_content='contexto de alguma evidência prática geral que permanece fixa, em vez de considerá-lo na ausência\\ncompleta de informações. As perguntas a seguir lhe pedem para provar versões mais gerais da regra\\ndo produto e da regra de Bayes, em relação a alguma evidência prática \\ne\\n:\\na.\\n Prove a versão condicionalizada da regra do produto geral:\\nP\\n(\\nX\\n, \\nY\\n | \\ne\\n) = \\nP\\n(\\nX\\n | \\nY\\n, \\ne\\n)\\nP\\n (\\nY\\n | \\ne\\n).\\nb.\\n Prove a versão condicionalizada da regra de Bayes na Equação 13.13.\\n13.17\\n Mostre que a declaração de independência condicional\\nP\\n(\\nX\\n, \\nY\\n | \\nZ\\n) = \\nP\\n(\\nX\\n | \\nZ\\n)\\nP\\n(\\nY\\n | \\nZ\\n)\\né equivalente a qualquer das duas declarações\\nP\\n(\\nX\\n | \\nY,Z\\n) = \\nP\\n(\\nX\\n |\\nZ\\n) e \\nP\\n(\\nB\\n | \\nX,Z\\n) = \\nP\\n(\\nY\\n | \\nZ\\n).\\n13.18\\n Suponha que você receba uma sacola com \\nn\\n moedas imparciais. Das moedas, n – 1 são\\nnormais, com cara de um lado e coroa de outro, enquanto que uma delas é falsa, com cara em ambos\\nos lados.\\na.\\n Suponha que você tire de dentro da sacola uma moeda aleatoriamente, arremesse e apareça\\ncara. Qual a probabilidade (condicional) que a moeda escolhida seja a falsa?\\nb.\\n Suponha que você continue a arremessar a moeda \\nK\\n vezes após apanhá-la e aparece \\nk\\n caras.\\nQual é agora a probabilidade condicional de pegar uma moeda falsa?\\nc.\\n Suponha que você gostaria de decidir se a moeda escolhida era a falsa ao arremessa-la \\nk\\n vezes.\\nO procedimento de decisão retorna \\nfalso\\n se todos os \\nk\\n arremessos apresentam caras; de outra\\nforma retorna \\nnormal\\n. Qual é a probabilidade (incondicional) que esse procedimento tenha um\\nerro?\\n13.19\\n Neste exercício, você completará o cálculo de normalização para o exemplo da meningite.\\nPrimeiro, componha um valor apropriado para \\nP\\n(\\ns\\n|¬\\nm\\n) e use esse valor para calcular valores não\\nnormalizados para \\nP\\n(\\nm\\n|\\ns\\n) e \\nP\\n(¬\\nm\\n|\\ns\\n) [isto é, ignorando o termo \\nP\\n(\\ns\\n) na expressão da regra de Bayes\\n(equação 13.14)]. Depois disso, normalize esses valores de forma que eles totalizem 1.\\n13.20\\n Sejam \\nX\\n, \\nY\\n, \\nZ\\n variáveis booleanas aleatórias. Identifique as oito entradas na distribuição\\nconjunta \\nP\\n(\\nX\\n, \\nY\\n, \\nZ\\n) com as letras de \\na\\n até \\nh\\n. Expresse, sob a forma de um conjunto de equações\\nrelacionadas às entradas de \\na\\n até \\nh\\n, a declaração de que \\nX\\n e \\nY\\n são condicionalmente independentes,\\ndada a variável \\nZ\\n. Quantas equações \\nnão redundantes\\n existem nesse conjunto?\\n13.21\\n (Adaptado de Pearl (1988).) Suponha que você seja testemunha de um acidente noturno\\nseguido de fuga envolvendo um taxi em Atenas. Todos os taxis em Atenas são azuis ou cinza. Você\\njura de pés juntos que o taxi era azul. Testes extensivos mostram que, em condição de luz fraca, a\\ndistinção entre cinza e azul é 75% confiável.\\na.\\n É possível calcular a cor mais provável do taxi?(\\nDica\\n: mostre cuidadosamente a diferença entre\\na proposição que o taxi seja azul e a proposição que \\npareça\\n azul.)\\nb.\\n E se você soubesse que 9 entre 10 taxis em Atenas são verdes?\\n13.22\\n Categorizar um texto é a tarefa de atribuir a determinado documento uma categoria de um\\nconjunto fixo de categorias, com base no texto que o documento contém. Os modelos de Bayes', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 596}),\n",
       " Document(page_content='ingênuos são empregados com frequência para essa tarefa. Nesses modelos, a variável de consulta é\\na categoria do documento, e as variáveis de “efeito” são a presença ou ausência de cada palavra na\\nlinguagem; a suposição é que as palavras ocorrem independentemente nos documentos, com suas\\nrespectivas frequências determinadas pela categoria de cada documento.\\na.\\n Explique precisamente como tal modelo pode ser construído, sendo fornecido para servir como\\n“dados de treinamento” um conjunto de documentos que foram atribuídos a categorias.\\nb.\\n Explique precisamente como categorizar um novo documento.\\nc.\\n A suposição de independência é razoável? Explique.\\n13.23\\n Em nossa análise do mundo de wumpus, usamos o fato de que cada quadrado contém um poço\\ncom probabilidade 0,2, independentemente do conteúdo dos outros quadrados. Suponha que, em vez\\ndisso, exatamente \\nN\\n/5 poços estejam uniformemente espalhados ao acaso entre os \\nN\\n quadrados\\ndiferentes de [1,1]. As variáveis \\nP\\ni,j\\n e \\nP\\nk,l\\n ainda serão independentes? Qual será agora a distribuição\\nconjunta \\nP\\n(\\nP\\n1,1\\n, …, \\nP\\n4,4\\n)? Efetue novamente os cálculos para as probabilidades de poços em [1,3] e\\n[2,2].\\n13.24\\n Refaça o cálculo da probabilidade dos poços em [1,3] e [2,2] assumindo que cada quadrado\\ncontém um poço com probabilidade 0,01, independente dos outros quadrados. O que você pode dizer\\nsobre o desempenho relativo de uma lógica \\nversus\\n um agente probabilístico nesse caso?\\n13.25\\n Implemente um agente probabilístico híbrido para o mundo de wumpus, baseado no\\nagente híbrido da \\nFigura 7.20\\n e no procedimento de inferência probabilística descrito neste capítulo.\\n1\\n Por ora, assumiremos um conjunto de mundos discreto, contável. O tratamento adequado do caso contínuo traz certas complicações\\nque são menos relevantes para a maioria dos propósitos em IA.\\n2\\n As dificuldades incluem o \\nconjunto de Vitali\\n, um conjunto bem definido do intervalo [0, 1] sem tamanho bem definido.\\n3\\n Pode-se argumentar que as preferências do agente por balanços financeiros diferentes são tais que a possibilidade de perder $1 não é\\ncontrabalançada pela igual possibilidade de ganhar $1. Uma resposta possível é fazer com que o valor das apostas diminua o suficiente\\npara evitar esse problema. A análise de Savage (1954) contorna o problema completamente.\\n4\\n Assim chamada devido a uma prática comum entre as companhias de seguros de escrever as somas das frequências observadas nas\\nmargens de tabelas de seguros.\\n5\\n Supomos que o paciente e o dentista sejam indivíduos distintos.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 597}),\n",
       " Document(page_content='O\\nCAPÍTULO\\n \\n14\\nRaciocínio probabilístico\\nEm que explicamos como construir modelos de redes para raciocinar sob a\\nincerteza, de acordo com as leis de teoria da probabilidade.\\nCapítulo 13 apresentou os elementos básicos da teoria da probabilidade e observou a\\nimportância dos relacionamentos de independência e de independência condicional na\\nsimplificação de representações probabilísticas do mundo. Este capítulo introduz um modo\\nsistemático de representar explicitamente tais relacionamentos, sob a forma de \\nredes bayesianas\\n.\\nDefinimos a sintaxe e a semântica dessas redes e mostramos como elas podem ser usadas para captar\\no conhecimento incerto de modo natural e eficiente. Em seguida, mostramos como a inferência\\nprobabilística, embora computacionalmente intratável no pior caso, pode ser realizada de maneira\\neficiente em muitas situações práticas. Também descrevemos uma variedade de algoritmos de\\ninferência aproximados, frequentemente aplicáveis quando a inferência exata é inviável. Exploramos\\nmodos de aplicar a teoria da probabilidade a mundos com objetos e relações, isto é, a\\nrepresentações de primeira ordem\\n, em vez de \\nproposicionais\\n. Por fim, estudamos abordagens\\nalternativas para o raciocínio incerto.\\n14.1 REPRESENTAÇÃO DO CONHECIMENTO EM UM DOMÍNIO\\nINCERTO\\nNo Capítulo 13, vimos que a distribuição de probabilidade conjunta total pode responder a\\nqualquer pergunta sobre o domínio, mas pode se tornar intratavelmente grande, à medida que o\\nnúmero de variáveis cresce. Além disso, especificar probabilidades para mundos possíveis, uma por\\numa, é antinatural e tedioso.\\nTambém vimos que os relacionamentos de independência e de independência condicional entre\\nvariáveis pode reduzir bastante o número de probabilidades que precisam ser especificadas, a fim de\\ndefinir a distribuição conjunta total. Esta seção introduz uma estrutura de dados chamada \\nrede\\nbayesiana\\n1\\n para representar as dependências entre variáveis. As redes bayesianas podem\\nrepresentar essencialmente qualquer distribuição de probabilidade conjunta completa e, em muitos\\ncasos, muito concisamente.\\nUma rede bayesiana é um grafo orientado em que cada \\nnó\\n é identificado com informações de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 599}),\n",
       " Document(page_content='probabilidade quantitativa. A especificação completa é dada a seguir:\\n1. Cada nó corresponde a uma variável aleatória, que pode ser discreta ou contínua.\\n2. Um conjunto de vínculos orientados ou setas conecta pares de nós. Se houver uma seta do nó \\nX\\naté o nó \\nY\\n, \\nX\\n será denominado \\npai\\n de \\nY\\n. O grafo não tem ciclos orientados (e, portanto, é um\\ngrafo acíclico orientado, ou GAO).\\n3. Cada nó \\nX\\ni\\n tem uma distribuição de probabilidade condicional \\nP\\n(\\nX\\ni\\n | \\nPais\\n(\\nX\\ni\\n)) que quantifica o\\nefeito dos pais sobre o nó.\\nA topologia da rede — o conjunto de nós e vínculos — especifica os relacionamentos de\\nindependência condicional que são válidos no domínio, de um modo que se tornará claro em breve.\\nO significado \\nintuitivo\\n de uma seta tipicamente é que \\nX\\n tem \\ninfluência direta\\n sobre \\nY\\n, o que sugere\\nque as causas devem ser pais dos efeitos. Normalmente é fácil para um especialista em domínios\\ndescobrir quais são as influências diretas existentes no domínio — na verdade, é muito mais fácil do\\nque realmente especificar as probabilidades em si. Uma vez que a topologia da rede bayesiana é\\ndefinida, só precisamos especificar uma distribuição de probabilidade condicional para cada\\nvariável, dados seus pais. Veremos que a combinação da topologia com as distribuições\\ncondicionais basta para especificar (de forma implícita) a distribuição conjunta total para todas as\\nvariáveis.\\nLembre-se do mundo simples descrito no Capítulo 13, que consiste nas variáveis \\nDorDeDente\\n,\\nCárie\\n, \\nBoticão\\n e \\nTempo\\n. Argumentamos que \\nTempo\\n é independente das outras variáveis; além disso,\\nobservamos que \\nDorDeDente\\n e \\nBoticão\\n são condicionalmente independentes, dada \\nCárie\\n. Esses\\nrelacionamentos são representados pela estrutura de rede bayesiana mostrada na \\nFigura 14.1\\n.\\nFormalmente, a independência condicional de \\nDorDeDente\\n e \\nBoticão\\n dada \\nCárie\\n é a \\nausência\\n de\\num vínculo entre \\nDorDeDente\\n e \\nBoticão\\n. Intuitivamente, a rede representa o fato de que \\nCárie\\n é uma\\ncausa direta de \\nDorDeDente\\n e \\nBoticão\\n, enquanto não existe nenhum relacionamento causal direto\\nentre \\nDorDeDente\\n e \\nBoticão\\n.\\nFigura 14.1\\n Uma rede bayesiana simples, na qual \\nTempo\\n é independente das outras três variáveis, e\\nDorDeDente\\n e \\nBoticão\\n são condicionalmente independentes, dada \\nCárie\\n.\\nAgora considere o exemplo a seguir, que é apenas um pouco mais complexo. Você tem um novo\\nalarme contra assaltantes instalado em sua casa. Ele é bastante confiável na detecção de um roubo,\\nmas também responde ocasionalmente a pequenos terremotos. (Esse exemplo se deve a Judea Pearl,\\nresidente em Los Angeles — daí o interesse em terremotos.) Você também tem dois vizinhos, João e\\nMaria, que prometeram chamá-lo no trabalho quando ouvirem o alarme. João quase sempre chama\\nquando ouve o alarme, mas às vezes confunde o toque do telefone com o alarme e também liga ao', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 600}),\n",
       " Document(page_content='ouvi-lo. Por outro lado, Maria gosta de ouvir música em alto volume e frequentemente esquece\\ncompletamente o alarme. Dada a evidência de quem telefonou ou não telefonou, gostaríamos de\\nestimar a probabilidade de um roubo.\\nA rede bayesiana para esse domínio é dada na \\nFigura 14.2\\n. A estrutura da rede mostra que o roubo\\ne os terremotos afetam diretamente a probabilidade de o alarme disparar se o telefonema de João e\\nMaria depender apenas do alarme. A rede representa, portanto, nossas suposições de que eles não\\npercebem roubos diretamente, não notam pequenos terremotos e não conferem antes de telefonar.\\nFigura 14.2\\n Uma rede bayesiana típica, mostrando a topologia e também as tabelas de probabilidade\\ncondicional (TPCs). Nas TPCs, as letras \\nR\\n, \\nT\\n, \\nA\\n, \\nJ\\n e \\nM\\n representam \\nRoubo\\n, \\nTerremoto\\n, \\nAlarme\\n,\\nJoãoLiga\\n e \\nMariaLiga\\n, respectivamente.\\nAs distribuições condicionais na \\nFigura 14.2\\n são mostradas como uma \\ntabela de probabilidade\\ncondicional\\n, ou TPC (essa forma de tabela pode ser usada para variáveis discretas; outras\\nrepresentações incluem as adequadas às variáveis contínuas, descritas na \\nSeção 14.2\\n). Cada linha da\\nTPC contém a probabilidade condicional de cada valor do nó para um \\ncaso de condicionamento\\n.\\nUm caso de condicionamento é apenas uma combinação possível de valores para os nós pai — uma\\nminiatura do mundo possível. Cada linha deve somar 1 porque as entradas representam um conjunto\\nexaustivo de casos da variável. Para as variáveis booleanas, uma vez que se sabe que a\\nprobabilidade de um valor verdadeiro seja \\np\\n, a probabilidade de falso deve ser 1 −\\np\\n; assim, muitas\\nvezes omitimos o segundo número, como na \\nFigura 14.2\\n. Em geral, uma tabela para uma variável\\nbooleana com \\nk\\n pais booleanos contém 2\\nk\\n probabilidades independentemente especificáveis. Um nó\\nsem pais tem apenas uma linha representando as probabilidades anteriores a cada valor possível da\\nvariável.\\nNote que a rede não tem nós correspondentes ao fato de Maria estar ouvindo música em alto\\nvolume no momento ou ao fato de o telefone tocar e confundir João. Esses fatores são resumidos na\\nincerteza associada aos vínculos de \\nAlarme\\n para \\nJoãoLiga\\n e \\nMariaLiga\\n. Isso mostra ao mesmo\\ntempo a preguiça e a ignorância em operação: seria muito trabalhoso descobrir por que esses fatores\\nseriam mais ou menos prováveis em qualquer caso específico e, na verdade, não temos nenhum modo\\nrazoável de obter as informações relevantes. As probabilidades realmente resumem um conjunto\\npotencialmente infinito\\n de circunstâncias em que o alarme poderia deixar de soar (umidade elevada,\\nfalta de energia, bateria descarregada, fios cortados, um rato morto preso à campainha etc.) ou então\\nJoão ou Maria podem deixar de ligar para informar que ele soou (saíram para almoçar, saíram de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 601}),\n",
       " Document(page_content='férias, estão temporariamente surdos, está passando um helicóptero etc.). Desse modo, um pequeno\\nagente pode lidar com um mundo muito grande, pelo menos aproximadamente. O grau de\\naproximação pode ser melhorado se introduzirmos informações relevantes adicionais.\\n14.2 A SEMÂNTICA DAS REDES BAYESIANAS\\nA seção anterior descreveu o que é uma rede, mas não o que ela significa. Há duas maneiras de\\ncompreender a semântica das redes bayesianas. A primeira é ver a rede como uma representação da\\ndistribuição de probabilidade conjunta. A segunda é visualizá-la como uma codificação de uma\\ncoleção de declarações de independência condicional. As duas visões são equivalentes, mas a\\nprimeira se mostra útil na compreensão de como \\nconstruir\\n redes, enquanto a segunda é útil no\\nprojeto de procedimentos de inferência.\\n14.2.1 Representação da distribuição conjunta total\\nVisto como um pedaço de “sintaxe”, uma rede bayesiana é um grafo acíclico orientado com alguns\\nparâmetros numéricos ligados a cada nó. Uma maneira de definir o que significa a rede — sua\\nsemântica — é definir a maneira pela qual ela representa uma distribuição conjunta específica sobre\\ntodas as variáveis. Para fazer isso, precisamos primeiro retirar (temporariamente) o que foi dito\\nanteriormente sobre os parâmetros associados a cada nó. Dissemos que esses parâmetros\\ncorrespondem às probabilidades condicionais \\nP\\n(\\nX\\ni\\n | \\nPais\\n (\\nX\\ni\\n)); essa é uma afirmação verdadeira,\\nmas até atribuirmos a semântica à rede como um todo devemos considerá-los apenas como números\\nθ\\n(\\nX\\ni\\n | \\nPais\\n (\\nX\\ni\\n)).\\nUma entrada genérica na distribuição conjunta é a probabilidade de uma conjunção de atribuições\\nespecíficas a cada variável, tal como \\nP\\n(\\nX\\n1\\n = \\nx\\n1\\n \\n∧\\n… \\n∧\\n \\nX\\nn\\n = \\nx\\nn\\n). Usamos a notação \\nP\\n(\\nx\\n1\\n, …, \\nx\\nn\\n)\\ncomo abreviação para isso. O valor dessa entrada é dado pela fórmula:\\nonde \\npais\\n(\\nX\\ni\\n) denota os valores em \\nPais\\n(\\nX\\ni\\n) que aparece em x\\n1\\n,….,x\\nn\\n. Desse modo, cada entrada na\\ndistribuição conjunta é representada pelo produto dos elementos apropriados das tabelas de\\nprobabilidade condicional (TPCs) na rede bayesiana.\\nA partir dessa definição, é fácil provar que os parâmetros \\nθ\\n(\\nX\\ni\\n | \\nPais\\n (\\nX\\ni\\n)) são exatamente as\\nprobabilidades condicionais \\nP\\n(\\nX\\ni\\n | \\nPais\\n (\\nX\\ni\\n)) deduzidas pela distribuição conjunta (ver Exercício\\n14.2). Assim, podemos reescrever a Equação 14.1 como', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 602}),\n",
       " Document(page_content='Em outras palavras, as tabelas que chamamos de tabelas de probabilidade condicional realmente\\nsão\\n tabelas de probabilidade condicional de acordo com a semântica definida na Equação 14.1.\\nPara ilustrar isso, podemos calcular a probabilidade de que o alarme tenha soado, mas não tenha\\nocorrido nenhum roubo nem terremoto, e que tanto João quanto Maria tenham ligado. Multiplicamos\\nas entradas da distribuição conjunta (usando nomes de letras únicas para as variáveis):\\nA \\nSeção 13.3\\n explicou que a distribuição conjunta total pode ser usada para responder a qualquer\\nconsulta sobre o domínio. Se uma rede bayesiana for uma representação da distribuição conjunta, ela\\ntambém poderá ser usada para responder a qualquer consulta, efetuando-se o somatório de todas as\\nentradas conjuntas relevantes. A \\nSeção 14.4\\n explica como fazer isso, mas também descreve métodos\\nque são muito mais eficientes.\\nUm método para construir redes bayesianas\\nA Equação 14.2 define o que significa uma rede bayesiana. A próxima etapa é como \\nconstruir\\n uma\\nrede bayesiana de tal modo que a distribuição conjunta resultante seja uma boa representação de\\ndado domínio. Agora, mostraremos que a Equação 14.2 implica certos relacionamentos de\\nindependência condicional que podem ser usados para orientar o engenheiro do conhecimento na\\nconstrução da topologia da rede.\\nPrimeiro, reescrevemos as entradas na distribuição conjunta em termos de uma probabilidade\\ncondicional usando a regra do produto:\\nP\\n(\\nx\\n1\\n,…, \\nx\\nn\\n) = \\nP\\n(\\nx\\nn\\n|\\nx\\nn – 1\\n,…, \\nx\\n1\\n)\\nP\\n(\\nx\\nn – 1\\n,…, \\nx\\n1\\n).\\nEm seguida, repetimos o processo reduzindo cada probabilidade conjuntiva a uma probabilidade\\ncondicional e uma conjunção menor. Terminamos com um grande produto:\\nEssa identidade é chamada de \\nregra da cadeia\\n. É válida para qualquer conjunto de variáveis\\naleatórias. Comparando-a com a Equação 14.2, vemos que a especificação da distribuição conjunta é\\nequivalente à afirmação geral de que, para toda variável \\nX\\ni\\n na rede, temos\\ndesde que \\nPais\\n(\\nX\\ni\\n) \\n {\\nX\\ni – 1\\n, …, \\nX\\n1\\n}. Esta última condição é satisfeita enumerando os nós em\\nqualquer ordem consistente com a ordem parcial implícita na estrutura do grafo.\\nO que a Equação 14.3 nos diz é que a rede bayesiana é uma representação correta do domínio\\nsomente se cada nó é condicionalmente independente de seus predecessores na ordenação de nós,\\ndados seus pais. Podemos satisfazer essa condição com esta metodologia:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 603}),\n",
       " Document(page_content='1. \\nNós\\n: Primeiro determine o conjunto de variáveis \\u200b\\u200bque são necessárias para modelar o domínio.\\nAgora as ordene, {\\nX\\n1\\n, …, \\nX\\nn\\n}. Qualquer ordem vai funcionar, mas a rede resultante será mais\\ncompacta se as variáveis forem ordenadas de tal forma que as causas precedam os efeitos.\\n2. \\nVínculos\\n: Para \\ni\\n = 1 até \\nn\\n faça:\\n•  Escolha, de \\nX\\n1\\n,…, \\nX\\ni-1\\n, um conjunto mínimo de pais para \\nX\\ni\\n, tal que a Equação 14.3 seja\\nsatisfeita.\\n•  Para cada pai insira um vínculo do pai para \\nX\\ni\\n.\\n•  TPCs: escreva a tabela de probabilidade condicional, \\nP\\n(\\nX\\ni\\n | \\nPais\\n (\\nX\\ni\\n)).\\n Intuitivamente, os pais do nó \\nX\\ni\\n devem conter todos os nós em \\nX\\n1\\n, …, \\nX\\ni –1\\n que \\ninfluenciam\\ndiretamente X\\ni\\n. Por exemplo, vamos supor que completamos a rede da \\nFigura 14.2\\n, exceto pela\\nescolha de pais para \\nMariaLiga\\n. \\nMariaLiga\\n certamente é influenciada pelo fato de haver ou não um\\nRoubo\\n ou um \\nTerremoto\\n, mas não é \\ndiretamente\\n influenciada. Intuitivamente, nosso conhecimento do\\ndomínio nos diz que esses eventos influenciam a disposição de Maria para telefonar somente por seu\\nefeito sobre o alarme. Além disso, dado o estado do alarme, o fato de João ligar não tem influência\\nsobre a ligação de Maria. Em termos formais, acreditamos que a declaração de independência\\ncondicional a seguir seja válida:\\nP\\n(\\nMariaLiga\\n | \\nJoãoLiga\\n, \\nAlarme\\n, \\nTerremoto\\n, \\nRoubo\\n) = \\nP\\n(\\nMariaLiga\\n | \\nAlarme\\n).\\nAssim, \\nAlarme\\n será o único nó pai para \\nMariaLiga.\\n Como cada nó só é ligado aos nós anteriores, esse método de construção garante que a rede é\\nacíclica. Outra propriedade importante da rede bayesiana é que ela não contém valores de\\nprobabilidade redundante. Se não houver redundância, não há chance para inconsistência: é\\nimpossível para o engenheiro de conhecimento ou especialista de domínio criar uma rede\\nbayesiana que viole os axiomas da probabilidade.\\nDensidade e ordenação de nós\\nAlém de ser uma representação completa e não redundante do domínio, uma rede bayesiana\\nfrequentemente pode ser muito mais \\ncompacta\\n que a distribuição conjunta total. Essa propriedade é o\\nque torna viável manipular domínios com muitas variáveis. A densidade das redes bayesianas é um\\nexemplo de propriedade muito geral de \\nsistemas localmente estruturados\\n (também chamados\\nsistemas esparsos\\n). Em um sistema localmente estruturado, cada subcomponente interage\\ndiretamente apenas com um número limitado de outros componentes, não importando o número total\\nde componentes. A estrutura local normalmente está associada a um crescimento linear, e não a um\\ncrescimento exponencial da complexidade. No caso das redes bayesianas, é razoável supor que, na\\nmaioria dos domínios, cada variável aleatória é diretamente influenciada por, no máximo, \\nk\\n outras,\\npara alguma constante \\nk\\n. Se supusermos \\nn\\n variáveis booleanas por simplicidade, a quantidade de\\ninformações necessárias para especificar cada tabela de probabilidade condicional será no máximo\\n2\\nk\\n números, e a rede completa poderá ser especificada por \\nn\\n2\\nk\\n números. Em contraste, a distribuição\\nconjunta contém 2\\nn\\n números. Para tornar esse exemplo concreto, vamos supor que tenhamos \\nn\\n = 30', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 604}),\n",
       " Document(page_content='nós, cada um com cinco pais (\\nk\\n = 5). Então, a rede bayesiana exigirá 960 números, mas a\\ndistribuição conjunta total exigirá mais de um bilhão.\\nExistem domínios em que cada variável pode ser diretamente influenciada por todas as outras, de\\nforma que a rede seja totalmente conectada. Então, a especificação das tabelas de probabilidade\\ncondicional exige a mesma quantidade de informações que a especificação da distribuição conjunta.\\nEm alguns domínios, existirão dependências fracas que deverão ser incluídas estritamente pela\\nadição de novos vínculos. Porém, se essas dependências forem muito tênues, talvez não compense a\\ncomplexidade adicional na rede em relação ao pequeno ganho em exatidão. Por exemplo, alguém\\npoderia fazer uma objeção à nossa rede de alarme contra roubo afirmando que, se houvesse um\\nterremoto, João e Maria não telefonariam mesmo que tivessem ouvido o alarme porque eles iriam\\nsupor que o terremoto fosse a causa. A decisão de adicionar o vínculo de \\nTerremoto\\n para \\nJoãoLiga\\ne para \\nMariaLiga\\n (e, desse modo, de ampliar as tabelas) dependerá da comparação entre a\\nimportância de obter probabilidades mais precisas e o custo de especificar as informações extras.\\nMesmo em um domínio localmente estruturado, só obteremos uma rede bayesiana se ordenarmos\\nbem para escolher o nó. O que acontecerá se escolhermos a ordem errada? Vamos considerar\\nnovamente o exemplo do alarme contra roubo. Suponha que decidimos adicionar os nós na ordem\\nMariaLiga\\n, \\nJoãoLiga\\n, \\nAlarme\\n, \\nRoubo\\n, \\nTerremoto\\n. Nesse caso, obtemos a rede um pouco mais\\ncomplicada mostrada na \\nFigura 14.3\\n(a). O processo se desenvolve assim:\\nFigura 14.3\\n A estrutura de rede depende da ordem de introdução. Em cada rede, introduzimos nós na\\nordem de cima para baixo.\\n•  Adicionando \\nMariaLiga\\n: não há pais.\\n•  Adicionando \\nJoãoLiga\\n: se Maria liga, isso provavelmente significa que o alarme soou, e é claro\\nque tornaria mais provável a ligação de João. Portanto, \\nJoãoLiga\\n precisa de \\nMariaLiga\\n como\\npai.\\n•  Adicionando \\nAlarme\\n: é claro que, se ambos ligarem, será mais provável que o alarme tenha\\nsoado do que se apenas um ou nenhum deles ligar; assim, precisamos de \\nMariaLiga\\n e \\nJoãoLiga\\ncomo pais.\\n•  Adicionando \\nRoubo\\n: se tivéssemos conhecimento do estado do alarme, a ligação de João ou de\\nMaria poderia nos dar informações sobre o ruído da campainha de nosso telefone ou sobre a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 605}),\n",
       " Document(page_content='música de Maria, mas não sobre roubo:\\nP\\n(\\nRoubo\\n | \\nAlarme\\n, \\nJoãoLiga\\n, \\nMariaLiga\\n) = \\nP\\n(\\nRoubo\\n | \\nAlarme\\n).\\nConsequentemente precisamos apenas de \\nAlarme\\n como pai.\\n•  Adicionando \\nTerremoto\\n: se o alarme estiver ligado, é mais provável que tenha havido um\\nterremoto. (O alarme é uma espécie de detector de terremotos.) Porém, se soubermos que houve\\num roubo, isso explica o alarme, e a probabilidade de um terremoto estaria apenas ligeiramente\\nacima da normal. Por conseguinte, precisamos de \\nAlarme\\n e \\nRoubo\\n como pais.\\n A rede resultante terá dois outros vínculos além da rede original da \\nFigura 14.2\\n e exigirá outras\\ntrês probabilidades para ser especificada. Pior ainda, alguns dos vínculos representam\\nrelacionamentos tênues que exigem julgamentos de probabilidade difíceis e antinaturais, como a\\navaliação da probabilidade de \\nTerremoto\\n, dados \\nRoubo\\n e \\nAlarme\\n. Esse fenômeno é bastante geral e\\nestá relacionado à distinção entre modelos causais e modelos de diagnóstico introduzidos na \\nSeção\\n13.5.1\\n (veja também o Exercício 8.13). Se tentarmos construir um modelo de diagnóstico com\\nvínculos de sintomas para causas (como, por exemplo, de \\nMariaLiga\\n para \\nAlarme\\n ou de \\nAlarme\\n para\\nRoubo\\n), acabaremos sendo obrigados a especificar dependências adicionais entre causas que de\\noutra forma seriam independentes (e, com frequência, também entre sintomas que ocorrem\\nseparadamente). \\nSe nos fixarmos em um modelo causal, acabaremos tendo de especificar uma\\nquantidade menor de números, e os números frequentemente serão mais fáceis de apresentar\\n. Por\\nexemplo, no domínio da medicina, foi demonstrado por Tversky e Kahneman (1982) que os médicos\\nespecialistas preferem apresentar julgamentos de probabilidade para regras causais, em vez de fazê-\\nlo para regras de diagnóstico.\\nA \\nFigura 14.3\\n(b) mostra uma ordenação de nós muito ruim: \\nMariaLiga\\n, \\nJoãoLiga\\n, \\nTerremoto\\n,\\nRoubo\\n, \\nAlarme\\n. Essa rede exige que sejam especificadas 31 probabilidades distintas — exatamente a\\nmesma quantidade que a da distribuição conjunta total. No entanto, é importante perceber que\\nqualquer das três redes pode representar \\nexatamente a mesma distribuição conjunta\\n. As duas\\núltimas versões simplesmente deixam de representar todos os relacionamentos de independência\\ncondicional e, consequentemente, acabam por especificar em vez disso muitos números\\ndesnecessários.\\n14.2.2 Relações de independência condicional em redes bayesianas\\nFornecemos uma semântica “numérica” para redes bayesianas em termos da representação da\\ndistribuição conjunta total, como na Equação 14.2. Usando essa semântica para derivar um método\\ncom a finalidade de construir redes bayesianas, fomos levados à consequência de que um nó é\\ncondicionalmente independente de seus predecessores, dados seus pais. Ocorre que também\\npodemos seguir o sentido inverso. Podemos começar de uma semântica “topológica” que especifique\\nos relacionamentos de independência condicional codificados pela estrutura de grafo e, a partir\\ndeles, podemos derivar a semântica “numérica”. A semântica topológica\\n2\\n especifica que cada\\nvariável é condicionalmente independente de seus não \\ndescendentes\\n, dados seus pais. Por exemplo,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 606}),\n",
       " Document(page_content='na \\nFigura 14.2\\n, \\nJoãoLiga\\n é independente de \\nRoubo\\n, \\nTerremoto\\n e \\nMariaLiga\\n dado o valor de\\nAlarme\\n. A definição está ilustrada na \\nFigura 14.4\\n(a). Dessas afirmações de independência\\ncondicional e da interpretação dos parâmetros da rede \\nθ\\n(\\nX\\ni\\n | \\nPais\\n (\\nX\\ni\\n)) como especificações das\\nprobabilidades condicionais \\nP\\n(\\nX\\ni\\n | \\nPais\\n (\\nX\\ni\\n)), a distribuição conjunta completa dada na Equação 14.2\\npode ser reconstruída. Nesse sentido, as semânticas “numérica” e a “topológica” são equivalentes.\\nFigura 14.4\\n (a) Um nó \\nX\\n é condicionalmente independente de seus não descendentes (por exemplo,\\nos nós \\nZ\\nij\\n) dados seus pais (os nós \\nU\\ni\\n mostrados na área cinza). (b) Um nó \\nX\\n é condicionalmente\\nindependente de todos os outros nós da rede, dada sua cobertura de Markov (a área cinza).\\nA semântica topológica implica outra propriedade importante de independência: um nó é\\ncondicionalmente independente de todos os outros nós na rede, dados seus pais, filhos e pais dos\\nfilhos, isto é, dada a \\ncobertura de Markov\\n (o Exercício 14.7 pede para provar isso). Por exemplo,\\nRoubo\\n é independente de \\nJoãoLiga e MariaLiga\\n, dados \\nAlarme e Terremoto\\n. Essa propriedade está\\nilustrada na \\nFigura 14.4\\n(b).\\n14.3 REPRESENTAÇÃO EFICIENTE DE DISTRIBUIÇÕES CONDICIONAIS\\nAinda que o número máximo de pais \\nk\\n seja reduzido, o preenchimento da TPC para um nó exige\\naté \\nO\\n(2\\nk\\n) números e talvez muita experiência com todos os casos de condicionamento possíveis. De\\nfato, esse é um cenário de pior caso, em que o relacionamento entre os pais e o filho é completamente\\narbitrário. Em geral, tais relacionamentos podem ser descritos por uma \\ndistribuição canônica\\n que se\\najusta a alguma forma-padrão. Em tais casos, a tabela completa pode ser especificada definindo-se o\\npadrão e talvez fornecendo-se alguns parâmetros — o que é muito mais fácil que fornecer um número\\nexponencial de parâmetros.\\nO exemplo mais simples é fornecido por \\nnós determinísticos\\n. Um nó determinístico tem seu valor\\nespecificado exatamente pelos valores de seus pais, sem qualquer incerteza. O relacionamento pode\\nser lógico: por exemplo, o relacionamento entre os nós pais \\nCanadense\\n, \\nAmericano\\n, \\nMexicano\\n e o\\nnó filho \\nNorte\\n-\\namericano\\n é simplesmente o fato de que o filho é a disjunção dos pais. O\\nrelacionamento também pode ser numérico: por exemplo, se os nós pais são os preços de um modelo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 607}),\n",
       " Document(page_content='específico de automóvel em diversos revendedores e o nó filho é o preço que um caçador de ofertas\\nacaba pagando, o nó filho é o valor mínimo entre os valores pais; ou, então, se os nós pais são os\\nafluentes — ou fluxos de entrada (rios, córregos, precipitações) de um lago — e os escoadouros —\\nou fluxos de saída (rios, evaporação, vazamentos) do lago — e o filho é a mudança no nível de água\\ndo lago, então o valor do filho é a soma dos fluxos de entrada menos a soma dos fluxos de saída.\\nOs relacionamentos incertos frequentemente podem ser caracterizados pelos chamados\\nrelacionamentos lógicos “ruidosos”. O exemplo-padrão é a relação \\nOU ruidoso\\n, uma generalização\\ndo OU lógico. Em lógica proposicional, poderíamos dizer que \\nFebre\\n é verdadeira se e somente se\\nResfriado\\n, \\nGripe\\n ou \\nMalária\\n é verdadeira. O modelo OU ruidoso permite a incerteza sobre a\\nhabilidade de cada pai para fazer o filho ser verdadeiro — o relacionamento causal entre pai e filho\\npode ser \\ninibido\\n, e assim um paciente pode ter um resfriado, mas não apresentar febre. O modelo faz\\nduas suposições. Primeiro, ele pressupõe que todas as causas possíveis estão listadas (se algo\\nestiver faltando, sempre podemos adicionar um chamado \\nnó de vazamento\\n que cobre “causas\\ndiversas”). Em segundo lugar, ele pressupõe que a inibição de cada pai é independente da inibição\\nde quaisquer outros pais: por exemplo, o que inibe \\nMalária\\n de causar uma febre é independente do\\nque inibe \\nGripe\\n de causar uma febre. Dadas essas suposições, \\nFebre\\n é \\nfalsa\\n se e somente se todos os\\nseus pais \\nverdadeiros\\n são inibidos, e a probabilidade de ocorrer isso é o produto das probabilidades\\nde inibição \\nθ\\n para cada pai. Vamos supor que essas probabilidades de inibição individuais sejam:\\nAssim, a partir dessas informações e das suposições de OU ruidoso, é possível construir a TPC\\ninteira. A regra geral é que:\\nonde o produto é obtido dos pais que são definidos como verdadeiro para essa linha da TPC. A\\ntabela a seguir ilustra esse cálculo:\\nResfriado\\nGripe\\nMalária\\nP\\n(\\nFebre\\n)\\nP\\n¬ \\n(Febre)\\nF\\nF\\nF\\n0,0\\n1,0\\nF\\nF\\nV\\n0,9\\n0,1\\nF\\nV\\nF\\n0,8\\n0,2\\nF\\nV\\nV\\n0,98\\n0,02 = 0,2 × 0,1\\nV\\nF\\nF\\n0,4\\n0,6\\nV\\nF\\nV\\n0,94\\n0,06 = 0,6 × 0,1\\nV\\nV\\nF\\n0,88\\n0,12 = 0,6 × 0,2\\nV\\nV\\nV\\n0,988\\n0,012 = 0,6 × 0,2 × 0,1\\nEm geral, relacionamentos lógicos ruidosos em que uma variável depende de \\nk\\n pais podem ser', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 608}),\n",
       " Document(page_content='descritos com o uso de \\nO\\n(\\nk\\n) parâmetros, em vez de \\nO\\n(2\\nk\\n) para a tabela de probabilidade condicional\\ncompleta. Isso torna muito mais fácil a avaliação e o aprendizado. Por exemplo, a rede CPCS\\n(Pradhan \\net al\\n., 1994) utiliza distribuições de OU ruidoso e MAX ruidoso para modelar\\nrelacionamentos entre doenças e sintomas em medicina interna. Com 448 nós e 906 vínculos, ela\\nexige apenas 8.254 valores, em vez de 133.931.430 para uma rede com TPCs completas.\\nRedes bayesianas com variáveis contínuas\\nMuitos problemas reais envolvem quantidades contínuas, como altura, massa, temperatura e\\ndinheiro; de fato, grande parte da estatística lida com variáveis aleatórias cujos domínios são\\ncontínuos. Por definição, variáveis contínuas têm um número infinito de valores possíveis e, assim, é\\nimpossível especificar explicitamente probabilidades condicionais para cada valor. Um modo\\npossível de manipular variáveis contínuas é evitá-las usando a \\ndiscretização\\n, isto é, repartindo os\\nvalores possíveis em um conjunto fixo de intervalos. Por exemplo, as temperaturas poderiam ser\\ndivididas dentre (<0°C), (0°C–100°C) e (>100°C). A discretização às vezes é uma solução\\nadequada, mas frequentemente resulta em perda considerável de precisão e em TPCs muito grandes.\\nA solução mais comum é definir famílias-padrão de funções de densidade de probabilidade (veja o\\nApêndice A) que são especificadas por um número finito de \\nparâmetros\\n. Por exemplo, uma\\ndistribuição gaussiana (ou normal) \\nN\\n(\\nµ\\n, \\nσ\\n2\\n)(\\nx\\n) tem a média µ e a variância \\nσ\\n2\\n como parâmetros.\\nAinda uma outra solução — às vezes chamada representação \\nnão paramétrica\\n — é definir\\nimplicitamente a distribuição condicional com uma coleção de instâncias, cada uma contendo os\\nvalores específicos das variáveis do pai e do filho\\u200b\\u200b. Essa abordagem será explorada no Capítulo 18.\\nUma rede com variáveis discretas e contínuas é chamada \\nrede bayesiana híbrida\\n. Para\\nespecificar uma rede híbrida, temos de especificar dois novos tipos de distribuições: a distribuição\\ncondicional para uma variável contínua dados pais discretos ou contínuos e a distribuição\\ncondicional para uma variável discreta dados pais contínuos. Considere o exemplo simples da \\nFigura\\n14.5\\n, em que um cliente compra alguma fruta dependendo de seu custo que, por sua vez, depende do\\nvolume da colheita e do fato de o esquema de subsídios do governo estar em vigor. A variável \\nCusto\\né contínua e tem pais contínuos e discretos; a variável \\nCompra\\n é discreta e tem pai contínuo.\\nFigura 14.5\\n Uma rede simples com variáveis discretas (\\nSubsídio\\n e \\nCompra\\n) e variáveis contínuas\\n(\\nColheita\\n e \\nCusto\\n).\\nPara a variável \\nCusto\\n, precisamos especificar \\nP\\n(\\nCusto\\n | \\nColheita\\n, \\nSubsídio\\n). O pai discreto é\\nmanipulado por enumeração explícita, ou seja, pela especificação de \\nP\\n(\\nCusto\\n | \\nColheita\\n, \\nsubsídio\\n) e\\nde \\nP\\n(\\nCusto\\n | \\nColheita\\n, ¬\\nsubsídio\\n). Para tratar \\nColheita\\n, especificamos como a distribuição sobre o\\ncusto \\nc\\n depende do valor contínuo \\nh\\n de \\nColheita\\n. Em outras palavras, especificamos os \\nparâmetros\\nda distribuição de custo como uma função de \\nh\\n. A escolha mais comum é a \\ndistribuição gaussiana', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 609}),\n",
       " Document(page_content='linear\\n, na qual o filho tem uma distribuição gaussiana cuja média µ varia linearmente com o valor do\\npai e cujo desvio-padrão \\nσ\\n é fixo. Precisamos de duas distribuições, uma para \\nsubsídio\\n e uma para\\n¬\\nsubsídio\\n, com parâmetros diferentes:\\nPara esse exemplo, a distribuição condicional para \\nCusto\\n é especificada pela nomenclatura da\\ndistribuição gaussiana linear, fornecendo-se os parâmetros \\na\\nt\\n, \\nb\\nt\\n, Σ\\nt\\n, \\na\\nf\\n, \\nb\\nf\\n e \\nΣ\\nf\\n. As Figuras 14.6(a) e\\n(b) mostram esses dois relacionamentos. Note que, em cada caso, a inclinação é negativa porque o\\npreço diminui à medida que a quantidade fornecida aumenta. (É claro que a suposição de linearidade\\nimplica que o preço se torna negativo em algum momento; o modelo linear só é razoável se o volume\\nda colheita for limitado a um intervalo estreito.) A \\nFigura 14.6\\n(c) mostra a distribuição \\nP\\n(\\nc\\n | \\nh\\n),\\ncalculada pela média sobre os dois valores possíveis de \\nSubsídio\\n e supondo que cada um deles tenha\\nprobabilidade \\na priori\\n igual a 0,5. Isso mostra que até mesmo com modelos muito simples podem ser\\nrepresentadas distribuições bastante interessantes.\\nFigura 14.6\\n Os grafos em (a) e (b) mostram a distribuição de probabilidade sobre \\nCusto\\n como uma\\nfunção do volume da \\nColheita\\n, com \\nSubsídio\\n verdadeiro e falso, respectivamente. O grafo (c) mostra\\na distribuição \\nP\\n(\\nCusto\\n | \\nColheita\\n), obtida pelo somatório sobre os dois casos de subsídios.\\nA distribuição gaussiana condicional linear tem algumas propriedades especiais. Uma rede que\\ncontém apenas variáveis contínuas com distribuições gaussianas lineares tem uma distribuição\\nconjunta que é uma distribuição gaussiana multivariada (veja o Apêndice A) sobre todas as variáveis\\n(Exercício 14.9). Além disso, dada alguma evidência, a distribuição posterior também tem essa\\npropriedade.\\n3\\n Quando são adicionadas variáveis discretas como pais (não como filhos) de variáveis\\ncontínuas, a rede define uma \\ndistribuição gaussiana condicional\\n, ou GC: dada qualquer atribuição às\\nvariáveis discretas, a distribuição sobre as variáveis contínuas é uma distribuição gaussiana\\nmultivariada.\\nAgora, vamos estudar as distribuições para variáveis discretas com pais contínuos. Por exemplo,\\nconsidere o nó \\nCompras\\n da \\nFigura 14.5\\n. Parece razoável supor que o cliente comprará se o custo for\\nbaixo e não comprará se ele for alto, e que a probabilidade de compra varia suavemente em alguma\\nregião intermediária. Em outras palavras, a distribuição condicional é semelhante a uma função de\\nlimiar “suave”. Um modo de criar limiares suaves é usar a \\nintegral\\n da distribuição normal padrão:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 610}),\n",
       " Document(page_content='Então, a probabilidade de \\nCompras\\n dado \\nCusto\\n poderia ser:\\no que significa que o limiar de custo ocorre em torno de \\nµ\\n, que a largura da região de limiar é\\nproporcional a \\nΣ\\n e que a probabilidade de compra diminui à medida que o custo aumenta.\\nEssa \\ndistribuição probit (\\nabreviatura de “unidade de probabilidade”) está ilustrada na \\nFigura\\n14.7\\n(a). A forma pode ser justificada pela proposição de que o processo de decisão subjacente tem\\num limiar difícil, mas que a posição precisa do limiar está sujeita a ruído gaussiano aleatório.\\nFigura 14.7\\n (a) Uma distribuição (gaussiana) normal para o limite de custo, centrada em \\nμ\\n = 6,0, com\\ndesvio-padrão \\nΣ\\n = 1,0. (b) Distribuições Logit e Probit para a probabilidade de \\ncompras\\n dado\\nc\\nusto\\n, para os parâmetros \\nμ\\n = 6,0 e \\nΣ\\n = 1,0.\\nUma alternativa para o modelo probit é a \\ndistribuição logit\\n, que utiliza a função logística 1/(1 +\\ne\\n−x\\n) para produzir um limiar suave:\\nIsso está ilustrado na \\nFigura 14.7\\n(b). As duas distribuições parecem semelhantes, mas, na\\nrealidade, a distribuição logit tem extremidades muito mais longas. Com frequência, a distribuição\\nprobit se ajusta melhor a situações reais, embora às vezes seja mais fácil lidar matematicamente com\\na distribuição logit. Ela é amplamente utilizada em redes neurais (Capítulo 20). Tanto probit quanto\\nlogit podem ser generalizadas para manipular vários pais contínuos, tomando-se uma combinação\\nlinear dos valores dos pais.\\n14.4 INFERÊNCIA EXATA EM REDES BAYESIANAS\\nA tarefa básica para qualquer sistema de inferência probabilístico é calcular a distribuição de\\nprobabilidade posterior para um conjunto de \\nvariáveis de consulta\\n, dado algum \\nevento\\n observado,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 611}),\n",
       " Document(page_content='isto é, alguma atribuição de valores a um conjunto de \\nvariáveis de evidência\\n. Para simplificar a\\napresentação, consideraremos apenas uma variável de consulta por vez; os algoritmos podem ser\\nfacilmente estendidos para consultas com variáveis múltiplas. Utilizaremos a notação introduzida no\\nCapítulo 13: \\nX\\n denota a variável de consulta; \\nE\\n denota o conjunto de variáveis de evidência \\nE\\n1\\n, …,\\nE\\nm\\n e \\ne\\n é um evento específico observado; \\nY\\n denotará as variáveis que não são de evidência \\nY\\n1\\n, …, \\nY\\nl\\n(às vezes chamadas \\nvariáveis ocultas\\n). Desse modo, o conjunto completo de variáveis \\nX\\n = {\\nX\\n} \\n \\nE\\n \\n \\nY\\n. Uma consulta típica busca a distribuição de probabilidade posterior \\nP\\n(\\nX\\n | \\ne\\n).\\nNa rede de alarme contra roubo, poderíamos observar o evento em que \\nJoãoLiga\\n = \\nverdadeiro\\n e\\nMariaLiga\\n = \\nverdadeiro\\n. Então, poderíamos buscar, digamos, a probabilidade de ter ocorrido um\\nroubo:\\nP\\n(\\nRoubo\\n | \\nJoãoLiga\\n = \\nverdadeiro\\n, \\nMariaLiga\\n = \\nverdadeiro\\n) = \\n〈\\n0,284, 0,716\\n〉\\n.\\nNesta seção, discutiremos algoritmos exatos para calcular probabilidades posteriores e\\nconsideraremos a complexidade dessa tarefa. Ocorre que o caso geral é intratável e, assim, a \\nSeção\\n14.5\\n estuda métodos para inferência aproximada.\\n14.4.1 Inferência por enumeração\\nO Capítulo 13 explicou que qualquer probabilidade condicional pode ser calculada pelo\\nsomatório de termos da distribuição conjunta total. Mais especificamente, uma consulta \\nP\\n(\\nX\\n | \\ne\\n) pode\\nser respondida com a utilização da Equação 13.9, que repetimos aqui por conveniência:\\n Agora, uma rede bayesiana fornece uma representação completa da distribuição conjunta total.\\nMais especificamente, a Equação 14.2 mostra que os termos \\nP\\n(\\nx\\n, \\ne\\n, \\ny\\n) na distribuição conjunta\\npodem ser escritos como produtos de probabilidades condicionais da rede. Por conseguinte, \\numa\\nconsulta pode ser respondida com o uso de uma rede bayesiana, calculando-se somas de produtos\\nde probabilidades condicionais da rede\\n.\\nConsidere a consulta \\nP\\n(\\nRoubo\\n | \\nJoãoLiga\\n = \\nverdadeiro\\n, \\nMariaLiga\\n = \\nverdadeiro\\n). As variáveis\\nocultas para essa consulta são \\nTerremoto\\n e \\nAlarme\\n. Da Equação 13.9, usando letras iniciais para\\nrepresentar as variáveis com o objetivo de encurtar as expressões, temos:\\n4\\nA semântica das redes bayesianas (Equação 14.2) nos dá então uma expressão em termos de\\nentradas de TPC. Por simplicidade, faremos isso apenas para \\nRoubo\\n = \\nverdadeiro\\n:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 612}),\n",
       " Document(page_content='Para calcular essa expressão, temos de somar quatro termos, cada um calculado pela multiplicação\\nde cinco números. No pior caso, em que teremos de efetuar o somatório de quase todas as variáveis,\\na complexidade do algoritmo para uma rede com \\nn\\n variáveis booleanas será \\nO\\n(\\nn\\n2\\nn\\n).\\nUma melhoria pode ser obtida a partir das observações simples a seguir: o termo \\nP\\n(\\nb\\n) é uma\\nconstante e pode ser movido para fora dos somatórios sobre \\na\\n e \\ne\\n, e o termo \\nP\\n(\\ne\\n) pode ser movido\\npara fora do somatório sobre \\na\\n. Consequentemente, temos:\\nEssa expressão pode ser avaliada por meio de um laço repetitivo através das variáveis em ordem,\\nmultiplicando entradas de TPC à medida que avançarmos. Para cada somatório, também precisamos\\nexecutar um laço sobre os valores possíveis da variável. A estrutura dessa computação é mostrada na\\nFigura 14.8\\n. Usando os números da \\nFigura 14.2\\n, obtemos \\nP\\n(\\nb\\n | \\nj\\n, \\nm\\n) = \\nα\\n × 0,00059224. A\\ncomputação correspondente para ¬\\nb\\n produz \\nα\\n × 0,0014919; por conseguinte,\\nFigura 14.8\\n Estrutura da expressão mostrada na Equação 14.4. A avaliação prossegue de cima para\\nbaixo, multiplicando valores ao longo de cada caminho e efetuando o somatório nos nós identificados\\ncom “+”. Note a repetição dos caminhos para \\nj\\n e \\nm\\n.\\nP\\n(\\nB\\n | \\nj\\n, \\nm\\n) = \\nα\\n \\n〈\\n0,00059224, 0,0014919\\n〉\\n ≈ \\n〈\\n0,284, 0,716\\n〉\\n.\\nOu seja, a chance de um roubo, dadas as ligações de ambos os vizinhos, é de aproximadamente\\n28%.\\nO processo de avaliação para a expressão da Equação 14.4 é mostrado como uma árvore de\\nexpressões na \\nFigura 14.8\\n. O algoritmo ASK-ENUMERAÇÃO da \\nFigura 14.9\\n avalia tais árvores\\nusando a recursão primeiro na profundidade. O algoritmo é muito semelhante em estrutura ao\\nalgoritmo de retrocesso para a resolução de PSRs (\\nFigura 6.5\\n) e ao algoritmo de satisfatibilidade\\nDPLL (\\nFigura 7.17\\n).\\nfunção\\n ASK-ENUMERAÇÃO(\\nX\\n, \\ne\\n, \\nrb\\n) \\nretorna\\n uma distribuição sobre \\nX', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 613}),\n",
       " Document(page_content='entradas:\\n \\nX\\n, a variável de consulta\\ne\\n, valores observados para variáveis \\nE\\nrb\\n, uma rede bayesiana com variáveis {\\nX\\n} \\n∪\\n \\nE\\n \\n∪\\n \\nY\\n /* \\nY\\n = \\nvariáveis ocultas\\n */\\n    \\n    \\nQ\\n(\\nX\\n) ← uma distribuição sobre \\nX\\n, inicialmente vazia\\n    \\npara cada\\n valor \\nx\\ni\\n de \\nX\\n \\nfaça\\n    estender \\ne\\n com valor \\nxi\\n para \\nX\\n        \\nQ\\n(\\nxi\\n) ← ENUMERAR-TODOS(\\nbn.\\nVARS, e\\nxi\\n)\\nWhere \\ne\\nxi\\n é \\ne\\n estendido com \\nX\\n = \\nx\\ni\\n    \\nretornar\\n NORMALIZAR(\\nQ\\n(\\nX\\n))\\n_____________________________________________________________________________________________________________\\nfunção\\n ENUMERAR-TODOS(\\nvars\\n, \\ne\\n) \\nretorna\\n um número real\\n    \\nse\\n VAZIO?(\\nvars\\n) \\nentão retornar\\n 1,0\\n    \\nY\\n ← PRIMEIRO(\\nvars\\n)\\n    \\nse\\n \\nY\\n tem valor \\ny\\n em \\ne\\n    \\nentão retornar\\n \\nP\\n(\\ny\\n | \\npais\\n(\\nY\\n)) × ENUMERAR-TODOS(RESTO(\\nvars\\n), \\ne\\n)\\n    senão retornar Σ\\ny\\n P(\\ny\\n | pais(y)) × ENUMERAR-TODOS (vars), e\\ny\\n)\\n        onde \\ne\\nyi\\n é \\ne\\n estendido com \\nY\\n = \\ny\\ni\\nFigura 14.9\\n O algoritmo de enumeração para responder a consultas sobre redes bayesianas.\\nDesse modo, a complexidade de espaço de ASK-ENUMERAÇÃO só é linear no número de\\nvariáveis: efetivamente, o algoritmo efetua o somatório sobre a distribuição conjunta total sem\\njamais construí-la de forma explícita. Infelizmente, sua complexidade de tempo para uma rede com \\nn\\nvariáveis booleanas é sempre \\nO\\n(2\\nn\\n) — melhor que o valor \\nO\\n(\\nn\\n2\\nn\\n) para a abordagem simples\\ndescrita anteriormente, mas ainda terrível.\\nObserve que a árvore da \\nFigura 14.8\\n torna explícitas as \\nsubexpressões repetidas\\n que são\\navaliadas pelo algoritmo. Os produtos \\nP\\n(\\nj\\n | \\na\\n)\\nP\\n(\\nm\\n | \\na\\n) e \\nP\\n( \\nj\\n | ¬\\na\\n)\\nP\\n(\\nm\\n | ¬\\na\\n) são calculados duas\\nvezes, uma para cada valor de \\ne\\n. A próxima seção descreve um método geral que evita esse\\ndesperdício de computações.\\n14.4.2 O algoritmo de eliminação de variáveis\\nO algoritmo de enumeração pode ser substancialmente melhorado eliminando-se cálculos\\nrepetidos do tipo ilustrado na \\nFigura 14.8\\n. A ideia é simples: efetuar o cálculo apenas uma vez e\\nguardar os resultados para uso posterior. Essa é uma forma de programação dinâmica. Existem várias\\nversões dessa abordagem; apresentamos o algoritmo de \\neliminação de variáveis\\n, que é a mais\\nsimples. A eliminação de variáveis funciona avaliando expressões como a Equação 14.4 na ordem\\nda direita para a esquerda\\n (isto é, \\nde baixo para cima\\n na \\nFigura 14.8\\n). Os resultados intermediários\\nsão armazenados, e os somatórios sobre cada variável são efetuados apenas para as porções da', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 614}),\n",
       " Document(page_content='expressão que dependem da variável.\\nVamos ilustrar esse processo para a rede de alarme contra roubo. Avaliamos a expressão:\\nObserve que identificamos cada parte da expressão com o nome do \\nfator\\n correspondente; cada\\nfator é uma matriz indexada pelos valores das variáveis de seu argumento. Por exemplo, os fatores\\nf\\n4\\n(A) e f\\n5\\n(A) correspondentes a \\nP\\n(\\nj\\n | \\na\\n) e \\nP\\n(\\nm\\n | \\na\\n) dependem apenas de \\nA\\n porque \\nJ\\n e \\nM\\n são fixados\\npela consulta. Eles são, portanto, vetores de dois elementos:\\nf\\n3\\n(\\nA, B, E\\n) será uma matriz 2 × 2 × 2, que é difícil de mostrar na página impressa. (O “primeiro”\\nelemento é dado por \\nP\\n(\\na\\n | \\nb,\\n \\ne\\n) = 0,95 e o “último” por \\nP\\n(¬\\na\\n | ¬\\nb\\n, ¬\\ne\\n) = 0,999.) Em termos de\\nfatores, a expressão de consulta é escrita como\\nonde o operador “×” não é uma matriz ordinária de multiplicação, mas a operação do \\nproduto\\npontual\\n, que será descrito brevemente.\\nO processo de avaliação é um processo de somar variáveis (da direita para a esquerda) dos\\nprodutos de fatores pontuais para produzir fatores novos, eventualmente gerando um fator que seja\\numa solução, ou seja, a distribuição posterior sobre a variável de consulta. As etapas são as\\nseguintes:\\n•  Em primeiro lugar, somamos A do produto de f\\n3\\n, f\\n4\\n e f\\n5\\n. Isso nos dá um fator novo 2 × 2 f\\n6\\n (\\nB\\n, \\nE\\n)\\ncujas faixas de índices vão de \\nB\\n a \\nE\\n:\\nAgora ficamos com a expressão\\n•  Em seguida, somamos E do produto de \\nf\\n2\\n e \\nf\\n6\\n:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 615}),\n",
       " Document(page_content='Fica a expressão\\nque pode ser avaliada extraindo o produto pontual e normalizando o resultado.\\nExaminando essa sequência de etapas, vemos que existem duas operações computacionais básicas\\nexigidas: o produto pontual de um par de fatores e o somatório de uma variável de um produto de\\nfatores. A próxima seção descreve cada uma dessas operações.\\nOperações com fatores\\nO produto pontual de dois fatores \\nf\\n1\\n e \\nf\\n2\\n gera um novo fator \\nf\\n cujas variáveis são a \\nunião\\n das\\nvariáveis contidas em \\nf\\n1\\n e \\nf\\n2\\n e cujos elementos são dados pelo produto dos elementos\\ncorrespondentes em dois fatores. Suponha que os dois fatores tenham variáveis \\nY\\n1\\n, …, \\nY\\nk\\n em comum.\\nEntão, temos:\\nSe todas as variáveis forem binárias, então \\nf\\n1\\n e \\nf\\n2\\n terão 2\\nj+k\\n e 2\\nk+l\\n entradas, respectivamente, e o\\nproduto pontual terá 2\\nj+k+l\\n entradas. Por exemplo, dados dois fatores \\nf\\n1\\n(\\nA\\n, \\nB\\n) e \\nf\\n2\\n(\\nB\\n, \\nC\\n), o produto\\npontual f\\n1\\n × f\\n2\\n = f\\n3\\n (\\nA\\n, \\nB\\n, \\nC\\n) tem 2\\n1+1+1\\n = 8 entradas, como ilustrado na \\nFigura 14.10\\n. Note que o fator\\nresultante de um produto pontual pode conter mais variáveis que qualquer um dos fatores que estão\\nsendo multiplicadas e que o tamanho de um fator é exponencial ao número de variáveis. Esse é o\\nlugar onde a complexidade de espaço e de tempo surge na variável algoritmo de eliminação.\\nA\\nB\\nf\\n1\\n(\\nA\\n, \\nB\\n)\\nB\\nC\\nf\\n2\\n(\\nB\\n, \\nC\\n)\\nA\\nB\\nC\\nf\\n3\\n(\\nA\\n, \\nB\\n, \\nC\\n)\\nV\\nV\\nF\\nF\\nV\\nF\\nV\\nF\\n0,3\\n0,7\\n0,9\\n0,1\\nV\\nV\\nF\\nF\\nV\\nF\\nV\\nF\\n0,2\\n0,8\\n0,6\\n0,4\\nV\\nV\\nV\\nV\\nF\\nF\\nF\\nF\\nV\\nV\\nF\\nF\\nV\\nV\\nF\\nF\\nV\\nF\\nV\\nF\\nV\\nF\\nV\\nF\\n0,3 × 0,2 = 0,06\\n0,3 × 0,8 = 0,24\\n0,7 × 0,6 = 0,42\\n0,7 × 0,4 = 0,28\\n0,9 × 0,2 = 0,18\\n0,9 × 0,8 = 0,72\\n0,1 × 0,6 = 0,06\\n0,1 × 0,4 = 0,04\\nFigure 14.10\\n Ilustração da multiplicação pontual: \\nf\\n1\\n(\\nA,B\\n) × \\nf\\n2\\n(\\nB,C\\n) = \\nf\\n3\\n(\\nA,B,C\\n).\\nA soma de uma variável de um produto de fatores é efetuada pela adição de submatrizes que são\\nformadas fixando a variável em cada um de seus valores por vez. Por exemplo, para a soma de \\nA\\nf\\n3\\n(\\nA\\n, \\nB\\n, \\nC\\n), escrevemos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 616}),\n",
       " Document(page_content='O único truque é notar que qualquer fator que \\nnão\\n dependa da variável a ser somada pode ser\\nmovido para fora do somatório. Por exemplo, se quiséssemos somar primeiro \\nE\\n na rede de roubo, a\\nparte relevante da expressão seria\\nAgora o produto pontual dentro do somatório é calculado, e a variável é a soma da matriz\\nresultante.\\nNote que as matrizes \\nnão\\n são multiplicadas até precisarmos efetuar o somatório de uma variável a\\npartir do produto acumulado. Nesse ponto, multiplicamos apenas as matrizes que incluem a variável\\na ser totalizada.\\nDadas as rotinas para produto pontual e somatório, o próprio algoritmo de eliminação de variáveis\\npode ser escrito de forma bastante simples, como mostra a \\nFigura 14.11\\n.\\nfunção\\n ASK-ELIMINAÇÃO(\\nX\\n, \\ne\\n, \\nrb\\n) \\nretorna\\n uma distribuição sobre \\nX\\n    \\nentradas:\\n \\nX\\n, a variável de consulta\\ne\\n, variáveis observadas da variável \\nE\\nrb\\n, uma rede bayesiana especificando a distribuição conjunta \\nP\\n(\\nX\\n1\\n, ..., \\nX\\nn\\n)\\n    \\n    \\nfatores\\n ← [ ]\\n    \\npara cada\\n \\nvar\\n \\nem\\n ORDEM\\n(rb.\\nVARS\\n)\\n \\nfaça\\n        \\nfatores\\n ← [CRIAR-FATOR (\\nvar\\n, \\ne\\n) \\nfatores\\n]\\n        \\nse\\n \\nvar\\n é uma variável oculta \\nentão\\n \\nfatores\\n ← SOMAR(\\nvar\\n | \\nfatores\\n)\\n    \\nretornar\\n NORMALIZAR(PRODUTO-PONTUAL(\\nfatores\\n))\\nFigura 14.11\\n Algoritmo de eliminação de variáveis para inferência nas redes bayesianas.\\nOrdenação e relevância de variáveis \\u200b\\u200b\\nO algoritmo na \\nFigura 14.11\\n inclui uma função ORDEM não especificada para escolher uma\\nordenação para as variáveis. Cada escolha de ordenação produz um algoritmo válido, mas\\nordenações diferentes fazem com que seja gerado durante o cálculo fatores intermediários diferentes.\\nPor exemplo, no cálculo mostrado anteriormente, eliminamos \\nA\\n antes de \\nE\\n; se fizermos o contrário, o\\ncálculo torna-se\\ndurante o qual um novo fator \\nf\\n6\\n(\\nA\\n, \\nB\\n) será gerado.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 617}),\n",
       " Document(page_content='Em geral, os requisitos de tempo e de espaço de eliminação de variáveis são dominados pelo\\ntamanho do maior fator construído durante a operação do algoritmo. Este, por sua vez, é determinado\\npela ordem de eliminação de variáveis e pela estrutura da rede. Determinar a ordem ótima é\\nintratável, mas várias heurísticas boas ficam disponíveis. Um método bastante eficaz é o guloso:\\neliminar qualquer variável que minimize o tamanho do próximo fator a ser construído.\\nVamos considerar mais uma consulta: \\nP\\n(\\nJoãoLiga\\n | \\nRoubo\\n = \\nverdadeira\\n). Como sempre, o\\nprimeiro passo é escrever o somatório aninhado:\\n Se avaliarmos essa expressão da direita para a esquerda, notaremos algo interessante: \\nΣ\\nm\\nP\\n(\\nm|a\\n) é igual a 1 por definição! Consequentemente, não havia nenhuma necessidade de incluí-lo; a\\nvariável \\nM\\n é \\nirrelevante\\n para essa consulta. Outro modo de dizer isso é afirmar que o resultado da\\nconsulta \\nP\\n(\\nJoãoLiga\\n | \\nRoubo\\n = \\nverdadeira\\n) ficará inalterado se removermos completamente da rede\\nMariaLiga\\n. Em geral, podemos remover qualquer nó de folha que não seja uma variável de consulta\\nou uma variável de evidência. Depois de sua remoção, pode haver mais alguns nós folhas, e esses\\ntambém podem ser irrelevantes. Continuando com esse processo, descobriremos por fim que \\ntoda\\nvariável que não é um ancestral de uma variável de consulta ou de uma variável de evidência é\\nirrelevante para a consulta\\n. Um algoritmo de eliminação de variáveis pode portanto remover todas\\nessas variáveis antes de avaliar a consulta.\\n14.4.3 A complexidade da inferência exata\\n A complexidade da inferência exata em redes bayesianas depende fortemente da estrutura da\\nrede. A rede de alarme contra roubo da \\nFigura 14.2\\n pertence à família de redes em que existe, no\\nmáximo, um caminho não orientado entre dois nós quaisquer na rede. Essas redes são chamadas\\nredes unicamente conexas\\n ou \\npoliárvores\\n, e têm uma propriedade particularmente interessante: \\na\\ncomplexidade de tempo e de espaço da inferência exata em poliárvores é linear em relação ao\\ntamanho da rede\\n. Aqui, o tamanho é definido como o número de entradas de TPC; se o número de\\npais de cada nó estiver limitado por uma constante, a complexidade também será linear em relação\\nao número de nós.\\n No caso de \\nredes multiplamente conectadas\\n, como a da \\nFigura 14.12\\n(a), a eliminação de\\nvariáveis pode ter complexidade de tempo e de espaço exponencial no pior caso, mesmo quando o\\nnúmero de pais por nó é limitado. Isso não é surpreendente quando se considerar que, \\npelo fato de\\nincluir a inferência em lógica proposicional como um caso especial\\n, \\na inferência em redes\\nbayesianas é NP\\n-\\ndifícil\\n. De fato, podemos mostrar (Exercício 14.16) que o problema é tão difícil\\nquanto o de calcular o \\nnúmero\\n de atribuições satisfatórias para uma fórmula de lógica proposicional.\\nIsso significa que ele é #P-difícil (“número P difícil”), isto é, estritamente mais difícil que\\nproblemas NP-completos.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 618}),\n",
       " Document(page_content='Figura 14.12\\n (a) Rede multiplamente conectada às tabelas de probabilidade condicional. (b)\\nFormação de agrupamentos equivalentes a uma rede multiplamente conectada.\\nExiste uma conexão estreita entre a complexidade da inferência de redes bayesianas e a\\ncomplexidade de problemas de satisfação de restrições (PSRs). Conforme discutimos no Capítulo 6,\\na dificuldade de resolução de um PSR discreto está relacionada ao quanto seu grafo de restrições é\\n“semelhante a uma árvore”. Medidas como \\nlargura de rárvore\\n, que limitam a complexidade de\\nresolução de um PSR, também podem ser aplicadas diretamente a redes bayesianas. Além disso, o\\nalgoritmo de eliminação de variáveis pode ser generalizado para resolver PSRs, bem como redes\\nbayesianas.\\n14.4.4 Algoritmos de formação de agrupamentos\\nO algoritmo de eliminação de variáveis é simples e eficiente para responder a consultas\\nindividuais. Porém, se quisermos calcular as probabilidades posteriores para todas as variáveis em\\numa rede, talvez ele seja menos eficiente. Por exemplo, em uma rede de poliárvore, seria necessário\\nemitir \\nO\\n(\\nn\\n) consultas ao custo de \\nO\\n(\\nn\\n) cada uma, totalizando um tempo igual a \\nO\\n(\\nn\\n2\\n). Usando-se\\nalgoritmos de \\nformação de agrupamentos\\n (também conhecidos como algoritmos de \\nárvore de\\njunção\\n), o tempo pode ser reduzido a \\nO\\n(\\nn\\n). Por essa razão, esses algoritmos são amplamente usados\\nem ferramentas comerciais de rede bayesiana.\\nA ideia básica da formação de agrupamentos é unir nós individuais da rede para formar nós de\\nagrupamento, de tal modo que a rede resultante seja uma poliárvore. Por exemplo, a rede de várias\\nconexões mostrada na \\nFigura 14.12\\n(a) pode ser convertida em uma poliárvore combinando-se os nós\\nIrrigador\\n e \\nChuva\\n em um nó de agrupamento chamado \\nIrrigador\\n+\\nChuva\\n, como mostra a \\nFigura\\n14.12\\n(b). Os dois nós booleanos são substituídos por um “meganó” que assume quatro valores\\npossíveis: \\ntt\\n, \\ntf\\n, \\nft\\n e \\nff\\n. O meganó tem apenas um pai, a variável booleana \\nNublado\\n e, assim, existem\\ndois casos de condicionamento. Apesar do exemplo não mostrar isso, o processo de formação de\\nagrupamentos sempre produz meganós que compartilham algumas variáveis.\\nUma vez que a rede está em forma de poliárvore, é requerido um algoritmo de inferência de uso\\nespecial porque métodos de inferência ordinária não podem manusear meganós que compartilham\\nvariáveis uns com os outros. Em essência, o algoritmo é uma forma de propagação de restrições', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 619}),\n",
       " Document(page_content='(veja o Capítulo 6) em que as restrições garantem que os agrupamentos vizinhos concordam sobre a\\nprobabilidade posterior de quaisquer variáveis que eles tenham em comum. Com uma contabilidade\\ncuidadosa, esse algoritmo é capaz de calcular probabilidades posteriores para todos os nós que não\\nsão de evidência na rede no tempo \\nlinear\\n no tamanho da rede com agrupamentos. No entanto, a NP-\\ndificuldade do problema não desapareceu: se uma rede exigir tempo e espaço exponenciais com a\\neliminação de variáveis, as TPCs na rede com agrupamentos necessariamente serão\\nexponencialmente grandes.\\n14.5 INFERÊNCIA APROXIMADA EM REDES BAYESIANAS\\nDada a intratabilidade da inferência exata em redes extensas com várias conexões, é essencial\\nconsiderar métodos de inferência aproximada. Esta seção descreve algoritmos de amostragem\\naleatória, também chamados algoritmos de \\nMonte Carlo\\n, que fornecem respostas aproximadas cuja\\nexatidão depende do número de amostras geradas. Em anos recentes, os algoritmos de Monte Carlo\\ndos quais a têmpera simulada é um exemplo, são utilizados em muitas ramificações da ciência da\\ncomputação para estimar quantidades que são difíceis de calcular com exatidão. Nesta seção,\\nestamos interessados na amostragem aplicada à computação de probabilidades posteriores.\\nDescreveremos duas famílias de algoritmos: amostragem direta e amostragem de cadeias de Markov.\\nDuas outras abordagens — métodos variacionais e propagação com laços — serão mencionadas nas\\nnotas no final do capítulo.\\n14.5.1 Métodos de amostragem direta\\nO elemento primitivo em qualquer algoritmo de amostragem é a geração de amostras a partir de\\numa distribuição de probabilidade conhecida. Por exemplo, uma moeda imparcial pode ser\\nconsiderada uma variável aleatória \\nMoeda\\n com os valores \\n〈\\ncara\\n, \\ncoroa\\n〉\\n e uma distribuição \\na priori\\nP\\n(\\nMoeda\\n) = \\n〈\\n0,5, 0,5\\n〉\\n. A amostragem a partir dessa distribuição é exatamente igual ao lançamento\\nda moeda: com probabilidade 0,5 ela retornará \\ncara\\n, e com probabilidade 0,5 retornará \\ncoroa\\n. Dada\\numa fonte de números aleatórios uniformemente distribuídos no intervalo [0, 1], é uma questão\\nsimples realizar a amostragem de qualquer distribuição sobre uma única variável, se discreta ou\\ncontínua (veja o Exercício 14.17).\\nA espécie mais simples de processo de amostragem aleatória para redes bayesianas gera eventos a\\npartir de uma rede que não tem nenhuma evidência associada a ela. A ideia é fazer a amostragem uma\\nvariável de cada vez, em ordem topológica. A distribuição de probabilidade a partir da qual se\\nobtém uma amostra do valor está condicionada aos valores já atribuídos aos pais da variável. Esse\\nalgoritmo é apresentado na \\nFigura 14.13\\n. Podemos ilustrar sua operação sobre a rede da \\nFigura\\n14.12\\n(a) supondo uma ordenação [\\nNublado\\n, \\nIrrigador\\n, \\nChuva\\n, \\nGramaMolhada\\n]:\\nfunção\\n AMOSTRA-A-PRIORI(\\nrb\\n) \\nretorna\\n um evento amostrado a partir da probabilidade \\na\\npriori\\n especificada por \\nrb', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 620}),\n",
       " Document(page_content='entradas:\\n \\nrb,\\n uma rede bayesiana que especifica a distribuição conjunta \\nP\\n(\\nX\\n1\\n, ..., \\nX\\nn\\n)\\n    \\n    \\nx\\n ← um evento com \\nn\\n elementos\\n    \\npara cada\\n variável X\\ni\\n, \\nem\\n X\\n1\\n,....,X\\nn\\n \\nfaça\\n        \\nx\\n[\\ni\\n] ← \\nu\\nma amostra aleatória de \\nP\\n(\\nX\\ni\\n | \\npais\\n(\\nX\\ni\\n))\\n    \\nretornar x\\nFigura 14.13\\n Um algoritmo de amostragem que gera eventos de uma rede bayesiana. Cada variável é\\namostrada de acordo com a distribuição condicional dados os valores já amostrados para os pais da\\nvariável.\\n1. Amostra de \\nP\\n(\\nNublado\\n) = \\n〈\\n0,5, 0,5\\n〉\\n; valor é \\nverdadeiro\\n.\\n2. Amostra de \\nP\\n(\\nIrrigador\\n | \\nNublado\\n = \\nverdadeiro\\n) = \\n〈\\n0,1, 0,9\\n〉\\n; valor é \\nfalso\\n.\\n3. Amostra de \\nP\\n(\\nChuva\\n | \\nNublado\\n = \\nverdadeiro\\n) = \\n〈\\n0,8, 0,2\\n〉\\n; valor é \\nverdadeiro\\n.\\n4. Amostra de \\nP\\n(\\nGramaMolhada\\n | \\nIrrigador\\n, = \\nfalso\\n, \\nChuva\\n = \\nverdadeiro\\n) = \\n〈\\n0,9, 0,1\\n〉\\n; valor é\\nverdadeiro\\n.\\nNesse caso, AMOSTRA-\\nA-PRIORI\\n retorna o evento [\\nverdadeiro\\n, \\nfalso\\n, \\nverdadeiro\\n, \\nverdadeiro\\n].\\nÉ fácil ver que AMOSTRA-A-PRIORI gera amostras a partir da distribuição conjunta \\na priori\\nespecificada pela rede. Primeiro, seja \\nS\\nPS\\n(\\nx\\n1\\n, …, \\nx\\nn\\n) a probabilidade de um evento específico ser\\ngerado pelo algoritmo AMOSTRA-A-PRIORI. \\nApenas observando o processo de amostragem\\n,\\ntemos:\\nporque cada etapa de amostragem depende apenas dos valores dos pais. Essa expressão deve\\nparecer familiar porque também é a probabilidade do evento de acordo com a representação da rede\\nbayesiana da distribuição conjunta, conforme observamos na Equação 14.2. Isto é, temos:\\nEsse fato simples torna muito fácil responder a perguntas utilizando amostras.\\nEm qualquer algoritmo de amostragem, as respostas são calculadas efetuando-se a contagem das\\namostras reais geradas. Suponha que existam \\nN\\n amostras ao todo e seja \\nN\\nPS\\n(\\nx\\n1\\n, …, \\nx\\nn\\n) o número de\\nvezes que o evento específico \\nx\\n1\\n, …, \\nx\\nn\\n ocorre no conjunto de amostras. Esperamos que esse número\\nseja uma fração do total para convergir no limite para seu valor esperado de acordo com a\\nprobabilidade de amostragem:\\nPor exemplo, considere o evento produzido anteriormente: [\\nverdadeiro\\n, \\nfalso\\n, \\nverdadeiro\\n,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 621}),\n",
       " Document(page_content='verdadeiro\\n]. A probabilidade de amostragem para esse evento é:\\nS\\nPS\\n(\\nverdadeiro\\n, \\nfalso\\n, \\nverdadeiro\\n, \\nverdadeiro\\n) = 0,5 × 0,9 × 0,8 × 0,9 = 0,324.\\nConsequentemente, no limite de \\nN\\n grande, esperamos que 32,4% das amostras sejam desse evento.\\nSempre que usamos uma igualdade aproximada (“≈”) no que se segue, queremos indicar\\nexatamente esse sentido — que a probabilidade estimada se torna exata no limite de uma amostra\\ngrande. Tal estimativa é chamada \\nconsistente\\n. Por exemplo, pode-se produzir uma estimativa\\nconsistente da probabilidade de qualquer evento parcialmente especificado, \\nx\\n1\\n, …, \\nx\\nm\\n, onde \\nm\\n ≤ \\nn\\n,\\ncomo a seguir:\\nOu seja, a probabilidade do evento pode ser estimada como a fração de todos os eventos\\ncompletos gerados pelo processo de amostragem que correspondem ao evento parcialmente\\nespecificado. Por exemplo, se gerarmos 1.000 amostras da rede de irrigadores e 511 delas tiverem\\nChuva\\n = \\nverdadeiro\\n, então a probabilidade estimada de chuva, escrita como \\n(\\nChuva\\n =\\nverdadeiro\\n), será 0,511.\\nAmostragem de rejeição em redes bayesianas\\nA \\namostragem de rejeição\\n é um método geral para produzir amostras a partir de uma distribuição\\ndifícil de amostrar, dada uma distribuição fácil de amostrar. Em sua forma mais simples, ela pode\\nser usada para calcular probabilidades condicionais, isto é, para determinar \\nP\\n(\\nX\\n | \\ne\\n). O algoritmo\\nAMOSTRAGEM-DE-REJEIÇÃO é representado na \\nFigura 14.14\\n. Primeiro, ele gera amostras a\\npartir da distribuição \\na priori\\n especificada pela rede. Em seguida, rejeita todas as que não\\ncorrespondem à evidência. Finalmente, a estimativa \\n(\\nX\\n = \\nx\\n | \\ne\\n) é obtida pela contagem da\\nfrequência com que \\nX\\n = \\nx\\n ocorre nas amostras restantes.\\nfunção\\n AMOSTRAGEM-DE-REJEIÇÃO(\\nX\\n, \\ne\\n, \\nrb\\n, \\nN\\n) \\nretorna\\n uma estimativa de \\nP\\n(X\\n | \\ne\\n)\\n    \\nentradas:\\n \\nX\\n, a variável de consulta\\ne\\n, valores observados para variáveis \\nE\\nrb\\n, uma rede bayesiana\\nN\\n, o número total de amostras a serem geradas\\n    \\nvariáveis locais: N\\n, um vetor de contagens para cada valor de \\nX\\n, inicialmente zero\\n    \\npara\\n \\nj\\n = 1 \\naté\\n \\nN\\n \\nfaça\\n        \\nx\\n ← AMOSTRA-A-PRIORI(\\nrb\\n)\\n        \\nse x\\n é consistente com \\ne então\\n            \\nN\\n[\\nx\\n] ← \\nN\\n[\\nx\\n]+1 onde \\nx\\n é o valor de \\nX\\n em \\nx\\n    \\nretornar\\n NORMALIZAR(\\nN\\n)\\nFigura 14.14\\n O algoritmo de amostragem de rejeição para responder a consultas, dada a evidência\\nem uma rede bayesiana.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 622}),\n",
       " Document(page_content='Seja \\n(\\nX\\n | \\ne\\n) a distribuição estimada que o algoritmo retorna. A partir da definição do algoritmo,\\ntemos:\\nA partir da Equação 14.6, isso se transforma em:\\nOu seja, a amostragem de rejeição produz uma estimativa consistente da probabilidade verdadeira.\\nContinuando com nosso exemplo da \\nFigura 14.12\\n(a), vamos supor que desejamos estimar\\nP\\n(\\nChuva\\n|\\nIrrigador\\n = \\nverdadeiro\\n), utilizando 100 amostras. Das 100 amostras que geramos, suponha\\nque 73 tenham \\nIrrigador\\n = \\nfalso\\n e sejam rejeitadas, enquanto 27 têm \\nIrrigador\\n = \\nverdadeiro\\n; destas,\\n27, 8 têm \\nChuva\\n = \\nverdadeiro\\n e 19 têm \\nChuva\\n = \\nfalso\\n. Consequentemente,\\nP\\n(\\nChuva\\n | \\nIrrigador\\n = \\nverdadeiro\\n) ≈ NORMALIZAR(\\n〈\\n8, 19\\n〉\\n) = \\n〈\\n0,296, 0,704\\n〉\\n.\\nA resposta verdadeira é \\n〈\\n0,3, 0,7\\n〉\\n. À medida que mais amostras forem coletadas, a estimativa\\nconvergirá para a resposta verdadeira. O desvio-padrão do erro em cada probabilidade será\\nproporcional a \\n, onde \\nn\\n é o número de amostras usadas na estimativa.\\nO maior problema com a amostragem de rejeição é que ela rejeita muitas amostras! A fração de\\namostras consistentes com a evidência \\ne\\n cai exponencialmente conforme o número de variáveis de\\nevidência cresce e, assim, o procedimento é simplesmente inútil para problemas complexos.\\nNote que a amostragem de rejeição é muito semelhante à avaliação de probabilidades\\ncondicionais diretamente do mundo real. Por exemplo, para estimar \\nP\\n(\\nChuva\\n | \\nCéuVermelhoNoite\\n =\\nverdadeiro\\n), pode-se simplesmente contar com que frequência chove depois que se observa um céu\\nvermelho na noite anterior — ignorando-se as noites em que o céu não está vermelho (aqui, o próprio\\nmundo desempenha o papel do algoritmo de geração de amostras). É óbvio que isso poderia tomar\\num longo tempo, se o céu só muito raramente ficasse vermelho, e essa é a deficiência da amostragem\\nde rejeição.\\nPonderação de probabilidade\\nA \\nponderação de probabilidade\\n evita a ineficiência da amostragem de rejeição gerando apenas\\neventos consistentes com a evidência \\ne\\n. É uma instância particular da técnica estatística geral de\\namostragem de importância\\n, sob medida para inferência em redes bayesianas. Começamos\\ndescrevendo como o algoritmo funciona; em seguida, mostraremos que ele funciona corretamente,\\nisto é, gera estimativas de probabilidade consistentes.\\nA PONDERAÇÃO-DE-PROBABILIDADE (veja a \\nFigura 14.15\\n) fixa os valores para as variáveis\\nde evidência \\nE\\n e amostras apenas de variáveis ocultas. Isso garante que cada evento gerado será\\nconsistente com a evidência. Porém, nem todos os eventos são iguais. Antes de efetuar as contas na\\ndistribuição para a variável de consulta, cada evento é ponderado pela \\nprobabilidade\\n de que o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 623}),\n",
       " Document(page_content='evento concorde com a evidência, medida pelo produto das probabilidades condicionais para cada\\nvariável de evidência, dados seus pais. Intuitivamente, eventos em que a evidência real parece\\nimprovável devem receber menor peso.\\nfunção\\n PONDERAÇÃO-DE-PROBABILIDADE (\\nX\\n, \\ne\\n, \\nrb\\n, \\nN\\n) \\nretorna\\n uma estimativa de \\nP\\n(\\nX\\n | \\ne\\n)\\n    \\nentradas:\\n \\nX\\n, a variável de consulta\\ne\\n, valores observados para variáveis \\nE\\nrb\\n, uma rede bayesiana especificando distribuição conjunta \\nP\\n(\\nX\\n1\\n,....,\\nX\\nn\\n)\\nN\\n, o número total de amostras a serem geradas\\n    \\nvariáveis locais: W\\n, um vetor de contagens ponderadas para cada valor de \\nX\\n, inicialmente igual a zero\\n    \\npara\\n \\nj\\n = 1 \\naté\\n \\nN\\n \\nfaça\\n        \\nx\\n, \\nw\\n ← AMOSTRA-PONDERADA(\\nrb, e\\n)\\n        \\nW\\n[\\nx\\n] ← \\nW\\n[\\nx\\n] + \\nw\\n onde \\nx\\n é o valor de \\nX\\n em \\nx\\n    \\nretornar\\n NORMALIZAR(\\nW\\n)\\n_____________________________________________________________________________________________________________\\nfunção\\n AMOSTRA-PONDERADA(\\nrb\\n, \\ne\\n) \\nretorna\\n um evento e um peso\\n    \\nw\\n ← 1; \\nx\\n ← um evento com \\nn\\n elementos inicializados de \\ne\\n    \\npara cada\\n variável \\nX\\ni\\n \\nem\\n \\nX\\n1\\n,....,\\nX\\nn\\n \\nfaça\\n        \\nse\\n \\nX\\ni\\n é uma variável de evidência com valor \\nx\\ni\\n em \\ne\\n            \\nentão\\n \\nw\\n ← \\nw\\n × \\nP\\n(\\nX\\ni\\n = \\nx\\ni\\n | \\npais\\n(\\nX\\ni\\n))\\n            \\nelse x\\n[\\ni\\n]←uma amostra aleatória de \\nP\\n(X\\ni\\n | pais(X\\ni\\n))\\n    \\nretornar x\\n, \\nw\\nFigura 14.15\\n Algoritmo de ponderação de probabilidade para inferência em redes bayesianas. Em\\nAMOSTRA-PONDERADA, cada variável oculta é amostrada de acordo com a distribuição\\ncondicional, dados os valores já amostrados para os pais da variável, enquanto um peso é acumulado\\nbaseado na probabilidade para cada variável de evidência.\\nVamos aplicar o algoritmo à rede apresentada na \\nFigura 14.12\\n(a), com a consulta \\nP\\n(\\nChuva\\n |\\nNublado\\n = \\nverdadeiro\\n, \\nGramaMolhada\\n = \\nverdadeiro\\n) e a ordenação \\nNublado,\\nIrrigador,Chuva,GramaMolhada\\n (qualquer ordem topológica vai funcionar). O processo se\\ndesenvolve assim: primeiro, o peso \\nw\\n é definido como 1.0. Em seguida, é gerado um evento:\\n1. \\nNublado\\n é uma variável de evidência com valor \\nverdadeiro\\n. Portanto, vamos definir\\nw\\n ← \\nw\\n × \\nP\\n(\\nNublado = verdadeiro\\n) = 0,5.\\n2. \\nIrrigador\\n não é uma variável de evidência, então a amostra de \\nP\\n(\\nIrrigador | Nublado =\\nverdadeiro\\n) = \\n〈\\n0,1, 0,9\\n〉\\n; suponha que retorne \\nfalso.\\n3. Da mesma forma, amostra de \\nP\\n(\\nChuva | Nublado = verdadeiro\\n) = \\n〈\\n0,8, 0,2\\n〉\\n; suponha que\\nretorne verdadeiro.\\n4. \\nGramaMolhada\\n é uma variável de evidência com valor \\nverdadeiro\\n. Portanto, definimos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 624}),\n",
       " Document(page_content='w\\n ← \\nw\\n × \\nP\\n(\\nGramaMolhada = verdadeiro | Irrigador = falso, Chuva = verdadeiro\\n) = 0,45.\\nNesse caso, AMOSTRA-PONDERADA retorna o evento [\\nverdadeiro\\n, \\nverdadeiro\\n, \\nverdadeiro\\n,\\nverdadeiro\\n] com peso 0,45, e isso é registrado sob \\nChuva\\n = \\nverdadeiro\\n.\\nPara entender por que a ponderação de probabilidade funciona, começamos examinando a\\ndistribuição de amostragem \\nS\\nWS\\n para AMOSTRA-PONDERADA. Lembre-se de que as variáveis de\\nevidência \\nE\\n são fixadas com valores \\ne\\n. Chamamos de variáveis \\nZ\\n que não são de evidência\\n(inclusive a variável de consulta \\nX\\n). O algoritmo realiza a amostragem de cada variável em \\nZ\\n dados\\nos valores de seus pais:\\nNote que \\nPais\\n(\\nZ\\ni\\n) pode incluir ambas, variáveis ocultas e de evidência. Diferentemente da\\ndistribuição \\na priori P\\n(\\nz\\n), a distribuição \\nS\\nWS\\n dedica alguma atenção à evidência: os valores\\namostrados para cada \\nZ\\ni\\n serão influenciados pela evidência entre os ancestrais de \\nZ\\ni\\n. Por exemplo,\\nquando é feita a amostra de \\nIrrigador\\n, o algoritmo presta atenção à evidência \\nNublado = verdadeiro\\nna sua variável pai. Por outro lado, \\nS\\nWS\\n dedica menor atenção à evidência do que a distribuição\\nposterior verdadeira \\nP\\n(\\nz\\n | \\ne\\n) porque os valores amostrados para cada \\nZ\\ni\\n \\nignoram\\n a evidência entre\\nos que não são ancestrais de \\nZ\\ni\\n.\\n5\\n Por exemplo, quando se tira amostra de \\nIrrigador\\n e \\nChuva\\n, o\\nalgoritmo ignora a evidência na variável filho \\nGramaMolhada =\\n \\nverdadeiro\\n; isso significa que vai\\ngerar muitas amostras com \\nIrrigador = falso e Chuva = falso\\n apesar do fato de que a evidência na\\nrealidade descarta esse caso.\\nO peso de probabilidade \\nw\\n constitui a diferença entre as distribuições de amostragem real e\\ndesejada. O peso para dada amostra \\nx\\n, composta de \\nz\\n e \\ne\\n, é o produto das probabilidades para cada\\nvariável de evidência, dados seus pais (dos quais alguns ou todos podem estar entre os valores \\nZ\\ni\\n):\\nMultiplicando as Equações 14.7 e 14.8, vemos que a probabilidade \\nponderada\\n de uma amostra\\ntem a forma particularmente conveniente:\\nporque os dois produtos abrangem todas as variáveis da rede, permitindo-nos utilizar a Equação 14.2\\npara a probabilidade conjunta.\\nAgora é fácil mostrar que as estimativas de ponderação de probabilidade são consistentes. Para\\nqualquer valor específico \\nx\\n de \\nX\\n, a probabilidade posterior estimada pode ser calculada como:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 625}),\n",
       " Document(page_content='Consequentemente, a ponderação de probabilidade retorna estimativas consistentes.\\nTendo em vista que a ponderação de probabilidade utiliza todas as amostras geradas, ela pode ser\\nmuito mais eficiente que a amostragem de rejeição. Entretanto, ela sofrerá uma degradação de\\ndesempenho à medida que o número de variáveis de evidência aumentar. Como muitas amostras\\nterão pesos muito baixos, consequentemente a estimativa ponderada será dominada pela minúscula\\nfração de amostras que concordam em uma proporção maior que uma probabilidade infinitesimal\\ncom a evidência. O problema será exacerbado se as variáveis de evidência ocorrerem mais\\ntardiamente na ordenação das variáveis porque as variáveis ocultas não terão evidência em seus pais\\ne ancestrais para guiar a geração de amostras. Isso significa que as amostras serão simulações que\\nterão pouca semelhança com a realidade sugerida pela evidência.\\n14.5.2 Inferência por simulação de cadeias de Markov\\nOs algoritmos de \\nMonte Carlo via cadeia de Markov\\n (CMMC) trabalham de forma bastante\\ndiferente da amostragem de rejeição e da ponderação de probabilidade. Em vez de gerar cada\\namostra a partir do zero, os algoritmos CMMC geram cada amostra, fazendo uma mudança aleatória\\nna amostra anterior. É útil, portanto, pensar em um algoritmo CMMC como estando em determinado\\nestado atual\\n especificando um valor para cada variável e gerando um \\nestado próximo\\n, fazendo\\nmudanças aleatórias no estado atual (se isso o faz lembrar a têmpera simulada do Capítulo 4 ou o\\nWALKSAT do Capítulo 7, deve-se ao fato de ambos serem membros da família CMMC).\\nDescrevemos aqui uma forma especial do CMMC chamada \\namostragem de Gibbs\\n, que é\\nespecialmente adequada para as redes bayesianas (outras formas, algumas delas muito mais\\npoderosas, serão discutidas nas notas ao final do capítulo). Vamos primeiro descrever o que o\\nalgoritmo faz; depois explicaremos por que funciona.\\nA amostragem de Gibbs em redes bayesianas\\nO algoritmo de amostragem de Gibbs para redes bayesianas começa com um estado arbitrário\\n(com as variáveis de evidência fixadas em seus valores observados) e gera um estado próximo por\\namostrar aleatoriamente um valor para uma das variáveis ocultas \\nX\\ni\\n. A amostragem para \\nX\\ni\\n é feita\\ncondicionada sobre os valores atuais das variáveis na cobertura de Markov de X\\ni\\n (lembre-se de\\nque já vimos que a cobertura de Markov de uma variável consiste em seus pais, filhos e pais dos\\nfilhos). Então, o algoritmo vagueia ao acaso pelo espaço de estados — o espaço de atribuições\\ncompletas possíveis, invertendo uma variável de cada vez, mas mantendo fixas as variáveis de\\nevidência.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 626}),\n",
       " Document(page_content='Considere a consulta \\nP\\n(\\nChuva\\n | \\nIrrigador\\n = \\nverdadeiro\\n, \\nGramaMolhada\\n = \\nverdadeiro\\n) aplicada\\nà rede na \\nFigura 14.12\\n(a). As variáveis de evidência \\nIrrigador\\n e \\nGramaMolhada\\n são fixadas com\\nseus valores observados e as variáveis ocultas \\nNublado\\n e \\nChuva\\n são inicializadas aleatoriamente —\\ndigamos que elas sejam inicializadas como \\nverdadeiro\\n e \\nfalso\\n, respectivamente. Desse modo, o\\nestado inicial é [\\nverdadeiro\\n, \\nverdadeiro\\n, \\nfalso\\n, \\nverdadeiro\\n]. Agora as etapas a seguir são executadas\\nrepetidamente:\\n1. \\nNublado\\n é amostrada, dados os valores atuais de suas variáveis de cobertura de Markov: nesse\\ncaso, obtemos a amostra a partir de \\nP\\n(\\nNublado\\n | \\nIrrigador\\n = \\nverdadeiro\\n, \\nChuva\\n = \\nfalso\\n) (em\\nbreve, mostraremos como calcular essa distribuição). Suponha que o resultado seja \\nNublado\\n =\\nfalso\\n. Então, o novo estado atual é [\\nfalso\\n, \\nverdadeiro\\n, \\nfalso\\n, \\nverdadeiro\\n].\\n2. \\nChuva\\n é amostrada, dados os valores atuais de suas variáveis de cobertura de Markov: nesse\\ncaso, obtemos a amostra a partir de \\nP\\n(\\nChuva\\n | \\nNublado\\n = \\nfalso\\n, \\nIrrigador\\n = \\nverdadeiro\\n,\\nGramaMolhada\\n = \\nverdadeiro\\n). Suponha que isso produza \\nChuva\\n = \\nverdadeiro\\n. O novo estado\\natual é [\\nfalso\\n, \\nverdadeiro\\n, \\nverdadeiro\\n, \\nverdadeiro\\n].\\nCada estado visitado durante esse processo é uma amostra que contribui para a estimativa\\nreferente à variável de consulta \\nChuva\\n. Se o processo visitar 20 estados em que \\nChuva\\n tem valor\\nverdadeiro e 60 estados em que \\nChuva\\n tem valor falso, a resposta à consulta será\\nNORMALIZAR(\\n〈\\n20, 60\\n〉\\n) = \\n〈\\n0,25, 0,75\\n〉\\n. O algoritmo completo é mostrado na \\nFigura 14.16\\n.\\nfunção\\n ASK-GIBBS(\\nX\\n, \\ne\\n, \\nrb, N\\n) \\nretorna\\n uma estimativa de \\nP\\n(\\nX\\n | \\ne\\n)\\n    \\nvariáveis locais: N\\n, um vetor de contagens sobre \\nX\\n, inicialmente zero\\nZ\\n, as variáveis não de evidência em \\nrb\\nx\\n, o estado atual da rede, inicialmente copiado de \\ne\\n    inicializar \\nx\\n com valores aleatórios para as variáveis em \\nZ\\n    \\npara\\n \\nj\\n = 1 até \\nN\\n \\nfaça\\n        \\npara cada\\n \\nZ\\ni\\n \\nem Z faça\\n            fazer a amostragem do valor de \\nZ\\ni\\n em \\nx\\n a partir de \\nP\\n(\\nZ\\ni\\n | \\nmb\\n(\\nZ\\ni\\n))\\n            SALTO, V.O. 537\\n    \\nretornar\\n NORMALIZAR(\\nN\\n)\\nFigura 14.16\\n Algoritmo de amostragem de Gibbs para inferência aproximada em redes bayesianas;\\nessa versão passa por um ciclo através das variáveis, mas a escolha de variáveis aleatórias também\\nfunciona.\\nPor que o algoritmo de Gibbs funciona\\n Agora, mostraremos que a amostragem de Gibbs retorna estimativas consistentes para\\nprobabilidades posteriores. O material desta seção é bastante técnico, mas a afirmação básica é\\nsimples: \\no processo de amostragem se fundamenta em um “equilíbrio dinâmico” no qual a fração\\na longo prazo do tempo gasto em cada estado é exatamente proporcional à sua probabilidade', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 627}),\n",
       " Document(page_content='posterior\\n. Essa notável propriedade decorre da \\nprobabilidade de transição\\n específica com que o\\nprocesso passa de um estado para outro, definida pela distribuição condicional dada pela cobertura\\nde Markov da variável cuja amostra está sendo coletada.\\nSeja \\nθ\\n(\\nx\\n, → \\nx\\n′) a probabilidade de que o processo faça uma transição do estado \\nx\\n para o estado\\nx\\n′. Essa probabilidade de transição define o que se denomina \\ncadeia de Markov\\n sobre o espaço de\\nestados (as cadeias de Markov também se destacarão nos Capítulos 15 e 17). Agora, suponha que\\nexecutemos a cadeia de Markov para \\nt\\n etapas, e seja π\\nt\\n(\\nx\\n) a probabilidade de que o sistema esteja no\\nestado \\nx\\n no tempo \\nt\\n. De modo semelhante, seja \\nπ\\nt+1\\n(\\nx\\n′) a probabilidade de o sistema se encontrar no\\nestado \\nx\\n′ no tempo \\nt\\n + 1. Dado \\nπ\\nt\\n(\\nx\\n), podemos calcular \\nπ\\nt+1\\n(\\nx\\n′) efetuando o somatório da\\nprobabilidade de estar em um estado multiplicada pela probabilidade de fazer a transição para \\nx\\n′,\\npara todos os estados em que o sistema poderia se encontrar no tempo \\nt\\n:\\nDiremos que a cadeia alcançou sua \\ndistribuição estacionária\\n se \\nπ\\nt\\n = \\nπ\\nt\\n + 1\\n. Vamos chamar essa\\ndistribuição estacionária de π; sua equação de definição é portanto:\\nDesde que a distribuição de probabilidade de transição \\nθ\\n seja \\nergódica —\\n isto é, cada estado\\npode ser alcançado de todos os outros e não há ciclos rigorosamente periódicos —, existe\\nexatamente uma distribuição π que satisfaz essa equação para qualquer \\nθ\\n dado.\\nA Equação 14.10 pode ser interpretada com o significado de que o “fluxo de saída” esperado a\\npartir de cada estado (isto é, sua “população” atual) é igual ao “fluxo de entrada” de todos os\\nestados. Um modo óbvio de satisfazer esse relacionamento ocorre se o fluxo esperado entre qualquer\\npar de estados é o mesmo em ambos os sentidos, isto é,\\nQuando essas equações são válidas podemos dizer que \\nθ\\n(\\nx\\n→\\nx\\n′) está em \\nequilíbrio detalhado\\n com\\nπ(\\nx).\\nPodemos mostrar que o equilíbrio detalhado implica imutabilidade simplesmente efetuando o\\nsomatório sobre \\nx\\n na Equação 14.11. Temos:\\nonde a última etapa se segue porque temos a garantia de que vai ocorrer uma transição a partir de \\nx\\n′.\\nAgora, mostraremos que a probabilidade de transição \\nθ\\n(\\nx\\n, \\nx\\n′) definida pela etapa de amostragem\\nem GIBBS-ASK na verdade é um caso especial da definição mais geral da amostragem de Gibbs,\\nsegundo a qual cada variável é amostrada condicionalmente sobre os valores atuais de \\ntodas\\n as\\noutras variáveis. Começamos por mostrar que essa definição geral da amostragem de Gibbs satisfaz', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 628}),\n",
       " Document(page_content='a equação de balanço detalhado com uma distribuição estacionária igual a \\nP\\n(\\nx | e\\n), (a distribuição\\nposterior verdadeira sobre variáveis ocultas). Então, observamos simplesmente que, para redes\\nbayesianas, a amostragem condicionalmente em todas as variáveis é equivalente a fazer a\\namostragem condicional sobre a cobertura de Markov da variável.\\nPara analisar o amostrador geral de Gibbs, que faz a amostra de cada \\nX\\ni\\n por vez, com uma\\nprobabilidade de transição \\nθ\\ni\\n que impõe condições sobre todas as outras variáveis, definimos \\ncomo essas outras variáveis (exceto as variáveis de evidência); seus valores no estado atual são \\n. Se fizermos a amostragem de um novo valor \\nx\\n’\\ni\\n para \\nX\\ni\\n condicionalmente sobre todas as outras\\nvariáveis, inclusive a evidência, teremos:\\nAgora mostraremos que a probabilidade de transição para cada etapa da amostragem de Gibbs\\nestá em equilíbrio detalhado com a distribuição posterior verdadeira:\\nPodemos pensar no laço \\n“para cada\\n \\nZ\\ni\\n \\nem Z faça”\\n da \\nFigura 14.16\\n como definindo uma grande\\nprobabilidade de transição \\nθ\\n que é a composição sequencial \\nθ\\n1\\n \\no\\n \\nθ\\n2\\n \\no\\n…\\no\\n \\nθ\\nn\\n das probabilidades de\\ntransição para as variáveis individuais. É fácil mostrar (Exercício 14.19) que, se cada \\nθ\\ni\\n e \\nθ\\nj\\n tiver \\nπ\\ncomo distribuição estacionária, a composição sequencial \\nθ\\ni\\n \\no\\n \\nθ\\nj\\n também terá, daí a probabilidade de\\ntransição \\nθ\\n para o laço todo terá \\nP\\n(\\nx | e\\n) como sua distribuição estacionária. Finalmente, a menos\\nque os TPCs contenham probabilidades de 0 ou 1 — que pode fazer com que o espaço de estado se\\ntorne desconectado — é fácil verificar que \\nθ\\n é ergódica. Assim, as amostras geradas pela\\namostragem de Gibbs acabarão por ser extraídas eventualmente pela distribuição posterior\\nverdadeira.\\nA etapa final é mostrar como realizar a etapa de amostragem geral de Gibbs geral — amostragem\\nX\\ni\\n de \\nP\\n(\\nX\\ni\\n | \\n, e) — em uma rede bayesiana. Lembre-se que uma variável é independente de todas\\nas outras variáveis \\u200b\\u200bdada a cobertura de Markov; daí,\\nonde \\nmb\\n(\\nX\\ni\\n) denota os valores das variáveis na cobertura de Markov \\nX\\ni\\n, \\nMB\\n(\\nX\\ni\\n). Como mostrado no\\nExercício 14.7, a probabilidade de uma variável dada sua cobertura de Markov é proporcional à\\nprobabilidade da variável dados seus pais vezes a probabilidade de cada filho dados seus pais\\nrespectivos:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 629}),\n",
       " Document(page_content='Daí, para tornar cada variável \\nX\\ni\\n condicionada à sua cobertura de Markov, o número de\\nmultiplicações necessárias é igual ao número de filhos de \\nX\\ni\\n.\\n14.6 MODELOS DE PROBABILIDADE RELACIONAL E DE PRIMEIRA\\nORDEM\\n No Capítulo 8, explicamos as vantagens de representação apresentadas pela lógica de primeira\\nordem em comparação à lógica proposicional. A lógica de primeira ordem se refere à existência de\\nobjetos e relações entre eles, e pode expressar fatos sobre \\nalguns\\n ou \\ntodos\\n os objetos de um\\ndomínio. Com frequência, isso resulta em representações muito mais concisas que as descrições\\nproposicionais equivalentes. As redes bayesianas são essencialmente proposicionais: o conjunto de\\nvariáveis aleatórias é fixo e finito, e cada um tem um domínio fixo de valores possíveis. Esse fato\\nlimita a aplicabilidade das redes bayesianas. \\nSe pudermos encontrar um modo de combinar a teoria\\nda probabilidade com o poder de expressão das representações de primeira ordem\\n, \\nesperamos\\npoder aumentar drasticamente a variedade de problemas que podem ser tratados\\n.\\nPor exemplo, suponha que um varejista de livros on-line gostaria de fornecer avaliações globais\\nde produtos com base nas recomendações recebidas de seus clientes. Dada a evidência disponível, a\\navaliação assumirá a forma de distribuição posterior sobre a qualidade do livro. É a solução mais\\nsimples para basear a avaliação sobre a recomendação média, talvez com uma variação determinada\\npela quantidade de recomendações, mas sem levar em conta o fato de que alguns clientes são mais\\namáveis do que os outros e alguns são menos honestos do que outros. Os clientes gentis tendem a dar\\nboas recomendações, mesmo para livros bastante medíocres, enquanto os clientes desonestos dão\\nrecomendações muito boas ou muito ruins por outras razões que não a qualidade — por exemplo,\\npodem trabalhar para um editor.\\n6\\nPara um único cliente \\nC\\n1\\n, recomendando um único livro \\nB\\n1\\n, a rede de Bayes pode parecer como a\\nmostrada na \\nFigura 14.17\\n(a). (Assim como na \\nSeção 9.1\\n, as expressões com parênteses como\\nHonesto(\\nC\\n1\\n) são apenas símbolos de fantasia — nesse caso, nomes de fantasia para variáveis \\naleatórias.)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 630}),\n",
       " Document(page_content='Figura 14.17\\n (a) Rede de Bayes para um único cliente \\nC\\n1\\n recomendando um único livro \\nB\\n1\\n.\\nHonesto\\n(\\nC\\n1\\n) é booleana, enquanto as outras variáveis têm valores inteiros de 1 a 5. (b) Rede de\\nBayes com dois clientes e dois livros.\\nCom dois clientes e dois livros, a rede de Bayes se parece com a da \\nFigura 14.17\\n(b). Para\\nquantidades maiores de livros e clientes, torna-se completamente inviável especificar a rede\\nmanualmente.\\nFelizmente, a rede tem muita estrutura repetida. Cada variável \\nRecomendação\\n(\\nc\\n, \\nb\\n) tem as\\nvariáveis \\u200b\\u200b\\nHonesto\\n(\\nc\\n), \\nGentileza\\n(\\nc\\n) e \\nQualidade\\n(\\nb\\n) como seus pais. Além disso, os TPCs de todas as\\nvariáveis \\nRecomendação\\n(\\nc\\n, \\nb\\n) são idênticos, como o são aqueles de todas as variáveis \\nHonesto\\n(\\nc\\n),\\ne assim por diante. A situação parece feita sob medida para uma linguagem de primeira ordem.\\nGostaríamos de dizer algo como\\nRecomendação\\n(\\nc, b\\n) ~ \\nRecTPC(Honesto\\n(\\nc\\n), \\nGentileza\\n(\\nc\\n), \\nQualidade\\n(\\nb\\n))\\ncom o significado pretendido que a recomendação de um cliente para um livro depende da\\nhonestidade e gentileza do cliente e da qualidade do livro de acordo com alguns TPCs fixos. Esta\\nseção desenvolve uma linguagem que nos permite dizer exatamente isso e muito mais.\\n14.6.1 Mundos possíveis\\nLembre-se do Capítulo 13, que um modelo de probabilidade define um conjunto \\nΩ\\n de mundos\\npossíveis com probabilidade \\nP\\n(w) para cada mundo w. Para redes bayesianas, os mundos possíveis\\nsão atribuições de valores para as variáveis; para o caso booleano em particular, os mundos\\npossíveis são idênticos aos da lógica proposicional. Para o modelo de probabilidade de primeira\\nordem, então, parece que precisamos de mundos possíveis como aqueles da lógica de primeira\\nordem, isto é, um conjunto de objetos com relações entre eles e uma interpretação que mapeia\\nsímbolos constantes para objetos, símbolos predicados para relações e símbolos de função para\\nfunções sobre esses objetos (veja a \\nSeção 8.2\\n). O modelo também precisa definir uma probabilidade\\npara cada mundo possível, tal como uma rede bayesiana define uma probabilidade para cada\\natribuição de valores para as variáveis.\\nVamos supor, por um momento, que descobrimos como fazer isso. Então, como de costume,\\npodemos obter a probabilidade de qualquer sentença lógica de primeira ordem \\nф\\n como uma soma de\\nmundos possíveis onde ele é verdadeiro:\\nPode-se obter probabilidades condicionais \\nP\\n (\\nф\\n | \\ne\\n) de forma semelhante; assim, podemos, em\\nprincípio, fazer qualquer pergunta que quisermos sobre o nosso modelo — por exemplo: “Quais\\nlivros são mais propensos a ser altamente recomendados por clientes desonestos?” — e obter uma\\nresposta. Até agora, tudo bem.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 631}),\n",
       " Document(page_content='Há, no entanto, um problema: o conjunto de modelos de primeira ordem é infinito. Vimos isso\\nexplicitamente na \\nFigura 8.4\\n, o que mostraremos novamente na \\nFigura 14.18\\n (parte superior). Isso\\nsignifica (1) que o somatório da Equação 14.13 pode ser inviável e (2) especificar distribuição\\nconsistente e completa sobre um conjunto infinito de mundos poderia ser muito difícil.\\nFigura 14.18\\n Em cima: alguns membros do conjunto de todos os mundos possíveis para uma\\nlinguagem com dois símbolos constantes, \\nR\\n e \\nJ\\n, e um símbolo de relação binária, sob a semântica-\\npadrão da lógica de primeira ordem. Embaixo: os mundos possíveis sob a semântica de banco de\\ndados. A interpretação dos símbolos constantes é fixa, e há um objeto distinto para cada símbolo\\nconstante.\\nA \\nSeção 14.6.2\\n explora uma abordagem para lidar com esse problema. A ideia é não adotar a\\nsemântica-padrão de lógica de primeira ordem, mas a \\nsemântica do banco de dados\\n definida na\\nSeção 8.2.8\\n. A semântica de banco de dados assume a \\nhipótese de nomes únicos\\n — aqui, nós a\\nadotamos para símbolos constantes; ela também assume o \\nfecho do domínio\\n — não há mais objetos\\ndo que aqueles que recebem nomes. Podemos, então, garantir um conjunto finito de mundos possíveis\\nfazendo com que o conjunto de objetos em cada mundo seja exatamente o conjunto de símbolos\\nconstantes que são usados. Como mostrado na \\nFigura 14.18\\n (parte inferior), não há incerteza sobre o\\nmapeamento de símbolos a objetos ou sobre os objetos que existem. Chamamos os modelos definidos\\ndessa forma de \\nmodelos de probabilidade relacional\\n, ou MPRs.\\n7\\n A diferença mais significativa\\nentre a semântica de MPRs e a semântica de banco de dados apresentada na \\nSeção 8.2.8\\n é que MPRs\\nnão constroem o pressuposto de mundo fechado — obviamente, supor que cada fato desconhecido\\nseja falso não faz sentido em um sistema de raciocínio probabilístico!\\nQuando os pressupostos subjacentes da semântica do banco de dados não conseguem se manter, os\\nMPRs não funcionam bem. Por exemplo, um varejista de livro pode usar um ISBN (International\\nStandard Book Number) como símbolo constante para denominar cada livro, mesmo que determinado\\nlivro “lógico” (por exemplo, \\nE o vento levou\\n) possa ter vários ISBNs. Faria sentido agregar\\nrecomendações através de múltiplos ISBNs, mas o varejista pode não saber com certeza quais ISBNs\\nsão realmente o mesmo livro (note que não estamos reificando as \\ncópias individuais\\n do livro, o que\\npode ser necessário para as vendas de livros usados, vendas de carros, e assim por diante). Pior\\nainda, cada cliente é identificado por um ID de login, mas um cliente desonesto pode ter milhares de\\nIDs! No campo de segurança computacional, esses múltiplos Ids são chamados \\nsibilas\\n, e seu uso para', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 632}),\n",
       " Document(page_content='confundir um sistema de reputação é chamado de \\nataque sibila\\n. Assim, mesmo uma aplicação\\nsimples em um domínio on-line relativamente bem definido envolve tanto a \\nincerteza da existência\\n(que são os verdadeiros livros e clientes subjacentes aos dados observados) e a \\nincerteza de\\nidentidade\\n (cujo símbolo na verdade se refere ao mesmo objeto). É necessário encarar e definir\\nmodelos de probabilidade com base na semântica-padrão de lógica de primeira ordem, para a qual\\nos mundos possíveis variam nos objetos que contêm e nos mapeamentos de símbolos a objetos. A\\nSeção 14.6.3\\n mostra como fazer isso.\\n14.6.2 Modelos de probabilidade relacional\\nComo a lógica de primeira ordem, os MPRs têm símbolos de constantes, funções e predicados (é\\nmais fácil visualizar predicados como funções que retornam verdadeiro ou falso). Vamos também\\nassumir uma \\nassinatura de tipos\\n para cada função, ou seja, uma especificação do tipo de cada\\nargumento e do valor da função. Se o tipo de cada objeto for conhecido, muitos mundos possíveis\\nespúrios serão eliminados por esse mecanismo. Para o domínio recomendado pelo livro, os tipos são\\nCliente e Livro\\n, e as assinaturas dos tipos para as funções e predicados são as seguintes:\\nHonesto: Cliente\\n → {\\nverdadeiro, falso\\n}\\nGentileza : Cliente\\n → {1, 2, 3, 4, 5}\\nQualidade : Livro\\n →{1, 2, 3, 4, 5}\\nRecomendação : Cliente\\n × \\nLivro\\n → {1, 2, 3, 4, 5}\\nOs símbolos constantes serão os nomes dos clientes e livros que aparecem no conjunto dos dados\\ndo varejista. No exemplo dado anteriormente (\\nFigura 14.17\\n(b)), são \\nC\\n1\\n, \\nC\\n2\\n e \\nB\\n1\\n, \\nB\\n2\\n.\\nDadas as constantes e seus tipos, juntamente com as funções e seus tipos de assinaturas, as\\nvariáveis aleatórias do MPR são obtidas pela instanciação de cada função com cada combinação\\npossível de objetos: \\nHonest (C\\n1\\n), Qualidade (B\\n2\\n), Recomendação (C\\n1\\n, B\\n2\\n),\\n e assim por diante. Essas\\nsão exatamente as variáveis que aparecem na \\nFigura 14.17\\n(b). Como cada tipo tem apenas um\\nnúmero finito de instâncias, o número de variáveis \\u200b\\u200baleatórias básicas também é finito.\\nPara completar o MPR, temos que escrever as dependências que governam essas variáveis\\naleatórias. Há apenas uma declaração de dependência para cada função, onde cada argumento da\\nfunção é uma variável lógica (ou seja, uma variável que varia dentro dos limites dos objetos, como\\nna lógica de primeira ordem):\\nHonesto\\n(\\nc\\n) ~ \\n〈\\n0,99, 0,01\\n〉\\nGentileza\\n(c) ~ \\n〈\\n0,1, 0,1, 0,2, 0,3, 0,3\\n〉\\nQualidade\\n(b) ~ \\n〈\\n0,05, 0,2, 0,4, 0,2, 0,15\\n〉\\nRecomendação(c, b)\\n ~ \\nRecTPC (Honesto(c), Gentileza(c), Qualidade(b))\\nonde \\nRecTPC\\n é uma distribuição condicional definida separadamente com 2 × 5 × 5 = 50 linhas,\\ncada uma com cinco entradas. A semântica de MPR pode ser obtida pela instanciação dessas\\ndependências de todas as constantes conhecidas, resultando em uma rede bayesiana (como na \\nFigura\\n14.17\\n(b)) que define uma distribuição conjunta sobre as variáveis aleatórias MPR.\\n8', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 633}),\n",
       " Document(page_content='Podemos refinar o modelo, introduzindo uma \\nindependência específica de contexto\\n para refletir\\no fato de que os clientes desonestos ignoram a qualidade ao dar uma recomendação; além disso, a\\ngentileza não desempenha nenhum papel em suas decisões. A independência específica de contexto\\npermite que uma variável seja independente de alguns de seus pais dado certos valores das outras;\\nportanto, \\nRecomendação\\n(\\nc\\n, \\nb\\n) é independente de \\nGentileza\\n(\\nc\\n) e de \\nQualidade\\n(\\nb\\n) quando \\nHonesto\\n(\\nc\\n)\\n= falso:\\nFigura 14.19\\n Fragmento da rede de Bayes equivalente quando \\nAutor\\n(\\nB\\n2\\n) é desconhecido.\\nEsse tipo de dependência pode ser parecido com uma instrução simples se-então-senão em uma\\nlinguagem de programação, mas há uma diferença fundamental: o mecanismo de \\ninferência não sabe\\nnecessariamente o valor do teste condicional!\\nPodemos elaborar esse modelo de maneiras infinitas e torná-lo mais realista. Por exemplo,\\nsuponha que um cliente honesto que é fã de um autor de livro sempre dê 5 ao livro,\\nindependentemente da qualidade:\\nNovamente, o teste condicional \\nFã\\n(\\nc\\n, \\nAutor\\n(\\nb\\n)) é desconhecido, mas se o cliente dá apenas nota 5\\npara um autor de livros particular, e não é do tipo especialmente gentil, então é alta a probabilidade\\nposterior que o cliente seja fã do autor. Além disso, a distribuição posterior tenderá a descontar os 5\\ndo cliente na avaliação da qualidade dos livros daquele autor.\\nNo exemplo anterior, assumimos implicitamente que o valor de \\nAutor\\n(\\nb\\n) é conhecido para cada \\nb\\n,\\nmas esse pode não ser o caso. Como pode o sistema raciocinar, por exemplo, sobre se \\nC\\n1\\n é fã de\\nAutor\\n(\\nB\\n2\\n) quando \\nAutor\\n(\\nB\\n2\\n) é desconhecido? A resposta é que o sistema pode ter de raciocinar\\nsobre todos os autores possíveis. Suponha que (para simplificar) existam apenas dois autores, \\nA\\n1\\n e\\nA\\n2\\n. Então \\nAutor\\n(\\nB\\n2\\n) é uma variável aleatória com dois valores possíveis, \\nA\\n1\\n e \\nA\\n2\\n, e é pai de\\nRecomendação(C\\n1\\n, B\\n2\\n).\\n As variáveis \\nFã\\n\\u200b\\u200b(\\nC\\n1\\n, \\nA\\n1\\n) e \\nFã\\n (\\nC\\n1\\n, \\nA\\n2\\n) realmente influenciam a\\nrecomendação. A \\nFigura 14.19\\n mostra um fragmento da rede de Bayes equivalente. A incerteza no\\nvalor de \\nAutor\\n(\\nB\\n2\\n), que afeta a estrutura de dependência da rede, é um exemplo da \\nincerteza', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 634}),\n",
       " Document(page_content='relacional.\\nNo caso de você estar se perguntando como o sistema possivelmente pode descobrir quem é o\\nautor de \\nB\\n2\\n: considere a possibilidade de que três outros clientes são fãs de \\nA\\n1\\n (e não têm outros\\nautores favoritos em comum) e todos três deram 5 a \\nB\\n2\\n, embora a maioria dos outros clientes ache\\nisso bastante desanimador. Nesse caso, é extremamente provável que \\nA\\n1\\n seja o autor de \\nB\\n2\\n. O\\nsurgimento de raciocínio sofisticado como esse de um modelo MPR de apenas algumas linhas é um\\nexemplo interessante de como as influências probabilísticas se espalharam através da rede de\\ninterconexões entre os objetos no modelo. Como mais dependências e mais objetos foram\\nadicionados, a imagem transmitida pela distribuição posterior geralmente se torna cada vez mais\\nclara.\\nA próxima pergunta é como fazer inferência em MPRs. Uma abordagem é coletar as evidências,\\nprovas, consultas e símbolos constantes nesse sentido, construir a rede de Bayes equivalente e\\naplicar qualquer um dos métodos de inferência discutidos neste capítulo. Essa técnica é chamada\\ndesenrolar.\\n A desvantagem óbvia é que a rede de Bayes resultante pode ser muito grande. Além\\ndisso, se houver muitos objetos candidatos de uma relação ou função desconhecida — por exemplo,\\no autor desconhecido de \\nB\\n2\\n —, algumas variáveis \\u200b\\u200bna rede podem ter muitos pais.\\nFelizmente, pode ser feito muito para melhorar os algoritmos de inferência genérica. Primeiro, a\\npresença de estruturas repetidas na rede de Bayes desenrolada significa que muitos dos fatores\\nconstruídos durante a eliminação de variáveis (e tipos semelhantes de tabelas construídas agrupando\\nalgoritmos) será idêntico; esquemas de \\ncaching\\n eficazes produziram aumentos de velocidade de três\\nordens de magnitude para grandes redes. Em segundo lugar, os métodos de inferência desenvolvidos\\npara tirar proveito da independência do contexto específico nas redes de Bayes encontram muitas\\naplicações em MPRs. Terceiro, algoritmos de inferência CMMC têm algumas propriedades\\ninteressantes quando aplicados a MPRs com incerteza relacional. O CMMC trabalha com\\namostragem de mundos completos possíveis, então em cada estado a estrutura relacional é totalmente\\nconhecida. No exemplo dado anteriormente, cada estado CMMC deveria especificar o valor de\\nAutor\\n(\\nB\\n2\\n) e,assim, os outros autores em potencial não são mais os pais dos nós de recomendação de\\nB\\n2\\n. Então, a incerteza relacional não causa aumento na complexidade da rede para CMMC; em vez\\ndisso, o processo de CMMC inclui transições que alteram a estrutura relacional e, portanto, a\\nestrutura de dependência da rede desenrolada.\\nTodos os métodos que acabamos de descrever assumem que o MPR tem de ser parcial ou\\ntotalmente desenrolado em uma rede bayesiana. Isso é exatamente análogo ao método de\\nproposicionalização\\n de inferência lógica de primeira ordem. A resolução de provadores de teorema\\ne de sistemas de programação lógica evita proposicionalizar pela instanciação das variáveis lógicas\\nsomente quando necessário para fazer a inferência passar por tudo, isto é, \\nelevar\\n o processo de\\ninferência acima do nível de base de sentenças proposicionais e fazer com que cada etapa elevada\\nfaça o trabalho de muitas etapas de base. A mesma ideia se aplica à inferência probabilística. Por\\nexemplo, na variável algoritmo de eliminação, um fator elevado pode representar todo um conjunto\\nde fatores de base que atribuem probabilidades a variáveis aleatórias no MPR, onde as variáveis \\naleatórias diferem apenas nos símbolos constantes usados para construí-las. Os detalhes desse\\nmétodo vão além do escopo deste livro, mas são fornecidas referências ao final do capítulo.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 635}),\n",
       " Document(page_content='14.6.3 Modelos de probabilidade de universo aberto\\nArgumentamos anteriormente que a semântica de banco de dados é adequada a situações em que\\nsabemos exatamente o conjunto de objetos relevantes que existem e podem ser identificados de forma\\ninequívoca (em particular, todas as observações sobre um objeto são corretamente associadas ao\\nsímbolo constante que o denomina). Em muitos contextos do mundo real, no entanto, esses\\npressupostos são simplesmente insustentáveis. Demos os exemplos de ISBNs múltiplos e ataques\\nsibila no domínio de recomendação do livro (ao qual retornaremos em um instante), mas o fenômeno\\né muito mais abrangente:\\n•  Um sistema de visão não sabe o que existe, nem se há algo dobrando a próxima esquina, e pode\\nnão saber se o objeto que vê agora é o mesmo que viu há poucos minutos.\\n•  Um sistema de compreensão de texto não sabe com antecedência as entidades que serão\\napresentadas em um texto e deve inferir sobre se frases como “Mary”, “Dr. Smith”, “ela”, “seu\\ncardiologista”, “sua mãe”, e assim por diante, referem-se ao mesmo objeto.\\n•  Um analista da inteligência perseguindo espiões nunca sabe realmente quantos espiões existem e\\nsó pode adivinhar se vários pseudônimos, números de telefone e avistamentos dizem respeito ao\\nmesmo indivíduo.\\nNa verdade, grande parte da cognição humana parece exigir saber que objetos existem e, sendo\\ncapaz de conectar observações – as quais quase nunca vêm associadas a identificações únicas –,\\nconstruir hipóteses sobre objetos no mundo.\\nPor essas razões, precisamos ser capazes de descrever o chamado modelo de probabilidade de\\nuniverso aberto\\n ou MPUOs com base na semântica-padrão de lógica de primeira ordem, como\\nilustrado na parte superior da \\nFigura 14.18\\n. Uma linguagem de MPUOs fornece uma maneira de\\nescrever esses modelos facilmente enquanto garante uma distribuição de probabilidade única,\\nconsistente, sobre o espaço infinito de mundos possíveis.\\nA ideia básica é entender como as redes bayesianas ordinárias e MPRs definem um modelo de\\nprobabilidade único e transferem esse conhecimento para o cenário de primeira ordem. Em essência,\\numa rede de Bayes \\ngera\\n cada mundo possível, evento por evento, na ordem topológica definida pela\\nestrutura de rede, onde cada evento é uma atribuição de um valor a uma variável. Um MPR estende\\nisso para conjuntos inteiros de eventos, definidos pelas instanciações possíveis das variáveis lógicas\\nem determinado predicado ou função. Os MPUOs vão mais longe, permitindo que estapas geradoras\\nadicionem objetos\\n ao mundo possível em construção, onde o número e o tipo de objetos podem\\ndepender de objetos que já estão nesse mundo. Ou seja, o evento que está sendo gerado não é a\\natribuição de um valor a uma variável, mas a própria \\nexistência\\n de objetos.\\nUma maneira de fazer isso em MPUOs é adicionar instruções que definem distribuições\\ncondicionais sobre os números de objetos de vários tipos. Por exemplo, no domínio de\\nrecomendação do livro, podemos querer distinguir entre \\nclientes\\n (pessoas reais) e seus \\nIDs de login\\n.\\nSuponha que esperamos algo entre 100 e 10.000 clientes distintos (os quais não podemos observar\\ndiretamente). Podemos expressar isso como uma distribuição \\na priori\\n log-normal\\n9\\n da seguinte forma:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 636}),\n",
       " Document(page_content='# \\nCliente ~ LogNormal\\n [6,9, 2,3\\n2\\n] ().\\nEsperamos que os clientes honestos tenham apenas um ID, enquanto os clientes desonestos podem\\nter entre 10 e 1.000 IDs:\\n# \\nLoginID\\n (\\nProprietário\\n = c) ~ \\nse\\n \\nHonesto\\n(\\nc\\n), \\nentão\\n \\nExatamente\\n(1)\\nsenão\\n \\nLogNormal\\n[6,9, 2,3\\n2\\n] ().\\nEssa declaração define o número de IDs de login de um dado proprietário, que é um cliente. A\\nfunção \\nProprietário\\n é chamada \\nfunção de origem\\n porque diz onde cada objeto é gerado. Na\\nsemântica formal do BLOG (distinta da lógica de primeira ordem), os elementos de domínio em cada\\nmundo possível são realmente histórias de geração (por exemplo, “o quarto ID de login do sétimo\\ncliente”), em vez de símbolos simples.\\nSujeitos a condições técnicas de aciclicidade e fundamentação similares aos MPRs, os modelos de\\nuniverso aberto desse tipo definem uma distribuição única sobre os mundos possíveis. Além disso,\\nexistem algoritmos de inferência que, para cada modelo bem definido e para todas as consultas de\\nprimeira ordem, retornam resposta que se aproxima da verdade posterior no limite. Há algumas\\nquestões complicadas relacionadas ao projeto destes algoritmos. Por exemplo, um algoritmo CMMC\\nnão pode fornecer amostra diretamente no espaço de mundos possíveis quando o tamanho desses\\nmundos é ilimitado; em vez disso, ele fornece amostras de mundos finitos, parciais, confiando no fato\\nde que apenas uma quantidade finita de objetos pode ser relevante para a consulta de maneiras\\ndistintas. Além disso, as transições devem permitir fundir dois objetos em um ou uma divisão de um\\nobjeto em dois (ver detalhes nas referências ao final do capítulo). Apesar dessas complicações, o\\nprincípio básico estabelecido na Equação 14.13 ainda é válido: a probabilidade de qualquer\\nsentença é bem definida e pode ser calculada.\\nAs pesquisas nessa área ainda se encontram em fase inicial, mas já está se tornando claro que o\\nraciocínio probabilístico de primeira ordem produz grande aumento na eficácia dos sistemas de IA\\nem lidar com informações incertas. As aplicações potenciais incluem as mencionadas antes — visão\\ncomputacional, entendimento de texto e análise de informação —, assim como muitos outros tipos de\\ninterpretação de sensor.\\n14.7 OUTRAS ABORDAGENS PARA RACIOCÍNIO INCERTO\\nOutras ciências (como, por exemplo, física, genética e economia) há muito tempo adotam a\\nprobabilidade como um modelo para incerteza. Em 1819, Pierre Laplace disse: “A teoria da\\nprobabilidade não é nada além do bom senso reduzido ao cálculo.” Em 1850, James Maxwell\\nafirmou: “A verdadeira lógica para esse mundo é o cálculo de probabilidades, que leva em conta a\\nmagnitude da probabilidade que está ou deveria estar na mente de um homem razoável.”\\nDada essa longa tradição, talvez seja surpreendente que a IA tenha considerado muitas alternativas\\npara a probabilidade. Os primeiros sistemas especialistas da década de 1970 ignoravam a incerteza\\ne usavam o raciocínio lógico estrito, mas logo ficou claro que isso era impraticável para a maioria\\ndos domínios do mundo real. A geração seguinte de sistemas especialistas (especialmente em', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 637}),\n",
       " Document(page_content='domínios médicos) empregava técnicas probabilísticas. Os resultados iniciais foram promissores,\\nmas não puderam ser usados em larga escala devido ao número exponencial de probabilidades\\nexigidas na distribuição conjunta total (os algoritmos eficientes de redes bayesianas eram\\ndesconhecidos na época). Como resultado, as abordagens probabilísticas perderam a preferência no\\nperíodo entre 1975 e 1988, e foram experimentadas diversas alternativas para probabilidade, por\\nvárias razões:\\n•  Uma visão comum é que a teoria da probabilidade é essencialmente numérica, enquanto o\\nraciocínio de bom senso do ser humano é mais “qualitativo”. Certamente, não temos consciência\\nda necessidade de efetuar cálculos numéricos de graus de crença (nem estamos cientes da\\nnecessidade de efetuar a unificação, ainda que aparentemente sejamos capazes de efetuar\\nraciocínio lógico). É possível que tenhamos algum tipo de graus numéricos de crença\\ncodificados diretamente em forças de conexões e ativações em nossos neurônios. Nesse caso, a\\ndificuldade de acesso consciente a essas forças não surpreende. Também devemos observar que\\nos mecanismos de raciocínio qualitativo podem ser construídos diretamente sobre a teoria da\\nprobabilidade, de forma que o argumento contrário à probabilidade baseado na ideia de “nada\\nde números” tem pouca força. Todavia, alguns esquemas qualitativos têm bastante apelo por si\\nsó. Um dos mais bem estudados é o \\nraciocínio default\\n, que trata as conclusões não como “dignas\\nde confiança até certo grau”, mas como “dignas de confiança até se encontrar uma razão melhor\\npara acreditar em algo diferente”. O raciocínio default é estudado no Capítulo 12.\\n•  As abordagens \\nbaseadas em regras\\n para a incerteza também foram experimentadas. Tais\\nabordagens esperam usar como fundamento o sucesso de sistemas baseados em regras lógicas,\\nmas acrescentam uma espécie de “fator de confusão” a cada regra para acomodar a incerteza.\\nEsses métodos foram desenvolvidos em meados da década de 1970 e formaram a base para um\\ngrande número de sistemas especialistas em medicina e outras áreas.\\n•  Uma área que não estudamos até agora é a questão da \\nignorância\\n, em oposição à incerteza.\\nConsidere o lançamento de uma moeda. Se soubermos que a moeda é imparcial, é razoável\\nadmitir a probabilidade de 0,5 para cara. Se soubermos que a moeda é parcial, mas não\\nsoubermos como, então 0,5 será a única probabilidade razoável. É óbvio que os dois casos são\\ndiferentes, ainda que o resultado da probabilidade pareça não fazer distinção entre eles. A\\nteoria de Dempster-Shafer\\n utiliza graus de crença com \\nvalores de intervalos\\n para representar\\no conhecimento de um agente sobre a probabilidade de uma proposição.\\n•  A probabilidade assume o mesmo compromisso ontológico da lógica: que as proposições sejam\\nverdadeiras ou falsas no mundo, ainda que o agente esteja inseguro sobre qual seja o caso. Os\\npesquisadores em \\nlógica difusa\\n propuseram uma ontologia que permite a \\nimprecisão\\n: uma\\nproposição pode ter “um grau de” verdade. A imprecisão e a incerteza são de fato questões\\nortogonais, como veremos.\\nAs três subseções a seguir tratam de algumas dessas abordagens com um pouco mais de\\nprofundidade. Não forneceremos material técnico detalhado, mas citaremos referências para estudo\\nadicional.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 638}),\n",
       " Document(page_content='14.7.1 Métodos baseados em regras para raciocínio incerto\\nOs sistemas baseados em regras emergiram do trabalho inicial sobre sistemas práticos e intuitivos\\npara inferência lógica. Os sistemas lógicos em geral e os sistemas baseados em regras lógicas em\\nparticular têm três propriedades interessantes:\\n•  \\nLocalidade:\\n Em sistemas lógicos, sempre que temos uma regra da forma \\nA\\n \\n⇒\\n \\nB\\n, podemos\\nconcluir \\nB\\n, dada a evidência \\nA\\n, \\nsem preocupação com quaisquer outras regras\\n. Em sistemas\\nprobabilísticos, precisamos considerar \\ntoda\\n evidência.\\n•  \\nSeparação:\\n Uma vez que uma prova lógica seja encontrada para uma proposição \\nB\\n, a\\nproposição pode ser usada, independentemente do modo como foi derivada. Ou seja, ela pode\\nser \\nseparada\\n de sua justificativa.Por outro lado, ao lidar com probabilidades, a origem da\\nevidência de uma crença é importante para o raciocínio subsequente.\\n•  \\nVerdade-funcionalidade:\\n Em lógica, a verdade de sentenças complexas pode ser calculada a\\npartir da verdade dos componentes. A combinação de probabilidades não funciona desse modo,\\nexceto sob suposições fortes de independência global.\\n Houve várias tentativas para criar esquemas de raciocínio incerto que retêm essas vantagens. A\\nideia é associar graus de crença a proposições e regras, e gerar esquemas puramente locais para\\ncombinar e propagar esses graus de crença. Os esquemas também são verdade-funcionais; por\\nexemplo, o grau de crença em \\nA\\n \\n∨\\n \\nB\\n é uma função da crença em \\nA\\n e da crença em \\nB\\n. A má notícia\\npara sistemas baseados em regras é que as propriedades de \\nlocalidade\\n, \\nseparação e verdade-\\nfuncionalidade simplesmente não são apropriadas para o raciocínio incerto\\n. Vamos examinar\\nprimeiro a verdade-funcionalidade. Seja \\nH\\n1\\n o evento em que um lançamento de moeda imparcial\\nresulta em cara, seja \\nT\\n1\\n o evento em que a moeda resulta em coroa nesse mesmo lançamento e seja\\nH\\n2\\n o evento em que a moeda mostra cara em um segundo lançamento. É claro que os três eventos têm\\na mesma probabilidade, 0,5, e portanto um sistema verdade-funcional deve atribuir a mesma crença à\\ndisjunção de dois desses eventos. No entanto, podemos ver que a probabilidade da disjunção\\ndepende dos próprios eventos e não apenas de suas probabilidades:\\nP\\n(\\nA\\n)\\nP\\n(\\nB\\n)\\nP\\n(\\nA\\n \\n∨\\n \\nB\\n)\\nP\\n(\\nH\\n1\\n) = 0,5\\nP\\n(\\nH\\n1\\n) = 0,5\\nP\\n(\\nT\\n1\\n) = 0,5\\nP\\n(\\nH\\n2\\n) = 0,5\\nP\\n(\\nH\\n1\\n \\n∨\\n \\nH\\n1\\n) = 0,50\\nP\\n(\\nH\\n1\\n \\n∨\\n \\nT\\n1\\n) = 1,00\\nP\\n(\\nH\\n1\\n \\n∨\\n \\nH\\n2\\n) = 0,75\\nA situação fica pior quando juntamos a evidência. Os sistemas verdade-funcionais têm \\nregras\\n da\\nforma \\nA\\n \\n \\nB\\n que nos permitem calcular a crença em \\nB\\n como uma função da crença na regra e a\\ncrença em \\nA\\n. Podem ser criados sistemas de encadeamento para a frente e de encadeamento para trás.\\nA crença na regra é considerada constante e, em geral, é especificada pelo engenheiro do\\nconhecimento — por exemplo, como \\nA\\n \\n0,9\\n \\nB\\n.\\nConsidere a situação de grama molhada da \\nFigura 14.12\\n(a). Se quiséssemos ter a possibilidade de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 639}),\n",
       " Document(page_content='desenvolver tanto o raciocínio causal quanto o raciocínio de diagnóstico, precisaríamos das duas\\nregras a seguir:\\nEssas duas regras formam um laço de realimentação: a evidência de \\nChuva\\n aumenta a crença em\\nGramaMolhada\\n que, por sua vez, aumenta ainda mais a crença em \\nChuva\\n. É claro que os sistemas de\\nraciocínio incerto precisam manter o controle dos caminhos ao longo dos quais a evidência é\\npropagada.\\nO raciocínio intercausal (ou de explicação muito boa) também é complicado. Considere o que\\nacontece quando temos as duas regras:\\nVamos supor que observamos que o irrigador está ligado. Por encadeamento direto através de\\nnossas regras, isso aumenta a crença de que a grama ficará molhada, o que, por sua vez, aumenta a\\ncrença de que está chovendo. Entretanto, isso é ridículo: o fato de o irrigador estar funcionando\\nexplica muito bem a grama molhada e deve \\nreduzir\\n a crença de chuva. Um sistema verdade-funcional\\natua como se também acreditasse que \\nIrrigador\\n \\n \\nChuva\\n.\\nDadas essas dificuldades, como é possível que sistemas verdade-funcionais podem ser úteis na\\nprática? A resposta reside na restrição da tarefa e em cuidadosa engenharia da base de regras para\\nque interações indesejáveis não ocorram. O exemplo mais famoso de um sistema verdade-funcional\\npara raciocínio incerto é o modelo de \\nfatores de certeza\\n, desenvolvido para o programa de\\ndiagnóstico médico MYCIN e que foi amplamente utilizado em sistemas especialistas do final da\\ndécada de 1970 e na década de 1980. Quase todos os usos de fatores de certeza envolviam conjuntos\\nde regras que eram puramente de diagnóstico (como no MYCIN) ou puramente causais. Além disso, a\\nevidência só foi introduzida nas “raízes” do conjunto de regras, e a maioria dos conjuntos de regras\\nera unicamente conectada. Heckerman (1986) mostrou que, sob essas circunstâncias, uma variação\\nsecundária na inferência do fator de certeza era exatamente equivalente à inferência bayesiana em\\npoliárvores. Em outras circunstâncias, os fatores de certeza poderiam resultar em graus de crença\\ndesastrosamente incorretos, devido à superestimativa da evidência. À medida que os conjuntos de\\nregras ficavam maiores, interações indesejáveis entre as regras se tornavam mais comuns, e os\\nmédicos descobriram que os fatores de certeza de muitas outras regras tinham de ser “adaptados”\\nquando novas regras eram adicionadas. Por essas razões, as redes bayesianas suplantaram os\\nmétodos baseados em regra de raciocínio incerto.\\n14.7.2 Representação da ignorância: teoria de Dempster-Shafer\\nA \\nteoria de Dempster-Shafer\\n foi criada para lidar com a distinção entre \\nincerteza\\n e \\nignorância\\n.\\nEm vez de calcular a probabilidade de uma proposição, ela calcula a probabilidade de que a\\nevidência admita a proposição. Essa medida de crença é chamada \\nfunção de crença\\n, representada\\npor \\nBel\\n(\\nX\\n).\\nVoltamos ao lançamento de moedas para ver um exemplo de funções de crença. Suponha que você', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 640}),\n",
       " Document(page_content='pegue uma moeda do bolso de um mágico. Dado que a moeda pode ou não ser imparcial, que crença\\nvocê deve atribuir ao evento de que o lançamento dará cara? A teoria de Dempster-Shafer lhe diz\\nque, como não há nenhuma evidência em contrário, você tem de afirmar que a crença \\nBel\\n(\\nCara\\n) = 0 e\\ntambém que \\nBel\\n(¬\\nCara\\n) = 0. Isso torna os sistemas de raciocínio de Dempster-Shafer céticos de um\\nmodo que apresenta certo apelo intuitivo. Agora, suponha que você tenha um especialista à sua\\ndisposição que atesta com 90% de certeza que a moeda é imparcial (isto é, ele está 90% certo de que\\nP\\n(\\nCara\\n) = 0,5). Então, a teoria de Dempster-Shafer resulta em \\nBel\\n(\\nCara\\n) = 0,9 × 0,5 = 0,45 e, da\\nmesma forma, em \\nBel\\n(¬\\nCara\\n) = 0,45. Existe ainda um “intervalo” de 10 pontos percentuais não\\ncontabilizado pela evidência.\\nOs fundamentos matemáticos da teoria de Dempster-Shafer têm um sabor semelhante ao da teoria\\nda probabilidade; a principal diferença é que, em vez de atribuir probabilidades para mundos\\npossíveis, a teoria atribui \\nmassas\\n para conjuntos de mundos possíveis, isto é, eventos. As massas\\nainda devem adicionar 1 sobre todos os eventos possíveis. \\nBel\\n(\\nA\\n) é definido como sendo a soma das\\nmassas para todos os eventos que são subconjuntos de \\nA\\n (ou seja, que implicam em \\nA\\n), incluindo o\\npróprio \\nA\\n. Com essa definição, a soma de \\nBel(A) e Bel(¬A)\\n é no \\nmáximo\\n 1, e o intervalo entre \\nBel(A)\\ne 1 − \\nBel(¬A)\\n é muitas vezes interpretado como limitando a probabilidade de \\nA\\n.\\nAssim como ocorre com o raciocínio default, há um problema na conexão entre crenças e ações.\\nSempre que existe uma lacuna nas crenças, um problema de decisão pode ser definido de tal forma\\nque o sistema de Dempster-Shafer é incapaz de tomar uma decisão. Na verdade, a noção de utilidade\\nno modelo de Dempster-Shafer ainda não está bem entendida, pois os significados das massas e\\ncrenças em si ainda não foram bem compreendidos. Pearl (1988) argumentou que \\nBel(A)\\n deve ser\\ninterpretado não como um grau de crença em \\nA\\n, mas como a probabilidade atribuída a todos os\\nmundos possíveis (agora interpretados como teorias lógicas) em que \\nA\\n é \\ndemonstrável\\n. Embora\\nexistam casos em que essa quantidade possa ser de interesse, ela não é o mesmo que a probabilidade\\nde que \\nA\\n seja verdadeiro.\\nUma análise bayesiana do lançamento da moeda sugere que não é necessário nenhum formalismo\\nnovo para lidar com esses casos. O modelo teria duas variáveis: a \\nParcialidade\\n da moeda (um\\nnúmero entre 0 e 1, onde 0 é uma moeda que sempre mostra coroa e 1 é uma moeda que sempre\\nmostra cara) e o resultado do próximo \\nLance\\n. A distribuição de probabilidade \\na priori\\n para\\nParcialidade\\n refletiria nossas crenças com base na origem da moeda (o bolso do mágico): uma\\npequena probabilidade que seja imparcial e outra que seja fortemente inclinada a dar cara ou coroa.\\nA distribuição condicional \\nP\\n(\\nLance\\n | \\nParcial\\n) simplesmente define como opera a parcialidade. Se\\nP\\n(\\nParcial\\n) for simétrico em torno de 0,5, então a nossa probabilidade prévia para o lance é de\\nEssa é a mesma previsão que teríamos se acreditássemos fortemente que a moeda fosse parcial,\\nmas \\nnão\\n significa que a teoria da probabilidade trata as duas situações de forma idêntica. A\\ndiferença surge \\napós\\n o lance, ao calcular a distribuição posterior da \\nParcialidade.\\n Se a moeda veio\\nde um banco, então verificar que deu cara três vezes quase não abalaria a nossa forte crença anterior\\nna sua imparcialidade; mas, se a moeda vier do bolso do mágico, a mesma evidência levará a uma\\ncrença posterior mais forte de que a moeda tende a dar coroa. Assim, uma abordagem bayesiana', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 641}),\n",
       " Document(page_content='expressa nossa “ignorância” em termos de como nossas crenças mudariam em face da coleta de\\ninformações futuras.\\n14.7.3 Representação da imprecisão: conjuntos difusos e lógica difusa\\n A \\nteoria de conjuntos difusos\\n é um meio de especificar o quanto um objeto satisfaz uma\\ndescrição vaga. Por exemplo, considere a proposição: “Nei é alto.” Isso é verdadeiro se Nei tiver\\n1,78 m? A maioria das pessoas hesitaria em responder “verdadeiro” ou “falso”, preferindo dizer:\\n“Talvez.” Observe que isso não é uma questão de incerteza sobre o mundo exterior — estamos certos\\nda altura de Nei. A questão é que o termo linguístico “alto” não se refere a uma demarcação nítida de\\nobjetos em duas classes — existem \\ngraus\\n de altura. Por essa razão, \\na teoria de conjuntos difusos\\nnão é de forma alguma um método para raciocínio incerto\\n. Em vez disso, a teoria de conjuntos\\ndifusos trata \\nAlto\\n como um predicado difuso e afirma que o valor-verdade de \\nAlto\\n(\\nNei\\n) é um número\\nentre 0 e 1, em vez de ser simplesmente \\nverdadeiro\\n ou \\nfalso\\n. O nome “conjuntos difusos” deriva da\\ninterpretação do predicado como a definição implícita de um conjunto de seus elementos — um\\nconjunto que não tem limites precisos.\\nA \\nlógica difusa\\n é um método para raciocínio com expressões lógicas que descrevem a pertinência\\na conjuntos difusos. Por exemplo, a sentença complexa \\nAlto\\n(\\nNei\\n) \\n∧\\n \\nPesado\\n(\\nNei\\n) tem um valor-\\nverdade difuso que é uma função dos valores-verdade de seus componentes. As regras-padrão para\\navaliar a verdade difusa, \\nV\\n, de uma sentença complexa são:\\nV\\n(\\nA\\n \\n∧\\n \\nB\\n) = min(\\nV\\n(\\nA\\n), \\nV\\n(\\nB\\n))\\nV\\n(\\nA\\n \\n∨\\n \\nB\\n) = max(\\nV\\n(\\nA\\n), \\nV\\n(\\nB\\n))\\nV\\n(¬\\nA\\n) = 1 – \\nV\\n(\\nA\\n).\\nA lógica difusa é um sistema verdade-funcional — um fato que causa sérias dificuldades. Por\\nexemplo, suponha que \\nV\\n(\\nAlto\\n(\\nNei\\n)) = 0,6 e \\nV\\n(\\nPesado\\n(\\nNei\\n)) = 0,4. Portanto, temos \\nV\\n(\\nAlto\\n(\\nNei\\n) \\n∧\\nPesado\\n(\\nNei\\n)) = 0,4, que parece razoável,mas também obtemos o resultado \\nV\\n(\\nAlto\\n(\\nNei\\n) \\n∧\\n¬\\nAlto\\n(\\nNei\\n)) = 0,4, que não parece nem um pouco razoável. Sem dúvida, o problema surge da\\ninabilidade de uma abordagem verdade-funcional levar em conta as correlações ou anticorrelações\\nentre as proposições componentes.\\nO \\ncontrole difuso\\n é uma metodologia para construir sistemas de controle em que o mapeamento\\nentre os parâmetros de entrada e saída com valores reais é representado por regras difusas. O\\ncontrole difuso tem sido muito bem-sucedido em produtos comerciais como transmissões\\nautomáticas, câmeras de vídeo e barbeadores elétricos. Os críticos (veja, por exemplo, Elkan, 1993)\\nargumentam que essas aplicações são bem-sucedidas porque têm bases de regras pequenas, nenhum\\nencadeamento de inferências e parâmetros harmoniosos que podem ser ajustados para melhorar o\\ndesempenho do sistema. O fato de eles serem implementados com operadores difusos poderia ser\\napenas circunstancial; a chave é simplesmente fornecer um modo conciso e intuitivo de especificar\\numa função de valores reais suavemente interpolada. Houve tentativas para fornecer uma explicação\\nda lógica difusa em termos da teoria da probabilidade. Uma ideia é visualizar asserções do tipo “Nei\\né alto” como observações discretas feitas em relação a uma variável contínua oculta, a \\nAltura\\n real de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 642}),\n",
       " Document(page_content='Nei. O modelo de probabilidade especifica \\nP\\n(O observador afirma que Nei é alto | \\nAltura\\n), talvez\\nusando uma \\ndistribuição probit\\n, como descrito anteriormente. Uma distribuição posterior sobre a\\naltura de Nei pode então ser calculada da maneira usual, por exemplo, se o modelo fizer parte de\\numa rede bayesiana híbrida. É claro que tal abordagem não é verdade-funcional. Por exemplo, a\\ndistribuição condicional:\\nP\\n(O observador afirma que Nei é alto e pesado | \\nAltura\\n, \\nPeso\\n)\\npermite interações entre altura e peso para formar a causa da observação. Desse modo, é muito\\nimprovável que alguém que tenha 2,43 metros de altura e pese 86 quilos seja chamado de “alto e\\npesado”, embora “2,43 metros” signifique “alto” e “86 quilos” signifique “pesado”.\\nOs predicados difusos também podem receber uma interpretação probabilística em termos de\\nconjuntos aleatórios\\n, isto é, variáveis aleatórias cujos valores possíveis são conjuntos de objetos.\\nPor exemplo, \\nAlto\\n é um conjunto aleatório cujos valores possíveis são conjuntos de pessoas. A\\nprobabilidade \\nP\\n(\\nAlto\\n = \\nS\\n1\\n), onde \\nS\\n1\\n é algum conjunto específico de pessoas, é a probabilidade de\\nque exatamente esse conjunto seja identificado como “alto” por um observador. Então, a\\nprobabilidade de “Nei é alto” é a soma das probabilidades de todos os conjuntos dos quais Nei é um\\nelemento.\\nTanto a abordagem de rede bayesiana híbrida quanto a abordagem de conjuntos aleatórios parecem\\ncaptar aspectos de imprecisão sem introduzir graus de verdade. Todavia, permanecem abertas muitas\\nquestões relativas à representação apropriada de observações linguísticas e quantidades contínuas —\\nquestões que foram negligenciadas pela maioria dos pesquisadores de fora da comunidade difusa.\\n14.8 RESUMO\\nEste capítulo descreveu as \\nredes bayesianas\\n, uma representação bem desenvolvida para o\\nconhecimento incerto. As redes bayesianas desempenham um papel aproximadamente análogo ao da\\nlógica proposicional para o conhecimento definido.\\n•  Uma rede bayesiana é um grafo acíclico orientado cujos nós correspondem a variáveis\\naleatórias; cada nó tem uma distribuição condicional para o nó, dados seus pais.\\n•  As redes bayesianas fornecem um modo conciso de representar relacionamentos de\\nindependência condicional\\n no domínio.\\n•  Uma rede bayesiana especifica uma distribuição conjunta total; cada entrada conjunta é definida\\ncomo o produto das entradas correspondentes nas distribuições condicionais locais. Uma rede\\nbayesiana com frequência é exponencialmente menor que a distribuição conjunta enumerada\\nexplicitamente.\\n•  Muitas distribuições condicionais podem ser representadas de forma compacta por famílias\\ncanônicas de distribuições. As \\nredes bayesianas híbridas\\n, que incluem tanto variáveis discretas\\nquanto variáveis contínuas, utilizam uma variedade de distribuições canônicas.\\n•  A inferência em redes bayesianas significa calcular a distribuição de probabilidade de um\\nconjunto de variáveis de consulta, dado um conjunto de variáveis de evidência. Os algoritmos de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 643}),\n",
       " Document(page_content='inferência exata, como a \\neliminação de variáveis\\n, avaliam somas de produtos de probabilidades\\ncondicionais de forma tão eficiente quanto possível.\\n•  Em \\npoliárvores\\n (redes unicamente conectadas), a inferência exata demora um tempo linear no\\ntamanho da rede. No caso geral, o problema é intratável.\\n•  Técnicas de aproximação estocástica como \\nponderação de probabilidade\\n e \\ncadeia de Markov\\nMonte Carlo\\n podem fornecer estimativas razoáveis das probabilidades posteriores verdadeiras\\nem uma rede e lidar com redes muito maiores do que os algoritmos exatos.\\n•  A teoria da probabilidade pode ser combinada com ideias de representação da lógica de\\nprimeira ordem para produzir sistemas muito poderosos destinados ao raciocínio sob incerteza.\\nOs \\nmodelos de probabilidade relacional\\n (MPRs) incluem restrições de representação que\\ngarantem uma distribuição de probabilidade bem definida que pode ser expressa como uma rede\\nbayesiana equivalente. Os \\nmodelos de probabilidade de universo aberto\\n tratam da existência e\\nda \\nincerteza da identidade\\n, definindo distribuições de probabilidade sobre o espaço infinito\\ndos mundos possíveis de primeira ordem.\\n•  Vários sistemas alternativos para raciocínio sob incerteza foram sugeridos. De modo geral,\\nsistemas \\nverdade-funcionais\\n não são adequados para tal raciocínio.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nO uso de redes para representar informações probabilísticas começou no início do século XX,\\ncom o trabalho de Sewall Wright sobre a análise probabilística de herança genética e fatores de\\ncrescimento dos animais (Wright, 1921, 1934). I. J. Good (1961), em colaboração com Alan Turing,\\ndesenvolveu representações probabilísticas e métodos de inferência de Bayes que poderiam ser\\nconsiderados precursores das redes bayesianas modernas, embora o artigo não seja citado com\\nfrequência nesse contexto.\\n10\\n O mesmo artigo é a fonte original do modelo de OU ruidoso.\\nA representação de \\ndiagrama de influência\\n para problemas de decisão, que incorporou uma\\nrepresentação de GAO para variáveis aleatórias, foi usada em análise de decisão no final dos anos\\n1970 (veja o Capítulo 16), mas apenas a enumeração foi usada para avaliação. Judea Pearl\\ndesenvolveu o método de passagem de mensagens para transporte de inferência em redes de árvores\\n(Pearl, 1982a) e em redes de poliárvores (Kim e Pearl, 1983) e explicou a importância de se\\nconstruírem modelos de probabilidade causal em lugar de modelos de probabilidade de diagnóstico,\\nem contraste com os sistemas de fatores de certeza então em voga.\\nO primeiro sistema especialista a utilizar redes bayesianas foi o CONVINCE (Kim, 1983).\\nAplicações antigas em medicina incluem o sistema MUNIN para diagnosticar enfermidades\\nneuromusculares (Andersen \\net al\\n., 1989) e o sistema PATHFINDER para patologia (Heckerman,\\n1991). O sistema CPCS (Pradhan \\net al\\n., 1994) é uma rede bayesiana para a medicina interna\\nconsistindo de 448 nós, 906 ligações e 8.254 valores de probabilidade condicional (a capa mostra\\numa parte da rede).\\nAs aplicações em engenharia incluem o trabalho do Electric Power Research Institute sobre\\nmonitoramento de geradores de energia (Morjaria \\net al\\n., 1995), o trabalho da Nasa sobre a exibição\\nde informação de tempo crítico no controle de missão em Houston (Horvitz e Barry, 1995), e o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 644}),\n",
       " Document(page_content='campo geral da \\ntomografia de rede\\n, que visa inferir propriedades locais de nós despercebidos e\\nlinks na Internet a partir de observações sobre o desempenho de mensagem de ponta a ponta (Castro\\net al\\n., 2004). Talvez a rede bayesiana utilizada mais amplamente tenha sido os módulos de diagnose\\ne reparação (por exemplo, o Printer Wizard) no Microsoft Windows (Breese e Heckerman, 1996) e o\\nOffice Assistant da Microsoft (Horvitz \\net al\\n., 1998). Outra área de aplicação importante é a biologia:\\ntêm sido utilizadas redes bayesianas para a identificação de genes humanos por referência a genes de\\nratos (Zhang \\net al\\n., 2003), inferindo redes celulares Friedman (2004) e muitas outras tarefas em\\nbioinformática. Poderíamos continuar, mas, em vez disso, vou encaminhá-lo para Pourret \\net al.\\n(2008), um guia de 400 páginas para aplicações de redes bayesianas.\\nRoss Shachter (1986), trabalhando na comunidade do diagrama de influência, desenvolveu o\\nprimeiro algoritmo completo para redes bayesianas gerais. Seu método era baseado em redução\\norientada ao objetivo da rede, utilizando transformações de preservação posterior. Pearl (1986)\\ndesenvolveu um algoritmo de agrupamento para inferência exata em redes bayesianas gerais,\\nutilizando uma conversão para uma poliárvore de agrupamentos orientada, em que a passagem de\\nmensagens foi utilizada para obter consistência sobre as variáveis compartilhadas entre\\nagrupamentos. Uma abordagem semelhante, desenvolvida pelos estatísticos David Spiegelhalter e\\nSteffen Lauritzen (Lauritzen e Spiegelhalter, 1988), baseia-se em conversão para uma forma não\\norientada do modelo gráfico chamado \\nrede de Markov\\n. Essa abordagem foi implementada no\\nsistema Hugin, uma ferramenta eficaz e amplamente utilizada para raciocínio incerto (Andersen \\net\\nal\\n., 1989). Boutilier \\net al\\n. (1996) mostram como explorar a independência de contexto específico em\\nalgoritmos de agrupamento.\\nA ideia básica de eliminação de variável — de que cálculos repetidos dentro da expressão geral\\nde soma de produtos podem ser evitados por \\ncaching\\n — apareceu no algoritmo de inferência\\nprobabilística simbólica (SPI) (Shachter \\net al.,\\n 1990). O algoritmo de eliminação que descrevemos\\nestá mais próximo daquele que foi desenvolvido por Zhang e Poole (1994). Critérios para podar\\nvariáveis irrelevantes foram desenvolvidos por Geiger \\net al.\\n (1990) e por Lauritzen \\net al.\\n (1990); o\\ncritério que apresentamos é um caso especial simples desses critérios. Dechter (1999) mostra como\\na ideia de eliminação de variáveis é essencialmente idêntica à \\nprogramação dinâmica não serial\\n(Bertele e Brioschi, 1972), uma abordagem algorítmica que pode ser aplicada para resolver uma\\nvariedade de problemas de inferência em redes bayesianas — como, por exemplo, encontrar a\\nexplicação mais provável\\n para um conjunto de observações. Esse método conecta algoritmos de\\nredes bayesianas inter-relacionados para resolver PSRs e apresenta uma medida direta da\\ncomplexidade da inferência exata em termos da largura de árvore da rede. Wexler e Meek (2009)\\ndescreveram um método de impedir o crescimento exponencial do tamanho dos fatores calculados na\\neliminação de variáveis; seu algoritmo divide os fatores grandes em produtos de fatores menores e\\ncalcula simultaneamente um limite de erro de aproximação resultante.\\nA inclusão de variáveis aleatórias contínuas em redes bayesianas foi considerada por Pearl (1988)\\ne por Shachter e Kenley (1989); esses documentos discutiam redes contendo apenas variáveis\\ncontínuas com distribuições gaussianas lineares. A inclusão de variáveis discretas foi investigada\\npor Lauritzen e Wermuth (1989) e implementada no sistema cHUGIN (Olesen, 1993). A análise mais\\naprofundada dos modelos lineares de Gauss, com conexões para muitos outros modelos utilizados\\nnas estatísticas, aparece em Roweis e Ghahramani (1999). A distribuição probit é geralmente', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 645}),\n",
       " Document(page_content='atribuída a Gaddum (1933) e Bliss (1934), embora tivesse sido descoberta várias vezes no século\\nXIX. O trabalho de Bliss foi expandido consideravelmente por Finney (1947). O probit foi\\namplamente utilizado para modelar fenômenos de escolha discreta e pode ser estendido para lidar\\ncom mais de duas escolhas (Daganzo, 1979). O modelo logit foi introduzido por Berkson (1944);\\ninicialmente muito ridicularizado, ele se tornou mais popular que o modelo probit. Bishop (1995)\\noferece uma justificação simples para o seu uso.\\nCooper (1990) mostrou que o problema geral de inferência em redes bayesianas irrestritas é NP-\\ndifícil, e Paul Dagum e Mike Luby (1993) mostraram que o problema de aproximação\\ncorrespondente é NP-difícil. A complexidade de espaço também é um problema sério em métodos de\\nformação de agrupamentos e de eliminação de variáveis. O método de \\ncondicionamento de conjunto\\nde corte\\n, desenvolvido para PSRs no Capítulo 6, evita a construção de tabelas exponencialmente\\ngrandes. Em uma rede bayesiana, um conjunto de corte é um conjunto de nós que, quando instanciado,\\nreduz os nós restantes a uma poliárvore que pode ser resolvida em tempo e espaço lineares. A\\nconsulta é respondida efetuando-se o somatório de todas as instanciações do conjunto de corte e,\\nportanto, o requisito de espaço global ainda é linear (Pearl, 1988). Darwiche (2001) descreve um\\nalgoritmo de condicionamento recursivo que permite um intervalo completo de compromissos de\\nespaço/tempo.\\nO desenvolvimento de algoritmos de aproximação rápida para inferência de redes bayesianas é\\numa área muito ativa, com contribuições da estatística, da ciência da computação e da física. O\\nmétodo de amostragem de rejeição é uma técnica geral conhecida há muito tempo pelos estatísticos;\\nela foi aplicada primeiro a redes bayesianas por Max Henrion (1988), que a denominou \\namostragem\\nde lógica\\n. A ponderação de probabilidade, desenvolvida por Fung e Chang (1989) e por Shachter e\\nPeot (1989), é um exemplo do método estatístico bem conhecido de \\namostragem de importância\\n.\\nCheng e Druzdzel (2000) descrevem uma versão adaptável da ponderação de probabilidade que\\nfunciona bem até mesmo quando a evidência tem uma probabilidade \\na priori\\n muito baixa.\\nOs algoritmos de cadeia de Markov Monte Carlo (CMMC) começaram com o algoritmo de\\nMetropolis, devido a Metropolis \\net al.\\n (1953), que também foi a origem do algoritmo de têmpera\\nsimulada descrito no Capítulo 4. O sistema de amostragem de Gibbs foi criado por Geman e Geman\\n(1984) para inferência em redes de Markov não orientadas. A aplicação de CMMC a redes\\nbayesianas se deve a Pearl (1987). Os documentos reunidos por Gilks \\net al.\\n (1996) abrangem ampla\\nvariedade de aplicações de CMMC, várias das quais foram desenvolvidas no bem conhecido pacote\\nBUGS (Gilks \\net al.\\n, 1994).\\nExistem duas famílias muito importantes de métodos de aproximação que não cobrimos no\\ncapítulo. A primeira é a família de métodos de \\naproximação variacional\\n, que podem ser usados para\\nsimplificar cálculos complexos de todos os tipos. A ideia básica é propor uma versão reduzida do\\nproblema original que seja simples de utilizar, mas que lembre tão aproximadamente quanto possível\\no problema original. O problema reduzido é descrito por alguns \\nparâmetros variacionais\\n \\nλ\\n que são\\najustados para minimizar uma função de distância \\nD\\n entre o problema original e o problema\\nreduzido, frequentemente pela resolução do sistema de equações ∂\\nD\\n/∂ \\nλ\\n = 0. Em muitos casos,\\npodem ser obtidos limites rígidos superiores e inferiores. Os métodos variacionais são empregados\\nhá longo tempo em estatística (Rustagi, 1976). Em física estatística, o método de \\ncampo médio\\n é uma\\naproximação variacional específica em que se supõe que as variáveis individuais que constituem o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 646}),\n",
       " Document(page_content='modelo são completamente independentes. Essa ideia foi aplicada à resolução de grandes redes de\\nMarkov não orientadas (Peterson e Anderson, 1987; Parisi, 1988). Saul \\net al.\\n (1996) desenvolveram\\nos fundamentos matemáticos para a aplicação de métodos variacionais a redes bayesianas e\\nobtiveram aproximações com limites inferiores mais precisos para redes de sigmoides com o\\nemprego de métodos de campo médio. Jaakkola e Jordan (1996) estenderam a metodologia para\\nobter tanto limites inferiores quanto superiores. Desde esses primeiros trabalhos, métodos\\nvariacionais foram aplicados a muitas famílias de modelos específicos. O artigo notável de\\nWainwright e Jordan (2008) fornece uma unificação da análise teórica da literatura sobre métodos\\nvariacionais.\\nUma segunda família importante de algoritmos de aproximação se baseia no algoritmo de\\npassagem de mensagens de poliárvore de Pearl (1982a). Esse algoritmo pode ser aplicado a redes\\ngerais, conforme foi sugerido por Pearl (1988). Os resultados podem ser incorretos ou o algoritmo\\npode deixar de terminar, mas, em muitos casos, os valores obtidos estão próximos dos valores\\nverdadeiros. Pouca atenção foi dada a essa abordagem, denominada \\npropagação de crença\\n (ou PC),\\naté McEliece \\net al.\\n (1998) observarem que a passagem de mensagens em uma rede bayesiana com\\nvárias conexões era exatamente a computação executada pelo algoritmo de \\ndecodificação turbo\\n(Berrou \\net al.\\n, 1993), o que proporcionou uma inovação importante no projeto de códigos eficientes\\nde correção de erros. A implicação é que PC é ao mesmo tempo rápida e precisa nas redes muito\\ngrandes e altamente conectadas usadas para decodificação, e poderia portanto ser útil em aplicações\\nmais gerais. Murphy \\net al.\\n (1999) apresentaram um estudo empírico promissor do desempenho do\\nPC, e Weiss e Freeman (2001) estabeleceram fortes resultados de convergência para o PC em redes\\nlineares de Gauss. Weiss (2000b) mostrou como funciona uma aproximação chamada propagação de\\ncrença por laço e quando a aproximação está correta. Yedidia \\net al.\\n (2001) descobriram conexões\\nadicionais entre a propagação com laços e ideias da física estatística.\\nA conexão entre probabilidade e linguagens de primeira ordem foi estudada inicialmente por\\nCarnap (1950). Gaifman (1964), bem como Scott e Krauss (1966), definiram uma linguagem em que\\nas probabilidades podiam ser associadas a sentenças de primeira ordem e para a qual os modelos\\neram medidas de probabilidade sobre mundos possíveis. Dentro da IA, essa ideia foi desenvolvida\\npara a lógica proposicional por Nilsson (1986) e para a lógica de primeira ordem por Halpern\\n(1990). A primeira investigação extensa de questões de representação de conhecimento em tais\\nlinguagens foi realizada por Bacchus (1990). A ideia básica era que cada sentença na base de\\nconhecimento expresse uma \\nrestrição\\n na distribuição sobre mundos possíveis; uma sentença permite\\nque a outra expresse uma restrição forte. Por exemplo, a sentença \\n∀\\nx \\nP\\n(\\nFaminto (x\\n))> 0,2 exclui\\ndistribuições em que qualquer objeto esteja faminto, com probabilidade inferior a 0,2; portanto,\\npermite a sentença \\n∀\\nx \\nP\\n(\\nFaminto (x\\n))> 0,1. Acontece que escrever um conjunto \\nconsistente\\n de\\nsentenças nessas linguagens é bastante difícil e construir um modelo único de probabilidade é quase\\nimpossível, a menos que se adote a abordagem de representação de redes bayesianas escrevendo\\nsentenças adequadas sobre probabilidades condicionais.\\nNo início dos anos 1990, pesquisadores trabalhando em aplicações complexas, observaram as\\nlimitações expressivas das redes bayesianas e desenvolveram várias linguagens para escrever\\n“modelos” com variáveis lógicas, a partir das quais se pode construir grandes redes automaticamente\\npara cada instância do problema (Breese, 1992; Wellman \\net al\\n., 1992). A linguagem mais importante', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 647}),\n",
       " Document(page_content='foi BUGS (inferência bayesiana usando amostragem de Gibbs) (Gilks \\net al\\n., 1994), que combinou\\nredes bayesianas com a notação da \\nvariável aleatória indexada\\n comum em estatística (em BUGS,\\numa variável indexada aleatória se parece com \\nX\\n[\\ni\\n], onde \\ni\\n tem um intervalo de números inteiros\\ndefinido). Essas linguagens herdaram a propriedade fundamental das redes bayesianas: toda a base\\nde conhecimento bem formada define um modelo de probabilidade consistente e único. Linguagens\\ncom semânticas bem definidas com base em nomes únicos e domínio fechado ocasionam capacidades\\nrepresentacionais da programação lógica (Poole, 1993; Sato e Kameya, 1997; Kersting \\net al\\n., 2000)\\ne de redes semânticas (Koller e Pfeffer, 1998; Pfeffer, 2000). Pfeffer (2007) continuou a desenvolver\\no IBAL, que representa modelos de probabilidade de primeira ordem como programas\\nprobabilísticos em uma linguagem de programação estendida com randomização primitiva. Outro\\nsegmento importante foi a combinação de notações relacional e de primeira ordem com as redes (não\\norientadas) de Markov (Taskar \\net al\\n., 2002; Domingos e Richardson, 2004), onde a ênfase está\\nmenos na representação do conhecimento e mais em aprender com grandes conjuntos de dados.\\nInicialmente, a inferência nesses modelos foi realizada através da geração de uma rede bayesiana\\nequivalente. Pfeffer \\net al.\\n (1999) introduziram um algoritmo de eliminação de variáveis \\u200b\\u200bque colocava\\nem cache cada fator calculado para reutilização por cálculos posteriores envolvendo as mesmas\\nrelações mas objetos diferentes, tornando real então parte dos ganhos computacionais da elevação. O\\nprimeiro algoritmo de inferência realmente elevado foi uma forma elevada de eliminação de variável\\ndescrita por Poole (2003) e posteriormente melhorado por Salvo Braz \\net al\\n. (2007). Outros avanços,\\nincluindo casos em que certas probabilidades agregadas podem ser calculadas de forma fechada, são\\ndescritos por Milch \\net al\\n. (2008) e Kisynski e Poole (2009). Pasula e Russell (2001) estudaram a\\naplicação CMMC para evitar a construção da rede de Bayes equivalente completa em casos de\\nincerteza relacional e de identidade. Getoor e Taskar (2007) reuniram muitas teses importantes sobre\\nmodelos e probabilidades de primeira ordem e seu uso na aprendizagem de máquina.\\nO raciocínio probabilístico sobre a incerteza de identidade tem duas origens distintas. Em\\nestatística, surge o problema de \\nligação de registro\\n quando os registros de dados não contêm\\nidentificadores únicos padrão, por exemplo, diversas citações deste livro podem denominar seu\\nprimeiro autor “Stuart Russell”ou “S. J. Russell” ou mesmo “Stewart Russle”, e outros autores\\npodem usar alguns dos mesmos nomes. Literalmente centenas de empresas existem apenas para\\nresolver problemas de ligação de registros financeiros, médicos, censos e outros dados. A análise\\nprobabilística volta ao trabalho de Dunn (1946); o modelo Fellegi-Sunter (1969), que é\\nessencialmente Bayes ingênuo aplicado à combinação, ainda domina a prática atual. A segunda\\norigem para o trabalho sobre a incerteza de identidade é de rastreamento multialvo (Sittler, 1964),\\nque cobriremos no Capítulo 15. Para a maioria de sua história, trabalhar com IA simbólico assumiu\\nerroneamente que os sensores poderiam fornecer sentenças com identificadores únicos de objetos. A\\nquestão foi estudada no contexto de compreensão da linguagem por Charniak e Goldman (1992) e no\\ncontexto da vigilância por Huang e Russell (1998) e Pasula \\net al.\\n (1999). Pasula \\net al.\\n (2003)\\ndesenvolveram um modelo complexo gerador para autores, teses e cadeias de citação, envolvendo\\ntanto incerteza relacional como de identidade, e demonstraram alta precisão para a extração de\\ninformações de citação. A primeira linguagem formalmente definida para os modelos de\\nprobabilidade de universo aberto foi a BLOG (Milch \\net al\\n., 2005), que veio com um algoritmo de\\ninferência completo (embora lento) CMMC para todos os modelos bem definidos. (O código do', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 648}),\n",
       " Document(page_content='probabilidade de universo aberto foi a BLOG (Milch \\net al\\n., 2005), que veio com um algoritmo de\\ninferência completo (embora lento) CMMC para todos os modelos bem definidos. (O código do\\nprograma ligeiramente visível na capa deste livro é parte de um modelo BLOG para a detecção de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 648}),\n",
       " Document(page_content='explosões nucleares a partir de sinais sísmicos, como parte do regime de verificação do UN\\nComprehensive Tet Ban Treaty.) Laskey (2008) descreve outra linguagem de modelagem de universo\\naberto chamada \\nredes bayesianas multientidades\\n.\\nComo explicamos no Capítulo 13, os primeiros sistemas probabilísticos perderam o interesse no\\ninício da década de 1970, deixando um vácuo parcial a ser preenchido por métodos alternativos. Os\\nfatores de certeza foram criados para uso no sistema especialista médico MYCIN (Shortliffe, 1976),\\ndestinado a ser tanto uma solução de engenharia quanto um modelo de julgamento humano sob\\nincerteza. A coleção \\nRule-Based Expert Systems\\n (Buchanan e Shortliffe, 1984) fornece uma visão\\ngeral completa do MYCIN e de seus descendentes (veja também Stefik, 1995). David Heckerman\\n(1986) mostrou que uma versão ligeiramente modificada de cálculos do fator de certeza fornece\\nresultados probabilísticos corretos em alguns casos, mas resulta em séria superestimativa da\\nevidência em outros casos. O sistema especialista PROSPECTOR (Duda \\net al.\\n, 1979) usou uma\\nabordagem baseada em regras, na qual as regras eram justificadas por uma suposição (raramente\\nsustentável) de independência global.\\nA teoria de Dempster-Shafer se origina de um ensaio de Arthur Dempster (1968) que propôs uma\\ngeneralização da probabilidade a valores de intervalos em uma regra de combinação para utilizá-los.\\nUm trabalho posterior de Glenn Shafer (1976) levou à visão da teoria de Dempster-Shafer como uma\\nabordagem concorrente para a probabilidade. Pearl (1988) e Ruspini \\net al.\\n (1992) analisam o\\nrelacionamento entre a teoria de Dempster-Shafer e a teoria da probabilidade-padrão.\\nOs conjuntos difusos foram desenvolvidos por Lotfi Zadeh (1965) em resposta à dificuldade\\npercebida de fornecer entradas exatas para sistemas inteligentes. O texto de Zimmermann (2001)\\nfornece uma introdução completa à teoria de conjuntos difusos; os documentos sobre aplicações\\ndifusas estão reunidos em Zimmermann (1999). Como mencionamos no texto, a lógica difusa com\\nfrequência foi percebida incorretamente como uma concorrente direta da teoria da probabilidade,\\nembora de fato ela focalize um conjunto de questões diferente. A \\nteoria da possibilidade\\n (Zadeh,\\n1978) foi introduzida para lidar com a incerteza em sistemas difusos e tem muito em comum com a\\nprobabilidade. Dubois e Prade (1994) fornecem um estudo completo das conexões entre a teoria da\\npossibilidade e a teoria da probabilidade.\\nO ressurgimento da probabilidade dependia principalmente do desenvolvimento das redes\\nbayesianas de Pearl como um método para representar e usar informações de independência\\ncondicional. Esse ressurgimento não veio sem luta; o combativo ensaio de Peter Cheeseman (1985),\\n“In Defense of Probability” e seu artigo posterior “An Inquiry into Computer Understanding”\\n(Cheeseman, 1988, com comentários) deram algum sabor ao debate. Eugene Charniak ajudou a\\napresentar as ideias para pesquisadores de IA com um artigo popular, “Bayesian networks without\\ntears”\\n11\\n (1991), e um livro (1993). O livro de Dean e Wellman (1991) também ajudou a introduzir as\\nredes bayesianas para os pesquisadores de IA. Uma das principais objeções dos logicistas foi o fato\\nde que os cálculos numéricos que a teoria da probabilidade exigia não eram aparentes para a\\nintrospecção e presumiam um nível não realista de precisão em nosso conhecimento incerto. O\\ndesenvolvimento de \\nredes probabilísticas qualitativas\\n (Wellman, 1990a) forneceu uma abstração\\npuramente qualitativa de redes bayesianas, usando a noção de influências positivas e negativas entre\\nvariáveis. Wellman mostra que, em muitos casos, tais informações são suficientes para a tomada de\\ndecisões ótimas sem a necessidade da especificação exata de valores de probabilidade. Goldszmidt', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 649}),\n",
       " Document(page_content='e Pearl (1996) têm uma abordagem semelhante. O trabalho de Adnan Darwiche e Matt Ginsberg\\n(1992) extrai as propriedades básicas de condicionamento e combinação de evidências da teoria da\\nprobabilidade e mostra que elas também podem ser aplicadas em raciocínio lógico e em raciocínio\\ndefault. Com frequência, os programas falam mais alto que as palavras, e a disponibilidade pronta do\\nsoftware de alta qualidade, como a ferramenta Net Bayes (Murphy, 2001), acelerou a adoção da\\ntecnologia.\\nA publicação mais importante para o crescimento das redes bayesianas foi, sem dúvida, o texto\\nProbabilistic Reasoning in Intelligent Systems\\n (Pearl, 1988). Vários textos excelentes (Lauritzen,\\n1996; Jensen, 2001; Korb e Nicholson, 2003; Jensen, 2007; Darwiche, 2009; Koller e Friedman,\\n2009) fornecem tratamentos completos dos tópicos que cobrimos neste capítulo. Novas pesquisas\\nsobre raciocínio probabilístico aparecem tanto em periódicos importantes sobre IA, como \\nArtificial\\nIntelligence\\n e \\nJournal of AI Research\\n, quanto em periódicos mais especializados, como o\\nInternational Journal of Approximate Reasoning\\n.\\nMuitos artigos sobre modelos gráficos, que incluem as redes bayesianas, são publicados em\\nperiódicos especializados em estatística. Os anais das conferências sobre Uncertainty in Artificial\\nIntelligence (UAI), Neural Information Processing Systems (NIPS) e Artificial Intelligence and\\nStatistics (AISTATS) são excelentes fontes de pesquisa atual.\\nEXERCÍCIOS\\n14.1\\n Temos um saco com três moedas tendenciosas \\na\\n, \\nb\\n e \\nc\\n e com probabilidade de 20%, 60% e\\n80%, respectivamente de virar cara. Uma moeda foi retirada aleatoriamente do saco (com\\nprobabilidade igual entre as três moedas) e lançada três vezes para gerar os resultados \\nX\\n1\\n, \\nX\\n2\\n e \\nX\\n3\\n.\\na\\n. Desenhe a rede bayesiana correspondente a essa configuração e defina os TPCs necessários.\\nb\\n. Calcule qual moeda é mais provável que tenha sido retirada do saco se os lançamentos\\nobservados deram cara duas vezes e coroa uma vez.\\n14.2\\n A equação 14.1 define a distribuição conjunta representada por uma rede bayesiana em termos\\ndos parâmetros \\nθ\\n(\\nX\\ni\\n | \\nPais\\n (\\nX\\ni\\n)). Este exercício pede para obter a equivalência entre os parâmetros e\\nas probabilidades condicionais \\nP\\n(\\nX\\ni\\n | \\nPais\\n(\\nX\\ni\\n)) dessa definição.\\na.\\n Considere uma rede simples \\nX\\n → \\nY\\n→ \\nZ\\n com três variáveis booleanas. Utilize as Equações 13.3\\ne 13.6 para expressar a probabilidade condicional P(\\nz\\n | \\ny\\n) como a razão entre duas somas, cada\\numa sobre as entradas na distribuição conjunta \\nP\\n(\\nX\\n, \\nY\\n, \\nZ\\n).\\nb\\n. Agora utilize a Equação 14.1 para escrever essa expressão em termos de parâmetros da rede \\nθ\\n(\\nX\\n), \\nθ\\n (\\nY\\n | \\nX\\n) e \\nθ\\n (\\nZ\\n | \\nY\\n).\\nc\\n. Em seguida, expanda os somatórios da expressão da parte (b) escrevendo explicitamente os\\ntermos para os valores verdadeiros e falsos de cada variável somada. Assumindo que todos os\\nparâmetros da rede satisfazem a restrição \\nΣ\\nxi\\n \\nθ\\n (\\nx\\ni\\n | \\nPais\\n(\\nX\\ni\\n) = 1, mostre que a expressão\\nresultante se reduz para \\nθ\\n (\\nx\\n | \\ny\\n).\\nd\\n. Generalize essa derivação para mostrar que \\nθ\\n (\\nX\\ni\\n|\\nPais\\n(\\nX\\ni\\n) = \\nP\\n(\\nX\\ni\\n|\\nPais\\n (\\nX\\ni\\n)) para qualquer rede', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 650}),\n",
       " Document(page_content='bayesiana.\\n14.3\\n A operação de \\nreversão de arco\\n em uma rede bayesiana permite-nos mudar a direção de um\\narco \\nX\\n → \\nY\\n, enquanto preserva a distribuição de probabilidade conjunta que a rede representa\\n(Shachter, 1986). A reversão de arco pode exigir a introdução de novos arcos: todos os pais de \\nX\\ntambém se tornaram pais de \\nY\\n, e todos os pais de \\nY\\n se tornaram pais de \\nX\\n.\\na\\n. Suponha que \\nX\\n e \\nY\\n comecem com os pais \\nm\\n e \\nn\\n, respectivamente, e que todas as variáveis têm\\nvalores \\nk\\n. Calculando a mudança no tamanho de TCPs de \\nX\\n e \\nY\\n, mostre que o número total de\\nparâmetros da rede não pode diminuir durante a reversão do arco. (\\nDica\\n: Os pais de \\nX\\n e \\nY\\n não\\nprecisam ser separados.)\\nb\\n. Sob que circunstâncias o número total pode permanecer constante?\\nc\\n. Faça \\nU\\n \\n \\nV\\n os pais de \\nX\\n e \\nV\\n \\n \\nW\\n os pais de \\nY\\n, onde \\nU\\n e \\nW\\n são disjuntos. As fórmulas para os\\nnovos TPPs após a reversão de arco são as seguintes:\\nDemonstre que a nova rede expressa a mesma distribuição disjunta sobre todas as variáveis\\ncomo a da rede original.\\n14.4\\n Considere a rede bayesiana na \\nFigura 14.2\\n.\\na.\\n Se nenhuma evidência for observada, \\nRoubo\\n e \\nTerremoto\\n são independentes? Demonstre isso\\npela semântica numérica e pela semântica topológica.\\nb\\n. Se observarmos que \\nAlarme = verdadeiro\\n, \\nRoubo\\n e \\nTerremoto\\n são independentes? Justifique\\nsua resposta calculando se as probabilidades envolvidas satisfazem a definição de\\nindependência condicional.\\n14.5\\n Suponha que em uma rede bayesiana que contém uma variável não observada Y, todas as\\nvariáveis na cobertura de Markov CM(Y) foram observadas.\\na.\\n Demonstre que a remoção do nó Y da rede não irá afetar a distribuição posterior de qualquer\\noutra variável não observada na rede.\\nb.\\n Questione se podemos remover Y se estamos planejando usar (i) amostragem de rejeição (ii)\\nponderação de probabilidade.\\n14.6\\n Seja \\nH\\nx\\n uma variável aleatória que denota a lateralidade de um indivíduo \\nx\\n, com valores\\npossíveis \\nl\\n ou \\nr\\n. Uma hipótese comum é que a lateralidade esquerda ou direita é herdada por um\\nmecanismo simples; ou seja, talvez haja um gene \\nG\\nx\\n, também com valores \\nl\\n ou \\nr\\n, e talvez a\\nlateralidade real acabe praticamente a mesma (com alguma probabilidade \\ns\\n) como sendo o gene que\\num indivíduo possui. Além disso, talvez, o gene tenha a mesma probabilidade de ser herdado de\\nambos os pais de um indivíduo, com pequena probabilidade \\nm\\n diferente de zero de uma mutação\\naleatória trocar a lateralidade.\\na\\n. Qual das três redes na \\nFigura 14.20\\n afirma que \\nP\\n(\\nG\\npai\\n, \\nG\\nmãe\\n, \\nG\\nfilho\\n) = \\nP\\n(\\nG\\npai\\n) \\nP\\n(\\nG\\nmãe\\n) \\nP\\n(\\nG\\nfilho\\n)?', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 651}),\n",
       " Document(page_content='Figura 14.20\\n Três estruturas possíveis para uma rede bayesiana descrevendo a herança genética de\\nlateralidade.\\nb\\n. Qual das três redes faz afirmações de independência que são consistentes com a hipótese sobre\\na herança da lateralidade?\\nc.\\n Qual das três redes é a melhor descrição da hipótese?\\nd.\\n Escreva o TPC para o nó \\nG\\nfilho\\n na rede (a), em termos de \\ns\\n e \\nm\\n.\\ne\\n. Suponha que \\nP\\n(\\nG\\npai\\n = \\nl\\n) = \\nP\\n(\\nG\\nmãe\\n = \\nl\\n) = \\nθ\\n. Na rede (a), derive uma expressão para \\nP\\n(\\nG\\nfilho\\n = \\nl\\n)\\nem termos de \\nm\\n e \\nθ\\n apenas, por condicionamento aos nós do seu pai.\\nf.\\n Em condições de equilíbrio genético, esperamos que a distribuição de genes seja a mesma\\natravés das gerações. Utilize essa opção para calcular o valor de \\nθ\\n e, dado o que você sabe\\nsobre a lateralidade em seres humanos, explique por que a hipótese descrita no início desta\\nquestão deve estar errada.\\n14.7\\n A \\ncobertura de Markov\\n de uma variável foi definida neste capítulo. Prove que uma variável é\\nindependente de todas as outras variáveis na rede, dada sua cobertura de Markov, e derive a\\nEquação 14.12.\\nFigura 14.21\\n Uma rede bayesiana que descreve algumas características do sistema elétrico e\\ndomotor de um carro. Cada variável é booleana, e o valor \\nverdadeiro\\n indica que o aspecto\\ncorrespondente do veículo está em perfeita ordem.\\n14.8\\n Considere a rede para diagnóstico de automóveis mostrada na \\nFigura 14.21\\n.\\na.\\n Estenda a rede com as variáveis booleanas \\nTempoGelado\\n e \\nMotorDePartida\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 652}),\n",
       " Document(page_content='b.\\n Apresente tabelas de probabilidade condicional razoáveis para todos os nós.\\nc.\\n Quantos valores independentes estão contidos na distribuição de probabilidade conjunta para\\noito nós booleanos, supondo-se que não seja conhecida nenhuma relação de independência\\ncondicional válida entre eles?\\nd.\\n Quantos valores de probabilidade independentes contêm suas tabelas de rede?\\ne.\\n A distribuição condicional para \\nPartida\\n poderia ser descrita como uma distribuição \\nE ruidosa\\n.\\nDefina essa família em geral e relacione-a com a distribuição OU ruidosa.\\n14.9\\n Considere a família de redes gaussianas lineares, ilustrada na página 520.\\na.\\n Em uma rede de duas variáveis, seja \\nX\\n1\\n o pai de \\nX\\n2\\n, sendo que \\nX\\n1\\n tem um \\na priori\\n gaussiano, e\\nseja \\nP\\n(\\nX\\n2\\n | \\nX\\n1\\n) uma distribuição gaussiana linear. Mostre que a distribuição conjunta \\nP\\n(\\nX\\n1\\n,\\nX\\n2\\n) é\\num gaussiano multivariado e calcule sua matriz de covariância.\\nb.\\n Prove por indução que a distribuição conjunta para uma rede gaussiana linear geral sobre \\nX\\n1\\n,…,\\nX\\nn\\n também é um gaussiano multivariado.\\n14.10\\n A distribuição probit definida neste capítulo descreve a distribuição de probabilidade para um\\nfilho booleano, dado um único pai contínuo.\\na.\\n Como a definição poderia ser estendida para cobrir vários pais contínuos?\\nb.\\n Como ela poderia ser estendida para lidar com uma variável filha \\nmultivalorada\\n? Considere\\ntanto casos em que os valores do filho estão ordenados (como na seleção de uma marcha\\nenquanto se está dirigindo, dependendo de velocidade, do declive, da aceleração desejada etc.)\\nquanto casos em que eles não estão ordenados (como na seleção de ônibus, trem ou carro para\\nchegar ao trabalho). [\\nSugestão\\n: Considere modos de dividir os valores possíveis em dois\\nconjuntos, a fim de imitar uma variável booleana.]\\n14.11\\n Em sua estação de energia nuclear local, existe um alarme que detecta quando um indicador de\\ntemperatura excede dado limiar. O indicador mede a temperatura do núcleo. Considere as variáveis\\nbooleanas \\nA\\n (o alarme soa), \\nF\\nA\\n (alarme defeituoso) e \\nF\\nG\\n (medidor defeituoso) e os nós de vários\\nvalores \\nG\\n (leitura do medidor) e \\nT\\n (temperatura real do núcleo).\\nFigura 14.22\\n Três redes possíveis para o problema do telescópio.\\na.\\n Trace uma rede bayesiana para esse domínio considerando que o medidor tem maior\\nprobabilidade de falhar quando a temperatura do núcleo fica muito alta.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 653}),\n",
       " Document(page_content='b.\\n Sua rede é uma poliárvore? Por quê?\\nc.\\n Suponha que existam apenas duas temperaturas reais e medidas possíveis, normal e alta; a\\nprobabilidade de que o medidor forneça a temperatura correta é \\nx\\n quando ele está funcionando,\\nmas é \\ny\\n quando ele apresenta defeito. Forneça a tabela de probabilidade condicional associada\\na \\nG\\n.\\nd.\\n Suponha que o alarme funcione corretamente, a menos que esteja defeituoso e, nesse caso, ele\\nnunca tocará. Forneça a tabela de probabilidade condicional associada com \\nA\\n.\\ne.\\n Suponha que o alarme e o medidor estejam funcionando e que o alarme toque. Calcule uma\\nexpressão para a probabilidade de que a temperatura do núcleo esteja muito alta, em termos das\\nvárias probabilidades condicionais na rede.\\n14.12\\n Dois astrônomos em diferentes partes do mundo fazem medições \\nM\\n1\\n e \\nM\\n2\\n do número de\\nestrelas \\nN\\n em alguma região pequena do céu, usando seus telescópios. Normalmente, existe uma\\npequena possibilidade \\ne\\n de erro de até uma estrela em cada direção. Cada telescópio também pode\\n(com uma probabilidade \\nf\\n, muito menor) estar completamente fora de foco (eventos \\nF\\n1\\n e \\nF\\n2\\n), e nesse\\ncaso o cientista vai contar três ou mais estrelas a menos (ou, se \\nN\\n for menor que 3, deixar de detectar\\nquaisquer estrelas). Considere as três redes mostradas na \\nFigura 14.22\\n.\\na.\\n Quais dessas redes bayesianas são representações corretas (mas não necessariamente\\neficientes) das informações precedentes?\\nb.\\n Qual é a melhor rede? Explique.\\nc.\\n Descreva uma distribuição condicional para \\nP\\n(\\nM\\n1\\n | \\nN\\n), para o caso em que \\nN\\n \\n∊\\n {1, 2, 3} e \\nM\\n1\\n \\n∊\\n{0, 1, 2, 3, 4}. Cada entrada na distribuição condicional deve ser expressa como uma função\\ndos parâmetros \\ne\\n e/ou \\nf\\n.\\nd.\\n Suponha \\nM\\n1\\n = 1 e \\nM\\n2\\n = 3. Quais são os números \\npossíveis\\n de estrelas se não supusermos\\nnenhuma restrição \\na priori\\n sobre os valores de \\nN\\n?\\ne.\\n Qual é o número \\nmais provável\\n de estrelas, dadas essas observações? Explique como calcular\\nesse número ou, se não for possível calculá-lo, explique que informações adicionais são\\nnecessárias e como elas afetariam o resultado.\\n14.13\\n Considere a rede mostrada na \\nFigura 14.22\\n (ii) e assuma que dois telescópios trabalham de\\nforma idêntica.\\nN\\n \\n∊\\n {1, 2, 3} e \\nM\\n1\\n, \\nM\\n2\\n \\n∊\\n {0, 1, 2, 3, 4},\\ncom os TPCs simbólicos como descrito no exercício 14.12. Usando o algoritmo de enumeração\\n(\\nFigura 14.9\\n), calcule a distribuição de probabilidade P(N|M\\n1\\n = 2, M\\n2\\n = 2).\\n14.14\\n Considere a rede de Bayes mostrada na \\nFigura 14.23\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 654}),\n",
       " Document(page_content='Figura 14.23\\n Uma rede de Bayes simples com variáveis booleanas \\nB\\n = \\nInfringiuLeiEleitoral\\n, \\nI =\\nIndiciado, M\\n = \\nPromotorPoliticamenteMotivado\\n, \\nG\\n = \\nConsideradoCulpado, J = Preso\\n.\\na\\n. Quais dos seguintes itens são declarados pela \\nestrutura\\n de rede?\\n(i) \\nP\\n(\\nB, I,M\\n) = \\nP\\n(\\nB\\n)\\nP\\n(\\nI\\n)\\nP\\n(\\nM\\n).\\n(ii) \\nP\\n(\\nJ\\n |\\nG\\n) = \\nP\\n(\\nJ\\n | \\nG, I\\n).\\n(iii) \\nP\\n(\\nM\\n | \\nG,B, I\\n) = \\nP\\n(\\nM\\n | \\nG,B, I, J\\n).\\nb\\n. Calcule o valor de \\nP\\n(\\nb\\n, \\ni\\n, ¬\\nm\\n, \\ng\\n, \\nj\\n).\\nc\\n. Calcule a probabilidade de alguém ir para a cadeia uma vez que infringiu a lei, foi indiciado e\\nenfrentou um promotor politicamente motivado.\\nd\\n. Uma \\nindependência específica de contexto\\n permite que uma variável seja independente de\\nalguns de seus pais, dados certos valores de outros. Além das independências condicionais\\nusuais, dadas pela estrutura de grafo, que independência específica de contexto existe na rede de\\nBayes na \\nFigura 14.23\\n?\\ne.\\n Suponha que queiramos adicionar a variável \\nP = PerdãoPresidencial\\n à rede; desenhe a nova\\nrede e explique brevemente os links que adicionou.\\n14.15\\n Considere o algoritmo de eliminação de variáveis \\u200b\\u200bna \\nFigura 14.11\\n.\\na.\\n A \\nSeção 14.4\\n aplica a eliminação de variáveis à consulta\\nP\\n(\\nRoubo\\n | \\nJoãoLiga\\n = \\nverdadeiro\\n, \\nMariaLiga\\n = \\nverdadeiro\\n).\\nExecute os cálculos indicados e verifique se a resposta está correta.\\nb.\\n Conte o número de operações aritméticas executadas e compare-o com o número de operações\\nexecutadas pelo algoritmo de enumeração.\\nc.\\n Suponha que uma rede tenha a forma de uma \\ncadeia\\n: uma sequência de variáveis booleanas \\nX\\n1\\n,\\n…, \\nX\\nn\\n onde \\nPais\\n(\\nX\\ni\\n) = {\\nX\\ni\\n–1\\n} para \\ni\\n = 2,…, \\nn\\n. Qual é a complexidade da computação de \\nP\\n(\\nX\\n1\\n |\\nXn\\n = \\nverdadeiro\\n) usando enumeração? E usando eliminação de variáveis?\\nd.\\n Prove que a complexidade de execução da eliminação de variáveis sobre uma rede de\\npoliárvore é linear no tamanho da árvore para qualquer ordenação de variáveis consistente com\\na estrutura da rede.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 655}),\n",
       " Document(page_content='14.16\\n Investigue a complexidade da inferência exata em redes bayesianas gerais:\\na.\\n Prove que qualquer problema de 3-SAT pode ser reduzido à inferência exata em uma rede\\nbayesiana construída para representar o problema específico e, consequentemente, que a\\ninferência exata é NP-difícil. [\\nSugestão\\n: Considere uma rede com uma variável para cada\\nsímbolo de proposição, uma para cada cláusula e uma para a conjunção de cláusulas.]\\nb.\\n O problema de contar o número de atribuições de satisfação para um problema de 3-SAT é #P-\\ncompleto. Mostre que a inferência exata tem pelo menos a mesma dificuldade.\\n14.17\\n Considere o problema de gerar uma amostra aleatória a partir de uma distribuição\\nespecificada sobre uma única variável. Suponha que um gerador de números aleatórios esteja\\ndisponível e retorne um número aleatório uniformemente distribuído entre 0 e 1.\\na.\\n Seja \\nX\\n uma variável discreta com \\nP\\n(\\nX\\n = \\nx\\ni\\n) = \\np\\ni\\n para \\ni\\n \\n∊\\n {1,…, \\nk\\n}. A \\ndistribuição cumulativa\\nde \\nX\\n fornece a probabilidade de \\nX\\n \\n∊\\n {x\\n1\\n,…, \\nx\\nj\\n} para cada \\nj\\n possível (veja também o Apêndice\\nA). Explique como calcular a distribuição cumulativa no tempo \\nO\\n(\\nk\\n) e como gerar uma única\\namostra de \\nX\\n a partir dela. Esta última operação pode ser realizada em tempo menor que \\nO\\n(\\nk\\n)?\\nb.\\n Suponha agora que queiramos gerar \\nN\\n amostras de \\nX\\n, onde \\nN\\n \\n \\nk\\n. Explique como fazer isso com\\num tempo de execução esperado por amostra que seja \\nconstante\\n (isto é, independente de \\nk\\n).\\nc.\\n Agora, considere uma variável com valores contínuos que tenha uma distribuição parametrizada\\n(por exemplo, gaussiana). Como é possível gerar amostras a partir de tal distribuição?\\nd.\\n Suponha que você queira consultar uma variável de valores contínuos e esteja usando um\\nalgoritmo de amostragem como PONDERAÇÃO-DE-PROBABILIDADE para realizar a\\ninferência. De que maneira você teria de modificar o processo de responder à consulta?\\n14.18\\n Considere a consulta \\nP\\n(\\nChuva\\n | \\nIrrigador\\n = \\nverdadeiro\\n, \\nGramaMolhada\\n = \\nverdadeiro\\n) na\\nFigura 14.12\\n(a) (página 529) e como o CMMC pode responder à consulta.\\na.\\n Quantos estados tem a cadeia de Markov?\\nb.\\n Calcule a \\nmatriz de transição Q\\n que contém \\nθ\\n(\\ny\\n → \\ny’\\n) para todo \\ny\\n, \\ny’\\n.\\nc.\\n O que representa \\nQ\\n2\\n, o quadrado da matriz de transição?\\nd.\\n O que representa \\nQ\\nn\\n à medida que \\nn\\n → ∞?\\ne.\\n Explique como realizar a inferência probabilística em redes bayesianas supondo que \\nQ\\nn\\n esteja\\ndisponível. Esse é um caminho prático de realizar a inferência?\\n14.19\\n Este exercício explora a distribuição estacionária de métodos de amostragem de Gibbs.\\na.\\n A composição convexa [\\nα\\n, \\nθ\\n1\\n, 1–\\nα\\n, \\nθ\\n2\\n] de \\nθ\\n1\\n e \\nθ\\n2\\n é uma distribuição de probabilidade de\\ntransição que primeiro escolhe um de \\nθ\\n1\\n e \\nθ\\n2\\n com probabilidades \\nα\\n e 1–\\nα\\n, respectivamente, e,\\nem seguida, aplica-se o que for escolhido. Demonstre que, se \\nθ\\n1\\n e \\nθ\\n2\\n estão em equilíbrio\\ndetalhado com \\nπ\\n, sua composição também é convexa em equilíbrio detalhado com \\nπ.\\n(Observação: esse resultado justifica uma variante do ASK-GIBBS em que as variáveis são\\nescolhidas de forma aleatória, em vez de amostradas em uma sequência fixa.)\\nb\\n. Prove que, se cada um de \\nθ\\n1\\n e \\nθ\\n2\\n tem \\nπ\\n como distribuição estacionária, a composição', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 656}),\n",
       " Document(page_content='sequencial \\nθ\\n = \\nθ\\n1\\n \\no\\n \\nθ\\n2\\n também tem π como distribuição estacionária.\\n14.20\\n O algoritmo de \\nMetropolis-Hastings\\n é um membro da família CMMC e, como tal, é projetado\\npara gerar amostras \\nx\\n (eventualmente) de acordo com probabilidades-alvo \\nπ\\n(\\nx\\n) (normalmente\\nestamos interessados em amostragem de \\nπ\\n(\\nx\\n) = \\nP\\n(\\nx\\n | \\ne\\n)). Assim como a têmpora simulada, o\\nMetropolis-Hastings opera em duas etapas. Primeiro, faz amostra de um novo estado \\nx\\n′ a partir de\\numa proposta de \\ndistribuição de proposta\\n \\nθ\\n(\\nx\\n′|\\nx\\n), dado o atual estado \\nx\\n. Então, probabilisticamente,\\naceita ou rejeita \\nx\\n′ de acordo com a \\nprobabilidade de aceitação\\nSe a proposta for rejeitada, o estado continua em \\nx\\n.\\na\\n. Considere uma etapa de amostragem de Gibbs comum para uma variável \\nX\\ni\\n específica. Mostre\\nque essa etapa, considerada como uma proposta, é a garantia de ser aceita pelo Metropolis-\\nHastings (assim, a amostragem de Gibbs é um caso especial de Metropolis-Hastings).\\nb\\n. Mostre que o processo de duas etapas anterior, visto como distribuição de probabilidade de\\ntransição, está em equilíbrio detalhado com π.\\n14.21\\n Três times de futebol, \\nA\\n, \\nB\\n e \\nC\\n, jogam entre si uma vez. Cada partida ocorre entre duas\\nequipes, e cada uma pode vencer, empatar ou perder. Cada time tem um grau fixo e desconhecido de\\nqualidade — um inteiro que varia de 0 a 3 — e o resultado de uma partida depende\\nprobabilisticamente da diferença de qualidade entre os dois times.\\na.\\n Construa um modelo de probabilidade relacional para descrever esse domínio e sugira valores\\nnuméricos para todas as distribuições de probabilidade necessárias.\\nb.\\n Construa a rede bayesiana equivalente para as três partidas.\\nc.\\n Suponha que, nas duas primeiras partidas, \\nA\\n vença \\nB\\n e empate com \\nC\\n. Empregando um\\nalgoritmo de inferência exata de sua escolha, calcule a distribuição posterior para o resultado\\nda terceira partida.\\nd.\\n Suponha que existam \\nn\\n times na liga e que temos os resultados para todas as partidas, com\\nexceção da última. Como a complexidade de prognosticar o resultado do último jogo varia com\\nn\\n?\\ne.\\n Investigue a aplicação de CMMC para esse problema. Com que rapidez ele converge na prática\\ne com que facilidade ele aumenta sua escala?\\n1\\n Esse é o nome mais comum, mas existem muitos sinônimos, como \\nrede de crença\\n, \\nrede probabilística\\n, \\nrede causal\\n e \\nmapa de\\nconhecimento\\n. Em estatística, a expressão \\nmodelo gráfico\\n se refere a uma classe um pouco mais ampla, que inclui as redes\\nbayesianas. Uma extensão de redes bayesianas chamada \\nrede de decisão\\n ou \\ndiagrama de influência\\n será focalizada no Capítulo 16.\\n2\\n Também existe um critério topológico geral chamado \\nseparação d\\n para se decidir se um conjunto de nós \\nX\\n é independente\\ncondicionalmente de outro conjunto \\nY\\n, dado um terceiro conjunto \\nZ\\n. O critério é bastante complicado e não é necessário para derivar os\\nalgoritmos deste capítulo; assim, vamos omiti-lo. Os detalhes podem ser encontrados em Pearl (1988) ou Darwiche (2009). Shachter\\n(1998) fornece um método mais intuitivo de averiguar a separação d.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 657}),\n",
       " Document(page_content='3\\n Segue-se que a inferência em redes gaussianas lineares demora apenas o tempo \\nO\\n(\\nn\\n3\\n) no pior caso, independentemente da topologia\\nda rede. Na \\nSeção 14.4\\n, veremos que a inferência para redes de variáveis discretas é NP-difícil.\\n4\\n Uma expressão como \\nΣ\\ne\\n \\nP\\n(\\na, e\\n) significa efetuar o somatório de \\nP\\n(\\nA\\n = \\na\\n, \\nE\\n = \\ne\\n) para todos os valores possíveis de \\ne\\n. Existe uma\\nambiguidade no fato de \\nP\\n(\\ne\\n) ser usada para indicar tanto \\nP\\n(\\nE\\n= \\nverdadeira\\n) quanto \\nP\\n(\\nE\\n = \\ne\\n), mas deve ficar claro a partir do contexto o\\nque se pretende dizer; em particular, no contexto de um somatório, a última forma é a pretendida.\\n5\\n No caso ideal, seria interessante usar uma distribuição de amostragem igual à distribuição posterior verdadeira \\nP\\n(\\nz\\n | \\ne\\n), para levar em\\nconta toda a evidência. Porém, isso não pode ser feito de modo eficiente. Se pudesse, seria possível realizar uma aproximação da\\nprobabilidade desejada até uma precisão arbitrária com um número de amostras polinomial. Pode-se demonstrar que não é possível\\nexistir tal esquema de aproximação em tempo polinomial.\\n6\\n Um teórico dos jogos aconselharia um cliente desonesto a evitar a detecção, recomendando ocasionalmente um bom livro de um\\nconcorrente. Consulte o Capítulo 17.\\n7\\n O nome do \\nmodelo de probabilidade relacional\\n foi dado por Pfeiffer (2000) para uma representação ligeiramente diferente, mas as\\nideias subjacentes são as mesmas.\\n8\\n Algumas condições técnicas devem ser observadas para garantir que o MPR defina uma distribuição adequada. Em primeiro lugar, as\\ndependências devem ser \\nacíclicas\\n; caso contrário, a rede bayesiana resultante terá ciclos e não definirá uma distribuição adequada.\\nSegundo, as dependências devem ser \\nbem fundamentadas\\n, isto é, não pode haver correntes de ancestrais infinitos, tais como poderia\\nsurgir a de dependências recursivas. Sob algumas circunstâncias (ver Exercício 14.6), um cálculo de ponto fixo produz um modelo de\\nprobabilidade bem definida para um MPR recursivo.\\n9\\n A distribuição \\nLogNormal\\n [\\nµ\\n, \\nΣ\\n2\\n] (\\nx\\n) é equivalente a uma distribuição \\nN\\n[\\nµ\\n, σ\\n2\\n] (\\nx\\n) sobre log\\ne\\n (\\nx\\n).\\n10\\n I. J. Good foi o principal estatístico da equipe de quebra de códigos de Turing na Segunda Guerra Mundial. Em \\n2001: Uma Odisseia\\nno Espaço\\n (Clarke, 1968a), Good e Minsky recebem o crédito pela inovadora criação que levou ao desenvolvimento do computador\\nHAL 9000.\\n11\\n O título da versão original do artigo era “Pearl for swine”.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 658}),\n",
       " Document(page_content='O\\nCAPÍTULO\\n \\n15\\nRaciocínio probabilístico temporal\\nEm que tentamos interpretar o presente, entender o passado e talvez prever o\\nfuturo, ainda que muito pouco seja transparente.\\ns agentes em ambientes parcialmente observáveis devem ser capazes de manter o controle do\\nestado atual até a medida que seus sensores permitam. Na \\nSeção 4.4\\n mostramos uma metodologia\\npara fazer isso: um agente mantinha um \\nestado de crença\\n que representava quais os estados do\\nmundo eram possíveis. Com base no estado de crença e em um \\nmodelo de transição\\n, o agente pode\\nprever como o mundo pode evoluir na próxima etapa de tempo. Com base nas percepções\\nobservadas e em um \\nmodelo de sensores\\n, o agente pode atualizar o estado de crença. Essa é uma\\nideia sempre presente: no Capítulo 4, os estados de crença eram representados por conjuntos de\\nestados explicitamente enumerados, enquanto nos Capítulos 7 e 11 eram representados por fórmulas\\nlógicas. Essas abordagens definiram os estados de crença em termos de quais estados do mundo eram\\npossíveis,\\n mas não podiam afirmar nada sobre quais estados eram \\nprováveis\\n ou \\nimprováveis\\n. Neste\\ncapítulo, usamos a teoria da probabilidade para quantificar o grau de crença em elementos do estado\\nde crença.\\nComo mostramos na \\nSeção 15.1\\n, o próprio tempo é tratado da mesma forma como no Capítulo 7:\\num mundo em mudança é modelado com a utilização de uma variável aleatória para cada aspecto do\\nestado do mundo \\nem cada instante no tempo\\n. A transição e os modelos sensoriais podem ser\\nincertos: o modelo de transição descreve a distribuição de probabilidade das variáveis no tempo \\nt\\n,\\ndado o estado do mundo em tempos passados, enquanto o modelo de sensores descreve a\\nprobabilidade de cada percepção no tempo \\nt\\n, dado o estado do mundo atual. A \\nSeção 15.2\\n define as\\ntarefas básicas de inferência e descreve a estrutura geral de algoritmos de inferência para modelos\\ntemporários. Em seguida, descrevemos três tipos específicos de modelos: \\nmodelos ocultos de\\nMarkov\\n, \\nfiltros de Kalman\\n e \\nredes bayesianas dinâmicas\\n (que incluem modelos ocultos de Markov\\ne filtros de Kalman como casos especiais). Finalmente, a \\nSeção 15.6\\n examina os problemas\\nencontrados quando se mantém o controle de mais de uma coisa.\\n15.1 TEMPO E INCERTEZA\\nDesenvolvemos nossas técnicas para raciocínio probabilístico no contexto de mundos \\nestáticos\\n,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 660}),\n",
       " Document(page_content='nos quais cada variável aleatória tem um único valor fixo. Por exemplo, ao consertar um carro,\\nsupomos que qualquer peça que esteja danificada continuará danificada durante o processo de\\ndiagnóstico; nosso trabalho é deduzir o estado do automóvel a partir da evidência observada, que\\ntambém permanece fixa.\\nAgora, considere um problema ligeiramente diferente: tratar um paciente diabético. Como no caso\\ndo conserto de automóveis, temos evidências, como doses de insulina recentes, alimentação,\\nmedições de açúcar no sangue e outros sinais físicos. A tarefa é avaliar o estado atual do paciente,\\ninclusive o nível real de açúcar no sangue e o nível de insulina. Dadas essa informações, podemos\\ntomar uma decisão sobre a alimentação e a dose de insulina do paciente. Diferentemente do caso de\\nconserto de automóveis, aqui os aspectos \\ndinâmicos\\n do problema são essenciais. Os níveis de\\naçúcar no sangue e as medições subsequentes podem mudar rapidamente com o tempo, dependendo\\nda alimentação e das doses de insulina recentes do paciente, de sua atividade metabólica, da hora do\\ndia, e assim por diante. Para avaliar o estado atual a partir do histórico de evidência e prever os\\nresultados de ações de tratamento, devemos modelar essas mudanças.\\nAs mesmas considerações surgem em muitos outros contextos, tal como acompanhar a localização\\ndo robô, o controle da atividade econômica de uma nação, até dar sentido a uma sequência de\\npalavras faladas. Como é possível modelar situações dinâmicas como essas?\\n15.1.1 Estados e observações\\nVemos o mundo como uma série de instantâneos, ou \\nfatias de tempo\\n, cada uma das quais contém\\num conjunto de variáveis aleatórias, algumas observáveis, e outras, não.\\n1\\n Por simplicidade, vamos\\nsupor que o mesmo subconjunto de variáveis seja observável em cada fatia de tempo (embora isso\\nnão seja estritamente necessário em nada do que será discutido a seguir). Usaremos \\nX\\nt\\n para denotar o\\nconjunto de variáveis de estados no tempo \\nt,\\n que assumimos ser não observáveis, e \\nE\\nt\\n para denotar o\\nconjunto de variáveis de evidência observáveis. A observação no tempo \\nt\\n é \\nE\\nt\\n = \\ne\\nt\\n para algum\\nconjunto de valores \\ne\\nt\\n.\\nConsidere o exemplo a seguir: suponha que você seja o guarda de segurança em alguma instalação\\nsubterrânea secreta. Você quer saber se hoje está chovendo, mas seu único acesso ao mundo exterior\\nocorre a cada manhã, quando vê o diretor entrando com ou sem guarda-chuva. Para cada dia \\nt\\n, o\\nconjunto \\nE\\nt\\n contém portanto uma única variável de evidência \\nGuarda-chuvat\\n ou \\nG\\nt\\n para abreviar\\n(indicando se o guarda-chuva aparece ou não) e o conjunto \\nX\\nt\\n contém uma única variável de estado\\nChuva\\nt\\n ou \\nC\\nt\\n (indicando se está chovendo). Outros problemas podem envolver conjuntos maiores de\\nvariáveis. No exemplo do diabetes, poderíamos ter variáveis de evidência como\\nAçúcarNoSangueMedido\\nt\\n e \\nPulsação\\nt\\n, e variáveis de estados como \\nAçúcarNoSangue\\nt\\n e\\nConteúdoDoEstômago\\nt\\n. (Observe que \\nAçúcarNoSangue\\nt\\n e \\nMedidaAçúcarNoSangue\\nt\\n não são as\\nmesmas variáveis; essa é a forma como tratamos com medidas ruidosas de quantidades reais.)\\nO intervalo entre fatias de tempo também depende do problema. Para monitoramento de diabetes,\\num intervalo apropriado poderia ser uma hora, em vez de um dia. Neste capítulo, assumiremos o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 661}),\n",
       " Document(page_content='intervalo entre fatias como fixo; assim poderemos rotular tempos como inteiros. Presumiremos que a\\nsequência de estados se inicie em \\nt\\n = 0; por diversas razões que não nos interessam no momento,\\nvamos supor que a evidência comece a chegar em \\nt\\n = 1 e não em \\nt\\n = 0. Consequentemente, nosso\\nmundo de guarda-chuva é representado por variáveis de estados \\nR\\n0\\n, \\nR\\n1\\n, \\nR\\n2\\n,… e por variáveis de\\nevidência \\nU\\n1\\n,\\nU\\n2\\n,… Usaremos a notação \\na\\n:\\nb\\n para denotar a sequência de inteiros de \\na\\n até \\nb\\n(inclusive) e a notação \\nX\\na:b\\n para denotar o conjunto correspondente de variáveis desde \\nX\\nA\\n até \\nX\\nB\\n.\\nPor exemplo, \\nU\\n1:3\\n corresponde às variáveis \\nU\\n1\\n, \\nU\\n2\\n, \\nU\\n3\\n.\\n15.1.2 Modelos de transição e de sensores\\nTendo decidido o conjunto de variáveis de estado e evidência para dado problema, a próxima\\netapa é especificar como o mundo evolui (o modelo de transição) e como as variáveis de evidência\\nobtêm seus valores (o modelo de sensores).\\nO modelo de transição especifica a distribuição de probabilidade sobre as variáveis de estado\\nmais recente, dados os valores anteriores, ou seja, \\nP\\n(\\nX\\nt\\n | \\nX\\n0:\\nt\\n−1\\n). Agora enfrentamos um problema: o\\nconjunto \\nX\\n0:\\n \\nt\\n−1\\n é ilimitado em tamanho à medida que \\nt\\n aumenta. Resolvemos o problema fazendo uma\\nsuposição de Markov —\\n que o estado atual depende apenas de \\num número fixo\\n \\nfinito\\n de estados\\nanteriores. Os processos que satisfazem essa suposição foram estudados em profundidade\\ninicialmente pelo estatístico russo Andrei Markov (1856−1922) e são chamados de \\nprocessos de\\nMarkov ou cadeias de Markov\\n. Há vários tipos de processos; o mais simples é o \\nprocesso de\\nMarkov de primeira ordem\\n, em que o estado atual depende apenas do estado anterior e não de\\nquaisquer estados anteriores. Em outras palavras, um estado fornece informação suficiente para\\ntornar o futuro condicionalmente independente do passado, e temos\\nAssim, em um processo de Markov de primeira ordem, o modelo de transição é a distribuição\\ncondicional \\nP\\n(\\nX\\nt\\n | \\nX\\nt\\n−1\\n). O modelo de transição para um processo de Markov de segunda ordem é a\\ndistribuição condicional \\nP\\n(\\nX\\nt\\n |\\nX\\nt\\n– 2\\n, \\nX\\nt\\n–1\\n). A \\nFigura 15.1\\n mostra as estruturas de redes bayesianas\\ncorrespondentes a processos de Markov de primeira e segunda ordem.\\nFigura 15.1\\n (a) Estrutura de rede bayesiana correspondente a um processo de Markov de primeira\\nordem como estado definido pelas variáveis \\nX\\nt\\n. (b) Um processo de Markov de segunda ordem.\\nMesmo com a suposição de Markov ainda há um problema: existem infinitos valores possíveis de\\nt\\n. Precisamos especificar uma distribuição diferente para cada etapa de tempo? Evitaremos esse', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 662}),\n",
       " Document(page_content='problema assumindo que as mudanças no estado do mundo são causadas por um \\nprocesso\\nestacionário\\n, isto é, um processo de mudança que é governado por leis que não se alteram ao longo\\ndo tempo (não confunda \\nestacionário\\n com \\nestático\\n: em um processo \\nestático\\n, o próprio estado não\\nmuda). No mundo do guarda-chuva, então, a probabilidade condicional de chuva, \\nP\\n(\\nR\\nt\\n |\\nR\\nt\\n−1\\n), é a\\nmesma para todo \\nt\\n, e temos apenas que especificar uma tabela de probabilidade condicional.\\nAgora para o modelo de sensores. As variáveis de evidência \\nE\\nt\\n poderiam depender de variáveis \\nanteriores, bem como as variáveis de estado atual, mas qualquer estado que seja eficiente deve ser\\nsuficiente para gerar os valores de sensor correntes. Assim, fazemos uma \\nsuposição de sensores de\\nMarkov\\n como segue:\\nAssim, \\nP\\n(\\nE\\nt\\n | \\nX\\nt\\n) é o nosso modelo de sensor (às vezes chamado de \\nmodelo de observação\\n). A\\nFigura 15.2\\n mostra tanto o modelo de transição como o modelo de sensor para o exemplo do guarda-\\nchuva. Observe a direção da dependência entre estado e sensores: as setas vão desde o estado real\\ndo mundo até os valores do sensor, pois o estado do mundo faz com que os sensores assumam\\nvalores particulares: a chuva \\nfaz com que\\n o guarda-chuva apareça. (É claro que o processo de\\ninferência se dá no sentido contrário; a distinção entre o sentido de dependências modeladas e o\\nsentido da inferência é uma das principais vantagens das redes bayesianas.)\\nFigura 15.2\\n A estrutura de rede bayesiana e as distribuições condicionais que descrevem o mundo de\\nguarda-chuva. O modelo de transição é \\nP\\n(\\nChuva\\nt\\n | \\nChuva\\nt\\n–1\\n) e o modelo de sensores é \\nP\\n(\\nGuarda-\\nchuva\\nt\\n | \\nChuva\\nt\\n).\\nAlém de especificar os modelos de transição e de sensores, precisamos dizer como tudo iniciou\\n— a distribuição de probabilidade anterior no tempo 0, \\nP\\n(\\nX\\n0\\n). Com isso, temos uma especificação\\nda distribuição conjunta completa sobre todas as variáveis, usando a Equação 14.2. Para qualquer \\nt\\n,\\nOs três termos do lado direito são o modelo do estado inicial \\nP\\n(\\nX\\n0\\n), o modelo de transição\\nP\\n(\\nX\\ni\\n|\\nX\\ni\\n−1\\n) e o modelo de sensores \\nP\\n(\\nE\\ni\\n|\\nX\\ni\\n).\\nA estrutura na \\nFigura 15.2\\n supõe um processo de Markov de primeira ordem porque se supõe que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 663}),\n",
       " Document(page_content='a probabilidade de chuva dependa apenas de ter chovido ou não no dia anterior. O fato de tal\\nhipótese ser razoável depende do próprio domínio. A hipótese de Markov de primeira ordem afirma\\nque as variáveis de estados contêm \\ntodas\\n as informações necessárias para caracterizar a distribuição\\nde probabilidade para a próxima fatia de tempo. Às vezes, a hipótese é exatamente verdadeira — por\\nexemplo, se uma partícula estiver executando um percurso aleatório ao longo do eixo \\nx\\n, mudando sua\\nposição em ±1 a cada período de tempo e depois usando a coordenada \\nx\\n à medida que o estado\\nfornece um processo de Markov de primeira ordem. Outras vezes, a hipótese é apenas aproximada,\\ncomo no caso da previsão de chuva apenas com base no fato de ter chovido ou não no dia anterior.\\nHá duas formas de melhorar a exatidão dessa aproximação:\\n1. Aumentar a ordem do modelo de processo de Markov. Por exemplo, poderíamos criar um\\nmodelo de segunda ordem adicionando \\nChuva\\nt\\n–2\\n como um pai de \\nChuva\\nt\\n, o que poderia resultar\\nem previsões um pouco mais precisas. Por exemplo, em Palo Alto, Califórnia, raramente chove\\nmais do que dois dias seguidos.\\n2. Aumentar o conjunto de variáveis de estados. Por exemplo, poderíamos adicionar \\nEstação\\nt\\n para\\nnos permitir incorporar registros históricos de estações chuvosas ou poderíamos adicionar\\nTemperatura\\nt\\n, \\nUmidade\\nt\\n e \\nPressão\\nt\\n \\n(\\ntalvez em uma série de locais) para nos dar a\\npossibilidade de usar um modelo físico de condições chuvosas.\\nO Exercício 15.1 pede para mostrar que a primeira solução — aumentar a ordem — sempre pode\\nser reformulada como um aumento no conjunto de variáveis de estados, mantendo-se a ordem fixa.\\nObserve que a adição de variáveis de estados poderia melhorar a capacidade de previsão do\\nsistema, mas também aumentaria os \\nrequisitos\\n de previsão: agora, temos de prever também as novas\\nvariáveis. Desse modo, estamos procurando por um conjunto de variáveis “autossuficiente”, o que na\\nrealidade significa que temos de entender a “física” do processo que está sendo modelado. O\\nrequisito de modelagem precisa do processo obviamente será reduzido se pudermos adicionar novos\\nsensores (por exemplo, medições de temperatura e pressão) que forneçam diretamente informações\\nsobre as novas variáveis de estados.\\nPor exemplo, considere o problema de acompanhar um robô que vaga ao acaso no plano X−Y.\\nSeria possível propor que a posição e a velocidade fossem um conjunto suficiente de variáveis de\\nestados: alguém poderia simplesmente usar as leis de Newton para calcular a nova posição, e a\\nvelocidade poderia mudar de forma imprevisível. Porém, se o robô for alimentado por bateria, o\\nesgotamento da carga da bateria tenderá a ter um efeito sistemático sobre a mudança na velocidade.\\nTendo em vista que isso, por sua vez, depende da quantidade de energia utilizada por todas as\\nmanobras anteriores, a propriedade de Markov é violada. Podemos restaurar a propriedade de\\nMarkov incluindo o nível de carga \\nBateria\\nt\\n como uma das variáveis de estados que compõem \\nX\\nt\\n.\\nIsso ajuda a prever o movimento do robô, mas, por outro lado, exige um modelo para prever \\nBateria\\nt\\na partir de \\nBateria\\nt\\n–1\\n e da velocidade. Em alguns casos, isso pode ser feito de forma confiável;\\npercebemos que o erro se acumula através do tempo. Nesse caso, a exatidão será melhorada\\nadicionando-se um novo sensor\\n para indicar o nível de carga da bateria.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 664}),\n",
       " Document(page_content='15.2 INFERÊNCIA EM MODELOS TEMPORAIS\\nTendo configurado a estrutura de um modelo temporal genérico, podemos formular as tarefas\\nbásicas de inferência que devem ser resolvidas:\\n•  \\nFiltragem:\\n Essa é a tarefa que consiste em calcular o \\nestado de crença\\n — a distribuição\\nposterior sobre o estado mais recente — dada toda a evidência até o momento. A filtragem\\n2\\n é\\ntambém chamada de \\nestimativa de estado\\n. Em nosso exemplo, desejamos calcular \\nP(X\\nt\\n | \\ne\\n1:\\nt\\n).\\nNo exemplo do guarda-chuva, isso significaria calcular a probabilidade de chuva hoje, dadas\\ntodas as observações do portador de guarda-chuva feitas até agora. A filtragem é o que um\\nagente racional precisa fazer, a fim de manter o controle do estado atual, de forma que possam\\nser tomadas decisões racionais. Ocorre que um cálculo quase idêntico fornece a \\nprobabilidade\\nda sequência de evidências \\nP\\n(\\ne\\n1:\\nt\\n).\\n•  \\nPrevisão:\\n Essa é a tarefa de calcular a distribuição posterior sobre o estado \\nfuturo\\n, dada toda a\\nevidência até o momento. Ou seja, desejamos calcular \\nP\\n(\\nX\\nt\\n+\\nk\\n | \\ne\\n1:\\nt\\n) para algum \\nk\\n > 0. No\\nexemplo de guarda-chuva, isso poderia significar calcular a probabilidade de chuva daqui a três\\ndias, dadas todas as observações do portador de guarda-chuva feitas até agora. A previsão é útil\\npara avaliar cursos de ação possíveis baseados nos resultados esperados.\\n•  \\nSuavização\\n: Essa é a tarefa de calcular a distribuição posterior sobre um estado \\npassado\\n dada\\ntoda a evidência até o presente. Isto é, desejamos calcular \\nP\\n(\\nX\\nk\\n | \\ne\\n1:\\nt\\n) para algum \\nk\\n tal que 0 ≤ \\nk\\n< \\nt\\n. No exemplo do guarda-chuva, isso pode significar o cálculo da probabilidade de ter chovido\\nna quarta-feira passada, dadas todas as observações do portador de guarda-chuva feitas até hoje.\\nA suavização fornece uma estimativa melhor do estado do que a estimativa que estava disponível\\nna época porque incorpora uma evidência maior.\\n3\\n•  \\nExplicação mais provável\\n: Dada uma sequência de observações, poderíamos desejar encontrar\\na sequência de estados que mais provavelmente gerou tais observações. Isto é, desejamos\\ncalcular \\n \\nP\\n(\\nx\\n1:\\nt\\n | \\ne\\n1:\\nt\\n). Por exemplo, se o guarda-chuva aparecer em cada um dos três\\nprimeiros dias e estiver ausente no quarto dia, a explicação mais provável será a de que choveu\\nnos três primeiros dias e não choveu no quarto dia. Os algoritmos para essa tarefa são úteis em\\nmuitas aplicações, inclusive no reconhecimento da fala — em que o objetivo é descobrir a\\nsequência de palavras mais provável, dada uma série de sons — e na reconstrução de cadeias de\\nbits transmitidos sobre um canal ruidoso.\\nAlém dessa\\ns\\n tarefas de inferência, temos também\\n•  \\nAprendizagem\\n: Os modelos de transição e de sensores, se ainda não são conhecidos, podem ser\\naprendidos de observações. Da mesma maneira que nas redes bayesianas estáticas, o\\naprendizado de redes bayesianas dinâmicas pode ser realizado como um subproduto de\\ninferência. A inferência fornece uma estimativa de quais transições realmente ocorreram e de\\nquais estados geraram as leituras de sensores, e essas estimativas podem ser usadas para\\natualizar os modelos. Os modelos atualizados fornecem novas estimativas, e o processo iterage\\npara a convergência. O processo global é uma instância da maximização de expectativas, ou', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 665}),\n",
       " Document(page_content='algoritmo EM\\n (veja a \\nSeção 20.3\\n).\\nNote que o aprendizado exige a inferência de suavização total, e não a filtragem, porque a\\nsuavização fornece melhores estimativas dos estados do processo. O aprendizado com filtragem\\npode deixar de convergir corretamente; por exemplo, considere o problema de aprender para\\nsolucionar assassinatos: a menos que você seja testemunha, a suavização será \\nsempre\\n exigida para se\\ndeduzir o que aconteceu na cena do crime, a partir das variáveis observáveis.\\nO restante desta seção descreve algoritmos genéricos para as quatro tarefas de inferência,\\nindependentemente do tipo particular de modelo empregado. Nas seções subsequentes serão\\ndescritas as melhorias específicas de cada modelo.\\n15.2.1 Filtragem e previsão\\nComo ressaltamos na \\nSeção 7.7.3\\n, um algoritmo de filtragem precisa manter uma estimativa do\\nestado atual e atualizá-la, em vez de retroceder ao longo da história inteira de percepções para cada\\natualização (caso contrário, o custo de cada atualização aumenta à medida que o tempo passa). Em\\noutras palavras, dado o resultado da filtragem até o tempo \\nt\\n, é possível calcular facilmente o\\nresultado correspondente a \\nt\\n + 1 a partir da nova evidência \\ne\\nt\\n+1\\n. Ou seja,\\npara alguma função \\nf\\n. Esse processo é chamado, com frequência, \\navaliação recursiva\\n. Podemos\\nvisualizar o cálculo como se ele fosse de fato composta por duas partes: primeiro, a distribuição de\\nestados atual é projetada adiante, de \\nt\\n para \\nt\\n + 1; em seguida, ela é atualizada com a utilização da\\nnova evidência \\ne\\nt\\n+1\\n. Esse processo de duas partes emerge de forma bastante simples quando a\\nfórmula é rearranjada:\\nAqui e ao longo deste capítulo, \\nα\\n é uma constante de normalização usada para fazer as\\nprobabilidades terem soma igual a 1. O segundo termo, \\nP\\n(\\nX\\nt\\n+1\\n | \\ne\\n1:\\nt\\n), representa uma previsão de um\\npasso para o estado seguinte, e o primeiro termo atualiza esse outro com a nova evidência; note que\\nP\\n(\\ne\\nt\\n+1\\n | \\nX\\nt\\n+1\\n) pode ser obtida diretamente a partir do modelo de sensores. Agora, obtemos a previsão\\nde um passo correspondente ao estado seguinte por condicionamento sobre o estado atual \\nX\\nt\\n:\\n Dentro do somatório, o primeiro fator é simplesmente o modelo de transição, e o segundo vem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 666}),\n",
       " Document(page_content='da distribuição de estados atual. Consequentemente, temos a formulação recursiva desejada.\\nPodemos imaginar a estimativa filtrada \\nP\\n(\\nX\\nt\\n |\\ne\\n1:\\nt\\n) como uma “mensagem” \\nf\\n1:\\nt\\n que é propagada ao\\nlongo da sequência, modificada por cada transição e atualizada por cada nova observação. O\\nprocesso é dado por:\\nonde PARAFRENTE implementa a atualização descrita na Equação 15.5 e o processo começa com\\nf\\n1:0\\n = \\nP\\n(\\nX\\n0\\n). Quando todas as variáveis de estados são discretas, o tempo para cada atualização é\\nconstante (isto é, independentemente de \\nt\\n) e o espaço exigido também é constante. (É claro que as\\nconstantes dependem do tamanho do espaço de estados e do tipo específico do modelo temporal em\\nquestão.) \\nOs requisitos de tempo e de espaço para atualização devem ser constantes se um agente\\ncom memória limitada tiver de controlar a distribuição do estado atual sobre uma sequência\\nilimitada de observações\\n.\\nVamos ilustrar o processo de filtragem para dois passos do exemplo básico do guarda-chuva\\n(\\nFigura 15.2\\n). Isto é, vamos calcular \\nP\\n(\\nR\\n2\\n | \\nu\\n1:2\\n) como segue:\\n•  No dia 0, não temos observações, apenas as crenças anteriores do guarda de segurança; vamos\\nsupor que consista em \\nP\\n(R0) = \\n〈\\n0,5, 0,5\\n〉\\n.\\n•  No dia 1, o guarda-chuva aparece e, assim, \\nU\\n1\\n = \\nverdadeiro\\n. A previsão de \\nt\\n = 0 até \\nt\\n =1 é dada\\npor:\\nEm seguida, a etapa de atualização simplesmente multiplica pela probabilidade da evidência\\npara \\nt\\n = 1 e normaliza, como mostrado na Equação 15.4:\\n•  No dia 2, o guarda-chuva aparece, então \\nU\\n2\\n = \\nverdadeiro\\n. A previsão a partir de \\nt\\n =1 até \\nt\\n = 2 é:\\ne sua atualização com a evidência correspondente a \\nt\\n = 2 fornece:\\nIntuitivamente, a probabilidade de chuva aumenta do dia 1 para o dia 2 porque a chuva persiste. O', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 667}),\n",
       " Document(page_content='Exercício 15.2(a) pede para investigar mais a fundo essa tendência.\\nA tarefa de \\nprevisão\\n pode ser vista simplesmente como a filtragem sem a adição de nova\\nevidência. De fato, o processo de filtragem já incorpora uma previsão de um passo e é fácil derivar o\\ncálculo recursivo a seguir para prever o estado em \\nt\\n + \\nk\\n + 1 a partir de uma previsão para \\nt\\n + \\nk\\n:\\nNaturalmente, esse cálculo envolve apenas o modelo de transição e não o modelo de sensores.\\nÉ interessante considerar o que acontece à medida que tentamos prever mais e mais à frente no\\nfuturo. Como mostra o Exercício 15.2(b), a distribuição prevista para chuva converge para um ponto\\nfixo \\n〈\\n0,5, 0,5\\n〉\\n, após o qual ela permanece constante durante todo o tempo. Essa é a \\ndistribuição\\nestacionária\\n do processo de Markov definido pelo modelo de transição. Conhecemos uma\\ninformação importante sobre as propriedades de tais distribuições e sobre o \\ntempo de mistura\\n —\\nem linhas gerais, o tempo necessário para alcançar o ponto fixo. Em termos práticos, isso condena ao\\nfracasso qualquer tentativa de prever o estado \\nreal\\n para uma série de passos que seja maior que uma\\npequena fração do tempo de mistura, a menos que a distribuição estacionária em si esteja aumentada\\nem uma pequena área do espaço de estados. Quanto mais incerteza existir no modelo de transição,\\nmais curto será o tempo de mistura e mais o futuro ficará obscurecido.\\nAlém da filtragem e da previsão, podemos usar uma recursão para a frente para calcular a\\nprobabilidade\\n da sequência de evidência, \\nP\\n(\\ne\\n1:t\\n). Essa é uma quantidade útil se quisermos comparar\\ndiferentes modelos temporais que podem ter produzido a mesma sequência de evidência (por\\nexemplo, dois modelos diferentes para a persistência da chuva). No caso dessa recursão, utilizamos\\numa mensagem de probabilidade \\nl\\n1:t\\n (\\nX\\nt\\n) = \\nP\\n(\\nX\\nt\\n, \\ne\\n1:\\nt\\n). É um exercício simples mostrar que o cálculo\\nda mensagem é idêntico à mensagem da filtragem:\\nTendo calculado \\nl\\n1:\\nt\\n, obtemos a probabilidade real pelo somatório de \\nX\\nt\\n:\\nObserve que a mensagem de probabilidade representa as probabilidades de sequências de\\nevidências cada vez mais longas à medida que o tempo passa e, assim, se torna numericamente cada\\nvez menor, levando a um problema de subfluxo com aritmética de ponto flutuante. Na prática esse é\\num problema importante, mas não vamos entrar no mérito das soluções aqui.\\n15.2.2 Suavização\\nComo vimos antes, a \\nsuavização\\n é o processo de calcular a distribuição sobre estados anteriores,\\ndada a evidência até o presente; isto é, \\nP\\n(\\nX\\nk\\n | \\ne\\n1:\\nt\\n) = para 0 ≤ \\nk\\n < \\nt\\n (veja a \\nFigura 15.3\\n). Em', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 668}),\n",
       " Document(page_content='antecipação a outra abordagem de transmissão de mensagens recursiva, podemos dividir o cálculo\\nem duas partes: a evidência até \\nk\\n e a evidência de \\nk\\n + 1 até \\nt\\n,\\nFigura 15.3\\n A suavização calcula \\nP\\n(\\nX\\nk\\n | \\ne\\n1:\\nt\\n), a distribuição posterior do estado em algum tempo\\npassado \\nk\\n, dada uma sequência completa de observações desde 1 até \\nt\\n.\\nonde “×” representa multiplicação de vetores pontuais. Aqui definimos uma mensagem “para trás”\\nb\\nk\\n+1:\\nt\\n = \\nP\\n(\\ne\\nk\\n+1:\\nt\\n | \\nX\\nk\\n), análoga à mensagem para a frente \\nf\\n1:\\nk\\n. A mensagem para a frente \\nf\\n1:\\nk\\n pode ser\\ncalculada pela filtragem para a frente de 1 até \\nk\\n, dada pela Equação 15.5. Em consequência disso, a\\nmensagem para trás \\nb\\nk\\n+1:\\nt\\n pode ser calculada por um processo recursivo que funciona no \\nsentido\\ninverso\\n a partir de \\nt\\n:\\nonde o último passo segue pela independência condicional de \\ne\\nk\\n+1\\n e \\ne\\nk\\n+2:\\nt\\n, dado \\nX\\nk\\n+1\\n. Dos três\\nfatores desse somatório, o primeiro e o terceiro são obtidos diretamente a partir do modelo, e o\\nsegundo é a “chamada recursiva”. Usando a notação de mensagem, temos:\\nb\\nk\\n+1:\\nt\\n = PARATRÁS(\\nb\\nk\\n+2:\\nt\\n, e\\nk\\n+1:\\nt\\n)\\nonde PARATRÁS implementa a atualização descrita na Equação 15.9. Como ocorre no caso da\\nrecursão para a frente, o tempo e o espaço necessários para cada atualização são constantes e, desse\\nmodo, independentes de \\nt\\n. Agora, podemos ver que os dois termos da Equação 15.8 podem ser\\ncalculados por recursões através do tempo, um deles no sentido direto a partir de 1 até \\nk\\n e usando a\\nequação de filtragem 15.5, e o outro funcionando no sentido inverso de \\nt\\n até \\nk +\\n 1 e usando a\\nEquação 15.9. Observe que a fase para a frente é inicializada com \\nb\\nt\\n+1\\n:t\\n = \\nP\\n(\\ne\\nt\\n+1:\\nt\\n | \\nX\\nt\\n) = \\nP\\n( |\\nX\\nt\\n )\\n1\\n,\\nonde \\n1\\n é um vetor de valores unitários (como \\ne\\nt\\n+1:\\nt\\n é uma sequência vazia, a probabilidade de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 669}),\n",
       " Document(page_content='observá-la é 1).\\nAgora, vamos aplicar esse algoritmo ao exemplo do guarda-chuva calculando a estimativa\\nsuavizada para a probabilidade de chuva em tempo \\nk\\n = 1, dadas as observações sobre o guarda-\\nchuva nos dias 1 e 2. A partir da Equação 15.8, essa estim ativa é dada por:\\nJá sabemos que o primeiro termo é \\n〈\\n0,818, 0,182\\n〉\\n, a partir do processo de filtragem para a frente\\ndescrito anteriormente. O segundo termo pode ser calculado pela aplicação da recursão para trás na\\nEquação 15.9:\\nInserindo essa expressão na Equação 15.10, descobrimos que a estimativa suavizada para chuva\\nno dia 1 é:\\nP\\n(\\nR\\n1\\n|\\nu\\n1\\n, \\nu\\n2\\n) = \\na\\n \\n〈\\n0,818, 0,182\\n〉\\n × \\n〈\\n0,69, 0,41\\n〉\\n ≈ \\n〈\\n0,883, 0,117\\n〉\\n.\\nDesse modo, a estimativa suavizada de chuva no dia 1é \\nmais alta\\n que a estimativa filtrada (0,818),\\nnesse caso. Isso ocorre porque o guarda-chuva no dia 2 torna mais provável ter chovido no dia 2; por\\nsua vez, como a chuva tende a persistir, isso torna mais provável ter chovido no dia 1.\\nAmbas as recursões, para a frente e para trás, demoram um período de tempo constante por passo;\\nconsequentemente, a complexidade de tempo de suavização com relação à evidência \\ne\\n1:t\\n é \\nO\\n(\\nt\\n). Essa\\né a complexidade para suavização em um período de tempo específico \\nk\\n. Se quisermos suavizar a\\nsequência inteira, um método óbvio será simplesmente executar todo o processo de suavização, uma\\nvez para cada período de tempo a ser suavizado. Isso resulta em uma complexidade de tempo igual a\\nO\\n(\\nt\\n2\\n). Uma abordagem melhor utiliza uma aplicação muito simples de programação dinâmica para\\nreduzir a complexidade a \\nO\\n(\\nt\\n). Aparece uma pista na análise precedente do exemplo de guarda-\\nchuva, onde fomos capazes de reutilizar os resultados da fase de filtragem para a frente. A chave\\npara o algoritmo de tempo linear é \\nregistrar os resultados\\n da filtragem para a frente sobre a\\nsequência inteira. Em seguida, executamos a recursão para trás desde \\nt\\n até 1, calculando a estimativa\\nsuavizada em cada passo \\nk\\n da mensagem para trás calculada \\nb\\nk\\n+1:\\nt\\n e da mensagem para a frente\\narmazenada \\nf\\n1:\\nk\\n. O algoritmo, apropriadamente chamado \\nalgoritmo para a frente-para trás\\n, é\\nmostrado na \\nFigura 15.4\\n.\\nfunção\\n PARAFRENTE-PARATRÁS(\\nev\\n, \\nanterior\\n) \\nretorna\\n um vetor de distribuições de\\nprobabilidade\\n    \\nentradas: ev\\n, um vetor de valores de evidência correspondentes aos passos 1, . . . , \\nt\\nanterior\\n, a distribuição anterior sobre o estado inicial, \\nP\\n(\\nX\\n0\\n)\\n    \\nvariáveis locais: fv\\n, um vetor de mensagens para a frente correspondentes aos passos 0, . . . , \\nt\\nb\\n, uma representação da mensagem para trás, formada inicialmente apenas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 670}),\n",
       " Document(page_content='por valores 1\\nsv\\n, um vetor de estimativas suavizadas correspondentes aos passos 1, ... , \\nt\\n    \\n    \\nfv\\n[0] ← \\nanterior\\n    \\npara\\n \\ni\\n = 1 \\naté\\n \\nt\\n \\nfaça\\n    \\nfv\\n[\\ni\\n] ← PARAFRENTE(\\nfv\\n[\\ni\\n – 1], \\nev\\n[\\ni\\n])\\n    \\npara\\n \\ni\\n = \\nt\\n \\ndescendo até\\n 1 \\nfaça\\n    \\nsv\\n[\\ni\\n] ← NORMALIZAR(\\nfv\\n[\\ni\\n] × \\nb\\n)\\n    \\nb\\n ← PARATRÁS(\\nb\\n, \\nev\\n[\\ni\\n])\\n    \\nretornar sv\\nFigura 15.4\\n Algoritmo para a frente-para trás de suavização para cálculo de probabilidades\\nposteriores de uma sequência de estados, dada uma sequência de observações. Os operadores\\nPARAFRENTE e PARATRÁS são definidos pelas Equações 15.5 e 15.9, respectivamente.\\nO leitor atento terá notado que a estrutura de rede bayesiana da \\nFigura 15.3\\n é uma \\npoliárvore\\n,\\ncomo definido anteriormente. Isso significa que uma aplicação para a frente do algoritmo de\\nformação de agrupamentos também resulta em um algoritmo de tempo linear que calcula estimativas\\nsuavizadas para a sequência inteira. Agora, demonstramos que o algoritmo para a frente-para trás é\\nna realidade um caso especial do algoritmo de propagação de poliárvore utilizado com métodos de\\nformação de agrupamentos (embora os dois tenham sido desenvolvidos de modo independente).\\nO algoritmo para a frente-para trás forma a espinha dorsal computacional que lida com sequências\\nde observações com ruído, variando desde o reconhecimento da fala até o acompanhamento de\\naeronaves por radar. Conforme descrevemos, ele apresenta duas desvantagens de ordem prática. A\\nprimeira é que sua complexidade de espaço pode ser muito alta para aplicações nas quais o espaço\\nde estados é grande e as sequências são longas. O algoritmo utiliza o espaço \\nO\\n(|\\nf\\n|\\nt\\n), onde |\\nf\\n| é o\\ntamanho da representação da mensagem para a frente. O requisito espacial pode ser reduzido para\\nO\\n(|\\nf\\n| log \\nt\\n), com aumento concomitante na complexidade de tempo por um fator igual a log \\nt\\n, como\\nmostra o Exercício 15.3. Em alguns casos (veja a \\nSeção 15.3\\n), um algoritmo de espaço constante\\npode ser usado sem qualquer penalidade de tempo.\\nA segunda desvantagem do algoritmo básico é que ele precisa ser modificado para funcionar em\\numa configuração \\non\\n-\\nline\\n na qual as estimativas suavizadas devem ser calculadas para fatias de\\ntempo anteriores, à medida que novas observações são continuamente adicionadas ao final da\\nsequência. O requisito mais comum é o de \\nsuavização de retardo fixo\\n, que exige o cálculo da\\nestimativa suavizada \\nP\\n(\\nX\\nt – d\\n | \\ne\\n1:\\nt\\n) para \\nd\\n fixo. Isto é, a suavização é feita para a fatia de tempo \\nd\\npassos atrasada em relação ao tempo atual \\nt\\n; conforme \\nt\\n aumenta, a suavização tem de continuar. É\\nóbvio que podemos executar o algoritmo para a frente-para trás sobre a “janela” de \\nd\\n passos à\\nmedida que cada nova observação é adicionada, mas isso parece ineficiente. Na \\nSeção 15.3\\n,\\nveremos que a suavização de retardo fixo pode, em alguns casos, ser feita em tempo constante por\\natualização, independentemente do retardo \\nd\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 671}),\n",
       " Document(page_content='15.2.3 Como descobrir a sequência mais provável\\nSuponha que [\\nverdadeiro\\n, \\nverdadeiro\\n, \\nfalso\\n, \\nverdadeiro\\n, \\nverdadeiro\\n] seja a sequência de guarda-\\nchuva para os cinco primeiros dias de serviço do guarda de segurança. Qual é a sequência de\\ncondições do clima com maior probabilidade de explicar isso? A ausência do guarda-chuva no dia 3\\nsignifica que não estava chovendo ou será que o diretor se esqueceu de trazer o guarda-chuva? Se\\nnão tivesse chovido no dia 3, talvez (porque as condições do clima tendem a persistir) também não\\ntivesse chovido no dia 4, mas o diretor pode ter trazido o guarda-chuva só por precaução. Ao todo,\\nexistem 2\\n5\\n possíveis sequências de condições do clima que poderíamos selecionar. Existe um meio\\nde encontrar a mais provável que não seja enumerando todas elas?\\nPoderíamos tentar o procedimento de tempo linear a seguir: usar o algoritmo de suavização para\\ndescobrir a distribuição posterior para as condições do clima em cada período; em seguida, construir\\na sequência, utilizando em cada passo as condições do clima mais provavelmente concordantes com\\na distribuição posterior. Tal abordagem deve fazer soar um alarme na cabeça do leitor porque as\\ndistribuições posteriores calculadas pela suavização são distribuições sobre períodos de tempo\\nisolados\\n; por outro lado, para encontrar a \\nsequência\\n mais provável temos de considerar\\nprobabilidades \\nconjuntas\\n sobre todos os períodos de tempo. Os resultados podem de fato ser\\nbastante diferentes (veja o Exercício 15.4).\\n \\nExiste\\n um algoritmo de tempo linear para encontrar a sequência mais provável, mas ele exige\\num pouco mais de reflexão. Esse algoritmo se baseia na mesma propriedade de Markov que gerou\\nalgoritmos eficientes para filtragem e suavização. O modo mais fácil de pensar no problema é\\nvisualizar cada sequência como um \\ncaminho\\n por um grafo cujos nós são os \\nestados\\n possíveis em\\ncada período de tempo. Mostramos esse grafo para o mundo do guarda-chuva na \\nFigura 15.5\\n(a).\\nAgora, considere a tarefa de descobrir o caminho mais provável por esse grafo, onde a\\nprobabilidade de qualquer caminho é o produto das probabilidades de transição ao longo do caminho\\npelas probabilidades das observações dadas em cada estado. Vamos nos concentrar em particular\\nnos caminhos que alcançam o estado \\nChuva\\n5\\n = \\nverdadeiro\\n. Devido à propriedade de Markov, segue-\\nse que o caminho mais provável para o estado \\nChuva\\n5\\n = \\nverdadeiro\\n consiste no caminho mais\\nprovável até \\nalgum\\n estado no tempo 4, seguido por uma transição para \\nChuva\\n5\\n = \\nverdadeiro\\n; e o\\nestado no tempo 4 que se tornará parte do caminho para \\nChuva\\n5\\n = \\nverdadeiro\\n será aquele que\\nmaximizar a probabilidade desse caminho. Em outras palavras, \\nexiste um relacionamento recursivo\\nentre caminhos mais prováveis até cada estado\\n \\nx\\nt\\n+1\\n \\ne caminhos mais prováveis até cada estado\\n \\nx\\nt\\n.\\nPodemos escrever esse relacionamento como uma equação que conecta as probabilidades dos\\ncaminhos:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 672}),\n",
       " Document(page_content='Figura 15.5\\n (a) Sequências de estados possíveis para \\nChuva\\nt\\n podem ser visualizadas como caminhos\\natravés de um grafo dos estados possíveis em cada período de tempo (os estados são mostrados\\ncomo nós quadrados para evitar confusão com os nós de uma rede bayesiana). (b) Operação do\\nalgoritmo de Viterbi para a sequência de observação de guarda-chuva [\\nverdadeiro\\n, \\nverdadeiro\\n,\\nfalso\\n, \\nverdadeiro\\n, \\nverdadeiro\\n]. Para cada período de tempo \\nt\\n, mostramos os valores da mensagem\\nm\\n1:t\\n, que fornece a probabilidade de a melhor sequência alcançar cada estado no tempo \\nt\\n. Além\\ndisso, para cada estado, a seta grossa que leva até ele indica seu melhor predecessor. Seguindo as\\nsetas grossas de volta a partir do estado mais provável em \\nm\\n1:5, temos a sequência mais provável.\\nA Equação 15.11 é \\nidêntica\\n à equação de filtragem 15.5, exceto pelo fato de que:\\n1. A mensagem para a frente \\nf\\n1:\\nt\\n = \\nP\\n(\\nX\\nt\\n | \\ne\\n1:\\nt\\n) é substituída pela mensagem:\\nisto é, as probabilidades do caminho mais provável até cada estado \\nx\\nt\\n; e\\n2. O somatório sobre \\nx\\nt\\n na Equação 15.5 é substituído pela maximização sobre \\nx\\nt\\n na Equação\\n15.11.\\nDesse modo, o algoritmo para calcular a sequência mais provável é semelhante à filtragem: ele\\npercorre a sequência no sentido para a frente calculando a mensagem \\nm\\n em cada período de tempo\\nutilizando a Equação 15.11. O progresso desse cálculo é mostrado na \\nFigura 15.5\\n(b). No final, ele\\nterá a probabilidade para a sequência mais provável que alcança \\ncada um\\n dos estados finais. Pode-\\nse, portanto, selecionar com facilidade a sequência mais provável de todas (o estado com contorno\\nem negrito). Com a finalidade de identificar a sequência real, em vez de simplesmente calcular sua\\nprobabilidade, o algoritmo também precisará registrar, para cada estado, o melhor estado que conduz\\na isso, o que está indicado pelas setas em negrito na \\nFigura 15.5\\n(b). A sequência ótima é identificada\\nseguindo-se os ponteiros de volta a partir do melhor estado final.\\nO algoritmo que acabamos de descrever denomina-se \\nalgoritmo de Viterbi\\n, em homenagem a seu\\ncriador. Como o algoritmo de filtragem, sua complexidade é linear em \\nt\\n, a duração da sequência.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 673}),\n",
       " Document(page_content='Porém, diferentemente da filtragem, que utiliza espaço constante, seu requisito de espaço também é\\nlinear em \\nt\\n. Isso ocorre porque o algoritmo de Viterbi precisa manter os ponteiros que identificam a\\nmelhor sequência que leva a cada estado.\\n15.3 MODELOS OCULTOS DE MARKOV\\nA seção precedente desenvolveu algoritmos para raciocínio probabilístico temporal usando uma\\nestrutura geral independente da forma específica dos modelos de transição e de sensores. Nesta e nas\\nduas seções seguintes, discutiremos modelos mais concretos e aplicações que ilustram a capacidade\\ndos algoritmos básicos e, em alguns casos, permitem aperfeiçoamentos adicionais.\\nComeçaremos com o \\nmodelo oculto de Markov\\n, ou \\nMOM\\n. Um MOM é um modelo probabilístico\\ntemporal no qual o estado do processo é descrito por uma \\núnica\\n variável aleatória \\ndiscreta\\n. Os\\nvalores possíveis da variável são os estados possíveis do mundo. O exemplo do guarda-chuva\\ndescrito na seção precedente é então um MOM, pois ele tem apenas uma variável de estado: \\nChuva\\nt\\n.\\nO que acontece se você tiver um modelo com duas ou mais variáveis de estado? Você pode ainda se\\nencaixar no quadro do MOM combinando todas as variáveis de estados em uma única\\n“megavariável”, cujos valores são todas as tuplas de valores possíveis das variáveis de estados\\nindividuais. Veremos que a estrutura restrita de MOMs permite a implementação de uma matriz muito\\nsimples e elegante de todos os algoritmos básicos.\\n4\\n15.3.1 Algoritmos matriciais simplificados\\nCom uma única variável de estado discreta X\\nt\\n, podemos dar forma concreta às representações do\\nmodelo de transição, do modelo de sensores e das mensagens para a frente e para trás. Seja a\\nvariável de estado \\nX\\nt\\n com valores denotados por inteiros 1, …, \\nS\\n, onde \\nS\\n é o número de estados\\npossíveis. O modelo de transição \\nP\\n(\\nX\\nt\\n | \\nX\\nt\\n– 1\\n) se torna uma matriz \\nT\\n \\nS\\n × \\nS\\n, onde:\\nT\\nij\\n = \\nP\\n(\\nX\\nt\\n = \\nj\\n | \\nX\\nt\\n – 1 = \\ni\\n).\\nOu seja. \\nT\\nij\\n é a probabilidade de uma transição do estado \\ni\\n para o estado \\nj\\n. Por exemplo, a matriz\\nde transição para o mundo de guarda-chuva é:\\nTambém colocamos o modelo de sensores em forma de matriz. Nesse caso, como o valor da\\nvariável de evidência \\nE\\nt\\n é conhecido no tempo \\nt\\n (chamemos \\ne\\nt\\n), precisamos apenas especificar, para\\ncada estado, com qual probabilidade o estado faz com que \\ne\\nt\\n apareça: precisamos de \\nP\\n(\\ne\\nt\\n | \\nX\\nt\\n = \\ni\\n)\\npara cada estado \\ni\\n. Para conveniência matemática colocamos esses valores em uma matriz diagonal \\nS\\n× \\nS\\n \\nO\\nt\\n cuja iésima entrada diagonal é \\nP\\n(\\ne\\nt\\n | \\nX\\nt\\n = \\ni\\n) e cujas outras entradas são 0. Por exemplo, no dia', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 674}),\n",
       " Document(page_content='1, no mundo do guarda-chuva da \\nFigura 15.5\\n, \\nU\\n1\\n = \\nverdadeiro\\n e, no dia 3, \\nU\\n3\\n = \\nfalso\\n; assim, da\\nFigura 15.2\\n, temos:\\nAgora, se utilizarmos vetores coluna para representar as mensagens para a frente e para trás, as\\ncomputações se tornarão simples operações de vetores de matrizes. A equação para a frente (15.5) se\\ntorna:\\ne a equação para trás (15.9) se torna:\\nA partir dessas equações, podemos ver que a complexidade de tempo do algoritmo para a frente-\\npara trás (\\nFigura 15.4\\n) aplicada a uma sequência cuja duração \\nt\\n é \\nO\\n(\\nS\\n2\\nt\\n) porque cada passo exige a\\nmultiplicação de um vetor de \\nS\\n elementos por uma matriz \\nS × S\\n. O requisito de espaço é \\nO\\n(\\nSt\\n)\\nporque a passagem para a frente armazena \\nt\\n vetores de tamanho \\nS\\n.\\nAlém de fornecer uma descrição elegante dos algoritmos de filtragem e suavização para MOMs, a\\nformulação de matriz revela oportunidades para algoritmos otimizados. O primeiro é uma simples\\nvariação sobre o algoritmo para a frente-para trás que permite que a suavização seja executada em\\nespaço \\nconstante\\n, independentemente da duração da sequência. A ideia é que a suavização para\\nqualquer fatia de tempo \\nk\\n específica exige a presença simultânea das mensagens para a frente e para\\ntrás, \\nf\\n1:\\nk\\n e \\nb\\nk\\n+1:\\nt\\n, de acordo com a Equação 15.8. O algoritmo para a frente-para trás consegue isso\\narmazenando os valores \\nf\\n calculados na passagem para a frente, de modo que eles fiquem\\ndisponíveis durante a passagem para trás. Outro modo de conseguir isso é usar uma única passagem\\nque efetue a propagação de \\nf\\n e de \\nb\\n, ambas no mesmo sentido. Por exemplo, a mensagem “para a\\nfrente” \\nf\\n pode ser propagada no sentido para trás se manipularmos a Equação 15.12 para atuar no\\noutro sentido:\\nO algoritmo de suavização modificado funciona executando primeiro a passagem para a frente\\npadrão para calcular \\nf\\nt:t\\n (ignorando-se todos os resultados intermediários) e depois executando a\\npassagem para trás para \\nb\\n e \\nf\\n juntas, utilizando-se essas mensagens para calcular a estimativa\\nsuavizada em cada passo. Tendo em vista que é necessária apenas uma cópia de cada mensagem, os\\nrequisitos de armazenamento são constantes (isto é, independentes de \\nt\\n, a duração da sequência).\\nExistem duas restrições significativas sobre esse algoritmo: ele exige que a matriz de transição tenha\\nmatriz inversa e que o modelo de sensores não tenha zeros, isto é, que toda observação seja possível\\nem todo estado.\\nUma segunda área em que a formulação de matriz revela um aperfeiçoamento é a suavização on-\\nline com retardo fixo. O fato de ser possível realizar a suavização em espaço constante sugere que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 675}),\n",
       " Document(page_content='deve existir um algoritmo recursivo eficiente para suavização on-line, isto é, um algoritmo cuja\\ncomplexidade de tempo seja independente da duração do retardo. Vamos supor que o retardo seja \\nd\\n;\\nisto é, estamos realizando a suavização na fatia de tempo \\nt\\n – \\nd\\n, onde o tempo atual é \\nt\\n. Pela Equação\\n15.8, precisamos calcular:\\npara a fatia \\nt\\n – \\nd\\n. Então, quando chegar uma nova observação, precisaremos calcular:\\npara a fatia \\nt\\n – \\nd\\n + 1. Como isso pode ser feito de modo incremental? Primeiro, podemos calcular\\nf\\n1:\\nt\\n–\\nd\\n+1\\n a partir de \\nf\\n1:\\nt\\n–\\nd\\n utilizando o processo de filtragem padrão, segundo a Equação 15.5.\\nCalcular a mensagem para trás de modo incremental é uma ação mais complicada porque não\\nexiste nenhum relacionamento simples entre a mensagem para trás antiga \\nb\\nt–d\\n+1:\\nt\\n e a nova mensagem\\npara trás \\nb\\nt–d\\n+2:\\nt\\n+1\\n. Em vez disso, examinaremos o relacionamento entre a mensagem para trás antiga\\nb\\nt–d\\n+1:\\nt\\n e a mensagem para trás no início da sequência, \\nb\\nt\\n+1:\\nt\\n. Para isso, aplicamos a Equação 15.13 \\nd\\nvezes para obter:\\nonde a matriz \\nB\\nt–d+\\n1\\n:t\\n é o produto da sequência de matrizes \\nT\\n e \\nO\\n. \\nB\\n pode ser considerado um\\n“operador de transformação”, que transforma uma mensagem para trás posterior em uma anterior.\\nUma equação semelhante é válida para as novas mensagens para trás \\ndepois\\n da chegada da\\nobservação seguinte:\\nExaminando as expressões de produtos nas Equações 15.14 e 15.15, vemos que elas têm um\\nrelacionamento simples: para obter o segundo produto, “divide-se” o primeiro produto pelo primeiro\\nelemento \\nTO\\nt–d\\n+1\\n e multiplica-se pelo último elemento novo \\nTO\\nt\\n+1\\n. Então, em linguagem de\\nmatrizes, existe um relacionamento simples entre as matrizes \\nB\\n antiga e nova:\\nEssa equação fornece uma atualização incremental para a matriz \\nB\\n que, por sua vez (pela Equação\\n15.15), nos oferece a possibilidade de calcular a nova mensagem para trás \\nb\\nt–d\\n+2:\\nt\\n+1\\n. O algoritmo\\ncompleto, que exige armazenamento e atualização de \\nf\\n e \\nB\\n, é mostrado na \\nFigura 15.6\\n.\\nfunção\\n SUAVIZAÇÃO-DE-RETARDO-FIXO(\\net\\n, \\nmom\\n, \\nd\\n) \\nretorna\\n uma distribuição sobre \\nX\\nt – d\\n    \\nentradas:\\n \\net\\n, a evidência atual por período de tempo \\nt', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 676}),\n",
       " Document(page_content='mom\\n, um modelo oculto de Markov com matriz de transição \\nT\\n \\nS × S\\nd\\n, a duração do retardo para suavização\\n    \\npersistente:\\n \\nt\\n, o tempo atual, inicialmente 1\\nf\\n, a mensagem para a frente \\nP\\n(\\nX\\nt\\n | \\ne\\n1:\\nt\\n), inicialmente ANTERIOR[\\nmom\\n]\\nB\\n, a matriz de transformação de \\nd\\n passos para trás, inicialmente a matriz\\nidentidade\\ne\\nt–d:t\\n, lista dupla de evidências a partir de \\nt\\n – \\nd\\n para \\nt\\n, inicialmente vazia\\n    \\nvariáveis locais\\n: \\nO\\nt – d\\n, \\nO\\nt\\n, matrizes diagonais contendo as informações do modelo de sensores\\n    \\n    somar \\net\\n ao final de \\ne\\nt–d:t\\n    \\nO\\nt\\n ← matriz diagonal contendo \\nP\\n(\\ne\\nt\\n |\\nX\\nt\\n)\\n    \\nse\\n \\nt\\n > \\nd\\n \\nentão\\n        \\nf\\n ← PARAFRENTE(\\nf\\n, \\ne\\nt\\n)\\n        remover \\ne\\nt–d\\n do início de \\ne\\nt–d:t\\n        \\nO\\nt–d\\n ← matriz diagonal contendo \\nP\\n(\\ne\\nt–d\\n | \\nX\\nt–d\\n)\\n        \\nB\\n ← \\nO\\n–1\\nt–d\\n \\nT\\n–1\\n \\nBTO\\nt\\n    \\nsenão B\\n ← \\nBTO\\nt\\n    \\nt\\n ← \\nt\\n + 1\\n    \\nse\\n \\nt\\n \\n>\\n \\nd\\n \\nentão retornar\\n NORMALIZAR(\\nf\\n × \\nB1\\n) \\nsenão retornar\\n nulo\\nFigura 15.6\\n Um algoritmo para suavização com retardo de tempo fixo de \\nd\\n passos, implementado\\ncomo um algoritmo on-line que mostra como saída a nova estimativa suavizada, dada a observação\\ncorrespondente a um novo período de tempo. Observe que o produto final NORMALIZAR(\\nf\\n × \\nB1\\n) é\\napenas \\na\\n \\nf\\n × \\nb\\n, pela Equação 15.14.\\n15.3.2 Exemplo do modelo oculto de Markov: localização\\nFoi introduzida uma forma simples de problema de \\nlocalização\\n para o mundo do aspirador de pó.\\nNessa versão, o robô teve uma única ação de \\nMovimento\\n não determinístico e seus sensores\\nrelataram perfeitamente se havia ou não obstáculos localizados ao norte, sul, leste e oeste; o estado\\nde crença do robô era o conjunto de locais possíveis onde ele poderia estar.\\nAqui nós tornamos o problema um pouco mais realista incluindo um modelo de probabilidade\\nsimples para o movimento do robô e permitindo o ruído nos sensores. O estado variável \\nX\\nt\\nrepresenta a localização do robô na grade discreta; o domínio dessa variável é o conjunto de\\nquadrados vazios {s\\n1\\n,…, s\\nn\\n}. Seja VIZINHOS(\\ns\\n) o conjunto de quadrados vazios que são adjacentes\\na \\ns\\n e seja \\nN\\n(\\ns\\n) o tamanho desse conjunto. Então, o modelo de transição para a ação \\nMover\\n diz que o\\nrobô tem a mesma probabilidade de acabar em qualquer quadrado vizinho:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 677}),\n",
       " Document(page_content='Não sabemos onde o robô começa, então vamos supor uma distribuição uniforme sobre todos os\\nquadrados, isto é, \\nP\\n(\\nX\\n0\\n = \\ni\\n) = 1/\\nn\\n. Para o ambiente especial que consideramos (\\nFigura 15.7\\n), \\nn\\n = 42\\ne a matriz de transição \\nT\\n tem 42 × 42 = 1.764 entradas.\\nFigura 15.7\\n Distribuição posterior sobre a localização do robô: (a) uma observação \\nE\\n1\\n = \\nNSO\\n; (b)\\ndepois de uma segunda observação \\nE\\n2\\n = \\nNS\\n. O tamanho de cada disco corresponde à probabilidade\\nde que o robô esteja naquela localização. A taxa de erro do sensor é \\n∊\\n = 0,2.\\nO sensor variável E\\nt\\n tem 16 valores possíveis, cada sequência de quatro bits informando a\\npresença ou ausência de um obstáculo em uma direção particular. Utilizaremos a notação \\nNS\\n, por\\nexemplo, para significar que os sensores do norte e do sul relatam um obstáculo enquanto os do leste\\ne oeste não relatam. Suponha que cada taxa de erro do sensor seja \\n∊\\n e os erros ocorrem\\nindependentemente das quatro direções do sensor. Nesse caso, a probabilidade de obter todos os\\nquatro bits da direita é (1 − \\n∊\\n)\\n4\\n e a probabilidade de obter todos errados é \\n∊\\n4\\n. Além disso, se \\nd\\nit\\n é a\\ndiscrepância — o número de bits que são diferentes — entre os valores verdadeiros do quadrado \\ni\\n e\\na leitura real de \\ne\\nt\\n, então a probabilidade de que um robô no quadrado \\ni\\n vá receber uma leitura do\\nsensor \\ne\\nt\\n é\\nPor exemplo, a probabilidade de que um quadrado com obstáculos para o norte e para o sul\\nproduza um sensor de leitura \\nNSL\\n é (1 − \\n∊\\n)\\n3\\n∊\\n1\\n.\\nDadas as matrizes \\nT\\n e \\nO\\nt\\n, o robô pode usar a Equação 15.12 para calcular a distribuição posterior\\nsobre as localizações, isto é, resolver onde ele está. A \\nFigura 15.7\\n mostra as distribuições \\nP\\n(\\nX\\n1\\n | \\nE\\n1\\n= \\nNSO\\n) e \\nP\\n(\\nX\\n2\\n | \\nE\\n1\\n = \\nNSO\\n, \\nE\\n2\\n = \\nNS\\n). Esse é o mesmo labirinto que vimos antes na \\nFigura 4.18\\n, mas\\nlá usamos filtragem lógica para encontrar as localizações \\npossíveis\\n, assumindo sensoriamento', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 678}),\n",
       " Document(page_content='perfeito. Essas mesmas localizações ainda são as mais prováveis com sensoriamento ruidoso, mas\\nagora \\ncada\\n localização tem uma probabilidade diferente de zero.\\nAlém da filtragem para estimar sua localização atual, o robô pode usar suavização (Equação\\n15.13) para perceber onde estava em qualquer tempo passado — por exemplo, onde começou no\\ntempo 0 — e pode usar o algoritmo de Viterbi para calcular o caminho mais provável que tenha\\ntomado para chegar onde está agora. A \\nFigura 15.8\\n mostra o erro de localização e a precisão do\\ncaminho de Viterbi para vários valores da taxa de erro do sensor per-bit. Mesmo quando \\n∊\\n for 20%\\n— o que significa que a leitura do sensor está errada 59% do tempo total — geralmente o robô é\\ncapaz de calcular sua localização dentro de dois quadrados depois de 25 observações. Isso por\\ncausa da habilidade do algoritmo de integrar a evidência ao longo do tempo e levar em conta as\\nrestrições probabilísticas impostas na sequência de localização pelo modelo de transição. Quando \\n∊\\nfor 10%, será difícil distinguir o desempenho após meia dúzia de observações do desempenho com\\nsensoriamento perfeito. O Exercício 15.7 pede que você explore a robustez do algoritmo de\\nlocalização de MOM em relação a erros na distribuição anterior \\nP\\n(X\\n0\\n) e no modelo de transição em\\nsi. De modo geral, os níveis elevados de localização e de precisão de caminho são mantidos mesmo\\nem face de erros substanciais nos modelos utilizados.\\nFigura 15.8\\n Desempenho da localização do MOM como função do comprimento da sequência de\\nobservação de vários valores diferentes de probabilidade de erro do sensor; dados calculados sobre\\n400 execuções. (a) Erro de localização, definido como a distância de Manhattan da localização\\nverdadeira. (b) Precisão do caminho de Viterbi, definida como fração de estados corretos sobre o\\ncaminho de Viterbi.\\nA variável de estado para o exemplo que consideramos nesta seção é a localização física no\\nmundo. Outros problemas podem, é claro, incluir outros aspectos do mundo. O Exercício 15.8 pede\\nque você considere uma versão do robô do aspirador de pó cujo programa de ação seja ir em linha\\nreta enquanto pode; só quando encontra um obstáculo, ele muda para uma nova direção (selecionada\\naleatoriamente). Para modelar esse robô, cada estado no modelo consiste em um par (\\nlocalização,\\ndireção\\n). Para o ambiente na \\nFigura 15.7\\n, que tem 42 quadrados vazios, isso leva a 168 estados e\\numa matriz de transição com 168\\n2\\n = 28. 224 entradas — um número ainda administrável. Se\\nadicionarmos a possibilidade de sujeira nos quadrados, o número de estados será multiplicado por\\n2\\n42\\n e a matriz de transição terminará com mais de 10\\n29\\n entradas — não mais um número gerenciável;\\na \\nSeção 15.5\\n mostra como usar redes bayesianas dinâmicas para modelar domínios com muitas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 679}),\n",
       " Document(page_content='variáveis de estado. Se permitirmos que o robô se mova continuamente em vez de uma grade\\ndiscreta, o número de estados torna-se infinito; a próxima seção mostra como lidar com esse caso.\\n15.4 FILTROS DE KALMAN\\nImagine assistir a um pequeno pássaro voando entre a folhagem da selva densa ao entardecer: você\\nvislumbra \\nflashes\\n breves e intermitentes de movimento, faz todo o possível para adivinhar onde o\\npássaro está e onde ele aparecerá em seguida, para não perdê-lo de vista. Ou, ainda, imagine que\\nvocê seja um operador de radar da Segunda Guerra Mundial que perscruta um blipe débil e errante\\nque surge uma vez a cada 10 segundos na tela. Ou, então, indo um pouco mais longe, imagine que\\nvocê seja Kepler tentando reconstruir os movimentos dos planetas a partir de uma coleção de\\nobservações angulares altamente inexatas, tomadas a intervalos irregulares e medidos de forma\\nimprecisa. Em todos esses casos, você está fazendo a filtragem: estimando variáveis de estado (aqui,\\nposição e velocidade) a partir de observações com ruído. Se as variáveis fossem discretas,\\npoderíamos modelar o sistema com o modelo oculto de Markov. Esta seção examina métodos de\\nlidar com variáveis contínuas usando um algoritmo chamado \\nfiltragem de Kalman\\n, em homenagem\\nao seu criador, Rudolf E. Kalman.\\nO voo do pássaro poderia ser especificado pela posição (\\nX\\nt\\n, \\nY\\nt\\n, \\nZ\\nt\\n) e pela velocidade (\\n) em\\ncada instante no tempo. Também precisaremos de densidades condicionais adequadas para\\nrepresentar os modelos de transição e de sensores; como no Capítulo 14, utilizaremos distribuições\\ngaussianas lineares\\n. Isso significa que o próximo estado \\nX\\nt\\n+1\\n deve ser uma função linear do estado\\natual \\nX\\nt\\n somada a algum ruído gaussiano, uma condição que acaba por ser bastante razoável na\\nprática. Por exemplo, considere a coordenada \\nX\\n do pássaro, ignorando por enquanto as outras\\ncoordenadas. Seja ∆ o intervalo de tempo entre observações e suponha velocidade constante; então,\\na atualização de posição é dada por \\n. Se adicionarmos ruído gaussiano (levando em\\nconta a variação do vento etc.), teremos um modelo de transição gaussiano linear:\\nA estrutura de rede bayesiana para um sistema com posição vetor \\nX\\nt\\n e velocidade \\n é mostrada na\\nFigura 15.9\\n. Observe que essa é uma forma muito específica do modelo gaussiano linear; a forma\\ngeral será descrita mais adiante nesta seção e cobrirá uma vasta série de aplicações, além dos\\nexemplos de movimento simples do primeiro parágrafo. O leitor talvez deseje consultar no Apêndice\\nA algumas propriedades matemáticas de distribuições gaussianas; para nossos propósitos imediatos,\\na mais importante é que uma distribuição \\ngaussiana multivariada\\n para \\nd\\n variáveis é especificada\\npor uma média μ de \\nd\\n elementos e uma matriz de covariância Σ \\nd\\n × \\nd\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 680}),\n",
       " Document(page_content='Figura 15.9\\n Estrutura de rede bayesiana para um sistema linear dinâmico com posição \\nX\\nt\\n, velocidade\\n e medida de posição \\nZ\\nt\\n.\\n15.4.1 Atualização de distribuições gaussianas\\nNo Capítulo 14 aludimos a uma propriedade-chave da família de distribuições gaussianas\\nlineares: ela permanece fechada sob as operações-padrão de redes bayesianas. Aqui, tornamos essa\\nasserção precisa no contexto de filtragem em um modelo de probabilidade temporal. As\\npropriedades exigidas correspondem ao cálculo de filtragem de dois passos na Equação 15.5:\\n1. Se a distribuição atual \\nP\\n(\\nX\\nt\\n | \\ne\\n1:\\nt\\n) é gaussiana e o modelo de transição \\nP\\n(\\nX\\nt\\n+1\\n | \\nx\\nt\\n) é gaussiana\\nlinear, então a distribuição prevista de um passo definido por\\ntambém é uma distribuição gaussiana.\\n2. Se a previsão \\nP\\n(\\nX\\nt\\n+1\\n|\\ne\\n1:\\nt\\n) é gaussiana e o modelo de sensores \\nP\\n(\\ne\\nt\\n+1\\n | \\nX\\nt\\n+1\\n) é gaussiano linear,\\ndepois do condicionamento sobre a nova evidência, a distribuição atualizada:\\ntambém é uma distribuição gaussiana.\\nDesse modo, o operador PARAFRENTE para filtragem de Kalman recebe uma mensagem\\ngaussiana para a frente \\nf\\n1:\\nt\\n, especificada por uma média \\nμ\\nt\\n e uma matriz de covariância \\nΣ\\nt\\n, e produz\\numa nova mensagem gaussiana para a frente multivariada \\nf\\n1:\\nt\\n+1\\n, especificada por uma média \\nµ\\nt\\n+1\\n e\\numa matriz de covariância \\nΣ\\nt\\n+1\\n. Assim, se começarmos com um valor \\na priori\\n gaussiano \\nf\\n1:0\\n = \\nP\\n(\\nX\\n0\\n)\\n=\\nN\\n(\\nµ\\n0\\n, \\nΣ\\n0\\n), a filtragem com um modelo gaussiano linear produzirá uma distribuição de estados\\ngaussiana para todo o tempo.\\n Esse parece ser um resultado ótimo e elegante; porém, por que é tão importante? A razão é que,\\nexceto para alguns casos especiais como esse, \\na filtragem com redes contínuas ou híbridas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 681}),\n",
       " Document(page_content='(\\ndiscretas e contínuas\\n) \\ngera distribuições de estados cuja representação cresce sem limite ao\\nlongo do tempo\\n. Não é fácil provar essa declaração no caso geral, mas o Exercício 15.10 mostra o\\nque acontece em um exemplo simples.\\n15.4.2 Um exemplo unidimensional simples\\nDissemos que o operador PARAFRENTE para o filtro de Kalman mapeia um gaussiano em um\\nnovo gaussiano. Isso se traduz no cálculo de uma nova média e uma matriz de covariância a partir da\\nmédia e da matriz de covariância anterior. A derivação da regra de atualização no caso geral\\n(multivariado) exige bastante álgebra linear e, assim, vamos nos limitar por enquanto a um caso\\nunivariado muito simples; mais tarde daremos os resultados para o caso geral. Mesmo para o caso\\nunivariado, os cálculos são um tanto tediosos, mas achamos que vale a pena observá-los porque a\\nutilidade do filtro de Kalman está amarrada de forma muito íntima às propriedades matemáticas de\\ndistribuições gaussianas.\\nO modelo temporal que consideraremos descreve um \\npercurso aleatório\\n de uma única variável de\\nestado contínua \\nX\\nt\\n com uma observação com ruído \\nZ\\nt\\n. Um exemplo poderia ser o índice de\\n“confiança do consumidor”, que podemos modelar como um valor que sofre mudança aleatória com\\ndistribuição gaussiana a cada mês e que é medido por uma pesquisa aleatória entre os consumidores\\nque também introduz ruído de amostragem gaussiano.\\nA distribuição anterior é considerada gaussiana com variância \\n:\\n(Por simplicidade, usaremos o mesmo símbolo \\nα\\n para todas as constantes de normalização nesta\\nseção.) O modelo de transição simplesmente adiciona uma perturbação gaussiana de variância\\nconstante \\n ao estado atual:\\nO modelo de sensores então supõe um ruído gaussiano com a variância \\n:\\nAgora, dada a distribuição anterior \\nP\\n(\\nX\\n0\\n), podemos calcular a distribuição prevista de um passo\\nusando a Equação 15.17:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 682}),\n",
       " Document(page_content='Essa integral parece bastante complicada. A chave para progredir é notar que o expoente é a soma\\nde duas expressões que são \\nquadráticas\\n em \\nx\\n0\\n e, consequentemente, ele próprio é quadrático em \\nx\\n0\\n.\\nUm artifício simples conhecido como \\ncompletar o quadrado\\n permite a reescrita de qualquer\\nexpressão quadrática \\n e \\n um termo residual \\n que é independente de \\nx\\n0\\n. O\\ntermo residual pode ser colocado fora da integral, o que nos dá:\\nAgora, a integral é apenas a integral de um gaussiano sobre seu intervalo completo, que vale\\nsimplesmente 1. Desse modo, ficamos somente com o termo residual da expressão quadrática. Então,\\nobservamos que o termo residual é um quadrático em \\nx\\n1\\n; de fato, após a simplificação obtemos\\nOu seja, a distribuição prevista de um passo é um gaussiano com a mesma média \\nμ\\n0\\n e uma\\nvariância igual à soma da variância original \\n e da variância de transição \\n.\\nPara completar a etapa de atualização, precisamos fazer o condicionamento sobre a observação no\\nprimeiro período de tempo, ou seja, \\nz\\n1\\n. A partir da Equação 15.18, isso é dado por:\\nMais uma vez, combinamos os expoentes e completamos o quadrado (Exercício 15.11), obtendo:\\nDesse modo, depois de um ciclo de atualização, temos uma nova distribuição gaussiana para a\\nvariável de estado.\\nA partir da fórmula gaussiana na Equação 15.19, vemos que a nova média e o novo desvio-padrão\\npodem ser calculados a partir da média e do desvio-padrão antigos, assim:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 683}),\n",
       " Document(page_content='A \\nFigura 15.10\\n mostra um ciclo de atualização para valores específicos dos modelos de transição\\ne de sensores.\\nFigura 15.10\\n Fases no ciclo de atualização do filtro de Kalman para um percurso aleatório com\\ndistribuição anterior dada por \\nm\\n0\\n = 0,0 e \\nσ\\n0\\n = 1,0, ruído de transição dado por \\nσ\\nx\\n = 2,0, ruído de\\nsensores dado por \\nσ\\nz\\n = 1,0 e uma primeira observação \\nz\\n1\\n = 2,5 (marcada no eixo \\nx\\n). Note que a\\nprevisão \\nP\\n(\\nx\\n1\\n) foi achatada, em relação a \\nP\\n(\\nx\\n0\\n), pelo ruído de transição. Note também que a média\\nda distribuição posterior \\nP\\n(\\nx\\n1\\n|\\nz\\n1\\n) está ligeiramente à esquerda da observação z\\n1\\n porque a média é\\numa média ponderada entre a previsão e a observação.\\nA Equação 15.20 desempenha exatamente o mesmo papel da equação de filtragem geral (15.5) ou\\nda equação de filtragem de MOM (15.12). Porém, devido à natureza especial das distribuições\\ngaussianas, as equações têm algumas propriedades adicionais interessantes. Primeiro, podemos\\ninterpretar o cálculo para a nova média \\nm\\nt\\n+1\\n simplesmente como uma \\nmédia ponderada\\n entre a nova\\nobservação \\nz\\nt\\n+1\\n e a média antiga \\nm\\nt\\n. Se a observação é pouco confiável, \\n é grande e dedicamos\\nmaior atenção à média antiga; se a média antiga é pouco confiável (\\n é grande) ou se o processo é\\naltamente imprevisível (\\n é grande), então dedicamos maior atenção à observação. Em segundo\\nlugar, note que a atualização para a variância \\n é \\nindependente da observação\\n. Podemos então\\ncalcular com antecedência qual será a sequência de valores de variância. Em terceiro lugar, a\\nsequência de valores de variância converge rapidamente para um valor fixo que só depende de \\n e \\n, simplificando assim de forma significativa os cálculos subsequentes (veja o o Exercício 15.12).\\n15.4.3 O caso geral\\nA derivação precedente ilustra a propriedade fundamental de distribuições gaussianas que permite\\no funcionamento da filtragem de Kalman: o fato de o expoente ser uma forma quadrática. Isso é\\nverdadeiro não apenas para o caso univariado; a distribuição gaussiana multivariada completa tem a\\nforma:\\nA multiplicação dos termos no expoente torna claro que o expoente também é uma função', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 684}),\n",
       " Document(page_content='quadrática dos valores de \\nx\\ni\\n em \\nx\\n. Como no caso univariado, a atualização de filtragem preserva a\\nnatureza gaussiana da distribuição de estados.\\nPrimeiro, vamos definir o modelo temporal geral usado com a filtragem de Kalman. Tanto o\\nmodelo de transição quanto o modelo de sensores permitem uma transformação \\nlinear\\n com ruído\\ngaussiano aditivo. Desse modo, temos:\\nonde \\nF\\n e \\nΣ\\nx\\n são matrizes que descrevem o modelo de transição linear e a covariância de ruído de\\ntransição, e onde \\nH\\n e \\nΣ\\nz\\n são as matrizes correspondentes para o modelo de sensores. Agora, as\\nequações de atualização para a média e a covariância, em sua forma total e extremamente\\ncomplicada, são:\\nonde \\n é chamada \\nmatriz de ganho de Kalman\\n.\\nAcredite ou não, essas equações fazem algum sentido intuitivo. Por exemplo, considere a atualização\\npara a estimativa de estado médio \\nµ\\n. O termo \\nFµ\\nt\\n é o estado \\nprevisto\\n em \\nt\\n + 1 e, assim, \\nHFµ\\nt\\n é a\\nobservação \\nprevista\\n. Portanto, o termo \\nz\\nt\\n+1\\n – \\nHF\\nµ\\nt\\n representa o erro na observação prevista. Esse\\ntermo é multiplicado por \\nK\\nt\\n+1\\n para corrigir o estado previsto; consequentemente, \\nK\\nt\\n+1\\n é uma medida\\ndo \\nquanto devemos levar a sério a nova observação\\n em relação à previsão. Como na Equação\\n15.18, também temos a propriedade de que a atualização da variância é independente das\\nobservações. A sequência de valores para \\nΣ\\nt\\n e \\nK\\nt\\n pode então ser calculada off-line, e os cálculos\\nreais exigidos durante o acompanhamento on-line serão bastante modestos.\\nPara ilustrar essas equações em funcionamento, elas foram aplicadas ao problema de acompanhar\\num objeto em movimento no plano \\nX\\n−\\nY\\n. As variáveis de estados são \\n e, assim, \\nF\\n, \\nΣ\\nx\\n, \\nH\\ne Σ\\nz\\n são matrizes 4 × 4. A \\nFigura 15.11\\n(a) mostra a trajetória verdadeira, uma série de observações\\ncom ruído e a trajetória estimada pela filtragem de Kalman, juntamente com as covariâncias\\nindicadas pelos contornos do único desvio-padrão. O processo de filtragem faz um bom trabalho de\\nacompanhamento do movimento real e, como esperado, a variância alcança rapidamente um ponto\\nfixo.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 685}),\n",
       " Document(page_content='Figura 15.11\\n (a) Resultados de filtragem de Kalman para um objeto em movimento no plano \\nX\\n−\\nY\\n,\\nmostrando a trajetória verdadeira (da esquerda para a direita), uma série de observações com ruído e\\na trajetória estimada por filtragem de Kalman. A variância na estimativa de posição é indicada pelas\\nelipses. (b) Resultados de suavização de Kalman para a mesma sequência de observação.\\nTambém podemos derivar equações para \\nsuavização\\n, bem como para filtragem com modelos\\ngaussianos lineares. Os resultados de suavização são mostrados na \\nFigura 15.11\\n(b). Note que a\\nvariância na estimativa de posição é nitidamente reduzida, exceto nas extremidades da trajetória (por\\nquê?) e que a trajetória estimada é muito mais suave.\\n15.4.4 A aplicabilidade da filtragem de Kalman\\nA filtragem de Kalman e suas elaborações são usadas em uma vasta série de aplicações. A\\naplicação “clássica” de filtros de Kalman ocorre em acompanhamento por radar de aeronaves e\\nmísseis. Aplicações inter-relacionadas incluem acompanhamento acústico de submarinos e veículos\\nterrestres e, ainda, acompanhamento visual de veículos e pessoas. Em um sentido ligeiramente mais\\nesotérico, os filtros de Kalman são utilizados para reconstruir trajetórias de partículas a partir de\\nfotografias de câmaras de bolha e correntes oceânicas a partir de medições de superfícies feitas por\\nsatélites. A variedade de aplicações é muito maior que o simples acompanhamento de movimentos:\\nqualquer sistema caracterizado por variáveis de estados contínuos e medições com ruído fará uso\\ndesse recurso. Tais sistemas incluem fábricas de polpa, indústrias químicas, reatores nucleares,\\necossistemas vegetais e economias nacionais.\\nO fato de ser possível aplicar a filtragem de Kalman a um sistema não significa que os resultados\\nserão válidos ou úteis. As hipóteses assumidas — uma transição gaussiana linear e modelos de\\nsensores — são muito fortes. O \\nfiltro de Kalman estendido\\n (\\nFKE\\n) tenta superar não linearidades no\\nsistema que está sendo modelado. Um sistema é não linear se o modelo de transição não pode ser\\ndescrito como uma multiplicação de matrizes do vetor de estados, como na Equação 15.21. O FKE\\nfunciona modelando o sistema como \\nlocalmente\\n linear em \\nx\\nt\\n na região de \\nx\\nt\\n = \\nµ\\nt\\n, a média da\\ndistribuição de estados atual. Isso funciona bem para sistemas suaves e bem comportados, e permite\\nao controlador manter e atualizar uma distribuição de estados gaussiana que representa uma\\naproximação razoável para a distribuição posterior verdadeira. Há um exemplo detalhado no', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 686}),\n",
       " Document(page_content='Capítulo 25.\\nO que significa um sistema ser “não suave” ou “mal comportado”? Tecnicamente, isso quer dizer\\nque existe uma não linearidade significativa na resposta do sistema dentro da região que está\\n“próxima” (de acordo com a covariância \\nΣ\\nt\\n) à média corrente \\nµ\\nt\\n. Para compreender essa ideia em\\ntermos não técnicos, considere o exemplo de tentar localizar um pássaro à medida que ele voa pela\\nfloresta. O pássaro parece estar se dirigindo em alta velocidade para um tronco de árvore. O filtro de\\nKalman, seja ele regular ou estendido, só pode fazer uma previsão gaussiana da posição do pássaro,\\ne a média dessa previsão gaussiana estará centrada no tronco, como mostra a \\nFigura 15.12\\n(a). Por\\noutro lado, um modelo razoável do pássaro iria prever uma ação evasiva para um lado ou outro,\\ncomo mostra a \\nFigura 15.12\\n(b). Tal modelo é altamente não linear porque a decisão do pássaro varia\\nnitidamente, dependendo de sua posição exata em relação ao tronco.\\nFigura 15.12\\n Um pássaro que voa em direção a uma árvore (vistas superiores). (a) Um filtro de\\nKalman vai prever a posição do pássaro usando um único gaussiano centrado no obstáculo. (b) Um\\nmodelo mais realista permite uma ação evasiva do pássaro, prevendo que ele voará para um lado ou\\npara o outro.\\nPara tratar exemplos como esses, é claro que precisamos de uma linguagem mais expressiva para\\nrepresentar o comportamento do sistema que está sendo modelado. Dentro da comunidade de teoria\\nde controle, para a qual problemas como manobras evasivas de aeronaves encontram os mesmos\\ntipos de dificuldades, a solução-padrão é o \\nfiltro de Kalman de comutação\\n. Nessa abordagem,\\nvários filtros de Kalman funcionam em paralelo, cada um usando um modelo diferente do sistema —\\npor exemplo, um para voo em linha reta, um para curvas bruscas à esquerda e um para curvas bruscas\\nà direita. É usada uma soma ponderada de previsões em que o peso depende do quanto cada filtro se\\nadapta bem aos dados atuais. Veremos na próxima seção que esse é simplesmente um caso especial\\ndo modelo geral de rede bayesiana dinâmica, obtido pela adição de uma variável de estado discreta\\nde “manobra” à rede mostrada na \\nFigura 15.9\\n. Os filtros de Kalman de comutação serão descritos\\ncom mais detalhes no Exercício 15.10.\\n15.5 REDES BAYESIANAS DINÂMICAS', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 687}),\n",
       " Document(page_content='Uma \\nrede bayesiana dinâmica\\n, ou \\nDBN\\n, é uma rede bayesiana que representa um modelo de\\nprobabilidade temporal do tipo descrito na \\nSeção 15.1\\n. Já vimos exemplos de DBNs: a rede de\\nguarda-chuva da \\nFigura 15.2\\n e a rede de filtro de Kalman da \\nFigura 15.9\\n. Em geral, cada fatia de uma\\nDBN pode ter qualquer número de variáveis de estados \\nX\\nt\\n e variáveis de evidência \\nE\\nt\\n. Por\\nsimplicidade, vamos supor que as variáveis e seus vínculos são reproduzidos exatamente de uma\\nfatia para outra e que a DBN representa um processo de Markov de primeira ordem, de forma que\\ncada variável possa ter pais somente em sua própria fatia ou na fatia imediatamente precedente.\\nDeve ficar claro que todo modelo oculto de Markov pode ser representado como uma DBN com\\numa única variável de estado e uma única variável de evidência. Também ocorre que toda DBN de\\nvariáveis discretas pode ser representada como um MOM; conforme explicamos na \\nSeção 15.3\\n,\\npodemos combinar todas as variáveis de estados na DBN em uma única variável de estado cujos\\nvalores são todas as tuplas de valores possíveis das variáveis de estados individuais. Agora, se todo\\nMOM for uma DBN e toda DBN puder ser convertida em um MOM, qual será a diferença? A\\ndiferença é que, \\ndecompondo-se o estado de um sistema complexo em suas variáveis constituintes\\n,\\na DBN será capaz de tirar proveito da\\n escassez \\nno modelo de probabilidade temporal\\n. Por\\nexemplo, suponha que uma DBN tenha 20 variáveis de estados booleanas, cada uma das quais tem\\ntrês pais na fatia precedente. Então, o modelo de transição de DBN tem 20 × 2\\n3\\n = 160\\nprobabilidades, enquanto o MOM correspondente tem 2\\n20\\n estados e, portanto, 2\\n40\\n, ou,\\naproximadamente, um trilhão de probabilidades na matriz de transição. Isso é ruim por pelo menos\\ntrês razões: primeiro, o próprio MOM exige muito mais espaço; em segundo lugar, a enorme matriz\\nde transição torna a inferência de MOM muito mais dispendiosa; em terceiro lugar, o problema de\\naprender um número tão enorme de parâmetros torna o modelo MOM puro inadequado para\\nproblemas grandes. O relacionamento entre DBNs e MOMs é aproximadamente análogo ao\\nrelacionamento entre redes bayesianas comuns e distribuições conjuntas totalmente tabuladas.\\nJá explicamos que todo modelo de filtro de Kalman pode ser representado em uma DBN com\\nvariáveis contínuas e distribuições condicionais gaussianas lineares (\\nFigura 15.9\\n). A partir da\\ndiscussão do final da seção precedente, deve ficar claro que \\nnem toda\\n DBN pode ser representada\\npor um modelo de filtro de Kalman. Em um filtro de Kalman, a distribuição de estados atual é sempre\\numa única distribuição gaussiana multivariada, isto é, um único “impacto” em uma posição\\nespecífica. Por outro lado, as DBNs podem modelar distribuições arbitrárias. Em muitas aplicações\\nreais, essa flexibilidade é essencial. Por exemplo, considere a posição atual de minhas chaves. Elas\\npoderiam estar em meu bolso, na mesa de cabeceira, sobre a mesa da cozinha, penduradas na\\nfechadura da porta da frente ou trancadas no carro. Uma colina gaussiana única que incluísse todos\\nesses lugares teria de alocar uma probabilidade significativa de que as chaves estivessem suspensas\\nno ar no corredor da frente. Aspectos do mundo real, como agentes intencionais, obstáculos e bolsos,\\nintroduzem “não linearidades” que exigem combinações de variáveis discretas e contínuas, a fim de\\nobter modelos razoáveis.\\n15.5.1 Construção de DBNs\\nPara construir uma DBN, devemos especificar três tipos de informações: a distribuição anterior', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 688}),\n",
       " Document(page_content='sobre as variáveis de estados, \\nP\\n(\\nX\\n0\\n); o modelo de transição \\nP\\n(\\nX\\nt\\n+1\\n|\\nX\\nt\\n); e o modelo de sensores\\nP\\n(\\nE\\nt\\n|\\nX\\nt\\n). Para especificar os modelos de transição e de sensores, também devemos especificar a\\ntopologia das conexões entre fatias sucessivas e entre as variáveis de estados e de evidência. Como\\nos modelos de transição e de sensores são supostamente estacionários — os mesmos para todo \\nt\\n —,\\né mais conveniente simplesmente especificá-los para a primeira fatia. Por exemplo, a especificação\\nde DBN completa para o mundo do guarda-chuva é dada pela rede de três nós da \\nFigura 15.13\\n(a). A\\npartir dessa especificação, é possível construir a DBN completa com um número infinito de fatias de\\ntempo, conforme seja necessário, copiando a primeira fatia.\\nFigura 15.13\\n (a) Especificação do modelo de transição anterior e do modelo de sensores para a\\nDBN de guarda-chuva. Todas as fatias subsequentes são consideradas cópias das fatia 1. (b) DBN\\nsimples para o movimento de um robô no plano X−Y.\\nAgora, vamos considerar um exemplo mais interessante: o monitoramento de um robô alimentado\\npor bateria que se move no plano X−Y, como vimos no final da \\nSeção 15.1\\n. Primeiro, precisamos de\\nvariáveis de estados, que incluirão tanto \\nX\\nt\\n = (\\nX\\nt\\n, \\nY\\nt\\n) para representar a posição quanto \\npara representar a velocidade.\\nPresumiremos algum método para medir a posição — talvez uma câmera fixa ou um GPS (\\nGlobal\\nPositioning System\\n) a bordo — produzindo medições de \\nZ\\nt\\n. A posição no período de tempo seguinte\\ndependerá da posição atual e da velocidade, como no modelo de filtro de Kalman padrão. A\\nvelocidade no período seguinte dependerá da velocidade atual e do estado da bateria.\\nAcrescentamos \\nBateria\\nt\\n para representar o nível de carga real da bateria, que tem como pais o nível\\nda bateria anterior e a velocidade, e também adicionamos \\nMedidorB\\nt\\n, que mede o nível de carga da\\nbateria. Isso nos dá o modelo básico mostrado na \\nFigura 15.13\\n(b).\\nVale a pena examinarmos com maior profundidade a natureza do modelo de sensores\\ncorrespondente a \\nMedidorB\\nt\\n. Vamos supor, por simplicidade, que tanto \\nBateria\\nt\\n quanto \\nMedidorB\\nt\\npossam assumir valores discretos de 0 até 5, de modo muito semelhante ao medidor do nível da\\nbateria em um laptop típico. Se o medidor for sempre preciso, a TPC (tabela de probabilidade\\ncondicional) \\nP\\n(\\nMedidorB\\nt\\n | \\nBateria\\nt\\n) deve ter probabilidades 1,0 “ao longo da diagonal” e\\nprobabilidades 0,0 nos outros lugares. Na realidade, o ruído sempre interfere nas medições. No caso', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 689}),\n",
       " Document(page_content='de medições contínuas, poderia ser usada em vez disso uma distribuição gaussiana com pequena\\nvariância.\\n5\\n No caso de nossas variáveis discretas, podemos fazer a aproximação de uma gaussiana\\nutilizando uma distribuição na qual a probabilidade de erro caia de maneira apropriada, de modo que\\na probabilidade de um erro grande seja muito pequena. Utilizaremos a expressão \\nmodelo de erro\\ngaussiano\\n para cobrir tanto a versão contínua quanto a versão discreta.\\nQualquer pessoa com experiência prática em robótica, controle de processos computadorizados ou\\noutras formas de detecção automática admitirá prontamente o fato de que pequenas quantidades de\\nruído de medição são muitas vezes o menor dos problemas. Os sensores reais \\nfalham\\n. Quando um\\nsensor falha, ele não envia necessariamente um sinal afirmando: “Oh, a propósito, os dados que estou\\nprestes a lhe enviar não têm o menor sentido.” Em vez disso, ele simplesmente envia os dados sem\\nsentido. A espécie mais simples de falha é chamada \\nfalha transiente\\n, na qual o sensor decide\\nocasionalmente enviar alguns dados sem sentido. Por exemplo, o sensor de nível da bateria pode ter\\no hábito de enviar um zero quando alguém se choca com o robô, mesmo que a bateria esteja\\ncompletamente carregada.\\nVamos ver o que acontece quando ocorre uma falha transiente com um modelo de erro gaussiano\\nque não admite tais falhas. Por exemplo, suponha que o robô esteja calmamente sentado e observe 20\\nleituras consecutivas da bateria indicando o nível de carga 5. Em seguida, o medidor da bateria tem\\num ataque temporário e a leitura seguinte é \\nMedidorB\\n21\\n = 0. Qual será o modelo de erro gaussiano\\nsimples que nos levará a acreditar em \\nBateria\\n21\\n? De acordo com a regra de Bayes, a resposta\\ndepende tanto do modelo de sensores \\nP\\n(\\nMedidorB\\n21\\n = 0 | \\nBateria\\n21\\n) quanto da previsão \\nP\\n(\\nBateria\\n21\\n |\\nMedidorB\\n1:20\\n). Se a probabilidade de um grande erro de sensor for significativamente menos\\nprovável que a probabilidade de uma transição para \\nBateria\\n21\\n = 0, mesmo que esta última seja muito\\nimprovável, então a distribuição posterior atribuirá alta probabilidade ao fato de a bateria estar sem\\ncarga. Uma segunda leitura igual a zero em \\nt\\n = 22 tornará essa conclusão quase certa. Se a falha\\ntransiente desaparecer em seguida e a leitura retornar a 5 a partir de \\nt\\n = 23 em diante, a estimativa do\\nnível da bateria voltará rapidamente a 5, como se fosse por mágica. Esse curso de eventos é ilustrado\\nna curva superior da \\nFigura 15.14\\n(a), que mostra o valor esperado de \\nBateria\\nt\\n ao longo do tempo,\\nusando um modelo de erro gaussiano discreto.\\nFigura 15.14\\n (a) Curva superior: trajetória do valor esperado de \\nBateria\\nt\\n para uma sequência de\\nobservações que consiste apenas em valores 5, exceto pelos valores 0 em \\nt\\n = 21 e \\nt\\n = 22, usando um\\nmodelo de erro gaussiano simples. Curva inferior: trajetória quando a observação permanece igual a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 690}),\n",
       " Document(page_content='0 a partir de \\nt\\n = 21. (b) A mesma experiência com o modelo de falha transiente. Note que a falha\\ntransiente é bem tratada, mas a falha persistente resulta em pessimismo excessivo sobre a carga da\\nbateria.\\n Apesar da recuperação, existe um tempo (\\nt\\n = 22) em que o robô se convence de que sua bateria\\nestá sem carga; então, presume-se que ele deve enviar um sinal de socorro e se desligar.\\nInfelizmente, seu modelo de sensores supersimplificado fez com que ele se perdesse. Como isso\\npode ser corrigido? Considere um exemplo familiar extraído da atividade humana diária de dirigir:\\nem curvas bruscas ou em colinas íngremes, o “tanque de combustível se esvazia” e às vezes faz a luz\\nde advertência acender. Em vez de procurar pelo telefone de emergência, lembramos que o medidor\\nde nível de combustível simplesmente comete um erro muito grande quando o combustível está\\njogando de um lado para outro dentro do tanque. Moral da história é: \\npara o sistema manipular\\nfalhas de sensores de maneira apropriada, o modelo de sensores deve incluir a possibilidade de\\nfalha\\n.\\nA espécie mais simples de modelo de falha para um sensor dá certa margem de probabilidade de\\nque o sensor retornará algum valor completamente incorreto, independentemente do estado\\nverdadeiro do mundo. Por exemplo, se o medidor de bateria falhar retornando 0, poderemos dizer\\nque\\nP\\n(\\nMedidorB\\nt\\n = 0 | \\nBateria\\nt\\n = 5) = 0,03,\\nque presumivelmente é muito maior que a probabilidade atribuída pelo modelo de erro gaussiano\\nsimples. Vamos chamá-lo \\nmodelo de falha transiente\\n. De que maneira ele nos ajuda quando estamos\\ndiante de uma leitura igual a 0? Considerando-se que a probabilidade \\nprevista\\n de uma bateria sem\\ncarga, de acordo com as leituras feitas até o momento, é muito menor que 0,03, a melhor explicação\\nda observação \\nMedidorB\\n21\\n = 0 é que o sensor falhou temporariamente. Por intuição, podemos\\nimaginar que a crença sobre o nível da bateria tem certa quantidade de “inércia” que ajuda a superar\\noscilações temporárias na leitura do medidor. A curva superior da \\nFigura 15.14\\n(b) mostra que o\\nmodelo de falha transiente pode manipular falhas transientes sem mudança catastrófica nas crenças.\\nEssa é a situação no caso de oscilações temporárias. E, se houver falha persistente de um sensor?\\nInfelizmente, falhas desse tipo são bastante comuns. Se o sensor retornar 20 leituras iguais a 5\\nseguidas por 20 leituras iguais a 0, então o modelo de falha de sensor transiente descrito no\\nparágrafo anterior terá como resultado o fato de o robô ser levado gradualmente a acreditar que sua\\nbateria está sem carga quando de fato talvez o medidor tenha falhado. A curva inferior da \\nFigura\\n15.14\\n(b) mostra a “trajetória” de crença para esse caso. Depois de \\nt\\n = 25 — cinco leituras iguais a 0\\n—, o robô se convence de que sua bateria está sem carga. É óbvio que preferiríamos que o robô\\nacreditasse que o medidor de sua bateria está quebrado, se esse de fato fosse o evento mais\\nprovável.\\nNão surpreende que, para tratar uma falha persistente, tenhamos necessidade de um \\nmodelo de\\nfalha persistente\\n que descreva como o sensor se comporta sob condições normais e após uma falha.\\nPara isso, precisamos ampliar o estado oculto do sistema com uma variável adicional, digamos\\nMBQuebrado\\n, que descreva o \\nstatus\\n do medidor da bateria. A persistência da falha deve ser', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 691}),\n",
       " Document(page_content='modelada por um arco vinculando \\nMBQuebrado\\n0\\n a \\nMBQuebrado\\n1\\n. Esse \\narco de persistência\\n tem\\numa TPC que fornece pequena probabilidade de falha em qualquer período de tempo dado, digamos\\n0,001, mas especifica que o sensor permanece quebrado depois de se quebrar. Quando o sensor está\\nem perfeitas condições, o modelo de sensores para \\nMedidorB\\n é idêntico ao modelo de falha\\ntransiente; quando o sensor está quebrado, ele informa que \\nMedidorB\\n é sempre 0, independentemente\\ndo estado real da bateria.\\nO modelo de falha persistente para o sensor de bateria é mostrado na \\nFigura 15.15\\n(a). Seu\\ndesempenho sobre as duas sequências de dados (oscilação temporária e falha persistente) é mostrado\\nna \\nFigura 15.15\\n(b). Devemos notar vários detalhes sobre essas curvas. Primeiro, no caso da\\noscilação temporária, a probabilidade de que o sensor esteja quebrado se eleva de forma\\nsignificativa após a segunda leitura 0, mas volta a cair imediatamente a zero depois de se observar\\num valor 5. Em segundo lugar, no caso de falha persistente, a probabilidade de que o sensor esteja\\nquebrado se eleva com rapidez até um valor próximo de 1 e permanece com esse valor. Por fim, uma\\nvez confirmado que o sensor está quebrado, o robô só pode supor que sua bateria se descarrega à\\nvelocidade “normal”, como mostra o nível gradualmente descendente de \\nE\\n(\\nBateria\\nt\\n | …).\\nFigura 15.15\\n (a) Um fragmento de DBN mostrando a variável de \\nstatus\\n de sensor exigida para a\\nmodelagem de falha persistente do sensor da bateria. (b) Curvas superiores: trajetórias do valor\\nesperado de \\nBateria\\nt\\n para as sequências de observações de “falha transiente” e “falha permanente”.\\nCurvas inferiores: trajetórias de probabilidade para \\nMBQuebrado\\n, dadas as duas sequências de\\nobservações.\\nAté agora, apenas arranhamos a superfície do problema de representação de processos complexos.\\nA variedade de modelos de transição é enorme, englobando tópicos tão discrepantes quanto a\\nmodelagem do sistema endócrino humano e a modelagem de vários veículos trafegando em uma\\nautoestrada. A modelagem de sensores também é por si só um vasto subcampo, mas, mesmo\\nfenômenos sutis, como flutuação de sensores, descalibração repentina e os efeitos de condições\\nexógenas (como as condições do clima) sobre leituras de sensores, podem ser manipuladas por\\nrepresentação explícita dentro de redes bayesianas dinâmicas.\\n15.5.2 Inferência exata em DBNs', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 692}),\n",
       " Document(page_content='Tendo esboçado algumas ideias para representar processos complexos como DBNs, vamos passar\\nagora à questão da inferência. De certo modo, essa pergunta já foi respondida: as redes bayesianas\\ndinâmicas \\nsão\\n redes bayesianas, e já temos algoritmos para inferência em redes bayesianas. Dada\\numa sequência de observações, é possível construir a representação de rede bayesiana total de uma\\nDBN replicando fatias até a rede ser grande o bastante para acomodar as observações, como na\\nFigura 15.16\\n. Essa técnica, mencionada no Capítulo 14 no contexto dos modelos de probabilidade\\nrelacional, é chamada \\ndesenrolamento\\n. (Tecnicamente, a DBN é equivalente à rede semi-infinita\\nobtida por desenrolamento eterno. Fatias adicionadas depois da última observação não têm nenhum\\nefeito sobre inferências dentro do período de observação e podem ser omitidas.) Uma vez que a\\nDBN é desenvolvida, pode-se empregar qualquer dos algoritmos de inferência — eliminação de\\nvariáveis, métodos de árvores de junção, e assim por diante — descritos no Capítulo 14.\\nFigura 15.16\\n Desenrolamento de uma rede bayesiana dinâmica: as fatias são replicadas para\\nacomodar a sequência de observações \\ngurda-chuva\\n1:3\\n. Fatias adicionais não têm nenhum efeito sobre\\ninferências dentro do período de observação.\\nInfelizmente, uma aplicação ingênua de desenrolamento não seria particularmente eficiente. Se\\nquiséssemos executar a filtragem ou a suavização com uma longa sequência de observações \\ne\\n1:\\nt\\n, a\\nrede desenrolada exigiria o espaço \\nO\\n(\\nt\\n) e, portanto, cresceria sem limite à medida que fossem\\nadicionadas mais observações. Além disso, se simplesmente executarmos de novo o algoritmo de\\ninferência a cada vez que for adicionada uma observação, o tempo de inferência por atualização\\ntambém aumentará com \\nO\\n(\\nt\\n).\\nVoltando à \\nSeção 15.2.1\\n, vemos que é possível obter atualização com tempo e espaço constantes\\npor filtragem se a computação puder ser realizada de forma recursiva. Em essência, a atualização de\\nfiltragem na Equação 15.5 funciona \\nefetuando-se o somatório\\n das variáveis de estados do período\\nde tempo anterior, a fim de se obter a distribuição correspondente ao novo período de tempo. Efetuar\\no somatório das variáveis é exatamente o que faz o algoritmo de \\neliminação de variáveis\\n (\\nFigura\\n14.11\\n), e ocorre que a execução da eliminação de variáveis com as variáveis em ordem temporal\\nimita de maneira exata a operação da atualização de filtragem recursiva da Equação 15.5. O\\nalgoritmo modificado mantém, no máximo, duas fatias na memória em qualquer instante: começando\\ncom a fatia 0, adicionamos a fatia 1, depois somamos a fatia 0, em seguida adicionamos a fatia 2,\\nsomamos a fatia 1, e assim por diante. Desse modo, podemos conseguir atualização com espaço e\\ntempo constantes por filtragem (o mesmo desempenho pode ser alcançado fazendo-se modificações\\napropriadas no agrupamento do algoritmo). O Exercício 15.17 pede para verificar esse fato no caso\\nda rede de guarda-chuva.\\nAgora esgotamos as boas notícias; vamos então examinar as más notícias. Ocorre que a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 693}),\n",
       " Document(page_content='“constante” para complexidade de tempo e espaço por atualização é, em quase todos os casos,\\nexponencial em relação ao número de variáveis de estados. Acontece que, à medida que a\\neliminação de variáveis prossegue, os fatores crescem até incluir todas as variáveis de estados (ou,\\nmais precisamente, todas as variáveis de estados que têm pais na fatia de tempo anterior). O tamanho\\nmáximo do fator é \\nO\\n(\\nd\\nn+k\\n) e o custo da atualização por etapa é \\nO\\n(\\nnd\\nn+k\\n), onde \\nd\\n é o tamanho do\\ndomínio das variáveis e \\nk\\n é o número máximo de pais de qualquer variável de estado.\\n É claro que esse é um valor muito menor que o custo de atualização de MOM, que é \\nO\\n(\\nd\\n2\\nn\\n), mas\\nainda é inviável para grande número de variáveis. Esse terrível fato é algo um tanto difícil de\\naceitar. Ele significa que, \\nembora possamos usar DBNs para\\n representar \\nprocessos temporais muito\\ncomplexos com muitas variáveis esparsamente conectadas, não podemos\\n raciocinar \\nde modo\\neficiente e exato sobre esses processos\\n. O próprio modelo de DBN, que representa a distribuição\\nconjunta anterior sobre todas as variáveis, pode ser fatorado em suas TPCs constituintes, mas a\\ndistribuição conjunta posterior condicionada sobre uma sequência de observações — ou seja, a\\nmensagem para a frente — em geral \\nnão\\n é fatorável. Até agora, ninguém encontrou um modo de\\ncontornar esse problema, a despeito do fato de que muitas áreas importantes de ciência e engenharia\\nse beneficiariam enormemente de sua solução. Desse modo, devemos recorrer a métodos\\naproximados.\\n15.5.3 Inferência aproximada em DBNs\\nA \\nSeção 14.5\\n descreveu dois algoritmos de aproximação: ponderação de probabilidades (\\nFigura\\n14.15\\n) e cadeia de Markov Monte Carlo (CMMC, \\nFigura 14.16\\n). Dos dois, o primeiro se adapta com\\nmaior facilidade ao contexto de DBN (um algoritmo de filtragem CMMC será descrito brevemente\\nnas notas ao final do capítulo). No entanto, veremos que são necessários vários aperfeiçoamentos\\nsobre o algoritmo-padrão de ponderação de probabilidades antes de emergir um método prático.\\n Lembre-se de que a ponderação de probabilidades funciona por amostragem dos nós de não\\nevidência da rede em ordem topológica, ponderando cada amostra pela probabilidade que ela\\nconcede às variáveis de evidência observadas. Como ocorre no caso de algoritmos exatos,\\npoderíamos aplicar a ponderação de probabilidades diretamente a uma DBN não desenrolada, mas\\nisso acarretaria os mesmos problemas em termos de aumento de requisitos de tempo e espaço por\\natualização, à medida que a sequência de observações crescesse. O problema é que o algoritmo-\\npadrão executa cada amostra por sua vez, percorrendo toda a rede. Em vez disso, podemos\\nsimplesmente executar todas as \\nN\\n amostras juntas pela DBN, uma fatia de cada vez. O algoritmo\\nmodificado se ajusta ao padrão geral de algoritmos de filtragem, com o conjunto de \\nN\\n amostras como\\na mensagem para a frente. Então, a primeira inovação-chave é \\nusar as próprias amostras como uma\\nrepresentação aproximada da distribuição de estados atual\\n. Isso atende ao requisito de um tempo\\n“constante” por atualização, embora a constante dependa do número de amostras necessárias para\\nmanter uma aproximação razoável em relação à distribuição posterior verdadeira. Não há nenhuma\\nnecessidade de desenrolar a DBN porque precisamos ter na memória apenas a fatia atual e a próxima\\nfatia.\\nEm nossa discussão da ponderação de probabilidades no Capítulo 14, destacamos que a exatidão', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 694}),\n",
       " Document(page_content='do algoritmo sofre se as variáveis de evidência estão “abaixo” das variáveis que estão sendo\\namostradas porque, nesse caso, as amostras são geradas sem qualquer influência da evidência.\\nExaminando a estrutura típica de uma DBN — digamos, a DBN do guarda-chuva da \\nFigura 15.16\\n —\\nvemos que, na verdade, as primeiras variáveis de estados serão amostradas sem o benefício da\\nevidência posterior. De fato, observando com maior cuidado, vemos que \\nnenhuma\\n das variáveis de\\nestados tem \\nquaisquer\\n variáveis de evidência entre seus ancestrais! Consequentemente, embora o\\npeso de cada amostra dependa da evidência, o conjunto real de amostras geradas será\\ncompletamente independente\\n da evidência. Por exemplo, ainda que o chefe trouxesse o guarda-\\nchuva todo dia, o processo de amostragem poderia refletir infinitos dias de sol. Na prática, isso\\nsignifica que a fração de amostras que permanecem razoavelmente próximas à série real de eventos\\n(e, portanto, têm pesos não elegíveis) cai exponencialmente com \\nt\\n, a duração da sequência de\\nobservações; em outras palavras, para manter dado nível de exatidão, precisamos aumentar\\nexponencialmente o número de amostras com \\nt\\n. Considerando que um algoritmo de filtragem que\\nfuncione em tempo real só pode usar um número fixo de amostras, o efeito prático é que o erro\\nexplode depois de um número muito pequeno de passos de atualização.\\n Sem dúvida, precisamos de uma solução melhor. A segunda inovação-chave é \\nconcentrar o\\nconjunto de amostras nas regiões de alta probabilidade do espaço de estados\\n. Isso pode ser feito\\ndescartando-se amostras que têm peso muito baixo, de acordo com as observações, enquanto se\\nreplicam as que têm peso elevado. Desse modo, a população de amostras permanecerá\\nrazoavelmente próxima da realidade. Se pensarmos nas amostras como um recurso para modelar a\\ndistribuição posterior, fará sentido usar mais amostras em regiões do espaço de estados em que a\\ndistribuição posterior for mais alta.\\nUma família de algoritmos denominados algoritmos de \\nfiltragem de partículas\\n foi projetada para\\nfazer exatamente isso. A filtragem de partículas funciona assim: primeiro, uma população de \\nN\\namostras de estado inicial é criada por amostragem da distribuição anterior no tempo 0, \\nP\\n(\\nX\\n0\\n). Em\\nseguida, o ciclo de atualização é repetido para cada período de tempo:\\n1. Cada amostra é propagada para a frente por amostragem do próximo valor de estado \\nx\\nt\\n+1\\n, dado\\no valor atual \\nx\\nt\\n para a amostra, e usando-se o modelo de transição \\nP\\n(\\nX\\nt\\n+1\\n|\\nx\\nt\\n).\\n2. Cada amostra é ponderada pela probabilidade que atribui à nova evidência, \\nP\\n(\\ne\\nt\\n+1\\n | \\nx\\nt\\n+1\\n).\\n3. A população é \\nreamostrada\\n para gerar uma nova população de \\nN\\n amostras. Cada nova amostra\\né selecionada a partir da população atual; a probabilidade de uma amostra específica ser\\nselecionada é proporcional ao seu peso. As novas amostras são não ponderadas.\\nO algoritmo é mostrado em detalhes na \\nFigura 15.17\\n, e sua operação para a DBN do guarda-chuva\\né ilustrada na \\nFigura 15.18\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 695}),\n",
       " Document(page_content='função\\n FILTRAGEM-DE-PARTÍCULAS(\\ne\\n, \\nN\\n, \\ndbn\\n) \\nretorna\\n um conjunto de amostras para o\\npróximo período de tempo\\n    \\nentradas: e\\n, a nova evidência de entrada\\nN\\n, o número de amostras a serem mantidas\\ndbn\\n, uma DBN com modelo de transição anterior \\nP\\n(\\nX\\n0\\n), modelo de transição\\nP\\n(\\nX\\n1\\n|\\nX\\n0\\n) e modelo de sensores \\nP\\n(\\nE\\n1\\n|\\nX\\n1\\n)\\n    \\npersistente:\\n \\nS\\n, um vetor de amostras de tamanho \\nN\\n, inicialmente gerado a partir de \\nP\\n(\\nX\\n0\\n)\\n    \\nvariáveis locais:\\nW\\n, um vetor de pesos de tamanho \\nN\\n    \\n    \\npara\\n \\ni\\n = 1 \\naté\\n \\nN\\n \\nfaça\\n        \\nS\\n[\\ni\\n] ← amostra de \\nP\\n(\\nX\\n1\\n | \\nX\\n0\\n = \\nS\\n[\\ni\\n]) /*etapa 1 */\\n        \\nW\\n[\\ni\\n] ← \\nP\\n(\\ne\\n | \\nX\\n1\\n = \\nS\\n[\\ni\\n]) /*etapa 2 */\\n    \\nS\\n ← AMOSTRAGEM-PONDERADA-COM-REPOSIÇÃO(\\nN\\n, \\nS\\n,\\nW\\n) /*etapa 3 */\\n    \\nretornar\\n \\nS\\nFigura 15.17\\n Algoritmo de filtragem de partículas implementado como uma operação de atualização\\nrecursiva com estado (o conjunto de amostras). Cada uma das etapas de amostragem envolve a\\namostragem das variáveis de fatias relevantes em ordem topológica, de modo muito semelhante à\\nAMOSTRAGEM-\\nA-PRIORI\\n. A operação de AMOSTRAGEM-PONDERADA-COM-REPOSIÇÃO\\npode ser implementada para funcionar no tempo esperado \\nO\\n(\\nN\\n). O número de etapas refere-se à\\ndescrição no texto.\\nFigura 15.18\\n Ciclo de atualização da filtragem de partículas para a DBN de guarda-chuva com \\nN\\n =\\n10, com as populações de amostras de cada estado. (a) No tempo \\nt\\n, oito amostras indicam \\nchuva\\n e\\nduas indicam ¬\\nchuva\\n. Cada uma é propagada para a frente pela amostragem do estado seguinte via', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 696}),\n",
       " Document(page_content='modelo de transição. No tempo \\nt\\n + 1, 6 amostras indicam \\nchuva\\n e quatro indicam ¬\\nchuva\\n. (b)\\n¬\\nguarda\\n-\\nchuva\\n é observado em \\nt\\n + 1.Cada amostra é ponderada por sua probabilidade referente à\\nobservação,como indicam os tamanhos dos círculos. (c) Um novo conjunto de 10 amostras é gerado\\npor seleção aleatória ponderada do conjunto atual, resultando em duas amostras que indicam \\nchuva\\n e\\noito que indicam ¬\\nchuva\\n.\\nPodemos mostrar que esse algoritmo é consistente — fornece as probabilidades corretas à medida\\nque \\nN\\n tende a infinito —, considerando-se o que acontece durante um ciclo de atualização. Vamos\\nsupor que a população de amostras comece com uma representação correta da mensagem para a\\nfrente \\nf\\n1:\\nt\\n = \\nP\\n(\\nX\\nt\\n | \\ne\\n1:\\nt\\n) no tempo \\nt\\n. Escrevendo \\nN\\n(\\nx\\nt\\n | \\ne\\n1:\\nt\\n) para representar o número de amostras que\\nocupam o estado \\nx\\nt\\n depois das observações \\ne\\n1:\\nt\\n terem sido processadas, temos:\\npara \\nN\\n grande. Agora, propagamos cada amostra para a frente, realizando a amostragem das\\nvariáveis de estados em \\nt\\n + 1, dados os valores para a amostra em \\nt\\n. O número de amostras que\\nalcançam o estado \\nx\\nt\\n+1\\n de cada \\nx\\nt\\n é a probabilidade de transição multiplicada pela população de \\nx\\nt\\n;\\nconsequentemente, o número total de amostras que alcançam \\nx\\nt\\n+1\\n é:\\nAgora, ponderamos cada amostra por sua probabilidade para a evidência em \\nt\\n +1. Uma amostra no\\nestado \\nx\\nt\\n+1\\n recebe peso \\nP\\n(\\ne\\nt\\n+1\\n | \\nx\\nt\\n+1\\n). O peso total das amostras em \\nx\\nt\\n+1\\n depois de se ver \\ne\\nt\\n+1\\n é\\nportanto\\nEm seguida, vamos à etapa de reamostragem. Tendo em vista que cada amostra é replicada com\\nprobabilidade proporcional ao seu peso, o número de amostras no estado \\nx\\nt\\n+1\\n depois da\\nreamostragem é proporcional ao peso total em \\nx\\nt\\n+1\\n antes da reamostragem:\\nPor conseguinte, a população da amostra após um ciclo de atualização representa corretamente a\\nmensagem para a frente no tempo \\nt\\n + 1.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 697}),\n",
       " Document(page_content='Então, a filtragem de partículas é \\nconsistente\\n; porém, ela é \\neficiente\\n? Na prática, parece que a\\nresposta é sim: a filtragem de partículas parece manter boa aproximação em relação à distribuição\\nposterior verdadeira com o uso de um número constante de amostras. Sob certas suposições — em\\nparticular, que as probabilidades nos modelos de transição e de sensores são estritamente maiores\\nque 0 e menores que 1 —, é possível provar que a aproximação mantém erro delimitado com alta\\nprobabilidade. Pelo lado prático, a gama de aplicações tem crescido, incluindo muitos campos da\\nciência e da engenharia; algumas referências são dadas ao final do capítulo.\\n15.6 MANUTENÇÃO E CONTROLE DE MUITOS OBJETOS\\nAs seções anteriores consideraram — sem mencionar — problemas de avaliação de estado\\nenvolvendo um único objeto. Nesta seção, veremos o que acontece quando dois ou mais objetos\\ngeram observações. O que torna esse caso diferente da avaliação de estado simples é que há agora a\\npossibilidade da \\nincerteza\\n sobre qual objeto gerou qual observação. Esse é o problema de \\nincerteza\\nde identidade\\n da \\nSeção 14.6.3\\n, agora visto em um contexto temporal. Na literatura da teoria de\\ncontrole, esse é o problema de \\nassociação de dados\\n, isto é, o problema de associar dados de\\nobservação com os objetos que os geraram.\\nO problema de associação de dados foi estudado inicialmente no contexto de rastreamento de\\nradar, onde são detectados os pulsos refletidos em intervalos de tempo fixos por uma antena de radar\\nrotativa. Em cada período de tempo, podem aparecer na tela múltiplos pontos de luz pequenos que\\nrepresentam um objeto no radar, mas não há nenhuma observação direta de quais pontos no tempo \\nt\\npertencem a quais pontos no tempo \\nt\\n − 1. A \\nFigura 15.19\\n(a) mostra um exemplo simples com dois\\npontos de luz por período de tempo de cinco etapas. Sejam as duas localizações do ponto de luz no\\ntempo \\nt\\n \\ne\\n1\\nt\\n e \\ne\\n2\\nt\\n (a rotulagem dos pontos de luz em um intervalo de tempo como “1” e “2” é\\ncompletamente arbitrária e não carrega informações). Suponhamos, por enquanto, que exatamente\\nduas aeronaves, \\nA\\n e \\nB\\n, geraram os pontos de luz; suas posições verdadeiras são \\nX\\nA\\nt\\n e \\nX\\nB\\nt\\n. Para\\nsimplificar, vamos supor também que cada aeronave se mova independentemente de acordo com um\\nmodelo de transição conhecido, por exemplo, um modelo linear gaussiano, como o utilizado no filtro\\nde Kalman (\\nSeção 15.4\\n).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 698}),\n",
       " Document(page_content='Figura 15.19 (a)\\n Observações feitas a partir de localizações de objetos no espaço 2-D ao longo de\\ncinco etapas de tempo. Cada observação é rotulada com o período de tempo, mas não identifica o\\nobjeto que o produziu. (b−c) Possíveis suposições sobre as pistas do objeto subjacente. (d) Uma\\nsuposição para o caso em que é possível: alarmes falsos, falha de detecção e inicio/término de pista.\\nSuponha que tentamos escrever o modelo de probabilidade completo para esse cenário, assim\\ncomo fizemos para os processos temporais gerais na Equação 15.3. Como de costume, os fatores de\\ndistribuição conjuntos em contribuição para cada período de tempo são os seguintes:\\nGostaríamos de decompor o termo de observação \\n em um produto de dois termos,\\num para cada objeto, mas isso exigiria saber que observação foi gerada por qual objeto. Em vez\\ndisso, temos que somar todas as formas possíveis de associar as observações com os objetos.\\nAlgumas dessas formas são mostradas na \\nFigura 15.19\\n (b−c); em geral, para \\nn\\n objetos e \\nT\\n períodos\\nde tempo, existem (\\nn\\n!)\\nT\\n maneiras de fazê-lo — um número muito grande.\\nMatematicamente falando, a “maneira de associar as observações com os objetos” é uma coleção\\nde variáveis aleatórias não observadas que identificam a origem de cada observação. Vamos\\nescrever \\nω\\nt\\n para indicar o mapeamento um a um a partir de objetos para observações no tempo \\nt\\n,\\ncom \\nω\\nt\\n(\\nA\\n) e \\nω\\nt\\n(\\nB\\n) indicando as observações específicas (1 ou 2) que \\nω\\nt\\n atribui a \\nA\\n e \\nB\\n (para \\nn\\nobjetos, ω\\nt\\n terá \\nn\\n! valores possíveis; aqui, \\nn\\n! = 2). Porque os rótulos “1” e “2” sobre as observações\\nsão atribuídos arbitrariamente, \\na priori\\n \\nω\\nt\\n é uniforme sobre \\nω\\nt\\n e independente dos estados dos\\nobjetos, \\n e \\n). Assim, podemos condicionar o termo de observação \\n sobre \\nω\\nt\\n e\\nsimplificar:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 699}),\n",
       " Document(page_content='Ligando com a Equação 15.24, obtemos uma expressão apenas em termos do modelo de transição\\ne de sensores para objetos e observações individuais.\\nAssim como ocorre para todos os modelos de probabilidade, inferência significa somar sobre as\\nvariáveis que não sejam a consulta e a evidência. Para filtragem em MOMs e DBNs, fomos capazes\\nde somar as variáveis de estado de 1 a \\nt\\n − 1 por um truque simples de programação dinâmica, para\\nos filtros de Kalman, aproveitando propriedades especiais gaussianas. Para associação de dados,\\ntivemos menos sorte. Não há algoritmo (conhecido) exato eficiente, pela mesma razão que não existe\\npara a filtragem de comutação de Kalman: a distribuição de filtragem \\n para o objeto \\nA\\nacaba como uma mistura de muitas distribuições exponenciais, uma para cada forma de escolher uma\\nsequência de observações para atribuir a \\nA\\n.\\nComo resultado da complexidade da inferência exata, foram utilizados muitos métodos\\naproximados diferentes. A abordagem mais simples é escolher uma única atribuição “melhor” em\\ncada período de tempo, dadas as posições dos objetos previstas no período de tempo atual. Essa\\natribuição associa observações com objetos e permite que a pista de cada objeto seja atualizada e\\nfeita uma previsão para o próximo período de tempo. Para escolher a “melhor” atribuição, é comum\\nusar o chamado \\nfiltro de vizinho mais próximo\\n, que escolhe repetidamente o par de posições\\nprevisto e a observação mais próxima e adiciona esse par à atribuição. O filtro de vizinho mais\\npróximo funciona bem quando os objetos estão bem separados no espaço de estados e o erro de\\nprevisão e incerteza é pequeno — em outras palavras, quando não há possibilidade de confusão.\\nQuando há mais incerteza quanto à atribuição correta, uma abordagem melhor é escolher a atribuição\\nque maximiza a probabilidade conjunta das observações atuais, dadas as posições previstas. Isso\\npode ser feito de forma muito eficiente usando o \\nalgoritmo húngaro\\n (Kuhn, 1955), embora haja \\nn\\n!\\natribuições para escolher.\\nQualquer método que se compromete com uma atribuição única e melhor em cada período de\\ntempo falha miseravelmente em condições mais difíceis. Em particular, se o algoritmo compromete-\\nse com uma atribuição incorreta, a previsão no próximo período de tempo pode estar\\nsignificativamente errada, conduzindo a mais atribuições incorretas, e assim por diante. Duas\\nabordagens modernas acabam por ser muito mais eficazes. Um algoritmo de \\nfiltragem de partícula\\npara associação de dados funciona pela manutenção de uma grande coleção de atribuições atuais\\npossíveis. Um algoritmo CMMC explora o espaço histórico de atribuições — por exemplo, a \\nFigura\\n15.19\\n (b−c) pode ser declarada no espaço de estados CMMC — e pode mudar de opinião sobre\\ndecisão de atribuições anteriores. Os métodos de dados de associação atuais, CMMC, podem lidar\\ncom muitas centenas de objetos em tempo real enquanto fornecem uma boa aproximação para as\\ndistribuições posteriores verdadeiras.\\nO cenário descrito até agora envolveu \\nn\\n objetos conhecidos gerando \\nn\\n observações em cada\\nperíodo de tempo. A aplicação real da associação de dados é tipicamente muito mais complicada.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 700}),\n",
       " Document(page_content='Muitas vezes, as observações relatadas incluem alarmes falsos (também conhecidos como \\nsinal\\nindesejado\\n), que não são provocados por objetos reais. Podem ocorrer \\nfalhas de detecção\\n, o que\\nsignifica que nenhuma observação é relatada com relação a um objeto real. Finalmente, chegam\\nobjetos novos e os antigos desaparecem. Esse fenômeno, que cria ainda mais mundos possíveis com\\nos quais se preocupar, está ilustrado na \\nFigura 15.19\\n(d).\\nA \\nFigura 15.20\\n mostra duas imagens de câmeras amplamente separadas em uma rodovia da\\nCalifórnia. Nessa aplicação, estamos interessados em dois objetivos: estimar o tempo que leva, em\\ntermos das condições de tráfego atual, para ir de um lugar para outro no sistema de autoestrada e\\nmedir a \\ndemanda\\n, ou seja, quantos veículos rodam entre dois pontos quaisquer no sistema em\\ndeterminado período de tempo do dia e em dias específicos da semana. Ambos os objetivos\\nrequerem a resolução do problema de associação de dados em uma área ampla com muitas câmeras e\\ndezenas de milhares de veículos por hora. Com a fiscalização visual, sombras em movimento,\\nveículos articulados, reflexos nas poças de água etc. causam alarmes falsos; oclusão, nevoeiro,\\nescuridão e falta de contraste visual causam falhas de detecção; e os veículos estão constantemente\\nentrando e saindo do sistema da rodovia. Além disso, o aparecimento de qualquer veículo pode\\nmudar drasticamente entre as câmeras, dependendo das condições de iluminação e da posição do\\nveículo na imagem, e o modelo de transição muda à medida que os engarrafamentos vêm e vão.\\nApesar desses problemas, os algoritmos de associação de dados modernos têm obtido sucesso ao\\nestimar parâmetros de tráfego em contextos do mundo real.\\nFigura 15.20\\n Imagens da fiscalização por câmeras do fluxo de subida (a) e descida (b) cerca de duas\\nmilhas distante da Autoestrada 99, em Sacramento, Califórnia. O veículo marcado com contorno foi\\nidentificado nas duas câmeras.\\nAs associações de dados são uma base essencial para manter o controle de um mundo complexo\\nporque sem elas não há maneira de combinar múltiplas observações de determinado objeto. Quando\\nos objetos do mundo interagem uns com os outros em atividades complexas, a compreensão do\\nmundo requer a combinação de associação de dados com os modelos de probabilidade relacional e\\nde universo aberto da \\nSeção 14.6.3\\n. Essa é atualmente uma área de pesquisa ativa.\\n15.7 RESUMO', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 701}),\n",
       " Document(page_content='Este capítulo tratou do problema geral de representar e raciocinar sobre processos temporais\\nprobabilísticos. Os principais pontos foram:\\n•  O estado mutável do mundo é manipulado pela utilização de um conjunto de variáveis aleatórias\\npara representar o estado em cada instante no tempo.\\n•  As representações podem ser projetadas para satisfazer à \\npropriedade de Markov\\n, de forma\\nque o futuro seja independente do passado, dado o presente. Combinado com a hipótese de que o\\nprocesso é \\nestacionário\\n — isto é, as dinâmicas não mudam ao longo do tempo —, isso\\nsimplifica bastante a representação.\\n•  Um modelo de probabilidade temporal pode ser considerado a união de um \\nmodelo de transição\\nque descreve a evolução e um \\nmodelo de sensores\\n que descreve o processo de observação.\\n•  As principais tarefas de inferência em modelos temporais são \\nfiltragem\\n, \\nprevisão\\n, \\nsuavização\\n e\\ncálculo da \\nexplicação mais provável\\n. Cada uma dessas tarefas pode ser realizada com o\\nemprego de algoritmos recursivos simples cujo tempo de execução é linear na duração da\\nsequência.\\n•  Três famílias de modelos temporais foram estudadas em maior profundidade: \\nmodelos ocultos\\nde Markov\\n, \\nfiltros de Kalman\\n e \\nredes bayesianas dinâmicas\\n (que incluem os outros dois\\ncomo casos especiais).\\n•  A menos que sejam feitas suposições especiais, como em filtros de Kalman, a inferência exata\\ncom muitas variáveis de estados parece ser intratável. Na prática, o algoritmo de \\nfiltragem de\\npartículas\\n parece ser um algoritmo de aproximação efetivo.\\n•  Ao tentar manter o controle de muitos objetos, surge a incerteza de quais observações pertencem\\na quais objetos — o problema de \\nassociação de dados\\n. O número de hipóteses de associação é\\ntipicamente bem intratável, mas os algoritmos CMMC e de filtragem de partículas para\\nassociação de dados funcionam bem na prática.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nMuitas das ideias básicas para avaliação do estado de sistemas dinâmicos vieram do matemático\\nC. F. Gauss (1809), que formulou um algoritmo determinístico de mínimos quadrados para o\\nproblema de estimar órbitas a partir de observações astronômicas. O matemático russo A. A. Markov\\n(1913) desenvolveu aquilo que se denominou mais tarde \\nhipótese de Markov\\n em sua análise dos\\nprocessos estocásticos; ele estimou uma cadeia de Markov de primeira ordem sobre letras do texto\\nde \\nEugene Onegin\\n. Levin \\net al.\\n (2008) abordam a teoria geral da cadeia de Markov e a mistura de\\ntempos.\\nUm trabalho secreto significativo sobre filtragem foi realizado durante a Segunda Guerra Mundial\\npor Wiener (1942) para processos de tempo contínuo e por Kolmogorov (1941) para processos de\\ntempo discreto. Embora esse trabalho tenha levado a importantes desenvolvimentos tecnológicos\\ndurante os 20 anos seguintes, seu uso de uma representação no domínio das frequências tornou muitos\\ncálculos bastante incômodos. A modelagem direta do espaço de estados do processo estocástico\\nacabou se mostrando mais simples, conforme demonstraram Peter Swerling (1959) e Rudolf Kalman\\n(1960). Este último ensaio introduziu o que se conhece agora como filtro de Kalman para inferência', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 702}),\n",
       " Document(page_content='para a frente em sistemas lineares com ruído gaussiano; os resultados de Kalman, no entanto, foram\\npreviamente obtidos pelo estatístico dinamarquês Thorvold Thiele (1880) e pelo matemático russo\\nRuslan Stratonovich (1959), que Kalman encontrou em Moscou em 1960. Após uma visita à Nasa\\nAmes Research Center, em 1960, Kalman viu a aplicabilidade do método de rastreamento de\\ntrajetórias de foguetes, e posteriormente o filtro foi implementado pelas missões Apollo. Importantes\\nresultados em suavização foram derivados por Rauch \\net al\\n. (1965), e o suavizador com o\\nimpressionante nome Rauch-Tung-Striebel ainda é uma técnica-padrão atualmente. Muitos resultados\\niniciais estão reunidos em Gelb (1974). Bar-Shalom e Fortmann (1988) apresentam tratamento mais\\nmoderno com uma abordagem de Bayes, além de muitas referências à vasta literatura sobre o assunto.\\nChatfield (1989) e Box \\net al.\\n (1994) cobrem a abordagem da teoria de controle para análise de\\nséries temporais.\\nO modelo oculto de Markov e os algoritmos associados para inferência e aprendizado, incluindo o\\nalgoritmo para a frente-para trás, foram desenvolvidos por Baum e Petrie (1966). O algoritmo de\\nViterbi apareceu primeiro em Viterbi (1967). Ideias semelhantes também apareceram\\nindependentemente na comunidade de filtragem de Kalman (Rauch \\net al\\n., 1965). O algoritmo para a\\nfrente-para trás foi um dos principais precursores da formulação geral do algoritmo EM (Dempster \\net\\nal\\n., 1977); veja também o Capítulo 20. A suavização do espaço de constantes aparece em Binder \\net\\nal\\n. (1997b), como também o algoritmo de dividir e conquistar desenvolvido no Exercício 15.3. A\\nsuavização de retardo fixo de tempo constante para MOMs apareceu pela primeira vez em Russell e\\nNorvig (2003). Foram encontradas muitas aplicações para MOMs no processamento da linguagem\\n(Charniak, 1993), reconhecimento da fala (Rabiner e Juang, 1993), tradução automática (Och e Ney,\\n2003), biologia computacional (Krogh \\net al\\n., 1994; Baldi \\net al\\n., 1994), economia financeira (Bhar e\\nHamori, 2004) e outros campos. Houve várias extensões para o modelo MOM básico, por exemplo,\\no MOM hierárquico (Fine \\net al\\n., 1998), e o MOM em camadas (Oliver \\net al\\n., 2004) introduziu a\\nestrutura de volta ao modelo, substituindo a variável de estado único dos MOMs.\\nAs redes bayesianas dinâmicas (DBNs) podem ser visualizadas como uma codificação esparsa de\\num processo de Markov e foram utilizadas primeiro em IA por Dean e Kanazawa (1989b), Nicholson\\ne Brady (1992) e Kjaerulff (1992). O último trabalho estende o sistema de rede de Hugin Bayes para\\nacomodar redes bayesianas dinâmicas. O livro de Dean e Wellman (1991) ajudou a popularizar\\nDBNs e a abordagem probabilística para o planejamento e controle dentro da IA. Murphy (2002)\\nforneceu uma análise completa de DBNs.\\nAs redes bayesianas dinâmicas se tornaram populares para modelar uma variedade de processos\\nde movimentos complexos em visão de computadores (Huang \\net al\\n., 1994; Intille e Bobick, 1999).\\nComo MOMs, encontraram aplicação em reconhecimento de fala (Zweig e Russell, 1998; Richardson\\net al\\n., 2000; Stephenson \\net al\\n., 2000; Nefian \\net al\\n., 2002; Livescu \\net al\\n., 2003), genômica (Murphy e\\nMian, 1999; Perrin \\net al\\n., 2003; Husmeier, 2003) e localização robótica (Theocharous \\net al\\n., 2004).\\nA ligação entre MOMs e DBNs, e entre algoritmo para a frente e para trás e propagação de rede\\nbayesiana, foi feita explicitamente por Smyth \\net al.\\n (1997). Uma unificação adicional com filtros de\\nKalman (e outros modelos estatísticos) aparece em Roweis e Ghahramani (1999). Existem\\nprocedimentos para aprender os parâmetros (Binder \\net al\\n., 1997a; Ghahramani, 1998) e as estruturas\\n(Friedman \\net al\\n., 1998) de DBNs.\\nO algoritmo de filtragem de partículas descrito na \\nSeção 15.5\\n tem uma história particularmente', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 703}),\n",
       " Document(page_content='interessante. Os primeiros algoritmos de amostragem para filtragem de partículas (também chamado\\nde método sequencial de Monte Carlo) foram desenvolvidos na comunidade de teoria de controle por\\nHandschin e Mayne (1969), e a ideia de reamostragem que constitui o núcleo da filtragem de\\npartículas apareceu em um periódico russo sobre controle (Zaritskii \\net al\\n., 1975). Mais tarde, ele foi\\nrecriado em estatística como reamostragem sequencial do tipo \\namostragem de importância\\n, ou \\nSIR\\n(Rubin, 1988; Liu e Chen, 1998), em teoria de controle como filtragem de partículas (Gordon \\net al\\n.,\\n1993; Gordon, 1994), em IA como \\nsobrevivência do mais adaptado\\n (Kanazawa \\net al\\n., 1995) e em\\nvisão de computadores como \\ncondensação\\n (Isard e Blake, 1996). O artigo de Kanazawa \\net al\\n.\\n(1995) inclui um aperfeiçoamento denominado \\nreversão da evidência\\n, pelo qual o estado no tempo \\nt\\n+ 1 tem uma amostragem condicional sobre o estado no tempo \\nt e sobre a evidência no tempo t\\n + 1.\\nIsso permite que a evidência influencie diretamente a geração de amostras, e foi demonstrado por\\nDoucet (1997) e Liu e Chen (1998) para reduzir o erro de aproximação. A filtragem de partícula foi\\naplicada em muitas áreas, incluindo o rastreamento de padrões de movimento complexos em vídeo\\n(Isard e Blake, 1996), a previsão do mercado de ações (Freitas \\net al\\n., 2000), e diagnóstico de falhas\\nem veículos planetários (Verma \\net al\\n., 2004). Uma variante chamada de \\nfiltro de partículas Rao-\\nBlackwellized\\n ou filtro de partículas FPRB (Doucet \\net al\\n., 2000;. Murphy e Russell, 2001) aplica\\nfiltragem de partícula em um subconjunto de variáveis de estado e, para cada partícula, realiza\\ninferência exata sobre as demais variáveis condicionadas à sequência de valor na partícula. Em\\nalguns casos, o FPRB funciona bem com milhares de variáveis de estado. No Capítulo 25 será\\ndescrita uma aplicação de FPRB para localização e mapeamento em robótica. O livro de Doucet \\net\\nal\\n. (2001) junta muitos artigos importantes sobre o algoritmo \\nsequencial de Monte Carlo\\n (SMC), do\\nqual a filtragem de partículas é o exemplo mais importante. Pierre Del Moral e seus colegas\\nrealizaram extensas análises teóricas dos algoritmos de SMC (Del Moral, 2004; Del Moral \\net al\\n.,\\n2006).\\nOs métodos CMMC (veja a \\nSeção 14.5.2\\n) podem ser aplicados para problemas de filtragem, por\\nexemplo, a amostragem de Gibbs pode ser aplicada diretamente a uma DBN desenrolada. Para evitar\\no problema de aumento nos tempos de atualização à medida que a rede cresce, a filtragem \\nCMMC\\ndecomposta\\n (Marthi \\net al\\n., 2002) prefere amostrar variáveis de estado mais recentes, com\\nprobabilidade de que se decomponha de 1/\\nk\\n2\\n para a variável \\nk\\n períodos para o passado. O CMMC\\ndecomposto é um filtro provavelmente não divergente. Os teoremas não divergentes podem também\\nser obtidos de certos tipos de \\nfiltragem de densidade assumida\\n.\\nUm filtro de densidade assumida pressupõe que a distribuição \\na posteriori\\n sobre os estados no\\ntempo \\nt\\n pertence a determinada família finitamente parametrizada; se as etapas de projeção e\\natualização a levarem para fora dessa família, a distribuição será projetada para trás para dar a\\nmelhor aproximação dentro da família. Para DBNs, o algoritmo de Boyen-Koller (Boyen \\net al\\n.,\\n1999) e o algoritmo de \\nfronteira fatorada\\n (Murphy e Weiss, 2001) assumem que a distribuição\\nposterior pode ser bem aproximada por um produto de fatores pequenos. Técnicas variacionais (veja\\no Capítulo 14) também foram desenvolvidas para modelos temporais. Ghahramani e Jordan (1997)\\ndescrevem um algoritmo de aproximação para o \\nMOM fatorial\\n, uma DBN na qual duas ou mais\\ncadeias de Markov que evoluem de modo independente são vinculadas por um fluxo de observação\\ncompartilhada. Jordan \\net al\\n. (1998) focalizam várias outras aplicações.\\nA associação de dados para rastrear alvos múltiplos foi descrita pela primeira vez em um cenário', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 704}),\n",
       " Document(page_content='probabilístico por Sittler (1964). O primeiro algoritmo prático para problemas de larga escala era o\\n“rastreador de múltiplas hipóteses” ou RMH (Reid, 1979). Bar-Shalom e Fortmann (1988) e Bar-\\nShalom (1992) juntaram muitos artigos importantes. Deve-se a Pasula \\net al\\n. (1999) o\\ndesenvolvimento de um algoritmo CMMC para associação de dados, que aplicou para os problemas\\nde fiscalização de tráfego. Oh \\net al\\n. (2009) fornecem uma análise formal e comparações\\nexperimentais extensas a outros métodos. Schulz \\net al\\n. (2003) descrevem um método de associação\\nde dados com base em filtragem de partícula. Ingemar Cox analisou a complexidade de associação\\nde dados (Cox, 1993; Cox e Hingorani, 1994) e trouxe o assunto à atenção da visão comunitária.\\nObservou também a aplicabilidade do algoritmo húngaro de tempo polinomial para o problema de\\nencontrar atribuições mais prováveis, que havia sido considerado por muito tempo um problema\\nintratável na comunidade de rastreamento. O algoritmo em si foi publicado por Kuhn (1955), com\\nbase em traduções de artigos publicados em 1931 por dois matemáticos húngaros, Dénes König e\\nJenö Egerváry. No entanto, o teorema fundamental havia sido derivado anteriormente de um\\nmanuscrito inédito em latim pelo famoso matemático prussiano Carl Gustav Jacobi (1804-1851).\\nEXERCÍCIOS\\n15.1\\n Mostre que qualquer processo de Markov de segunda ordem pode ser reescrito como um\\nprocesso de Markov de primeira ordem com um conjunto ampliado de variáveis de estados. Isso\\nsempre pode ser feito de maneira \\nparcimoniosa\\n, isto é, sem aumentar o número de parâmetros\\nnecessários para especificar o modelo de transição?\\n15.2\\n Neste exercício, examinamos o que acontece com probabilidades no mundo do guarda-chuva, no\\nlimite de longas sequências de tempo.\\na.\\n Suponha que observamos uma sequência interminável de dias em que o guarda-chuva aparece.\\nMostre que, à medida que passam os dias, a probabilidade de chuva no dia atual aumenta\\nmonotonicamente, tendendo a um ponto fixo. Calcule esse ponto fixo.\\nb.\\n Agora, considere uma \\nprevisão\\n cada vez mais longe no futuro, dadas apenas as duas primeiras\\nobservações de guarda-chuva. Primeiro, calcule a probabilidade \\nP\\n(\\nr\\n2 + k\\n | \\nu\\n1\\n, \\nu\\n2\\n) para \\nk\\n = 1 …\\n20 e represente os resultados em um gráfico. Você deverá verificar que a probabilidade\\nconverge em direção a um ponto fixo. Demonstre que o valor exato desse ponto fixo é 0,05.\\n15.3\\n Este exercício desenvolve uma variante com eficiência de espaço do algoritmo para a frente-\\npara trás descrito na \\nFigura 15.4\\n. Desejamos calcular \\nP\\n(\\nX\\nk\\n | \\ne\\n1:\\nt\\n) para \\nk\\n = 1, …, \\nt\\n. Isso será feito com\\numa abordagem de dividir e conquistar.\\na.\\n Suponha, por simplicidade, que \\nt\\n seja ímpar, e seja \\nh\\n = (\\nt\\n + 1)/2 o ponto médio. Mostre que\\nP\\n(\\nX\\nk\\n | \\ne\\n1:\\nt\\n) pode ser calculada para \\nk\\n = 1, …, \\nh\\n, dada apenas a mensagem para a frente inicial\\nf\\n1:0\\n, a mensagem para trás \\nb\\nh\\n+1:\\nt\\n e a evidência \\ne\\n1:\\nh\\n.\\nb.\\n Mostre um resultado semelhante para a segunda metade da sequência.\\nc.\\n Dados os resultados de (a) e (b), é possível construir um algoritmo de dividir e conquistar,\\nexecutando-se o algoritmo primeiro no sentido para a frente ao longo da sequência e depois no', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 705}),\n",
       " Document(page_content='sentido para trás a partir do fim, armazenando apenas as mensagens exigidas no ponto médio e\\nnas extremidades. Em seguida, o algoritmo é chamado em cada metade. Escreva o algoritmo em\\ndetalhes.\\nd.\\n Calcule a complexidade de tempo e espaço do algoritmo como uma função de \\nt\\n, a duração da\\nsequência. Como isso se altera se dividirmos a entrada em mais de dois fragmentos?\\n15.4\\n Neste capítulo, delineamos um procedimento com falhas para descobrir a sequência de estados\\nmais provável, dada uma sequência de observações. O procedimento envolve a descoberta do estado\\nmais provável em cada período de tempo, o uso da suavização e o retorno da sequência composta\\npor esses estados. Mostre que, para alguns modelos de probabilidade temporal e sequências de\\nobservações, esse procedimento retorna uma sequência de estados impossível (isto é, a\\nprobabilidade posterior da sequência é zero).\\n15.5\\n A Equação 15.12 descreve o processo de filtragem para a formulação da matriz do MOMs.\\nForneça uma equação semelhante para o cálculo de probabilidades, que foi descrita genericamente\\nna Equação 15.7.\\n15.6\\n Considere o mundo do aspirador de pó da \\nFigura 4.18\\n (sensoriamento perfeito) e a \\nFigura 15.7\\n(sensoriamento ruidoso). Suponha que o robô receba uma sequência de observações, tais que, com o\\nsensoriamento perfeito, há apenas uma localização perfeita em que ele poderia estar. Será essa a\\nlocalização necessariamente mais provável para a probabilidade \\n∊\\n de ruído suficientemente pequeno\\nsob sensoriamento ruidoso? Prove sua argumentação ou forneça um contra exemplo.\\n \\n15.7\\n Na \\nSeção 15.3.2\\n, a distribuição prévia sobre as localizações é uniforme e o modelo de\\ntransição assume a mesma probabilidade de movimento para qualquer quadrado vizinho. E se esses\\npressupostos estiverem errados? Suponha que a localização inicial seja realmente escolhida de\\nforma uniforme a partir do quadrante noroeste da sala e a ação \\nMover\\n realmente tenda a mover para\\no sudeste. Mantendo o modelo MOM fixo, explore o efeito sobre a precisão da localização e do\\ncaminho à medida que aumenta a tendência para o sudeste, para diferentes valores de \\n∊\\n.\\n15.8\\n Considere uma versão do robô do aspirador de pó cujo programa de ação é ir em linha reta pelo\\ntempo que puder; só quando encontra um obstáculo ele muda para uma nova direção (selecionada\\naleatoriamente). Para modelar esse robô, cada estado no modelo consiste em um par (\\nlocalização\\n,\\ndireção\\n). Implemente esse modelo e veja quão bem o algoritmo de Viterbi pode acompanhar um robô\\ncom esse modelo. Por ser o programa de ação do robô mais restrito do que o do robô de passeio\\naleatório, significa que as previsões do caminho mais provável são mais precisas?\\n15.9\\n Este exercício trata da filtragem em um ambiente sem pontos de referência. Considere um robô\\nde aspirador de pó em uma sala vazia, representado por uma grade retangular \\nn\\n × m. A localização\\ndo robô está oculta; a única evidência disponível para o observador é um sensor de localização\\nruidoso que dá uma aproximação da localização do robô. Se o robô estiver na posição (\\nx\\n, \\ny\\n), com\\nprobabilidade 0,1 o sensor indica a localização correta, com probabilidade 0,05 ele relata um dos\\noito locais circundantes (\\nx\\n, \\ny\\n), com probabilidade 0,025 ele relata uma das 16 localidades que\\nrodeiam os oito, e com a probabilidade remanescente de 0,1 ele relata “sem leitura”. O programa de\\nação do robô é escolher uma direção e segui-la com probabilidade 0,8 em cada etapa; o robô muda\\npara uma nova direção selecionada aleatoriamente com probabilidade 0,2 (ou com probabilidade 1', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 706}),\n",
       " Document(page_content='caso encontre uma parede). Implemente isso como um MOM e faça a filtragem para acompanhar o\\nrobô. Com que precisão podemos rastrear o caminho do robô?\\n15.10\\n Com frequência, desejamos monitorar um sistema de estados contínuos cujo comportamento se\\nalterna de maneira imprevisível entre um conjunto de \\nk “\\nmodos” distintos. Por exemplo, uma\\naeronave que tenta escapar de um míssil pode executar uma série de manobras distintas que o míssil\\ntalvez tente acompanhar. Uma representação de rede bayesiana de tal modelo de \\nfiltro de Kalman de\\ncomutação\\n é mostrada na \\nFigura 15.21\\n.\\nFigura 15.21\\n Representação de rede bayesiana de um filtro de Kalman de comutação. A variável de\\ncomutação \\nS\\nt\\n é uma variável de estado discreto cujo valor determina o modelo de transição para as\\nvariáveis de estados contínuos \\nX\\nt\\n. Para qualquer estado discreto \\ni\\n, o modelo de transição \\nP\\n(\\nX\\nt\\n+1\\n | \\nX\\nt\\n,\\nS\\nt\\n = \\ni\\n) é um modelo gaussiano linear, da mesma maneira que ocorre em um filtro de Kalman normal.\\nO modelo de transição para o estado discreto, \\nP\\n(\\nS\\nt\\n+1\\n | \\nS\\nt\\n), pode ser considerado uma matriz, como\\nocorre em um modelo oculto de Markov.\\na.\\n Suponha que o estado discreto \\nSt\\n tenha \\nk\\n valores possíveis e que a estimativa de estado anterior\\ncontínuo \\nP\\n(\\nX\\n0\\n) seja uma distribuição gaussiana multivariada. Mostre que a previsão \\nP\\n(\\nX\\n1\\n) é\\numa \\nmistura de gaussianos\\n, isto é, uma soma ponderada de gaussianos, tal que a soma dos\\npesos seja igual a 1.\\nb.\\n Mostre que, se a estimativa atual de estados contínuos \\nP\\n(\\nX\\nt\\n | \\ne\\n1:\\nt\\n) é uma mistura de \\nm\\ngaussianos, então no caso geral a estimativa atualizada de estado \\nP\\n(\\nX\\nt\\n+1\\n | \\ne\\n1:\\nt\\n+1\\n) será uma\\nmistura de \\nkm\\n gaussianos.\\nc.\\n Que aspecto do processo temporal os pesos na mistura gaussiana representam?\\nJuntos, os resultados de (a) e (b) mostram que a representação da distribuição posterior cresce sem\\nlimite, até mesmo para filtros de Kalman de comutação, que são os modelos dinâmicos híbridos mais\\nsimples.\\n15.11\\n Complete a etapa omitida na derivação da Equação 15.19, a primeira etapa de atualização para\\no filtro de Kalman unidimensional.\\n15.12\\n Vamos examinar o comportamento da atualização de variância na Equação 15.20.\\na.\\n Represente o valor de \\n como uma função de \\nt\\n, dados diversos valores para \\n e \\n.\\nb.\\n Mostre que a atualização tem um ponto fixo \\nσ\\n2\\n tal que \\n → \\nσ\\n2\\n à medida que \\nt\\n → ∞, e calcule o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 707}),\n",
       " Document(page_content='valor de σ\\n2\\n.\\nc.\\n Forneça uma explicação qualitativa para o que acontece à medida que \\n → 0 e \\n → 0.\\n15.13\\n Um professor quer saber se os estudantes estão dormindo o suficiente. Cada dia, o professor\\nobserva se os alunos dormem em sala de aula e se têm os olhos vermelhos. O professor tem a\\nseguinte teoria de domínio:\\n•  A probabilidade mais forte de dormir o suficiente, sem observações, é de 0,7.\\n•  A probabilidade de dormir o suficiente na noite \\nt\\n é de 0,8, dado que o aluno dormiu o suficiente\\nna noite anterior, e 0,3 se não dormiu.\\n•  A probabilidade de ter os olhos vermelhos é de 0,2 se o aluno dormiu o suficiente e 0,7 se não\\ndormiu.\\n•  A probabilidade de dormir em sala de aula é de 0,1 se o aluno dormiu o suficiente e 0,3 se não\\ndormiu.\\nFormule essa informação como uma rede bayesiana dinâmica que o professor poderia utilizar para\\nfiltrar ou prever a partir de uma sequência de observações. Em seguida, reformule-a como um\\nmodelo oculto de Markov que tem apenas uma variável única de observação. Forneça as tabelas de\\nprobabilidade completas para o modelo.\\n15.14\\n Para a DBN especificada no Exercício 15.13 e para os valores de evidência\\ne\\n1\\n = sem olhos vermelhos, não dormir em sala de aula\\ne\\n2\\n = olhos vermelhos, não dormir em sala de aula\\ne\\n3\\n = olhos vermelhos, dormir em sala de aula\\nrealizar os seguintes cálculos:\\na.\\n Estimativa de estado: calcule \\nP\\n(\\nSonoSuficiente\\nt\\n | e\\n1: t\\n) para cada um dos \\nt\\n = 1, 2, 3.\\nb.\\n Suavização: calcule \\nP\\n(\\nSonoSuficiente\\nt\\n | e\\n1: 3\\n) para cada um dos \\nt\\n = 1, 2, 3.\\nc.\\n Compare as probabilidades suavizadas e filtradas para \\nt\\n = 1 e \\nt\\n = 2.\\n15.15\\n Suponha que um aluno em particular apareça com os olhos vermelhos e durma na sala de aula\\ntodos os dias. Dado o modelo descrito no Exercício 15.13, explique por que a probabilidade que o\\naluno tenha dormido o suficiente na noite anterior converge para um ponto fixo em vez de continuar a\\ndescer enquanto reunimos mais dias de evidência. Qual é o ponto fixo? Responda tanto\\nnumericamente (por cálculo) como analiticamente.\\n15.16\\n Este exercício analisa em mais detalhes o modelo de falha persistente correspondente ao\\nsensor de bateria da \\nFigura 15.15\\n(a).\\na.\\n A \\nFigura 15.15\\n(b) para em \\nt\\n = 32. Descreva qualitativamente o que deve acontecer à medida\\nque \\nt\\n → ∞ caso a leitura do sensor continue a ser 0.\\nb.\\n Suponha que a temperatura externa afete o sensor da bateria de tal modo que as falhas\\ntransientes se tornem mais prováveis à medida que a temperatura aumenta. Mostre como ampliar\\na estrutura de DBN da \\nFigura 15.15\\n(a) e explique quais são as mudanças necessárias nas TPCs.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 708}),\n",
       " Document(page_content='c.\\n Dada a nova estrutura de rede, as leituras do nível de carga da bateria podem ser utilizadas pelo\\nrobô para deduzir a temperatura atual?\\n15.17\\n Considere a aplicação do algoritmo de eliminação de variáveis à DBN de guarda-chuva\\ndesenvolvida para três fatias, onde a consulta é \\nP\\n(\\nR\\n3\\n | \\nu\\n1\\n,\\nu\\n2\\n,\\nu\\n3\\n). Mostre que a complexidade de\\nespaço do algoritmo — o tamanho do maior fator — é a mesma, independentemente do fato de as\\nvariáveis de chuva serem eliminadas em ordem para a frente ou para trás.\\n1\\n A incerteza sobre o tempo contínuo pode ser modelada por \\nequações diferenciais estocásticas\\n (EDSs). Os modelos estudados\\nneste capítulo podem ser vistos como aproximações em tempo discreto para EDSs.\\n2\\n O termo “filtragem” refere-se às raízes do problema no trabalho inicial de processamento de sinal, onde o problema era filtrar o ruído\\nem um sinal estimando suas propriedades subjacentes.\\n3\\n Em particular, ao acompanhar um objeto em movimento com observações de posição imprecisa, a suavização fornece uma trajetória\\nestimada mais suave que a filtragem — daí o nome.\\n4\\n O leitor pouco familiarizado com operações básicas sobre vetores e matrizes talvez deseje consultar o Apêndice A antes de prosseguir\\ncom o estudo desta seção.\\n5\\n A rigor, uma distribuição gaussiana é problemática porque atribui probabilidade diferente de zero a níveis muito negativos de carga. Às\\nvezes, a \\ndistribuição beta\\n é uma escolha melhor para uma variável cujo intervalo é restrito.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 709}),\n",
       " Document(page_content='N\\nCAPÍTULO\\n \\n16\\nTomada de decisões simples\\nEm que vemos como um agente deve tomar decisões de forma a obter o que\\ndeseja – pelo menos em média.\\neste capítulo, complementaremos os detalhes de como a teoria da utilidade combina com a teoria\\nda probabilidade para formar um agente de teoria da decisão — um agente que pode tomar\\ndecisões racionais baseadas em suas crenças e no que ele deseja. Tal agente pode tomar decisões\\nem contextos nos quais a incerteza e objetivos conflitantes deixam um agente lógico sem meios para\\nse decidir. Na realidade, um agente baseado em objetivos faz distinção binária entre estados bons\\n(objetivos) e estados ruins (não objetivos), enquanto um agente de teoria da decisão tem uma medida\\ncontínua da qualidade dos estados.\\nA \\nSeção 16.1\\n introduz o princípio básico da teoria da decisão: a maximização da utilidade\\nesperada. A \\nSeção 16.2\\n mostra que o comportamento de qualquer agente racional pode ser captado\\nsupondo-se uma função utilidade que está sendo maximizada. A \\nSeção 16.3\\n discute a natureza das\\nfunções utilidade com mais detalhes e, em particular, sua relação com quantidades individuais como\\no dinheiro. A \\nSeção 16.4\\n mostra como tratar funções utilidade que dependem de diversas\\nquantidades. Na \\nSeção 16.5\\n, descrevemos a implementação de sistemas de tomada de decisões. Em\\nparticular, introduzimos um formalismo chamado \\nredes de decisão\\n (também conhecido como\\ndiagramas de influência\\n) que estende as redes bayesianas incorporando ações e utilidades. O\\nrestante do capítulo discute questões que surgem em aplicações da teoria da decisão a sistemas\\nespecialistas.\\n16.1 COMBINAÇÃO DE CRENÇAS E DESEJOS SOB INCERTEZA\\nA teoria da decisão, na sua forma mais simples, trata de escolher entre as ações com base na\\nconveniência dos seus resultados \\nimediatos\\n, isto é, assume-se que o ambiente é episódico no sentido\\njá definido (essa suposição será descrita no Capítulo 17). No Capítulo 3 utilizamos a notação\\nRESULTADO(\\ns\\n0\\n, \\na\\n) para o estado que é o resultado determinístico de tomar a ação \\na\\n no estado \\ns\\n0\\n.\\nNeste capítulo, trataremos de ambientes não determinísticos parcialmente observáveis. Como o\\nagente pode não saber o estado atual, nós o omitimos e definimos RESULTADO(\\na\\n) como uma\\nvariável\\n aleatória cujos valores são os estados resultantes possíveis. A probabilidade do resultado', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 711}),\n",
       " Document(page_content='s\\n′, dadas as observações de evidências \\ne\\n, é escrita como\\nP\\n(RESULTADO (\\na\\n) = \\ns\\n′ | \\na\\n, \\ne\\n),\\nonde o \\na\\n no lado direito da barra significa o evento em que a ação \\na\\n é executada.\\n1\\nAs preferências dos agentes são apreendidas por uma \\nfunção utilidade\\n, \\nU\\n(\\ns\\n), que atribui um único\\nnúmero utilidade para expressar a conveniência de um estado. A \\nutilidade esperada\\n de uma ação,\\ndada a evidência, \\nUE\\n(\\na\\n | \\ne\\n), é apenas o valor da utilidade média ponderada dos resultados, pela\\nprobabilidade que o resultado ocorra:\\nO princípio da \\nutilidade máxima esperada\\n (UME) diz que um agente racional deve escolher a\\nação que maximize a utilidade esperada do agente:\\nDe certo modo, o princípio de UME poderia ser visto como a definição de tudo em IA. Tudo o que\\num agente inteligente tem de fazer é calcular as diversas quantidades, maximizar a utilidade sobre\\nsuas ações e ir em frente. Porém, isso não significa que o problema da IA seja \\nresolvido\\n pela\\ndefinição!\\nO princípio UME \\nformaliza\\n a noção geral de que o agente deve “fazer a coisa certa”, mas\\npercorre apenas uma pequena distância em direção a uma \\noperacionalização\\n desse conselho.\\nEstimar o estado do mundo exige percepção, aprendizagem, representação do conhecimento e\\ninferência. O cálculo \\nP\\n(RESULTADO (\\na\\n) | \\na\\n, \\ne\\n) requer um modelo causal completo do mundo e,\\ncomo vimos no Capítulo 14, inferência NP-difícil em redes bayesianas (muito grandes). Calcular os\\nresultados das utilidades \\nU\\n(\\ns\\n′) frequentemente requer pesquisa ou planejamento porque um agente\\npode não saber o quanto um estado é bom até que saiba onde pode chegar a partir desse estado.\\nAssim, a teoria da decisão não é uma panaceia que resolve o problema de IA, mas fornece uma\\nestrutura útil.\\n O princípio de UME tem relação clara com a ideia de medidas de desempenho introduzida no\\nCapítulo 2. A ideia básica é muito simples. Considere os ambientes que poderiam levar um agente a\\nter um dado histórico de percepções e considere os diferentes agentes que poderíamos projetar. \\nSe\\num agente age para maximizar uma função utilidade que reflete corretamente a medida de\\ndesempenho pela qual seu comportamento está sendo julgado\\n, \\nele alcançará a mais alta\\npontuação de desempenho possível (a média sobre todos os outros ambientes possíveis)\\n. Essa é a\\njustificação central para o próprio princípio de UME. Embora a afirmação possa parecer tautológica,\\nde fato ela incorpora uma transição muito importante a partir de um critério global externo de\\nracionalidade — a medida de desempenho sobre históricos de ambientes até um critério local interno\\nque envolve a maximização de uma função utilidade aplicada ao próximo estado.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 712}),\n",
       " Document(page_content='16.2 A BASE DA TEORIA DA UTILIDADE\\nIntuitivamente, o princípio de utilidade máxima esperada (UME) parece um modo razoável de\\ntomar decisões, mas não é de forma alguma evidente que ele seja o \\núnico\\n modo racional. Afinal, por\\nque maximizar a utilidade \\nmédia\\n é tão especial? O que há de errado com um agente que maximiza a\\nsoma ponderada dos cubos das utilidades possíveis ou tenta minimizar a pior perda possível? Além\\ndisso, um agente não poderia agir racionalmente apenas expressando preferências entre estados, sem\\nlhes atribuir valores numéricos? Finalmente, por que deve existir uma função utilidade com as\\npropriedades exigidas? Veremos.\\n16.2.1 Restrições sobre preferências racionais\\nEssas perguntas podem ser respondidas registrando-se algumas restrições sobre as preferências\\nque um agente racional deve ter e depois mostrando-se que o princípio de UME pode ser derivado\\ndas restrições. Utilizamos a notação a seguir para descrever as preferências de um agente:\\nAgora a pergunta óbvia é: que tipos de itens são A e B? Eles poderiam ser os estados do mundo,\\nmas mais frequentemente do que nunca há incerteza sobre o que realmente está sendo oferecido. Por\\nexemplo, o passageiro de uma companhia aérea a quem é oferecido um “prato de macarrão ou de\\nfrango” não sabe o que está sob o papel de alumínio.\\n2\\n A massa pode estar congelada ou deliciosa, o\\nfrango suculento ou cozido além do recomendável. Podemos pensar sobre o conjunto de resultados\\npara cada ação como uma \\nloteria\\n — pense em cada ação como um bilhete. A notação da loteria \\nL\\ncom os possíveis resultados \\nS\\n1\\n,…, \\nS\\nn\\n que ocorrem com probabilidades \\np\\n1\\n,…, \\np\\nn\\n é\\nL\\n = [\\np\\n1\\n, \\nS\\n1\\n; \\np\\n2\\n, \\nS\\n2\\n;… \\np\\nn\\n, \\nS\\nn\\n].\\nEm geral, cada resultado S\\ni\\n de uma loteria pode ser tanto um estado atômico como outra loteria. O\\nprincipal problema da teoria da utilidade é entender como preferências entre loterias complexas\\nestão relacionados com as preferências entre os estados subjacentes nessas loterias. Para resolver\\nesse problema, listamos seis restrições que exigem qualquer preferência razoável a ser obedecida:\\n•  \\nOrdenabilidade:\\n Dadas duas loterias quaisquer, um agente racional deve preferir uma à outra\\nou, então, classificar as duas como igualmente preferíveis.Ou seja, o agente não pode evitar a\\ndecisão. Como vimos anteriormente, recusar-se a apostar é como recusar-se a deixar o tempo\\npassar.\\n•  \\nTransitividade:\\n DadAs três loterias quaisquer, se um agente preferir \\nA\\n a \\nB\\n e preferir \\nB\\n a \\nC\\n,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 713}),\n",
       " Document(page_content='então o agente deverá preferir \\nA\\n a \\nC\\n.\\n•  \\nContinuidade:\\n Se alguma loteria \\nB\\n estiver entre \\nA\\n e \\nC\\n em preferência, haverá alguma\\nprobabilidade \\np\\n de que o agente racional fique indiferente entre escolher \\nB\\n por garantia ou\\nescolher a loteria que produz \\nA\\n com probabilidade \\np\\n e \\nC\\n com probabilidade 1 – \\np\\n.\\n•  \\nSubstitutibilidade:\\n Se um agente está indiferente entre duas loterias \\nA\\n e \\nB\\n, então o agente está\\nindiferente entre duas outras loterias complexas que são a mesma loteria, exceto pelo fato de \\nA\\nser substituído por \\nB\\n em uma delas. Isso é válido independentemente das probabilidades e do(s)\\noutro(s) resultado(s) das loterias.\\nIsto também é válido se substituirmos \\n por \\n∼\\n nesse axioma.\\n•  \\nMonotonicidade:\\n Suponha que existam duas loterias que tenham os mesmos dois resultados, \\nA\\n e\\nB\\n. Se um agente prefere \\nA\\n a \\nB\\n, então o agente deve preferir a loteria que tem uma probabilidade\\nmais alta para \\nA\\n (e vice-versa).\\n•  \\nDecomponibilidade:\\n As loterias compostas podem ser reduzidas a loterias mais simples com o\\nuso das leis da probabilidade. Isso se chama regra de “nada de diversão no jogo” porque afirma\\nque duas loterias consecutivas podem ser compactadas em uma única loteria equivalente, como\\nmostra a \\nFigura 16.1\\n(b).\\n3\\nFigura 16.1\\n (a) Um ciclo de trocas mostrando que as preferências não transitivas A \\n B \\n C \\n A\\nresultam em comportamento irracional. (b) O axioma de decomponibilidade.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 714}),\n",
       " Document(page_content='Essas restrições são conhecidas como axiomas da teoria da utilidade. Cada axioma pode ser\\nmotivado mostrando que um agente que o viola vai exibir comportamento claramente irracional em\\nalgumas situações. Por exemplo, podemos motivar a transitividade fazendo com que um agente com\\npreferências não transitivas nos dê todo o seu dinheiro. Suponha que o agente tenha as preferências\\nintransitivas \\nA\\n \\n \\nB\\n \\n \\nC\\n \\n \\nA\\n em que \\nA\\n, \\nB\\n e \\nC\\n são bens que podem ser trocados livremente. Se o agente\\ntem A atualmente, poderemos oferecer a troca de \\nC\\n por \\nA\\n mais um centavo. O agente prefere \\nC\\n e,\\nassim, estará disposto a fazer essa troca. Poderemos, então, oferecer a troca de \\nB\\n por \\nC\\n, tirando mais\\num centavo, e, finalmente, a troca de \\nA\\n por \\nB\\n. Isso nos leva de volta para onde começamos, com\\nexceção que o agente nos deu três centavos (\\nFigura 16.1\\n(a)). Podemos continuar no ciclo todo até que\\no agente não tenha mais dinheiro. É claro que nesse caso o agente agiu irracionalmente.\\n16.2.2 Preferências levam à utilidade\\nObserve que os axiomas da teoria da utilidade são realmente axiomas sobre as preferências —\\neles não dizem nada sobre a função utilidade. Mas o fato é que dos axiomas de utilidade podemos\\nderivar as seguintes consequências (para demonstração, consulte Von Neumann e Morgestern, 1944):\\n•  \\nExistência da função utilidade:\\n Se as preferências de um agente obedecem aos axiomas de\\nutilidade, existe uma função de valores reais \\nU\\n que opera sobre estados tais que \\nU\\n(\\nA\\n) > \\nU\\n(\\nB\\n) se\\ne somente se \\nA\\n é preferível em relação a \\nB\\n, e \\nU\\n(\\nA\\n) = \\nU\\n(\\nB\\n) se e somente se o agente está\\nindiferente entre \\nA\\n e \\nB\\n.\\n•  \\nUtilidade esperada de uma loteria:\\n A utilidade de uma loteria é o somatório da probabilidade\\nde cada resultado vezes a utilidade desse resultado.\\nEm outras palavras, uma vez que as probabilidades e as utilidades dos estados resultantes\\npossíveis são especificadas, a utilidade de uma loteria composta envolvendo esses estados fica\\ncompletamente determinada.\\nComo o resultado de uma ação não determinística é uma loteria, segue que um agente pode agir\\nracionalmente — isto é, de forma consistente com suas preferências — somente pela escolha de uma\\nação que maximize a utilidade esperada de acordo com a Equação 16.1.\\nOs teoremas anteriores estabelecem que \\nexiste\\n uma função utilidade para qualquer agente racional,\\nmas eles não demonstram que ela é \\núnica.\\n É fácil de ver, de fato, que o comportamento de um agente\\nnão mudaria se a sua função utilidade \\nU\\n(\\nS\\n) fosse transformada de acordo com\\nonde \\na\\n e \\nb\\n são constantes e \\na\\n > 0; uma transformação afim.\\n4\\n Esse fato foi observado no Capítulo 5', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 715}),\n",
       " Document(page_content='para dois jogadores de jogos de azar; aqui, percebemos que é completamente genérico.\\nComo em um jogo, em um ambiente determinístico um agente só precisa de uma categorização de\\npreferência dos estados — os números não importam. Isso é chamado de \\nfunção de valor\\n ou \\nfunção\\nutilidade ordinal\\n.\\nÉ importante lembrar que a existência de uma função utilidade que descreve o comportamento de\\npreferências de um agente não significa necessariamente que o agente esteja maximizando\\nexplicitamente\\n essa função utilidade em suas próprias deliberações. Como mostramos no Capítulo 2,\\no comportamento racional pode ser gerado em qualquer número de aspectos. Porém, observando as\\npreferências de um agente racional, um observador pode construir a função utilidade que representa o\\nque o agente está de fato tentando realizar (mesmo se ele não souber disso).\\n16.3 FUNçõES UTILIDADE\\nA utilidade é uma função que faz o mapeamento de estados em números reais. Sabemos que\\nexistem alguns axiomas de utilidades aos quais todos os agentes racionais devem obedecer. Isso é\\ntudo o que podemos dizer sobre as funções utilidade? No sentido exato, sim. Além das restrições\\nlistadas antes, um agente pode ter as preferências que desejar. Por exemplo, um agente pode preferir\\nter um número primo de reais em sua conta bancária; nesse caso, se tivesse $16, ele abriria mão de\\n$3. Pode não ser usual, mas não podemos chamar de irracional. Um agente talvez preferisse um\\nsurrado Corcel 1973 a um brilhante Mercedes novo. As preferências também podem interagir: por\\nexemplo, é possível que ele só prefira números primos de reais quando for proprietário do Corcel,\\nmas quando tiver o Mercedes talvez prefira ter mais reais. Felizmente, as preferências de agentes\\nreais em geral são mais sistemáticas e, por isso, mais fáceis de lidar.\\n16.3.1 Avalição de utilidade e escalas de utilidade\\nSe queremos construir um sistema de decisão teórica que ajude o agente a tomar decisões ou agir\\nem seu nome, é preciso primeiro descobrir o que é a função utilidade do agente. Esse processo,\\nmuitas vezes chamado de \\nelicitação de preferência\\n, envolve a apresentação de escolhas para o\\nagente e usa as preferências observadas para responder com precisão à função utilidade subjacente.\\nA Equação 16.2 informa que não existe escala absoluta de utilidades, mas é útil, no entanto,\\nestabelecer uma \\nescala\\n em que as utilidades podem ser registradas e comparadas com qualquer\\nproblema particular. A escala pode ser estabelecida pela fixação das utilidades de quaisquer dois\\nresultados particulares, da mesma forma que determinamos uma escala de temperatura, fixando o\\nponto de congelamento e o ponto de ebulição da água. Normalmente, fixamos a utilidade de um\\n“melhor prêmio possível” em \\n e da “pior catástrofe possível” em \\n. \\nUtilidades\\nnormalizadas\\n usam uma escala com \\n.\\nDada uma escala de utilidade entre \\n, podemos avaliar a utilidade de qualquer prêmio\\nparticular \\nS\\n pedindo para o agente escolher entre \\nS\\n e uma \\nloteria-padrão\\n \\n. A\\nprobabilidade \\np\\n é ajustada até que o agente esteja indiferente entre \\nS\\n e a loteria-padrão. Assumindo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 716}),\n",
       " Document(page_content='utilidades normalizadas, a utilidade \\nS\\n é dada por \\np\\n. Uma vez feito isso, as loterias de todas as\\nutilidades que envolvem aqueles prêmios são determinadas.\\n Em problemas de decisão das áreas médica, de transporte e ambiental, entre outros, a vida da\\npessoas está em jogo. Em tais casos, \\n é o valor atribuído à morte imediata (ou talvez a muitas\\nmortes). \\nEmbora ninguém se sinta confortável em definir um valor para a vida humana\\n, \\no fato é\\nque são estabelecidos compromissos o tempo todo\\n. As aeronaves recebem uma revisão completa a\\nintervalos determinados pelos percursos e por milhas voadas, e não depois de cada viagem. Os\\ncarros são fabricados de uma forma que compense os custos das taxas de sobrevivência em um\\nacidente. Paradoxalmente, uma recusa a “impor um valor monetário à vida” significa que a vida com\\nfrequência é \\nsubestimada\\n. Ross Shachter relata experiência com uma agência governamental que\\nsubvencionou um estudo sobre a remoção do amianto nas escolas. Os analistas de decisão realizaram\\no estudo assumindo um valor em dólares em particular para a vida de uma criança em idade escolar,\\ne argumentaram que a escolha racional sob essa suposição era remover o amianto. A agência\\ngovernamental, moralmente afrontada, rejeitou o relatório. Em seguida, decidiu-se contra a remoção\\ndo amianto afirmando implicitamente um valor menor para a vida de uma criança do que o atribuído\\npelos analistas.\\nAlgumas tentativas foram feitas para descobrir o valor que as pessoas dão à sua própria vida.\\n“Moedas” comuns utilizadas em análise médica e de segurança são a \\nmicromorte\\n (uma chance de\\nmorrer em um milhão) e o \\nQALY\\n (\\nquality-adjusted life year\\n), equivalente a um ano de boa saúde\\nsem qualquer enfermidade. Se você perguntar às pessoas o quanto elas pagariam para evitar um risco\\n— por exemplo, para evitar jogar roleta-russa com um revólver com milhões de balas — elas vão\\nresponder com números muito grandes, talvez dezenas de milhares de dólares, mas o seu\\ncomportamento real reflete um valor monetário muito mais baixo de uma micromorte. Por exemplo,\\ndirigir um carro por 370 quilômetros incorre em um risco de uma micromorte; sobre a vida útil do\\nseu carro, digamos 148.000 quilômetros, isto corresponde a 400 micromortes. As pessoas parecem\\nestar dispostas a pagar a mais cerca de $10.000 (ao preço de 2009) por um seguro de carro que\\nreduz pela metade o risco de morte ou cerca de $50 por micromorte. Muitos estudos confirmaram\\numa cifra nessa faixa entre muitos indivíduos e tipos de risco. Claro, esse argumento é válido apenas\\npara riscos pequenos. A maioria das pessoas não concorda em se matar por $50 milhões.\\nOutra medida é o \\nQALY\\n, ou ano de vida ajustado pela qualidade. Pacientes com deficiência estão\\ndispostos a aceitar menor expectativa de vida se a sua saúde integral for restaurada. Por exemplo,\\npacientes renais, em média, são indiferentes entre viver dois anos em uma máquina de diálise e um\\nano em plena saúde.\\n16.3.2 A utilidade do dinheiro\\nA teoria da utilidade tem suas raízes na economia, e a economia apresenta um candidato óbvio\\npara se tornar uma medida de utilidade: o dinheiro (ou, mais especificamente, os bens líquidos totais\\nde um agente). A quase universal capacidade de troca do dinheiro por todos os tipos de mercadorias\\ne serviços sugere que o dinheiro desempenha um papel significativo nas funções humanas de\\nutilidade.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 717}),\n",
       " Document(page_content='Normalmente, o agente vai preferir mais dinheiro a menos dinheiro, sendo todos os outros itens\\niguais. Dizemos que o agente exiba uma \\npreferência monotônica\\n por mais dinheiro. No entanto, isso\\nnão significa que o dinheiro se comporta como função utilidade porque ele não diz nada sobre as\\npreferências entre \\nloterias\\n que envolvem dinheiro.\\nVamos supor que você tenha triunfado sobre os outros concorrentes em um programa de jogos pela\\ntelevisão. Agora, o apresentador lhe oferece uma opção: levar o prêmio de $1.000.000 ou apostar\\ntudo no lançamento de uma moeda (cara ou coroa). Se der cara, você acabará sem nada, mas, se der\\ncoroa, você ganhará US$2.500.000,00. Se for como a maioria das pessoas, você recusará o jogo e\\nembolsará o milhão. Nesse caso, você estará sendo irracional?\\nSupondo que você acredite que a moeda é justa, o \\nvalor monetário esperado\\n (VME) do jogo é \\n($0) + \\n($2.500.000) = $1.250.000, que é mais que o prêmio original de $1.000.000. Porém, isso não\\nsignifica necessariamente que aceitar a aposta seja uma decisão melhor. Suponha que utilizamos \\nSn\\npara denotar o estado de possuir a riqueza total $\\nn\\n e que sua riqueza atual seja $\\nk\\n. Então, as\\nutilidades esperadas das duas ações de aceitar e recusar o jogo são:\\nPara determinar o que fazer precisamos atribuir utilidades aos estados resultantes. A utilidade não\\né diretamente proporcional ao valor monetário porque a utilidade para o seu primeiro milhão é muito\\nalta (é o que achamos), enquanto a utilidade para um milhão adicional é menor.\\nSuponha que você atribua a utilidade 5 ao seu \\nstatus\\n financeiro atual (\\nS\\nk\\n), 9 ao estado \\nS\\nk\\n+2.500.000\\n e\\n8 ao estado \\nS\\nk\\n+1.000.000\\n. Então, a ação racional seria recusar porque a utilidade esperada de aceitar é\\napenas 7 (menos que a utilidade 8 de recusar). Por outro lado, é mais provável que um bilionário\\ntenha uma função utilidade que seja localmente linear no intervalo de poucos milhões a mais e,\\nassim, aceitaria a aposta.\\nEm um estudo pioneiro das funções utilidade reais, Grayson (1960) descobriu que a utilidade do\\ndinheiro era quase exatamente proporcional ao logaritmo da quantia (essa ideia foi sugerida primeiro\\npor Bernoulli (1738); veja o Exercício 16.3). Uma curva específica, para um certo Mr. Beard, é\\nmostrada na \\nFigura 16.2\\n(a). Os dados obtidos para as preferências de Mr. Beard são consistentes\\ncom uma função utilidade', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 718}),\n",
       " Document(page_content='Figura 16.2\\n A utilidade do dinheiro. (a) Dados empíricos para Mr. Beard sobre um intervalo\\nlimitado. (b) Uma curva típica para o intervalo completo.\\npara o intervalo entre \\nn\\n = –$150.000 e \\nn\\n = $800.000.\\nNão devemos supor que essa seja a função utilidade definitiva para valor monetário, mas é\\nprovável que a maioria das pessoas tenha uma função utilidade côncava para riquezas positivas.\\nContrair dívidas é em geral considerado desastroso, mas as preferências entre diferentes níveis de\\ndívidas podem exibir uma inversão da concavidade associada com riqueza positiva. Por exemplo,\\nalguém que já deve $10.000.000 poderia muito bem aceitar uma aposta em um lançamento de moeda\\njusto com um ganho de $10.000.000 para caras e uma perda de $20.000.000 para coroas.\\n5\\n Isso gera a\\ncurva em forma de \\nS\\n mostrada na \\nFigura 16.2\\n(b).\\nVamos limitar nossa atenção à parte positiva das curvas, onde a declividade está diminuindo;\\nentão, para qualquer loteria \\nL\\n, a utilidade de se defrontar com essa loteria é menor que a utilidade de\\nreceber o valor monetário esperado da loteria como algo certo:\\nU\\n(\\nL\\n) < \\nU\\n(\\nS\\nVME\\n(\\nL\\n))\\nIsto é, agentes com curvas dessa forma são \\navessos ao risco\\n: eles preferem algo certo com\\ncompensação menor que o valor monetário esperado de uma aposta. Por outro lado, na região\\n“desesperada” de grande riqueza negativa da \\nFigura 16.2\\n(b), o comportamento é de \\nbusca do risco\\n.\\nO valor que um agente aceitará em vez de se arriscar em uma loteria é chamado \\nequivalente de\\ncerteza\\n da loteria. Os estudos mostram que a maioria das pessoas aceitará cerca de $400 em vez de\\numa aposta que ofereça $1.000 na metade do tempo e $0 na outra metade, ou seja, o equivalente de\\ncerteza da loteria é $400, enquanto o valor monetário esperado é $500. A diferença entre o valor\\nmonetário esperado de uma loteria e seu equivalente de certeza é chamado \\nprêmio de seguro\\n. A\\naversão ao risco é a base da indústria de seguros porque significa que os prêmios de seguros são\\npositivos. As pessoas preferem pagar um prêmio de seguro pequeno a apostar o valor de sua casa\\ncontra a chance de um incêndio. Do ponto de vista da companhia de seguros, o preço da casa é muito\\npequeno comparado às reservas totais da firma. Isso significa que a curva de utilidade da seguradora\\né aproximadamente linear sobre essa pequena região, e o jogo não custa quase nada para a empresa.\\nNote que, no caso de \\npequenas\\n mudanças de riqueza em relação à riqueza atual, quase qualquer\\ncurva será aproximadamente linear. Um agente que tenha uma curva linear é dito \\nneutro ao risco\\n.\\nPortanto, no caso de apostas com pequenas somas, esperamos a neutralidade ao risco. De certo\\nmodo, isso justifica o procedimento simplificado que propôs pequenas apostas para avaliar as\\nprobabilidades e justificar os axiomas de probabilidade na \\nSeção 13.2.3\\n.\\n16.3.3 Utilidade esperada e decepção pós-decisão\\nA forma racional para escolher a melhor ação, \\na\\n*, é maximizar a utilidade esperada:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 719}),\n",
       " Document(page_content='Se tivermos calculado a utilidade esperada corretamente, de acordo com nosso modelo de\\nprobabilidade, e se o modelo probabilístico refletir corretamente os processos estocásticos\\nsubjacentes que geram os resultados, em média teremos a utilidade que esperamos se todo o processo\\nfor repetido muitas vezes.\\nNa realidade, porém, o nosso modelo geralmente simplifica demais a situação real, seja porque\\nnão sabemos o suficiente (por exemplo, ao fazer uma decisão de investimento complexo) seja porque\\no cálculo da verdadeira utilidade esperada é muito difícil (por exemplo, ao estimar a utilidade de\\nestados sucessores do nó raiz no gamão). Nesse caso, estamos trabalhando realmente com\\nestimativas \\n da utilidade esperada verdadeira. Vamos supor, de forma cordial talvez, que as\\nestimativas sejam \\nimparciais\\n, isto é, o valor esperado do erro, \\n, é zero. Nesse\\ncaso, ainda parece razoável escolher a ação com a mais alta utilidade estimada e esperar receber\\nessa utilidade, em média, quando a ação for executada.\\nInfelizmente, o resultado real geralmente será significativamente \\npior\\n do que estimamos, mesmo\\nque a estimativa seja imparcial! Para saber o motivo, considere um problema de decisão em que haja\\nk\\n escolhas, cada uma com utilidade estimada verdadeira de 0. Suponha que o erro em cada estimativa\\nde utilidade tenha zero de média e desvio-padrão de 1, como vemos na curva em negrito na \\nFigura\\n16.3\\n. Agora, como realmente começamos a gerar estimativas, alguns dos erros serão negativos\\n(pessimistas) e outros positivos (otimistas). Como selecionamos a ação com a estimativa mais alta\\nde utilidade, é óbvio que estaremos favorecendo as estimativas excessivamente otimistas, e isso é a\\norigem da inclinação. Calcular a distribuição do máximo das estimativas \\nk\\n é uma questão simples\\n(veja o Exercício 16.11) e, assim, temos como quantificar o grau de nossa decepção. A curva na\\nFigura 16.3\\n para \\nk\\n = 3 tem média em torno de 0,85, de modo que a decepção média será cerca de\\n85% do desvio-padrão nas estimativas de utilidade.\\nFigura 16.3\\n Representação gráfica do erro em cada uma das estimativas de utilidade \\nk\\n e da\\ndistribuição do máximo da estimativa para \\nk\\n = 3, 10 e 30.\\nCom mais opções, são mais propensas a surgirem estimativas extremamente otimistas: para \\nk\\n = 30,\\na decepção será de cerca de duas vezes o desvio-padrão das estimativas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 720}),\n",
       " Document(page_content='Essa tendência de a utilidade esperada estimada da melhor escolha ser demasiado elevada é\\nchamada de \\nmaldição do otimizador\\n (Smith e Winkler, 2006) e aflige mesmo os mais experientes\\nanalistas de decisão e estatísticos. Manifestações graves incluem acreditar que uma nova droga\\nexcelente que curou 80% dos doentes (foi escolhida entre \\nk\\n = milhares de drogas candidatas) ou o\\nanúncio de um fundo mútuo teve retornos médios altos fará com que continue a tê-los (foi escolhido\\npara aparecer no anúncio de \\nk\\n = dezenas de fundos na carteira total da companhia). Pode até mesmo\\nser o caso de o que parece ser a melhor escolha pode não ser, se a variação na estimativa de\\nutilidade for alta: uma droga, selecionada a partir de milhares de tentativas, que curou 9 dentre 10\\npacientes é provavelmente \\npior\\n do que outra que tenha curado 800 dentre 1.000 pacientes.\\nA maldição do otimizador surge em todos os lugares por causa da onipresença dos processos de\\nseleção da maximização de utilidade, portanto tomar as estimativas de utilidade pelo valor nominal é\\numa má ideia. Podemos evitar a maldição usando um modelo de probabilidade explícito \\n do\\nerro nas estimativas de utilidade. Dado esse modelo e um \\nP\\n(\\nUE\\n) anterior sobre o que poderíamos\\nesperar razoavelmente que fossem as utilidades, lidamos com a estimativa de utilidade, uma vez\\nobtida, como prova e calculamos a distribuição posterior para a utilidade verdadeira utilizando a\\nregra de Bayes.\\n16.3.4 Julgamento humano e irracionalidade\\nA teoria da decisão é uma \\nteoria normativa\\n: ela descreve como um agente racional \\ndeve\\n agir. A\\nteoria descritiva\\n, por outro lado, descreve como os agentes reais — por exemplo, os seres humanos\\n— agem realmente. A aplicação da teoria econômica seria muito maior se os dois coincidissem, mas\\nparece haver alguma evidência experimental em contrário. A evidência sugere que os seres humanos\\nsão “previsivelmente irracionais” (Ariely, 2009).\\nO problema mais conhecido é o paradoxo de Allais (Allais, 1953). As pessoas recebem uma\\nescolha entre as loterias \\nA\\n e \\nB\\n e, em seguida, entre \\nC\\n e \\nD\\n, que têm os seguintes prêmios:\\nA\\n: 80% de chance de $4.000\\nB\\n: 100% de chance de $3.000\\nC\\n: 20% de chance de $4.000\\nD\\n: 25% de chance de $3.000.\\nA maioria das pessoas prefere consistentemente \\nB\\n sobre \\nA\\n (decidindo pelo certo) e \\nC\\n sobre \\nD\\n(considerando o maior VME). A análise normativa discorda! Podemos ver isso mais facilmente se\\nusarmos a liberdade implícita pela Equação 16.2 para definir \\nU\\n($0) = 0. Nesse caso, B \\n \\nA\\n implica\\nque \\nU\\n($3.000) > 0,8\\nU\\n ($4.000), enquanto C \\n \\nD\\n implica exatamente o inverso. Em outras palavras,\\nnão há nenhuma função utilidade que seja consistente com essas escolhas. Uma explicação para as\\npreferências aparentemente irracionais é o \\nefeito certeza\\n (Kahneman e Tversky, 1979): as pessoas\\nsão fortemente atraídas para os ganhos que são certos. Existem várias razões pelas quais isso pode\\nser assim. Primeiro, as pessoas podem preferir reduzir sua carga de cálculo; escolhendo certos\\nresultados, elas não têm que calcular probabilidades. Mas o efeito persiste mesmo quando os\\ncálculos envolvidos são muito fáceis. Em segundo lugar, as pessoas podem desconfiar da', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 721}),\n",
       " Document(page_content='legitimidade das probabilidades declaradas. Confio que o lançamento de uma moeda é mais ou\\nmenos 50/50 se eu tiver controle sobre a moeda e sobre o lance, mas posso desconfiar do resultado\\nse o lançamento for feito por alguém com interesse no resultado.\\n6\\n Na presença de desconfiança,\\ntalvez seja melhor ir para a certeza.\\n7\\n Terceiro, as pessoas podem estar considerando seu estado\\nemocional, bem como o financeiro. Elas sabem que experimentariam \\npesar\\n se desistissem de certa\\nrecompensa (\\nB\\n) por 80% de chance de uma recompensa maior e depois perdessem. Em outras\\npalavras, se \\nA\\n for escolhido, há uma chance de 20% de não obter dinheiro e \\nsentir-se como um\\ncompleto idiota\\n, que é pior do que simplesmente ficar sem dinheiro. Assim, talvez as pessoas que\\nescolhem \\nB\\n sobre \\nA\\n e \\nC\\n sobre \\nD\\n não sejam tão irracionais; estão apenas dizendo que estão dispostas\\na desistir de $200 de VME para evitar 20% de chance de se sentirem idiotas.\\nUm problema relacionado é o paradoxo de Ellsberg. Aqui os prêmios são fixos, mas as\\nprobabilidades são irrestritas. Sua recompensa vai depender da cor de uma bola escolhida em uma\\nurna. Você sabe que a urna contém 1/3 de bolas vermelhas e 2/3 de bolas pretas ou amarelas, mas\\nvocê não sabe quantas são pretas e quantas são amarelas. Novamente, perguntam se você prefere a\\nloteria \\nA\\n ou \\nB\\n e, em seguida, \\nC\\n ou \\nD\\n:\\nA\\n: $100 para uma bola vermelha\\nB\\n: $100 para uma bola preta\\nC\\n: $100 para uma bola vermelha ou amarela\\nD\\n: $100 para uma bola preta ou amarela.\\nDeve ficar claro que, se acha que há mais bolas vermelhas do que pretas, você deve preferir \\nA\\nsobre \\nB\\n e \\nC\\n sobre \\nD\\n; se acha que há menos vermelhas do que pretas, deve preferir o oposto. Mas\\nacontece que a maioria das pessoas prefere \\nA\\n sobre \\nB\\n e também \\nD\\n sobre \\nC\\n, mesmo que não haja\\nestado do mundo para o qual isso seja racional. Parece que as pessoas têm \\naversão à ambiguidade\\n:\\nA\\n oferece uma chance de ganho de 1/3, enquanto \\nB\\n pode estar em qualquer lugar entre 0 e 2/3. Da\\nmesma forma, \\nD\\n oferece 2/3 de chance, enquanto \\nC\\n pode estar entre 1/3 e 3/3. A maioria das pessoas\\nelege a probabilidade conhecida, em vez de as incógnitas desconhecidas.\\nOutro problema é que a formulação exata de um problema de decisão pode ter grande impacto\\nsobre as escolhas do agente, o que é chamado de efeito \\nframing\\n. A experiência mostra que as\\npessoas preferem um procedimento médico, que é descrito como tendo “taxa de sobrevivência de\\n90%” cerca de duas vezes mais do que aquele descrito como tendo “taxa de mortalidade de 10%”,\\nmesmo que essas duas declarações signifiquem exatamente a mesma coisa. Essa discrepância no\\njulgamento foi encontrada em experimentos múltiplos e é quase a mesma se os sujeitos forem\\npacientes de uma clínica, estudantes de uma escola de negócios muito sofisticada ou médicos\\nexperientes.\\nAs pessoas sentem-se mais confortáveis fazendo julgamentos de utilidade \\nrelativa\\n do que\\nabsoluta. Eu posso ter pouca ideia de quanto poderia gostar dos diversos vinhos oferecidos por um\\nrestaurante.\\nO restaurante aproveita isso oferecendo uma garrafa de $200 que sabe que ninguém vai comprar,\\nmas que serve para elevar a estimativa de valor de todos os vinhos do cliente e fazer a garrafa de\\n$55 parecer uma pechincha. Isso se chama \\nefeito de ancoragem\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 722}),\n",
       " Document(page_content='Se informantes humanos insistem em juízos de preferência contraditória, não há nada que os\\nagentes automatizados possam fazer para ser coerentes com eles. Felizmente, os julgamentos de\\npreferência feitos por seres humanos muitas vezes são passíveis de revisão, à luz de uma análise\\nmais aprofundada. Paradoxos, como o paradoxo de Allais, são muito reduzidos (mas não eliminados)\\nse as escolhas forem mais bem explicadas. No trabalho na Harvard Business School sobre a\\navaliação da utilidade do dinheiro, Keeney e Raiffa (1976, p. 210) encontraram o seguinte:\\nOs indivíduos tendem a ser muito avessos ao risco nos pequenos e, portanto (…) as funções\\nutilidade adequadas exibem prêmios de risco muito grande e inaceitável para loterias com grande\\nenvergadura… A maioria dos indivíduos, no entanto, pode conciliar as inconsistências e sentir que\\naprendeu uma lição importante sobre como querem se comportar. Como consequência, alguns\\nindivíduos cancelam seu seguro automobilístico contra colisão e acrescentam mais cláusulas em\\nseu seguro de vida.\\nA evidência para a irracionalidade humana também é questionada por pesquisadores no campo da\\npsicologia evolucionária\\n, que aponta para o fato de que os mecanismos de tomada de decisão do\\nnosso cérebro não evoluíram para resolver problemas de palavras com probabilidades e prêmios\\ndeclarados como números decimais. Admitamos, por causa do argumento, que o cérebro tem um\\nmecanismo neural embutido para calcular probabilidades e utilidades ou algo funcionalmente\\nequivalente; em caso afirmativo, os insumos necessários seriam obtidos através da experiência\\nacumulada de resultados e recompensas, em vez de através de apresentações linguísticas de valores\\nnuméricos. Está longe de ser óbvio que podemos acessar diretamente os mecanismos neurais\\nembutidos no cérebro apresentando problemas de decisão na forma linguística/numérica. O próprio\\nfato de que formulações diferentes do \\nmesmo problema de decisão\\n provocam escolhas diferentes\\nsugere que o problema de decisão em si não conseguiu aprovação. Estimulados por essa observação,\\nos psicólogos têm tentado apresentar problemas de raciocínio incerto e tomada de decisão em forma\\nde “evolução adequada”; por exemplo, em vez de dizer “ taxa de sobrevivência de 90%”, o\\nexperimentador pode mostrar 100 figuras de animação estilizadas, onde o paciente morre em 10\\ndelas e sobrevive em 90. (O tédio é um fator complicador nesses experimentos!) Com problemas de\\ndecisão colocados dessa maneira, as pessoas parecem ficar muito mais perto de um comportamento\\nracional do que anteriormente se suspeitava.\\n16.4 FUNÇÕES UTILIDADE MULTIATRIBUTO\\nA tomada de decisões no campo de política pública envolve altos riscos, tanto em dinheiro como\\nem vidas. Por exemplo, ao decidir quais níveis de emissões nocivas permitir de uma fábrica\\npoderosa, os legisladores devem ponderar a prevenção de morte e incapacidade em relação ao\\nbenefício do poder e da carga econômica de mitigar as emissões. O projeto de um novo aeroporto\\nexige que seja considerada a ruptura causada pela construção, o custo do terreno, a distância até os\\ncentros populacionais, o ruído das operações de voo, questões de segurança relacionadas à\\ntopografia local e às condições meteorológicas, e assim por diante. Problemas como esses, em que\\nos resultados são caracterizados por dois ou mais atributos, são manipulados pela \\nteoria de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 723}),\n",
       " Document(page_content='utilidade multiatributo\\n.\\nChamaremos os atributos de \\nX\\n = \\nX\\n1\\n,…, \\nX\\nn\\n; um vetor completo de atribuições será \\nx\\n = \\n〈\\nx\\n1\\n, …, \\nx\\nn\\n〉\\n.\\nonde cada \\nx\\ni\\n é um valor numérico ou um valor discreto com ordenação de valores assumida. Vamos\\nsupor que os valores mais altos de um atributo correspondam às utilidades mais altas, todas as outras\\ncoisas sendo iguais. Por exemplo, se escolhermos \\nAusênciaDeRuído\\n como um atributo no problema\\nde aeroporto, quanto maior seu valor, melhor a solução.\\n8\\n Começamos examinando casos em que as\\ndecisões podem ser tomadas \\nsem\\n combinar os valores de atributo em um único valor de utilidade.\\nEm seguida, examinaremos casos em que as utilidades de combinações de atributos podem ser\\nespecificadas de forma muito concisa.\\n16.4.1 Dominância\\nVamos supor que o local do aeroporto \\nS\\n1\\n custe menos, gere menos poluição sonora e seja mais\\nseguro que o local \\nS\\n2\\n. Ninguém hesitaria em rejeitar \\nS\\n2\\n. Então, dizemos que existe uma \\ndominância\\nestrita\\n de \\nS\\n1\\n sobre \\nS\\n2\\n. Em geral, se uma opção tiver valor mais baixo que alguma outra opção em\\ntodos os atributos, ela não precisará de consideração adicional. Com frequência, a dominância estrita\\né muito útil no estreitamento do campo de opções para os competidores reais, embora raramente\\nresulte em uma única escolha. A \\nFigura 16.4\\n(a) mostra um diagrama esquemático para o caso de dois\\natributos.\\nFigura 16.4\\n Dominância estrita. (a) Determinística: a opçãoA é estritamente dominada por B, mas\\nnão por C ou D. (b) Incerta: A é estritamente dominado por B, mas não por C.\\nIsso é ótimo para o caso determinístico, em que os valores de atributos são conhecidos com\\ncerteza. E o caso geral, em que os resultados das ações são incertos? Pode ser construída uma\\nanalogia direta da dominância estrita em que, apesar da incerteza, todos os resultados concretos\\npossíveis para \\nS\\n1\\n dominam estritamente todos os resultados possíveis para \\nS\\n2\\n (veja a \\nFigura\\n16.4\\n(b)). É claro que isso provavelmente ocorrerá com frequência ainda menor que no caso\\ndeterminístico.\\nFelizmente, existe uma generalização mais útil chamada \\ndominância estocástica\\n, que ocorre com\\nmuita frequência em problemas reais. É mais fácil compreender a dominância estocástica no contexto\\nde um único atributo. Vamos supor que acreditamos que o custo da localização do aeroporto em \\nS\\n1', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 724}),\n",
       " Document(page_content='esteja uniformemente distribuído entre $2,8 bilhões e $4,8 bilhões, e que o custo em \\nS\\n2\\n esteja\\nuniformemente distribuído entre $3 bilhões e $5,2 bilhões. A \\nFigura 16.5\\n(a) mostra essas\\ndistribuições, com o custo representado como um valor negativo. Então, dada apenas a informação de\\nque a utilidade diminui com o custo, podemos afirmar que \\nS\\n1\\n domina estocasticamente \\nS\\n2\\n (isto é, \\nS\\n2\\npode ser descartado). É importante observar que isso \\nnão\\n decorre da comparação entre os custos\\nesperados. Por exemplo, se soubéssemos que o custo de \\nS\\n1\\n é \\nexatamente\\n $3,8 bilhões, seríamos\\nincapazes\\n de tomar uma decisão sem informações adicionais sobre a utilidade do dinheiro.\\nFigura 16.5\\n Dominância estocástica. (a) \\nS\\n1\\n domina estocasticamente \\nS\\n2\\n em custo. (b) Distribuições\\ncumulativas para o custo negativo de \\nS\\n1\\n e \\nS\\n2\\n.\\n(Pode parecer estranho que \\nmais\\n informações sobre o custo de \\nS\\n1\\n poderia fazer o agente \\nmenos\\ncapaz de decidir. O paradoxo é resolvido observando que, na ausência de informações exatas de\\ncusto, a decisão é mais fácil de tomar, mas é mais provável que esteja errada.)\\nO relacionamento exato entre as distribuições de atributos necessárias para estabelecer a\\ndominância estocástica é mais bem visualizada examinando-se as \\ndistribuições cumulativas\\n,\\nmostradas na \\nFigura 16.5\\n(b) (veja também o Apêndice A). A distribuição cumulativa mede a\\nprobabilidade de que o custo seja menor ou igual a qualquer valor dado, ou seja, ela integra a\\ndistribuição original. Se a distribuição cumulativa para \\nS\\n1\\n estiver sempre à direita da distribuição\\ncumulativa para \\nS\\n2\\n, em termos estocásticos \\nS\\n1\\n será mais econômico que \\nS\\n2\\n. Formalmente, se duas\\nações \\nA\\n1\\n e \\nA\\n2\\n resultam em distribuições de probabilidade \\np\\n1\\n(\\nx\\n) e \\np\\n2\\n(\\nx\\n) sobre o atributo \\nX\\n, então \\nA\\n1\\ndominará estocasticamente \\nA\\n2\\n sobre \\nX\\n se:\\n A relevância dessa definição para a seleção de decisões ótimas vem da seguinte propriedade:\\nse A\\n1\\n \\ndomina estocasticamente A\\n2\\n, \\nentão, para qualquer função utilidade monotonicamente não\\ndecrescente U\\n(\\nx\\n), \\na utilidade esperada de A\\n1\\n \\né pelo menos tão alta quanto a utilidade esperada de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 725}),\n",
       " Document(page_content='A\\n2\\n. Em consequência disso, se uma ação é estocasticamente dominada por outra ação em todos os\\natributos, ela pode ser descartada.\\nA condição de dominância estocástica pode parecer bastante técnica e talvez não muito fácil de\\navaliar sem cálculos extensivos de probabilidade. De fato, ela pode ser decidida com muita\\nfacilidade em vários casos. Por exemplo, suponha que o custo de transporte da construção dependa\\nda distância até o fornecedor. O custo em si é incerto, mas, quanto maior a distância, maior o custo.\\nSe \\nS\\n1\\n estiver mais próximo que \\nS\\n2\\n, \\nS\\n1\\n dominará \\nS\\n2\\n em custo. Existem algoritmos — embora eles não\\nsejam apresentados aqui — que realizam a propagação dessa espécie de informação qualitativa entre\\nvariáveis incertas em \\nredes probabilísticas qualitativas\\n, permitindo a um sistema tomar decisões\\nracionais baseadas em dominância estocástica, sem utilizar valores numéricos.\\n16.4.2 Estrutura de preferências e utilidade multiatributo\\nVamos supor que tenhamos \\nn\\n atributos, cada um dos quais com \\nd\\n valores distintos possíveis. Para\\nespecificar a função utilidade completa \\nU\\n(\\nx\\n1\\n,…, \\nx\\nn\\n), precisamos de \\nd\\nn\\n valores no pior caso. Agora,\\no pior caso corresponde a uma situação em que as preferências do agente não têm absolutamente\\nnenhuma regularidade. A teoria da utilidade multiatributo se baseia na suposição de que as\\npreferências de agentes típicos têm muito mais estrutura que isso. A abordagem básica é identificar\\nregularidades no comportamento de preferências que esperaríamos ver e utilizar o que chamamos\\nteoremas de representação\\n para mostrar que um agente com certo tipo de estrutura de preferências\\ntem uma função utilidade\\nonde \\nF\\n é, esperamos, uma função simples como a adição. Note a semelhança com o uso de redes\\nbayesianas para decompor a probabilidade conjunta de diversas variáveis aleatórias.\\nPreferências sem incerteza\\nVamos começar com o caso determinístico. Lembre-se de que, para ambientes determinísticos, o\\nagente tem uma função de valor \\nV\\n(\\nx\\n1\\n,…, \\nx\\nn\\n); o objetivo é representar essa função de forma concisa.\\nAregularidade básica que surge em estruturas de preferências determinísticas é chamada\\nindependência de preferências\\n. Dois atributos \\nX\\n1\\n e \\nX\\n2\\n são preferencialmente independentes de um\\nterceiro atributo \\nX\\n3\\n se a preferência entre resultados \\n〈\\nx\\n1\\n, \\nx\\n2\\n, \\nx\\n3\\n〉\\n e \\n〈\\n〉\\n não depende do valor\\nespecífico \\nx\\n3\\n para o atributo \\nX\\n3\\n.\\nVoltando ao exemplo do aeroporto, onde temos (entre outros atributos) \\nRuído\\n, \\nCusto\\n e \\nMortes\\n a\\nconsiderar, alguém poderia propor que \\nRuído\\n e \\nCusto\\n sejam preferencialmente independentes de\\nMortes\\n. Por exemplo, se preferirmos um estado com 20.000 pessoas residentes na rota de voos e um\\ncusto de construção de $4 bilhões a um estado com 70.000 pessoas residentes na rota de voos e um\\ncusto de $3,7 bilhões quando o nível de segurança é 0,06 morte por milhão de milhas de passageiros\\nem ambos os casos, teremos a mesma preferência quando o nível de segurança for 0,12 ou 0,03, e a\\nmesma independência seria válida para preferências entre qualquer outro par de valores de \\nRuído\\n e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 726}),\n",
       " Document(page_content='Custo\\n. Também é aparente que \\nCusto\\n e \\nMortes\\n são preferencialmente independentes de \\nRuído\\n, e que\\nRuído\\n e \\nMortes\\n são preferencialmente independentes de \\nCusto\\n. Dizemos que o conjunto de atributos\\n{\\nRuído\\n, \\nCusto\\n, \\nMortes\\n} exibe \\nindependência preferencial mútua\\n (IPM). A IPM afirma que, embora\\ncada atributo possa ser importante, não afeta os compromissos que os outros atributos mantêm entre\\nsi.\\n A independência preferencial mútua é uma expressão que parece complicada, mas, graças a um\\nimportante teorema devido ao economista Gérard Debreu (1960), podemos derivar a partir dela uma\\nforma muito simples para a função de valor do agente: se os atributos \\nX\\n1\\n, …, \\nX\\nn\\n \\nguardam entre si\\numa independência preferencial mútua\\n, \\nentão o comportamento de preferências do agente pode\\nser descrito como a maximização da função\\n:\\nonde cada Vi é uma função de valor que se refere apenas ao atributo X\\ni\\n. Por exemplo, talvez a\\ndecisão sobre o local do aeroporto pudesse ser tomada com o uso de uma função de valor:\\nV\\n(\\nruído\\n, \\ncusto\\n, \\nmortes\\n) = \\n–ruído\\n × 10\\n4\\n \\n– custo – mortes\\n × 10\\n12\\n.\\nUma função de valor desse tipo é chamada \\nfunção de valor aditiva\\n. As funções aditivas\\nconstituem um modo extremamente natural de se descrever a função de valor de um agente, e são\\nválidas em muitas situações reais. Para \\nn\\n atributos, avaliar uma função de valor aditivo exige avaliar\\nem separado funções de valor \\nn\\n unidimensional, em vez de uma função \\nn\\n dimensional; normalmente,\\nisso representa uma redução exponencial do número de experimentos de preferência que são\\nnecessários. Mesmo quando a IPM não é estritamente válida, como poderia ocorrer no caso de\\nvalores extremos dos atributos, uma função de valor aditiva ainda poderia fornecer boa aproximação\\npara as preferências do agente. Isso é especialmente verdadeiro quando as violações da IPM\\nocorrem em porções dos intervalos de atributos que têm pouca probabilidade de ocorrerem na\\nprática.\\nPara entender melhor o IPM, ajuda examinar os casos em que \\nnão\\n \\nsão\\n válidos. Suponha que você\\nesteja em um mercado medieval, considerando a compra de alguns cães de caça, algumas galinhas e\\nalgumas gaiolas de vime para as galinhas. Os cães de caça são muito valiosos, mas, se você não tiver\\ngaiolas suficientes para as galinhas, os cachorros vão comer as galinhas; daí, a troca entre cães e\\ngalinhas depende fortemente do número de gaiolas, e o IPM será violado. A existência desses tipos\\nde interações entre vários atributos torna muito mais difícil avaliar a função de valor global.\\nPreferências com incerteza\\nQuando a incerteza estiver presente no domínio, também precisaremos considerar a estrutura de\\npreferências entre loterias e entender as propriedades resultantes de funções utilidade, e não apenas\\nde funções de valor. A matemática desse problema pode se tornar bastante complicada e, assim,\\napresentaremos apenas um dos principais resultados para dar uma ideia do que pode ser feito. O\\nleitor deve consultar o trabalho de Keeney e Raiffa (1976) para ver um estudo completo do campo.\\nA noção básica de \\nindependência da utilidade\\n estende a independência de preferências para', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 727}),\n",
       " Document(page_content='cobrir as loterias: um conjunto de atributos \\nX\\n é independente da utilidade de um conjunto de atributos\\nY\\n se as preferências entre loterias sobre os atributos em \\nX\\n são independentes dos valores específicos\\ndos atributos em \\nY\\n. Um conjunto de atributos é \\nmutuamente independente da utilidade\\n (MIU) se\\ncada um de seus subconjuntos é independente da utilidade dos atributos restantes. Mais uma vez,\\nparece razoável propor que os atributos do aeroporto sejam MIU.\\nA MIU implica que o comportamento do agente pode ser descrito com o uso de uma \\nfunção\\nutilidade multiplicativa\\n (Keeney, 1974). A forma geral de uma função utilidade multiplicativa é mais\\nbem visualizada observando-se o caso correspondente a três atributos. Por concisão, utilizaremos \\nU\\ni\\npara representar \\nU\\ni\\n(\\nx\\ni\\n):\\nEmbora não pareça muito simples, essa expressão contém apenas três funções utilidade de um\\núnico atributo e três constantes. Em geral, um problema de \\nn\\n atributos que exibe mil pode ser\\nmodelado com a utilização de \\nn\\n utilidades de um único atributo e \\nn\\n constantes. Cada uma das funções\\nutilidade de um único atributo pode ser desenvolvida independentemente dos outros atributos, e essa\\ncombinação oferecerá a garantia de gerar as preferências globais corretas. São necessárias\\nsuposições adicionais para se obter uma função utilidade puramente aditiva.\\n16.5 REDES DE DECISÃO\\nNesta seção, examinaremos um mecanismo geral para a tomada de decisões racionais. Com\\nfrequência, a notação é chamada \\ndiagrama de influência\\n (Howard e Matheson, 1984), mas\\nutilizaremos a expressão mais descritiva \\nrede de decisão\\n. As redes de decisão combinam redes\\nbayesianas com tipos de nós adicionais para ações e utilidades. Usaremos a localização do aeroporto\\ncomo exemplo.\\n16.5.1 Representação de um problema de decisão com uma rede de decisão\\nEm sua forma mais geral, uma rede de decisão representa informações sobre o estado atual do\\nagente, suas ações possíveis, o estado que resultará da ação do agente e a utilidade desse estado.\\nPortanto, ela fornece um substrato para a implementação de agentes baseados em utilidade do tipo\\napresentado primeiro na \\nSeção 2.4.5\\n. A \\nFigura 16.6\\n mostra uma rede de decisão para o problema de\\nlocalização do aeroporto. Ela ilustra os três tipos de nós utilizados:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 728}),\n",
       " Document(page_content='Figura 16.6\\n Uma rede de decisão simples para o problema de localização do aeroporto.\\n•  \\nNós de acaso\\n (elipses) representam variáveis aleatórias, da mesma maneira que nas redes\\nbayesianas. O agente poderia estar inseguro sobre o custo da construção, o nível de tráfego aéreo\\ne o potencial para litígio, e as variáveis \\nMortes\\n, \\nRuído\\n e \\nCusto\\n total, cada uma das quais\\ntambém depende do local escolhido. Cada nó de acaso está associado a uma distribuição\\ncondicional que é indexada pelo estado dos nós pais. Em redes de decisão, os nós pais podem\\nincluir nós de decisão, bem como nós de acaso. Observe que cada um dos nós de acaso do\\nestado atual poderia fazer parte de uma grande rede bayesiana para avaliar os custos de\\nconstrução, os níveis de tráfego aéreo ou os potenciais de litígio.\\n•  \\nNós de decisão\\n (retângulos) representam pontos em que o tomador de decisão tem a\\npossibilidade de escolher ações. Nesse caso, a ação \\nLocalAeroporto\\n pode assumir um valor\\ndiferente para cada local que está sendo considerado. A escolha influencia o custo, a segurança e\\no ruído resultantes. Neste capítulo, vamos supor que estamos lidando com um único nó de\\ndecisão. O Capítulo 17 lida com casos em que deve ser tomada mais de uma decisão.\\n•  \\nNós de utilidade\\n (losangos) representam a função utilidade do agente.\\n9\\n O nó de utilidade tem\\ncomo pais todas as variáveis que descrevem o resultado que afeta diretamente a utilidade.\\nAssociada ao nó de utilidade, encontramos uma descrição da utilidade do agente como uma\\nfunção dos atributos do pai. A descrição poderia ser simplesmente uma tabulação da função ou\\numa função parametrizada aditiva ou multilinear.\\nEm muitos casos, também é utilizada uma forma simplificada. A notação permanece idêntica, mas\\nos nós de acaso que descrevem o estado resultante são omitidos. Em vez disso, o nó de utilidade é\\nconectado diretamente aos nós do estado atual e ao nó de decisão. Nesse caso, em vez de representar\\numa função utilidade sobre estados, o nó de utilidade representa a utilidade \\nesperada\\n associada a\\ncada ação, conforme definimos na Equação 16.1, ou seja, o nó está associado com uma \\nfunção ação-\\nutilidade\\n (também conhecida como \\nQ-função\\n em aprendizado por reforço, como descrito no\\nCapítulo 21). A \\nFigura 16.7\\n mostra a representação de ação-utilidade do problema de aeroporto.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 729}),\n",
       " Document(page_content='Figura 16.7\\n Representação simplificada do problema de localização do aeroporto. Os nós de acaso\\nque correspondem a estados resultantes foram fatorados.\\nNote que, pelo fato de os nós de acaso \\nRuído\\n, \\nMortes\\n e \\nCusto\\n da \\nFigura 16.6\\n se referirem a\\nestados futuros, eles nunca podem ter seus valores definidos como variáveis de evidência. Desse\\nmodo, a versão simplificada que omite esses nós pode ser empregada sempre que a forma mais geral\\npuder ser utilizada. Embora a forma simplificada contenha menos nós, a omissão de uma descrição\\nexplícita do resultado da decisão sobre a localização significa que ela é menos flexível com relação\\na mudanças nas circunstâncias. Por exemplo, na \\nFigura 16.6\\n, uma mudança nos níveis de ruído das\\naeronaves pode se refletir em uma alteração na tabela de probabilidade condicional associada ao nó\\nRuído\\n, enquanto uma mudança no peso acordado para a poluição sonora na função utilidade pode se\\nrefletir em uma mudança na tabela de utilidade. Por outro lado, no diagrama de ação-utilidade,\\napresentado na \\nFigura 16.7\\n, todas essas mudanças têm de ser refletidas por alterações na tabela de\\nação-utilidade. Em essência, a formulação de ação-utilidade é uma versão \\ncompilada\\n da formulação\\noriginal.\\n16.5.2 Avaliação de redes de decisão\\nAs ações são selecionadas pela avaliação da rede de decisão correspondente a cada configuração\\npossível do nó de decisão. Uma vez que o nó de decisão é estabelecido, ele se comporta exatamente\\ncomo um nó de acaso que tenha sido definido como uma variável de evidência. O algoritmo para\\navaliar redes de decisão é dado a seguir:\\n1. Definir as variáveis de evidência para o estado atual.\\n2. Para cada valor possível do nó de decisão:\\n(a) Definir o nó de decisão com esse valor.\\n(b) Calcular as probabilidades posteriores para os nós pais do nó de utilidade, usando um\\nalgoritmo-padrão de inferência probabilística.\\n(c) Calcular a utilidade resultante para a ação.\\n3. Retornar a ação com a utilidade mais alta.\\nEssa é uma extensão direta do algoritmo de rede bayesiana e pode ser diretamente incorporada ao', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 730}),\n",
       " Document(page_content='projeto de agente apresentado na \\nFigura 13.1\\n. Veremos no Capítulo 17 que a possibilidade de\\nexecutar diversas ações em sequência torna o problema muito mais interessante.\\n16.6 O VALOR DA INFORMAÇÃO\\n Na análise precedente, partimos do princípio de que todas as informações relevantes, ou pelo\\nmenos todas as informações disponíveis, são fornecidas ao agente antes de ele tomar sua decisão. Na\\nprática, isso dificilmente acontece. \\nUma das partes mais importantes da tomada de decisões é\\nsaber que perguntas formular\\n. Por exemplo, um médico não pode esperar ter o resultado de \\ntodos\\nos possíveis\\n exames e questões de diagnóstico no momento em que um paciente entra pela primeira\\nvez no consultório.\\n10\\n Muitas vezes, os exames são dispendiosos, e às vezes arriscados (tanto\\ndiretamente quanto devido a retardos associados). Sua importância depende de duas variáveis: do\\nfato de os resultados dos exames levarem ou não a um plano de tratamento significativamente melhor\\ne da probabilidade de cada um dos diversos resultados para os exames.\\nEsta seção descreve a \\nteoria do valor da informação\\n, que permite a um agente escolher que\\ninformação adquirir. Assumimos que, antes de escolher uma ação “real” representada pelo nó de\\ndecisão, o agente pode adquirir o valor de qualquer uma das variáveis de acaso potencialmente\\nobserváveis no modelo. Assim, a teoria do valor da informação envolve uma forma simplificada de\\ntomada decisão sequencial — simplificada, pois as ações de observação afetam apenas \\no estado de\\ncrença\\n do agente, não o estado físico externo. O valor de qualquer observação particular deve\\nderivar do potencial de afetar a eventual ação física do agente; e esse potencial pode ser estimado\\ndiretamente a partir do modelo de decisão em si.\\n16.6.1 Um exemplo simples\\nVamos supor que uma empresa petrolífera espere comprar um dos \\nn\\n blocos indistinguíveis de\\ndireitos de perfuração oceânica. Vamos supor ainda que exatamente um dos blocos contenha petróleo\\nno valor de \\nC\\n dólares, enquanto os outros não têm valor. O preço inicial de cada bloco é \\nC\\n/\\nn\\ndólares. Se a empresa for de risco neutro, ela será indiferente entre comprar e não comprar um bloco.\\nAgora, suponha que um sismólogo ofereça à empresa os resultados de uma sondagem do bloco\\nnúmero 3, que indica definitivamente se o bloco contém petróleo. Quanto a empresa deve estar\\ndisposta a pagar pela informação? O caminho para responder a essa pergunta é examinar o que a\\nempresa faria se tivesse a informação:\\n•  Com probabilidade 1/\\nn\\n, a sondagem indicará petróleo no bloco 3. Nesse caso, a empresa\\ncomprará o bloco 3 por \\nC\\n/\\nn\\n dólare\\ns\\n e terá um lucro de \\nC – C\\n/\\nn\\n = (\\nn –\\n 1)\\nC\\n/\\nn\\n dólares.\\n•  Com probabilidade (\\nn –\\n 1)/\\nn\\n, a sondagem mostrará que o bloco não contém petróleo e, nesse\\ncaso, a empresa comprará um bloco diferente. Agora a probabilidade de encontrar petróleo em\\num dos outros blocos muda de 1/\\nn\\n para 1/(\\nn –\\n 1) e, assim, a empresa obtém um lucro esperado\\nde \\nC\\n/(\\nn –\\n 1) – \\nC\\n/\\nn\\n = \\nC\\n/\\nn\\n(\\nn –\\n 1) dólares.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 731}),\n",
       " Document(page_content='Agora podemos calcular o lucro esperado, dadas as informações da sondagem:\\nEntão, a empresa deve estar disposta a pagar ao sismólogo até \\nC\\n/\\nn\\n dólares pela informação: a\\ninformação é tão valiosa quanto o próprio bloco.\\nO valor da informação deriva do fato de que, \\ncom\\n a informação, um curso de ação pode ser\\nalterado para se adaptar à situação \\nreal\\n. É possível decidir de acordo com a situação; por outro lado,\\nsem a informação, a decisão tem de ser tomada avaliando-se a melhor opção em média sobre as\\nsituações possíveis. Em geral, o valor de dado item de informação é definido como a diferença de\\nvalor esperado entre as ações antes e depois da obtenção da informação.\\n16.6.2 Fórmula geral da informação perfeita\\nÉ simples derivar uma fórmula matemática geral para o valor da informação. Em geral, supomos\\nque a evidência exata seja obtida sobre o valor de alguma variável aleatória \\nE\\nj\\n e, assim, é usada a\\nexpressão \\nvalor da informação perfeita\\n (VIP).\\n11\\nSeja \\ne\\n o conhecimento atual do agente. Então, o valor da melhor ação atual α é definido por:\\ne o valor da melhor ação nova (após a nova evidência \\nE\\nj\\n \\n= e\\nj\\n ser obtida) será:\\nPorém, \\nE\\nj\\n é uma variável aleatória cujo valor é \\natualmente\\n desconhecido; assim, para determinar\\no valor de \\nE\\nj\\n, dada uma informação atual \\ne\\n devemos calcular a média sobre todos os valores\\npossíveis \\ne\\njk\\n que poderíamos descobrir para \\nE\\nj\\n utilizando nossas crenças \\natuais\\n sobre seu valor:\\nPara obter alguma intuição relativa a essa fórmula, considere o caso simples em que existem\\napenas duas ações, \\nα\\n1\\n e \\nα\\n2\\n, da qual devemos escolher uma. Suas utilidades esperadas atuais são \\nU\\n1\\n e\\nU\\n2\\n. As informações \\nE\\nj\\n = \\ne\\njk\\n produzirão algumas novas utilidades esperadas \\n para as ações;\\nporém, antes de obter \\nE\\nj\\n, teremos algumas distribuições de probabilidade sobre os valores possíveis\\nde \\n (que vamos supor independentes).\\nSuponha que \\na\\n1\\n e \\na\\n2\\n representem duas rotas diferentes através de uma cordilheira no inverno. \\na\\n1\\n é', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 732}),\n",
       " Document(page_content='uma ótima estrada reta que passa por um vale, e \\na\\n2\\n é uma estrada poeirenta e sinuosa, próxima ao\\ncume das montanhas.\\nApenas com essas informações, \\na\\n1\\n é claramente preferível porque é bastante provável que \\na\\n2\\nesteja bloqueada por avalanches, enquanto é improvável que algo bloqueie \\na\\n1\\n. Então, \\nU\\n1\\n é sem\\ndúvida mais alta que \\nU\\n2\\n. É possível obter relatórios \\nE\\nj\\n sobre o estado real de cada estrada, o que nos\\ndará novas expectativas, \\n, relativas às duas rotas. As distribuições para essas expectativas são\\nmostradas na \\nFigura 16.8\\n(a). É óbvio que, nesse caso, não vale a pena a despesa de obter relatórios\\nde satélites porque é improvável que as informações que derivam deles alterem o plano. Sem\\nmudança, a informação não tem nenhum valor.\\nFigura 16.8\\n Três casos genéricos para o valor da informação. Em (a), \\na\\n1\\n quase certamente\\npermanecerá superior a \\na\\n2\\n e, assim, a informação não é necessária. Em (b), a escolha é obscura e a\\ninformação é crucial. Em (c), a escolha é obscura, mas, como faz pouca diferença, a informação é\\nmenos valiosa. (Observação: o fato de \\nU\\n2\\n ter um pico alto em (c) significa que seu valor esperado é\\nconhecido com maior certeza que em \\nU\\n1\\n.)\\nAgora vamos supor que estamos escolhendo entre duas estradas sinuosas distintas, de\\ncomprimentos ligeiramente diferentes e transportando um passageiro seriamente ferido. Então,\\nmesmo quando \\nU\\n1\\n e \\nU\\n2\\n estão muito próximos, as distribuições de \\n são muito amplas. Existe\\npossibilidade significativa de que a segunda rota acabe ficando limpa enquanto a primeira se mantém\\nbloqueada e, nesse caso, a diferença de utilidade será muito alta. A fórmula de VIP indica que talvez\\ncompense obter os relatórios do satélite. Tal situação é mostrada na \\nFigura 16.8\\n(b).\\nFinalmente, suponha que estejamos escolhendo entre duas estradas poeirentas no verão, quando o\\nbloqueio por avalanches é improvável. Nesse caso, os relatórios dos satélites poderiam mostrar que,\\nem uma das estradas, encontraremos uma paisagem mais bonita que a da outra porque ela passa por\\nprados alpinos floridos ou, então, talvez uma delas seja mais úmida porque tem muitos córregos.\\nProvavelmente mudaríamos nossos planos se tivéssemos essas informações. Entretanto, nesse caso, a\\ndiferença de valor entre as duas rotas talvez ainda fosse muito pequena, de forma que não nos\\npreocuparemos em obter os relatórios. Essa situação é mostrada na \\nFigura 16.8\\n(c).\\n Em resumo, \\na informação tem valor até o ponto em que apresenta alguma probabilidade de\\ncausar uma mudança de planos e até o ponto em que o novo plano é significativamente melhor que\\no velho\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 733}),\n",
       " Document(page_content='16.6.3 Propriedades do valor da informação\\nPoderíamos perguntar se é possível a informação ser prejudicial: ela pode realmente ter valor\\nesperado negativo? Intuitivamente, devemos esperar que isso seja impossível. Afinal, no pior caso,\\npoderíamos simplesmente ignorar a informação e fingir que nunca a recebemos. Isso é confirmado\\npelo teorema a seguir, que se aplica a qualquer agente de teoria da decisão:\\n \\nO valor da informação é não negativo\\n:\\nO teorema decorre diretamente da definição de VIP, e deixamos a prova como exercício\\n(Exercício16.18). Naturalmente, é um teorema sobre o valor \\nesperado\\n, não sobre o valor \\nreal\\n.\\nInformação adicional pode conduzir facilmente a um plano que \\nacaba\\n por ser pior do que o plano\\noriginal, se acontecer de a informação ser enganosa. Por exemplo, um exame médico que dá\\nresultado falso-positivo pode levar a cirurgias desnecessárias; mas isso não significa que o teste não\\ndeva ser feito.\\nÉ importante lembrar que o VIP depende do estado atual da informação, e é esse o motivo pelo\\nqual ele tem um subscrito. Ele pode mudar à medida que mais informações são adquiridas. Para\\nqualquer evidência determinada de \\nE\\nj\\n, o valor de aquisição pode cair (por exemplo, se outra\\nvariável restringe fortemente a posterior por \\nE\\nj\\n) ou subir (por exemplo, se outra variável fornece\\numa pista em que \\nE\\nj\\n se desenvolva, possibilitando que um plano novo e melhor seja concebido).\\nDesse modo, VIP é não aditivo, isto é:\\nEntretanto, o VIP é independente da ordem. Ou seja:\\nA independência da ordem distingue ações de detecção de ações comuns e simplifica o problema\\nde calcular o valor de uma sequência de ações de detecção.\\n16.6.4 Implementação de um agente de coleta de informações\\nUm agente sensato deve formular as perguntas do usuário em uma ordem razoável, deve evitar\\nformular perguntas irrelevantes, deve levar em conta a importância de cada fragmento de informação\\nem relação a seu custo e deve parar de formular perguntas quando isso for apropriado. Todos esses\\nrecursos podem ser alcançados com o uso do valor da informação como guia.\\nA \\nFigura 16.9\\n mostra o projeto global de um agente que pode coletar informações de forma\\ninteligente antes de agir. Por enquanto, vamos supor que, a cada variável de evidência observável \\nE\\nj\\n,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 734}),\n",
       " Document(page_content='existe um custo associado, \\nCusto\\n(\\nE\\nj\\n), que reflete o custo da obtenção da evidência através de testes,\\nconsultores, perguntas ou qualquer outro processo. O agente solicita o que parece ser o item de\\ninformação mais valioso, comparado a seu custo. Supomos que, como resultado da ação\\nSolicitar\\n(\\nE\\nj\\n), a percepção seguinte forneça o valor de \\nE\\nj\\n. Se nenhuma observação compensar seu\\ncusto, o agente selecionará uma ação “real”.\\nfunção\\n AGENTE-DE-COLETA-DE-INFORMAÇÕES(\\npercepção\\n) \\nretorna\\n uma \\nação\\n    \\nvariáveis estáticas:\\n \\nD\\n, uma rede de decisão\\n    \\n    integrar \\npercepção\\n a \\nD\\n    \\nj\\n ← o valor que maximiza \\nVIP\\n (\\nE\\nj\\n) \\n/ Custo\\n (\\nE\\nj\\n)\\n    \\nse\\n \\nVIP\\n(\\nE\\nj\\n) > \\nCusto\\n(\\nE\\nj\\n)\\n        \\nentão retornar\\n SOLICITAR(\\nE\\nj\\n)\\n    \\nsenão retornar\\n a melhor ação a partir de \\nD\\nFigura 16.9\\n Projeto de um agente de coleta de informações. O agente funciona selecionando\\nrepetidamente a observação com o mais alto valor de informação, até o custo da próxima observação\\nser maior que o seu benefício esperado.\\nO algoritmo de agente que descrevemos implementa uma forma de coleta de informações chamada\\nmíope\\n. Ela recebe esse nome porque utiliza a fórmula do VIP de maneira limitada, calculando o\\nvalor da informação como se apenas uma única variável de evidência fosse adquirida. O controle\\nmíope se baseia na mesma ideia de heurística da pesquisa gulosa, e com frequência funciona bem na\\nprática (por exemplo, mostrou- se que ele supera os médicos especialistas na seleção de exames de\\ndiagnóstico).\\nPorém, se não houver nenhuma única variável de evidência que ajude muito, um agente míope\\npode apressadamente tomar uma ação quando teria sido melhor pedir duas ou mais variáveis \\nprimeiro e depois agir. Uma abordagem melhor nessa situação seria a construção de um \\nplano\\ncondicional\\n (conforme descrito na \\nSeção 11.3.2\\n) que pede os valores das variáveis e escolhe os\\npróximos passos, dependendo da resposta.\\nUma consideração final é o efeito que uma série de questões terá sobre um entrevistado humano.\\nAs pessoas podem responder melhor a uma série de perguntas, se elas “fizerem sentido”, de modo\\nque alguns sistemas especialistas são construídos para levar isso em conta, fazendo perguntas em\\numa ordem que maximiza a utilidade total do sistema e dos humanos em vez de uma ordem que\\nmaximiza o valor da informação.\\n16.7 SISTEMAS ESPECIALISTAS DE TEORIA DA DECISÃO\\nO campo da \\nanálise da decisão\\n, que evoluiu nas décadas de 1950 e 1960, estuda a aplicação da\\nteoria da decisão a problemas reais de decisão. Ela é utilizada para ajudar na tomada de decisões\\nracionais em domínios importantes em que os riscos são altos, como os de negócios, governo, leis,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 735}),\n",
       " Document(page_content='estratégia militar, diagnóstico médico e saúde pública, projetos de engenharia e gerenciamento de\\nrecursos. O processo envolve um estudo cuidadoso das ações e resultados possíveis, bem como as\\npreferências estabelecidas para cada resultado. É tradicional na análise da decisão mencionar dois\\npapéis: o \\ntomador de decisões\\n enuncia preferências entre resultados e o \\nanalista de decisões\\nenumera as ações e os resultados possíveis, e se baseia nas preferências do tomador de decisões\\npara determinar o melhor curso de ação. Até o início da década de 1980, o principal objetivo da\\nanálise da decisão era ajudar os seres humanos a tomarem decisões que realmente refletissem suas\\npróprias preferências. Como cada vez mais processos de decisão tornam-se automatizados, a análise\\nde decisão é cada vez mais utilizada para garantir que os processos automatizados se comportarão\\ncomo desejado.\\nAs primeiras pesquisas de sistemas especialistas se concentravam em responder a perguntas, e não\\nna tomada de decisões. Esses sistemas, que recomendavam ações em vez de fornecer opiniões sobre\\nas questões em geral, faziam isso utilizando regras de condição-ação, em vez de empregarem\\nrepresentações explícitas de resultados e preferências. O surgimento das redes bayesianas, no final\\nda década de 1980, tornou possível a construção de sistemas em grande escala que geravam\\ninferências probabilísticas consistentes a partir da evidência. A adição de redes de decisão significa\\nque podem ser desenvolvidos sistemas especialistas que recomendem decisões ótimas, refletindo as\\npreferências do usuário, bem como a evidência disponível.\\nUm sistema que incorpora utilidades pode evitar uma das armadilhas mais comuns associadas ao\\nprocesso de consulta: confundir probabilidade e importância. Por exemplo, uma estratégia comum\\nnos primeiros sistemas especialistas médicos era classificar os diagnósticos possíveis em ordem de\\nprobabilidade e informar o mais provável. Infelizmente, isso pode ser desastroso! Para a maioria dos\\npacientes em geral, os dois diagnósticos mais \\nprováveis\\n são normalmente “não há nada de errado\\ncom você” e “você tem um forte resfriado”; porém, se o terceiro diagnóstico mais provável para\\ndeterminado paciente for câncer de pulmão, esse será um assunto sério. É óbvio que um plano de\\nexames ou de tratamento deve depender tanto de probabilidades quanto de utilidades. Os sistemas\\nespecialistas médicos atuais podem levar em conta o valor da informação para recomendar testes e,\\nem seguida, descrever um diagnóstico diferencial.\\nDescreveremos agora o processo de engenharia do conhecimento para sistemas especialistas de\\nteoria da decisão. Como exemplo, consideraremos o problema de selecionar um tratamento médico\\npara uma espécie de doença congênita do coração em crianças (veja Lucas, 1996).\\nCerca de 0,8% das crianças nascem com uma anomalia do coração, sendo a mais comum o\\nestreitamento da aorta\\n (uma constrição da aorta). Essa anomalia pode ser tratada com cirurgia,\\nangioplastia (expandindo-se a aorta com um balão inserido na artéria) ou medicação. O problema é\\ndecidir que tratamento usar e quando fazê-lo: quanto mais jovem for a criança, maiores serão os\\nriscos de certos tratamentos, mas não se deve esperar muito tempo. Um sistema especialista de teoria\\nda decisão para esse problema pode ser criado por uma equipe que consiste em um especialista em\\npelo menos um domínio (um cardiologista pediátrico) e um engenheiro do conhecimento. O processo\\npode ser dividido nas etapas a seguir:\\nCrie um modelo causal.\\n Determine quais são os sintomas possíveis, as doenças, os tratamentos e\\nos resultados. Em seguida, desenhe arcos entre eles, indicando que doenças causam cada um dos\\nsintomas e que tratamentos aliviam os sintomas de cada doença. Alguns desses itens serão bem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 736}),\n",
       " Document(page_content='conhecidos para o especialista do domínio e outros virão da literatura. Com frequência, o modelo\\ncombinará bem com as descrições gráficas informais apresentadas em textos da literatura médica.\\nSimplifique até chegar a um modelo de decisão qualitativa.\\n Tendo em vista que estamos usando\\no modelo para tomar decisões de tratamento e não para outras finalidades (como determinar a\\nprobabilidade conjunta de certas combinações de sintoma/doença), muitas vezes podemos\\nsimplificar, removendo variáveis que não estão envolvidas em decisões de tratamento. Às vezes, as\\nvariáveis terão de ser divididas ou reunidas para corresponder às intuições do especialista. Por\\nexemplo, o modelo original de estreitamento da aorta tinha uma variável \\nTratamento\\n com valores\\ncirurgia\\n, \\nangioplastia\\n e \\nmedicação\\n, e uma variável separada para representar o \\nTiming\\n (o melhor\\nmomento) do tratamento. Porém, o especialista teve dificuldades para considerar essas variáveis\\nseparadamente e, assim, elas foram combinadas, com \\nTratamento\\n assumindo valores como \\ncirurgia\\nem um mês\\n. Isso nos dá o modelo da \\nFigura 16.10\\n.\\nFigura 16.10\\n Diagrama de influência para estreitamento da aorta (cortesia de Peter Lucas).\\nAtribua probabilidades.\\n As probabilidades podem vir de bancos de dados de pacientes, de\\nestudos de literatura ou de avaliações subjetivas do especialista. Observe que um sistema de\\ndiagnóstico vai concluir, a partir de sintomas e outras observações, a doença ou outra causa dos\\nproblemas. Assim, no início dos anos de construção desses sistemas, dado um efeito, era questionado', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 737}),\n",
       " Document(page_content='aos especialistas sobre a probabilidade de determinada causa. Em geral, eles achavam isso difícil de\\nfazer e preferiam avaliar a probabilidade de dado efeito de uma causa. Assim, os sistemas modernos\\nde modo geral avaliam o conhecimento causal e o codificam diretamente na estrutura da rede\\nbayesiana do modelo, deixando o raciocínio do diagnóstico para os algoritmos de inferência da rede\\nbayesiana (Shachter e Heckerman, 1987).\\nAtribua utilidades.\\n Quando existe um número pequeno de resultados possíveis, eles podem ser\\nenumerados e avaliados individualmente utilizando os métodos da \\nSeção 16.3.1\\n. Criaríamos uma\\nescala desde o melhor até o pior resultado e daríamos um valor numérico a cada um, por exemplo, 0\\npara morte e 1 para recuperação completa. Em seguida, colocaríamos os outros resultados nessa\\nescala. Isso pode ser feito pelo especialista,mas será melhor se o paciente (ou, no caso de crianças,\\nos pais do paciente) estiver envolvido porque pessoas diferentes têm preferências diferentes. Se\\nhouver um número exponencialmente grande de resultados, precisaremos de algum modo de\\ncombiná-los usando funções utilidade multiatributo. Por exemplo, podemos dizer que a utilidade\\nnegativa de diversas complicações é aditiva.\\nVerifique e refine o modelo.\\n Para avaliar o sistema, precisaremos de um conjunto de pares\\n(entrada, saída) corretos; um \\npadrão-ouro\\n, como ele é chamado, a fim de servir de base de\\ncomparação. Para sistemas especialistas médicos, em geral isso significa reunir os melhores médicos\\ndisponíveis, apresentar-lhes alguns casos. E pedir-lhes um diagnóstico e um plano de tratamento\\nrecomendado para cada caso. Em seguida, observamos o quanto o sistema corresponde a suas\\nrecomendações. Se o sistema se sair mal, tentaremos isolar e corrigir as partes que geram resultados\\nerrados. Pode ser útil executar o sistema “de trás para a frente”. Em vez de apresentar sintomas ao\\nsistema e solicitar um diagnóstico, podemos apresentar um diagnóstico como “falha do coração”,\\nexaminar a probabilidade prevista de sintomas como taquicardia e compará-la com a literatura\\nmédica.\\nExecute a análise de sensibilidade.\\n Essa importante etapa verifica se a melhor decisão é sensível\\na pequenas mudanças nas probabilidades e utilidades atribuídas pela variação sistemática desses\\nparâmetros e pela execução repetida da avaliação. Se pequenas mudanças levam a decisões\\nsignificativamente diferentes, talvez compense gastar mais recursos para reunir dados melhores. Se\\ntodas as variações levarem à mesma decisão, o usuário terá mais confiança em que essa é a decisão\\ncorreta. A análise de sensibilidade é particularmente importante porque uma das principais críticas\\nàs abordagens probabilísticas para sistemas especialistas se refere à grande dificuldade para avaliar\\nas probabilidades numéricas exigidas. Com frequência, a análise de sensibilidade revela que muitos\\nnúmeros precisam ser especificados apenas de forma muito aproximada. Por exemplo, poderíamos\\nestar inseguros sobre a probabilidade condicional \\nP\\n(\\ntaquicardia\\n | \\ndispneia)\\n, mas, se a decisão ótima\\nfor razoavelmente robusta a variações pequenas na probabilidade, a nossa ignorância é uma\\npreocupação menor.\\n16.8 RESUMO\\nEste capítulo mostrou como combinar a teoria da utilidade com a probabilidade para permitir a um\\nagente selecionar ações que vão maximizar seu desempenho esperado.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 738}),\n",
       " Document(page_content='•  A \\nteoria da probabilidade\\n descreve aquilo em que um agente deve acreditar com base na\\nevidência, a \\nteoria da utilidade descreve\\n o que um agente quer e a \\nteoria da decisão\\n reúne as\\noutras duas para descrever o que um agente deve fazer.\\n•  Podemos usar a teoria da decisão para construir um sistema que toma decisões considerando\\ntodas as ações possíveis e escolhendo aquela que leva ao melhor resultado esperado. Tal\\nsistema é conhecido como \\nagente racional\\n.\\n•  A teoria da utilidade mostra que um agente cujas preferências entre loterias são consistentes com\\num conjunto de axiomas simples pode ser descrito como um agente que possui uma função\\nutilidade.\\n•  A \\nteoria da utilidade multiatributo\\n lida com utilidades que dependem de vários atributos\\ndistintos de estados. A \\ndominância estocástica\\n é uma técnica particularmente útil para a tomada\\nde decisões não ambíguas, mesmo sem valores de utilidade precisos para atributos.\\n•  As \\nredes de decisão\\n fornecem um formalismo simples para expressar e resolver problemas de\\ndecisão. Elas constituem uma extensão natural de redes bayesianas, contendo nós de decisão e de\\nutilidade, além de nós de acaso.\\n•  Às vezes, a resolução de um problema envolve a descoberta de mais informações antes de tomar\\numa decisão. O \\nvalor da informação\\n é definido como a melhora esperada na utilidade, em\\ncomparação com a tomada de uma decisão sem a informação.\\n•  Os \\nsistemas especialistas\\n que incorporam informações de utilidade têm capacidades adicionais\\nem comparação com sistemas de inferência puros. Além de poder tomar decisões, eles podem\\nutilizar o valor da informação para decidir as perguntas a serem feitas, se houver; podem\\nrecomendar planos de contingência e podem calcular a sensibilidade das suas decisões a\\npequenas mudanças nas avaliações de probabilidade e utilidade.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nO livro \\nL’art de penser\\n, também conhecido como \\nPort-Royal Logic\\n (Arnauld, 1662) afirma:\\nPara julgar o que é preciso fazer para obter o bem ou evitar o mal, é necessário considerar não só\\no bem e o mal em si, mas também a probabilidade de que aconteça ou não e visualizar\\ngeometricamente a proporção que todas têm em conjunto.\\nTextos modernos falam de \\nutilidade\\n em vez do bem e do mal, mas essa afirmação observa\\ncorretamente que se deve multiplicar a utilidade pela probabilidade (“visão geométrica”) para dar a\\nutilidade esperada e maximizá-la mais que todos os resultados (“todas essas coisas”) para “julgar o\\nque deve ser feito”. É notável o quanto isso está certo, há 350 anos, e apenas oito anos depois de\\nPascal e Fermat mostrarem como usar corretamente a probabilidade. O \\nPort-Royal Logic\\n também\\nmarcou a primeira publicação da aposta de Pascal.\\nDaniel Bernoulli (1738), investigando o paradoxo de São Petersburgo (veja o Exercício 16.3), foi\\no primeiro a perceber a importância da medição de preferências para loterias, escrevendo que “o\\nvalor\\n de um item não deve se basear em seu \\npreço\\n, mas na \\nutilidade\\n que ele gera” (os grifos são do\\nautor). O filósofo utilitarista Jeremy Bentham (1823) propôs o \\ncálculo hedônico\\n para ponderar', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 739}),\n",
       " Document(page_content='“prazeres” e “dores”, argumentando que todas as decisões (não apenas as decisões monetárias)\\npoderiam ser reduzidas a comparações entre utilidades.\\nA derivação de utilidades numéricas a partir de preferências foi realizada primeiro por Ramsey\\n(1931); os axiomas para preferência neste texto estão mais próximos em forma aos que foram\\nredescobertos na \\nTheory of Games and Economic Behavior\\n (von Neumann e Morgenstern, 1944).\\nUma boa apresentação desses axiomas, no curso de uma discussão sobre preferência de risco, é feita\\npor Howard (1977). Ramsey derivou probabilidades subjetivas (não apenas utilidades) a partir das\\npreferências de um agente; Savage (1954) e Jeffrey (1983) elaboram construções mais recentes desse\\ntipo. Von Winterfeldt e Edwards (1986) fornecem uma perspectiva moderna sobre a análise da\\ndecisão e seu relacionamento com as estruturas de preferências humanas. A medida de utilidade\\nmicromorte é discutida por Howard (1989). Um levantamento feito em 1994 pelo \\nEconomist\\n definiu\\no valor de uma vida entre US$750.000 e US$2,6 milhões. Porém, Richard Thaler (1992) descobriu\\nefeitos irracionais de enquadramento sobre os preços que alguém está disposto a pagar para evitar o\\nrisco de morrer, em comparação com o preço que alguém está disposto a receber para aceitar um\\nrisco. Para uma chance de 1/1.000, uma pessoa consultada não pagaria mais de $200 para remover o\\nrisco, mas não aceitaria $50.000 para assumir o risco. O quanto as pessoas estão dispostas a pagar\\npor um QALY? Quando se trata de um caso específico de salvar a si mesmo ou a um membro da\\nfamília, o número é aproximadamente “o que eu tiver”. Mas podemos perguntar em nível social:\\nsuponha que exista uma vacina que produziria X QALYs mas custa Y dólares; vale a pena? Nesse\\ncaso, as pessoas relatam ampla gama de valores de cerca de $10.000-150.000 por QALY (Prades \\net\\nal\\n., 2008). Os QALYs são muito mais extensamente usados na tomada de decisões médicas e de\\npolítica social que as micromortes; veja em Russell (1990) um exemplo típico de argumento para\\numa mudança importante na política de saúde pública, com base no aumento da utilidade esperada\\nmedida em QALYs.\\nSmith e Winkler (2006) trouxeram de maneira firme a \\nmaldição do otimizador\\n à vista dos\\nanalistas de decisão, que apontaram que os benefícios financeiros projetados para o cliente pelos\\nanalistas para o curso da ação proposta quase nunca se materializavam. Eles traçaram isso\\ndiretamente a partir da tendência introduzida de selecionar uma ação ideal e mostraram que uma\\nanálise bayesiana mais completa elimina o problema. O mesmo conceito subjacente foi chamado de\\ndecepção pós-decisão\\n por Harrison e March (1984) e foi observado no contexto da análise de\\nprojetos de investimento de capital por Brown (1974). A maldição do otimizador está também\\nintimamente relacionada com a maldição do vencedor (Cape \\net al\\n., 1971; Thaler, 1992), que se\\naplica à licitação em leilões: quem ganha o leilão é muito provável que tenha superestimado o valor\\ndo objeto em questão. Cape \\net al\\n. citaram um engenheiro de petróleo no tema de licitação para\\nexploração de direitos de petróleo: “Se alguém ganha um trato contra dois ou três outros pode sentir-\\nse bem sobre a sua boa sorte. Mas como se sentiria se ganhasse contra 50 outras pessoas?”\\nFinalmente, por trás das duas maldições existe o fenômeno geral da \\nregressão à média\\n, segundo a\\nqual os indivíduos selecionam com base em características excepcionais do desejo previamente\\nexposto, com alta probabilidade de tornarem-se menos excepcionais no futuro.\\nO paradoxo de Allais, devido ao ganhador do Prêmio Nobel, o economista Maurice Allais (1953),\\nfoi testado experimentalmente (Tversky e Kahneman, 1982; Conlisk, 1989) para mostrar que as\\npessoas são consistentemente inconsistentes em seus julgamentos. O paradoxo de Ellsberg sobre a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 740}),\n",
       " Document(page_content='aversão à ambiguidade foi introduzido na tese de Ph.D. de Daniel Ellsberg (Ellsberg, 1962), que\\npassou a ser analista militar da Corporação RAND e vazou documentos conhecidos como The\\nPentagon Papers, o que contribuiu para o fim da guerra do Vietnã e a renúncia do presidente Nixon.\\nFox e Tversky (1995) descrevem um estudo mais aprofundado de aversão à ambiguidade. Mark\\nMachina (2005) dá uma visão geral de escolha sob incerteza e como ela pode variar da teoria da\\nutilidade esperada.\\nHouve uma manifestação recente de livros populares sobre a irracionalidade humana. O mais\\nconhecido é \\nPredictably Irrational\\n (Ariely, 2009); outros incluem \\nSway\\n (Brafman e Brafman, 2009),\\nNudge\\n (Thaler e Sunstein, 2009), \\nKluge\\n (Marcus, 2009), \\nHow We Decide\\n (Lehrer, 2009) e \\nOn Being\\nCertain\\n (Burton, 2009). Eles complementam o clássico (Kahneman \\net al\\n., 1982) e o artigo que\\ncomeçou isso tudo (Kahneman e Tversky, 1979). O campo da psicologia evolutiva (Buss, 2005), por\\noutro lado, é contrário a essa literatura, argumentando que os seres humanos são muito racionais em\\ncontextos evolutivamente adequados. Seus adeptos apontam que a irracionalidade é penalizada, por\\ndefinição, em um contexto evolutivo e mostra que, em alguns casos, é um artefato de configuração\\nexperimental (Cummins e Allen, 1998). Houve ressurgimento recente do interesse em modelos\\nbayesianos de cognição, derrubando décadas de pessimismo (Oaksford e Chater, 1998; Elio, 2002;\\nChater e Oaksford, 2008).\\nKeeney e Raiffa (1976) fornecem uma introdução completa à teoria da utilidade multiatributo. Eles\\ndescrevem as primeiras implementações de computador de métodos para extrair os parâmetros\\nnecessários a uma função utilidade multiatributo e incluem uma extensiva relação de aplicações reais\\nda teoria. Em IA, a principal referência para MAUT é o trabalho de Wellman (1985), que inclui um\\nsistema chamado URP (Utility Reasoning Package), que pode usar uma coleção de declarações sobre\\na independência de preferências e a independência condicional para analisar a estrutura de\\nproblemas de decisão. O uso da dominância estocástica, juntamente com modelos de probabilidade\\nqualitativos, foi extensamente investigado por Wellman (1988, 1990a). Wellman e Doyle (1992)\\nfornecem um esboço preliminar de como um conjunto complexo de relacionamentos de\\nindependência de utilidade poderia ser utilizado para fornecer um modelo estruturado de uma função\\nutilidade, de modo muito semelhante à forma como as redes bayesianas fornecem um modelo\\nestruturado de distribuições de probabilidade conjunta. Bacchus e Grove (1995, 1996) e também La\\nMura e Shoham (1999) apresentam resultados adicionais que seguem essas linhas.\\nA teoria da decisão tem sido uma ferramenta padrão em economia, finanças e gestão desde a\\ndécada de 1950. Até os anos 1980, as árvores de decisão eram a principal ferramenta utilizada para\\nrepresentar problemas de decisão simples. Smith (1988) fornece uma visão geral da \\nmetodologia\\n da\\nanálise da decisão. As redes de decisão ou diagramas de influência foram introduzidas por Howard e\\nMatheson (1984), com base em trabalho anterior no SRI (Miller \\net al\\n., 1976). O método de Howard\\ne Matheson envolvia a derivação de uma árvore de decisão a partir de uma rede de decisão, mas, em\\ngeral, a árvore tem tamanho exponencial. Shachter (1986) desenvolveu um método para tomada de\\ndecisões baseado diretamente em uma rede de decisão, sem a criação de uma árvore de decisão\\nintermediária. Esse algoritmo também foi um dos primeiros a fornecer inferência completa para\\nredes bayesianas com várias conexões. Zhang \\net al.\\n (1994) mostraram como tirar vantagem da\\nindependência condicional de informação para reduzir o tamanho das árvores na prática; eles\\nutilizaram a expressão \\nrede de decisão\\n para redes que usam essa abordagem (embora outros a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 741}),\n",
       " Document(page_content='utilizem como sinônimo de diagrama de influência). O trabalho recente de Nilsson e Lauritzen (2000)\\nvincula algoritmos para redes de decisão a desenvolvimentos contínuos em algoritmos de formação\\nde agrupamentos para redes bayesianas. Koller e Milch (2003) mostram como os diagramas de\\ninfluência podem ser usados para resolver jogos que envolvem a coleta de informações por\\njogadores adversários, e Detwarasiti e Shachter (2005) mostram como diagramas de influência\\npodem ser usados como auxílio para a tomada de decisão por uma equipe que compartilha objetivo\\nmas é incapaz de compartilhar todas as informações perfeitamente. A coleção de Oliver e Smith\\n(1990) tem vários artigos úteis sobre redes de decisão, como também o número especial de 1990 do\\nperiódico \\nNetworks\\n. Os artigos sobre redes de decisão e modelagem de utilidade também aparecem\\nregularmente nos periódicos \\nManagement Science\\n e \\nDecision Analysis\\n.\\nA teoria do valor da informação foi explorada em primeiro lugar no contexto de experimentos\\nestatísticos, onde foi utilizada uma quase utilidade (redução da entropia) (Lindley, 1956). O teórico\\nde controle russo Ruslan Stratonovich (1965) desenvolveu a teoria mais geral aqui apresentada, em\\nque a informação tem valor em virtude de sua capacidade de afetar decisões. O trabalho de\\nStratonovich não era conhecido no Ocidente, onde Ron Howard (1966) foi pioneiro com a mesma\\nideia. Seu papel termina com a observação: “Se a teoria da informação de valor e as estruturas\\nteóricas associadas à decisão no futuro não ocuparem grande parte da educação de engenheiros, a\\nprofissão de engenharia vai achar que seu papel tradicional de gestão dos recursos científicos e\\neconômicos para o benefício do homem foi perdida para outra profissão.” Até o momento, a\\nrevolução que implica métodos de gestão não ocorreu.\\nO trabalho recente de Krause e Guestrin (2009) mostra que o cálculo do valor não míope exato da\\ninformação é intratável, mesmo em redes de múltiplas árvores. Há outros casos — mais restritos do\\nque o valor geral de informações — em que o algoritmo míope prevê uma aproximação\\ncomprovadamente boa para a sequência ótima de observações (Krause \\net al\\n., 2008). Em alguns casos\\n— por exemplo, à procura de um tesouro enterrado em um dos \\nn\\n lugares —, experimentos em ordem\\nde probabilidade de sucesso dividido pelo custo fornecem uma solução ótima (Kadane e Simon,\\n1977).\\nSurpreendentemente, poucos pesquisadores de IA adotaram ferramentas de teoria da decisão\\ndepois das primeiras aplicações em tomada de decisões médicas descritas no Capítulo 13. Uma das\\npoucas exceções foi Jerry Feldman, que aplicou a teoria da decisão a problemas da visão (Feldman e\\nYakimovsky, 1974) e de planejamento (Feldman e Sproull, 1977). Depois do ressurgimento do\\ninteresse em métodos probabilísticos em IA, na década de 1980, os sistemas especialistas de teoria\\nda decisão ganharam ampla aceitação (Horvitz \\net al.\\n; Cowell \\net al\\n., 2002). De fato, de 1991 em\\ndiante, o projeto de capa do periódico \\nArtificial Intelligence\\n passou a representar uma rede de\\ndecisão, embora pareça ter sido adotada alguma licença artística na orientação das setas.\\nEXERCÍCIOS\\n16.1\\n (Adaptado de David Heckerman.) Este exercício se refere ao \\nAlmanac Game\\n, utilizado por\\nanalistas de decisões para calibrar estimativas numéricas. Para cada uma das perguntas que seguem,\\nforneça seu melhor palpite sobre a resposta, isto é, um número que você imagina ter a mesma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 742}),\n",
       " Document(page_content='probabilidade de ser muito alto quanto de ser muito baixo. Também dê seu palpite em uma estimativa\\nde 25\\no\\n percentil, ou seja, um número que você imagina ter uma chance de 25% de ser muito alto e\\numa chance de 75% de ser muito baixo. Faça o mesmo para o 75\\no\\n percentil. (Desse modo, você deve\\nfornecer três estimativas ao todo — baixa, mediana e alta — para cada pergunta.)\\na.\\n Número de passageiros que voaram entre Nova York e Los Angeles em 1989.\\nb.\\n População de Varsóvia em 1992.\\nc.\\n Ano em que Coronado descobriu o rio Mississippi.\\nd.\\n Número de votos recebidos por Jimmy Carter na eleição presidencial de 1976.\\ne.\\n Idade da árvore viva mais antiga em 2002.\\nf.\\n A altura da represa Hoover em pés.\\ng.\\n Número de ovos produzidos no Oregon em 1985.\\nh.\\n Número de budistas no mundo em 1992.\\ni.\\n Número de mortes por aids nos Estados Unidos em 1981.\\nj.\\n Número de patentes concedidas nos Estados Unidos em 1901.\\nAs respostas corretas aparecem depois do último exercício deste capítulo. A partir do ponto de vista\\nda análise da decisão, o detalhe interessante não é o quanto seus palpites medianos se aproximaram\\ndas respostas reais, mas a frequência com que a resposta real ficou dentro de seus limites de 25% e\\n75%. Se essa frequência foi de aproximadamente metade do tempo, seus limites são precisos. Porém,\\nse for como a maioria das pessoas, você estará mais seguro de si do que deveria estar porque, nesse\\ncaso, menos da metade das respostas ficará dentro dos limites. Com a prática, você poderá ajustar\\nsuas respostas a limites realistas e, desse modo, será mais útil para fornecer informações que serão\\nusadas na tomada de decisões. Tente este segundo conjunto de perguntas e veja se há alguma\\nmelhora:\\na.\\n Ano de nascimento de Zsa Zsa Gabor.\\nb.\\n Distância máxima de Marte ao Sol em milhas.\\nc.\\n Valor em dólares das exportações de trigo dos Estados Unidos em 1992.\\nd.\\n Toneladas de mercadorias manipuladas no Porto de Honolulu em 1991.\\ne.\\n Salário anual em dólares do governador da Califórnia em 1993.\\nf.\\n População de San Diego em 1990.\\ng.\\n Ano em que Roger Williams fundou Providence, em Rhode Island.\\nh.\\n Altura do monte Kilimanjaro em pés.\\ni.\\n Extensão da Ponte de Brooklyn em pés.\\nj.\\n Número de mortes em acidentes automobilísticos nos Estados Unidos em 1992.\\n16.2\\n Chris considera cinco carros usados antes de comprar um com utilidade máxima esperada. Pat\\nconsidera 11 carros e faz o mesmo. Considerando o restante equivalente, quem provavelmente terá o\\nmelhor carro? Quem tem mais probabilidade de ficar decepcionado com a qualidade do carro? Por\\nquanto (em termos do desvio-padrão da qualidade esperada)?', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 743}),\n",
       " Document(page_content='16.3\\n Em1713, Nicolas Bernoulli expôs um quebra-cabeças, hoje chamado de paradoxo de São\\nPetersburgo, que funciona assim: você tem a oportunidade de participar de um jogo em que uma\\nmoeda imparcial é lançada repetidamente até dar o resultado cara. Se o primeiro resultado cara\\naparecer no \\nn\\n-ésimo lançamento, você ganha 2\\nn\\n dólares.\\na.\\n Mostre que o valor monetário esperado desse jogo é infinito.\\nb.\\n Quanto você pessoalmente pagaria para participar do jogo?\\nc.\\n O primo de Nicolas, Daniel Bernoulli, resolveu o aparente paradoxo em 1738 sugerindo que a\\nutilidade do dinheiro é medida em uma escala logarítmica (isto é, \\nU\\n(\\nS\\nn\\n) = \\na\\n log\\n2\\n \\nn\\n + \\nb\\n, onde \\nS\\nn\\né o estado de ter $\\nn\\n). Qual é a utilidade esperada do jogo sob essa hipótese?\\nd.\\n Qual quantia máxima seria racional pagar para participar do jogo, supondo-se que a riqueza\\ninicial de alguém seja $\\nk\\n ?\\n16.4\\n Escreva um programa de computador para automatizar o processo no Exercício 16.9.\\nExperimente seu programa com diversas pessoas de diferentes perspectivas e visões políticas.\\nComente a consistência de seus resultados, tanto para um indivíduo quanto para diversos indivíduos.\\n16.5\\n A Companhia de Doces Surpresa fabrica doces de dois sabores: 70% são de sabor morango e\\n30% são de sabor anchova. Cada novo pedaço de doce começa com uma forma redonda; à medida\\nque se move ao longo da linha de produção, uma máquina seleciona aleatoriamente determinada\\nporcentagem a ser aparada em um quadrado; então, cada peça é acondicionada em uma embalagem\\ncuja cor é escolhida aleatoriamente, podendo ser vermelho ou marrom. Oitenta por cento dos doces\\nde morango são redondos e 80% têm embalagem vermelha, enquanto 90% dos doces de anchova são\\nquadrados e 90% têm embalagem marrom. Todos os doces são vendidos individualmente em caixas\\npretas, lacradas e idênticas.\\nAgora você, o cliente, acabou de comprar um doce Surpresa na loja, mas ainda não abriu a caixa.\\nConsidere as três redes de Bayes na \\nFigura 16.11\\n.\\nFigura 16.11\\n Três redes de Bayes propostas para o problema Doce Surpresa, Exercício 16.5.\\na.\\n Que rede pode representar corretamente \\nP\\n(\\nSabor\\n, \\nEmbalagem\\n, \\nForma\\n)?\\nb.\\n Qual rede é a melhor representação para esse problema?\\nc.\\n A rede (i) afirma que \\nP\\n(\\nEmbalagem\\n | \\nForma\\n) = \\nP\\n(\\nEmbalagem\\n)?\\nd.\\n Qual é a probabilidade de que seu doce tenha embalagem vermelha?\\ne.\\n Na caixa há um doce redondo com embalagem vermelha. Qual a probabilidade de que seu sabor\\nseja morango?\\nf.\\n Um doce de morango desembrulhado vale \\ns\\n no mercado aberto e um doce de anchova', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 744}),\n",
       " Document(page_content='desembrulhado vale \\na\\n. Escreva uma expressão para o valor de uma caixa de doces fechada.\\ng.\\n Uma nova lei proíbe o comércio de doces desembrulhados, mas ainda é legal vender doces na\\nembalagem (fora da caixa). Agora uma caixa de doces fechado vale mais ou menos, ou o mesmo\\ndo que antes?\\n16.6\\n Demonstre que os julgamentos \\nB\\n \\n \\nA\\n e \\nC\\n \\n \\nD\\n no paradoxo de Allais violam o axioma da\\nsubstitutibilidade.\\n16.7\\n Considere o paradoxo de Allais: um agente que prefere \\nB\\n sobre \\nA\\n (fazendo tudo certo) e \\nC\\nsobre \\nD\\n (escolhendo o maior VME) não está agindo racionalmente, de acordo com a teoria da\\nutilidade. Você acha que isso indica um problema para o agente, um problema para a teoria ou\\nnenhum problema? Explique.\\n16.8\\n Os bilhetes de uma loteria custam $1. Há dois prêmios possíveis: pagamento de $10 com\\nprobabilidade de 1/50 e o pagamento de $1.000.000 com probabilidade de 1/2.000.000. Qual seria o\\nvalor monetário esperado de um bilhete de loteria? Quando (se em algum caso) é racional comprar\\num bilhete de loteria? Seja preciso – mostre uma equação que envolva utilidades. Você pode assumir\\na riqueza atual de $\\nk\\n e que U(\\nS\\nk\\n) = 0. Assuma também que U(S\\nk\\n+10\\n) = 10 × U(S\\nk\\n+1\\n), mas não faça\\nnenhuma suposição em relação a U(\\nS\\nk\\n+1.000.000\\n). Estudos sociológicos mostram que as pessoas com\\nmenos renda compram uma quantidade desproporcional de bilhetes de loteria. Você considera que\\nisso se deve a eles não serem bons tomadores de decisão ou porque possuem uma função utilidade\\ndiferente? Considere o valor de contemplar a possibilidade de ganhar na loteria versus o valor de ser\\ncontemplado em se tornar um herói de ação ao assistir a um filme de aventura.\\n16.9\\n Avalie sua própria utilidade para quantidades incrementais diferentes de dinheiro, executando\\numa série de testes de preferência entre alguma quantia definida \\nM\\n1\\n e uma loteria [\\np\\n, \\nM\\n2\\n; (1 – \\np\\n), 0].\\nEscolha valores diferentes de \\nM\\n1\\n e \\nM\\n2\\n, e faça \\np\\n variar até ficar indiferente entre as duas escolhas.\\nRepresente a função utilidade resultante.\\n16.10\\n Quanto vale para você uma micromorte? Crie um protocolo para definir isso. Faça perguntas\\nbaseadas no pagamento para evitar o risco e a possibilidade de receber para aceitar o risco.\\n16.11\\n Considere as variáveis contínuas \\nX\\n1\\n,…, \\nX\\nk\\n distribuídas independentemente de acordo com a\\nmesma função de densidade de probabilidade \\nf\\n(\\nx\\n). Demonstre que a função de densidade para\\nmax{\\nX\\n1\\n,…, \\nX\\nk\\n} é dada por \\nkf\\n (\\nx\\n) (\\nF\\n (\\nx\\n))\\nk\\n-1\\n, onde \\nF\\n é a distribuição cumulativa de \\nf\\n.\\n16.12\\n Os economistas muitas vezes fazem uso de uma função utilidade exponencial para o dinheiro:\\nU\\n(\\nx\\n) = −\\ne\\nx/R\\n, onde \\nR\\n é uma constante positiva que representa a tolerância ao risco do indivíduo. A\\ntolerância ao risco reflete a probabilidade de um indivíduo aceitar uma loteria com valor monetário\\nesperado em particular (VME) \\nversus\\n algum retorno certo. Como \\nR\\n (que é medido na mesma unidade\\nque \\nx\\n) torna-se maior, o indivíduo torna-se menos avesso ao risco.\\na.\\n Assuma que Maria tem uma função utilidade exponencial com \\nR\\n = $500. Maria pode escolher\\nentre receber $500 com certeza (probabilidade 1) ou participar de uma loteria que tenha\\nprobabilidade de 60% de ganhar $5.000 e probabilidade de 40% de não ganhar nada.\\nAssumindo que Maria age racionalmente, qual opção ela vai escolher? Mostre como você\\nderivou sua resposta.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 745}),\n",
       " Document(page_content='b.\\n Considere a escolha entre ter certeza de receber $100 (probabilidade 1) ou participar de uma\\nloteria que tenha probabilidade de 50% de ganhar e 50% de não ganhar nada. O valor\\naproximado de \\nR\\n (com três dígitos significativos) em uma função utilidade exponencial faria\\ncom que um indivíduo fosse indiferente a essas duas alternativas (pode ser útil codificar um\\nprograma pequeno para ajudar a resolver esse problema).\\n16.13\\n Repita o Exercício 16.16 usando a representação de ação-utilidade mostrada na \\nFigura 16.7\\n.\\n16.14\\n Para qualquer dos diagramas de localização do aeroporto dos Exercícios 16.16 e 16.13, a qual\\nitem da tabela de probabilidade condicional a utilidade é mais sensível, dada a evidência\\ndisponível?\\n16.15\\n Considere um aluno que tenha a opção de comprar ou não um livro para um curso.\\nModelaremos isso como um problema de decisão com um nó de decisão booleano, \\nB\\n, indicando se o\\nagente optou por comprar o livro, e dois nós de acaso booleanos, \\nM\\n, indicando se o aluno dominou o\\nmaterial no livro, e \\nP\\n, indicando se o aluno passou no curso. Claro, há também um nó de utilidade, \\nU\\n.\\nDeterminado aluno, Sam, tem uma função utilidade aditiva: 0 para não comprar o livro e –$100 para\\ncomprá-lo; $2.000 para passar no curso e 0 para não passar. Segue as estimativas de probabilidade\\ncondicionais de Sam:\\nP\\n(\\np\\n | \\nb\\n, \\nm\\n) = 0,9\\nP\\n(\\np\\n | \\nb\\n, ¬\\nm\\n) = 0,5\\nP\\n(\\np\\n | ¬\\nb\\n, \\nm\\n) = 0,8\\nP\\n(\\np\\n | ¬\\nb\\n, ¬\\nm\\n) = 0,3\\nP\\n(\\nm\\n | \\nb\\n) = 0,9\\nP\\n(\\nm\\n | ¬\\nb\\n) = 0,7\\nVocê pode pensar que \\nP\\n seria independente de \\nB\\n dado \\nM\\n, mas nese curso, ao final, pode-se utilizar o\\nlivro; assim, ter o livro ajuda.\\na.\\n Desenhe a rede de decisão para esse problema.\\nb.\\n Calcule a utilidade esperada de comprar o livro e de não comprá-lo.\\nc.\\n O que Sam deve fazer?\\n16.16\\n Este exercício completa a análise do problema de localização do aeroporto da \\nFigura\\n16.6\\n.\\na.\\n Forneça domínios de variáveis, probabilidades e utilidades razoáveis para a rede supondo que\\nexistam três locais possíveis.\\nb.\\n Resolva o problema de decisão.\\nc.\\n O que acontecerá se as mudanças na tecnologia indicarem que cada aeronave gera metade do\\nruído?\\nd.\\n E se evitar o ruído se tornar três vezes mais importante?\\ne.\\n Calcule o VIP para \\nTráfegoAéreo\\n, \\nLitígio\\n e \\nConstrução\\n em seu modelo.\\n16.17\\n (Adaptado de Pearl (1988).) Um comprador de carros usados pode decidir realizar vários', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 746}),\n",
       " Document(page_content='testes com diversos custos (por exemplo, chutar os pneus, levar o carro a um mecânico qualificado) e\\ndepois, dependendo do resultado dos testes, decidir que carro comprar. Vamos supor que o\\ncomprador esteja decidindo comprar o carro \\nc\\n1\\n, que exista tempo para executar no máximo um teste e\\nque \\nt\\n1\\n é o teste de \\nc\\n1\\n e custa $50.\\nUm carro pode estar em bom estado (qualidade \\nθ\\n+\\n) ou em mau estado (qualidade \\nq–\\n) e os testes\\npodem ajudar a indicar em que estado o carro se encontra. O carro \\nc\\n1\\n custa $1.500 e seu valor\\nde mercado é $2.000, se estiver em bom estado; caso contrário, serão necessários $700 em\\nreparos para colocá-lo em boas condições. A estimativa do comprador é que \\nc\\n1\\n tem uma chance\\nde 70% de se encontrar em bom estado.\\na.\\n Desenhe a rede de decisão que representa esse problema.\\nb.\\n Calcule o ganho líquido esperado da compra de \\nc\\n1\\n sem a realização de qualquer teste.\\nc.\\n Os testes podem ser descritos pela probabilidade de o carro ser aprovado (passar) ou ser\\nreprovado (não passar) no teste, dado que o carro está em bom estado ou mau estado. Temos as\\nseguintes informações:\\nP\\n(\\npassar\\n(\\nc\\n1\\n, \\nt\\n1\\n)|\\nθ\\n+ (\\nc\\n1\\n)) = 0,8\\nP\\n(\\npassar\\n(\\nc\\n1\\n,\\nt\\n1\\n)\\n|q\\n– (\\nc\\n1\\n)) = 0,35\\nUse o teorema de Bayes para calcular a probabilidade de o carro passar (ou ser reprovado)\\nem seu teste e, consequentemente, a probabilidade de que ele esteja em bom (ou mau) estado,\\ndado cada resultado de teste possível.\\nd.\\n Calcule as decisões ótimas dada uma aprovação ou reprovação no teste e suas utilidades\\nesperadas.\\ne.\\n Calcule o valor da informação do teste e derive um plano condicional ótimo para o comprador.\\n16.18\\n Lembre-se da definição do \\nvalor da informação\\n na \\nSeção 16.6\\n.\\na.\\n Demonstre que o valor da informação é não negativo e independente de ordem.\\nb.\\n Explique por que algumas pessoas preferem não obter informação — por exemplo, não querer\\nsaber o sexo do bebê quando é feito um ultrassom.\\nc.\\n Uma função \\nf\\n sobre conjuntos é \\nsubmodular\\n se, para qualquer elemento de \\nx\\n e quaisquer\\nconjuntos \\nA\\n e \\nB\\n tal que A \\n B acrescentar \\nx\\n a \\nA\\n gera maior aumento em \\nf\\n que adicionar \\nx\\n a \\nB\\n:\\nA submodularidade capta a noção intuitiva de \\nretornos decrescentes\\n. O valor da informação é\\nvisto como uma função \\nf\\n sobre conjuntos de observações possíveis, submodulares? Demonstre\\nou encontre um contraexemplo.\\nAs respostas do Exercício 16.1 (onde M representa um milhão) são: primeiro conjunto: 3M, 1,6M,\\n1.541, 41M, 4.768, 221, 649M, 295M, 132, 25.546; segundo conjunto: 1.917, 155M, 4.500M, 11M,\\n120.000, 1,1M, 1.636, 19.340, 1.595, 41.710.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 747}),\n",
       " Document(page_content='1\\n A teoria da decisão clássica deixa o estado atual \\nS\\n0\\n implícito, mas podemos torná-lo explícito, escrevendo \\nP\\n(RESULTADO (\\na\\n) = \\ns\\n′ | \\na\\n,\\ne\\n) Σ\\ns\\n \\nP\\n(RESULTADO (\\ns\\n, \\na\\n) = \\ns\\n′ | \\na\\n)\\nP\\n(\\nS\\n0\\n = \\ns\\n | \\ne\\n).\\n2\\n Pedimos desculpas aos leitores cujas companhias aéreas locais não mais oferecem refeições em voos longos.\\n3\\n Podemos levar em conta o prazer de jogar codificando eventos de jogos na descrição do estado; por exemplo, “Tem 10 reais e jogou”\\ntalvez fosse preferível a “Tem 10 reais e não jogou”.\\n4\\n Nesse sentido, utilidades assemelham-se às temperaturas: a temperatura em Fahrenheit é 1,8 vez a temperatura em graus Celsius mais\\n32. Você obtém os mesmos resultados em qualquer sistema de medição.\\n5\\n Tal comportamento poderia ser chamado de desesperado, mas é racional se alguém já está em situação desesperada.\\n6\\n Por exemplo, o matemático/mágico Persi Diaconis pode fazer o lançamento de uma moeda sair do jeito que ele quer todas as vezes\\n(Landhuis, 2004).\\n7\\n Mesmo o que é certo pode não ser seguro. Apesar de promessas fortes, ainda não recebemos os 27 milhões de dólares da conta\\nbancária nigeriana de um parente falecido até então desconhecido.\\n8\\n Em alguns casos, talvez seja necessário subdividir o intervalo de valores de tal forma que a utilidade varie monotonicamente dentro de\\ncada intervalo. Por exemplo, se o atributo \\nTemperaturaSala\\n tiver um pico de utilidade a 21°C, o dividiremos em dois atributos medindo a\\ndiferença do ideal, um mais frio e outro mais quente. A utilidade seria, então, monotonicamente crescente em cada atributo.\\n9\\n Esses nós são chamados \\nnós de valor\\n na literatura.\\n10\\n Nos Estados Unidos, a única pergunta que sempre é feita de antemão é se o paciente tem plano de saúde.\\n11\\n Não há perda de expressividade em exigir informação perfeita. Suponha que quiséssemos modelar o caso em que nos tornamos um\\npouco mais certos sobre uma variável. Podemos fazer isso através da introdução de outra variável sobre a qual aprendemos a\\ninformação perfeita. Por exemplo, suponha que inicialmente tenhamos ampla incerteza sobre a variável \\ntemperatura\\n. Então, obtemos o\\nconhecimento perfeito \\nTermômetro\\n = 37; isso nos dá uma informação imperfeita sobre a \\nTemperatura\\n verdadeira e a incerteza devida\\nao erro de medição estar codificado no modelo de sensor \\nP\\n(\\nTermômetro\\n | \\nTemperatura\\n). Consulte o Exercício 16.17 para outro\\nexemplo.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 748}),\n",
       " Document(page_content='N\\nCAPÍTULO\\n \\n17\\nTomada de decisões complexas\\nEm que examinamos métodos para decidir o que fazer hoje, dado que podemos\\ndecidir novamente amanhã.\\neste capítulo, abordaremos as questões computacionais envolvidas na tomada de decisões em\\nambiente estocástico. Enquanto o Capítulo 16 estava preocupado com problemas de decisão\\ninstantânea ou episódica, em que a utilidade do resultado de cada ação era bem conhecida, aqui\\nvamos nos preocupar com \\nproblemas de decisão sequencial\\n, em que a utilidade do agente depende\\nde uma sequência de decisões. Problemas de decisão sequencial incorporam utilidades, incerteza e\\npercepção, e incluem os problemas de busca e planejamento como casos especiais. A \\nSeção 17.1\\nexplica como os problemas de decisão sequencial são definidos, e as Seções 17.2 e 17.3 explicam\\ncomo eles podem ser resolvidos para gerar um comportamento ótimo que equilibre os riscos e as\\nrecompensas de agir em um ambiente incerto. A \\nSeção 17.4\\n estende essas ideias ao caso de\\nambientes parcialmente observáveis, e a \\nSeção 17.4.3\\n desenvolve um projeto completo para agentes\\nde teoria da decisão em ambientes parcialmente observáveis, combinando as redes bayesianas\\ndinâmicas do Capítulo 15 com as redes de decisão do Capítulo 16.\\nA segunda parte do capítulo cobre ambientes com múltiplos agentes. Em tais ambientes, a noção\\nde comportamento ótimo se torna muito mais complicada pelas interações entre os agentes. A \\nSeção\\n17.5\\n introduz as principais ideias da \\nteoria dos jogos\\n, inclusive a ideia de que agentes racionais\\ntalvez precisem se comportar de modo aleatório. A \\nSeção 17.6\\n examina como os sistemas\\nmultiagente podem ser projetados para que vários agentes possam alcançar um objetivo comum.\\n17.1 PROBLEMAS DE DECISÃO SEQUENCIAL\\nSuponha que um agente esteja situado no ambiente 4 × 3 mostrado na \\nFigura 17.1\\n(a). Começando\\nno estado inicial, ele deve escolher uma ação em cada passo de tempo. A interação com o ambiente\\ntermina quando o agente alcança um dos estados objetivos, marcados com +1 ou –1. Assim como\\npara problemas de busca, as ações disponíveis para o agente em cada estado são dadas por\\nAÇÕES(\\ns\\n), algumas vezes abreviado como \\nA\\n(\\ns\\n); no ambiente 4 × 3, as ações em todos os estados são\\nAcima\\n, \\nAbaixo\\n, \\nEsquerda\\n e \\nDireita\\n.Vamos supor, por enquanto, que o ambiente seja \\ncompletamente\\nobservável\\n, de forma que o agente sempre saiba onde está.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 750}),\n",
       " Document(page_content='Figura 17.1\\n (a) Um ambiente simples de 4 × 3 que apresenta ao agente um problema de decisão\\nsequencial. (b) Ilustração do modelo de transição do ambiente: o resultado “pretendido” ocorre com\\nprobabilidade 0,8, mas com probabilidade 0,2 o agente se move em um ângulo reto em relação à\\ndireção pretendida. Uma colisão com uma parede resulta em nenhum movimento. Os dois estados\\nterminais têm recompensa +1 e –1, respectivamente, e todos os outros estados têm recompensa –0,04.\\nSe o ambiente fosse determinístico, seria fácil encontrar uma solução: [\\nAcima\\n, \\nAcima\\n, \\nDireita\\n,\\nDireita\\n, \\nDireita\\n]. Infelizmente, o ambiente nem sempre responderá como esperado com essa solução\\nporque as ações são pouco confiáveis. O modelo específico de movimento estocástico que adotamos\\nestá ilustrado na \\nFigura 17.1\\n(b). Cada ação alcança o efeito pretendido com probabilidade 0,8, mas,\\nno restante do tempo, a ação move o agente em ângulos retos até a direção pretendida. Além disso, se\\no agente bater em uma parede, ele permanecerá no mesmo quadrado. Por exemplo, a partir do\\nquadrado inicial (1,1), a ação \\nAcima\\n move o agente para (1,2) com probabilidade 0,8, mas, com\\nprobabilidade 0,1, ele se move para a direita até (2,1) e, com probabilidade 0,1, ele se move para a\\nesquerda, choca-se com a parede e fica em (1,1). Em tal ambiente, a sequência [\\nAcima\\n, \\nAcima\\n,\\nDireita\\n, \\nDireita\\n, \\nDireita\\n] contorna a barreira e alcança o estado de meta em (4,3) com probabilidade\\n0,8\\n5\\n = 0,32768. Também existe uma pequena chance de atingir acidentalmente a meta indo por outro\\ncaminho, com probabilidade 0,1\\n4\\n × 0,8, dando um total geral igual a 0,32776 (veja também o\\nExercício 17.1).\\nComo no Capítulo 3, o \\nmodelo de transição\\n (ou apenas “modelo”, quando não gerar confusão)\\ndescreve o resultado de cada ação em cada estado. Aqui, o resultado é estocástico, então escrevemos\\nP\\n(\\ns’\\n | \\ns\\n, \\na\\n) para indicar a probabilidade de alcançar o estado \\ns’\\n se a ação \\na\\n for feita no estado \\ns\\n.\\nVamos supor que as transições são de \\nmarkesianas\\n no sentido do Capítulo 15, isto é, a\\nprobabilidade de alcançar \\ns’\\n a partir de \\ns\\n depende apenas de \\ns\\n, e não do histórico de estados\\nanteriores. No momento, você pode pensar em \\nP\\n(\\ns’\\n | \\ns\\n, \\na\\n) como uma grande tabela tridimensional\\ncontendo probabilidades. Mais adiante, na \\nSeção 17.4.3\\n, veremos que o modelo de transição pode\\nser representado como uma \\nrede bayesiana dinâmica\\n, da mesma maneira que no Capítulo15.\\nPara completar a definição do ambiente de tarefa, devemos especificar a função utilidade para o\\nagente. Como o problema de decisão é sequencial, a função utilidade dependerá de uma sequência de\\nestados — um \\nhistórico do ambiente\\n —, em vez de depender de um único estado. Mais adiante,\\nnesta seção, investigaremos como tais funções utilidade podem ser especificadas em geral; por\\nenquanto, vamos simplesmente estipular que, em cada estado \\ns\\n, o agente recebe uma \\nrecompensa\\nR\\n(\\ns\\n), que pode ser positiva ou negativa, mas deve ser limitada. Para nosso exemplo específico, a\\nrecompensa é –0,04 em todos os estados, exceto os estados terminais (que têm recompensas +1 e –\\n1). A utilidade de um histórico do ambiente é simplesmente (por enquanto) a \\nsoma\\n das recompensas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 751}),\n",
       " Document(page_content='recebidas. Por exemplo, se o agente alcançar o estado +1 depois de 10 passos, sua utilidade total\\nserá 0,6. A recompensa negativa igual a –0,04 dá ao agente um incentivo para alcançar (4,3)\\ndepressa e, assim, nosso ambiente é uma generalização estocástica dos problemas de busca do\\nCapítulo 3. Outro modo de dizer isso é afirmar que o agente não aprecia viver nesse ambiente e,\\nportanto, quer deixá-lo assim que possível.\\nPara resumir: um problema de decisão sequencial para um ambiente completamente observável,\\nestocástico, com um modelo de transição de Markov e recompensas aditivas, é chamado de \\nprocesso\\nde decisão de Marko\\nv ou \\nMDP\\n (Makov Decison Process), e consiste de um conjunto de estados\\n(com estado inicial \\ns\\n0\\n); um conjunto de AÇÕES(\\ns\\n) de ações aplicáveis em cada estado; um modelo\\nde transição \\nP\\n(\\ns’\\n | \\ns\\n, \\na\\n) e uma função de recompensa \\nR\\n(\\ns\\n).\\n1\\nA próxima questão é definir qual seria a aparência de uma solução para o problema. Vimos que\\nqualquer sequência fixa de ações não resolverá o problema porque o agente poderia acabar em um\\nestado diferente da meta. Desta forma, uma solução tem de especificar o que o agente deve fazer para\\nqualquer\\n estado que o agente possa alcançar. Uma solução desse tipo é chamada de \\npolítica\\n.\\nNormalmente, denotamos uma política por \\nπ\\n e \\nπ\\n(\\ns\\n) é a ação recomendada pela política \\nπ\\n para o\\nestado \\ns\\n. Se o agente tiver uma política completa, não importará o resultado de qualquer ação, o\\nagente sempre saberá o que fazer em seguida.\\nToda vez que uma dada política for executada a partir do estado inicial, a natureza estocástica do\\nambiente poderá levar a um histórico de ambiente diferente. A qualidade de uma política é, portanto,\\nmedida pela utilidade \\nesperada\\n dos históricos de ambientes possíveis gerados por essa política.\\nUma \\npolítica ótima\\n é uma política que produz a utilidade esperada mais alta. Usamos \\nπ\\n* para\\ndenotar uma política ótima. Dado \\nπ\\n*, o agente decide o que fazer consultando sua percepção atual,\\nque informa o estado atual \\ns\\n, e depois executando a ação \\nπ\\n*(\\ns\\n). Uma política representa\\nexplicitamente a função do agente e, portanto, é uma descrição de um agente reflexivo simples,\\ncalculada a partir das informações usadas por um agente baseado na utilidade.\\nUma política ótima para o mundo da \\nFigura 17.1\\n é mostrada na \\nFigura 17.2\\n(a). Observe que, como\\no custo de dar um passo é bastante pequeno em comparação com a penalidade por terminar em (4,2)\\npor acidente, a política ótima para o estado (3,1) é conservadora. A política recomenda seguir o\\ncaminho longo, em vez de tomar o atalho e se arriscar a entrar em (4,2).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 752}),\n",
       " Document(page_content='Figura 17.2\\n (a) Uma política ótima para o ambiente estocástico com \\nR\\n(\\ns\\n) = –0,04 nos estados não\\nterminais. (b) Políticas ótimas para quatro intervalos diferentes de \\nR\\n(\\ns\\n).\\nO equilíbrio entre risco e recompensa muda dependendo do valor de \\nR\\n(\\ns\\n) para os estados não\\nterminais. A \\nFigura 17.2\\n(b) mostra políticas ótimas para quatro intervalos diferentes de \\nR\\n(\\ns\\n). Quando\\nR\\n(\\ns\\n) ≤ –1,6284, a vida é tão difícil que o agente vai direto para a saída mais próxima, ainda que a\\nsaída tenha o valor –1. Quando –0,4278 ≤ \\nR\\n(\\ns\\n) ≤ –0,0850, a vida é bastante desagradável; o agente\\ntoma a rota mais curta até o estado +1 e está disposto a correr o risco de cair no estado –1 por\\nacidente. Em particular, o agente toma o atalho a partir de (3,1). Quando a vida é apenas ligeiramente\\nruim (–0,0221 < \\nR\\n(\\ns\\n) < 0), a política ótima não assume \\nabsolutamente nenhum risco\\n. Em (4,1) e\\n(3,2) o agente segue diretamente para fora do estado –1, de forma que não possa cair nesse estado\\npor acidente, embora isso signifique bater a cabeça contra a parede várias vezes. Finalmente, se \\nR\\n(\\ns\\n)\\n> 0, a vida positivamente é agradável e o agente evita \\nambas\\n as saídas. Desde que as ações em (4,1),\\n(3,2) e (3,3) sejam as que estão representadas, toda política é ótima, e o agente obtém recompensa\\ntotal infinita porque nunca entra em estado terminal. Surpreendentemente, verificamos que existem\\nseis outras políticas ótimas para vários intervalos de \\nR\\n(\\ns\\n); o Exercício 17.5 pede para encontrá-las.\\nO equilíbrio cuidadoso entre risco e recompensa é uma característica dos MDPs que não surge em\\nproblemas de busca determinística; além disso, é uma característica de muitos problemas de decisão\\ndo mundo real. Por essa razão, os MDPs foram estudados em vários campos, inclusive em IA,\\npesquisa operacional, economia e teoria de controle. Foram propostas dezenas de algoritmos para\\ncalcular políticas ótimas. Nas Seções 17.2 e 17.3, descrevemos duas das famílias mais importantes\\nde algoritmos. Porém, primeiro devemos completar nossa investigação das utilidades e políticas para\\nproblemas de decisão sequencial.\\n17.1.1 Utilidades ao longo do tempo\\nNo exemplo de MDP da \\nFigura 17.1\\n, o desempenho do agente foi medido por uma soma de\\nrecompensas para os estados visitados. Essa escolha de medida de desempenho não é arbitrária, mas\\nnão é a única possibilidade da função utilidade sobre históricos de ambiente, que escrevemos como\\nU\\nh\\n([s\\n0\\n, s\\n1\\n,…, S\\nn\\n]). Nossa análise baseia-se na \\nteoria da utilidade de multiatributo\\n (\\nSeção 16.4\\n) e é\\num pouco técnica; o leitor impaciente pode pular para a próxima seção.\\nA primeira pergunta a responder é se existe um \\nhorizonte finito\\n ou um \\nhorizonte infinito\\n para\\ntomada de decisão. Um horizonte finito significa que existe um tempo \\nfixo N\\n depois do qual nada\\nimporta — o jogo acabou, por assim dizer. Desse modo, \\nU\\nh\\n([\\ns\\n0\\n, \\ns\\n1\\n, …, \\ns\\nN+ k\\n]) = \\nU\\nh\\n([\\ns\\n0\\n, \\ns\\n1\\n, …, \\ns\\nn\\n])\\npara todo \\nk\\n > 0. Por exemplo, suponha que um agente comece em (3,1) no mundo 4 × 3 da Figura 17,\\ne suponha que \\nN\\n = 3. Então, para ter qualquer chance de alcançar o estado +1, o agente deve ir\\ndiretamente para ele, e a ação ótima é ir \\nAcima\\n. Por outro lado, se \\nN\\n = 100, existe bastante tempo\\npara seguir a rota segura dirigindo-se para a \\nEsquerda\\n. \\nAssim\\n, \\ncom um horizonte finito\\n, \\na ação\\nótima em um dado estado poderia mudar com o passar do tempo\\n. Dizemos que a política ótima para\\num horizonte finito é \\nnão estacionária\\n. Por outro lado, sem um limite de tempo fixo, não existe\\nnenhuma razão para se comportar de maneira diferente no mesmo estado em momentos distintos.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 753}),\n",
       " Document(page_content='Consequentemente, a ação ótima depende apenas do estado atual, e a política ótima é \\nestacionária\\n.\\nPolíticas para o caso de horizonte infinito são portanto mais simples que aquelas para o caso de\\nhorizonte finito, e lidaremos principalmente com o caso de horizonte infinito neste capítulo.\\n(Veremos mais adiante que, para ambientes parcialmente observáveis, o caso de horizonte infinito\\nnão é tão simples.) Observe que “horizonte infinito” não significa necessariamente que todas as\\nsequências de estados são infinitas; significa apenas que não existe nenhum prazo final fixo. Em\\nparticular, pode haver sequências de estados finitos em um MDP de horizonte infinito contendo um\\nestado terminal.\\n A próxima pergunta a que devemos responder é como calcular a utilidade de sequências de\\nestados. Na terminologia da teoria de utilidade de multiatributo, cada estado \\ns\\ni\\n pode ser visto como\\num atributo da sequência de estado [\\ns\\n0\\n, \\ns\\n1\\n, \\ns\\n2\\n, …]. Para obter uma expressão simples em termos dos\\natributos, precisaremos fazer algum tipo de suposição de independência de preferência. A suposição\\nmais natural é que as preferências do agente entre sequências de estados são \\nestacionárias\\n. O caráter\\nestacionário para preferências significa que, se duas sequências de estados [\\ns\\n0\\n, \\ns\\n1\\n, \\ns\\n2\\n, …] e [\\n] começam com o mesmo estado (isto é, \\n), então as duas sequências devem ser\\nordenadas por preferência, do mesmo modo que as sequências [\\ns\\n1\\n, \\ns\\n2\\n, …] e [\\n]. Em linguagem\\ncomum, isso significa que, se preferir um futuro a outro que comece amanhã, você ainda deverá\\npreferir esse futuro se ele tiver de começar hoje em vez de amanhã. O caráter estacionário é uma\\nhipótese de aparência bastante inócua mas com consequências muito fortes: sob esse caráter\\nestacionário, existem apenas duas maneiras de atribuir utilidades a sequências:\\n1. \\nRecompensas aditivas:\\n A utilidade de uma sequência de estados é:\\nU\\nh\\n([\\ns\\n0\\n, \\ns\\n1\\n, \\ns\\n2\\n, …]) = \\nR\\n(\\ns\\n0\\n) + \\nR\\n(\\ns\\n1\\n) + \\nR\\n(\\ns\\n2\\n) + ….\\nO mundo de 4 × 3 da \\nFigura 17.1\\n utiliza recompensas aditivas. Note que a aditividade foi\\nempregada implicitamente em nosso uso de funções de custo de caminho em algoritmos de busca\\nheurística (Capítulo 3).\\n2. \\nRecompensas descontadas:\\n A utilidade de uma sequência de estados é:\\nU\\nh\\n([\\ns\\n0\\n, \\ns\\n1\\n, \\ns\\n2\\n, …]) = \\nR\\n(\\ns\\n0\\n) + γ\\nR\\n(\\ns\\n1\\n) + γ\\n2\\nR\\n(\\ns\\n2\\n) + …,\\nonde o \\nfator de desconto\\n \\nγ\\n é um número entre 0 e 1. O fator de desconto descreve a preferência\\nde um agente por recompensas atuais sobre recompensas futuras. Quando \\nγ\\n é próximo de 0, as\\nrecompensas no futuro distante são vistas como insignificantes. Quando \\nγ\\n é 1, recompensas\\ndescontadas são exatamente equivalentes a recompensas aditivas e, assim, as recompensas\\naditivas constituem um caso especial de recompensas descontadas. O desconto parece ser um\\nbom modelo de preferências, tanto de animais quanto de humanos, ao longo do tempo. Um fator\\nde desconto γ é equivalente a uma taxa de juros de (1/γ) – 1.\\nPor motivos que em breve ficarão claros, vamos assumir recompensas descontadas no restante do\\ncapítulo, embora às vezes seja permitido γ = 1.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 754}),\n",
       " Document(page_content='Há uma questão que surge de nossa escolha de horizontes infinitos: se o ambiente não contém um\\nestado terminal ou se o agente nunca alcança um desses estados, todos os históricos de ambientes\\nserão infinitamente longos, e as utilidades com recompensas aditivas não descontadas em geral serão\\ninfinitas. Agora, podemos concordar que +∞ é melhor que –∞, mas comparar duas sequências de\\nestados, ambas com utilidade +∞, é mais difícil. Existem três soluções, duas das quais já estudamos:\\n1. Com recompensas descontadas, a utilidade de uma sequência infinita é \\nfinita\\n. De fato, se γ < 1 e\\nas recompensas são limitadas por ±\\nR\\nmax\\n, temos:\\nusando a fórmula-padrão para a soma de uma série geométrica infinita.\\n2. Se o ambiente contém estados terminais \\ne se o agente oferece a garantia de eventualmente\\nchegar a um deles\\n, nunca precisaremos comparar sequências infinitas. Uma política que\\noferece a garantia de alcançar um estado terminal é chamada de \\npolítica própria\\n. Com políticas\\npróprias, podemos usar γ = 1 (isto é, recompensas aditivas). As três primeiras políticas\\nmostradas na \\nFigura 17.2\\n(b) são próprias, mas a quarta é imprópria. Ela ganha recompensa\\ntotal infinita ficando afastada dos estados terminais quando a recompensa para os estados não\\nterminais é positiva. A existência de políticas impróprias pode fazer os algoritmos clássicos\\npara resolução de MDPs falharem com recompensas aditivas e, assim, oferece uma boa razão\\npara utilização de recompensas descontadas.\\n3. As sequências infinitas podem ser comparadas em termos da \\nrecompensa média\\n obtida por\\npasso de tempo. Suponha que o quadrado (1,1) no mundo 4 × 3 tenha recompensa de 0,1,\\nenquanto os outros estados não terminais têm recompensa de 0,01. Então, uma política que fizer\\no melhor possível para ficar em (1,1) terá recompensa média mais alta que uma política que\\npermanecer em outro lugar. A recompensa média é um critério útil para alguns problemas, mas\\na análise de algoritmos de recompensa média está além do escopo deste livro.\\nEm suma, o uso de recompensas descontadas apresenta um número menor de dificuldades na\\navaliação de sequências de estados.\\n17.1.2 As políticas ótimas e as utilidades dos estados\\nAo decidir que a utilidade de uma determinada sequência de estados é a soma das recompensas\\ndescontadas obtidas durante a sequência, podemos comparar políticas comparando as utilidades\\nesperadas\\n obtidas quando as executamos. Assumimos que o agente está em algum estado inicial \\ns\\n e\\ndefinimos \\nS\\nt\\n (uma variável aleatória) como o estado que o agente alcançou no tempo \\nt\\n ao executar\\numa política determinada \\nπ.\\n (Obviamente, \\nS\\n0\\n = \\ns\\n, o estado em que o agente está agora.) A\\ndistribuição de probabilidade sobre as sequências de estados S\\n1\\n, S\\n2\\n,…, é determinada pelo estado\\ninicial \\ns\\n, a política π, e o modelo de transição do ambiente.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 755}),\n",
       " Document(page_content='A utilidade esperada obtida executando π a partir de \\ns\\n é dada por\\nonde a expectativa está relacionada à distribuição de probabilidade sobre sequências de estados\\ndeterminadas por \\ns\\n e \\nπ.\\n Agora, entre todas as políticas que o agente poderia escolher executar a\\npartir de \\ns\\n, uma (ou mais) terá utilidades esperadas maiores do que todas as outras. Vamos usar \\npara indicar uma dessas políticas:\\nLembre-se que \\n é uma política, por isso recomenda uma ação para cada estado; em particular,\\nsua conexão com \\ns\\n é ser uma política ótima quando \\ns\\n for o estado inicial. Uma consequência notável\\ndo uso de utilidades descontadas com horizontes infinitos é que a política ótima é \\nindependente\\n do\\nestado inicial (é claro, a \\nsequência de ação\\n não será independente; lembre-se de que uma política é\\numa função especificando uma ação para cada estado). Esse fato parece intuitivamente óbvio: se a\\npolítica \\n é ótima começando em \\na\\n e a política \\n é ótima começando em \\nb\\n; então, quando\\nalcançarem um terceiro estado \\nc\\n, não há nenhuma boa razão para que discordem uma da outra, ou de \\n, sobre o que fazer a seguir.\\n2\\n Assim, podemos simplesmente escrever π* para uma política ótima.\\nDada essa definição, a utilidade verdadeira de um estado é simplesmente \\nU\\nπ*\\n(\\ns\\n), isto é, a soma\\nesperada de recompensas descontadas se o agente executa uma política ótima. Escrevemos como\\nU\\n(\\ns\\n), de acordo com a notação usada no Capítulo 16 para a utilidade de um resultado. Note que \\nU\\n(\\ns\\n)\\ne \\nR\\n(\\ns\\n) são quantidades bastante diferentes; \\nR\\n(\\ns\\n) é a recompensa “a curto prazo” por estar em \\ns\\n,\\nenquanto \\nU\\n(\\ns\\n) é a recompensa total “a longo prazo” de \\ns\\n em diante. A \\nFigura 17.3\\n mostra as\\nutilidades para o mundo 4 × 3. Note que as utilidades são mais altas para estados mais próximos à\\nsaída +1, porque são necessários menos passos para alcançar a saída.\\nFigura 17.3\\n As utilidades dos estados no mundo 4 × 3, calculadas com \\nγ\\n = 1 e \\nR\\n(\\ns\\n) = –0,04 para\\nestados não terminais.\\nA função utilidade \\nU\\n(\\ns\\n) permite ao agente selecionar ações usando o princípio de utilidade\\nesperada máxima do Capítulo 16, isto é, escolher a ação que maximiza a utilidade esperada do\\nestado subsequente:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 756}),\n",
       " Document(page_content='Nas duas próximas seções descreveremos algoritmos para encontrar políticas ótimas.\\n17.2 ITERAÇÃO DE VALOR\\nNesta seção, apresentaremos um algoritmo, chamado de \\niteração de valor\\n, para calcular uma\\npolítica ótima. A ideia básica é calcular a utilidade de cada estado e, em seguida, usar as utilidades\\ndo estado para selecionar uma ação ótima em cada estado.\\n17.2.1 A equação de Bellman para utilidades\\n A \\nSeção 17.1.2\\n definiu a utilidade de estar em um estado como a soma esperada de\\nrecompensas descontadas a partir desse momento. A partir disso, segue que há uma relação direta\\nentre a utilidade de um estado e a utilidade de seus vizinhos: \\na utilidade de um estado é a\\nrecompensa imediata correspondente a esse estado mais a utilidade descontada esperada do\\npróximo estado, assumindo que o agente escolha a ação ótima.\\n Isto é, a utilidade de um estado \\ns\\n é\\ndada por\\nEssa equação é chamada de \\nequação de Bellman\\n, em homenagem a Richard Bellman (1957). As\\nutilidades dos estados — definidas pela Equação 17.2, como a utilidade esperada das sequências de\\nestados subsequentes — são soluções do conjunto das equações de Bellman. Na verdade, são as\\núnicas\\n soluções, como mostramos na \\nSeção 17.2.3\\n.\\nVamos examinar uma das equações de Bellman para o mundo 4 × 3. A equação para o estado (1,1)\\né:\\nQuando inserirmos os números da \\nFigura 17.3\\n, descobriremos que \\nAcima\\n é a melhor ação.\\n17.2.2 O algoritmo de iteração de valor\\nA equação de Bellman é a base do algoritmo de iteração de valor para resolução de MDPs. Se\\nhouver \\nn\\n estados possíveis, haverá \\nn\\n equações de Bellman, uma para cada estado. As \\nn\\n equações', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 757}),\n",
       " Document(page_content='contêm \\nn\\n incógnitas — as utilidades dos estados. Então, gostaríamos de resolver essas equações\\nsimultâneas para encontrar as utilidades. Porém, existe um problema: as equações são \\nnão lineares\\nporque o operador “max” não é um operador linear. Enquanto sistemas de equações lineares podem\\nser resolvidos com rapidez usando-se técnicas de álgebra linear, sistemas de equações não lineares\\nsão mais problemáticos. Podemos experimentar uma abordagem \\niterativa\\n. Começaremos com\\nvalores iniciais arbitrários para as utilidades, calculamos o lado direito da equação e o inserimos no\\nlado esquerdo, atualizando assim a utilidade de cada estado a partir das utilidades de seus vizinhos.\\nRepetimos esse processo até chegarmos a um equilíbrio. Seja \\nU\\ni\\n(\\ns\\n) o valor de utilidade para o\\nestado \\ns\\n na \\ni\\n-ésima iteração. A etapa de iteração, chamada \\natualização de Bellman\\n, é feita da\\nseguinte forma:\\nonde se assume que a atualização será aplicada simultaneamente a todos os estados em cada iteração.\\nSe aplicarmos a atualização de Bellman com frequência infinita, teremos a garantia de alcançar um\\nequilíbrio (consulte a \\nSeção 17.2.3\\n) e, nesse caso, os valores finais de utilidade deverão ser\\nsoluções para as equações de Bellman. De fato, eles também são as \\núnicas\\n soluções, e a política\\ncorrespondente (obtida com o uso da Equação 17.4) é ótima. O algoritmo, chamado ITERAÇÃO-DE-\\nVALOR, é mostrado na \\nFigura 17.4\\n.\\nFigura 17.4\\n O algoritmo de iteração de valor para calcular utilidades de estados. A condição de\\ntérmino vem da Equação 17.8.\\nPodemos aplicar a iteração de valor ao mundo 4 × 3 da \\nFigura 17.1\\n(a). Começando com valores\\niniciais iguais a zero, as utilidades evoluem como mostra a \\nFigura 17.5\\n(a). Note como os estados a\\ndiferentes distâncias de (4,3) acumulam recompensa negativa até um caminho para (4,3) ser\\nencontrado; daí em diante, as utilidades começam a aumentar. Podemos imaginar o algoritmo de\\niteração de valor como a \\npropagação de informações\\n pelo espaço de estados por meio de\\natualizações locais.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 758}),\n",
       " Document(page_content='Figura 17.5\\n (a) Grafo mostrando a evolução das utilidades de estados selecionados usando iteração\\nde valor. (b) O número de iterações de valor \\nk\\n necessárias para garantir um erro no máximo igual a \\nε\\n= \\nc\\n · \\nR\\nmax\\n, para diferentes valores de \\nc\\n, como uma função do fator de desconto γ.\\n17.2.3 Convergência da iteração de valor\\nDissemos que a iteração de valor eventualmente converge para um único conjunto de soluções das\\nequações de Bellman. Nesta seção, explicaremos por que isso acontece. Introduziremos algumas\\nideias matemáticas úteis ao longo do processo e obteremos alguns métodos para avaliar o erro na\\nfunção utilidade devolvida quando o algoritmo é terminado prematuramente; isso é útil porque\\nsignifica que não teremos de continuar para sempre. Essa seção é bastante técnica.\\nO conceito básico usado para mostrar que a iteração de valor converge é a noção de \\ncontração\\n. A\\ngrosso modo\\n, uma contração é uma função de um único argumento que, ao ser aplicada a duas\\nentradas diferentes, uma de cada vez, produz dois valores de saída que estão “mais próximos entre\\nsi” por pelo menos um fator constante, em relação às entradas originais. Por exemplo, a função\\n“dividir por dois” é uma contração porque, depois de dividirmos dois números quaisquer por dois,\\nsua diferença é reduzida à metade. Note que a função “dividir por dois” tem um ponto fixo, isto é,\\nzero, que não é alterado pela aplicação da função. A partir desse exemplo, podemos distinguir duas\\npropriedades importantes de contrações:\\n•  Uma contração tem apenas um ponto fixo; se houvesse dois pontos fixos, eles não ficariam mais\\npróximos um do outro quando a função fosse aplicada e não seria uma contração.\\n•  Quando a função é aplicada a qualquer argumento, o valor deve ficar mais próximo do ponto fixo\\n(porque o ponto fixo não se move) e, assim, a aplicação repetida de uma contração sempre\\nalcança o ponto fixo no limite.\\nAgora, vamos supor que visualizamos a atualização de Bellman (Equação 17.6) como um operador\\nB\\n que é aplicado simultaneamente para atualizar a utilidade de todo estado. Seja \\nU\\ni\\n o vetor de\\nutilidades para todos os estados na \\ni\\n-ésima iteração. Então, a equação da atualização de Bellman\\npode ser escrita como', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 759}),\n",
       " Document(page_content='U\\ni\\n+1\\n ← \\nBU\\ni\\n.\\nEm seguida, precisamos de um modo de medir distâncias entre vetores de utilidade. Utilizaremos a\\nnorma max\\n, que mede o “comprimento” de um vetor pelo valor absoluto de seu maior componente:\\n Com essa definição, a “distância” entre dois vetores, ||\\nU\\n – \\nU\\n′||, é a diferença máxima entre dois\\nelementos correspondentes quaisquer. O principal resultado desta seção é: \\nsejam U\\ni\\n e \\n \\ndois vetores\\nde utilidade quaisquer\\n.\\nEntão, temos\\n:\\nIsto é\\n, \\na atualização de Bellman é uma contração por um fator\\n \\nγ\\n \\nno espaço de vetores de\\nutilidade\\n (o Exercício 17.6 fornece alguma orientação para provar esta afirmação). Assim, a partir\\ndas propriedades de contrações em geral, segue que a iteração de valor sempre converge para uma\\nsolução única das equações de Bellman, sempre que γ < 1.\\nPodemos também utilizar a propriedade de contração para analisar \\na taxa\\n de convergência para\\numa solução. Em particular, podemos substituir \\n na Equação (17.7) pelas utilidades \\nverdadeiras U\\n,\\npara as quais \\nBU\\n = \\nU\\n. Então, obtemos a desigualdade:\\nAssim, se visualizarmos ||\\nU\\ni\\n – \\nU\\n|| como o \\nerro\\n na estimativa \\nU\\ni\\n, veremos que o erro é reduzido por\\num fator de pelo menos \\nγ\\n em cada iteração. Isso significa que a iteração de valor converge de forma\\nexponencialmente rápida. Podemos calcular o número de iterações necessárias para alcançar um\\nlimite de erro especificado \\nε\\n, da seguinte forma: primeiro, vimos na Equação 17.1 que as utilidades\\nde todos os estados são limitadas por ±\\nR\\nmax\\n/(1 – \\nγ\\n). Isso significa que o erro inicial máximo ||\\nU\\n0\\n –\\nU\\n|| ≤ 2\\nR\\nmax\\n/(1 – \\nγ\\n). Vamos supor que sejam realizadas \\nN\\n iterações para alcançar um erro de no\\nmáximo \\nε.\\n Então, como o erro é reduzido por pelo menos \\nγ\\n em cada vez, é necessário que (\\nγ\\nN\\n ·\\n2\\nR\\nmax\\n/(1 – γ) ≤ ε. Usando logaritmos, descobrimos que\\niterações bastam. A \\nFigura 17.5\\n(b) mostra como \\nN\\n varia com \\nγ\\n para diferentes valores da razão\\nε/\\nR\\nmax\\n. A boa notícia é que, devido à convergência exponencialmente rápida, \\nN\\n não depende muito\\nda razão ε/\\nR\\nmax\\n. A má notícia é que \\nN\\n cresce rapidamente à medida que γ se aproxima de 1. Podemos\\nobter a convergência rápida se tornarmos \\nγ\\n pequeno, mas isso efetivamente dá ao agente um\\nhorizonte curto e pode anular os efeitos a longo prazo das ações do agente.\\nO limite de erro no parágrafo anterior nos dá alguma ideia dos fatores que influenciam o tempo de\\nexecução do algoritmo, mas às vezes é excessivamente conservador como um método para decidir\\nquando interromper a iteração. Para este último propósito, podemos utilizar um limite relacionando o\\nerro ao tamanho da atualização de Bellman em qualquer iteração dada. A partir da propriedade de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 760}),\n",
       " Document(page_content='contração (Equação 17.7), podemos mostrar que, se a atualização for pequena (isto é, se a utilidade\\nnão mudar muito para nenhum estado), então o erro, comparado à função utilidade verdadeira,\\ntambém será pequeno. Mais precisamente,\\nEssa é a condição de término usada no algoritmo ITERAÇÃO-DE-VALOR da \\nFigura 17.4\\n.\\n Até agora, analisamos o erro na função utilidade devolvida pelo algoritmo de iteração de valor.\\nPorém, o que realmente importa para o agente é como ele se sairá se tomar suas decisões com\\nbase em sua função utilidade\\n. Vamos supor que, depois de \\ni\\n iterações da iteração de valor, o agente\\ntenha uma estimativa \\nU\\ni\\n da utilidade verdadeira \\nU\\n e obtenha a política \\nπ\\ni\\n de UME \\nπ\\ni\\n com base na\\nobservação para frente de um passo usando \\nU\\ni\\n (como na Equação 17.4). O comportamento resultante\\nserá quase tão bom quanto o comportamento ótimo? Essa é uma questão crucial para qualquer agente\\nreal, e sua resposta é sim. \\nU\\nπ\\ni\\n (\\ns\\n) é a utilidade obtida se \\nπ\\ni\\n é executada a partir de \\ns\\n, e a \\nperda de\\npolítica\\n ||\\nU\\nπ\\ni\\n – \\nU\\n|| é o máximo que o agente pode perder executando \\nπ\\ni\\n em lugar da política ótima \\nπ\\n*.\\nA perda de política de π\\ni\\n está relacionada ao erro em \\nU\\ni\\n pela desigualdade a seguir:\\nNa prática, com frequência ocorre que \\nπ\\ni\\n se torna ótima bem antes de \\nU\\ni\\n ter convergido. A \\nFigura\\n17.6\\n mostra como o erro máximo em \\nU\\ni\\n e a perda de política se aproximam de zero à medida que o\\nprocesso de iteração de valor prossegue para o ambiente 4 × 3 com \\nγ\\n = 0,9. A política \\nπ\\ni\\n é ótima\\nquando \\ni\\n = 4, embora o erro máximo em \\nU\\ni\\n ainda seja 0,46.\\nFigura 17.6\\n O erro máximo ||\\nU\\ni\\n –\\nU\\n|| das estimativas de utilidade e a perda de política ||\\nU\\nπ\\n′ – \\nU\\n ||,\\ncomo uma função do número de iterações da iteração de valor.\\nAgora temos tudo o que precisamos para utilizar a iteração de valor na prática. Sabemos que ela\\nconverge para as utilidades corretas, podemos limitar o erro nas estimativas de utilidade se pararmos\\napós um número finito de iterações e podemos limitar a perda de política que resulta da execução da\\npolítica UME correspondente. Como observação final, todos os resultados desta seção dependem do\\ndesconto com \\nγ\\n < 1. Se \\nγ\\n = 1 e o ambiente contiver estados terminais, um conjunto semelhante de\\nresultados de convergência e de limites de erro poderá ser derivado sempre que certas condições', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 761}),\n",
       " Document(page_content='técnicas forem satisfeitas.\\n17.3 ITERAÇÃO DE POLÍTICA\\nNa seção anterior, observamos que é possível conseguir uma política ótima até mesmo quando a\\nestimativa de função utilidade é inexata. Se uma ação é claramente melhor que todas as outras, a\\nmagnitude exata das utilidades nos estados envolvidos não precisa ser exata. Essa ideia sugere um\\ncaminho alternativo para encontrar políticas ótimas. O algoritmo de \\niteração de política\\n alterna as\\nduas etapas a seguir, começando com alguma política inicial π\\n0\\n:\\n•  \\nAvaliação de política:\\n Dada uma política \\nπ\\ni\\n, calcular \\nU\\ni\\n = \\nU\\nπ\\ni\\n, a utilidade de cada estado se \\nπ\\ni\\nfosse exe\\u200bcutada.\\n•  \\nAperfeiçoamento de política:\\n Calcular uma nova política UME \\nπ\\ni\\n \\n+1\\n utilizando a observação\\npara frente de um passo baseada em \\nU\\ni\\n (como na Equação (17.4).\\nO algoritmo termina quando a etapa de aperfeiçoamento da política não produz nenhuma mudança\\nnas utilidades. Nesse ponto, sabemos que a função utilidade \\nU\\ni\\n é um ponto fixo da atualização de\\nBellman, e portanto ela é uma solução para as equações de Bellman, e π\\ni\\n deve ser uma política ótima.\\nComo existe apenas um número finito de políticas para um espaço de estados finito e podemos\\nmostrar que cada iteração produz uma política melhor, a iteração de políticas tem de terminar. O\\nalgoritmo é mostrado na \\nFigura 17.7\\n.\\nFigura 17.7\\n Algoritmo de iteração de política para calcular de uma política ótima.\\nA etapa de aperfeiçoamento da política é obviamente direta; porém, como a rotina AVALIAÇÃO-\\nDE-POLÍTICA pode ser implementada? Na realidade, fazer isso é muito mais simples que resolver\\nas equações de Bellman (o que é feito pela iteração de valor) porque a ação em cada estado é fixada\\npela política. Na \\ni\\n-ésima iteração, a política \\nπ\\ni\\n especifica a ação \\nπ\\ni\\n(\\ns\\n) no estado \\ns\\n. Isso significa que\\ntemos uma versão simplificada da equação de Bellman (17.5) relacionando a utilidade de \\ns\\n (sob \\nπ\\ni\\n)', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 762}),\n",
       " Document(page_content='às utilidades de seus vizinhos:\\nPor exemplo, vamos supor que π\\ni\\n seja a política mostrada na \\nFigura 17.2\\n(a). Então, temos π\\ni\\n(1,1) =\\nAcima\\n, π\\ni\\n(1, 2) = \\nAcima\\n, e assim por diante, e as equações de Bellman simplificadas são:\\nO ponto importante é que essas equações são \\nlineares\\n porque o operador “max” foi removido.\\nPara \\nn\\n estados, temos \\nn\\n equações lineares com \\nn\\n incógnitas, que podem ser resolvidas exatamente no\\ntempo \\nO\\n(\\nn\\n3\\n) por métodos clássicos de álgebra linear.\\nPara espaços de estados pequenos, a avaliação de política usando métodos de solução exata em\\ngeral é a abordagem mais eficiente. Para os espaços de estados grandes, o tempo \\nO\\n(\\nn\\n3\\n) talvez seja\\nproibitivo. Felizmente, não é necessário fazer a avaliação de política \\nexata\\n. Em vez disso, podemos\\nexecutar algum número de passos de iteração de valor simplificada (simplificada porque a política é\\nfixa) para fornecer uma aproximação razoavelmente boa das utilidades. A atualização de Bellman\\nsimplificada para esse processo é\\ne é repetida \\nk\\n vezes para produzir a próxima estimativa de utilidade. O algoritmo resultante é\\nchamado \\niteração de política modificada\\n. Com frequência, ele é muito mais eficiente que a iteração\\nde política clássica ou a iteração de valor.\\nOs algoritmos que descrevemos até agora exigem atualização da utilidade ou da política para\\ntodos os estados de uma vez. Ocorre que isso não é estritamente necessário. De fato, em cada\\niteração, podemos escolher \\nqualquer subconjunto\\n de estados e aplicar um dos tipos de atualização\\n(aperfeiçoamento de política ou \\numa\\n iteração de valor simplificada) a esse subconjunto. Esse\\nalgoritmo bem geral é chamado \\niteração de política assíncrona\\n. Dadas certas condições sobre a\\npolítica inicial e sobre a função utilidade, a iteração de política assíncrona oferece a garantia de\\nconvergir para uma política ótima. A liberdade de escolher quaisquer estados para trabalhar\\nsignifica que podemos projetar algoritmos heurísticos muito mais eficientes — por exemplo,\\nalgoritmos que se concentram em atualizar os valores de estados que provavelmente serão\\nalcançados por uma boa política. Isso faz muito sentido na vida real: se uma pessoa não tem nenhuma\\nintenção de se lançar em um precipício, não devemos perder tempo nos preocupando com o valor\\nexato dos estados resultantes.\\n17.4 MDPS PARCIALMENTE OBSERVÁVEIS\\nA descrição de processos de decisão de Markov na \\nSeção 17.1\\n pressupôs que o ambiente era', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 763}),\n",
       " Document(page_content='completamente observável\\n. Com essa suposição, o agente sempre sabe em que estado se encontra.\\nIsso, combinado com a hipótese de Markov para o modelo de transição, significa que a política ótima\\ndepende unicamente do estado atual. Quando o ambiente é apenas \\nparcialmente observável\\n, a\\nsituação é muito menos clara. O agente não sabe necessariamente em que estado se encontra e,\\nportanto, não pode executar a ação π(\\ns\\n) recomendada para esse estado. Além disso, a utilidade de um\\nestado \\ns\\n e a ação ótima em \\ns\\n não dependem apenas de \\ns\\n, mas também \\ndo quanto o agente sabe\\nquando está em \\ns\\n. Por essas razões, os \\nMDPs parcialmente observáveis\\n (ou POMDPs) em geral são\\nconsiderados muito mais difíceis que os MDPs comuns. No entanto, não podemos evitar POMDPs\\nporque o mundo real é um deles.\\n17.4.1 Definição de POMDPs\\nPara compreender os POMDPs, primeiro devemos defini-los corretamente. Um POMDP tem os\\nmesmos elementos que um MDP — o modelo de transição \\nP\\n(\\ns’|\\n \\ns\\n, \\na\\n), as ações A(\\ns\\n) e a função\\nrecompensa \\nR\\n(\\ns\\n) —, mas, como os problemas de busca parcialmente observáveis da \\nSeção 4.4\\n, ele\\ntambém tem um \\nmodelo de sensoriamento\\n \\nP\\n(\\ne\\n | \\ns\\n). Aqui, como no Capítulo 15, o modelo de\\nsensoriamento especifica a probabilidade de perceber a evidência \\ne\\n no estado \\ns\\n.\\n3\\n Por exemplo,\\npodemos converter o mundo 4 × 3 da \\nFigura 17.1\\n em um POMDPs pela adição de um sensoriamento\\nruidoso ou parcial em vez de assumir que o agente conhece a sua localização exata. Tal\\nsensoriamento pode medir o \\nnúmero de paredes adjacentes\\n, que vem a ser 2 em todos os quadrados\\nnão terminais, exceto os da terceira coluna, onde o valor é 1; uma versão ruidosa pode dar o valor\\nerrado com probabilidade 0,1.\\nNos Capítulos 4 e 11, estudamos problemas de planejamento não determinístico e parcialmente\\nobservável, e identificamos o \\nestado de crença\\n — o conjunto de estados reais em que o agente\\npoderia estar — como um conceito fundamental para descrever e calcular soluções. Em POMDPs, o\\nestado de crença \\nb torna\\n-se uma \\ndistribuição de probabilidade\\n sobre todos os estados possíveis,\\ncomo no Capítulo 15. Por exemplo, o estado de crença inicial para o POMDP 4 × 3 poderia ter a\\ndistribuição uniforme sobre nove estados não terminais, ou seja, \\n〈\\n〉\\n.\\nEscreveremos \\nb\\n(\\ns\\n) para representar a probabilidade atribuída ao estado real \\ns\\n pelo estado de crença\\nb\\n. O agente pode calcular seu estado de crença atual como a distribuição de probabilidade\\ncondicional sobre os estados reais, dada a sequência de observações e ações até o momento. Em\\nessência, essa é a tarefa de \\nfiltragem\\n descrita no Capítulo 15. A equação de filtragem recursiva\\nbásica (15.5) mostra como calcular o novo estado de crença a partir do estado de crença anterior e a\\nnova evidência. No caso de POMDPs, também temos uma ação a considerar, mas o resultado é\\nessencialmente o mesmo. Se \\nb\\n(\\ns\\n) era o estado de crença anterior, e o agente executa a ação \\na\\n e\\npercebe a evidência \\ne\\n, então o novo estado de crença é dado por\\nonde é uma constante de normalização que torna a soma do estado de crença igual a 1. Por analogia\\ncom o operador de atualização de filtragem (\\nSeção 15.2.1\\n), podemos escrever como', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 764}),\n",
       " Document(page_content='No POMDP 4 × 3 suponha que o agente se mova para a \\nEsquerda\\n e seu sensor relate uma parede\\nadjacente; então, é bem provável (embora não garantido, porque tanto o movimento como o sensor\\nsão ruidosos) que o agente agora esteja em (3,1). O Exercício 17.13 pede para calcular os valores de\\nprobabilidade exata para o novo estado de crença.\\n A ideia fundamental necessária para entender os POMDPs é: \\na ação ótima depende apenas do\\nestado de crença atual do agente\\n. Isto é, a política ótima pode ser descrita por um mapeamento \\nπ\\n*\\n(\\nb\\n) de estados de crença para ações. Ela \\nnão\\n depende do estado \\nreal\\n em que o agente se encontra.\\nIsso é bom, porque o agente não conhece seu estado real; tudo o que ele conhece é o estado de\\ncrença. Consequentemente, o ciclo de decisão de um agente POMDP pode ser quebrado nos três\\nseguintes passos:\\n1. Dado o estado de crença atual \\nb\\n, executar a ação \\na\\n = π*(\\nb\\n).\\n2. Receber a percepção \\ne\\n.\\n3. Definir o estado de crença atual como PARAFRENTE(\\nb\\n, \\na\\n, \\ne\\n) e repetir.\\nAgora, podemos pensar que os POMDPs precisam fazer uma busca no espaço de estados de\\ncrença, exatamente como os métodos para problemas sem sensores e de contingência do Capítulo 4.\\nA principal diferença é que o espaço de estados de crença de POMDPs é \\ncontínuo\\n porque um estado\\nde crença de um POMDP é uma distribuição de probabilidade. Por exemplo, um estado de crença\\npara o mundo 4 × 3 é um ponto em um espaço contínuo de 11 dimensões. Uma ação altera o estado de\\ncrença, não apenas o estado físico. Assim, a ação é avaliada, pelo menos em parte, de acordo com as\\ninformações que o agente adquire como resultado. Portanto, os POMDPs incluem o valor da\\ninformação (\\nSeção 16.6\\n) como um componente do problema de decisão.\\nVamos examinar mais cuidadosamente o resultado das ações. Em particular, vamos calcular a\\nprobabilidade de um agente no estado de crença \\nb\\n alcançar o estado de crença \\nb\\n′ depois da execução\\nda ação \\na\\n. Se tivéssemos conhecimento da ação \\ne da percepção subsequente\\n, a Equação 17.11\\nforneceria uma atualização \\ndeterminística\\n para o estado de crença: \\nb\\n′ = PARAFRENTE(\\nb\\n, \\na\\n, \\ne\\n). É\\nclaro que a percepção subsequente ainda não é conhecida e, assim, o agente pode chegar a um dos\\nvários estados de crença \\nb\\n′ possíveis, dependendo da percepção que ocorre. A probabilidade de\\nperceber \\ne\\n, dado que \\na\\n foi executada a partir do estado de crença \\nb\\n, é dada pelo somatório sobre\\ntodos os estados reais \\ns\\n′, que o agente poderia alcançar:\\nVamos escrever a probabilidade de alcançar \\nb\\n′ a partir de \\nb\\n, dada a ação \\na\\n, como \\nP\\n(\\nb\\n′\\n|\\n \\nb\\n, \\na\\n).\\nEntão, isso nos dá', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 765}),\n",
       " Document(page_content='onde \\nP\\n(\\nb\\n′ | \\ne\\n, \\na\\n, \\nb\\n) é 1 se \\nb\\n′ = PARAFRENTE(\\nb\\n, \\na\\n, \\ne\\n) e 0 em caso contrário.\\nA Equação 17.12 pode ser vista como a definição de um modelo de transição para o espaço de\\nestados de crença. Também podemos definir uma função de recompensa para estados de crença (isto\\né, a recompensa esperada para os estados reais em que o agente poderia estar):\\n Juntos, \\nP\\n(\\nb\\n′ \\n| b,a\\n) e \\nP\\n(\\nb\\n) definem um MDP \\nobservável\\n sobre o espaço de estados de crença.\\nAlém disso, é possível mostrar que uma política ótima para esse MDP, \\nπ\\n*(\\nb\\n), também é uma política\\nótima para o POMDP original. Em outras palavras, \\na resolução de um POMDP em um espaço de\\nestados físicos pode ser reduzida à resolução de um MDP no espaço de estados de crença\\ncorrespondente\\n. Esse fato talvez seja menos surpreendente se lembrarmos que, por definição, o\\nestado de crença é sempre observável para o agente.\\nNote que, embora tenhamos reduzido os POMDPs a MDPs, o MDP que obtemos tem um espaço de\\nestados contínuo (e, em geral, com número elevado de dimensões). Nenhum dos algoritmos de MDP\\ndescritos nas Seções 17.2 e 17.3 se aplica diretamente a tais MDPs. As próximas duas subseções\\ndescrevem um algoritmo de iteração de valor projetado especificamente para POMDPs e um\\nalgoritmo de tomada de decisão on-line, semelhante ao desenvolvido para jogos no Capítulo 5.\\n17.4.2 Iteração de valor para POMDPs\\nA \\nSeção 17.2\\n descreveu um algoritmo de iteração de valor que calcula um valor de utilidade para\\ncada estado. Com os estados de crença infinitos, precisamos ser mais criativos. Considere uma\\npolítica ótima \\nπ\\n* e sua aplicação em um estado de crença específico \\nb\\n: a política gera uma ação;\\nentão, para cada percepção subsequente, o estado de crença é atualizado e uma nova ação é gerada, e\\nassim por diante. Para esse \\nb\\n específico, portanto, a política é exatamente equivalente a um \\nplano\\ncondicional\\n, conforme definido no Capítulo 4 para problemas não determinísticos e parcialmente\\nobserváveis. Em vez de pensar sobre as políticas, vamos pensar sobre planos condicionais e como a\\nutilidade esperada da execução de um plano condicional fixo varia com o estado de crença inicial.\\nFaremos duas observações:\\n1. Seja \\nα\\np\\n(\\ns\\n) a utilidade de execução de um plano condicional fixo \\np\\n que inicia em um estado\\nfísico \\ns\\n. Então, a utilidade esperada da execução de \\np\\n no estado de crença \\nb\\n é exatamente \\n ou \\nb\\n · \\nα\\np\\n se considerarmos ambos como vetores. Assim, a utilidade esperada de um\\nplano condicional fixo vai variar \\nlinearmente\\n com \\nb\\n, ou seja, corresponde a um hiperplano no\\nespaço de crença.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 766}),\n",
       " Document(page_content='2. Em qualquer estado de crença \\nb\\n dado a política ótima, vai escolher executar o plano\\ncondicional com a maior utilidade esperada, e a utilidade esperada de \\nb\\n sob política ótima será\\nexatamente a utilidade do plano condicional:\\nSe a política ótima \\nπ\\n* escolher executar \\np\\n a partir de \\nb\\n, então é razoável esperar que possamos\\nescolher executar \\np\\n nos estados de crença que estão muito perto de \\nb\\n. Na verdade, se limitarmos\\na profundidade dos planos condicionais, haverá apenas um número finito de tais planos e o\\nespaço contínuo de estados de crença geralmente será dividido em \\nregiões\\n, cada uma\\ncorrespondendo a determinado plano condicional que é o ótimo daquela região.\\nDessas duas observações, vemos que a função utilidade \\nU\\n(\\nb\\n) nos estados de crença, sendo o\\nmáximo de um conjunto de hiperplanos, será \\nlinear por partes\\n e \\nconvexa\\n.\\nPara ilustrar, utilizaremos um mundo simples de dois estados. Os estados são rotulados como 0 e\\n1, com \\nR\\n(0) = 0 e \\nR\\n(1) = 1. Há duas ações: \\nPermanecer\\n, faz com que o agente fique no mesmo estado\\ncom probabilidade 0,9, e \\nIr,\\n faz com que o agente mova para o outro estado com probabilidade 0,9.\\nPor enquanto vamos assumir o fator de desconto \\nγ\\n = 1. O sensor informa o estado correto com\\nprobabilidade 0,6. Obviamente, o agente deve \\nPermanecer\\n quando acredita que está no estado 1 e \\nIr\\nquando acredita que está no estado 0.\\nA vantagem de um mundo de dois estados é que o espaço de crença pode ser visto como\\nunidimensional porque as duas probabilidades devem somar 1. Na \\nFigura 17.8\\n (a), o eixo \\nx\\nrepresenta o estado de crença, definido por \\nb\\n(1), a probabilidade de estar no estado 1. Vamos\\nconsiderar os planos de um passo [\\nPermanecer\\n] e [\\nIr\\n], cada um dos quais recebe a recompensa pelo\\nestado corrente seguido pela recompensa (descontada) para o estado alcançado após a ação:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 767}),\n",
       " Document(page_content='Figura 17.8\\n (a) Utilidade de dois planos de um passo como função do estado de crença inicial \\nb\\n(1)\\npara o mundo de dois estados, com a função utilidade correspondente mostrada em negrito. (b)\\nUtilidades para oito planos distintos de dois passos. (c) Utilidades para quatro planos de dois passos\\nnão dominados. (d) Função utilidade para planos ótimos de oito passos.\\nOs hiperplanos (linhas, nesse caso) para \\nb\\n · \\nα\\n[\\nPermanecer\\n]\\n e \\nb\\n · \\nα\\n[\\nIr\\n]\\n são mostrados na \\nFigura\\n17.8\\n(a) e o seu máximo é mostrado em negrito. A linha em negrito representa, portanto, a função\\nutilidade para o problema de horizonte finito que permite apenas uma ação, e, em cada “parte” da\\nfunção utilidade linear por partes, a ação ótima é a primeira ação do plano condicional\\ncorrespondente. Nesse caso, a política de um passo ótima é \\nPermanecer\\n quando \\nb\\n(1) > 0,5 e \\nIr,\\n caso\\ncontrário.\\nUma vez que temos utilidades \\nα\\np\\n(\\ns\\n) para todos os planos condicionais \\np\\n de profundidade 1 em\\ncada estado físico \\ns\\n, podemos calcular as utilidades para os planos condicionais de profundidade 2\\nconsiderando cada primeira ação possível, cada percepção subsequente possível e, então, cada\\nforma de escolher um plano de profundidade 1 para executar para cada percepção:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 768}),\n",
       " Document(page_content='Ao todo, há oito planos distintos de profundidade 2, e suas utilidades são mostradas na \\nFigura\\n17.8\\n(b). Note que quatro dos planos mostrados como linhas tracejadas são subótimos em todo o\\nespaço de crença — dizemos que esses planos são \\ndominados\\n, e eles não precisam mais ser\\nconsiderados. Há quatro planos não dominados, cada um dos quais é ótimo em uma região\\nespecífica, como mostrado na Figura17.8(c). As regiões dividem o espaço de estados de crença.\\nRepetimos o processo para a profundidade 3, e assim por diante. Em geral, seja \\np\\n um plano\\ncondicional de profundidade \\nd\\n cuja ação inicial é \\na\\n e cujo subplano de profundidade \\nd\\n − 1 para a\\npercepção \\ne\\n é \\np.e\\n; então\\nEssa recursão naturalmente nos dá um algoritmo de iteração de valor, que está esboçado na \\nFigura\\n17.9\\n. A estrutura do algoritmo e sua análise de erro são semelhantes aos algoritmos de iteração de\\nvalor básico da \\nFigura 17.4\\n; a principal diferença é que, em vez de calcular um número de utilidade\\npara cada estado, o mantém uma coleção de planos não dominados com seus hiperplanos de\\nutilidade. A complexidade do algoritmo depende, principalmente, de quantos planos são gerados.\\nDadas |\\nA\\n| ações e |\\nE\\n| observações possíveis, é fácil mostrar que existem \\n planos distintos com\\nprofundidade \\nd\\n. Mesmo para o simples mundo de dois estados, com \\nd\\n = 8, o número exato é 2\\n255\\n. A\\neliminação dos planos dominados é fundamental para reduzir esse crescimento duplamente\\nexponencial: o número de planos não dominados com \\nd\\n = 8 é de apenas 144. A função utilidade para\\nesses 144 planos é mostrada na \\nFigura 17.8\\n(d).\\nfunção\\nITERAÇÃO-DE-VALOR-POMDP(pomdp, \\n∊\\n) \\nretorna\\n uma função utilidade\\n    \\nentradas\\n: \\npomdp\\n, um POMDP com estados \\nS\\n, ações \\nA\\n(\\ns\\n), modelo de transição \\nP\\n(\\ns\\n′ | \\ns\\n, \\na\\n),\\nmodelo de sensoriamento \\nP\\n(\\ne\\n | \\ns\\n), recompensa \\nR\\n(\\ns\\n), desconto γ\\n∊\\n, erro máximo permitido na utilidade de qualquer estado\\n    \\nvariáveis \\u200b\\u200blocais\\n: \\nU\\n, \\nU\\n′, conjuntos de planos \\np\\n associados com vetores de utilidade a\\np\\n    \\nU\\n′ ← conjunto contendo apenas o plano vazio [ ], com a\\n[ ]\\n (\\ns\\n) = \\nR\\n(\\ns\\n)\\n    \\nrepetir\\n    \\nU\\n ← \\nU\\n′\\n        \\nU\\n′ ← conjunto de todos os planos que consistem em uma ação e, para cada próxima\\npercepção possível, um plano em \\nU\\n com vetores de utilidade calculados de acordo com a\\nEquação 17.13\\n        \\nU\\n′ ← REMOVER-PLANOS-DOMINADOS (\\nU\\n′)\\n    \\naté\\n DIFERENÇA-MAX (\\nU\\n, \\nU\\n′) < \\n∊\\n(1 − γ)/γ\\n    \\nretornar\\n \\nU\\nFigura 17.9\\n Esboço de alto nível do algoritmo de iteração de valor para POMDPs. A etapa\\nREMOVER-PLANOS-DOMINADOS e o teste da DIFERENÇA-MAX são implementados\\nnormalmente como programas lineares.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 769}),\n",
       " Document(page_content='Observe que, apesar do estado 0 ter utilidade mais baixa do que o estado 1, os estados de crença\\nintermediários têm utilidade ainda mais baixa porque o agente não tem a informação necessária para\\nescolher uma boa ação. É por isso que a informação tem valor no sentido definido na \\nSeção 16.6\\n, e\\nas políticas ótimas em POMDPs muitas vezes incluem ações de coleta de informações.\\nDada tal função utilidade, pode-se extrair uma política executável examinando qual hiperplano é\\nótimo em qualquer estado de crença dado \\nb\\n e executando a primeira ação do plano correspondente.\\nNa \\nFigura 17.8\\n(d), a política ótima correspondente ainda é a mesma que para os planos de\\nprofundidade 1: \\nPermanecer\\n quando \\nb\\n(1) > 0,5 e \\nIr\\n, caso contrário.\\nNa prática, o algoritmo de iteração de valor na \\nFigura 17.9\\n é muito ineficiente para problemas\\nmaiores — mesmo o POMDP 4 × 3 é muito difícil. A principal razão é que, dados \\nn\\n planos\\ncondicionais no nível \\nd\\n, o algoritmo constrói |\\nA\\n| · \\nn\\n|\\nE\\n|\\n planos condicionais no nível \\nd\\n + 1 antes de\\neliminar os dominados. Desde os anos 1970, quando esse algoritmo foi desenvolvido, houve vários\\navanços, incluindo formas mais eficientes de iteração de valor e de vários tipos de algoritmos de\\niteração de política. Alguns deles são discutidos nas notas ao final do capítulo. No entanto, para\\nPOMDPs em geral, encontrar políticas ótimas é muito difícil (PSPACE-difícil, na verdade, ou seja,\\nmuito difícil mesmo). Problemas com poucas dúzias de estados muitas vezes são inviáveis. A\\npróxima seção descreve um método diferente, aproximado, para resolver POMDPs, baseado em\\nbusca de observação para frente.\\n17.4.3 Agentes on-line de POMDPs\\nNesta seção, esboçaremos uma abordagem simples para projeto de agentes destinados a ambientes\\nestocásticos parcialmente observáveis. Os elementos básicos do projeto já são familiares:\\n•  Os modelos de transição e sensoriamento são representados por uma \\nrede bayesiana dinâmica\\n(DBN), como descrito no Capítulo 15.\\n•  A rede bayesiana dinâmica é estendida com nós de decisão e utilidade, como os que são usados\\nnas \\nredes de decisão\\n do Capítulo 16. O modelo resultante é chamado de \\nrede de decisão\\ndinâmica\\n ou DDN.\\n•  Um algoritmo de filtragem é usado para incorporar cada nova percepção e cada nova ação, e\\npara atualizar a representação de estados de crença.\\n•  As decisões são tomadas projetando-se para frente sequências de ações diretas possíveis e\\nescolhendo-se a melhor.\\nDBNs são \\nrepresentações fatoradas\\n na terminologia do Capítulo 2, elas normalmente têm a\\nvantagem da complexidade exponencial sobre as representações atômicas e podem modelar muitos\\nproblemas do mundo real. O projeto de agente é, portanto, uma implementação prática do \\nagente\\nbaseado na utilidade\\n esboçado no Capítulo 2.\\nNuma DBN, o único estado \\nS\\nt\\n torna-se um conjunto de variáveis de estado \\nX\\nt\\n, e pode haver\\nmúltiplas variáveis de evidência \\nE\\nt\\n. Usaremos \\nA\\nt\\n para fazer referência à ação no instante \\nt\\n e, assim, o\\nmodelo de transição se torna \\nP\\n(\\nX\\nt+1\\n|X\\nt\\n, A\\nt\\n) e o modelo de sensoriamento se torna, \\nP\\n(\\nE\\nt\\n|X\\nt\\n). Usaremos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 770}),\n",
       " Document(page_content='R\\nt\\n para fazer referência à recompensa recebida no instante \\nt\\n e \\nU\\nt\\n para fazer referência à utilidade do\\nestado no tempo \\nt\\n (ambas são variáveis aleatórias). Com essa notação, uma rede de decisão dinâmica\\nserá semelhante à rede mostrada na \\nFigura 17.10\\n.\\nFigura 17.10\\n Estrutura genérica de uma rede de decisão dinâmica. As variáveis com valores\\nconhecidos estão sombreadas. O tempo atual é \\nt\\n e o agente deve decidir o que fazer, isto é, escolher\\num valor para \\nA\\nt\\n. A rede foi desenvolvida para o futuro correspondente a três passos e representa\\nrecompensas futuras, bem como a utilidade do estado no horizonte de observação para frente.\\nAs redes de decisão dinâmica podem ser usadas como entrada para qualquer algoritmo de\\nPOMDP, incluindo aqueles para métodos de iteração de valor e de política. Nesta seção, vamos nos\\nconcentrar em métodos de observação antecipada que projetam para frente sequências de ações, a\\npartir do estado de crença atual, de maneira muito semelhante à forma como funcionam os algoritmos\\nde jogos do Capítulo 5. A rede da \\nFigura 17.10\\n foi projetada três passos para o futuro; as decisões\\natuais e futuras \\nA\\n, as observações futuras \\nE\\n e as recompensas futuras \\nR\\n são desconhecidas. Note que\\na rede inclui nós para as \\nrecompensas\\n correspondentes a \\nX\\nt\\n+1\\n e \\nX\\nt+2\\n, mas a \\nutilidade\\n correspondente\\na \\nX\\nt\\n+3\\n. Isso ocorre porque o agente deve maximizar a soma (descontada) de todas as recompensas\\nfuturas, e \\nU\\n(\\nX\\nt\\n+3\\n) representa a recompensa para \\nX\\nt\\n+3\\n e todas as recompensas subsequentes. Como no\\nCapítulo 5, supomos que \\nU\\n só está disponível em alguma forma aproximada: se estivessem\\ndisponíveis valores de utilidade exata, não haveria necessidade de observação antecipada além da\\nprofundidade 1.\\nA \\nFigura 17.11\\n mostra parte da árvore de busca que corresponde à DDN de observação\\nantecipada de três passos da \\nFigura 17.10\\n. Cada um dos nós triangulares é um estado de crença em\\nque o agente toma uma decisão \\nA\\nt+i\\n para \\ni\\n = 0, 1, 2,…. Os nós (de chance) redondos correspondem a\\nescolhas feitas pelo ambiente, isto é, em qual observação \\nE\\nt\\n+i\\n ocorre. Note que não existe nenhum nó\\nde chance correspondente aos resultados de ações; isso acontece porque a atualização do estado de\\ncrença para uma ação é determinística, não importando o resultado real.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 771}),\n",
       " Document(page_content='Figura 17.11\\n Parte da solução de observação antecipada da DDN da \\nFigura 17.10\\n. Cada decisão\\nserá tomada no estado de crença indicado.\\nO estado de crença em cada nó triangular pode ser calculado aplicando-se um algoritmo de\\nfiltragem à sequência de percepções e ações que levam a ele. Desse modo, o algoritmo leva em conta\\no fato de que, para a decisão \\nA\\nt+i\\n, o agente \\nterá\\n percepções disponíveis \\nE\\nt+1\\n,…, \\nE\\nt+i\\n, embora, no\\ntempo \\nt\\n, ele não saiba quais serão essas percepções. Desse modo, um agente de teoria da decisão\\nlevará em conta automaticamente o valor da informação e executará ações de coleta de informações\\nonde for apropriado.\\nUma decisão pode ser extraída da árvore de busca copiando-se os valores de utilidade das folhas,\\ntomando uma média nos nós de chance e o máximo nos nós de decisão. Isso é semelhante ao\\nalgoritmo EXPECTIMINIMAX para árvores de jogos com nós de chance, exceto pelo fato de que (1)\\ntambém podem existir recompensas em estados que não são folhas e (2) os nós de decisão\\ncorrespondem a estados de crença, e não a estados reais. A complexidade de tempo de uma busca\\nexaustiva até a profundidade \\nd\\n é \\nO\\n(|\\nA\\n|\\nd\\n ·|\\nE\\n|\\nd\\n), onde |\\nA\\n| é o número de ações disponíveis e \\x00\\nE\\n\\x00 é o\\nnúmero de percepções possíveis (note que é bem menos que o número de planos condicionais de\\nprofundidade \\nd\\n gerados pela iteração de valor). Para problemas em que o fator de desconto \\nγ\\n não é\\ntão próximo de 1, uma busca rasa frequentemente é boa o bastante para gerar decisões quase ótimas.\\nTambém é possível fazer uma aproximação da etapa de cálculo da média nos nós de chance pela\\namostragem do conjunto de percepções possíveis, em vez de somar todas as percepções possíveis.\\nExistem várias outras maneiras de descobrir rapidamente boas soluções aproximadas, mas vamos\\nadiá-las até o Capítulo 21.\\nOs agentes de teoria da decisão baseados em redes de decisão dinâmicas têm diversas vantagens\\nem comparação com outros projetos de agentes mais simples apresentados em capítulos anteriores.\\nEm particular, eles tratam ambientes com incerteza, parcialmente observáveis, e podem revisar com\\nfacilidade seus “planos” para tratar percepções inesperadas. Com modelos apropriados de sensores,\\neles podem tratar falhas de sensores e planejar para obter informações. Esses agentes exibem\\n“degradação suave” sob limitação de tempo e em ambientes complexos, utilizando várias técnicas de\\naproximação. Então, o que está faltando? Um defeito de nosso algoritmo baseado em DDN é sua\\nconfiança na busca para a frente através do espaço de estados, em vez de utilizar as técnicas de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 772}),\n",
       " Document(page_content='planejamento hierárquicos e outras técnicas avançadas de planejamento descritas no Capítulo 11.\\nHouve tentativas para estender essas técnicas ao domínio probabilístico, mas até agora elas se\\nmostraram ineficientes. Um segundo problema relacionado é a natureza basicamente proposicional da\\nlinguagem de DDNs. Gostaríamos de poder estender algumas das ideias das linguagens\\nprobabilísticas de primeira ordem ao problema de tomada de decisões. A pesquisa atual tem\\nmostrado que essa extensão é possível e tem benefícios significativos, como veremos nas notas no\\nfinal do capítulo.\\n17.5 DECISÕES COM VÁRIOS AGENTES: TEORIA DOS JOGOS\\nEste capítulo se concentrou na tomada de decisões em ambientes incertos. Porém, e se a incerteza\\nse dever a outros agentes e às decisões que eles tomam? E se as decisões desses agentes, por sua\\nvez, forem influenciadas por nossas decisões? Já tratamos essa questão antes, quando estudamos os\\njogos no Capítulo 5. No entanto, naquele capítulo, estávamos preocupados com jogos de revezamento\\nem ambientes completamente observáveis, para os quais a busca de minimax pode ser empregada\\npara encontrar movimentos ótimos. Nesta seção, estudaremos os aspectos da \\nteoria dos jogos\\n que\\npodem ser utilizados para analisar jogos com movimentos simultâneos e outras fontes de\\nobservabilidade parcial (os teóricos dos jogos usam as expressões \\ninformação perfeita\\n e\\ninformação imperfeita\\n, ao em vez de total e parcialmente observável). Existem pelo menos duas\\nmaneiras de utilizar a teoria dos jogos:\\n1. \\nProjeto de agentes\\n: A teoria dos jogos pode analisar as decisões do agente e calcular a\\nutilidade esperada para cada decisão (sob a hipótese de que outros agentes estão agindo de\\nforma ótima de acordo com a teoria dos jogos). Por exemplo, no jogo \\npar ou ímpar\\n, dois\\njogadores, \\nO\\n e \\nE\\n, exibem simultaneamente um ou dois dedos. Seja \\nf\\n o número total de dedos. Se\\nf\\n é ímpar, \\nO\\n recebe \\nf\\n dólares de \\nE\\n e, se \\nf\\n é par, \\nE\\n recebe \\nf\\n dólares de \\nO\\n. A teoria dos jogos\\npode determinar a melhor estratégia contra um jogador racional e o retorno esperado para cada\\njogador.\\n4\\n2. \\nProjeto de mecanismos\\n: Quando um ambiente é habitado por muitos agentes, talvez seja\\npossível definir as regras do ambiente (isto é, o jogo que os agentes devem jogar) de forma que\\no bem coletivo de todos os agentes seja maximizado quando cada agente adotar a solução da\\nteoria dos jogos que maximiza sua própria utilidade. Por exemplo, a teoria dos jogos pode\\najudar a projetar os protocolos para uma coleção de roteadores de tráfego da Internet, de forma\\nque cada roteador tenha um incentivo para agir de tal modo que o \\nthroughput\\n global seja\\nmaximizado. O projeto de mecanismos também pode ser usado para construir \\nsistemas\\nmultiagente\\n inteligentes que resolvem problemas complexos de modo distribuído.\\n17.5.1 Jogos de um movimento\\nComeçamos por considerar um conjunto restrito de jogos: aqueles em que todos os jogadores agem\\nsimultaneamente e o resultado do jogo é baseado nesse único conjunto de ações. (Na verdade, não é', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 773}),\n",
       " Document(page_content='fundamental que as ações ocorram exatamente ao mesmo tempo; o que importa é que nenhum jogador\\ntenha conhecimento das escolhas dos outros jogadores.) A restrição a um único movimento (e o\\npróprio uso da palavra “jogo”) pode fazer isso parecer trivial, mas na verdade a teoria dos jogos é\\num assunto sério.\\nEla é utilizada em situações de tomada de decisão, incluindo o leilão de direitos de perfuração de\\npetróleo e direitos de espectro de frequência sem fio, processos de falência, desenvolvimento de\\nprodutos e decisões de preços, e defesa nacional — situações que envolvem bilhões de dólares e\\ncentenas de milhares de vidas. Um jogo de um movimento é definido por três componentes:\\n•  Os \\njogadores\\n ou agentes que estarão tomando decisões. Os jogos de dois jogadores têm\\nrecebido mais atenção, embora também sejam comuns jogos de \\nn\\n jogadores, sendo \\nn\\n > 2.\\nUtilizaremos nomes de jogadores com letras (iniciais) maiúsculas, como \\nAlice\\n e \\nBob\\n ou \\nO\\n e \\nE\\n.\\n•  As \\nações\\n que os jogadores podem escolher. Empregaremos nomes em minúsculas para\\nrepresentar as ações, como \\num\\n ou \\ntestemunhar\\n. Os jogadores podem ter ou não o mesmo\\nconjunto de ações disponíveis.\\n•  Uma \\nfunção recompensa\\n que fornece a cada jogador a utilidade correspondente a cada\\ncombinação de ações realizadas por todos os jogadores. Para jogos de um movimento, a função\\nrecompensa pode ser representada por uma matriz, uma representação conhecida como \\nforma\\nestratégica\\n (também chamada de \\nforma normal\\n). A matriz de recompensa para o jogo de par ou\\nímpar é dada a seguir:\\nO: um\\nO: dois\\nE: um\\nE\\n = +2, \\nO\\n = –2\\nE\\n = –3, \\nO\\n = +3\\nE: dois\\nE\\n = –3, \\nO\\n = +3\\nE\\n = +4, \\nO\\n = –4\\nPor exemplo, o canto inferior direito mostra que, quando \\nO\\n escolhe a ação \\ndois\\n e \\nE\\n também\\nescolhe \\ndois\\n, a recompensa é +4 para \\nE\\n e –4 para \\nO\\n.\\nCada jogador em um jogo deve adotar e depois executar uma \\nestratégia\\n (o nome usado em teoria\\ndos jogos para indicar uma \\npolítica\\n). Uma \\nestratégia pura\\n é uma política determinística; no caso de\\num jogo de um movimento, uma estratégia pura é apenas uma ação única. Para muitos jogos, um\\nagente pode fazer melhor com uma \\nestratégia mista\\n, que é uma política aleatória que seleciona\\nações de acordo com uma distribuição de probabilidade. A estratégia mista que escolhe a ação \\na\\ncom probabilidade \\np\\n e a ação \\nb\\n em caso contrário é escrita como [\\np\\n: \\na\\n; (1 – \\np\\n): \\nb\\n]. Por exemplo, uma\\nestratégia mista para par ou ímpar poderia ser [0,5: \\num\\n; 0,5: \\ndois\\n]. Um \\nperfil de estratégia\\n é uma\\natribuição de uma estratégia para cada jogador; dado o perfil de estratégia, o \\nresultado\\n do jogo é um\\nvalor numérico para cada jogador.\\nUma \\nsolução\\n para um jogo é um perfil de estratégia em que cada jogador adota uma estratégia\\nracional. Veremos que a questão mais importante em teoria dos jogos é definir o que significa\\n“racional” quando cada agente escolhe apenas uma parte do perfil de estratégia que determina o\\nresultado. É importante perceber que esses resultados são resultados reais da participação em um\\njogo, enquanto soluções são construções teóricas utilizadas para analisar um jogo. Veremos que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 774}),\n",
       " Document(page_content='alguns jogos só têm uma solução em estratégias mistas. Porém, isso não significa que um jogador\\ndeva literalmente adotar uma estratégia mista para ser racional.\\nConsidere a situação a seguir: dois suspeitos de roubo, Alice e Bob, são pegos em flagrante\\npróximo à cena de um roubo e são interrogados separadamente pela polícia. Um promotor oferece um\\nacordo a cada um: se você testemunhar contra seu parceiro como o líder do roubo do anel, ficará\\nlivre por ter cooperado, enquanto seu parceiro pegará 10 anos de prisão. No entanto, se um\\ntestemunhar contra o outro, ambos terão cinco anos de pena. Alice e Bob também sabem que, se os\\ndois se recusarem a depor, a pena será de apenas um ano para cada um, pelo delito mais leve de\\nestar de posse de propriedade roubada. Agora, Alice e Bob estão diante do chamado \\ndilema do\\nprisioneiro:\\n eles devem testemunhar ou recusar o acordo? Sendo agentes racionais, Alice e Bob\\nquerem, cada um, maximizar sua própria utilidade esperada. Vamos supor que Alice esteja\\ninsensivelmente desinteressada em relação ao destino do seu companheiro e, portanto, sua utilidade\\ndiminui proporcionalmente ao número de anos que ela passará na prisão, não importando o que\\nacontecerá a Bob. Por sua vez, Bob se sente exatamente do mesmo modo. Para ajudá-los a alcançar\\numa decisão racional, os dois constroem a seguinte matriz de recompensa:\\nAlice: testemunhar\\nAlice: recusar\\nBob: testemunhar\\nA\\n = –5, \\nB\\n = –5\\nA\\n = –10, \\nB\\n = 0\\nBob: recusar\\nA\\n = 0, \\nB\\n = –10\\nA\\n = –1, \\nB\\n = –1\\nAlice analisa a matriz de recompensa da seguinte maneira: “Suponha que Bob testemunhe. Nesse\\ncaso, eu pego cinco anos se testemunhar e 10 anos se não o fizer; portanto, nesse caso, testemunhar é\\nmelhor. Por outro lado, se Bob se recusar, eu consigo 0 se testemunhar e um ano se me recusar; logo,\\ntambém nesse caso, testemunhar é melhor. Desse modo, em um ou outro caso, para mim é melhor\\ntestemunhar, de forma que isso é o que devo fazer.”\\nAlice descobriu que \\ntestemunhar\\n é uma \\nestratégia dominante\\n para o jogo. Dizemos que uma\\nestratégia \\ns\\n para o jogador \\np\\n \\ndomina fortemente\\n a estratégia \\ns\\n′ se o resultado correspondente a \\ns\\n é\\nmelhor para \\np\\n que o resultado correspondente a \\ns\\n′, considerando-se todas as escolhas de estratégias\\npelos outros jogadores. A estratégia \\ns\\n \\ndomina fracamente\\n \\ns\\n′ se \\ns\\n é melhor que \\ns\\n′ em pelo menos um\\nperfil de estratégia e não é pior em qualquer outro. Uma estratégia dominante é uma estratégia que\\ndomina todas as outras. É irracional executar uma estratégia fortemente dominada e irracional não\\nexecutar uma estratégia dominante, se ela existir. Sendo racional, Alice escolhe a estratégia\\ndominante. Precisamos apenas de um pouco mais de terminologia antes de continuar: dizemos que um\\nresultado é \\nótimo de Pareto\\n5\\n se não há nenhum outro resultado preferido por todos os jogadores. Um\\nresultado é \\ndominado de Pareto\\n por outro resultado se todos os jogadores preferem o outro\\nresultado.\\nSe for inteligente e também racional, Alice continuará a raciocinar assim: a estratégia dominante\\nde Bob também é testemunhar. Então, ele testemunhará e nós dois pegaremos cinco anos. Quando\\ncada jogador tem uma estratégia dominante, a combinação dessas estratégias é chamada \\nequilíbrio de\\nestratégia dominante\\n. Em geral, um perfil de estratégia forma um \\nequilíbrio\\n se nenhum jogador pode\\nse beneficiar da troca de estratégias, dado que todos os outros jogadores se mantêm com a mesma\\nestratégia. Um equilíbrio é essencialmente um \\nótimo local\\n no espaço de políticas; ele é a parte', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 775}),\n",
       " Document(page_content='superior de um pico que desce ao longo de toda dimensão, onde uma dimensão corresponde às\\nescolhas de estratégias de um jogador.\\n O matemático John Nash (1928−) provou que \\ntodo jogo tem pelo menos um equilíbrio.\\n O\\nconceito geral de equilíbrio é agora chamado de \\nequilíbrio de Nash\\n em sua honra. Certamente, uma\\nestratégia dominante de equilíbrio é o equilíbrio de Nash (Exercício 17.16), mas alguns jogos têm\\nequilíbrio de Nash mas nenhuma estratégia dominante.\\nO \\ndilema\\n no dilema do prisioneiro é que o resultado do ponto de equilíbrio é pior para ambos os\\njogadores que o resultado que eles obteriam se ambos se recusassem a testemunhar. Em outras\\npalavras, o resultado para a solução de equilíbrio é dominada de Pareto pelo resultado (–1, –1) de\\n(\\nrecusar\\n, \\nrecusar\\n). Existe algum modo de Alice e Bob chegarem ao resultado (–1, –1)? Certamente\\numa opção \\npermissível\\n para ambos é se recusar a testemunhar, mas é difícil ver como os agentes\\nracionais podem chegar lá, dada a definição do jogo. Qualquer dos jogadores que preferir jogar\\nrecusar\\n perceberá que seria melhor jogar \\ntestemunhar\\n. Esse é o poder de atração de um ponto de\\nequilíbrio. Teóricos de jogos concordam que estar em equilíbrio de Nash é uma condição necessária\\npara uma solução, embora discordem se essa é uma condição suficiente.\\nÉ suficientemente fácil chegar à solução (\\nrecusar, recusar\\n) se modificarmos o jogo. Por exemplo,\\npoderíamos mudar para um \\njogo repetido\\n em que os jogadores sabem que se encontrarão novamente.\\nOu os agentes podem ter crenças morais que encorajam cooperação e justiça. O que significa que\\neles têm uma função utilidade diferente, necessitando de uma matriz de recompensa diferente,\\ntornando esse um jogo diferente. Veremos mais adiante que alterar os agentes para ter poderes\\ncomputacionais limitados, em vez da habilidade de raciocinar de maneira absolutamente racional,\\npode resultar em resultados sem equilíbrio, pois pode informar a um agente que o outro tem\\nracionalida limitada. Nesse caso, estamos considerando um jogo diferente do descrito anteriormente\\nna matriz de recompensa.\\nAgora, vamos examinar um jogo que não tem nenhuma estratégia dominante. A Acme, uma empresa\\nfabricante de hardware para videogames, tem de decidir se sua próxima máquina de jogos usará\\nDVDs ou discos Blu-ray. Enquanto isso, o produtor de software de videogames Best precisa decidir\\nse deve produzir seu próximo jogo em DVD ou Blu-ray. Os lucros para ambos serão positivos se\\neles concordarem e negativos se discordarem, como mostra a matriz de recompensa a seguir:\\nAcme: bluray\\nAcme: dvd\\nBest: bluray\\nA\\n = +9, \\nB\\n = +9\\nA\\n = –4, \\nB\\n = –1\\nBest: dvd\\nA\\n = –3, \\nB\\n = –1\\nA\\n = +5, \\nB\\n = +5\\n Não existe nenhum equilíbrio de estratégia dominante para esse jogo, mas existem \\ndois\\nequilíbrios de Nash\\n: (bluray, bluray)\\n e (\\ndvd\\n, \\ndvd\\n). Sabemos que esses são equilíbrios de Nash\\nporque, se um ou outro jogador mudar unilateralmente para uma estratégia diferente, esse jogador\\nficará em pior situação. Agora os agentes têm um problema: \\nexistem várias soluções aceitáveis,\\nmas\\n, \\nse cada agente escolher uma solução diferente, ambos os agentes sofrerão\\n. Como eles podem\\nconcordar sobre uma solução? Uma resposta é que ambos devem escolher a solução ótima de Pareto\\n(bluray, bluray)\\n; isto é, podemos restringir a definição de “solução” ao único equilíbrio de Nash', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 776}),\n",
       " Document(page_content='ótimo de Pareto, \\ndesde que exista um\\n. Todo jogo tem pelo menos uma solução ótima de Pareto, mas\\num jogo poderia ter várias ou elas não seriam pontos de equilíbrio. Por exemplo, se (\\nbluray, bluray\\n)\\ntiver recompensa (5,5), haverá dois pontos de equilíbrio ótimo de Pareto iguais entre si. Para\\nescolher entre eles, os agentes podem adivinhar ou \\nse comunicar\\n, o que pode ser feito\\nestabelecendo-se uma convenção que ordena as soluções antes de o jogo começar ou negociando\\npara alcançar uma solução mutuamente benéfica durante o jogo (o que significaria incluir ações de\\ncomunicação como parte de um jogo sequencial). Desse modo, a comunicação surge na teoria dos\\njogos exatamente pelas mesmas razões que a fizeram surgir no planejamento de multiagentes na\\nSeção 11.4\\n. Jogos como esse em que os jogadores precisam se comunicar são chamados de \\njogos de\\ncoordenação\\n.\\nVimos que um jogo pode ter mais de um equilíbrio de Nash; como sabemos que todo jogo deve ter\\npelo menos um? Alguns jogos não têm nenhum equilíbrio de Nash de \\nestratégia pura\\n. Por exemplo,\\nconsidere qualquer perfil de estratégia pura para o jogo de par ou ímpar. Se o número total de dedos\\nfor par, \\nO\\n desejará trocar sua aposta; por outro lado, se o total for ímpar, então \\nE\\n desejará mudar.\\nPortanto, nenhum perfil de estratégia pura pode ser um equilíbrio e nesse caso devemos examinar\\nestratégias mistas. Mas qual estratégia mista? Em 1928, von Neumann desenvolveu um método para\\nencontrar a \\nestratégia mista ótima\\n para \\njogos de soma zero —\\n jogos em que a soma das\\nrecompensas é sempre zero.\\n6\\n Sem dúvida, o jogo de par ou ímpar é um desses jogos. No caso de\\njogos de dois jogadores de soma zero, sabemos que as recompensas são iguais e opostas, e portanto\\nprecisamos considerar as recompensas de apenas um jogador, que será o maximizador (da mesma\\nmaneira que no Capítulo 5). No caso do par ou ímpar, selecionamos o jogador que escolhe par, \\nE\\n,\\npara ser o maximizador, e então podemos definir a matriz de recompensa pelos valores \\nU\\nE\\n(\\ne\\n, \\no\\n) — a\\nrecompensa para \\nE\\n se \\nE\\n executa a ação \\ne\\n e \\nO\\n executa \\no\\n (por conveniência, chamaremos o jogador \\nE\\nde “sua” e o jogador O de “seu”). O método de von Neumann é chamado de técnica de \\nmaximin\\n, e\\nfunciona da maneira descrita a seguir:\\n•  Suponha que mudamos as regras da seguinte forma: primeiro \\nE\\n escolhe sua estratégia e revela\\npara \\nO\\n. Então, \\nO\\n escolhe sua estratégia, com conhecimento da estratégia de \\nE\\n. Finalmente,\\navaliamos a recompensa esperada do jogo com base nas estratégias escolhidas. Isso nos dá um\\njogo de revezamento ao qual podemos aplicar o algoritmo \\nminimax\\n do Capítulo 5. Vamos supor\\nque isso forneça um resultado \\nU\\nE,O\\n. É claro que esse jogo favorece \\nO\\n, e, assim, a verdadeira\\nutilidade \\nU\\n do jogo original (do ponto de vista de \\nE\\n) é, \\nno mínimo\\n, \\nU\\nE,O\\n. Por exemplo, se\\nsimplesmente examinarmos estratégias puras, a árvore de jogo de minimax terá um valor de raiz\\nigual a –3 (veja a \\nFigura 17.12\\n(a)), e assim sabemos que \\nU\\n ≥ – 3.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 777}),\n",
       " Document(page_content='Figura 17.12\\n (a) e (b): Árvores de jogos de minimax para o jogo par ou ímpar, se os jogadores se\\nrevezam jogando estratégias puras. (c) e (d): Árvores de jogos parametrizadas em que o primeiro\\njogador executa uma estratégia mista. As recompensas dependem do parâmetro de probabilidade (\\np\\nou \\nθ\\n) na estratégia mista. (e) e (f): Para qualquer valor específico do parâmetro de probabilidade, o\\nsegundo jogador escolherá a “melhor” das duas ações e, assim, o valor da estratégia mista do\\nprimeiro jogador é dado pelas linhas grossas. O primeiro jogador escolherá o parâmetro de\\nprobabilidade para a estratégia mista no ponto de interseção.\\n•  Agora, vamos supor que alteramos as regras para forçar \\nO\\n a revelar sua estratégia primeiro,\\nseguido por \\nE\\n. Então, o valor de minimax desse jogo será \\nU\\nO,E\\n e, como esse jogo favorece \\nE\\n,\\nsabemos que \\nU\\n é, \\nno máximo\\n, \\nU\\nO,E\\n. Com estratégias puras, o valor é +2 (veja a \\nFigura\\n17.12\\n(b)), e assim sabemos que \\nU\\n ≤ +2.\\nCombinando esses dois argumentos, vemos que a verdadeira utilidade \\nU\\n da solução para o jogo\\noriginal deve satisfazer', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 778}),\n",
       " Document(page_content='Para definir o valor de \\nU\\n, precisamos deslocar nossa análise para as estratégias mistas.\\nPrimeiro, observe: \\numa vez que o primeiro jogador revela sua estratégia\\n, \\no segundo jogador pode\\ntambém escolher uma estratégia pura\\n. A razão é simples: se o segundo jogador jogar uma estratégia\\nmista, [\\np\\n: \\num\\n; (1 – \\np\\n): \\ndois\\n], sua utilidade esperada será uma combinação linear (\\np\\n \\n⋅\\n \\nu\\num\\n + (1 – \\np\\n) \\n⋅\\nu\\ndois\\n) das utilidades das estratégias puras \\nu\\num\\n e \\nu\\ndois\\n. Essa combinação linear nunca pode ser melhor\\nque a melhor entre \\nu\\num\\n e \\nu\\ndois\\n, e assim o segundo jogador pode simplesmente escolher a melhor\\ndelas.\\nCom essa observação em mente, as árvores de minimax podem ser imaginadas como tendo número\\ninfinito de ramificações na raiz, correspondentes ao número infinitamente grande de estratégias\\nmistas que o primeiro jogador pode escolher. Cada uma delas leva a um nó com duas ramificações\\nque correspondem às estratégias puras para o segundo jogador. Podemos representar essas árvores\\ninfinitas de forma finita, tendo uma única escolha “parametrizada” na raiz:\\n•  Se \\nE\\n se move primeiro, a situação é a mostrada na \\nFigura 17.12\\n(c). \\nE\\n escolhe a estratégia [\\np\\n:\\num\\n; (1–\\np\\n): \\ndois\\n] na raiz, e depois \\nO\\n escolhe uma estratégia pura (e por isso um movimento) dado\\no valor de \\np\\n. Se \\nO\\n escolher \\num\\n, a recompensa esperada (para \\nE\\n) é 2\\np\\n – 3(1 – \\np\\n) = 5\\np\\n – 3; se \\nO\\nescolher \\ndois\\n, a recompensa esperada é –3\\np\\n + 4(1 – \\np\\n)= 4 – 7\\np\\n. Podemos desenhar essas duas\\nrecompensas como linhas retas em um grafo, onde \\np\\n varia de 0 até 1 no eixo \\nx\\n, como mostra a\\nFigura 17.12\\n(e). \\nO\\n, o minimizador, sempre escolherá a mais baixa das duas linhas, como\\nmostram as linhas grossas na figura. Portanto, o melhor que \\nE\\n pode fazer na raiz é escolher \\np\\npara o ponto de interseção, onde:\\n5\\np\\n – 3 = 4 – 7\\np\\n \\n⇒\\n \\np\\n = 7/12.\\nA utilidade para \\nE\\n nesse ponto é \\nU\\nE,O\\n = –1/12.\\n•  Se \\nO\\n se mover primeiro, a situação será a da \\nFigura 17.12\\n(d). \\nO\\n escolhe a estratégia [\\nθ\\n: \\num\\n; (1–\\nθ\\n): \\ndois\\n] na raiz, e então \\nE\\n escolhe um movimento, dado o valor de \\nθ\\n. As recompensas são 2\\nθ\\n –\\n3(1 – \\nθ\\n) = 5\\nθ\\n – 3 e –3\\nθ\\n + 4(1 – \\nθ\\n) = 4 – 7\\nθ\\n.\\n7\\n Novamente, a \\nFigura 17.12\\n(f) mostra que o melhor\\nque \\nO\\n pode fazer na raiz é escolher o ponto de interseção:\\n5\\nθ\\n – 3 = 1 – 7\\nθ\\n \\n⇒\\n \\nθ\\n = 7/12.\\nA utilidade para \\nE\\n nesse ponto é \\nU\\nO,E\\n = –1/12.\\nAgora sabemos que a verdadeira utilidade do jogo original fica entre –1/12 e –1/12, ou seja, ela é\\nexatamente –1/12! (A moral é que é melhor ser \\nO\\n do que \\nE\\n, se você estiver participando desse jogo.)\\nAlém disso, a verdadeira utilidade é atingida pela estratégia mista [7/12: \\num\\n; 5/12: \\ndois\\n], que deve\\nser utilizada por ambos os jogadores. Essa estratégia é chamada de \\nequilíbrio de maximin\\n do jogo, e\\né um equilíbrio de Nash. Observe que cada estratégia componente em uma estratégia de equilíbrio\\nmisto tem a mesma utilidade esperada. Nesse caso, tanto \\num\\n quanto \\ndois\\n têm a mesma utilidade\\nesperada, –1/12, como a estratégia mista propriamente dita.\\n Nosso resultado para o jogo par ou ímpar é um exemplo do resultado geral enunciado por von', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 779}),\n",
       " Document(page_content='Neumann: \\ntodo jogo de soma zero de dois jogadores tem equilíbrio de maximin quando se\\npermitem estratégias mistas\\n. Além disso, todo equilíbrio de Nash em um jogo de soma zero é um\\nmaximin para ambos os jogadores. Um jogador que adota a estratégia de maximin tem duas garantias:\\nem primeiro lugar, nenhuma outra estratégia pode ser melhor contra um adversário que jogue bem\\n(apesar de que algumas outras estratégias podem ser melhores em explorar um adversário que comete\\nerros irracionais). Em segundo lugar, o jogador continua a jogar bem, mesmo que a estratégia seja\\nrevelada ao adversário.\\nO algoritmo geral para encontrar equilíbrios de maximin em jogos de soma zero é um pouco mais\\ncomplicado do que as Figuras 17.12(e) e (f) poderiam sugerir. Quando existem \\nn\\n ações possíveis,\\numa estratégia mista é um ponto em um espaço \\nn\\n dimensional, e as linhas se tornam hiperplanos.\\nTambém é possível que algumas estratégias puras para o segundo jogador sejam dominadas por\\noutras, de modo que elas não são ótimas contra \\nqualquer\\n estratégia para o primeiro jogador. Depois\\nde remover todas essas estratégias (o que talvez tenha de ser feito repetidamente), a escolha ótima na\\nraiz é o mais alto (ou mais baixo) ponto de interseção dos hiperplanos restantes. A descoberta dessa\\nescolha é um exemplo de problema de \\nprogramação linear\\n: maximizar uma função objetivo, sujeita\\na restrições lineares. Tais problemas podem ser resolvidos por técnicas padrões em tempo\\npolinomial no número de ações (e no número de bits usados para especificar a função recompensa,\\nse quisermos ser mais técnicos).\\nA pergunta permanece: o que um agente racional realmente deve \\nfazer\\n para jogar uma única\\npartida de par ou ímpar? O agente racional terá derivado o fato de que [7/12: \\num\\n; 5/12: \\ndois\\n] é a\\nestratégia de equilíbrio de maximin e assumiremos que esse seja um conhecimento mútuo com um\\noponente racional. O agente poderia usar um dado de 12 faces ou um gerador de números aleatórios\\npara escolher ao acaso de acordo com essa estratégia mista e, nesse caso, a recompensa esperada\\nseria –1/12 para \\nE\\n. Ou, então, o agente poderia simplesmente decidir jogar \\num\\n ou \\ndois\\n. Em um ou\\noutro caso, a recompensa esperada permanece –1/12 para \\nE\\n. Curiosamente, a escolha unilateral de\\numa ação específica não prejudica a recompensa esperada de nenhum dos dois agentes, mas permitir\\nao outro agente saber que se tomou tal decisão unilateral \\nafeta\\n a recompensa esperada porque o\\noponente poderá ajustar sua estratégia de acordo com isso.\\nDescobrir o equilíbrio em jogos de soma diferentes de zero é um pouco mais complicado. A\\nabordagem geral tem duas etapas: (1) enumerar todos os possíveis subconjuntos de ações que\\npoderiam formar estratégias mistas. Por exemplo, primeiro tente todos os perfis de estratégias em\\nque cada jogador usa uma única ação, depois aqueles em que cada jogador utiliza uma ou duas ações,\\ne assim por diante. Isso é exponencial em relação ao número de ações e, assim, só se aplica a jogos\\nrelativamente pequenos. (2) Para cada perfil de estratégia enumerada em (1), verificar se ele é um\\nequilíbrio. Isso é feito resolvendo-se um conjunto de equações e desigualdades semelhantes às que\\nforam usadas no caso de soma zero. Para dois jogadores, essas equações são lineares e podem ser\\nresolvidas com técnicas básicas de programação linear; porém, para três ou mais jogadores, elas são\\nnão lineares, e pode ser muito difícil resolvê-las.\\n17.5.2 Jogos repetidos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 780}),\n",
       " Document(page_content='Até agora, examinamos apenas jogos que duram um único movimento. A espécie mais simples de\\njogo de vários movimentos é o \\njogo repetido\\n, no qual os jogadores ficam diante da mesma escolha\\nrepetidamente, mas, em cada vez, com conhecimento da história das escolhas anteriores de todos os\\njogadores. Um perfil de estratégia para um jogo repetido especifica uma escolha de ação para cada\\njogador em cada período de tempo para toda história possível de escolhas anteriores. Como ocorre\\ncom MDPs, as recompensas são aditivas com o passar do tempo.\\nVamos considerar a versão repetida do dilema do prisioneiro. Alice e Bob se recusarão a\\ntestemunhar, sabendo que se encontrarão novamente? A resposta depende dos detalhes do\\ncompromisso. Por exemplo, suponha que Alice e Bob saibam que devem jogar exatamente 100\\nrodadas do dilema do prisioneiro. Então, ambos sabem que a 100\\na\\n rodada não será um jogo repetido\\n— isto é, seu resultado pode não ter nenhum efeito sobre rodadas futuras — e, portanto, ambos\\nescolherão a estratégia dominante, \\ntestemunhar\\n, nessa rodada. Porém, uma vez que a 100\\na\\n rodada\\nseja determinada, a 99\\na\\n rodada poderá não ter nenhum efeito sobre rodadas subsequentes e, assim, ela\\ntambém terá um equilíbrio de estratégia dominante em (\\ntestemunhar\\n, \\ntestemunhar\\n). Por indução,\\nambos os jogadores escolherão \\ntestemunhar\\n em toda rodada, ganhando cada um uma sentença de\\nprisão total de 500 anos.\\nPodemos obter diferentes soluções alterando as regras da interação. Por exemplo, suponha que,\\ndepois de cada rodada, exista uma chance de 99% dos jogadores se encontrarem novamente. Então, o\\nnúmero esperado de rodadas ainda será 100, mas nenhum jogador saberá com certeza qual rodada\\nserá a última. Sob essas condições, é possível um comportamento mais cooperativo. Por exemplo,\\numa estratégia de equilíbrio é cada jogador \\nrecusar\\n, a menos que o outro jogador tenha jogado\\ntestemunhar\\n. Essa estratégia poderia ser chamada de \\ncastigo perpétuo\\n. Suponha que ambos os\\njogadores tenham adotado essa estratégia e que ela seja de conhecimento mútuo. Então, desde que\\nnenhum jogador tenha jogado \\ntestemunhar\\n, em qualquer instante a recompensa total esperada no\\nfuturo para cada jogador será:\\nUm jogador que desvia da estratégia e escolhe \\ntestemunhar\\n ganhará uma pontuação 0 em lugar de\\n–1 em seu próximo movimento, mas daí em diante os dois jogadores vão jogar \\ntestemunhar\\n e a\\nrecompensa futura esperada total do jogador se tornará:\\nEntão, em cada etapa, não haverá nenhum incentivo para divergir de (\\nrecusar\\n, \\nrecusar\\n). O castigo\\nperpétuo é a estratégia de “destruição mutuamente garantida” do dilema do prisioneiro: uma vez que\\num ou outro jogador decide testemunhar, ela assegura que ambos os jogadores sofrerão muito. No\\nentanto, ela só funcionará como um meio de intimidação se o outro jogador acreditar que você adotou\\nessa estratégia — ou, pelo menos, que você poderia tê-la adotado.\\nExistem outras estratégias mais generosas. A mais famosa, chamada \\ntête-à-tête\\n (tit-for-tat),\\nconsiste em começar com \\nrecusar\\n e depois ecoar o movimento anterior do outro jogador em todos os', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 781}),\n",
       " Document(page_content='movimentos subsequentes. Assim, Alice se recusaria desde que Bob se recusasse e testemunharia no\\nmovimento seguinte ao testemunho de Bob, mas voltaria a recusar se Bob o fizesse. Embora muito\\nsimples, essa estratégia se mostrou altamente robusta e eficiente contra uma ampla variedade de\\nestratégias.\\nTambém podemos obter diferentes soluções alterando os agentes, em vez de alterar as regras de\\ncompromisso. Suponha que os agentes sejam máquinas de estados finitos com \\nn\\n estados e que\\nestejam participando de um jogo com \\nm\\n > \\nn\\n passos no total. Desse modo, os agentes são incapazes de\\nrepresentar o número de passos restantes e devem tratá-lo como uma incógnita. Então, eles não\\npodem realizar a indução e ficam livres para chegar ao equilíbrio mais favorável (\\nrecusar\\n, \\nrecusar\\n).\\nNesse caso, ignorância \\né\\n felicidade, ou melhor, fazer seu oponente acreditar que você é ignorante é a\\nfelicidade. Seu sucesso nesses jogos repetidos depende da \\npercepção\\n do outro jogador de que você é\\num tirano ou um simplório, e não de suas características reais.\\n17.5.3 Jogos sequenciais\\nEm geral, um jogo consiste em uma sequência de turnos que não precisam ser todos iguais. Tais\\njogos são mais bem representados por uma árvore de jogo, que os teóricos dos jogos chamam de\\nforma extensiva\\n. A árvore inclui todas as mesmas informações que vimos na \\nSeção 5.1\\n: um estado\\ninicial \\nS\\n0\\n, uma função JOGADOR(\\ns\\n), que diz que jogador tem a vez, uma função AÇÕES(\\ns\\n), que\\nenumera as ações possíveis, uma função RESULTADO(\\ns\\n, \\na\\n), que define a transição para um novo\\nestado, e uma função parcial UTILIDADE(\\ns\\n, \\np\\n), que é definida apenas em estados terminais, para dar\\na recompensa para cada jogador.\\nPara representar jogos estocásticos, como gamão, adicionamos um jogador distinto, \\nchance\\n, que\\npode tomar medidas aleatórias. A “estratégia” do acaso é parte da definição do jogo, especificado\\ncomo uma distribuição de probabilidade sobre as ações (os outros jogadores escolhem sua própria\\nestratégia). Para representar jogos com ações não determinísticas, como o bilhar, separamos a ação\\nem duas partes: a ação do jogador em si tem resultado determinístico e, depois, \\nchance\\n tem a vez\\npara reagir à ação em sua própria maneira caprichosa. Para representar movimentos simultâneos,\\ncomo no dilema do prisioneiro ou no jogo de par ou ímpar, impomos uma ordem arbitrária aos\\njogadores, mas temos a opção de afirmar que as ações anteriores do jogador não são observáveis aos\\njogadores subsequentes: por exemplo, Alice deve escolher \\nrecusar\\n ou \\ndepor\\n primeiro, então Bob\\nescolhe, mas Bob não sabe qual a escolha de Alice na sua vez (podemos também representar o fato\\nde que o movimento será revelado mais tarde). No entanto, assumimos que os jogadores sempre\\nlembram todos as suas \\npróprias\\n ações anteriores; essa suposição é chamada de \\nmemória perfeita\\n.\\nA ideia-chave da forma extensiva que a distingue das árvores de jogo do Capítulo 5 é a\\nrepresentação de observabilidade parcial. Vimos na \\nSeção 5.6\\n que um jogador em um jogo\\nparcialmente observável, como o Kriegspiel, pode criar uma árvore de jogo sobre o espaço de\\nestados de crença\\n. Com essa árvore, vimos que, em alguns casos, um jogador pode encontrar uma\\nsequência de movimentos (uma estratégia) que leva a um xeque-mate forçado, independentemente de\\nqual estado real iniciamos, e independentemente de qual estratégia o adversário usou. No entanto, as\\ntécnicas do Capítulo 5 não poderiam informar a um jogador o que fazer quando não houver um xeque-', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 782}),\n",
       " Document(page_content='mate garantido. Se a melhor estratégia do jogador depende da estratégia do adversário e vice-versa,\\no minimax (ou alfa-beta), não pode encontrar uma solução por si só. A forma extensiva permite que\\nencontremos soluções porque representa o estado de crença (teóricos dos jogos chamam de\\nconjuntos de informações\\n) de todos os jogadores de uma vez. Dessa representação, podemos\\nencontrar soluções de equilíbrio, assim como fizemos com a forma normal de jogos.\\nComo exemplo simples de um jogo sequencial, coloque dois agentes no mundo 4 × 3 da \\nFigura\\n17.1\\n e faça-os moverem-se simultaneamente até que um agente chegue a um quadrado de saída e\\npegue a recompensa desse quadrado. Se especificarmos que não ocorre nenhum movimento quando\\nos dois agentes tentarem mover-se no mesmo quadrado simultaneamente (um problema comum nos\\ncruzamentos de trânsito), determinadas estratégias puras podem ficar presas para sempre. Assim, os\\nagentes precisam de uma estratégia mista para um bom desempenho nesse jogo: escolher\\naleatoriamente entre avançar e permanecer no lugar. Isso é exatamente o que é feito para resolver\\ncolisões de pacotes em redes Ethernet.\\nEm seguida, vamos considerar uma variante muito simples do pôquer. O baralho tem apenas quatro\\ncartas, dois ases e dois reis. Uma carta é distribuída a cada jogador. O primeiro jogador tem a opção\\nde \\naumentar\\n a aposta do jogo a partir de 1 ponto para 2 ou \\npassar\\n. Se o jogador 1 passar, o jogo\\ntermina. Se ele aumentar a aposta, o jogador 2 tem a opção de \\nigualar o valor da aposta\\n aceitando\\nque o jogo vale 2 pontos ou \\ndesistir da mão\\n, concedendo 1 ponto. Se o jogo não terminar com a\\ndesistência, a recompensa depende das cartas: zero para ambos os jogadores se eles tiverem a\\nmesma carta; caso contrário, o jogador com o rei paga a aposta para o jogador com o ás.\\nA árvore de forma extensiva para esse jogo é mostrada na \\nFigura 17.13\\n. Os estados não terminais\\nsão mostrados como círculos, com o jogador a se mover dentro do círculo; o jogador 0 é \\nchance\\n.\\nCada ação é retratada como uma seta com um rótulo, correspondente a \\naumentar a aposta\\n, \\npassar\\n,\\nigualar o valor da aposta\\n, \\ndesistir da mão ou arriscar\\n as quatro jogadas possíveis (“AK” significa\\nque o jogador 1 recebeu um ás, e o jogador 2, um rei). Estados terminais são retângulos rotulados\\npelas suas recompensas para os jogadores 1 e 2. Os conjuntos de informações são mostrados como\\ncaixas tracejadas rotuladas, por exemplo, \\nI\\n1,1\\n é o conjunto de informações, em que é a vez do jogador\\n1, e ele sabe que tem um ás (mas não sabe o que o jogador 2 tem). No conjunto de informação \\nI\\n2,1\\n, é a\\nvez do jogador 2, e ele sabe que tem um ás e o jogador 1 aumentou a aposta, mas não sabe que cartão\\no jogador 1 tem (devido ao limite do papel bidimensional, esse conjunto de informação é mostrado\\ncomo duas caixas em vez de uma).', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 783}),\n",
       " Document(page_content='Figura 17.13\\n Forma extensiva de uma versão simplificada do pôquer.\\nUma maneira de resolver um jogo extensivo é convertê-lo para um jogo de forma normal. Lembre-\\nse de que a forma normal é uma matriz, cada linha é rotulada com uma estratégia pura para o jogador\\n1 e cada coluna por uma estratégia pura para o jogador 2. Em um jogo extensivo, uma estratégia pura\\npara o jogador \\ni\\n corresponde a uma ação para cada conjunto de informações envolvendo esse\\njogador. Assim, na \\nFigura 17.13\\n, uma estratégia pura para o jogador 1 é “aumentar a aposta quando\\nem \\nI\\n1,1\\n (isto é, quando tiver um ás) e passar quando em \\nI\\n1,2\\n (quando tiver um rei). Na matriz de\\nrecompensa a seguir, essa estratégia é chamada de \\nrk\\n. Da mesma forma, a estratégia \\ncf\\n do jogador 2\\nsignifica “igualar o valor da aposta quando eu tiver um ás e desistir da mão quando tiver um rei”.\\nComo esse é um jogo de soma zero, a matriz a seguir dá apenas a recompensa para o jogador 1; o\\njogador 2 tem sempre a recompensa oposta:\\n2:\\ncc\\n2:\\ncf\\n2:\\nff\\n2:\\nfc\\n1:rr\\n0\\n−1/6\\n1\\n7/6\\n1:\\nkr\\n−1/3\\n−1/6\\n5/6\\n2/3\\n1:rk\\n1/3\\n0\\n1/6\\n1/2\\n1:\\nkk\\n0\\n0\\n0\\n0\\nEsse jogo é tão simples que tem dois equilíbrios de estratégia pura, mostrador em negrito: \\ncf\\n para\\no jogador 2 e \\nrk\\n ou \\nkk\\n para o jogador 1. Mas, em geral, podemos resolver jogos extensivos,\\nconvertendo para a forma normal e depois encontrando uma solução (geralmente uma estratégia\\nmista), utilizando métodos de programação linear padrão. Isso funciona na teoria. Mas, se um\\njogador tiver conjuntos de informação \\nI\\n e ações \\na\\n por conjunto, esse jogador terá \\na\\nI\\n estratégias puras.\\nEm outras palavras, o tamanho da matriz de forma normal é exponencial em número de conjuntos de\\ninformações, então na prática a abordagem funciona apenas para árvores de jogo muito pequenas, da\\nordem de uma dúzia de estados. Um jogo como o Texas Hold’em Poker tem cerca de 10\\n18\\n estados,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 784}),\n",
       " Document(page_content='tornando essa abordagem completamente inviável.\\nQuais são as alternativas? No Capítulo 5, vimos como a busca alfa-beta poderia lidar com jogos\\nde informação perfeita com árvores de jogo enormes, através da geração da árvore de jogo de forma\\nincremental, com a poda de algumas ramificações e a avaliação heurística de nós não terminais. Mas\\nessa abordagem não funciona bem para jogos com informação imperfeita, por duas razões: primeiro,\\né mais difícil podar porque precisamos considerar estratégias mistas que combinem várias\\nramificações, não uma estratégia pura que sempre escolha a melhor ramificação. Segundo, é mais\\ndifícil avaliar heuristicamente um nó não terminal porque estamos lidando com conjuntos de\\ninformação, não com estados individuais.\\nKoller \\net al\\n. (1996) vieram em auxílio com uma representação alternativa de jogos extensivos,\\nchamada de \\nforma sequencial\\n, que é apenas linear no tamanho da árvore, em vez de exponencial. Em\\nvez de representar estratégias, representa caminhos através da árvore; o número de caminhos é igual\\nao número de nós terminais. Métodos de programação linear padrão podem ser aplicados novamente\\npara essa representação. O sistema resultante pode resolver variantes do pôquer com 25.000 estados\\nem um minuto ou dois. Essa é uma aceleração exponencial sobre a abordagem da forma normal, mas\\nainda está muito aquém do tratamento do pôquer completo, com 10\\n18\\n estados.\\nSe não podemos lidar com 10\\n18\\n estados, talvez possamos simplificar o problema, alterando o jogo\\npara uma forma mais simples. Por exemplo, se eu segurar um ás considerando a possibilidade de que\\npróxima carta vá me dar um par de ases, então não importa o naipe da próxima carta, qualquer naipe\\nserve. Isso sugere a formação de uma \\nabstração\\n do jogo, em que os naipes são ignorados. A árvore\\nde jogo resultante será menor por um fator de 4! = 24. Supondo que eu possa resolver esse pequeno\\njogo, como é que a solução para esse jogo se relaciona com o jogo original? Se nenhum jogador\\nestiver seguindo para um \\nflush\\n (cinco cartas do mesmo naipe) (ou um blefe), então os naipes não\\nimportam para nenhum jogador, e a solução para a abstração será também uma solução para o jogo\\noriginal. No entanto, se houver qualquer jogador que esteja contemplando um \\nflush\\n, a abstração será\\napenas uma solução aproximada (mas é possível calcular os limites sobre o erro).\\nExistem muitas oportunidades para a abstração. Por exemplo, em um jogo, no ponto em que cada\\njogador tem duas cartas, se eu tiver um par de damas, a mão dos outros jogadores pode ser abstraída\\nem três classes: \\nmelhor\\n (apenas um par de reis ou um par de ases), \\nmesma\\n (par de rainhas) ou \\npior\\n(o restante). No entanto, essa abstração pode ser muito tosca. Uma melhor abstração seria dividir\\npior\\n em, digamos, \\npar médio\\n (nove até o valete), \\npar baixo\\n e \\nnenhum par\\n. Esses exemplos são\\nabstrações de estados, sendo possível também abstrair ações. Por exemplo, em vez de ter uma ação\\nde aposta para cada inteiro de 1 a 1.000, poderíamos restringir as apostas para 10\\n0\\n, 10\\n1\\n, 10\\n2\\n e 10\\n3\\n.\\nOu poderíamos cortar completamente uma das rodadas de apostas. Podemos também abstrair sobre\\nnós de chance, considerando apenas um subconjunto de tratos possíveis. Isso é equivalente à técnica\\nde \\nrollout\\n usada em programas Go. Colocando todas essas abstrações juntas, podemos reduzir os\\n10\\n18\\n estados do pôquer para 10\\n7\\n estados, um tamanho que pode ser resolvido com as técnicas atuais.\\nOs programas de pôquer com base nessa abordagem podem facilmente derrotar novatos e alguns\\njogadores humanos experientes, mas ainda não estão no nível de jogadores mestres. Parte do\\nproblema é que a solução aproximada desses programas — a solução de equilíbrio — é ótima\\napenas contra um adversário que também joga a estratégia de equilíbrio. Contra os jogadores\\nhumanos falíveis é importante ser capaz de explorar o desvio de um oponente da estratégia de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 785}),\n",
       " Document(page_content='equilíbrio. Como Gautam Rao (também conhecido como “o conde”), líder mundial de jogo de pôquer\\non-line, disse (Billings \\net al.\\n, 2003): “Você tem um programa muito forte. Depois de adicionar uma\\nmodelagem do adversário, ele vai matar todos.” No entanto, bons modelos de jogadores humanos\\nainda precisam ser criados.\\nEm certo sentido, a forma extensiva do jogo é uma das representações mais completas que temos\\nvisto até agora: pode lidar com ambientes parcialmente observáveis, multiagentes, estocásticos,\\nsequenciais, dinâmicos — a maioria dos casos difíceis da lista de propriedades do ambiente. No\\nentanto, há duas limitações da teoria dos jogos. Primeiro, ela não lida bem com estados contínuos e\\nações (embora tenha havido algumas extensões para o caso contínuo; por exemplo, a teoria da\\ncompetição de Cournot\\n utiliza a teoria dos jogos para resolver problemas em que duas empresas\\nescolhem os preços de seus produtos a partir de um espaço contínuo). Segundo a teoria dos jogos,\\nassume que o jogo é \\nconhecido.\\n Partes do jogo podem ser especificadas para alguns dos jogadores\\ncomo não observáveis, mas deve-se saber que partes são não observáveis. Em casos em que os\\njogadores aprendem a estrutura desconhecida do jogo ao longo do tempo, o modelo começa a entrar\\nem colapso. Examinemos cada fonte de incerteza e se cada uma delas pode ser representada na teoria\\ndos jogos.\\nAções\\n: não há nenhuma maneira fácil de representar um jogo em que os jogadores têm de descobrir\\nque ações estão disponíveis. Considere o jogo entre os criadores de vírus de computador e os\\nespecialistas em segurança. Parte do problema é antecipar qual será a próxima ação dos criadores de\\nvírus.\\nEstratégias\\n: a teoria dos jogos é muito boa em representar a ideia de que a estratégia dos outros\\njogadores é inicialmente desconhecida — desde que assumamos que todos os agentes são racionais.\\nA teoria em si não diz o que fazer quando outros jogadores são menos que totalmente racionais. A\\nnoção do \\nequilíbrio de Bayes-Nash\\n aborda parcialmente esse ponto: é um equilíbrio com relação à\\ndistribuição da probabilidade anterior de um jogador sobre as estratégias dos outros jogadores —\\nem outras palavras, expressa as crenças de um jogador sobre as estratégias prováveis dos outros\\njogadores.\\nChance\\n: Se um jogo depende do lançamento de um dado, será bem fácil modelar um nó de acaso\\ncom distribuição uniforme sobre os resultados. Mas, e se for possível que o dado seja viciado?\\nPodemos representar isso com outro nó de acaso, mais acima na árvore, com duas ramificações para\\n“dado imparcial” e “dado viciado”, de tal forma que os nós correspondentes em cada ramificação\\nestão no mesmo conjunto de informação (isto é, os jogadores não sabem se o dado é viciado ou não).\\nE se suspeitarmos que o outro adversário sabe? Então adicionamos \\noutro\\n nó de acaso, com uma\\nramificação representando o caso em que o adversário sabe, e um em que ele não sabe.\\nUtilidades\\n: e se não conhecermos as utilidades de nosso oponente? Mais uma vez, pode ser\\nmodelado com um nó de acaso, de tal forma que o outro agente conheça a própria utilidade em cada\\nramificação, mas nós, não. E se não conhecermos nossa própria utilidade? Por exemplo, como sei se\\né racional pedir a salada do chefe, se não sei o quanto vou gostar? Podemos modelar isso com mais\\num nó de acaso especificando uma “qualidade intrínseca” não observável \\u200b\\u200bda salada.\\nAssim, vemos que a teoria dos jogos é eficaz em representar a maioria das origens de incerteza,\\nmas ao custo de dobrar o tamanho da árvore cada vez que adicionamos outro nó, um hábito que leva\\nrapidamente a árvores grandes que se tornam intratáveis. Devido a esses e outros problemas da', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 786}),\n",
       " Document(page_content='teoria dos jogos, usa-se a princípio \\nanalisar\\n ambientes que estão em equilíbrio, em vez de \\ncontrolar\\nagentes dentro de um ambiente. Em seguida veremos como o \\nprojeto\\n de ambientes pode ajudar.\\n17.6 PROJETO DE MECANISMOS\\nNa seção anterior, perguntamos: “Dado um jogo, o que é uma estratégia racional?” Nesta seção,\\nperguntamos: “Dados os agentes que escolhem estratégias racionais, que jogo devemos projetar?”\\nMais especificamente, gostaríamos de projetar um jogo cujas soluções, consistindo na busca por\\ncada agente de sua própria estratégia racional, resultassem na maximização de alguma função\\nutilidade global. Esse problema é chamado de \\nprojeto de mecanismos\\n ou, às vezes, \\nteoria dos\\njogos inversa\\n. O projeto de mecanismos é uma mistura de economia e ciência política. O\\ncapitalismo 101 diz que, se todos tentam ficar ricos, a riqueza total da sociedade vai aumentar. Mas\\nos exemplos que vamos discutir mostram que é necessário um projeto de mecanismo apropriado para\\nmanter o jogo no caminho certo. Para coleções de agentes, o projeto de mecanismo nos permite\\nconstruir sistemas inteligentes a partir de uma coleção de sistemas mais limitados — até mesmo\\nsistemas não cooperativos —, quase do mesmo modo como as equipes de seres humanos conseguem\\natingir metas muito além do alcance de qualquer indivíduo.\\nOs exemplos de projeto de mecanismos incluem o leilão de passagens aéreas a baixo preço, o\\nroteamento de pacotes TCP entre computadores, a decisão de como os médicos residentes serão\\ndesignados para hospitais e a decisão de como os jogadores de futebol robóticos cooperarão com\\nseus companheiros de equipes. O projeto de mecanismos se tornou mais que um assunto acadêmico\\nna década de 1990, quando várias nações, diante do problema de leiloar licenças para transmissão\\npública em diversas bandas de frequência, perderam centenas de milhões de dólares em receita\\npotencial como resultado de um projeto de mecanismo fraco. Formalmente, um \\nmecanismo\\n consiste\\nem (1) uma linguagem para descrever o (possivelmente infinito) conjunto de estratégias permitidas\\nque os agentes podem adotar, (2) um agente distinto, chamado \\nleiloeiro\\n, que reúne relatos de\\nescolhas de estratégia dos agentes no jogo e (3) uma regra de resultado, conhecida por todos os\\nagentes, que o leiloeiro usa para determinar as recompensas de cada agente, dadas as suas escolhas\\nde estratégia.\\n17.6.1 Leilões\\nVamos considerar primeiro os \\nleilões\\n. Um leilão é um mecanismo para vender alguns bens para\\nmembros de um grupo de consumidores. Para simplificar, nos concentraremos em leilões com um\\núnico item para venda.\\nCada licitante \\ni\\n tem um valor de utilidade \\nv\\ni\\n para ter o item. Em alguns casos, cada agente ofertante\\ntem um \\nvalor privado\\n para o item. Por exemplo, o primeiro item vendido no eBay foi um ponteiro a\\nlaser\\n quebrado, vendido por $14,83 para um colecionador de ponteiros a \\nlaser\\n quebrados. Assim,\\nsabemos que o colecionador tem \\nv\\ni\\n ≥ $14,83, mas a maioria das pessoas teria \\nv\\nj\\n \\n $14,83. Em outros\\ncasos, como o leilão de direitos de perfuração para um tratado de petróleo, o item tem um \\nvalor', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 787}),\n",
       " Document(page_content='comum\\n — o tratado vai produzir certa quantidade em dinheiro, \\nX\\n, e todos os ofertantes valem\\nigualmente um dólar — mas há incerteza quanto ao valor real de \\nX\\n. Ofertantes diferentes têm\\ninformações diferentes e, portanto, estimativas diferentes do valor verdadeiro do item. Em ambos os\\ncasos, os ofertantes acabam com o seu próprio \\nv\\ni\\n. Dado o \\nv\\ni\\n, cada ofertante tem uma chance, no\\nmomento adequado ou nos momentos adequados no leilão, de fazer uma oferta \\nb\\ni\\n. O lance mais alto,\\nb\\nmax\\n, ganha o item, mas o preço pago não precisa ser \\nb\\nmax\\n; isso é parte do projeto de mecanismo.\\nO mecanismo de leilões mais conhecido é o \\nlance ascendente\\n,\\n8\\n ou \\nleilão inglês\\n, em que o\\nleiloeiro começa pedindo um lance mínimo \\nb\\nmin\\n (ou \\nreserva\\n). Se algum ofertante estiver disposto a\\npagar essa quantia, o leiloeiro, então, pede \\nb\\nmin\\n + \\nd\\n, para algum incremento \\nd\\n, e continua a partir daí.\\nO leilão termina quando ninguém estiver disposto a oferecer mais; então, o último ofertante ganha o\\nitem, pagando o preço do seu lance.\\nComo sabemos se esse é um bom mecanismo? Um dos objetivos é maximizar a receita esperada\\npara o vendedor. Outro objetivo é maximizar uma noção de utilidade global. Essas metas se\\nsobrepõem, até certo ponto, porque um aspecto da maximização da utilidade global é garantir que o\\nvencedor do leilão seja o agente que mais valorizou o item (e, portanto, está disposto a pagar mais).\\nDizemos que um leilão é \\neficiente\\n se os bens forem para o agente que mais os valoriza. O lance\\nascendente do leilão geralmente é eficiente e maximiza a receita, mas se o preço de reserva for muito\\nalto o ofertante que mais o valoriza pode não concorrer e, se a reserva for muito baixa, o vendedor\\nperde a receita líquida.\\nProvavelmente, uma das coisas mais importantes que um mecanismo de leilão pode fazer é\\nencorajar um número suficiente de consumidores a entrar no jogo e desencorajá-los de se envolver\\nem \\ncoalisão\\n. Coalisão é um acordo injusto ou ilegal por dois ou mais licitantes para manipular os\\npreços. Pode acontecer em acordos secretos de bastidores ou tacitamente, dentro das regras do\\nmecanismo.\\nPor exemplo, em 1999, a Alemanha leiloou dez blocos de espectro de telefonia celular com um\\nleilão simultâneo (eram consideradas apostas de todos os dez blocos, ao mesmo tempo), utilizando a\\nregra de que qualquer lance deveria ter aumento mínimo de 10% sobre o lance do bloco anterior.\\nHavia apenas dois ofertantes credíveis, e o primeiro, a Mannesman, entrou com a oferta de 20\\nmilhões de marcos nos blocos 1 a 5 e 18,18 milhões nos blocos 6 a10. Por que 18,18M? Um dos\\ngerentes da T-Mobile disse que eles “interpretaram o primeiro lance da Mannesman como uma\\noferta”. Ambas as partes podem calcular que um aumento de 10% sobre 18,18M é 19,99M; assim, o\\nlance da Mannesman foi interpretado como se dissesse: “Cada um de nós pode obter a metade dos\\nblocos por 20M; não vamos desperdiçá-la oferecendo preços mais elevados.” E, de fato, o lance da\\nT-Mobile de 20M dos blocos 6-10 foi o fim do leilão. O governo alemão obteve menos do que o\\nesperado porque os dois concorrentes foram capazes de usar o mecanismo de licitação para chegar a\\num acordo tácito sobre como não competir. Do ponto de vista do governo, poderia ter sido obtido\\nresultado melhor por qualquer uma dessas alterações no mecanismo: preço de reserva mais alto;\\noferta selada de primeiro preço do leilão, para que os concorrentes não pudessem se comunicar\\natravés de seus lances; ou incentivo para trazer um terceiro licitante. Talvez a regra dos 10% tenha\\nsido um erro no projeto de mecanismo porque facilitou a sinalização precisa da Mannesman para a\\nT-Mobile.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 788}),\n",
       " Document(page_content='Em geral, tanto o vendedor como a função utilidade global se beneficiam se houver mais\\ninteressados, embora a utilidade global possa sofrer se você contar o custo do tempo perdido dos\\nofertantes que não têm chance de ganhar. Uma maneira de encorajar mais os ofertantes é tornar o\\nmecanismo mais fácil para eles. Afinal, ao requerer muita pesquisa ou cálculo por parte dos\\nofertantes, eles podem decidir empregar o seu dinheiro em outro lugar. Por isso, é desejável que os\\nofertantes tenham uma \\nestratégia dominante\\n. Lembre-se de que “dominante” significa que a\\nestratégia funcione em oposição a todas as outras estratégias, que por sua vez significa que um agente\\npode adotá-la sem levar em conta as outras estratégias. Um agente com uma estratégia dominante\\npode simplesmente licitar, sem perder tempo contemplando possíveis estratégias de outros agentes.\\nUm mecanismo pelo qual os agentes têm uma estratégia dominante é chamado de mecanismo a \\nprova\\nde estratégia\\n. Se, como geralmente ocorre, essa estratégia envolve ofertantes revelando o seu valor\\nverdadeiro, \\nv\\ni\\n, então é chamado de \\nleilão revelador da verdade\\n ou \\nconfiável\\n; a expressão \\nincentivo\\ncompatível\\n também é usada. O princípio da revelação estabelece que qualquer mecanismo pode ser\\ntransformado em um mecanismo de revelação da verdade equivalente; então, parte do projeto do\\nmecanismo é encontrar esses mecanismos equivalentes.\\nAcontece que o leilão de lance ascendente tem a maioria das propriedades desejáveis. O agente\\ncom o maior valor \\nv\\ni\\n recebe os bens ao preço de \\nb\\no\\n + d, onde \\nb\\no\\n é o lance mais alto entre todos os\\noutros agentes e \\nd\\n é o incremento do leiloeiro.\\n9\\n Os ofertantes têm uma estratégia dominante simples:\\ncontinuar oferecendo lances enquanto o custo atual for menor que seu \\nv\\ni\\n. O mecanismo não é\\nexatamente revelador da verdade porque o ofertante vencedor revela apenas que seu \\nv\\ni\\n ≥ \\nb\\no\\n \\n+ d\\n;\\ntemos um limite inferior em \\nv\\ni\\n, mas não uma quantidade exata.\\nUma desvantagem (do ponto de vista do vendedor) do leilão de lance ascendente é que pode\\ndesencorajar a concorrência. Suponha que, em um lance para espectro de telefone celular, haja uma\\nempresa favorecida e que todos concordam que seria capaz de alavancar os clientes existentes e a\\ninfraestrutura, podendo assim ter um lucro maior do que ninguém. Os concorrentes potenciais podem\\nver que não têm chance em um leilão de lance ascendente porque a empresa favorecida pode sempre\\ndar um lance mais alto. Dessa forma, os competidores podem não entrar no leilão, e a empresa\\nfavorecida acaba ganhando ao preço de reserva.\\nUma propriedade negativa do leilão inglês é seu alto custo de comunicação. Ou o leilão tem lugar\\nem uma sala, ou todos os agentes precisam ter linhas de comunicação confiáveis de alta velocidade;\\nem ambos os casos tem de haver tempo disponível para passar por várias rodadas de lances. Um\\nmecanismo alternativo que exige bem menos comunicação é o \\nleilão de oferta lacrada\\n. Aqui, cada\\nlicitante faz uma única oferta e a comunica ao leiloeiro, sem os outros licitantes tomarem\\nconhecimento dela. Com esse mecanismo, não há mais uma simples estratégia dominante. Se o seu\\nvalor é \\nv\\ni\\n e você acredita que a oferta máxima de todos os outros participantes será \\nb\\no\\n, você deve\\nofertar \\nb\\no\\n \\n+\\n \\nε\\n, para algum \\nε\\n pequeno, se for menos que \\nv\\ni\\n. Assim, o seu lance depende de sua\\nestimativa dos lances de outros agentes, exigindo que você trabalhe mais. Observe, também, que o\\nagente com o \\nv\\ni\\n maior pode não ganhar o leilão. Isso é compensado pelo fato de que o leilão é mais\\ncompetitivo, reduzindo a propensão para um ofertante favorecido.\\nUma pequena mudança no mecanismo de leilões de ofertas lacradas produz o \\nleilão de oferta\\nlacrada de segundo preço\\n, também conhecido como \\nleilão de Vickrey\\n.\\n10\\n Em tais leilões, o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 789}),\n",
       " Document(page_content='vencedor paga o preço da \\nsegunda\\n oferta mais alta, \\nb\\no\\n, em vez de pagar sua própria oferta. Essa\\nsimples modificação elimina completamente as deliberações complexas exigidas pelos leilões de\\nofertas lacradas padrão (ou \\nde primeiro preço\\n) porque agora a estratégia dominante é simplesmente\\noferecer \\nv\\ni\\n; o mecanismo é revelador da verdade. Observe que a utilidade do participante \\ni\\n em\\ntermos de sua oferta \\nb\\ni\\n, seu valor \\nv\\ni\\n e a melhor oferta entre os outros jogadores, \\nb\\no\\n, é:\\nPara ver que \\nb\\ni\\n = \\nv\\ni\\n é uma estratégia dominante observe que, quando (\\nv\\ni\\n – \\nb\\no\\n) é positivo, qualquer\\noferta que vença o leilão é ótima, e a oferta de \\nv\\ni\\n em particular vence o leilão. Por outro lado, quando\\n(\\nv\\ni\\n – \\nb\\no\\n) é negativo, qualquer oferta que perde o leilão é ótima, e a oferta de \\nv\\ni\\n em particular perde o\\nleilão. Assim, a oferta de \\nv\\ni\\n é ótima para todos os valores possíveis de \\nb\\no\\n e, de fato, \\nv\\ni\\n é a única\\noferta que tem essa propriedade. Devido à sua simplicidade e aos requisitos mínimos de\\ncomputação, tanto para o vendedor quanto para os ofertantes, o leilão de Vickrey é amplamente\\nutilizado na construção de sistemas distribuídos de IA. Além disso, os mecanismos de busca na\\ninternet conduzem mais de um bilhão de leilões por dia para vender anúncios juntamente com os seus\\nresultados de busca, e sites de leilão on-line manipulam $100 bilhões por ano em bens, todos\\nutilizando variantes do leilão de Vickrey. Observe que o valor esperado para o vendedor é \\nb\\no\\n, que é\\no mesmo retorno esperado que o limite do leilão inglês à medida que o incremento \\nd\\n tende a zero.\\nEsse é realmente um resultado muito geral: o \\nteorema da equivalência de receitas\\n, com algumas\\nressalvas menores, afirma que qualquer mecanismo de leilão em que os licitantes com risco neutro\\ntêm valores \\nv\\ni\\n que apenas eles conhecem (mas conhecem a distribuição de probabilidade de onde\\nesses valores são amostrados), vai produzir a mesma receita esperada. Esse princípio significa que\\nos vários mecanismos não são concorrentes com base na geração de receitas, mas em outras\\nqualidades.\\nEmbora o leilão de segundo preço seja revelador da verdade, verifica-se que estender a ideia de\\nmúltiplos bens e utilizar um leilão de próximo preço não é revelador da verdade. Muitos mecanismos\\nde busca na internet utilizam um mecanismo que oferece em leilão \\nk\\n janelas para comerciais em uma\\npágina. O maior lance ganha o primeiro lugar, o segundo fica em segundo, e assim por diante. Cada\\nvencedor paga o preço do lance do próximo ofertante com valor inferior, com o entendimento de que\\no pagamento é feito somente se o pesquisador realmente clicar no anúncio. As janelas na parte\\nsuperior são consideradas mais valiosas porque são mais propensas a ser vistas e clicadas. Imagine\\nque três ofertantes, \\nb\\n1\\n, \\nb\\n2\\n e b\\n3\\n, tenham avaliações por um clique de \\nv\\n1\\n = 200, \\nv\\n2\\n = 180, e v\\n3\\n = 100, e\\nque \\nk\\n = 2 janelas estão disponíveis; sabe-se que a janela mais bem posicionada é clicada 5% do\\ntempo, e a pior posicionada, 2%. Se todos os ofertantes fizerem lances confiáveis, \\nb\\n1\\n ganhará a\\njanela superior e pagará 180, com retorno esperado de (200 − 180) × 0,05 = 1. A segunda janela irá\\npara \\nb\\n2\\n. Mas \\nb\\n1\\n pode constatar que, se ofertasse qualquer coisa no intervalo entre 101-179,\\nconcederia a janela superior para \\nb\\n2\\n ele ganharia a segunda janela e produziria um retorno esperado\\nde (200 − 100) × 0,02 = 2. Assim, nesse caso, \\nb\\n1\\n pode dobrar o seu retorno esperado ao dar um\\nlance menor do que o seu verdadeiro valor. Em geral, os ofertantes nesse leilão de múltiplas janelas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 790}),\n",
       " Document(page_content='têm de gastar muita energia analisando as ofertas dos outros para determinar a sua melhor estratégia;\\nnão há estratégia simples dominante. Aggarwal \\net al.\\n (2006) mostram que há um único mecanismo de\\nleilão confiável para esse problema, em que o vencedor da janela \\nj\\n paga o preço total pela janela \\nj\\napenas por aqueles cliques adicionais que estão disponíveis na janela \\nj\\n e não na janela \\nj\\n + 1. O\\nvencedor paga o preço mais baixo pela janela para os cliques restantes. No nosso exemplo, \\nb\\n1\\n iria\\nofertar 200 realmente, e pagaria 180 por 0,05 – 0, 02 = 0,03 cliques adicionais na janela superior,\\nmas iria pagar apenas o custo da janela inferior, 100, pelos restantes 0,02 cliques. Assim, o retorno\\ntotal para \\nb\\n1\\n seria (200 − 180) × 0,03 + (200 − 100) × 0,02 = 2,6.\\nOutro exemplo em que os leilões podem ser úteis em IA é quando uma coleção de agentes está\\ndecidindo sobre cooperação em um plano conjunto. Hunsberger e Grosz (2000) mostraram que isso\\npode ser feito de forma eficiente com um leilão em que os agentes fazem lances por papéis no plano\\nconjunto.\\n17.6.2 Bens comunitários\\nAgora vamos considerar outro tipo de jogo, em que os países estabelecem suas políticas de\\ncontrole da poluição do ar. Cada país tem uma escolha: pode reduzir a poluição a um custo de −10\\npontos para implementar as mudanças necessárias ou pode continuar a poluir, o que lhe confere uma\\nutilidade de rede de −5 (em acréscimo a despesas de saúde etc.) e também contribui com −1 ponto\\npara todos os outros países (porque o ar é compartilhado entre os países). É evidente que a estratégia\\ndominante para cada país é “continuar a poluir”, mas se houver 100 países e cada um seguir essa\\npolítica, cada país obterá uma utilidade total de −104, enquanto que se todo país reduzir a sua\\npoluição cada um terá uma utilidade de −10. Essa situação é chamada de \\ntragédia das comunidades\\n:\\nse ninguém tem de pagar para utilizar um recurso comum, ele tende a ser explorado de maneira que\\nleva a baixar a utilidade total para todos os agentes. É semelhante ao dilema do prisioneiro: não há\\noutra solução para o jogo que seja melhor para todas as partes, mas parece não haver maneira de os\\nagentes racionais chegarem a essa solução.\\nA abordagem padrão para lidar com a tragédia das comunidades é mudar o mecanismo para aquele\\nque impõe uma tarifa a cada agente pelo uso de bens comuns. Mais geralmente, precisamos garantir\\nque todas as \\nexternalidades\\n — efeitos sobre a utilidade global que não são reconhecidos nas\\ntransações dos agentes individuais — sejam explicitadas. A fixação dos preços corretamente é a\\nparte difícil. No limite, essa abordagem equivale à criação de um mecanismo em que cada agente\\ntenha de efetivamente maximizar a utilidade global, mas possa fazê-lo tomando uma decisão local.\\nPara esse exemplo, um imposto sobre o carbono seria um exemplo de mecanismo que cobra pelo uso\\nde um bem comum de uma forma que, se bem implementado, maximiza a utilidade global.\\nComo exemplo final, considere o problema de alocação de alguns bens comuns. Suponha que uma\\ncidade decida que quer instalar alguns transceptores de internet sem fio gratuito. No entanto, o\\nnúmero de transceptores que a cidade pode adquirir é inferior ao número de bairros que o desejam.\\nA cidade quer alocar os bens de forma eficiente aos bairros que mais os valorizariam. Ou seja, eles\\nquerem maximizar a utilidade global \\n. O problema é que, se simplesmente for perguntado a\\ncada conselho de bairro “o quanto você valoriza esse donativo gratuito?”, todos eles terão um', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 791}),\n",
       " Document(page_content='incentivo para mentir e relatar um valor mais alto. Acontece que existe um mecanismo, conhecido\\ncomo \\nVickrey-Clarke-Groves\\n, ou \\nVCG\\n, que torna isso uma estratégia dominante para cada agente\\nou relata a sua verdadeira utilidade, o que alcança uma alocação eficiente dos bens. O truque é que\\ncada agente paga um imposto equivalente à perda da utilidade global que ocorre devido à presença\\ndo agente no jogo. O mecanismo funciona assim:\\n1. O leiloeiro pede a cada agente para relatar o seu valor para receber um item. Denominaremos\\nb\\ni\\n.\\n2. O leiloeiro destina os bens a um subconjunto de ofertantes. Chamaremos esse subconjunto de \\nA\\ne usaremos a notação \\nb\\ni\\n(\\nA\\n) para significar o resultado de \\ni\\n sob essa atribuição: \\nb\\ni\\n, se \\ni\\n está em\\nA\\n (isto é, \\ni\\n é um vencedor) e 0 caso contrário. O leiloeiro escolhe \\nA\\n para maximizar a utilidade\\ntotal relatada \\n.\\n3. O leiloeiro calcula (para cada \\ni\\n) a soma das utilidades relatadas para todos os vencedores,\\nexceto \\ni\\n. Usamos a notação \\n. O leiloeiro também calcula (para cada \\ni\\n) a alocação\\nque maximizaria a utilidade global se \\ni\\n não estivesse no jogo; chamaremos essa soma de \\nW\\n−i\\n.\\n4. Cada agente \\ni\\n paga um imposto igual a W\\n–i\\n – B\\n–i\\n.\\nNesse exemplo, a regra VCG significa que cada vencedor pagaria um imposto igual ao valor mais\\nalto relatado entre os perdedores. Ou seja, se eu relatar que meu valor é 5 e isso fizer com que\\nalguém com o valor 2 seja excluído de uma alocação, pagarei um imposto de 2. Todos os vencedores\\ndeverão ficar felizes por pagar um imposto inferior a seu valor, e todos os perdedores ficarão o mais\\nfeliz possível porque valorizam menos os bens do que o imposto exigido.\\nPor que esse mecanismo é revelador da verdade? Primeiro, considere o pagamento ao agente \\ni\\n,\\nque é o valor da obtenção de um item menos o imposto:\\nAqui distinguimos a verdadeira utilidade do agente, \\nv\\ni\\n, de sua utilidade relatada \\nb\\ni\\n (mas estamos\\ntentando mostrar que a estratégia dominante é \\nb\\ni\\n = \\nv\\ni\\n). O agente \\ni\\n sabe que o leiloeiro vai maximizar a\\nutilidade global usando os valores relatados,\\nenquanto o agente \\ni\\n quer que o leiloeiro maximize (17.14), que pode ser reescrita como\\nDesde que o agente \\ni\\n não possa afetar o valor da \\nW\\n–i\\n (que depende apenas de outros agentes), a\\núnica maneira como \\ni\\n pode fazer com que o leiloeiro otimize o que \\ni\\n quer é relatar a utilidade\\nverdadeira, \\nb\\ni\\n = \\nv\\ni\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 792}),\n",
       " Document(page_content='17.7 RESUMO\\nEste capítulo mostrou como usar o conhecimento sobre o mundo para tomar decisões, mesmo\\nquando os resultados de uma ação são incertos e as recompensas por uma ação podem não ser\\nrecebidas até muitas ações terem passado. Os principais pontos são:\\n•  Problemas de decisão sequencial em ambientes incertos, também chamados \\nprocessos de\\ndecisão de Markov\\n, ou MDPs, são definidos por um \\nmodelo de transição\\n que especifica os\\nresultados probabilísticos de ações e uma \\nfunção de recompensa\\n que especifica a recompensa\\nem cada estado.\\n•  A utilidade de uma sequência de estados é a soma de todas as recompensas sobre a sequência,\\npossivelmente descontadas com o passar do tempo. A solução de um MDP é uma \\npolítica\\n que\\nassocia uma decisão com todo estado que o agente possa alcançar. Uma política ótima maximiza\\na utilidade das sequências de estados encontradas quando ela é executada.\\n•  A utilidade de um estado é a utilidade esperada das sequências de estados encontradas quando\\numa política ótima é executada, começando nesse estado. O algoritmo de \\niteração de valor\\n para\\nresolver MDPs funciona resolvendo iterativamente as equações que relacionam as utilidades de\\ncada estado às de seus vizinhos.\\n•  A \\niteração de política\\n se alterna entre o cálculo das utilidades de estados sob a política atual e\\no aperfei\\u200bçoamento da política atual com relação às utilidades atuais.\\n•  MDPs parcialmente observáveis, ou POMDPs, são muito mais difíceis de resolver que MDPs.\\nEles podem ser resolvidos pela conversão para um MDP no espaço contínuo de estados de\\ncrença; tanto os algoritmos de iteração de valor como de iteração de políticas foram delineados.\\nO comportamento ótimo em POMDPs inclui a coleta de informações para reduzir a incerteza e,\\nportanto, tomar melhores decisões no futuro.\\n•  Um agente de teoria da decisão pode ser construído para ambientes de POMDPs. O agente\\nutiliza uma \\nrede de decisão dinâmica\\n para representar os modelos de transição e observação,\\natualizar seu estado de crença e projetar para a frente possíveis sequências de ações.\\n•  A \\nteoria dos jogos\\n descreve o comportamento racional para agentes em situações nas quais\\nvários agentes interagem simultaneamente. As soluções de jogos são \\nequilíbrios de Nash\\n —\\nperfis de estratégias em que nenhum agente tem incentivo para divergir da estratégia\\nespecificada.\\n•  O \\nprojeto de mecanismos\\n pode ser usado para definir as regras pelas quais os agentes vão\\ninteragir, a fim de maximizar alguma utilidade global pela operação de agentes individualmente\\nracionais. Às vezes, existem mecanismos que atingem essa meta sem exigir que cada agente\\nconsidere as escolhas feitas por outros agentes.\\nRetornaremos ao mundo de MDPs e POMDPs no Capítulo 21, quando estudarmos métodos de\\naprendizado por reforço\\n que permitem a um agente melhorar seu comportamento a partir da\\nexperiência em ambientes sequenciais incertos.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 793}),\n",
       " Document(page_content='Richard Bellman desenvolveu as ideias subjacentes à abordagem moderna para problemas de\\ndecisão sequencial ao trabalhar na RAND Corporation no início de 1949. Segundo sua autobiografia\\n(Bellman, 1984), ele cunhou a incrível expressão “programação dinâmica” para ocultar do secretário\\nda Defesa, Charles Wilson, que tinha fobia a pesquisa, o fato de que seu grupo estava trabalhando em\\nmatemática (isso não deve ser verdade realmente porque o seu primeiro trabalho utilizando a\\nexpressão (Bellman, 1952) apareceu antes de Wilson tornar-se secretário da Defesa, em 1953). O\\nlivro de Bellman, \\nDynamic Programming\\n (1957), deu uma base sólida ao novo campo e introduziu\\nas abordagens algorítmicas básicas. A tese de doutorado de Ron Howard (1960) introduziu a\\niteração de política e a ideia de recompensa média para resolver problemas de horizonte infinito.\\nVários resultados adicionais foram introduzidos por Bellman e Dreyfus (1962). A iteração de\\npolítica modificada se deve a Van Nunen (1976) e a Puterman e Shin (1978). A iteração de política\\nassíncrona foi analisada por Williams e Baird (1993), que também provaram o limite de perda de\\npolítica da Equação 17.9. A análise de desconto em termos de preferências estacionárias se deve a\\nKoopmans (1972). Os textos de Bertsekas (1987), Puterman (1994) e Bertsekas e Tsitsiklis (1996)\\nfornecem uma introdução rigorosa a problemas de decisão sequencial. Papadimitriou e Tsitsiklis\\n(1987) descrevem resultados sobre a complexidade computacional de MDPs.\\nO importante trabalho de Sutton (1988) e Watkins (1989) em métodos de aprendizado por reforço\\npara resolução de MDPs desempenhou uma função significativa na introdução de MDPs na\\ncomunidade de IA, assim como a pesquisa posterior realizada por Barto \\net al\\n. (1995) —\\nanteriormente, o trabalho de Werbos (1977) continha muitas ideias semelhantes, mas não obteve tanta\\nrepercussão. A conexão entre MDPs e problemas de planejamento de IA foi realizada primeiro por\\nSven Koenig (1991), que mostrou que operadores probabilísticos de STRIPS fornecem uma\\nrepresentação compacta para modelos de transição — veja também Wellman (1990b). O trabalho de\\nDean \\net al\\n. (1993) e de Tash e Russell (1994) tentou superar a análise combinatória de grandes\\nespaços de estados usando um horizonte de busca limitado e estados abstratos. As heurísticas\\nbaseadas no valor de informações podem ser usadas para selecionar áreas do espaço de estados em\\nque uma expansão local do horizonte resultará em aperfeiçoamento significativo na qualidade da\\ndecisão. Os agentes que utilizam essa abordagem podem ajustar seu esforço para lidar com a pressão\\ndo tempo e gerar alguns comportamentos interessantes, como a utilização de “caminhos batidos”\\nfamiliares para descobrir rapidamente sua rota pelo espaço de estados sem ter de recalcular decisões\\nótimas em cada ponto.\\nComo se poderia esperar, os pesquisadores de IA levaram MDPs na direção de representações\\nmais expressivas, que podem acomodar problemas muito maiores do que as representações atômicas\\ntradicionais com base em matrizes de transição. O uso de uma rede bayesiana dinâmica para\\nrepresentar os modelos de transição foi uma ideia óbvia, mas o trabalho em \\nMDPs fatorados\\n(Boutilier \\net al\\n., 2000;. Koller e Parr, 2000; Guestrin \\net al\\n., 2003b) estendeu a ideia de\\nrepresentações estruturadas da função valor com melhorias demonstráveis em termos de\\ncomplexidade.\\nMDPs relacionais\\n (Boutilier \\net al\\n., 2001; Guestrin \\net al\\n., 2003a) vão um passo além, utilizando\\nrepresentações estruturadas para lidar com domínios com muitos objetos relacionados.\\nA observação de que um MDP parcialmente observável pode ser transformado em um MDP', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 794}),\n",
       " Document(page_content='regular com a utilização de estados de crença se deve a Astrom (1965) e Aoki (1965). O primeiro\\nalgoritmo completo para a solução exata de POMDPs — essencialmente o algoritmo de iteração de\\nvalor apresentado neste capítulo — foi proposto por Edward Sondik (1971) em sua tese de\\ndoutorado. — um artigo publicado mais tarde por Smallwood e Sondik (1973) contém alguns erros,\\nembora seja mais acessível. Lovejoy (1991) participou dos primeiros 25 anos de pesquisa em\\nPOMDP, atingindo conclusões um pouco pessimistas sobre a viabilidade de solução para problemas\\nde grande porte. A primeira contribuição importante dentro de IA foi o algoritmo Witness (Cassandra\\net al\\n., 1994;. Kaelbling \\net al\\n,.1998), uma versão melhorada da iteração de valor do POMDP. Logo se\\nseguiram outros algoritmos, incluindo uma abordagem criada por Hansen (1998) que constrói uma\\npolítica de modo incremental, sob a forma de um autômato de estados finitos. Um trabalho mais\\nrecente em IA focou métodos de iteração de valor \\nbaseados em ponto\\n, que, a cada iteração, geram\\nplanos condicionais e a-vetores para um conjunto finito de estados de crença, em vez de para o\\nespaço de crença inteiro. Lovejoy (1991) propôs tal algoritmo para uma grade fixa de pontos, uma\\nabordagem adotada também por Bonet (2002). Um artigo influente por Pineau \\net al.\\n (2003) sugeriu a\\ngeração de pontos alcançáveis através da simulação de trajetórias de uma forma um pouco\\ngananciosa; Spaan e Vlassis (2005) observaram que é necessário gerar planos para apenas um\\nsubconjunto pequeno de pontos, selecionados aleatoriamente para melhorar os planos de iteração\\nanteriores para todos os pontos no conjunto. Métodos atuais baseados em pontos — tal como iteração\\nde política baseada em ponto (Ji \\net al\\n., 2007) — podem gerar soluções quase ótimas para POMDP\\ncom milhares de estados. Como POMDPs são PSPACE-difícil (Papadimitriou e Tsitsiklis, 1987),\\nnovos progressos poderão exigir aproveitar vários tipos de estrutura dentro de uma representação\\nfatorada.\\nA abordagem on-line — utilizando busca de observação antecipada para selecionar uma ação para\\no estado de crença atual — primeiro foi analisada por Satia e Lave (1973). O uso da amostragem em\\nnós de acaso foi explorado analiticamente por Kearns \\net al\\n. (2000) e Ng e Jordan (2000). As ideias\\nbásicas para uma arquitetura de agentes usando redes de decisão dinâmicas foram propostas por\\nDean e Kanazawa (1989a). O livro \\nPlanning and Control\\n de Dean e Wellman (1991) trata o assunto\\ncom muito maior profundidade, fazendo conexões entre modelos de DBN/DDN e a literatura clássica\\nde controle sobre filtragem. Tatman e Shachter (1990) mostraram como aplicar algoritmos de\\nprogramação dinâmica a modelos de DDN. Russell (1998) explica várias maneiras pelas quais tais\\nagentes podem ter sua escala aumentada e identifica várias questões abertas de pesquisa.\\nAs raízes mais antigas da teoria dos jogos podem ser localizadas em propostas feitas no século\\nXVII por Christiaan Huygens e Gottfried Leibniz para estudar interações humanas competitivas e\\ncooperativas de forma científica e matemática. Ao longo do século XIX, vários economistas\\nimportantes criaram exemplos matemáticos simples para analisar casos específicos de situações\\ncompetitivas. Os primeiros resultados formais em teoria dos jogos se devem a Zermelo (1913) (que,\\nno ano anterior, sugeriu uma forma de busca de minimax para jogos, embora ela estivesse incorreta).\\nEmile Borel (1921) introduziu a noção de estratégia mista. John Von Neumann (1928) provou que\\ntodo jogo de duas pessoas e de soma zero tem um equilíbrio de maximin em estratégias mistas e um\\nvalor bem definido. A colaboração de Von Neumann com o economista Oskar Morgenstern levou à\\npublicação em 1944 do volume \\nTheory of Games and Economic Behavior\\n, o livro definitivo sobre\\nteoria dos jogos. A publicação do livro foi atrasada pela escassez de papel na época da guerra, até\\num membro da família Rockefeller subsidiar pessoalmente sua publicação.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 795}),\n",
       " Document(page_content='Em 1950, com 21 anos de idade, John Nash publicou suas ideias relativas a equilíbrios em jogos\\ngerais. Sua definição de uma solução de equilíbrio, embora se originasse do trabalho de Cournot\\n(1838), ficou conhecida como equilíbrio de Nash. Depois de um longo atraso devido à esquizofrenia\\nque ele sofreu de 1959 em diante, Nash recebeu o Prêmio Nobel de Economia em memória\\n(juntamente com Reinhart Selten e John Harsanyi) em 1994. O equilíbrio de Bayes-Nash é descrito\\npor Harsanyi (1967) e discutido por Kadane e Larkey (1982). Algumas questões relacionadas ao uso\\nda teoria dos jogos para controle de agentes são abordadas por Binmore (1982).\\nO dilema do prisioneiro foi criado como exercício de sala de aula por Albert W. Tucker em 1950\\n(baseado em um exemplo de Merrill Flood e Melvin Dresher) e foi amplamente focalizado por\\nAxelrod (1985) e Poundstone (1993). Jogos repetidos foram introduzidos por Luce e Raiffa (1957),\\nbem como jogos de informações parciais por Kuhn (1953). O primeiro algoritmo prático para jogos\\nde informações parciais, sequenciais, foi desenvolvido dentro da IA por Koller \\net al\\n. (1996); o\\nartigo de Koller e Pfeffer (1997) fornece uma introdução legível à área em geral e descreve um\\nsistema funcional para representar e resolver jogos sequenciais.\\nBillings et al. (2003) discutem o uso de abstração para reduzir uma árvore de jogo para um\\ntamanho que possa ser resolvido com a técnica de Koller. Bowling \\net al.\\n (2008) mostram como usar\\namostragem importante para obter melhor estimativa do valor de uma estratégia. Waugh \\net al.\\n (2009)\\nmostram que a abordagem da abstração é vulnerável para cometer erros sistemáticos na aproximação\\nda solução de equilíbrio, o que significa que toda a abordagem está em um terreno de areia\\nmovediça: funciona para alguns jogos, mas não para outros. Korb \\net al\\n. (1999) fizeram experimento\\ncom um modelo de oponente na forma de rede bayesiana. Ele joga com cinco cartas tão bem quanto\\nos seres humanos experientes. Zinkevich \\net al\\n. (2008) mostram como uma abordagem que minimiza o\\narrependimento pode encontrar o equilíbrio aproximado para abstrações com 10\\n12\\n estados, 100 vezes\\nmais do que os métodos anteriores.\\nA teoria dos jogos e os MDPs são combinados com os jogos da teoria de jogos de Markov,\\ntambém chamados jogos estocásticos (Littman, 1994; Hu e Wellman, 1998). Shapley (1953)\\ndescreveu realmente o algoritmo de iteração de valor independentemente de Bellman, mas seus\\nresultados não foram apreciados amplamente, talvez porque foram apresentados no contexto dos\\njogos de Markov. A teoria evolucionária dos jogos (Smith, 1982; Weibull, 1995) analisa a estratégia\\nderivada ao longo do tempo: se a estratégia do adversário estiver mudando, como se deve reagir?\\nLivros sobre a teoria dos jogos a partir de um ponto de vista econômico incluem os de Myerson\\n(1991), Fudenberg e Tirole (1991), Osborne (2004) e Osborne e Rubinstein (1994); Mailath e\\nSamuelson (2006) concentraram-se em jogos repetidos. Da perspectiva de IA temos Nisan \\net al\\n.\\n(2007), Leyton-Browne Shoham (2008) e Shoham e Leyton-Brown (2009).\\nEm 2007, o Prêmio Nobel de Economia foi para Hurwicz, Maskin e Myerson “por estabelecerem\\nas bases da teoria de projeto de mecanismos” (Hurwicz, 1973). A tragédia das comunidades, um\\nproblema motivante para o campo, foi apresentado por Hardin (1968). A revelação do princípio foi\\ndevida a Myerson (1986), e o teorema de receita de equivalência foi desenvolvido\\nindependentemente por Myerson (1981) e Riley e Samuelson (1981). Dois economistas, Milgrom\\n(1997) e Klemperer (2002), escreveram sobre os leilões de espectro de bilhões de dólares em que\\nestavam envolvidos.\\nO projeto de mecanismo é usado no planejamento multiagente (Hunsberger e Grosz, 2000; Stone \\net', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 796}),\n",
       " Document(page_content='al\\n., 2009) e escalonamento (Rassenti \\net al\\n., 1982). Varian (1995) apresenta um breve panorama com\\nligações com a literatura de ciência da computação, e Rosenschein e Zlotkin (1994) apresentam um\\ntratamento do tamanho de um livro com aplicações de IA distribuído. Trabalhos relacionados sobre\\nIA distribuído também aparecem com outros nomes, incluindo inteligência coletiva (Tumer e\\nWolpert, 2000; Segaran, 2000) e controle baseado em mercado (Clearwater, 1996). Desde 2001\\nacontece a Trading Agents Competition (TAC), em que os agentes tentam extrair o melhor lucro em\\numa série de leilões (Wellman \\net al.\\n, 2001; Arunachalam e Sadeh, 2005). Artigos sobre problemas\\ncomputacionais em leilões sempre aparecem na ACM Conferences on Electronic Commerce.\\nEXERCÍCIOS\\n17.1\\n Para o mundo 4 × 3 mostrado na \\nFigura 17.1\\n, calcule que quadrados podem ser alcançados a\\npartir de (1,1) pela sequência de ações [\\nAcima\\n, \\nAcima, Direita\\n, \\nDireita, Direita\\n] e com que\\nprobabilidades. Explique como essa computação está relacionada à tarefa de predição (veja a \\nSeção\\n15.2.1\\n) para um modelo oculto de Markov.\\n17.2\\n Selecione o membro específico do conjunto de políticas que sejam ótimas para R(s ) > 0 como\\nmostrado na \\nFigura 17.2\\n(b) e calcule a fração do tempo que o agente gasta em cada estado, no limite,\\nse a política for executada para sempre (Dica: construa a matriz de probabilidade de transição de\\nestado para estado que corresponde à política e consulte o exercício 15.2.)\\n17.3\\n Suponha que definamos a utilidade de uma sequência de estados como sendo a recompensa\\nmáxima\\n obtida em qualquer estado na sequência. Mostre que essa função utilidade não resulta em\\npreferências estacionárias entre as sequências de estados. Ainda é possível definir a função utilidade\\nem estados tais que a tomada de decisões de UME resulte em comportamento ótimo?\\n17.4\\n Às vezes, os MDPs são formulados com uma função recompensa \\nR\\n(\\ns\\n, \\na\\n) que depende da ação\\ntomada ou com uma função de recompensa \\nR\\n(\\ns\\n, \\na\\n, \\ns\\n′) que também depende do estado resultante.\\na.\\n Escreva as equações de Bellman para essas formulações.\\nb.\\n Mostre como um MDP com função de recompensa \\nR\\n(\\ns\\n, \\na\\n, \\ns\\n′) pode ser transformado em um MDP\\ndiferente com função recompensa \\nR\\n(\\ns\\n, \\na\\n), tal que políticas ótimas no novo MDP correspondam\\nexatamente às políticas ótimas no MDP original.\\nc.\\n Agora faça o mesmo para converter MDPs com \\nR\\n(\\ns\\n, \\na\\n) em MDPs com \\nR\\n(\\ns\\n).\\n17.5\\n Para o ambiente mostrado na \\nFigura 17.1\\n, encontre todos os valores de limiar para \\nR\\n(\\ns\\n),\\ntais que a política ótima se altere quando o limiar for cruzado. Você precisará de um modo para\\ncalcular a política ótima e seu valor para \\nR\\n(\\ns\\n) fixo. [\\nSugestão\\n: Prove que o valor de qualquer\\npolítica fixa varia linearmente com \\nR\\n(\\ns\\n).]\\n17.6\\n A Equação 17.7 (\\nSeção 17.2.3\\n) afirma que o operador de Bellman é uma contração.\\na.\\n Mostre que, para quaisquer funções \\nf\\n e \\ng\\n,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 797}),\n",
       " Document(page_content='b.\\n Escreva uma expressão para |\\n(BU\\ni\\n \\n– BU\\n′\\ni\\n)(s)| e aplique o resultado de (a) para completar a\\nprova de que o operador de Bellman é uma contração.\\n17.7\\n Este exercício considera os MDPs de dois jogadores que correspondem a jogos de revezamento\\nde soma zero, como os do Capítulo 5. Sejam os jogadores \\nA\\n e \\nB\\n, e seja \\nR\\n(\\ns\\n) a recompensa para o\\njogador \\nA\\n em \\ns\\n (a recompensa para \\nB\\n é sempre igual e oposta).\\na.\\n Seja \\nU\\nA\\n(\\ns\\n) a utilidade do estado \\ns\\n quando é a vez de \\nA\\n executar um movimento em \\ns\\n, e seja\\nU\\nB\\n(\\ns\\n) a utilidade do estado \\ns\\n quando é a vez de \\nB\\n fazer um movimento em \\ns\\n. Todas as\\nrecompensas e utilidades são calculadas a partir de ponto de vista de \\nA\\n (exatamente como na\\nárvore de jogo de minimax). Escreva equações de Bellman que definam \\nU\\nA\\n(\\ns\\n) e \\nU\\nB\\n(\\ns\\n).\\nb.\\n Explique como realizar a iteração de valor de dois jogadores com essas equações e defina um\\ncritério de parada apropriado.\\nc.\\n Considere o jogo descrito na \\nFigura 5.17\\n. Desenhe o espaço de estados (e não a árvore de\\njogo), mostrando os movimentos feitos por \\nA\\n como linhas contínuas e os movimentos de \\nB\\n como\\nlinhas tracejadas. Marque cada estado com \\nR\\n(\\ns\\n). Você descobrirá que é útil organizar os\\nestados (\\ns\\nA\\n, \\ns\\nB\\n) em uma grade bidimensional, usando \\ns\\nA\\n e \\ns\\nB\\n como “coordenadas”.\\nd.\\n Agora, aplique a iteração de valor de dois jogadores para resolver esse jogo e derive a política\\nótima.\\n17.8\\n Considere o mundo 3 × 3 mostrado na \\nFigura 17.14\\n(a). O modelo de transição é o mesmo que o\\n4 × 3 da \\nFigura 17.1\\n: em 80% do tempo o agente vai à direção que seleciona, o resto do tempo ele se\\nmove em ângulo reto para a direção pretendida.\\nFigura 17.14\\n (a) o mundo 3 × 3 do Exercício 17.8. A recompensa para cada estado está indicada. O\\nquadrado superior direito é um estado terminal. (b) O mundo 101 × 3 do Exercício 17.9 (omitindo 93\\ncolunas idênticas no meio). O estado inicial tem recompensa 0.\\nImplemente a iteração de valor para esse mundo para cada valor de \\nr\\n a seguir. Use recompensas\\ndescontadas com um fator de desconto de 0,99. Mostre a política obtida em cada caso. Explique\\nintuitivamente por que o valor de \\nr\\n conduz a cada política.\\na.\\n \\nr\\n = 100\\nb.\\n \\nr\\n = −3\\nc.\\n \\nr\\n = 0\\nd.\\n \\nr\\n = +3\\n17.9\\n Considere o mundo 101 × 3 mostrado na \\nFigura 17.14\\n(b). No estado inicial, o agente tem uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 798}),\n",
       " Document(page_content='escolha de duas ações determinísticas, \\nAcima\\n ou \\nAbaixo\\n, mas nos outros estados o agente tem uma\\nação determinística \\nDireita\\n. Assumindo uma função recompensa descontada, para quais valores de\\ndesconto \\nγ\\n o agente deveria escolher \\nAcima\\n e para quais \\nAbaixo\\n? Calcule a utilidade de cada ação\\ncomo uma função de \\nγ.\\n (Note que esse exemplo simples reflete realmente muitas situações do mundo\\nreal em que um deve pesar o valor de uma ação imediata em relação às consequências contínuas de\\nlongo prazo, como a escolha de despejar poluentes em um lago.)\\n17.10\\n Considere um MDP não descontado que tem três estados, (1, 2, 3), com recompensas –1, –2, 0,\\nrespectivamente. O estado 3 é um estado terminal. Nos estados 1 e 2 existem duas ações possíveis: \\na\\ne \\nb\\n. O modelo de transição é:\\n•  No estado 1, a ação \\na\\n move o agente para o estado 2 com probabilidade 0,8 e faz o agente ficar\\nparado com probabilidade 0,2.\\n•  No estado 2, a ação \\na\\n move o agente para o estado 1 com probabilidade 0,8 e faz o agente ficar\\nparado com probabilidade 0,2.\\n•  No estado 1 ou no estado 2, a ação \\nb\\n move o agente para o estado 3 com probabilidade 0,1 e faz\\no agente ficar parado com probabilidade 0,9.\\nResponda às perguntas a seguir:\\na.\\n O que pode ser determinado \\nqualitativamente\\n sobre a política ótima nos estados 1 e 2?\\nb.\\n Aplique a iteração de política mostrando completamente cada etapa, a fim de determinar a\\npolítica ótima e os valores dos estados 1 e 2. Suponha que a política inicial tenha a ação \\nb\\n em\\nambos os estados.\\nc.\\n O que acontecerá à iteração de política se a política inicial tiver a ação \\na\\n em ambos os estados?\\nO desconto ajudará? A política ótima dependerá do fator de desconto?\\n17.11\\n Considere o mundo 4 × 3 mostrado na \\nFigura 17.1\\n.\\na.\\n Implemente um simulador de ambiente para esse ambiente, tal que a geografia específica do\\nambiente seja facilmente alterada. Algum código necessário para isso já está no repositório de\\ncódigo on-line.\\nb.\\n Crie um agente que utilize iteração de política, e meça seu desempenho no simulador de\\nambiente a partir de vários estados iniciais. Execute vários experimentos a partir de cada estado\\ninicial e compare a recompensa total média recebida por execução com a utilidade do estado,\\ndeterminada por seu algoritmo.\\nc.\\n Experimente aumentar o tamanho do ambiente. De que maneira o tempo de execução para a\\niteração de política varia com o tamanho do ambiente?\\n17.12\\n Como se pode usar o algoritmo de determinação de valor para calcular a perda esperada\\nexperimentada por um agente usando um determinado conjunto de estimativas de utilidade U e um\\nmodelo estimado P, em comparação com um agente utilizando valores corretos?\\n17.13\\n Seja \\nb\\n0\\n o estado de crença inicial para que o POMDP 4 × 3 (\\nSeção 17.4.1\\n) seja a distribuição\\nuniforme sobre os estados não terminais, ou seja, \\n〈\\n〉\\n. Calcular o estado de\\ncrença exato \\nb\\n1\\n após o agente executar \\nEsquerda\\n e seu sensor relatar uma parede adjacente. Calcule', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 799}),\n",
       " Document(page_content='também \\nb\\n2\\n assumindo que o mesmo novamente acontecerá.\\n17.14\\n Qual é a complexidade de tempo das etapas de iteração do valor do POMDP para um ambiente\\nsem sensores?\\n17.15\\n Considere uma versão do POMDP de dois estados no qual o sensor é 90% confiável no estado\\n0, mas não fornece nenhuma informação no estado 1 (isto é, relata 0 ou 1 com probabilidade igual).\\nAnalise, seja qualitativa ou quantitativamente, a função utilidade e a política ótima para esse\\nproblema.\\n17.16\\n Mostre que uma estratégia de equilíbrio dominante é um equilíbrio de Nash, e não \\nvice\\n-\\nversa\\n.\\n17.7\\n No jogo infantil pedra-papel-tesoura cada jogador revela ao mesmo tempo uma escolha de\\npedra, papel ou tesoura. O papel embrulha a pedra, a pedra deixa a tesoura cega e a tesoura corta o\\npapel. Na versão extendida pedra-papel-tesoura-fogo-água, o fogo incide sobre a pedra, papel e\\ntesoura; pedra, papel e tesoura batem na água; e a água incide sobre o fogo. Escreva a matriz de\\nrecompensa e encontre uma solução de estratégia mista para esse jogo.\\n17.8\\n A matriz de recompensa seguinte, de Blinder (1983), através de Bernstein (1996), mostra um\\njogo entre políticos e o Banco Federal.\\nFed: contrair\\nFed:não fazer nada\\nFed: expandir\\nPol:contrair\\nF = 7, P = 1\\nF = 9, P = 4\\nF = 6, P = 6\\nPol:não fazer nada\\nF = 8, P = 2\\nF = 5, P = 5\\nF = 4, P = 9\\nPol: expandir\\nF = 3, P = 3\\nF = 2, P = 7\\nF = 1, P = 8\\nOs políticos podem expandir ou contrair a política fiscal, enquanto o Fed pode contrair ou expandir a\\npolítica monetária. (E certamente os dois lados podem escolher não fazer nada.) Cada lado também\\ntem preferências quanto a quem faz o que – nenhum dos lados deseja parcer ruim. As recompensas\\napresentadas são apenas as classificações das ordenações: 9 para a primeira escolha. Encontre o\\nequilíbrio do jogo de Nash utilzando estratégia pura. Essa é uma solução ótima de Pareto? Talvez à\\nessa luz você deseje analisar as políticas de administrações recentes.\\n17.19\\n Um leilão holandês é similar a um leilão inglês, mas, em vez de começar a licitação a um\\npreço baixo e incremental, em um leilão holandês o vendedor começa com um preço elevado e,\\ngradualmente, reduz o preço até que algum comprador esteja disposto a aceitar esse preço (se vários\\nagentes aceitarem o preço, um será escolhido arbitrariamente como vencedor). Mais formalmente, o\\nvendedor começa com um preço \\np\\n e gradualmente reduz \\np\\n em incrementos de \\nd\\n até que pelo menos\\num comprador aceite o preço. Assumindo que todos os ofertantes ajam racionalmente, é verdade que\\npara um \\nd\\n arbitrariamente pequeno, um leilão holandês vai sempre resultar em um valor maior para\\noofertante obter o item? Se assim for, mostre matematicamente por quê. Se não, explique como pode\\nser possível que o ofertante com o maior valor para o item não o obtenha.\\n17.20\\n Imagine um mecanismo de leilão que é apenas como um leilão de lance ascendente, exceto que,\\nao final, o ofertante vencedor, aquele que oferta b\\nmax\\n, paga apenas b\\nmax\\n/2 em vez de b\\nmax.\\n Assumindo\\nque todos os agentes são racionais, qual é a receita esperada para o leiloeiro para esse mecanismo,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 800}),\n",
       " Document(page_content='em comparação com um leilão ascendente padrão?\\n17.21\\n Equipes da National Hockey League recebem historicamente 2 pontos se ganhar um jogo e 0 se\\nperder. Se o jogo estiver empatado, haverá uma prorrogação; se ninguém ganhar na prorrogação, o\\njogo será um empate e cada equipe receberá um ponto. Mas a liga oficial sentiu que as equipes\\nestavam jogando muito conservadoramente nas prorrogações (para evitar perda), e seria mais\\nemocionante se a prorrogação produzisse um vencedor. Então, em 1999, os funcionários\\nexperimentaram um projeto de mecanismos: as regras foram alteradas, dando 1 ponto e não 0 para a\\nequipe que perder na prorrogação. Continua 2 pontos por vitória e 1 para o empate.\\na.\\n O hóquei era um jogo de soma zero antes da mudança de regra? E depois?\\nb.\\n Suponha que, em determinado período de tempo \\nt\\n em um jogo, o time da casa tenha\\nprobabilidade \\np\\n de ganhar no tempo regulamentar, probabilidade 0,78 − \\np\\n de perder e\\nprobabilidade 0,22 de entrar em prorrogação, na qual eles têm probabilidade \\nθ\\n de ganhar, 0,9 −\\nθ\\n de perder e 0,1 de empatar. Represente as equações para o valor esperado para os times de\\ncasa e visitantes.\\nc.\\n Imagine que seria legal e ético para as duas equipes fazerem um pacto pelo qual concordassem\\nque iriam patinar para obter um empate no tempo regulamentar e, depois, ambas tentariam\\nvencer seriamente na prorrogação. Em que condições, em termos de \\np\\n e \\nθ\\n, seria racional para os\\ndois times concordar com esse pacto?\\nd.\\n Longley e Sankaran (2005) relataram que, desde que a regra mudou, o percentual de jogos com\\nvencedor na prorrogação subiu 18,2%, conforme desejado, mas o percentual de prorrogações\\ntambém subiu 3,6%. O que isso sugere sobre o possível jogo de coalisão ou conservador após a\\nmudança na regra?\\n1\\n Algumas definições de MDPs permitem que a recompensa dependa também da ação e do resultado e, assim, a função de recompensa\\né \\nR\\n(\\ns\\n, \\na\\n, \\ns\\n′). Isso simplifica a descrição de alguns ambientes, mas não altera o problema em nenhum aspecto fundamental, como\\nmostrado no Exercício 17.4.\\n2\\n Embora isso pareça óbvio, não vale para as políticas de horizonte finito ou para outras formas de combinar recompensas ao longo do\\ntempo. A prova decorre diretamente da singularidade da função utilidade sobre os estados, como mostrado na \\nSeção 17.2\\n.\\n3\\n Tal como acontece com a função recompensa para MDPs, o modelo de sensoriamento também pode depender da ação e do estado\\nresultante, mas novamente essa alteração não é fundamental.\\n4\\n O jogo de par-ou-ímpar é uma versão recreativa de um \\njogo de inspeção\\n. Em tais jogos, um inspetor escolhe um dia para inspecionar\\numa instalação (como um restaurante ou uma fábrica de armas biológicas), e o operador da instalação escolhe um dia para esconder\\ntodo o material irregular. O inspetor ganha se os dias forem diferentes, e o operador da instalação ganha se eles forem iguais.\\n5\\n O caráter ótimo de Pareto tem esse nome em homenagem ao economista Vilfredo Pareto (1848-1923).\\n6\\n Ou uma constante.\\n7\\n É uma coincidência o fato de essas equações serem iguais às de \\np\\n; a coincidência surge porque \\nU\\nE\\n(\\num\\n, \\ndois\\n) = \\nU\\nE\\n(\\ndois\\n, \\num\\n) = –3.\\nIsso também explica por que a estratégia ótima é a mesma para ambos os jogadores.\\n8\\n A palavra “\\nauction\\n” (“leilão” em português) vem do latim \\naugere\\n, “aumentar”.\\n9\\n Existe realmente uma pequena chance de que o jogador com \\nv\\ni\\n mais alto deixe de obter as mercadorias no caso em que \\nb\\no\\n < \\nv\\ni\\n < \\nb\\no\\n +\\nd\\n. A chance desse acontecimento pode ser arbitrariamente pequena diminuindo-se o incremento \\nd\\n.\\n10\\n Esse nome é uma homenagem a William Vickrey (1914-1996), que ganhou o Prêmio Nobel de economia em 1996 por seu trabalho e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 801}),\n",
       " Document(page_content='morreu de um ataque cardíaco três anos depois.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 802}),\n",
       " Document(page_content='PARTE V\\nAprendizagem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 803}),\n",
       " Document(page_content='U\\nCAPÍTULO\\n \\n18\\nAprendendo a partir de exemplos\\nEm que descrevemos agentes que podem melhorar seu comportamento através\\ndo estudo diligente de suas próprias experiências.\\nm agente estará \\naprendendo\\n se melhorar o seu desempenho nas tarefas futuras de aprendizagem\\napós fazer observações sobre o mundo. A aprendizagem pode variar do corriqueiro, como anotar\\num número de telefone, até o profundo, como mostrado por Albert Einstein, que inferiu uma nova\\nteoria para o universo. Neste capítulo, vamos nos concentrar em uma classe de problema de\\naprendizagem, o que parece restrito, mas na verdade tem ampla aplicabilidade: a partir de uma\\ncoleção de pares de entrada e saída, aprender uma função que prevê a saída para novas entradas.\\nPor que iríamos querer um agente para aprender? Se o projeto do agente pode ser melhorado, para\\ncomeçar, por que os projetistas não apenas programam essa melhoria? Há três razões principais.\\nPrimeiro, os projetistas não podem antecipar todas as situações possíveis em que o agente possa se\\nencontrar. Por exemplo, um robô projetado para navegar em labirintos tem de aprender a\\nconfiguração de cada novo labirinto que encontra. Em segundo lugar, os projetistas não podem\\nantecipar todas as mudanças ao longo do tempo; um programa projetado para prever os preços do\\nmercado de ações de amanhã deve aprender a se adaptar quando as condições mudam do súbito\\ncrescimento ao fracasso. Terceiro, por vezes, os programadores humanos não têm ideia de como\\nprogramar uma solução por si só. Por exemplo, a maioria das pessoas é boa em reconhecer o rosto\\ndos membros da família, mas mesmo os melhores programadores são incapazes de programar um\\ncomputador para realizar essa tarefa, exceto por meio de algoritmos de aprendizagem. Este capítulo\\nprimeiro dá uma visão geral das diferentes formas de aprendizagem, em seguida descreve uma\\nabordagem popular, aprendizagem em árvore de decisão, na \\nSeção 18.3\\n, seguida por uma análise\\nteórica da aprendizagem nas Seções 18.4 e 18.5. Verificamos vários sistemas de aprendizagem\\nutilizados na prática: os modelos lineares, não lineares (em particular, redes neurais), não\\nparamétricos e máquinas de vetores de suporte. Finalmente vamos mostrar como conjuntos de\\nmodelos podem superar um modelo único.\\n18.1 FORMAS DE APRENDIZAGEM\\nQualquer componente de um agente pode ser melhorado através da aprendizagem a partir dos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 805}),\n",
       " Document(page_content='dados. As melhorias e as técnicas usadas para construí-los depende de quatro fatores principais:\\n•  Que \\ncomponente\\n deve ser melhorado.\\n•  O \\nconhecimento prévio\\n que o agente já tem.\\n•  Que \\nrepresentação\\n é usada para os dados e para o componente.\\n•  Que \\nfeedback\\n está disponível para aprendizagem.\\nComponentes a serem aprendidos\\nO Capítulo 2 descreveu vários projetos de agentes. Os componentes desses agentes incluem:\\n1. Um mapeamento direto de condições no estado atual para ações.\\n2. Um meio para deduzir propriedades relevantes do mundo a partir da sequência de percepções.\\n3. Informações sobre o modo como o mundo evolui e sobre os resultados de ações possíveis que o\\nagente pode executar.\\n4. Informações de utilidade indicando a desejabilidade de estados do mundo.\\n5. Informações de valores de ações indicando a desejabilidade de ações.\\n6. Metas que descrevem classes de estados cuja realização maximiza a utilidade do agente.\\nCada um desses componentes pode ser aprendido a partir de realimentação apropriada. Por\\nexemplo, considere o treinamento de um agente para se tornar motorista de táxi. Toda vez que o\\ninstrutor gritar “Freie!”, o agente poderá aprender uma regra de condição-ação sobre quando frear\\n(componente 1); o agente também sabe toda vez que o instrutor não grita. Ao ver muitas imagens que\\nlhe mostram ônibus, o agente pode aprender a reconhecê-los (2). Experimentando ações e\\nobservando os resultados — por exemplo, freando bruscamente em uma estrada molhada —, ele\\npoderá aprender os efeitos de suas ações (3). Depois, se não receber nenhuma gorjeta de passageiros\\nque foram sacudidos durante o percurso, poderá aprender um componente útil de sua função utilidade\\nglobal (4).\\nRepresentação e conhecimento prévio\\nVimos vários exemplos de representações para os componentes do agente: sentenças lógicas\\nproposicionais e de primeira ordem para os componentes de um agente lógico; redes bayesianas para\\nos componentes inferenciais de um agente de decisão teórica, e assim por diante. Os algoritmos de\\naprendizagem eficazes foram concebidos para todas essas representações. Este capítulo (e a maioria\\ndos atuais de pesquisa em aprendizagem de máquina) abrange entradas que formam uma\\nrepresentação fatorada —\\n um vetor de valores e atributos — e saídas que podem ser tanto um\\nvalor contínuo numérico como um valor discreto. O Capítulo 19 abrange funções e conhecimento\\nprévio composto por sentenças lógicas de primeira ordem, e o Capítulo 20 concentra-se em redes\\nbayesianas.\\nHá outra maneira de ver os vários tipos de aprendizagem. Dizemos que a aprendizagem de uma\\nfunção geral ou regra (possivelmente incorreta) a partir de pares específicos de entrada-saída é\\nchamada de \\naprendizagem indutiva\\n. Veremos no Capítulo 19 que também podemos fazer\\naprendizagem analítica\\n ou \\ndedutiva\\n: passar de uma regra geral conhecida a uma nova regra\\nlogicamente derivada porém útil, por permitir um processamento mais eficiente.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 806}),\n",
       " Document(page_content='Feedback\\n para aprender\\nExistem \\ntrês tipos de feedback\\n que determinam os três principais tipos de aprendizagem:\\nNa \\naprendizagem não supervisionada\\n, o agente aprende padrões na entrada, embora não seja\\nfornecido nenhum \\nfeedback\\n explícito. A tarefa mais comum de aprendizagem não supervisionada é o\\nagrupamento\\n: a detecção de grupos de exemplos de entrada potencialmente úteis. Por exemplo, um\\nagente de táxi pode desenvolver gradualmente um conceito de “dia de tráfego bom” e “dia de tráfego\\nruim” sem nunca ter sido rotulados exemplos de cada um deles por um professor.\\nEm \\naprendizagem por reforço\\n, o agente aprende a partir de uma série de reforços —\\nrecompensas ou punições. Por exemplo, a falta de gorjeta ao final de uma corrida dá ao agente do\\ntáxi a indicação de que algo saiu errado. Os dois pontos de vitória no final de um jogo de xadrez\\ninformam ao agente que fez a coisa certa. Cabe ao agente decidir qual das ações anteriores ao\\nreforço foram as maiores responsáveis \\u200b\\u200bpor isso.\\nNa \\naprendizagem supervisionada\\n, o agente observa alguns exemplos de pares de entrada e saída,\\ne aprende uma função que faz o mapeamento da entrada para a saída. No componente 1 dos\\nparágrafos anteriores, as entradas são percepções e a saída é fornecida por um instrutor que diz\\n“Freie!” ou “Vire à esquerda”. No componente 2, as entradas são imagens da câmera, e as saídas\\nvêm de um instrutor que diz “isso é ônibus”. Em 3, a teoria da frenagem é uma função de estados e\\nações de frenagem até a distância de parada. Nesse caso, o valor da saída está disponível\\ndiretamente da percepção do agente (após o fato); o ambiente é o instrutor.\\nNa prática, essas distinções nem sempre são tão nítidas. Na \\naprendizagem semissupervisionada\\n,\\nsão dados alguns poucos exemplos rotulados e deve-se fazer o que puder de uma grande coleção de\\nexemplos não rotulados. Mesmo os rótulos em si podem não ser as verdades oraculares que\\nesperamos. Imagine que você esteja tentando construir um sistema para adivinhar a idade de uma\\npessoa a partir de uma foto. Você reúne alguns exemplos rotulados tirando fotos das pessoas e\\nperguntando a idade. Isso é aprendizagem supervisionada. Mas, na realidade, algumas das pessoas\\nmentiram sua idade. Não é só que haja ruído aleatório nos dados, mas as imprecisões são\\nsistemáticas, e descobri-las é um problema de aprendizagem não supervisionada, envolvendo\\nimagens, idades autorrelatadas e idades (desconhecidas) verdadeiras. Assim, tanto ruído como falta\\nde rótulos cria um \\ncontinuum\\n entre aprendizagem supervisionada e não supervisionada.\\n18.2 APRENDIZAGEM SUPERVISIONADA\\nA tarefa de aprendizagem supervisionada é a seguinte:\\nDado um \\nconjunto de treinamento\\n de \\nN\\n pares de exemplos de entrada e saída\\n(\\nx\\n1\\n, y\\n1\\n), (\\nx\\n2\\n, y\\n2\\n),… (\\nx\\nn\\n, y\\nn\\n),\\nonde cada \\ny\\nj\\n foi gerado por uma função desconhecida \\ny = f(x),\\ndescobrir uma função \\nh\\n que se aproxime da função verdadeira \\nf\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 807}),\n",
       " Document(page_content='Aqui \\nx\\n e \\ny\\n podem ter qualquer valor, não precisando ser números. A função \\nh\\n é uma \\nhipótese\\n.\\n1\\nAprendizagem é uma busca através do espaço de hipóteses possíveis por aquele que terá um bom\\ndesempenho, mesmo em novos exemplos além do conjunto de treinamento. Para medir a precisão de\\numa hipótese, fornecemos um \\nconjunto de testes\\n de exemplos que são distintos do conjunto de\\ntreinamento. Dizemos que uma hipótese \\ngeneraliza\\n bem se prevê corretamente o valor de \\ny\\n para\\nnovos exemplos. Às vezes, a função \\nf\\n é estocástica — não é estritamente uma função de \\nx\\n, e o que\\ntemos de aprender é uma distribuição de probabilidade condicional, \\nP\\n(Y | x).\\nQuando a saída \\ny\\n for de um conjunto finito de valores (como \\nensolarado, nublado\\n ou \\nchuvoso\\n), o\\nproblema da aprendizagem será chamado de \\nclassificação\\n, e será chamado de classificação booleana\\nou binária se houver apenas dois valores. Quando \\ny\\n for um número (como temperatura de amanhã), o\\nproblema de aprendizagem é chamado de \\nregressão\\n. (Tecnicamente, a solução de um problema de\\nregressão é encontrar uma expectativa condicional ou valor médio de \\ny\\n porque a probabilidade de\\nacharmos \\nexatamente\\n o número de valor real certo para \\ny\\n é 0.)\\nA \\nFigura 18.1\\n mostra um exemplo familiar: o ajuste de função de uma única variável a alguns\\npontos de dados. Os exemplos são pontos no plano (\\nx\\n, \\ny\\n), onde \\ny = f(x).\\n Não sabemos qual é o \\nf\\n, mas\\nvamos aproximá-lo com uma função \\nh\\n selecionada a partir de um \\nespaço de hipótese\\n, \\n, que para\\neste exemplo vamos tomar como conjunto de polinômios, tais como \\nx\\n5\\n + 3\\nx\\n2\\n + 2. A \\nFigura 18.1\\n(a)\\nmostra alguns dados com um ajuste exato por linha reta (o polinômio 0,4\\nx\\n + 3). A linha é chamada\\nhipótese \\nconsistente\\n porque concorda com todos os dados. A \\nFigura 18.1\\n(b) mostra um polinômio\\nde grau alto que também é consistente com os mesmos dados. Isso ilustra o problema fundamental de\\naprendizagem indutiva: \\ncomo escolhemos entre várias hipóteses consistentes?\\n Uma resposta é\\npreferir a hipótese consistente \\nmais simples\\n para os dados. Esse princípio é chamado de \\nnavalha de\\nOckham\\n, devido ao filósofo inglês do século XIV, Guilherme de Ockham, que a usou para\\nargumentar fortemente contra todos os tipos de complicações. A definição de simplicidade não é\\nfácil, mas parece claro que um polinômio de grau 1 é mais simples do que um polinômio de grau 7 e,\\nassim, (a) deve ser preferido a (b). Tornaremos essa intuição mais precisa na \\nSeção 18.4.3\\n.\\nFigura 18.1\\n (a) Exemplo de pares (\\nx\\n, \\nf\\n(\\nx\\n)) e uma hipótese linear consistente. (b) Hipótese de\\npolinômio de grau 7 consistente para o mesmo conjunto de dados. (c) Conjunto de dados diferente\\nque admite um ajuste de polinômio de grau 6 exato ou um ajuste linear aproximado. (d) Um simples\\najuste senoidal exato para o mesmo conjunto de dados.\\n A \\nFigura 18.1\\n(c) mostra um segundo conjunto de dados. Não existe nenhuma linha reta\\nconsistente para esse conjunto de dados; de fato, ele exige um polinômio de grau 6 (com sete\\nparâmetros) para um ajuste exato. Existem apenas sete pontos de dados e, assim, o polinômio com\\nsete parâmetros não parece encontrar qualquer padrão nos dados e não esperamos que ele generalize', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 808}),\n",
       " Document(page_content='bem. A linha reta que não é consistente com qualquer um dos pontos de dados, mas pode generalizar\\nmuito bem para os valores invisíveis de \\nx\\n, também é mostrada em (c). \\nEm geral, há uma\\ncompensação entre as hipóteses complexas que ajustam bem os dados de treinamento e as\\nhipóteses mais simples que podem generalizar melhor\\n. Na \\nFigura 18.1\\n(d) expandimos o espaço de\\nhipótese \\n para permitir polinômios sobre \\nx\\n e \\nseno\\n(\\nx\\n) e verificar que os dados em (c) podem ser\\najustados exatamente por uma função simples da forma \\nax + b + c\\n seno(\\nx\\n). Isso mostra a importância\\nda escolha do espaço de hipóteses. Dizemos que um problema de aprendizagem é \\nrealizável\\n se o\\nespaço de hipótese contiver a função verdadeira. Infelizmente, nem sempre podemos dizer se um\\nproblema de aprendizagem dado é realizável porque a função verdadeira não é conhecida.\\nEm alguns casos, um analista, ao verificar um problema, está querendo fazer distinções mais\\nrefinadas sobre o espaço de hipótese mesmo sem antes ter visto todos os dados, o que não significa\\napenas que uma hipótese é possível ou impossível, mas o quanto ela é provável. Pode-se fazer a\\naprendizagem supervisionada escolhendo a hipótese \\nh*\\n que é mais provável, com os dados:\\nPela regra de Bayes isso é equivalente a\\nEntão podemos dizer que a probabilidade prévia \\nP(h)\\n é alta para um polinômio de grau 1 ou 2,\\nmas baixa para um polinômio de grau 7, e especialmente baixa para polinômios de grau 7 com\\ngrandes pontas acentuadas como na \\nFigura 18.1\\n(b). Permitimos funções de aparência incomum\\nquando os dados informam que precisam delas realmente, mas a desencorajamos, dando-lhes uma\\nprobabilidade baixa \\na priori\\n.\\n Por que não deixar \\n ser a classe de todos os programas em Java ou máquinas de Turing?\\nAfinal, cada função computável pode ser representada por alguma máquina de Turing, e isso é o\\nmelhor que podemos fazer. Um problema com essa ideia é que ela não leva em conta a complexidade\\ncomputacional da aprendizagem. \\nHá um compromisso entre a expressividade de um espaço de\\nhipótese e a complexidade de encontrar uma boa hipótese dentro desse espaço.\\n Por exemplo, a\\nadaptação de uma linha reta aos dados é um cálculo fácil, a adaptação de polinômios de grau alto é\\num pouco mais difícil, e a adaptação de máquinas de Turing em geral é indecidível. Uma segunda\\nrazão para preferir espaços de hipótese simples é que, presumivelmente, vamos querer usar \\nh\\n depois\\nde termos aprendido isso, e é garantido que o cálculo de \\nh(x)\\n quando \\nh\\n for uma função linear é mais\\nrápido, enquanto o cálculo em um programa arbitrário de máquina de Turing nem sequer se garante\\nque termine. Por essas razões, a maioria dos trabalhos sobre aprendizagem tem se concentrado em\\nrepresentações simples.\\nVerificaremos que o compromisso entre expressividade e complexidade não é tão simples como\\nparece à primeira vista: como vimos com lógica de primeira ordem, no Capítulo 8, uma linguagem\\nexpressiva torna possível que uma hipótese \\nsimples\\n ajuste-se aos dados, enquanto restringir a\\nexpressividade da língua significa que qualquer hipótese consistente deve ser muito complexa. Por\\nexemplo, as regras do xadrez podem ser escritas em uma página ou duas de lógica de primeira\\nordem, mas exigem milhares de páginas quando escritas em lógica proposicional.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 809}),\n",
       " Document(page_content='18.3 APRENDIZAGEM EM ÁRVORES DE DECISÃO\\nA indução de árvores de decisão é uma das formas mais simples, e ainda assim mais bem-\\nsucedidas, de aprendizagem de máquina. Primeiro, descreveremos a representação — o espaço de\\nhipótese — e, em seguida, como aprender uma boa hipótese.\\n18.3.1 Representação da árvore de decisão\\nUma \\nárvore de decisão\\n representa uma função que toma como entrada um vetor de valores de\\natributos e retorna uma “decisão” — um valor de saída único. Os valores de entrada e saída podem\\nser discretos ou contínuos. Por ora vamos nos concentrar em problemas em que a entrada tem valores\\ndiscretos e a saída tem exatamente dois valores possíveis; isso é classificação booleana, em que\\ncada exemplo é classificado como verdadeiro (\\npositivo\\n) ou falso (\\nnegativo\\n).\\nUma árvore de decisão alcança sua decisão executando uma sequência de testes. Cada nó interno\\nna árvore corresponde a um teste do valor de um dos atributos de entrada, \\nA\\ni\\n, e as ramificações dos\\nnós são classificadas com os valores possíveis do atributo, \\nA\\ni\\n \\n= v\\nik\\n. Cada nó de folha na árvore\\nespecifica o valor a ser retornado pela função. A representação de árvores de decisão parece ser\\nmuito natural para os seres humanos; na realidade, muitos manuais do tipo “como fazer” (por\\nexemplo, para consertos de automóveis) são inteiramente escritos como uma única árvore de decisão\\nque se estende por centenas de páginas.\\nComo exemplo, construiremos uma árvore de decisão para decidir a espera ou não de uma mesa\\nem um restaurante. Aqui, o objetivo é aprender uma definição para o \\npredicado de objetivo\\nVaiEsperar\\n. Primeiro listaremos os atributos que vamos considerar como parte da entrada:\\n1. \\nAlternativa\\n: Se há um restaurante alternativo apropriado por perto.\\n2. \\nBar\\n: Se o restaurante tem uma área de bar confortável onde se possa esperar.\\n3. \\nSex/Sáb\\n: Verdadeiro às sextas e sábados.\\n4. \\nFaminto\\n: Se estamos com fome.\\n5. \\nClientes\\n: Quantas pessoas estão no restaurante (os valores são: \\nNenhum\\n, \\nAlguns\\n e \\nCheio\\n).\\n6. \\nPreço\\n: A faixa de preços do restaurante ($, $$, $$$).\\n7. \\nChovendo\\n: Se está chovendo do lado de fora.\\n8. \\nReserva\\n: Se fizemos uma reserva.\\n9. \\nTipo\\n: O tipo de restaurante (francês, italiano, tailandês ou só de hambúrguer).\\n10. \\nEsperaEstimad\\na: A espera estimada pelo gerente (0-10 minutos, 10-30, 30-60, >60).\\nObserve que cada variável tem um pequeno conjunto de valores possíveis, o valor de\\nEsperaEstimada\\n, por exemplo, não é um número inteiro, ao contrário, é um dos quatro valores\\ndiscretos 0-10, 10-30, 30-60 ou >60. Na \\nFigura 18.2\\n é mostrada a árvore de decisão geralmente\\nusada por um de nós (SR) para esse domínio. Observe que a árvore ignora o \\nPreço\\n e o \\nTipo\\n dos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 810}),\n",
       " Document(page_content='atributos. Os exemplos são processados pela árvore a partir da raiz e seguindo a ramificação\\napropriada até alcançar uma folha. Por exemplo, uma situação com \\nClientes\\n = \\nCheio\\n e\\nEsperaEstimada\\n = 0-10 será classificada como positiva (isto é, sim, esperaremos por uma mesa).\\nFigura 18.2\\n Árvore de decisão para definir se vamos ou não esperar por uma mesa.\\n18.3.2 Expressividade de árvores de decisão\\nUma árvore de decisão booleana é logicamente equivalente à afirmação de que o atributo meta é\\nverdadeiro se e somente se os atributos de entrada satisfizerem um dos caminhos que levam a uma\\nfolha com valor \\nverdadeiro\\n. Escrevendo isso na lógica proposicional, temos\\nObjetivo\\n \\n⇔\\n (\\nCaminho\\n1\\n \\n∨\\n \\nCaminho\\n2\\n \\n∨\\n…),\\nonde cada \\nCaminho\\n é uma conjunção de testes necessários de valores de atributos para seguir esse\\ncaminho. Assim, a expressão inteira é equivalente à forma normal disjuntiva, que significa que\\nqualquer função na lógica proposicional pode ser expressa como uma árvore de decisão. Como\\nexemplo, o caminho mais à direita na \\nFigura 18.2\\n é\\nCaminho =\\n (\\nClientes = Cheio\\n \\n∧\\n \\nEsperaEstimada\\n = 0-10).\\nPara uma grande variedade de problemas, o formato da árvore de decisão gera um resultado\\nagradável e conciso. Mas algumas funções não podem ser representadas de forma concisa. Por\\nexemplo, a função da maioria, que retorna verdadeiro se e somente se mais da metade das entradas\\nfor verdadeira, exige uma árvore de decisão exponencialmente grande. Em outras palavras, as\\nárvores de decisão são boas para alguns tipos de funções e ruins para outros. Existe \\nalgum\\n tipo de\\nrepresentação que seja eficiente para todos os tipos de funções? Infelizmente, a resposta é não.\\nPodemos mostrar isso de maneira geral. Considere o conjunto de todas as funções booleanas em \\nn\\natributos. Quantas funções diferentes existem nesse conjunto? Esse é apenas o número de tabelas-\\nverdade diferentes que podemos escrever porque a função é definida pela sua tabela-verdade. A', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 811}),\n",
       " Document(page_content='tabela-verdade sobre \\nn\\n atributos tem 2\\nn\\n linhas, uma para cada combinação de valores dos atributos.\\nPodemos considerar a coluna de “resposta” da tabela como o número com 2\\nn\\n-bits que define a\\nfunção. Isso significa que há \\n funções diferentes (e haverá mais que esse número de árvores, já\\nque mais de uma árvore pode calcular a mesma função). Isso é um número assustador. Por exemplo,\\ncom apenas 10 atributos booleanos do nosso problema do restaurante há 2\\n1.024\\n ou cerca de 10\\n308\\nfunções diferentes para escolher, e, para 20 atributos, há cerca de 10\\n300.000\\n. Serão necessários alguns\\nalgoritmos engenhosos para encontrar boas hipóteses em tão grande espaço.\\n18.3.3 Indução de árvores de decisão a partir de exemplos\\nUm exemplo de árvore de decisão booleana consiste em um par (\\nx\\n, \\ny\\n), onde \\nx\\n é um vetor de\\nvalores para os atributos de entrada e \\ny\\n é um valor único de saída booleano. Um conjunto de\\ntreinamento de 12 exemplos são mostrados na \\nFigura 18.3\\n. Os exemplos positivos são aqueles em\\nque a meta \\nVaiEsperar\\n é verdadeira (\\nx\\n1\\n, \\nx\\n3\\n, …); os exemplos negativos são aqueles em que ela é\\nfalsa (\\nx\\n2\\n, \\nx\\n5\\n, …).\\nExemplo\\nAtributos\\nMeta\\nVaiEsperar\\nAlt\\nBar\\nSex\\nFam\\nCli\\nPreço\\nChuva\\nRes\\nTipo\\nEstim\\nx\\n1\\nx\\n2\\nx\\n3\\nx\\n4\\nx\\n5\\nx\\n6\\nx\\n7\\nx\\n8\\nx\\n9\\nx\\n10\\nx\\n11\\nx\\n12\\nSim\\nSim\\nNão\\nSim\\nSim\\nNão\\nNão\\nNão\\nNão\\nSim\\nNão\\nSim\\nNão\\nNão\\nSim\\nNão\\nNão\\nSim\\nSim\\nNão\\nSim\\nSim\\nNão\\nSim\\nNão\\nNão\\nNão\\nSim\\nSim\\nNão\\nNão\\nNão\\nSim\\nSim\\nNão\\nSim\\nSim\\nSim\\nNão\\nSim\\nNão\\nSim\\nNão\\nSim\\nNão\\nSim\\nNão\\nSim\\nAlguns\\nCheio\\nAlguns\\nCheio\\nCheio\\nAlguns\\nNenhum\\nAlguns\\nCheio\\nCheio\\nNenhum\\nCheio\\n$$$\\n$\\n$\\n$\\n$$$\\n$$\\n$\\n$$\\n$\\n$$$\\n$\\n$\\nNão\\nNão\\nNão\\nSim\\nNão\\nSim\\nSim\\nSim\\nSim\\nNão\\nNão\\nNão\\nSim\\nNão\\nNão\\nNão\\nSim\\nSim\\nNão\\nSim\\nNão\\nSim\\nNão\\nNão\\nFrancês\\nTailandês\\nHambúrguer\\nTailandês\\nFrancês\\nItaliano\\nHambúrguer\\nTailandês\\nHambúrguer\\nItaliano\\nTailandês\\nHambúrguer\\n0-10\\n30-60\\n0-10\\n10-30\\n>60\\n0-10\\n0-10\\n0-10\\n>60\\n10-30\\n0-10\\n30-60\\ny\\n1\\n = \\nSim\\ny\\n2\\n = \\nNão\\ny\\n3\\n = \\nSim\\ny\\n4\\n = \\nSim\\ny\\n5\\n = \\nNão\\ny\\n6\\n = \\nSim\\ny\\n7\\n = \\nNão\\ny\\n8\\n = \\nSim\\ny\\n9\\n = \\nNão\\ny\\n10\\n = \\nNão\\ny\\n11\\n = \\nNão\\ny\\n12\\n = \\nSim\\nFigura 18.3\\n Exemplos para o domínio de restaurante.\\nQueremos uma árvore que seja consistente com os exemplos e seja a menor possível. Infelizmente,\\nnão importa como medimos o tamanho, é um problema intratável encontrar a menor árvore\\nconsistente; não há maneira eficiente de busca através de \\n árvores. Com uma heurística simples,\\nno entanto, podemos encontrar uma boa solução aproximada: uma pequena (mas não a menor) árvore\\nconsistente. O algoritmo de APRENDIZAGEM EM ÁRVORE DE DECISÃO adota uma estratégia\\ngulosa de dividir para conquistar: sempre testar o atributo mais importante em primeiro lugar. Esse', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 812}),\n",
       " Document(page_content='teste divide o problema em subproblemas menores que podem então ser resolvidos de forma\\nrecursiva. Por “atributo mais importante” referimo-nos àquele que faz mais diferença para a\\nclassificação de um exemplo. Dessa forma, esperamos obter a classificação correta, com um pequeno\\nnúmero de testes, o que significa que todos os caminhos na árvore serão curtos e a árvore como um\\ntodo será pouco profunda.\\nA \\nFigura 18.4\\n(a) mostra que \\nTipo\\n é um atributo fraco porque nos deixa com quatro resultados\\npossíveis, cada um dos quais tem o mesmo número de exemplos positivos e negativos. Por outro\\nlado, na \\nFigura 18.4\\n(b), vemos que \\nClientes\\n é um atributo bastante importante porque, se o valor é\\nNenhum\\n ou \\nAlguns\\n, ficamos com conjuntos de exemplos para os quais podemos definitivamente\\nresponder (\\nNão\\n e \\nSim\\n, respectivamente). Se o valor é \\nCheio\\n, ficamos com um conjunto misto de\\nexemplos. Em geral, depois que o primeiro teste de atributo separar os exemplos, cada resultado será\\num novo problema de aprendizagem de árvore de decisão em si, com menos exemplos e um atributo a\\nmenos. Existem quatro casos a considerar para esses problemas recursivos:\\nFigura 18.4\\n Divisão dos exemplos por meio de testes em atributos. A cada nó mostramos os\\nexemplos remanescentes: positivos (caixas claras) e negativos (caixas escuras). (a) A divisão por\\nTipo\\n não nos leva mais perto de distinguir entre exemplos positivos e negativos. (b) A divisão em\\nClientes faz um bom trabalho de separação de exemplos positivos e negativos. Após a divisão em\\nClientes\\n, \\nFaminto\\n é um segundo teste razoavelmente bom.\\n1. Se todos os exemplos restantes forem positivos (ou todos negativos), terminamos: podemos\\nresponder \\nSim\\n ou \\nNão\\n. A \\nFigura 18.4\\n(b) mostra exemplos disso nos casos \\nNenhum\\n e \\nAlguns\\n.\\n2. Se existem alguns exemplos positivos e alguns negativos, escolha o melhor atributo para dividi-\\nlos. A \\nFigura 18.4\\n(b) mostra \\nFaminto\\n sendo usado para dividir os exemplos restantes.\\n3. Se não resta nenhum exemplo, isso significa que nenhum exemplo desse tipo foi observado, e\\nretornamos um valor-padrão calculado a partir da classificação de maioria de todos os\\nexemplos que foram utilizados na construção do nó pai. Esses são transmitidos na variável\\nexemplos-pais\\n.\\n4. Se não resta nenhum atributo mas há exemplos positivos e negativos, esses exemplos têm\\nexatamente a mesma descrição, mas classificações diferentes. Isso acontece quando alguns\\ndados estão incorretos (dizemos nesse caso que existe \\nruído\\n nos dados) e também quando o\\ndomínio é não determinístico, ou ainda porque não podemos observar um atributo que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 813}),\n",
       " Document(page_content='distinguiria os exemplos. O melhor que podemos fazer é voltar à classificação da maioria dos\\nexemplos remanescentes.\\nO algoritmo de APRENDIZAGEM EM ÁRVORE DE DECISÃO é mostrado na \\nFigura 18.5\\n.\\nObserve que o conjunto de exemplos é crucial para a \\nconstrução\\n da árvore, mas na árvore mesmo os\\nexemplos não aparecem em nenhum lugar. Uma árvore é composta apenas de testes em atributos no\\ninterior de seu nós, valores de atributos nas ramificações e valores de saída nos nós folha. Os\\ndetalhes da função IMPORTÂNCIA são apresentados na \\nSeção 18.3.4\\n. A saída do algoritmo de\\naprendizagem na nossa amostra de conjunto de treinamento é mostrada na \\nFigura 18.6\\n. A árvore é\\nclaramente diferente da árvore original mostrada na \\nFigura 18.2\\n. Pode-se concluir que o algoritmo de\\naprendizagem não está fazendo um trabalho muito bom na aprendizagem da função correta. No\\nentanto, isso seria a conclusão errada. O algoritmo de aprendizagem verifica os exemplos, e não a\\nfunção correta e, de fato, sua hipótese (\\nFigura 18.6\\n) não só é compatível com todos os exemplos, mas\\né consideravelmente mais simples que a árvore original! O algoritmo de aprendizagem não tem razão\\npara incluir testes para \\nChuva e Reserva\\n porque pode classificar todos os exemplos sem eles. Foi\\ntambém detectado um padrão interessante e previamente insuspeito: o primeiro autor vai esperar por\\ncomida tailandesa em fins de semana. Também se vê limitado a cometer erros em casos em que não\\nhaja exemplos. Por exemplo, ele nunca viu um caso em que a espera é 0-10 minutos, mas o\\nrestaurante está cheio.\\nfunção\\n APRENDIZAGEM-EM-ÁRVORE-DE-DECISÃO(\\nexemplos, atributos, exemplos-pais)\\nretorna\\n uma árvore de decisão\\n    \\nse\\n exemplos é vazio \\nentão retornar\\n VALOR-DA-MAIORIA (\\nexemplos_pais\\n)\\n    \\nsenão se\\n todos os \\nexemplos\\n têm a mesma classificação \\nentão retornar\\n a classificação\\n    \\nsenão se\\n \\natributos\\n é vazio \\nentão retornar\\n VALOR-DA-MAIORIA(\\nexemplos\\n)\\n    \\nsenão\\n        A ← argmax \\na\\n \\n∊\\n \\natributes\\nIMPORTÂNCIA (\\na\\n, \\nexemplos\\n)\\n        \\nárvore\\n ← uma nova árvore de decisão com teste de raiz \\nA\\n        \\npara cada\\n valor \\nv\\nk\\n de \\nA\\n \\nfaça\\n            \\nexs\\n ← {\\ne\\n : \\ne\\n \\n∊\\n \\nexemplos\\n \\ne\\n \\ne\\n.\\nA\\n \\n=\\n \\nv\\nk\\n}\\n            \\nsubárvore\\n ← APRENDIZAGEM-EM-ÁRVORE-DE-DECISÃO (\\nexs, atributos\\n — \\nA,\\nexemplos\\n)\\n            adicionar uma ramificação à árvore com rótulo (\\nA = v\\nk\\n) e subárvore \\nsubárvore\\n        \\nretornar\\n \\nárvore\\nFigura 18.5\\n O algoritmo de aprendizagem de árvore de decisão. A função IMPORTÂNCIA será\\ndescrita na \\nSeção 18.3.4\\n. A função VALOR-DA MAIORIA seleciona o valor de saída mais comum\\nem um conjunto de exemplos, resolvendo os empates aleatoriamente.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 814}),\n",
       " Document(page_content='Figura 18.6\\n Árvore de decisão induzida a partir do conjunto de treinamento de 12 exemplos.\\nNesse caso, não é para esperar quando \\nFaminto\\n for falso, mas eu (SR) certamente vou esperar.\\nCom mais exemplos de treinamento, o programa de aprendizagem poderia corrigir esse erro.\\nObservamos que há um perigo de superinterpretar a árvore que o algoritmo seleciona. Quando\\nexistem diversas variáveis de importância similar, a escolha entre elas é um tanto arbitrária: com\\nexemplos de entrada ligeiramente diferentes, em primeiro lugar, seria escolhida uma variável\\ndiferente para dividir, e a árvore toda pareceria completamente diferente. A função calculada pela\\nárvore ainda seria semelhante, mas a estrutura da árvore poderia variar muito.\\nPode-se avaliar a precisão de um algoritmo de aprendizagem com uma \\ncurva de aprendizagem\\n,\\ncomo mostrado na \\nFigura 18.7\\n. Temos 100 exemplos à nossa disposição, que dividimos em um\\nconjunto de treinamento e em um conjunto de teste. Aprendemos uma hipótese \\nh\\n com o conjunto de\\ntreinamento e medimos a sua precisão com o conjunto de teste. Fazemos isso começando com um\\nconjunto de treinamento de tamanho 1 e aumentando um de cada vez até o tamanho 99. Para cada\\ntamanho realmente repetimos o processo de dividir 20 vezes aleatoriamente e tiramos a média dos\\nresultados de 20 tentativas. A curva mostra que, à medida que o tamanho do conjunto de treinamento\\ncresce, a precisão aumenta (por essa razão, as curvas de aprendizagem são também chamadas de\\ncurvas felizes\\n). Nessa curva nós atingimos 95% de precisão, e parece que com mais dados a curva\\npode continuar a aumentar.\\nFigura 18.7\\n Curva de aprendizagem do algoritmo de aprendizagem em árvore de decisão em 100\\nexemplos gerados aleatoriamente no domínio do restaurante. Cada ponto de dados é a média de 20\\ntentativas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 815}),\n",
       " Document(page_content='18.3.4 Escolha de testes de atributos\\nA busca gulosa utilizada em aprendizagem de árvore de decisão foi projetada para minimizar\\naproximadamente a profundidade da árvore final. A ideia é escolher o atributo que vá o mais longe\\npossível na tentativa de fornecer uma classificação exata dos exemplos. Um atributo perfeito divide\\nos exemplos em conjuntos, cada um dos quais será todo positivo ou negativo que, então, se tornarão\\nas folhas da árvore. O atributo \\nClientes\\n não é perfeito, mas é bastante bom. Um atributo realmente\\ninútil, como \\nTipo\\n, deixa os conjuntos de exemplos com aproximadamente a mesma proporção de\\nexemplos positivos e negativos do conjunto original.\\nEntão, tudo de que precisamos é uma medida formal de “bastante bom” e “realmente inútil”, e\\npoderemos implementar a função IMPORTÂNCIA da \\nFigura 18.5\\n. Usaremos a noção de ganho de\\ninformação, que é definida em termos de \\nentropia\\n, a quantidade fundamental em teoria da informação\\n(Shannon e Weaver, 1949).\\nA entropia é uma medida da incerteza de uma variável aleatória; a aquisição de informação\\ncorresponde a uma redução na entropia. A variável aleatória com um único valor — uma moeda que\\nsempre dá cara — não tem incerteza e, portanto, sua entropia é definida como zero; assim, obtemos a\\ninformação observando o seu valor. O lançamento de uma moeda honesta é igualmente provável de\\ndar cara ou coroa, 0 ou 1; mostraremos em breve que isso vale como “1 bit” de entropia. O\\nlançamento de um dado honesto de quatro lados tem 2 bits de entropia porque toma dois bits para\\ndescrever uma de quatro escolhas igualmente prováveis. Agora, considere uma moeda viciada que dá\\ncara 99% do tempo. Intuitivamente, essa moeda tem menos incerteza do que a moeda honesta — se\\napostarmos em cara estaremos errados apenas 1% do tempo — de modo que gostaríamos que ela\\ntivesse uma medida de entropia perto de zero, mas positiva. Em geral, a entropia de uma variável\\naleatória \\nV\\n com valores \\nv\\nk\\n cada um com probabilidade \\nP\\n(\\nv\\nk\\n), é definida como\\nPodemos verificar que a entropia de um lançamento de uma moeda honesta é realmente de 1 bit:\\nH (honesta\\n) = − (0,5 log\\n2\\n 0,5 + 0,5 log\\n2\\n 0,5) = 1.\\nSe a moeda for adulterada para dar 99% cara, obtemos\\nH (adulterada\\n) = − (0,99 log\\n2\\n 0,99 + 0,01 log\\n2\\n 0,01) ≈ 0,08 bits.\\nEla vai ajudar a definir \\nB\\n(\\nθ\\n) como a entropia de uma variável aleatória booleana que é verdadeira\\ncom probabilidade \\nθ\\n:\\nB\\n(\\nθ\\n) = − (\\nθ\\n log\\n2\\n q + (1−\\nθ\\n) log\\n2\\n (1 − \\nθ\\n)).\\nAssim, \\n(\\nAdulterada\\n) = \\nB\\n(0,99) ≈ 0,08. Agora vamos voltar para a aprendizagem da árvore de\\ndecisão. Se um conjunto de treinamento contiver \\np\\n exemplos positivos e \\nn\\n exemplos negativos, a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 816}),\n",
       " Document(page_content='entropia do atributo meta em todo o conjunto será\\nO conjunto de treinamento do restaurante na \\nFigura 18.3\\n tem \\np = n\\n = 6, então a entropia\\ncorrespondente é \\nB\\n(0,5) ou exatamente 1 bit. Um teste em um único atributo \\nA\\n pode nos dar apenas\\numa parte desse bit 1. Podemos medir exatamente o quanto verificando a entropia remanescente \\napós\\no teste do atributo.\\nUm atributo \\nA\\n com valores distintos \\nd\\n divide o conjunto de treinamento \\nE\\n em subconjuntos \\nE\\n1\\n,…,\\nE\\nd\\n. Cada subconjunto \\nE\\nk\\n tem \\np\\nk\\n exemplos positivos e \\nn\\nk\\n exemplos negativos; por isso, se\\ncontinuarmos ao longo dessa ramificação, precisaremos de \\nB(p\\nk\\n/(p\\nk\\n \\n+ n\\nk\\n))\\n bits adicionais de\\ninformação para responder à pergunta. Um exemplo escolhido aleatoriamente do conjunto de\\ntreinamento tem o valor \\nk\\n-ésimo para o atributo com probabilidade (\\np\\nk\\n \\n+ n\\nk\\n)/(p + n\\n), então a\\nentropia esperada remanescente após testar o atributo \\nA\\n é\\nO \\nganho de informação\\n do teste do atributo em \\nA\\n é a redução esperada na entropia:\\nDe fato \\nGanho\\n(\\nA\\n) é justamente o que precisamos para implementar a função IMPORTÂNCIA.\\nRetornando aos atributos considerados na \\nFigura 18.4\\n, temos\\nconfirmando a nossa intuição de que \\nClientes\\n é um atributo melhor para dividir. Na verdade,\\nClientes\\n tem o ganho máximo de qualquer dos atributos e seria escolhido pelo algoritmo de\\naprendizagem em árvore de decisão como a raiz.\\n18.3.5 Generalização e superadaptação\\nEm alguns problemas, o algoritmo APRENDIZAGEM-EM-ÁRVORE-DE-DECISÃO vai gerar\\numa grande árvore quando realmente não houver padrão a ser encontrado. Considere o problema de\\ntentar prever se o lançamento de um dado vai dar 6 ou não. Suponha que os experimentos sejam\\nrealizados com dados diferentes e que os atributos que descrevem cada exemplo de treinamento\\nincluem a cor do dado, seu peso, o tempo em que o lançamento foi feito e se os testadadores tinham\\nos dedos cruzados. Se os dados forem honestos, a aprendizagem correta será uma árvore com um\\núnico nó que diz “não”, mas o algoritmo APRENDIZAGEM-EM-ÁRVORE-DE-DECISÃO vai se', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 817}),\n",
       " Document(page_content='aproveitar de qualquer padrão que puder encontrar na entrada. Se for descoberto que há dois lances\\nde um dado azul de 7 g com os dedos cruzados e os dois dão 6, então o algoritmo pode construir um\\ncaminho que prevê 6 nesse caso. Esse problema é chamado de \\nsuperadaptação\\n. Um fenômeno geral,\\na superadaptação ocorre com todos os tipos de aprendizes, mesmo quando a função de destino não\\nfor de todo aleatória. Na \\nFigura 18.1\\n(b) e (c), vimos funções polinomiais sobreadaptando os dados.\\nA superadaptação torna-se mais provável à medida que o espaço de hipótese e o número de atributos\\nde entrada cresce, e menos provável à medida que aumentamos o número de exemplos de\\ntreinamento.\\nPara árvores de decisão, uma técnica chamada \\npoda de árvore de decisão\\n combate a\\nsuperadaptação. A poda funciona através da eliminação dos nós que não são claramente relevantes.\\nComeçamos com uma árvore cheia, como a gerada pela APRENDIZAGEM-EM-ÁRVORE-DE-\\nDECISÃO. Em seguida, verificamos um nó de teste que tem somente nós folha como descendentes.\\nSe o teste parece ser irrelevante — detecta apenas o ruído dos dados —, eliminamos o teste,\\nsubstituindo-o por um nó folha. Repetimos esse processo, considerando cada teste apenas com\\ndescendentes folha, até que cada um seja podado ou aceito como é.\\nA questão é como podemos detectar que um nó está testando um atributo irrelevante. Suponha que\\nestejamos em um nó consistindo os exemplos em \\np\\n positivo e \\nn\\n negativos. Se o atributo for\\nirrelevante, seria de esperar que dividisse os exemplos em subconjuntos com aproximadamente a\\nmesma proporção de exemplos positivos como o conjunto todo, \\np\\n/(\\np\\n + \\nn\\n) e, assim, o ganho de\\ninformação estaria perto de zero.\\n2\\n Desse modo, o ganho de informações é uma boa pista para a\\nirrelevância. Agora, a pergunta é: qual o tamanho do ganho que devemos exigir para fazer uma\\ndivisão baseada em um atributo específico?\\nPodemos responder a essa pergunta usando um \\nteste de significância\\n estatístico. Tal teste começa\\npela suposição de que não existe nenhum padrão subjacente (a hipótese conhecida como \\nhipótese\\nnula\\n). Então, os dados reais são analisados para se calcular até que ponto eles divergem de uma\\nausência perfeita de padrão. Se o grau de desvio for estatisticamente improvável (em geral, adotado\\ncomo a média para indicar probabilidade de 5% ou menos), ele será considerado como boa\\nevidência da presença de um padrão significativo nos dados. As probabilidades são calculadas a\\npartir de distribuições-padrão da proporção de desvio que se esperaria ver em uma amostragem\\naleatória.\\nNesse caso, a hipótese nula é que o atributo é irrelevante e, consequentemente, que o ganho de\\ninformações para uma amostra infinitamente grande seria zero. Precisamos calcular a probabilidade\\nde que, sob a hipótese nula, uma amostra de tamanho \\nv\\n = \\nn\\n + \\np\\n exiba o desvio observado a partir da\\ndistribuição esperada de exemplos positivos e negativos. Podemos medir o desvio comparando os\\nnúmeros reais de exemplos positivos e negativos em cada subconjunto, \\np\\nk\\n e \\nn\\nk\\n, com os números\\nesperados, \\n, supondo irrelevância verdadeira:\\nUma medida conveniente do desvio total é dada por:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 818}),\n",
       " Document(page_content='Sob a hipótese nula, o valor de ∆ é distribuído de acordo com a distribuição \\nχ\\n2\\n (qui-quadrado)\\ncom \\nv\\n – 1 graus da liberdade. Podemos usar uma tabela \\nχ\\n2\\n ou uma rotina de biblioteca padrão de\\nestatística para ver se um valor ∆ particular confirma ou rejeita a hipótese nula. Por exemplo,\\nconsidere o atributo do tipo restaurante, com quatro valores e, portanto, três graus de liberdade. Um\\nvalor de ∆ = 7,82 ou mais rejeitaria a hipótese nula ao nível de 5% (e um valor de ∆ = 11,35 ou mais\\nrejeitaria ao nível de 1%). O Exercício 18.8 pede para fazer as mudanças apropriadas em\\nAPRENDIZAGEM-EM-ÁRVORE-DE-DECISÃO para implementar essa forma de poda, que é\\nconhecida como \\npoda\\n χ\\n2\\n.\\nCom a poda, o ruído nos exemplos podem ser tolerados. Erros no rótulo do exemplo (por exemplo,\\num exemplo (\\nx\\n, \\nSim\\n) que deve ser (\\nx\\n, \\nNão\\n)) fornece um aumento linear no erro de previsão, enquanto\\nos erros nas descrições de exemplos (por exemplo, \\nPreço\\n = $ quando na verdade era \\nPreço\\n = $$)\\ntem um efeito assintótico que piora à medida que a árvore encolhe para conjuntos menores. As\\nárvores podadas desempenham significativamente melhor do que as árvores não podadas quando os\\ndados contêm grande quantidade de ruído. Além disso, as árvores podadas geralmente são muito\\nmenores e, portanto, mais fáceis de entender.\\nUm aviso final: você poderia pensar que a poda \\nχ\\n2\\n e o ganho de informação parecem semelhantes,\\nentão por que não combiná-los usando uma abordagem chamada \\nparada antecipada\\n — a\\npropriedade do algoritmo da árvore de decisão parar de gerar nós quando não houver um bom\\natributo para dividir, em vez de enfrentar todo o problema de geração de nós para então podá-los? O\\nproblema com a parada antecipada é que impede de reconhecer situações em que não há um atributo\\nbom, mas há combinações de atributos que são informativos. Por exemplo, considere a função XOR\\nde dois atributos binários. Se houver um número aproximadamente igual de exemplos para todas as\\nquatro combinações de valores de entrada, nenhum atributo será informativo, e o correto a fazer é\\ndividir um dos atributos (não importa qual) e depois, no segundo nível, obteremos divisões que são\\ninformativas. A parada antecipada perderia isso, mas gerar e podar trataria isso corretamente.\\n18.3.6 Ampliando a aplicabilidade de árvores de decisão\\nPara estender a indução de árvore de decisão a uma variedade mais ampla de problemas, devemos\\natacar várias questões. Mencionaremos rapidamente várias, sugerindo que a compreensão total será\\nobtida fazendo-se os exercícios associados:\\n•  \\nOmissão de dados:\\n Em muitos domínios, nem todos os valores de atributos serão conhecidos\\npara todo exemplo. Os valores podem não ter sido registrados ou talvez seja dispendioso demais\\nobtê-los. Isso dá origem a dois problemas: primeiro, dada uma árvore de decisão completa,\\ncomo se deve classificar um objeto em que esteja faltando um dos atributos de teste? Em segundo\\nlugar, como se deve modificar a fórmula de ganho de informações quando alguns exemplos têm\\nvalores desconhecidos para o atributo? Essas perguntas serão tratadas no Exercício 18.9.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 819}),\n",
       " Document(page_content='•  \\nAtributos multivalorados\\n: Quando um atributo tem muitos valores possíveis, a medida de ganho\\nde informações fornece uma indicação imprópria da utilidade do atributo. No caso extremo, um\\natributo como \\nExactTime\\n tem valor diferente para cada exemplo, o que significa que cada\\nsubconjunto de exemplos é avulso com classificação única, e a medida do ganho de informação\\nterá seu maior valor para esse atributo. Mas, em primeiro lugar, a escolha dessa divisão é pouco\\nprovável de produzir a melhor árvore. Uma solução é usar a \\nrazão de ganho\\n (Exercício 18.10).\\nOutra possibilidade é permitir que um teste booleano da forma \\nA\\n = \\nv\\nk\\n,\\n isto é, tomar apenas um\\ndos valores possíveis para um atributo, deixando os valores restantes para serem testados\\neventualmente depois na árvore.\\n•  \\nAtributos de entrada com valores contínuos e inteiros\\n: Os atributos de valores contínuos ou\\ninteiros, como \\nAltura\\n e \\nPeso\\n, têm um conjunto infinito de valores possíveis. Em vez de gerar um\\nnúmero infinito de ramificações, os algoritmos de aprendizagem de árvore de decisão em geral\\nencontram o ponto de divisão que fornece o mais alto ganho de informações. Por exemplo, em\\ndado nó na árvore, talvez a realização de testes sobre \\nPeso\\n >160 forneça o máximo de\\ninformações. Existem métodos eficientes para encontrar pontos de divisão bons: começar\\nclassificando os valores do atributo e depois considerar apenas os pontos de divisão que estão\\nentre dois exemplos em ordem com diferentes classificações, enquanto acompanhando a\\nexecução dos totais de exemplos positivos e negativos de cada lado do ponto de divisão. A\\ndivisão é a parte mais cara das aplicações de aprendizagem em árvore de decisão do mundo\\nreal.\\n•  \\nAtributos de saída com valores contínuos:\\n Se estamos tentando prever um valor numérico de\\nsaída, como o preço de um apartamento, precisamos de uma \\nárvore de regressão\\n, em vez de\\numa árvore de classificação. Uma árvore de regressão tem em cada folha uma função linear de\\num subconjunto de atributos numéricos, em vez de um único valor. Por exemplo, a ramificação\\npara o apartamento de dois quartos pode acabar em uma função linear de metragem quadrada,\\nnúmero de banheiros e a renda média da vizinhança. O algoritmo de aprendizagem deve decidir\\nquando interromper a divisão e começar a aplicar a regressão linear (consulte a \\nSeção 18.6\\n)\\nsobre os atributos.\\nUm sistema de aprendizagem em árvore de decisão para aplicações reais deve ser capaz de\\nmanipular todos esses problemas. O tratamento de variáveis de valores contínuos é especialmente\\nimportante porque tanto processos físicos quanto financeiros fornecem dados numéricos. Vários\\npacotes comerciais foram construídos para atender a esses critérios, e eles têm sido usados para\\ndesenvolver milhares de sistemas de campo. Em muitas áreas da indústria e do comércio, as árvores\\nde decisão costumam ser o primeiro método experimentado quando um método de classificação tem\\nde ser extraído de um conjunto de dados. Uma propriedade importante das árvores de decisão é que é\\npossível para um ser humano entender a razão da saída do algoritmo de aprendizagem (na realidade,\\nessa é uma \\nexigência\\n legal para decisões financeiras que estão sujeitas a leis contra a\\ndiscriminação). Essa propriedade não é compartilhada por algumas outras representações, tais como\\nas redes neurais.\\n18.4 AVALIAÇÃO E ESCOLHA DA MELHOR HIPÓTESE', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 820}),\n",
       " Document(page_content='Queremos aprender uma hipótese que melhor se ajuste aos dados futuros. Para tornar isso preciso\\nprecisamos definir “dados futuros” e “melhor”. Façamos a \\nsuposição de estacionaridade\\n: que há\\numa distribuição de probabilidade sobre exemplos que permanece estacionária ao longo do tempo.\\nCada exemplo de ponto de dados (antes de vê-lo) é uma variável aleatória \\nE\\nj\\n cujo valor observado\\ne\\nj\\n \\n= (x\\nj\\n, y\\nj\\n)\\n é amostrado da distribuição e é independente dos exemplos anteriores:\\ne cada exemplo tem uma distribuição de probabilidades anterior idêntica:\\nOs exemplos que satisfazem essas suposições são chamados \\nindependentes e identicamente\\ndistribuídos\\n ou \\ni.i.d.\\n Uma suposição i.i.d. liga o passado ao futuro; sem tal conexão, todas as apostas\\nestão fora — o futuro poderá ser qualquer coisa (veremos mais adiante que a aprendizagem ainda\\npode ocorrer se houver mudanças lentas na distribuição).\\nO próximo passo é definir o “melhor ajuste”. Definimos a \\ntaxa de erro\\n de uma hipótese como a\\nproporção de erros que ela comete — a proporção de vezes em que \\nh\\n(\\nx\\n) ≠ \\ny\\n para o exemplo (\\nx\\n, \\ny\\n).\\nAgora, só porque uma hipótese \\nh\\n tem taxa de erro baixa no conjunto de treinamento não significa que\\nela generalize bem. Um professor sabe que um exame não vai avaliar com precisão os alunos se eles\\njá viram as questões do exame. Da mesma forma, para obter avaliação precisa de uma hipótese, é\\npreciso testá-la em um conjunto de exemplos que não tenham sido vistos ainda. A abordagem mais\\nsimples é a que já vimos: dividir aleatoriamente os dados disponíveis em um conjunto de treinamento\\na partir do qual o algoritmo de aprendizagem produz \\nh\\n e um conjunto de teste em que a precisão de \\nh\\né avaliada. Esse método, chamado às vezes de \\nvalidação cruzada por retenção\\n, tem a desvantagem\\nde não conseguir usar todos os dados disponíveis; se utilizarmos a metade dos dados para o conjunto\\nde teste, estaremos treinando em apenas metade dos dados, e podemos ter uma hipótese mais fraca.\\nPor outro lado, se reservamos apenas 10% dos dados para o conjunto de teste, podemos, por acaso\\nestatístico, obter uma estimativa fraca da precisão real.\\nPodemos apertar mais os dados e ainda obter uma estimativa precisa usando uma técnica chamada\\nvalidação cruzada com\\n \\nk\\n-repetições\\n. A ideia é que cada exemplo sirva duplamente — como dados\\nde treinamento e dados de teste. Primeiro dividimos os dados em \\nk\\n subconjuntos iguais. Em seguida,\\nrealizamos \\nk\\n rodadas de aprendizagem; em cada rodada 1/\\nk\\n dos dados é retido como um conjunto de\\nteste e os exemplos restantes são usados como dados de treinamento. A pontuação média do conjunto\\nde teste de \\nk\\n rodadas deve então ser uma estimativa melhor do que uma pontuação única. Os valores\\npopulares de \\nk\\n são 5 e 10 — o suficiente para dar uma estimativa que é estatisticamente provável que\\nseja precisa, a um custo 5-10 vezes maior do tempo de computação. O extremo é \\nk\\n = \\nn\\n, também\\nconhecido como \\nvalidação cruzada com omissão de um\\n ou \\nVCCOU\\n.\\nApesar dos melhores esforços dos metodólogos estatísticos, os usuários frequentemente invalidam\\nseus resultados ao \\nespreitar\\n inadvertidamente os dados de teste. A espreita pode acontecer assim:\\num algoritmo de aprendizagem tem vários “botões” que podem ser fraudados para ajustar seu\\ncomportamento — por exemplo, vários critérios diferentes para escolher o próximo atributo de\\naprendizagem em árvore de decisão. O pesquisador gera hipóteses para várias configurações', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 821}),\n",
       " Document(page_content='diferentes dos botões, as medidas de suas taxas de erro sobre o conjunto de teste e relatórios de taxa\\nde erro das melhores hipóteses. Infelizmente, ocorreu a espreita! A razão é que a hipótese foi\\nselecionada com base em sua \\ntaxa de erro de conjunto de teste\\n; assim, a informação sobre o\\nconjunto de teste vazou no algoritmo de aprendizagem.\\nEspreitar é uma consequência de uso do desempenho do conjunto de teste, tanto para \\nescolher\\n uma\\nhipótese como para \\navaliá\\n-la. A maneira de evitar isso é \\nrealmente\\n reter o conjunto de teste —\\nbloqueá-lo até que a aprendizagem esteja completa e se deseja simplesmente obter uma avaliação\\nindependente da hipótese final. (E, então, se você não gostar dos resultados… terá de obter, e\\nbloquear, um conjunto de teste completamente novo se quiser voltar e encontrar uma hipótese\\nmelhor.) Se o conjunto de teste estiver bloqueado, mas você ainda quiser medir o desempenho dos\\ndados não vistos, como forma de selecionar uma boa hipótese, divida os dados disponíveis (sem o\\nconjunto de teste) em um conjunto de treinamento e em um \\nconjunto de validação\\n. A próxima seção\\nmostra como usar conjuntos de validação para encontrar uma boa contrapartida entre a complexidade\\nda hipótese e a excelência do ajuste.\\n18.4.1 Seleção do modelo: complexidade\\n \\nversus\\n \\nexcelência de ajuste\\nNa \\nFigura 18.1\\n mostramos que os polinômios de maior grau podem se ajustar melhor aos dados de\\ntreinamento, mas quando o grau é muito alto eles vão se superadaptar e desempenhar mal a validação\\ndos dados. A escolha do grau do polinômio é um exemplo do problema de \\nseleção de modelos\\n.\\nImagine a tarefa de encontrar a melhor hipótese como duas tarefas: a seleção do modelo define o\\nespaço de hipóteses e a \\notimização\\n encontra a melhor hipótese dentro desse espaço.\\nNesta seção, vamos explicar como escolher entre os modelos que são parametrizados por\\ntamanho\\n. Por exemplo, com polinômios temos o \\ntamanho\\n = 1 para funções lineares, o \\ntamanho\\n = 2\\npara equações quadráticas, e assim por diante. Para árvores de decisão, o tamanho pode ser o\\nnúmero de nós na árvore. Em todos os casos queremos encontrar o valor do parâmetro \\ntamanho\\n que\\nmelhor equilibre a subadaptação e a superadaptação para proporcionar a melhor precisão do\\nconjunto de teste.\\nA \\nFigura 18.8\\n mostra um algoritmo para realizar a seleção do modelo e a otimização. É um\\nempacotador\\n que toma um algoritmo de aprendizagem como argumento (APRENDIZAGEM-EM-\\nÁRVORE-DE-DECISÃO, por exemplo). O empacotador enumera os modelos de acordo com o\\nparâmetro \\ntamanho\\n. Para cada tamanho, ele usa validação cruzada em \\nAprendiz\\n para calcular a taxa\\nmédia de erro sobre os conjuntos de treinamento e de teste. Começaremos com os modelos menores e\\nmais simples (que provavelmente subadaptam os dados) e fazem iteração, considerando os modelos\\nmais complexos em cada etapa, até que os modelos comecem a superadaptar. Na \\nFigura 18.9\\nobservamos curvas típicas: o erro do conjunto de treinamento diminui monotonicamente (embora, em\\ngeral, possa haver uma ligeira variação aleatória), enquanto, a princípio, o conjunto de validação de\\nerro diminui e depois aumenta quando o modelo começa a superadaptar. O procedimento de\\nvalidação cruzada pega o valor de \\ntamanho\\n com o menor erro do conjunto de validação, a parte\\ninferior da curva em forma de U. Geramos então uma hipótese desse \\ntamanho\\n usando todos os dados\\n(sem reter qualquer deles). Finalmente, é certo que devemos avaliar a hipótese retornada em um', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 822}),\n",
       " Document(page_content='conjunto de teste em separado.\\nfunção\\n VALIDAÇÃO-CRUZADA-EMPACOTADOR (\\nAprendiz, k, exemplos\\n ) \\nretorna\\n \\nhipótese\\n    \\nvariáveis locais:\\n \\nerrT\\n, uma tabela, indexada por \\ntamanho\\n, armazenamento da taxa de erro do conjunto-de-treinamento\\nerrV\\n, uma tabela, indexada por \\ntamanho\\n, armazenamento da taxa de erro do conjunto-de-validação\\n    \\npara\\n tamanho = 1 \\naté faça\\n    \\nerrT\\n[\\ntamanho\\n], \\nerrV\\n[\\ntamanho\\n] ← VALIDAÇÃO-CRUZADA(\\nAprendiz, tamanho, k, exemplos\\n)\\n    \\nse\\n \\nerrT\\n convergiu \\nentão faça\\n    \\nmelhor-tamanho\\n ← o valor do \\ntamanho\\n com \\nerrV\\n[\\ntamanho\\n] mínimo\\n    \\nretornar\\n \\nAprendi\\n (melhor_tamanho\\n, exemplos\\n)\\n_____________________________________________________________________________________________________________\\nfunção\\n VALIDAÇÃO-CRUZADA(\\nAprendiz, tamanho, k, exemplos\\n) \\nretornar\\n dois valores:\\n        taxa de erro média do conjunto-de-treinamento, taxa de erro média do conjunto-de-validação\\n    \\nerr_dobraT\\n ← 0; \\nerr_dobraV\\n ← 0\\n    \\npara\\n dobra = 1 até \\nk\\n \\nfaça\\n        \\nconjunto-de-treinamento\\n, \\nconjunto-de-validação\\n ← PARTIÇÃO (\\nexemplos, dobra, k\\n)\\n        \\nh\\n ← \\nAprendiz\\n (\\ntamanho, conjunto-de-treinamento\\n)\\n        \\nerr_dobraT\\n ← \\nerr_dobraT\\n + TAXA-ERRO(\\nh\\n, \\nconjunto-de-treinamento\\n)\\n        \\nerr_dobraV\\n ← \\nerr_dobraV\\n + TAXA-ERRO (\\nh, conjunto-de-validaçao\\n)\\n    \\nretornar\\n \\nerr_dobra T/k, err_dobraV/k\\nFigura 18.8\\n Algoritmo para selecionar o modelo que tem a menor taxa de erro em validação de\\ndados através da construção de modelos de complexidade crescente e da escolha daquele com\\nmelhor taxa empírica de erro na validação de dados. Aqui \\nerrT\\n significa taxa de erro dos dados de\\ntreinamento, e \\nerrV\\n significa taxa de erro de validação de dados. \\nAprendiz\\n(\\ntamanho, exemplos\\n)\\nretorna uma hipótese cuja complexidade é definida pelo \\ntamanho\\n do parâmetro e que é instruída\\npelos exemplos. PARTIÇÃO(\\nexemplos, dobra, k\\n) divide \\nexemplos\\n em dois subconjuntos: um\\nconjunto de validação de tamanho \\nN/k\\n e um conjunto de treinamento com todos os outros exemplos. A\\ndivisão é diferente para cada valor de \\ndobra\\n.\\nFigura 18.9\\n Taxas de erro em dados de treinamento (linha inferior, tracejada) e de validação de\\ndados (linha superior, sólida) para árvores de decisão de tamanhos diferentes. Paramos quando a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 823}),\n",
       " Document(page_content='taxa de erro do conjunto de treinamento tende a ficar assíntota e, então, escolhemos a árvore com\\nerro mínimo no conjunto de validação, nesse caso a árvore com tamanho de sete nós.\\nEssa abordagem requer que o algoritmo de aprendizagem aceite um parâmetro, \\ntamanho\\n, e\\nentregue uma hipótese desse tamanho. Como dissemos, para a aprendizagem em árvore de decisão, o\\ntamanho pode ser o número de nós. Podemos modificar o APRENDIZ- EM-ÁRVORE-DE-DECISÃO\\npara que ele pegue o número de nós como entrada, construa a árvore de busca em largura em vez de\\nem profundidade (mas em cada nível ainda escolha o atributo de maior ganho em primeiro lugar) e\\npare quando atingir o número desejado de nós.\\n18.4.2 De taxas de erro a perdas\\nAté agora, tentamos minimizar a taxa de erro. É claro que isso é melhor do que maximizar a taxa\\nde erro, mas não é toda a história. Considere o problema de classificação de mensagens de e-mail\\ncomo spam ou não spam. É pior classificar não spam como spam (e perder, portanto, uma mensagem\\nmuito importante), do que classificar spam como não spam (e, portanto, sofrer alguns segundos de\\naborrecimento). Assim, um classificador com taxa de erro de 1%, em que quase todos os erros foram\\nclassificar spam como não spam, seria melhor do que um classificador com apenas uma taxa de erro\\nde 0,5%, se a maioria desses erros fosse classificar não spam como spam. Vimos no Capítulo 16 que\\nos tomadores de decisão devem maximizar a utilidade esperada, algo que os aprendizes devem\\nmaximizar também. Em aprendizagem de máquina é tradicional expressar utilidade por meio da\\nfunção de perda\\n. A função de perda \\nL\\n(\\nx, y,\\n \\n) é definida como o montante de utilidade perdida pela\\nprevisão \\nh\\n(\\nx\\n) = \\n quando a resposta correta é \\nf\\n(\\nx\\n) = \\ny:\\nEssa é a formulação mais geral da função de perda. Muitas vezes utiliza-se uma versão\\nsimplificada, \\nL\\n(\\ny,\\n \\n), que é independente de \\nx\\n. Usaremos a versão simplificada no restante do\\ncapítulo, o que significa que não podemos dizer que seja pior classificar erroneamente a carta da mãe\\ndo que a carta de um primo chato, mas podemos dizer que é 10 vezes pior classificar não spam como\\nspam do que vice-versa:\\nL\\n(\\nspam, não spam\\n) = 1,      \\nL\\n(\\nnão spam, spam\\n) \\n=\\n 10.\\nObserve que \\nL\\n(\\ny, y\\n) é sempre zero; por definição, não há perda quando você supõe exatamente o\\ncorreto. Para funções com saídas discretas, podemos enumerar um valor de perda para cada erro de\\nclassificação possível, mas não podemos enumerar todas as possibilidades para dados com valores\\nreais. Se \\nf(x)\\n fosse 137.035999, ficaríamos bastante satisfeitos com \\nh(x)\\n = 137.036, mas o quanto\\nfelizes deveríamos estar? Em geral, pequenos erros são melhores do que grandes; duas funções que\\nimplementam essa ideia são o valor absoluto da diferença (chamado de perda \\nL\\n1\\n) e o quadrado da\\ndiferença (chamado de perda \\nL\\n2\\n). Se estivermos satisfeitos com a ideia de minimizar a taxa de erro,\\npoderemos usar a função perda \\nL\\n0/1\\n, que tem perda de 1 para uma resposta incorreta e é apropriada', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 824}),\n",
       " Document(page_content='para saídas de valores discretos:\\nO agente de aprendizagem pode, teoricamente, maximizar a sua utilidade esperada escolhendo a\\nhipótese que minimiza a perda esperada de todos os pares de entrada e saída que vai verificar. Não\\ntem sentido falar sobre essa expectativa sem definir uma distribuição de probabilidade anterior, \\nP\\n(\\nX,\\nY\\n) para os exemplos. Seja \\nε\\n o conjunto de todos os possíveis exemplos de entrada e saída. Então, a\\ngeneralização da perda\\n esperada de uma hipótese \\nh\\n (com relação à função de perda \\nL\\n) é\\ne a melhor hipótese, \\nh*\\n, é a que apresenta a mínima perda de generalização esperada:\\nComo \\nP(x, y\\n) não é conhecido, o agente de aprendizagem só pode estimar a perda de generalização\\ncom \\nperda empírica\\n sobre um conjunto de exemplos, \\nE\\n:\\nA melhor hipótese estimada \\n* é, então, a que tem a perda empírica mínima:\\nExistem quatro razões pelas quais \\n* pode ser diferente da verdadeira função \\nf\\n: impossibilidade\\nde realizar, variância, ruído e complexidade computacional. Primeiro, \\nf\\n pode não ser realizável —\\npode não estar em \\n — ou pode estar presente de tal forma que outras hipóteses sejam preferidas.\\nSegundo, um algoritmo de aprendizagem retornará hipóteses diferentes para conjuntos de exemplos\\ndiferentes, mesmo que esses conjuntos sejam extraídos da mesma função \\nf\\n verdadeira, e essas\\nhipóteses vão fazer previsões diferentes em novos exemplos. Quanto maior a variância entre as\\nprevisões, maior a probabilidade de erro significativo. Note que, mesmo quando o problema é\\nrealizável, ainda haverá variância aleatória, mas essa variância tende a zero à medida que o número\\nde exemplos de treinamento aumenta. Terceiro, \\nf\\n pode ser não determinístico ou \\nruidoso\\n — pode\\nretornar valores diferentes para \\nf(x\\n) \\na\\n cada vez que \\nx\\n ocorre. Por definição, o ruído não pode ser\\nprevisto; em muitos casos, surge porque os rótulos \\ny\\n observados são o resultado de atributos do\\nambiente que não constam em \\nx\\n. E, finalmente, quando \\n é complexo, pode ser intratável\\ncomputacionalmente para pesquisar de forma sistemática todo o espaço de hipótese. O melhor que\\npodemos fazer é uma busca local (subidas de encosta ou busca gulosa) que explora apenas uma parte\\ndo espaço. Isso nos dá um erro de aproximação. Combinando as fontes de erro, ficamos com uma\\nestimativa de aproximação da função verdadeira \\nf\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 825}),\n",
       " Document(page_content='Os métodos tradicionais em estatística e os primeiros anos de aprendizagem de máquina\\nconcentraram-se em \\naprendizagem em pequena escala\\n, em que o número de exemplos de\\ntreinamento variava de dezenas a poucos milhares. Aqui o erro de generalização em sua maioria\\nvinha do erro de aproximação de não ter o \\nf\\n verdadeiro no espaço de hipóteses e do erro de\\nestimativa de não ter exemplos suficientes de treinamento para limitar a variância. Nos últimos anos\\ntem havido mais ênfase em \\naprendizagem em larga escala\\n, muitas vezes com milhões de exemplos.\\nAqui o erro de generalização é dominado pelos limites do cálculo: há dados suficientes e um modelo\\nabundante o suficiente para podermos encontrar um \\nh\\n muito próximo do \\nf\\n verdadeiro, mas o cálculo\\npara chegar a isso é demasiado complexo; por isso, estabelecemos uma aproximação subótima.\\n18.4.3 Regularização\\nNa \\nSeção 18.4.1\\n, vimos como fazer seleção de modelo com validação cruzada sobre o tamanho do\\nmodelo. Uma abordagem alternativa é a busca de uma hipótese que minimize diretamente a soma\\nponderada da perda empírica e a complexidade da hipótese, que chamaremos de custo total:\\nAqui \\nλ\\n é um parâmetro, um número positivo que serve como taxa de conversão entre perda e\\ncomplexidade de hipótese (que, afinal, não são medidas na mesma escala). Essa abordagem combina\\nperda e complexidade em uma métrica, permitindo-nos encontrar a melhor hipótese. Infelizmente\\nainda temos de fazer busca de validação cruzada para encontrar a hipótese que generaliza melhor,\\nmas dessa vez é com valores diferentes de \\nλ\\n em vez de \\ntamanho\\n. Selecionamos o valor de \\nλ\\n que nos\\ndá a melhor pontuação do conjunto de validação.\\nO processo de penalizar explicitamente a hipótese complexa é chamado de \\nregularização\\n (porque\\nprocura por uma função que seja mais regular ou menos complexa). Observe que a função de custo\\nnos obriga a fazer duas escolhas: a função perda e a medida de complexidade, que é chamada de\\nfunção de regularização. A escolha da função de regularização depende do espaço de hipótese. Por\\nexemplo, uma função de regularização para polinômios é a soma dos quadrados dos coeficientes — a\\nmanutenção da soma pequena nos levaria para longe dos polinômios sinuosos da \\nFigura 18.1\\n(b) e\\n(c). Vamos mostrar um exemplo desse tipo de regularização na \\nSeção 18.6\\n.\\nOutra maneira de simplificar os modelos é reduzir as dimensões com as quais os modelos\\nfuncionam. Um processo de \\nseleção de atributos\\n pode ser realizado para descartar atributos que\\nparecem ser irrelevantes. A poda χ\\n2\\n é uma espécie de seleção de atributos.\\nDe fato, é possível obter perda empírica e a complexidade medida na mesma escala sem o fator de\\nconversão \\nλ\\n: ambos podem ser medidos em bits. Primeiro codifique a hipótese como um programa\\nde máquina de Turing e conte o número de bits. Em seguida, conte o número de bits necessários para\\ncodificar os dados, em que um exemplo previsto corretamente custa zero bits e o custo de um\\nexemplo previsto incorretamente depende da grandeza do erro. O \\ncomprimento de descrição\\nmínimo\\n ou hipótese CDM minimiza o número total de bits necessário. Isso funciona bem no limite,\\nmas para problemas menores há uma dificuldade pois a escolha da codificação para o programa —', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 826}),\n",
       " Document(page_content='por exemplo, qual a melhor forma de codificar uma árvore de decisão como sequência de bits —\\nafeta o resultado. No Capítulo 20, descrevemos uma interpretação probabilística da abordagem\\nCDM.\\n18.5 TEORIA DA APRENDIZAGEM\\nA principal questão sem resposta na aprendizagem é esta: como podemos ter certeza de que o\\nalgoritmo de aprendizagem produziu uma hipótese que vai prever o valor correto para as entradas\\nnão vistas anteriormente? Em termos formais, como sabemos que a hipótese \\nh\\n está próxima da\\nfunção-alvo \\nf\\n se não sabemos o que é \\nf\\n? Essas questões têm sido ponderadas por vários séculos. Em\\ndécadas mais recentes, outras questões surgiram: quantos exemplos precisamos para obter um bom\\nh\\n? Que espaço de hipótese devemos usar? Se o espaço de hipótese for muito complexo, podemos\\nainda achar o melhor \\nh\\n ou temos que nos contentar com um máximo local no espaço de hipóteses?\\nQuanto complexo deve ser \\nh\\n? Como podemos evitar a superadaptação? Esta seção examina essas\\nquestões.\\n Vamos começar com a pergunta de quantos exemplos são necessários para a aprendizagem.\\nVimos, a partir da curva de aprendizagem em árvore de decisão sobre o problema do restaurante\\n(\\nFigura 18.7\\n), que melhora com mais dados de treinamento. As curvas de aprendizagem são úteis,\\nmas específicas para determinado algoritmo de aprendizagem em um problema particular. Existem\\nalguns princípios mais genéricos que regem o número de exemplos que em geral são necessários?\\nPerguntas como essa são abordadas pela \\nteoria da aprendizagem computacional\\n, que fica no\\ncruzamento entre IA, estatística e ciência da computação teórica. O princípio subjacente é que\\nqualquer hipótese que esteja seriamente errada será quase certamente “descoberta” com alta\\nprobabilidade depois de um pequeno número de exemplos, porque vai fazer uma previsão\\nincorreta. Assim, qualquer hipótese que seja consistente com um conjunto suficientemente grande\\nde exemplos de conjunto de treinamento é improvável de estar seriamente errada, ou seja, deve\\nestar\\n \\nprovavelmente aproximadamente correta.\\n Qualquer algoritmo de aprendizagem que retorne\\nhipóteses que sejam provavelmente aproximadamente correto é chamado de algoritmo de\\naprendizagem PAC\\n; podemos usar essa abordagem para fornecer limites sobre o desempenho de\\nvários algoritmos de aprendizagem.\\nOs teoremas de aprendizagem PAC, como os demais teoremas, são consequências lógicas dos\\naxiomas. Quando um \\nteorema\\n (em oposição, digamos, a um comentarista político) afirma algo sobre\\no futuro com base no passado, os axiomas têm de fornecer a “energia” para fazer essa ligação. Para a\\naprendizagem PAC, a ligação é fornecida pelo pressuposto de estacionariedade já introduzido, que\\ndiz que exemplos futuros vão ser retirados da mesma distribuição fixa \\nP\\n(\\nE\\n) \\n=\\n \\nP\\n(\\nX, Y\\n) como os\\nexemplos passados (observe que não temos de saber que distribuição é, apenas que ela não muda).\\nAlém disso, para manter as coisas simples, vamos supor que a função verdadeira \\nf\\n seja\\ndeterminística e membro da classe de hipótese \\n que está sendo considerada.\\nOs teoremas PAC mais simples lidam com funções booleanas, para as quais a perda 0/1 é\\napropriada. A \\ntaxa de erro\\n de uma hipótese \\nh\\n, definida antes informalmente; aqui é definida\\nformalmente como o erro de generalização esperado para exemplos tirados da distribuição', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 827}),\n",
       " Document(page_content='estacionária:\\nEm outras palavras, o erro (\\nh\\n) é a probabilidade de que \\nh\\n classifique incorretamente um novo\\nexemplo. Essa é a mesma quantidade que estava sendo medida experimentalmente pelas curvas de\\naprendizagem mostradas anteriormente.\\nA hipótese \\nh\\n é chamada de \\naproximadamente correta\\n se o erro (\\nh\\n) ≤ \\n∊\\n onde \\n∊\\n é uma constante\\npequena. Vamos mostrar que podemos encontrar \\nN\\n tal que, depois de verificar \\nN\\n exemplos, com\\nprobabilidade alta, todas as hipóteses consistentes serão aproximadamente corretas. Pode-se pensar\\nem uma hipótese aproximadamente correta como sendo “próxima” à função verdadeira no espaço de\\nhipótese: repousa sobre o que é chamado \\n∊\\n-\\nbola\\n em torno da verdadeira função \\nf\\n. O espaço de\\nhipótese fora dessa esfera é chamado \\nruim\\n.\\nPodemos calcular a probabilidade de que uma hipótese “seriamente errada” \\nh\\nr\\n \\n∊\\n \\nruim\\n seja\\nconsistente com os primeiros \\nN\\n exemplos, como segue. Sabemos que o erro (\\nh\\nr\\n) > \\n∊\\n. Assim, a\\nprobabilidade de que esteja de acordo com um exemplo dado é no máximo 1 − \\n∊\\n. Uma vez que os\\nexemplos são independentes, o limite para \\nN\\n exemplos é\\nA probabilidade de que \\nruim\\n contenha pelo menos uma hipótese consistente é limitada pela soma\\ndas probabilidades individuais:\\nP(\\nruim\\n contém uma hipótese consistente) ≤ |\\nruim\\n|(1 – \\n∊\\n)\\nN\\n ≤ |\\n|(1 – \\n∊\\n)\\nN\\n, onde usamos o fato de que\\n|\\nruim\\n| ≤ |\\n|. Gostaríamos de reduzir a probabilidade desse evento abaixo de algum número pequeno\\nδ\\n:\\nDado que \\n, podemos conseguir isso se permitirmos que o algoritmo verifique\\nexemplos. Assim, se um algoritmo de aprendizagem retornar uma hipótese que seja consistente com\\nessa quantidade de exemplos, com probabilidade de pelo menos 1 − \\nδ\\n existe erro de, no máximo, \\n∊\\n.\\nEm outras palavras, provavelmente é aproximadamente correto. O número de exemplos necessários,\\nem função de \\n∊\\n e \\nδ\\n, é chamado de \\ncomplexidade da amostra\\n do espaço de hipótese.\\nComo vimos anteriormente, se \\n for o conjunto de todas as funções booleanas sobre \\nn\\n atributos,\\nentão |\\n| = \\n. Assim, a complexidade da amostra do espaço cresce 2\\nn\\n. Como o número de\\nexemplos possíveis também é 2\\nn\\n, isso sugere que a aprendizagem PAC na classe de todas as funções\\nbooleanas requer verificação de todos ou quase todos os exemplos possíveis. Pensando rapidamente\\nsabemos a razão para isso: \\n contém hipóteses suficientes para classificar qualquer conjunto de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 828}),\n",
       " Document(page_content='exemplos dados de todas as maneiras possíveis. Em particular, para qualquer conjunto de \\nN\\nexemplos, o conjunto de hipóteses consistentes com esses exemplos contém números iguais de\\nhipóteses que predizem que \\nx\\nN+1\\n seja positivo e de hipóteses que predizem que \\nx\\nN+1\\n seja negativo.\\nEntão, para obter a generalização real de exemplos não vistos, parece que precisamos restringir o\\nespaço de hipótese \\n de alguma forma, mas é claro que, se restringirmos o espaço, também\\npoderemos eliminar a função verdadeira. Há três maneiras de fugir desse dilema. A primeira, a qual\\nserá abordada no Capítulo 19, é trazer o conhecimento prévio para apoiar o problema. A segunda,\\nque introduzimos na \\nSeção 18.4.3\\n, é insistir que o algoritmo retorne não apenas qualquer hipótese\\nconsistente, mas de preferência uma simples (como é feito em aprendizagem em árvore de decisão).\\nNos casos em que é tratável encontrar hipóteses consistentes simples, os resultados da complexidade\\nda amostra são geralmente melhores do que os da análise com base apenas na consistência. A\\nterceira maneira, que veremos a seguir, é concentrar-se em subconjuntos aprendíveis do espaço de\\nhipótese inteiro de funções booleanas. Essa abordagem se fundamenta no pressuposto de que a\\nlinguagem restrita contém uma hipótese \\nh\\n que está perto o suficiente da função verdadeira \\nf\\n; os\\nbenefícios são que o espaço de hipótese restrito permite a generalização eficaz e geralmente é mais\\nfácil de buscar. Examinaremos agora com mais detalhes essa linguagem restrita.\\n18.5.1 Exemplo de aprendizagem PAC: aprendizagem de listas de decisão\\nVamos agora mostrar como aplicar a aprendizagem PAC para um espaço de hipótese novo: \\nlistas\\nde decisão\\n. Uma lista de decisão consiste em uma série de testes, cada um dos quais é uma\\nconjunção de literais. Se um teste for bem-sucedido quando aplicado a uma descrição do exemplo, a\\nlista de decisão especificará o valor a ser retornado. Se o teste falhar, o processamento continua com\\no próximo teste na lista. As listas de decisão se assemelham às árvores de decisão, mas a sua\\nestrutura geral é mais simples: elas se ramificam apenas em uma direção. Em contraste, os testes\\nindividuais são mais complexos. A \\nFigura 18.10\\n mostra uma lista de decisão que representa a\\nhipótese a seguir:\\nFigura 18.10\\n Lista de decisão para o problema do restaurante.\\nVaiEsperar\\n \\n⇔\\n (\\nClientes = Alguns)\\n \\n∨\\n \\n(Clientess = Cheio\\n \\n∧\\n \\nSex/Sáb).\\nSe permitirmos testes de tamanho arbitrário, as listas de decisão podem representar qualquer\\nfunção booleana (Exercício 18.14). Por outro lado, se restringirmos o tamanho de cada teste para no\\nmáximo \\nk\\n literais, é possível para o algoritmo de aprendizagem generalizar com sucesso um pequeno\\nnúmero de exemplos. Chamamos essa linguagem de \\nk\\n-\\nDL\\n. O exemplo da \\nFigura 18.10\\n está em 2-DL.\\nÉ fácil mostrar (Exercício 18.14) que \\nk\\n-DL inclui como subconjunto a linguagem \\nk\\n-\\nDT\\n, o conjunto de\\ntodas as árvores de decisão de profundidade, no máximo, \\nk\\n. É importante lembrar que a linguagem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 829}),\n",
       " Document(page_content='particular a que se refere o \\nk\\n-DL depende dos atributos utilizados para descrever os exemplos.\\nUsaremos a notação \\nk\\n-DL(\\nn\\n) para indicar uma linguagem \\nk-\\nDL usando \\nn\\n atributos booleanos.\\nA primeira tarefa é mostrar que \\nk\\n-DL é aprendível, ou seja, que qualquer função em \\nk\\n-DL pode ser\\naproximada com precisão após o treinamento com um número razoável de exemplos. Para fazer isso,\\nprecisamos calcular o número de hipóteses na linguagem. Seja a linguagem de testes — conjunções\\nde, no máximo, \\nk\\n literais usando \\nn\\n atributos — \\nConj\\n(\\nn, k\\n). Como uma lista de decisão é constituída\\npor testes, e cada teste pode estar ligado a um resultado \\nSim ou Não\\n ou pode estar ausente da lista de\\ndecisão, há no máximo 3\\n|\\nConj\\n \\n(\\nn\\n,\\nk\\n)|\\n conjuntos distintos de testes de componente. Cada um desses\\nconjuntos de testes pode estar em qualquer ordem, de modo que\\nO número de conjunções de \\nk\\n literais de \\nn\\n atributos é dado por\\nAssim, após algum trabalho, obtemos\\nPodemos ligá-la à Equação 18.1 para mostrar que o número de exemplos necessários para a\\naprendizagem PAC em uma função \\nk\\n-DL é polinomial em \\nn\\n:\\nPortanto, qualquer algoritmo que retorne uma lista de decisão consistente vai PAC-aprender uma\\nfunção \\nk\\n-DL em um número razoável de exemplos, para pequenos \\nk\\n.\\nA próxima tarefa é encontrar um algoritmo eficiente que retorne uma lista de decisão consistente.\\nUsaremos um algoritmo guloso chamado APRENDIZAGEM-EM-LISTA-DE-DECISÃO que\\nrepetidamente encontra um teste que concorda exatamente com um subconjunto do conjunto de\\ntreinamento. Uma vez que ele encontra um teste desse tipo, adiciona-o à lista de decisão em\\nconstrução e remove os exemplos correspondentes. Constrói, então, o restante da lista de decisão\\nutilizando apenas os exemplos restantes. Repete-se até que não haja mais exemplos. O algoritmo é\\nmostrado na \\nFigura 18.11\\n.\\nfunção\\n APRENDIZAGEM-LISTA-DE-DECISÃO (\\nexemplos\\n) \\nretorna\\n uma lista de decisão ou\\nfalha\\n    \\nse\\n \\nexemplos\\n é vazio \\nentão retornar\\n lista de decisão comum \\nNão\\n    \\nt\\n ← um teste que combina um subconjunto não vazio de \\nexemplos\\nt\\n de \\nexemplos\\n        tal que os membros de \\nexemplos\\nt\\n são todos positivos ou negativos\\n    \\nse\\n não houver tal \\nt\\n \\nentão retornar\\n \\nfalha', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 830}),\n",
       " Document(page_content='se\\n exemplos em \\nexemplos\\nt\\n é positivo \\nentão\\n \\no\\n ← \\nSim\\n \\nsenão\\n \\no\\n ← \\nNão\\n    \\nretornar\\n uma lista de decisão com o teste \\nt\\n inicial e o resultado \\no\\n e os testes restantes dados\\npor\\n        APRENDIZAGEM- EM- LISTA-DE-DECISÃO(\\nexemplos\\n — \\nexemplos\\nt\\n)\\nFigura 18.11\\n Algoritmo de aprendizagem em lista de decisão.\\nEsse algoritmo não especifica o método para selecionar o próximo teste para adicionar à lista de\\ndecisão. Embora os resultados formais dados anteriormente não dependam do método de seleção,\\nparece razoável preferir pequenos testes que correspondam a grandes conjuntos de exemplos\\nclassificados de forma uniforme, de modo que a lista de decisão global seja a mais compacta\\npossível. A estratégia mais simples é encontrar o menor teste \\nt\\n que combine com qualquer\\nsubconjunto uniformemente classificado, independentemente do tamanho do subconjunto. Essa\\nabordagem também funciona muito bem, como a \\nFigura 18.12\\n sugere.\\nFigura 18.12\\n Curva de aprendizagem para o algoritmo APRENDIZAGEM-EM -LISTA-DE-\\nDECISÃO sobre os dados do restaurante. A curva de aprendizagem para a APRENDIZAGEM-EM-\\nÁRVODE-DE-DECISÃO é mostrada para comparação.\\n18.6 REGRESSÃO E CLASSIFICAÇÃO COM MODELOS LINEARES\\nAgora é hora de passar de árvores de decisão e de listas para um espaço de hipótese diferente, que\\ntem sido utilizado durante centenas de anos: a classe de \\nfunções lineares\\n de entradas de valor\\ncontínuo.\\nVamos começar com o caso mais simples: regressão com uma função linear univariada, também\\nconhecida como “adaptação de uma linha reta”. A \\nSeção 18.6.2\\n abrange o caso multivariado. As\\nSeções 18.6.3 e 18.6.4 mostram como transformar funções lineares em classificadores aplicando\\nlimiares duros e suaves.\\n18.6.1 Regressão linear univariada', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 831}),\n",
       " Document(page_content='Uma função linear univariada (linha reta), com entrada \\nx\\n e saída \\ny\\n tem a forma \\ny = w\\n1\\nx + w\\n0\\n, onde\\nw\\n0\\n e \\nw\\n1\\n são coeficientes de valores reais a serem aprendidos. Usamos a letra \\nw\\n porque imaginamos\\nos coeficientes como \\npesos;\\n o valor de \\ny\\n é alterado pela mudança do peso relativo de um termo para\\noutro. Definimos \\nw\\n como o vetor [\\nw\\n0\\n, \\nw\\n1\\n] e definimos\\nh\\nw\\n(\\nx\\n) = \\nw\\n1\\nx + w\\n0\\n.\\nA \\nFigura 18.13\\n(a) mostra um exemplo de conjunto de treinamento de \\nn\\n pontos no plano \\nx\\n, \\ny\\n, cada\\nponto representando o tamanho em metros quadrados e o preço de uma casa à venda. A tarefa de\\nencontrar o \\nh\\nw\\n que melhor se encaixe nesses dados é chamada de \\nregressão linear\\n. Para ajustar uma\\nlinha com os dados, tudo o que temos a fazer é encontrar os valores dos pesos [\\nw\\n0\\n, w\\n1\\n] que\\nminimizam a perda empírica. É tradicional (voltando a Gauss\\n3\\n) usar a função de perda quadrática,\\nL\\n2\\n, a soma de todos os exemplos de treinamento:\\nGostaríamos de encontrar \\nw\\n* = argmin\\nw\\n \\nPerda\\n(\\nh\\nw\\n). A soma \\n é minimizada\\nquando suas derivadas parciais em relação a \\nw\\n0\\n e \\nw\\n1\\n são zero:\\nFigura 18.13\\n (a) Pontos de dados de preço \\nversus\\n espaço dos imóveis em área para venda em\\nBerkeley, CA, em julho de 2009, junto com a hipótese de função linear que minimiza o erro de perda\\nao quadrado: \\ny\\n = 0,232\\nx\\n + 246. (b) Representação gráfica da função perda \\n para\\ndiversos valores de \\nw\\n0\\n e \\nw\\n1\\n. Observe que a função perda é convexa, com um único mínimo global.\\nEssas equações têm solução única:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 832}),\n",
       " Document(page_content='Para o exemplo na \\nFigura 18.13\\n(a), a solução é \\nw\\n1\\n = 0,232, \\nw\\n0\\n = 246, e a linha com os pesos é\\nmostrada na figura como uma linha tracejada.\\nMuitas formas de aprendizagem envolvem o ajuste de pesos para minimizar a perda, por isso ajuda\\nter uma imagem mental do que está acontecendo no \\nespaço de peso\\n — o espaço definido por todas\\nas configurações de pesos possíveis. Para a regressão linear univariada, o espaço definido por \\nw\\n0\\n e\\nw\\n1\\n é bidimensional, para que possamos colocar em gráfico a perda em função de \\nw\\n0\\n e \\nw\\n1\\n em um\\nplano 3-D (veja a \\nFigura 18.13\\n(b)). Observamos que a função perda é \\nconvexa\\n, conforme definido\\nanteriormente; isso é verdade para \\ncada\\n problema de regressão linear com uma função de perda \\nL\\n2\\n, e\\nimplica que não há mínimo local. Em certo sentido, esse é o fim da história para os modelos lineares;\\nse precisarmos ajustar linhas aos dados, aplicamos a Equação 18.3.\\n4\\nPara ir além dos modelos lineares, teremos que encarar o fato de que as equações que definem a\\nperda mínima (como a Equação 18.2), muitas vezes, não têm solução de forma fechada. Em vez\\ndisso, se tem de enfrentar um problema de busca de otimização geral em um espaço de peso contínuo.\\nComo indicado na \\nSeção 4.2\\n, tais problemas podem ser resolvidos por um algoritmo de subida de\\nencosta, que segue o \\ngradiente\\n da função a ser otimizada. Nesse caso, como estamos tentando\\nminimizar a perda, usaremos a \\ndescida pelo gradiente\\n. Escolhemos qualquer ponto de partida em\\nespaço de peso — aqui, um ponto no plano (\\nw\\n0\\n, \\nw\\n1\\n) — e em seguida movemos para um ponto vizinho\\nque está em declive, repetindo até que convirja para a mínima perda possível:\\nO parâmetro, que chamamos de \\ntamanho do passo\\n na \\nSeção 4.2\\n, é geralmente chamado de \\ntaxa de\\naprendizagem\\n quando estamos tentando minimizar a perda em um problema de aprendizagem. Pode\\nser uma constante fixa ou pode decair ao longo do tempo à medida que o processo de aprendizagem\\nprossegue.\\nPara a regressão univariada, a função de perda é uma função quadrática, então a derivada parcial\\nserá uma função linear. (O único cálculo que é necessário saber é \\n e \\n). Primeiro vamos\\ncalcular as derivadas parciais — as inclinações — no caso simplificado de apenas um exemplo de\\ntreinamento, (\\nx\\n, \\ny\\n):\\naplicando para \\nw\\n0\\n e \\nw\\n1\\n obtemos:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 833}),\n",
       " Document(page_content='Então, ligando de volta na Equação 18.4 e incorporando 2 em uma taxa de aprendizagem não\\nespecificada, temos a seguinte regra de aprendizagem para os pesos:\\nEssas atualizações fazem sentido intuitivo: se \\nh\\nw\\n (x)> y, ou seja, a saída da hipótese for muito\\ngrande, reduza um pouco \\nw\\n0\\n e reduza \\nw\\n1\\n se \\nx\\n for uma entrada positiva mas aumente \\nw\\n1\\n se \\nx\\n for uma\\nentrada negativa.\\nAs equações anteriores abrangem um exemplo de treinamento. Para \\nN\\n exemplos de treinamento,\\nqueremos minimizar a soma das perdas individuais para cada exemplo. A derivada de uma soma é a\\nsoma das derivadas, por isso temos:\\nEssas atualizações constituem a regra de aprendizagem da \\ndescida pelo gradiente em lotes\\n para\\nregressão linear univariada. A convergência é garantida para o único mínimo global (contanto que\\nescolhamos um pequeno o suficiente), mas pode ser muito lenta: temos de percorrer todos os dados\\nde treinamento para cada etapa, e pode haver muitas etapas.\\nExiste outra possibilidade, chamada de \\ndescida estocástica pelo gradiente\\n, onde consideramos\\num único ponto de treinamento por vez, seguindo uma etapa após a outra, usando a Equação 18.5. A\\ndescida estocástica pelo gradiente pode ser usada em um ambiente on-line, onde chegam novos\\ndados, um de cada vez, ou off-line, onde percorremos os mesmos dados tantas vezes quantas forem\\nnecessárias, selecionando uma etapa depois de considerar cada exemplo. Muitas vezes é mais rápido\\ndo que a descida pelo gradiente em lotes. Uma taxa de aprendizagem fixa, no entanto, não garante a\\nconvergência, podendo oscilar em torno do mínimo, sem se fixar. Em alguns casos, como veremos\\nmais adiante, planejar um cronograma de taxas de aprendizagem descendente (como em recozimento\\nsimulado) garante a convergência.\\n18.6.2 Regressão linear multivariada\\nPodemos facilmente estender para problemas de regressão linear multivariada, em que cada\\nexemplo \\nx\\nj\\n é um vetor de \\nn\\n elementos.\\n5\\n Nosso espaço de hipótese é o conjunto de funções da forma\\nO termo \\nw\\n0\\n, a interseção, distingue-se como diferente dos outros. Podemos corrigir isso pela\\ncriação de um atributo de entrada fictício, \\nx\\nj\\n,0\\n, que sempre é definido como igual a 1. Então, \\nh\\n é', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 834}),\n",
       " Document(page_content='simplesmente o produto escalar dos pesos e do vetor de entrada (ou, de forma equivalente, o produto\\nda matriz transposta dos pesos pelo vetor de entrada):\\nO melhor vetor de pesos, \\nw\\n*, minimiza a perda de erro quadrático nos exemplos:\\nA regressão linear multivariada não é muito mais complicada do que o caso univariado já\\nabrangido. A descida pelo gradiente vai atingir o mínimo (único) da função de perda; a equação de\\natualização de cada peso \\nw\\ni\\n é\\nTambém é possível resolver analiticamente para o \\nw\\n que minimiza a perda. Seja \\ny\\n o vetor de\\nsaída para os exemplos de treinamento e \\nX\\n a \\nmatriz de dados\\n, ou seja, a matriz de entradas com um\\nexemplo \\nn\\n dimensional por linha. Então, a solução\\nminimiza o erro quadrático.\\nCom a regressão linear univariada não precisamos nos preocupar com a superadaptação. Mas,\\ncom a regressão linear multivariada em espaços de dimensão superior, é possível que alguma\\ndimensão que seja realmente irrelevante pareça ser útil por acaso, resultando em \\nsuperadaptação\\n.\\nAssim, é comum o uso de \\nregularização\\n em funções lineares multivariadas para evitar a\\nsuperadaptação. Lembre-se de que, com a regularização, minimizamos o custo total de uma hipótese,\\ncontando tanto com a perda empírica como com a complexidade da hipótese:\\nCusto\\n(\\nh\\n) = \\nPerdaEmp\\n(\\nh\\n) + λ \\nComplexidade\\n(\\nh\\n).\\nPara as funções lineares, a complexidade pode ser especificada em função dos pesos. Podemos\\nconsiderar uma família de funções de regularização:\\nTal como acontece com as funções de perda\\n6\\n com \\nθ\\n = 1 temos a regularização \\nL\\n1\\n, o que minimiza a\\nsoma dos valores absolutos; com \\nθ\\n = 2, a regularização \\nL\\n2\\n minimiza a soma dos quadrados. Qual\\nfunção de regularização se deve escolher? Isso depende do problema específico, mas a regularização\\nL\\n1\\n tem uma vantagem importante: tende a produzir um \\nmodelo esparso\\n. Isto é, muitas vezes define', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 835}),\n",
       " Document(page_content='muitos pesos para zero, declarando efetivamente os atributos correspondentes como irrelevantes —\\ncomo a APRENDIZAGEM-EM-ÁRVORE-DE-DECISÃO faz (embora por um mecanismo diferente).\\nAs hipóteses que descartam atributos podem ser mais fáceis de um ser humano entender, e podem ser\\nmenos prováveis de superadaptar.\\nA \\nFigura 18.14\\n fornece uma explicação intuitiva da razão pela qual a regularização \\nL\\n1\\n leva a\\npesos zero, enquanto a regularização \\nL\\n2\\n não leva. Observe que a minimização \\nPerdas(\\nw\\n) +\\n \\nλ\\nComplexidade(\\nw\\n)\\n é equivalente à minimização \\nPerda\\n(\\nw\\n) sujeita à restrição de que\\nComplexidade\\n(\\nw\\n) ≤ \\nc\\n, para alguma constante \\nc\\n que esteja relacionada com \\nλ.\\n Agora, na \\nFigura\\n18.14\\n(a) a caixa em forma de diamante representa o conjunto de pontos \\nw\\n no espaço de peso\\nbidimensional que tem a complexidade \\nL\\n1\\n menor que \\nc\\n; nossa solução terá de estar em algum lugar\\ndentro dessa caixa. As ovais concêntricas representam contornos da função de perda, com a perda\\nmínima ao centro. Queremos encontrar o ponto na caixa que esteja mais próximo ao mínimo; você\\npode observar no diagrama que, para uma posição arbitrária de mínimo e seus contornos, será\\ncomum para o canto da caixa encontrar sua forma mais próxima ao mínimo só porque os cantos são\\npontudos. E, claro, os cantos são os pontos que têm valor de zero em alguma dimensão. Na \\nFigura\\n18.14\\n(b), fizemos o mesmo para a medida de complexidade \\nL\\n2\\n, que representa um círculo, em vez de\\num diamante. Aqui você pode verificar que, em geral, não há razão para a interseção aparecer em um\\ndos eixos; assim, a regularização \\nL\\n2\\n não tende a produzir pesos zero. O resultado é que o número de\\nexemplos necessários para encontrar um bom \\nh\\n é linear no número de características irrelevantes\\npara a regularização \\nL\\n2\\n, mas somente com a regularização logarítmica \\nL\\n1\\n. A evidência empírica de\\nmuitos problemas reforça essa análise.\\nFigura 18.14\\n Por que a regularização de \\nL\\n1\\n tende a produzir um modelo esparso. (a) Com a\\nregularização (caixa) de \\nL\\n1\\n, a perda mínima atingível (contornos concêntricos), muitas vezes, ocorre\\nem um eixo, o que significa peso zero. (b) Com a regularização \\nL\\n2\\n (círculo), é provável que a perda\\nmínima ocorra em qualquer parte do círculo, não dando preferência a pesos zero.\\nOutra maneira de ver isso é que a regularização \\nL\\n1\\n leva os eixos dimensionais a sério, enquanto a\\nL\\n2\\n trata-os como arbitrários. A função de \\nL\\n2\\n é esférica, o que a torna rotacionalmente invariante:\\nimagine um conjunto de pontos em um plano, medido por suas coordenadas \\nx\\n e \\ny\\n. Agora imagine a\\nrotação de 45º dos eixos. Você gostaria de obter um conjunto de valores diferentes de (x′, y′)\\nrepresentando os mesmos pontos. Se aplicar a regularização \\nL\\n2\\n antes e depois da rotação, terá', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 836}),\n",
       " Document(page_content='exatamente o mesmo ponto como resposta (embora o ponto seja descrito com a nova coordenada (x’,\\ny’)). Isso é apropriado quando a escolha dos eixos realmente for arbitrária — quando não importar\\nse as suas duas dimensões são as distâncias norte e leste ou nordeste e sudeste. Com a regularização\\nL\\n1\\n obtém-se uma resposta diferente porque a função \\nL\\n1\\n não é rotacionalmente invariante. Isso é\\napropriado quando os eixos não são intercambiáveis, mas não faz sentido rodar o “número de\\nbanheiros” 45º para o “tamanho do lote”.\\n18.6.3 Classificadores lineares com limiar rígido\\nAs funções lineares podem ser usadas tanto para fazer a classificação como a regressão. Por\\nexemplo, a \\nFigura 18.15\\n(a) mostra os pontos de dados de duas classes: os terremotos (que são de\\ninteresse para os sismólogos) e as explosões subterrâneas (que são de interesse dos especialistas em\\ncontrole de armas). Cada ponto é definido por dois valores de entrada, \\nx\\n1\\n e \\nx\\n2\\n, que se referem a\\nmagnitudes de onda do corpo e da superfície, calculados a partir do sinal sísmico. Tendo em conta\\nesses dados de treinamento, a tarefa de classificação é aprender uma hipótese \\nh\\n, que terá novos (\\nx\\n1\\n,\\nx\\n2\\n) pontos e retornará 0 para terremotos ou 1 para explosões.\\nFigura 18.15\\n (a) Representação gráfica de dois parâmetros de dados sísmicos, a magnitude do corpo\\nda onda \\nx\\n1\\n e a magnitude do corpo da superfície \\nx\\n2\\n, para terremotos (círculos brancos) e explosões\\nnucleares (círculos pretos) ocorridos entre 1982 e 1990 na Ásia e no Oriente Médio (Kebeasy \\net al\\n.,\\n1998). Também é mostrado um limite de decisão entre as classes. (b) O mesmo domínio com mais\\npontos de dados. Os terremotos e explosões já não são mais linearmente separáveis.\\nA \\nfronteira de decisão\\n é uma linha (ou uma superfície, em dimensões superiores) que separa as\\nduas classes. Na \\nFigura 18.15\\n(a), a fronteira de decisão é uma linha reta. O limite da decisão linear é\\nchamado de \\nseparador linear\\n e os dados que admitem tal separador são chamados de \\nlinearmente\\nseparáveis\\n. O separador linear, nesse caso, é definido por\\nx\\n2\\n = 1,7\\nx\\n1\\n − 4.9 ou − 4,9 + 1,7\\nx\\n1\\n − \\nx\\n2\\n = 0.\\nAs explosões, que queremos classificar com valor 1, estão à direita dessa linha com valores\\nmaiores de \\nx\\n1\\n e valores menores de \\nx\\n2\\n; então eles são pontos para os quais −4,9 + 1,7\\nx\\n1\\n − \\nx\\n2\\n > 0,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 837}),\n",
       " Document(page_content='enquanto os terremotos têm −4,9 + 1,7\\nx\\n1\\n − \\nx\\n2\\n < 0. Usando a convenção de entrada fictícia \\nx\\n0\\n = 1,\\npodemos escrever a hipótese de classificação como\\nh\\nw\\n(\\nx\\n) = 1 se \\nw\\n · \\nx\\n ≥ 0 e 0 caso contrário.\\nAlternativamente, podemos pensar em \\nh\\n como o resultado de passar a função linear \\nw · x\\n através\\nde uma \\nfunção de limiar\\n:\\nh\\nw\\n(\\nx\\n) = \\nLimiar\\n(\\nw · x\\n), onde \\nLimiar\\n(\\nz\\n) = 1 se \\nz\\n ≥ 0 e 0 caso contrário.\\nA função de limiar é mostrada na \\nFigura 18.17\\n(a).\\nAgora que a hipótese \\nh\\nw\\n(\\nx\\n) tem forma matemática bem definida, podemos pensar em escolher os\\npesos \\nw\\n para minimizar a perda. Nas Seções 18.6.1 e 18.6.2, fizemos isso de forma fechada\\n(definindo o gradiente como zero e resolvendo para os pesos) e por gradiente de descida no espaço\\nde peso. Aqui não podemos fazer nenhuma dessas coisas porque o gradiente é zero em quase todo o\\nespaço de peso, exceto nos pontos em que \\nw · x\\n = 0 e naqueles pontos em que o gradiente é\\nindefinido.\\nHá, no entanto, uma regra simples de atualização de peso que converge para uma solução, isto é,\\num separador linear que classifica os dados perfeitamente desde que os dados sejam linearmente\\nseparáveis. Para um único exemplo (\\nx\\n, \\ny\\n), temos\\nque é essencialmente idêntico à Equação 18.6, a regra de atualização para a regressão linear! Essa\\nregra é chamada de \\nregra de aprendizagem perceptron\\n, por razões que serão esclarecidas na \\nSeção\\n18.7\\n. Como estamos considerando um problema de classificação 0/1, no entanto, o comportamento é\\num pouco diferente. Tanto o valor verdadeiro \\ny\\n como a hipótese de saída \\nh\\nw\\n(\\nx\\n) são 0 ou 1, por isso\\nhá três possibilidades:\\n•  Se a saída está correta, ou seja, y = \\nh\\nw\\n(\\nx\\n), os pesos não são alterados.\\n•  Se \\ny\\n for 1, mas \\nh\\nw\\n(\\nx\\n) for 0, \\nw\\ni\\n será \\naumentado\\n quando a entrada correspondente \\nx\\ni\\n for positiva e\\ndiminuído quando \\nx\\ni\\n for negativo. Isso faz sentido porque queremos fazer \\nw · x\\n maior para que\\nh\\nw\\n(\\nx\\n) gere um 1.\\n•  Se \\ny\\n for 0, mas \\nh\\nw\\n(\\nx\\n) for 1, \\nw\\ni\\n será diminuído quando a entrada correspondente \\nx\\ni\\n for positiva e\\naumentado quando \\nx\\ni\\n for negativo. Isso faz sentido porque queremos fazer \\nw · x\\n menor para que\\nh\\nw\\n(\\nx\\n) gere um 0.\\nNormalmente, a regra de aprendizagem é aplicada em um exemplo de cada vez, escolhendo\\nexemplos ao acaso (como no gradiente estocástico de descida). A \\nFigura 18.16\\n(a) mostra uma \\ncurva\\nde treinamento\\n para essa regra de aprendizagem aplicada aos dados do terremoto/explosão\\nmostrados na \\nFigura 18.15\\n(a). A curva de treinamento mede o desempenho do classificador em um\\nconjunto de treinamento fixo à medida que o processo de aprendizagem prossegue naquele mesmo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 838}),\n",
       " Document(page_content='conjunto de treinamento. A curva mostra a regra de atualização convergindo para um separador linear\\nde erro zero. O processo de “convergência” não é exatamente belo, mas sempre funciona. Essa\\nexecução particular leva 657 etapas para convergir para um conjunto de dados com 63 exemplos, de\\nmodo que cada exemplo seja apresentado cerca de 10 vezes, em média. É previsível que a variação\\nentre as execuções seja muito grande.\\nFigura 18.16\\n (a) Representação gráfica da precisão do conjunto de treinamento total \\nversus\\n o\\nnúmero de iterações através do conjunto de treinamento para a regra de aprendizagem perceptron,\\ncom base nos dados do terremoto/explosão da \\nFigura 18.15\\n(a). (b) A mesma representação gráfica\\npara os dados não separáveis, ruidosos da \\nFigura 18.15\\n(b); observe a mudança na escala do eixo \\nx\\n.\\n(C) A mesma representação gráfica como em (b), com uma programação de taxa de aprendizagem (\\nt\\n)\\n= 1000/(1000 + \\nt\\n).\\nFigura 18.17\\n (a) A função de limiar rígido \\nLimiar\\n(\\nz\\n) com saída 0/1. Observe que a função é não\\ndiferençável em \\nz\\n = 0. (b) A função logística, \\nLogística\\n(\\nz\\n) = \\n é também conhecida como função\\nsigmoide. (c) Representação gráfica de uma hipótese de regressão logística \\nh\\nw\\n(\\nx\\n) = \\nLogística\\n(\\nw · x\\n)\\npara os dados mostrados na \\nFigura 18.15\\n(b).\\nDissemos que a regra de aprendizagem do perceptron converge para um separador linear perfeito\\nquando os pontos de dados são linearmente separáveis, mas, e se não forem? Essa situação é muito\\ncomum no mundo real. Por exemplo, a \\nFigura 18.15\\n(b) adiciona de volta os pontos de dados\\nomitidos por Kebeasy \\net al\\n. (1998) quando eles marcaram os dados mostrados na \\nFigura 18.15\\n(a).\\nNa \\nFigura 18.16\\n(b), mostramos que a regra de aprendizagem perceptron não conseguiu convergir,\\nmesmo depois de 10 mil etapas: mesmo que ela atinja a solução de erro mínimo (três erros), muitas\\nvezes o algoritmo continuará mudando os pesos. Em geral, a regra perceptron não pode convergir\\npara uma solução estável para a taxa de aprendizagem fixada a, mas se decai para \\nO\\n(1/\\nt\\n) onde \\nt\\n é o\\nnúmero de iteração, a regra pode ser mostrada para convergir para uma solução de erro mínimo\\nquando os exemplos forem apresentados em uma sequência aleatória.\\n7\\n Também se pode mostrar que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 839}),\n",
       " Document(page_content='encontrar a solução mínima de erros é NP-difícil, por isso espera-se que muitas apresentações de\\nexemplos sejam necessárias para que a convergência seja alcançada. A \\nFigura 18.16\\n(b) mostra o\\nprocesso de treinamento com uma programação de taxa de aprendizagem \\nα\\n (t) = 1000/(1000 + \\nt\\n): a\\nconvergência não é perfeita depois de 100.000 iterações, mas é muito melhor do que o caso fixo α.\\n18.6.4 Classificação linear com regressão logística\\nVimos que passar a saída de uma função linear através da função de limiar cria um classificador\\nlinear; também a natureza rígida do limiar causa alguns problemas: a hipótese \\nh\\nw\\n(\\nx\\n) não é\\ndiferenciável, e é na verdade fato uma função descontínua de suas entradas e seus pesos, o que torna\\na aprendizagem com a regra perceptron uma aventura muito imprevisível. Além disso, o classificador\\nlinear sempre anuncia uma previsão completamente confiante de 1 ou 0, mesmo para exemplos que\\nestão muito perto da fronteira; em muitas situações, precisamos realmente de previsões mais\\ngraduais.\\nTodos esses problemas podem ser resolvidos em grande medida suavizando a função de limiar,\\naproximando o limiar rígido com uma função contínua, diferenciável. No Capítulo 14, vimos duas\\nfunções que parecem limiares suaves: integral de distribuição normal padrão (usada para o modelo\\nprobit) e a função logística (usada para o modelo logit). Embora as duas funções tenham forma muito\\nsemelhante, a função logística\\ntem mais propriedades matemáticas convenientes. A função é mostrada na \\nFigura 18.17\\n(b). Com a\\nfunção logística substituindo a função de limiar, agora temos\\nUm exemplo de tal hipótese para o problema de duas entradas terremoto/explosão é mostrado na\\nFigura 18.17\\n(c). Observe que a saída, sendo um número entre 0 e 1, pode ser interpretada como uma\\nprobabilidade\\n de pertencer à classe rotulada de 1. A hipótese forma um limiar suave no espaço de\\nentrada e dá uma probabilidade de 0,5 para qualquer entrada ao centro da região de limiar, e às\\nabordagens 0 ou 1 à medida que nos afastamos do limiar.\\nO processo de ajuste dos pesos desse modelo para minimizar a perda em um conjunto de dados é\\nchamado de \\nregressão logística\\n. Não há solução fácil de forma fechada para encontrar o valor ótimo\\nde \\nw\\n com esse modelo, mas o cálculo da descida pelo gradiente é simples. Devido a nossas\\nhipóteses não gerarem apenas 0 ou 1, vamos utilizar a função de perda \\nL\\n2\\n; para manter as fórmulas\\nlegíveis vamos também usar \\ng\\n para representar a função logística, com \\ng\\n′ sua derivada.\\nPara um único exemplo (\\nx\\n, \\ny\\n), a derivação do gradiente é a mesma que para a regressão linear\\n(Equação 18.5) até o ponto onde é inserida a forma real de \\nh\\n. (Para essa derivada, precisaremos da\\nregra da cadeia\\n, \\n∂g\\n(\\nf\\n(\\nx\\n))/∂ \\nx\\n = \\ng\\n′(\\nf\\n(\\nx\\n))∂ \\nf\\n(\\nx\\n)/∂\\nx\\n.)) Temos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 840}),\n",
       " Document(page_content='A derivada \\ng\\n′ da função logística satisfaz \\ng\\n′(\\nz\\n) = \\ng\\n(\\nz\\n) (1 – \\ng\\n (\\nz\\n)), então temos\\nassim, a atualização de peso para minimizar a perda é\\nRepetindo os experimentos da \\nFigura 18.16\\n com regressão logística em vez de classificador de\\nlimiar linear, obtemos os resultados mostrados na \\nFigura 18.18\\n. Em (a), como o caso é separável\\nlinearmente, a regressão logística é um pouco mais lenta para convergir, mas tem um comportamento\\nmuito mais previsível. Em (b) e (c), onde os dados são ruidosos e não separáveis, a regressão\\nlogística converge muito mais rápido e confiavelmente. Essas vantagens tendem a se manter em\\naplicações do mundo real, e a regressão logística tornou-se uma das técnicas de classificação mais\\npopulares para problemas de medicina, marketing e análise de dados, pontuação de crédito, saúde\\npública e outras aplicações.\\nFigura 18.18\\n Repetição dos experimentos na \\nFigura 18.16\\n por regressão logística e erro quadrático.\\nA representação gráfica em (a) abrange 5.000 iterações em vez de 1.000, enquanto (b) e (c) utilizam\\na mesma escala.\\n18.7 REDES NEURAIS ARTIFICIAIS\\nPassaremos agora ao que parece ser um tema um tanto independente: o cérebro. Na verdade, como\\nveremos, as ideias técnicas que discutimos até agora neste capítulo serão úteis na construção de\\nmodelos matemáticos da atividade do cérebro e, de forma inversa, pensar sobre o cérebro tem\\najudado a estender o âmbito das ideias técnicas.\\nO Capítulo 1 passou brevemente pelos resultados básicos da neurociência — em particular, a\\nhipótese de que a atividade mental consiste basicamente na atividade eletroquímica em redes de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 841}),\n",
       " Document(page_content='células cerebrais chamadas \\nneurônios\\n (a \\nFigura 1.2\\n mostrou um diagrama esquemático de um\\nneurônio típico). Inspirado por essa hipótese, alguns dos trabalhos mais antigos de IA tiveram o\\nobjetivo de criar \\nredes neurais artificiais\\n (outros nomes do campo incluem \\nconexionismo\\n,\\nprocessamento distribuído em paralelo\\n e \\ncomputação neural\\n). A \\nFigura 18.19\\n apresenta um\\nmodelo matemático simples do neurônio desenvolvido por McCulloch e Pitts (1943). Grosseiramente\\nfalando, ele “dispara” quando uma combinação linear de suas entradas excede algum limiar (rígido\\nou suave), ou seja, ele implementa um classificador linear do tipo descrito na seção anterior. Uma\\nrede neural é apenas uma coleção de unidades conectadas; as propriedades da rede são determinadas\\npela sua topologia e pelas propriedades dos “neurônios”.\\nFigura 18.19\\n Modelo matemático simples de um neurônio. A ativação de saída da unidade é \\n, onde \\na\\ni\\n é a ativação de saída da unidade \\ni\\n e \\nw\\ni,j\\n é o peso sobre a ligação da\\nunidade \\ni\\n com essa unidade.\\nDesde 1943, têm sido desenvolvidos modelos muito mais detalhados e realistas, tanto de\\nneurônios como de sistemas maiores no cérebro, levando ao campo moderno da \\nneurociência\\ncomputacional\\n. Por outro lado, os pesquisadores de IA e os estatísticos tornaram-se interessados nas\\npropriedades mais abstratas das redes neurais, tais como sua capacidade de realizar computação\\ndistribuída, de tolerar entradas ruidosas e aprender. Embora entendamos agora que outros tipos de\\nsistemas — incluindo redes bayesianas — têm essas propriedades, as redes neurais permanecem uma\\ndas formas mais populares e eficazes de aprendizagem do sistema e são dignos de estudo.\\n18.7.1 Estrutura das redes neurais\\nAs redes neurais são compostas por nós ou \\nunidades\\n (ver \\nFigura 18.19\\n) conectadas por \\nligações\\ndirecionadas. Uma ligação da unidade \\ni\\n para a unidade \\nj\\n serve para propagar a \\nativação\\n \\na\\ni\\n de \\ni\\n para\\nj\\n.\\n8\\n Cada ligação também tem um \\npeso\\n numérico \\nw\\ni,j\\n associado a ele, que determina a força e o sinal\\nde conexão. Assim como em modelos de regressão linear, cada unidade tem uma entrada fictícia \\na\\n0\\n =\\n1 com peso associado \\nw\\n0,\\nj\\n. Cada unidade \\nj\\n primeiro calcula uma soma ponderada de suas entradas:\\nEm seguida, aplica uma \\nfunção de ativação\\n \\ng\\n a essa soma para obter a saída:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 842}),\n",
       " Document(page_content='A ativação da função \\ng\\n tipicamente é tanto um limiar rígido (\\nFigura 18.17\\n(a)), caso em que a\\nunidade é chamada de \\nperceptron\\n, como uma função logística (\\nFigura 18.17\\n (b)), caso em que por\\nvezes é utilizado o termo \\nperceptron sigmoide\\n. Ambas as funções de ativação não linear garantem a\\npropriedade importante de que toda a rede de unidades pode representar uma função não linear (veja\\no Exercício 18.22). Como mencionado na discussão de regressão logística, a função de ativação\\nlogística tem a vantagem adicional de ser diferenciável.\\nTendo decidido sobre o modelo matemático para “neurônios” individuais, a próxima tarefa é\\nconectá-los para formar uma rede. Existem duas formas fundamentalmente distintas para fazer isso.\\nUma \\nrede com alimentação para a frente\\n tem conexões somente em uma direção, isto é, forma um\\ngrafo acíclico dirigido. Cada nó recebe a entrada de nós “para cima” e libera a saída de nós “para\\nbaixo”; não há laços. Uma rede com alimentação para a frente representa uma função de sua entrada\\natual; portanto, não tem estado interno que não seja os próprios pesos. A \\nrede recorrente\\n, por outro\\nlado, alimenta suas saídas de volta às suas próprias entradas. Isso significa que os níveis de ativação\\nda rede formam um sistema dinâmico que pode atingir um estado estável ou apresentar oscilações ou\\naté mesmo um comportamento caótico. Além disso, a resposta da rede para determinada entrada\\ndepende do seu estado inicial, que pode depender de entradas anteriores. Portanto, as redes\\nrecorrentes (ao contrário das redes com alimentação para a frente) podem suportar memória de curto\\nprazo. Isso as torna mais interessantes como modelos de cérebro, mas também mais difícil de\\nentender. Esta seção vai se concentrar em redes com alimentação para a frente; algumas dicas para\\nmais informação sobre redes recorrentes são dadas ao final do capítulo.\\nAs redes com alimentação para a frente normalmente estão dispostas em \\ncamadas\\n, de tal forma\\nque cada unidade recebe a entrada somente a partir de unidades na camada imediatamente anterior.\\nNas duas próximas subseções, analisaremos as redes de camada única, em que cada unidade se\\nconecta diretamente a partir de entradas da rede para suas saídas, e as redes de camadas múltiplas,\\nque têm uma ou mais camadas de \\nunidades ocultas\\n que não são conectadas às saídas da rede. Até\\nagora, neste capítulo, consideramos apenas problemas de aprendizagem com uma variável única de\\nsaída \\ny\\n, mas as redes neurais são frequentemente usadas em casos em que são adequadas saídas\\nmúltiplas. Por exemplo, se quisermos formar uma rede para adicionar dois bits de entrada, cada 0 ou\\n1, precisaremos de uma saída para o bit de soma e uma para o bit de vai-um. Além disso, quando o\\nproblema de aprendizagem envolve classificação em mais que duas classes — por exemplo, quando\\naprendemos a categorizar imagens de dígitos manuscritos —, é comum o uso de uma unidade de\\nsaída para cada classe.\\n18.7.2 Redes neurais de camada única com alimentação para a frente\\n(perceptrons)\\nUma rede com todas as entradas conectadas diretamente com as saídas é chamada de \\nrede neural\\nde camada única\\n ou \\nrede perceptron\\n. A \\nFigura 18.20\\n mostra uma rede perceptron simples de duas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 843}),\n",
       " Document(page_content='entradas e duas saídas. Com uma rede desse tipo, podemos ter a esperança de aprender a função\\nadicionador de dois bits, por exemplo. Aqui estão todos os dados de treinamento de que\\nprecisaremos:\\nx\\n1\\nx\\n2\\ny\\n3\\n (transporte)\\ny\\n4\\n (soma)\\n0\\n0\\n0\\n0\\n0\\n1\\n0\\n1\\n1\\n0\\n0\\n1\\n1\\n1\\n1\\n0\\nA primeira coisa a notar é que uma rede perceptron com \\nm\\n saídas é realmente \\nm\\n redes separadas,\\npois cada peso afeta apenas uma das saídas. Assim, haverá \\nm\\n processos de treinamento separados.\\nAlém disso, dependendo do tipo de função de ativação utilizada, o processo de treinamento será\\ntanto a \\nregra de aprendizagem perceptron\\n (Equação 18.7) como a regra de descida pelo gradiente\\npor \\nregressão logística\\n (Equação 18.8).\\nFigura 18.20\\n (a) Rede perceptron com duas unidades de entrada e duas unidades de saída. (b) Rede\\nneural com duas entradas, uma camada oculta de duas unidades e uma unidade de saída. As entradas\\nfictícias e seus pesos associados não são mostrados.\\nSe você tentar qualquer método nos dados somadores de dois bits, algo interessante acontecerá. A\\nunidade 3 aprende a função vai-um com facilidade, mas a unidade 4 falha completamente em\\naprender a função soma. Não, a unidade 4 não está com defeito! O problema é com a função de soma\\nem si. Vimos na \\nSeção 18.6\\n que classificadores lineares (rígidos ou suaves) podem representar\\nlimiares de decisão linear no espaço de entrada. Isso funciona bem para a função vai-um, que é uma\\nlógica E (ver \\nFigura 18.21\\n(a)). A função soma, porém, é um XOR (OU exclusivo) das duas entradas.\\nComo a \\nFigura 18.21\\n(c) ilustra, essa função não é linearmente separável de modo que o perceptron\\nnão pode aprendê-la.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 844}),\n",
       " Document(page_content='Figura 18.21\\n Separabilidade linear em limiar de perceptrons. Os pontos pretos indicam um ponto no\\nespaço de entrada onde o valor da função é 1, e pontos brancos indicam um ponto onde o valor é 0. O\\nperceptron retorna 1 na região do lado não sombreado da linha. Em (c), não existe essa linha que\\nclassifica corretamente as entradas.\\nAs funções linearmente separáveis constituem apenas uma pequena fração de todas as funções\\nbooleanas; o Exercício 18.20 pede para quantificar essa fração. A incapacidade dos perceptrons de\\naprender mesmo tais funções simples como XOR foi um revés significativo para a comunidade\\nnascente de redes neurais na década de 1960. No entanto, os perceptrons estão longe de ser inúteis.\\nA \\nSeção 18.6.4\\n observou que a regressão logística (ou seja, o treinamento de um perceptron\\nsigmoide) ainda é hoje muito popular e uma ferramenta eficaz. Além disso, um perceptron pode\\nrepresentar uma função booleana bastante “complexa” de forma compacta. Por exemplo, a \\nfunção da\\nmaioria\\n, que gera um 1 apenas se mais da metade de suas entradas \\nn\\n forem 1, pode ser representada\\npor um perceptron com cada \\nw\\ni\\n = 1 e com \\nw\\n0\\n = −\\nn\\n/2. Uma árvore de decisão precisaria\\nexponencialmente de muitos mais nós para representar essa função.\\nA \\nFigura 18.22\\n mostra a curva de aprendizagem para um perceptron em dois problemas diferentes.\\nÀ esquerda, mostramos a curva de aprendizagem da função maioria com 11 entradas booleanas (ou\\nseja, a função de saída 1, se seis ou mais entradas forem 1). Como seria de esperar, o perceptron\\naprende a função de forma rápida porque a função da maioria é linearmente separável. Por outro\\nlado, o aprendiz de árvore de decisão não faz nenhum progresso porque a função da maioria é muito\\ndifícil (embora não seja impossível) para ser representada como árvore de decisão. À direita, temos\\no exemplo do restaurante. A solução do problema é facilmente representada como uma árvore de\\ndecisão, mas não é linearmente separável. O melhor plano utilizando dados classifica corretamente\\napenas 65%.\\nFigura 18.22\\n Comparação do desempenho dos perceptrons e das árvores de decisão. (a) Os\\nperceptrons são melhores em aprender a função de maioria de 11 entradas. (b) As árvores de decisão\\nsão melhores em aprender o predicado \\nVamosEsperar\\n no exemplo do restaurante.\\n18.7.3 Redes neurais com alimentação para a frente multicamada\\nMcCulloch e Pitts (1943) sabiam que uma única unidade de limiar não resolveria todos os seus', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 845}),\n",
       " Document(page_content='problemas. De fato, suas teses provam que tal unidade pode representar funções booleanas básicas E,\\nOU e NÃO, e depois continuam a argumentar que qualquer funcionalidade desejada pode ser obtida\\nligando grande número de unidades em redes de profundidade arbitrária (possivelmente recorrentes).\\nO problema era que ninguém sabia como treinar tais redes.\\nIsso acaba por ser um problema fácil se pensarmos em uma rede da maneira certa: como uma\\nfunção \\nh\\nw\\n(\\nx\\n) parametrizada pelos pesos \\nw\\n. Considere a rede simples mostrada na \\nFigura 18.20\\n (b),\\nque tem duas unidades de entrada, duas unidades ocultas e duas unidades de saída (além disso, cada\\nunidade tem uma entrada fictícia fixada em 1). Dado um vetor de entrada \\nx\\n = (\\nx\\n1\\n, \\nx\\n2\\n), as ativações\\ndas unidades de entrada são definidas como (\\na\\n1\\n, \\na\\n2\\n) = (\\nx\\n1\\n, \\nx\\n2\\n). A saída da unidade 5 é dada por\\nAssim, temos a saída expressa como uma função das entradas e dos pesos. Uma expressão similar\\nvale para a unidade 6. Enquanto podemos calcular as derivadas de tais expressões com relação aos\\npesos, podemos usar o método de minimização de perda da descida pelo gradiente para treinar a\\nrede. A \\nSeção 18.7.4\\n mostra exatamente como fazer isso. E, como a função representada por uma\\nrede pode ser altamente não linear — composta por funções de limiar suave não lineares aninhadas\\n— pode-se ver as redes neurais como ferramenta para fazer \\nregressão não linear\\n.\\nAntes de nos aprofundar em regras de aprendizagem, vamos observar como as redes geram\\nfunções complicadas. Primeiro, lembre-se de que cada unidade em uma rede sigmoide representa um\\nlimiar suave em seu espaço de entrada, como mostrado na \\nFigura 18.17\\n(c). Com uma camada oculta e\\numa camada de saída, como na \\nFigura 18.20\\n(b), cada unidade de saída calcula uma combinação\\nlinear de limiar suave dessas várias funções. Por exemplo, pela adição de duas funções de limiar\\nsuave opostas e limitando o resultado, podemos obter uma função “cume” como mostrado na \\nFigura\\n18.23\\n(a). A combinação das duas cristas em ângulos corretos entre si (ou seja, combinando as saídas\\nde quatro unidades ocultas), obtém um “sobressalto”, como mostrado na \\nFigura 18.23\\n(b).\\nFigura 18.23\\n (a) Resultado da combinação de duas funções de limiar suave opostas para produzir um\\ncume. (b) Rresultado da combinação de duas cristas para produzir um sobressalto.\\nCom mais unidades ocultas, podemos produzir outros sobressaltos de tamanhos diferentes em\\noutros lugares. Na verdade, com uma camada oculta única, suficientemente grande, é possível\\nrepresentar qualquer função contínua de entrada com precisão arbitrária; com duas camadas, podem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 846}),\n",
       " Document(page_content='ser representadas até mesmo funções descontínuas.\\n9\\n Infelizmente, para qualquer estrutura de rede\\nparticular\\n, é mais difícil caracterizar exatamente as funções que podem ser representadas e as que\\nnão podem.\\n18.7.4 Aprendizagem em redes multicamadas\\nPrimeiro, vamos tratar de uma complicação menor decorrente de redes multicamadas: interações\\nentre os problemas de aprendizagem quando a rede tem várias saídas. Nesses casos, devemos pensar\\nna rede como uma função vetorial \\nh\\nw\\n de implementação, em vez de uma função escalar \\nh\\nw\\n; por\\nexemplo, a rede na \\nFigura 18.20\\n(b) retorna um vetor [\\na\\n5\\n, \\na\\n6\\n]. Da mesma forma, a saída de destino\\nserá um vetor \\ny\\n. Considerando que uma rede perceptron se decompõe em \\nm\\n problemas de\\naprendizagem em separado para um problema de \\nm\\n saídas, essa decomposição falha em uma rede de\\nmúltiplas camadas. Por exemplo, tanto \\na\\n5\\n como \\na\\n6\\n na \\nFigura 18.20\\n(b) dependem de todos os pesos\\nda camada de entrada, de modo que as atualizações desses pesos dependerão de erros tanto em \\na\\n5\\ncomo em \\na\\n6\\n. Felizmente, essa dependência é muito simples, no caso de qualquer função de perda que\\nseja \\naditiva\\n entre os componentes do vetor de erro \\ny − h\\nw\\n(\\nx\\n). Pela perda \\nL\\n2\\n, temos, para qualquer\\npeso \\nw\\n,\\nonde o índice \\nk\\n varia no intervalo dos nós na camada de saída. Cada termo, no somatório final, é\\napenas o gradiente de perda para a \\nk\\n-ésima saída, calculado como se outras saídas não existissem.\\nAssim, podemos decompor um problema de aprendizagem com \\nm\\n-saídas em \\nm\\n problemas de\\naprendizagem, desde que não esqueçamos de somar as contribuições do gradiente de cada um deles\\nao atualizar os pesos.\\nA principal complicação vem da adição de camadas ocultas da rede. Enquanto que o erro \\ny − h\\nw\\nna camada de saída é claro, o erro nas camadas ocultas parece misterioso porque os dados de\\ntreinamento não dizem que valor os nós ocultos devem ter. Felizmente, verifica-se que podemos\\nretropropagar\\n o erro da camada de saída para as camadas ocultas. O processo de retropropagação\\nemerge diretamente de uma derivação do gradiente de erro geral. Primeiro, descreveremos o\\nprocesso com uma justificação intuitiva; depois, mostraremos a derivação.\\nNa camada de saída, a regra de atualização do peso é idêntica à Equação 18.8. Temos unidades de\\nsaída múltiplas; assim, façamos \\nErr\\nk\\n o componente do erro \\nk\\n-ésimo do vetor de erro \\ny − h\\nw\\n.\\nTambém é conveniente definir um erro modificado \\n, para que a regra de atualização de\\npeso torne-se\\nPara atualizar as conexões entre as unidades de entrada e as unidades ocultas, precisamos definir\\numa quantidade análoga ao termo de erro dos nós de saída. Aqui fazemos a retropropagação do erro.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 847}),\n",
       " Document(page_content='A ideia é que o nó oculto \\nj\\n seja “responsável” por uma fração do erro ∆\\nk\\n em cada um dos nós de\\nsaída aos quais ele se conecta. Assim, os valores ∆\\nk\\n são divididos de acordo com a força de ligação\\nentre o nó oculto e o nó de saída e são retropropagados para fornecer os valores ∆\\nj\\n para a camada\\noculta. A regra para a propagação dos valores ∆ é a seguinte:\\nAgora a regra de atualização de peso para os pesos entre as entradas e a camada oculta é\\nessencialmente idêntica à regra de atualização para a camada de saída:\\nO processo de retropropagação pode ser resumido da seguinte forma:\\n•  Calcule valores ∆ para as unidades de saída usando o erro observado.\\n•  A partir da camada de saída, repita o seguinte para cada camada da rede até que a primeira\\ncamada oculta seja alcançada:\\n–  Propague os valores ∆ de volta à camada anterior.\\n–  Atualize os pesos entre as duas camadas.\\nO algoritmo detalhado é mostrado na \\nFigura 18.24\\n.\\nFigura 18.24\\n Algoritmo de retropropagação para o aprendizagem em redes multicamadas.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 848}),\n",
       " Document(page_content='Para quem gosta de matemática, vamos agora derivar as equações de retropropagação dos\\nprimeiros princípios. A derivação é bastante semelhante ao cálculo de gradiente de regressão\\nlogística (que conduziu à Equação 18.8), exceto que temos de usar a regra de cadeia mais de uma\\nvez.\\nA partir da Equação 18.10, calculamos apenas o gradiente de \\nPerda\\nk\\n = (\\ny\\nk\\n − \\na\\nk\\n)\\n2\\n na \\nk\\n-ésima\\nsaída. O gradiente dessa perda com relação aos pesos de conexão com a camada oculta até a camada\\nde saída será zero, exceto para os pesos w\\nj,k\\n que se unem à \\nk\\n-ésima unidade de saída.\\nPara aqueles pesos, temos\\ncom ∆\\nk\\n definido como antes. Para obter o gradiente com relação aos pesos \\nw\\ni,j\\n em conexão com a\\ncamada de entrada até \\na\\nj\\n camada oculta temos que expandir as ativações \\na\\nj\\n e reaplicar a regra da\\ncadeia. Vamos mostrar a derivação em pormenores porque é interessante ver como o operador de\\nderivada retropropaga através da rede:\\nonde ∆\\nj\\n foi definido como antes. Assim, obtemos as regras de atualização obtidas anteriormente a\\npartir de considerações intuitivas. Também fica claro que o processo pode ser continuado para redes\\ncom mais de uma camada oculta, o que justifica o algoritmo geral dado na \\nFigura 18.24\\n.\\nPassando por toda essa matemática, vamos ver o desempenho de uma rede de camada oculta única\\nno problema do restaurante. Primeiro, precisamos determinar a estrutura da rede. Temos 10 atributos\\nque descrevem cada exemplo, então precisaremos de 10 unidades de entrada. Deveríamos ter uma\\ncamada oculta ou duas? Quantos nós em cada camada? Devem estar totalmente conectados? Não há\\nnenhuma boa teoria que nos forneça a resposta (veja a próxima seção). Como sempre, podemos usar\\na validação cruzada: tentar várias estruturas diferentes e ver qual funciona melhor. Acontece que uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 849}),\n",
       " Document(page_content='rede com uma camada oculta contendo quatro nós parece razoável para esse problema. Na \\nFigura\\n18.25\\n, apresentamos duas curvas. A primeira é uma curva de treinamento mostrando o erro\\nquadrático médio, dado um conjunto de treinamento de 100 exemplos de restaurante durante o\\nprocesso de atualização de peso. Isso demonstra que a rede, de fato, converge para um ajuste perfeito\\naos dados de treinamento. A segunda curva é a curva de aprendizagem padrão para os dados do\\nrestaurante. A rede neural aprende bem, embora não tão rápido quanto a aprendizagem em árvore de\\ndecisão, o que não é surpreendente, em primeiro lugar porque os dados foram gerados a partir de\\numa árvore de decisão simples.\\nFigura 18.25\\n (a) A curva de treinamento mostra a redução gradual do erro à medida que os pesos são\\nmodificados ao longo de diversas épocas, para um conjunto de exemplos determinados do domínio\\ndo restaurante. (b) Curvas de aprendizagem comparativas mostrando que a aprendizagem em árvore\\nde decisão é um pouco melhor para o problema do restaurante do que a retropropagação em uma rede\\nde múltiplas camadas.\\nCertamente as redes neurais são capazes de tarefas muito mais complexas de aprendizagem,\\nembora deva ser dito que é necessário certa quantidade de esforço para obter a estrutura da rede\\ncorreta e alcançar a convergência para algo próximo ao ótimo global no espaço de peso. Há\\nliteralmente dezenas de milhares de aplicações publicadas de redes neurais. A \\nSeção 18.11.1\\napresentará um aplicativo, com mais profundidade.\\n18.7.5 Aprendendo as estruturas de redes neurais\\nAté agora, consideramos o problema de pesos de aprendizagem, dada uma estrutura de rede fixa;\\nassim como com redes bayesianas, também precisamos entender como encontrar a melhor estrutura\\nde rede. Se escolhermos uma rede muito grande, ela será capaz de memorizar todos os exemplos,\\nformando uma tabela grande de pesquisa, mas não generalizará bem necessariamente as entradas que\\nnunca foram vistas antes.\\n10\\n Em outras palavras, como todos os modelos estatísticos, as redes neurais\\nestão sujeitas a \\nsuperadaptações\\n quando existem muitos parâmetros no modelo. Vimos isso na\\nFigura 18.1\\n, onde os modelos de muitos parâmetros em (b) e (c) ajustam todos os dados, mas podem\\nnão generalizar, assim como os modelos de poucos parâmetros em (a) e (d).\\nSe nos ativermos a redes totalmente conectadas, as únicas escolhas a serem feitas dizem respeito', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 850}),\n",
       " Document(page_content='ao número de camadas ocultas e seus tamanhos. A abordagem usual é tentar várias mantendo as\\nmelhores. Será necessária a técnica de \\nvalidação cruzad\\na se quisermos evitar \\nespreitar\\n o conjunto\\nde teste. Ou seja, escolhemos a arquitetura de rede que oferece a maior previsão de precisão nos\\nconjuntos de validação.\\nSe quisermos considerar redes que não estejam totalmente conectadas, precisamos encontrar algum\\nmétodo de busca eficaz através do espaço muito grande de topologias possíveis de conexão. O\\nalgoritmo de dano cerebral ótimo\\n começa com uma rede totalmente conectada e remove as\\nconexões dela. Depois que a rede é instruída pela primeira vez, uma abordagem teórica de\\ninformação identifica uma seleção ideal de conexões que podem ser descartadas. A rede é, então,\\nreciclada, e se seu desempenho não diminuir, o processo será repetido. Além de remover as\\nconexões, também é possível remover as unidades que não estão contribuindo muito para o resultado.\\nVários algoritmos têm sido propostos para produzir uma rede maior de uma menor. Um deles, o\\nalgoritmo de ladrilhamento, assemelha-se à aprendizagem com lista de decisão. A ideia é iniciar com\\numa unidade única que faz o melhor para produzir a saída correta para tantos exemplos de\\ntreinamento quanto possível. As unidades subsequentes são adicionadas para cuidar dos exemplos\\nque a primeira unidade obteve errado. O algoritmo adiciona apenas tantas unidades quantas forem\\nnecessárias para abranger todos os exemplos.\\n18.8 MODELOS NÃO PARAMÉTRICOS\\nA regressão linear e as redes neurais utilizam dados de treinamento para estimar um conjunto fixo\\nde parâmetros \\nw\\n. Isso define a nossa hipótese \\nh\\nw\\n(\\nx\\n), e nesse ponto podemos jogar fora os dados de\\ntreinamento porque todos eles estão resumidos por \\nw\\n. Um modelo de aprendizagem que resume os\\ndados com um conjunto de parâmetros de tamanho fixo (independentemente do número de exemplos\\nde treinamento) é chamado de \\nmodelo paramétrico\\n.\\nNão importa a quantidade de dados que você jogue em um modelo paramétrico, não muda a ideia\\nsobre quantos parâmetros são necessários. Quando os conjuntos de dados são pequenos, faz sentido\\nter uma restrição forte nas hipóteses permitidas, para evitar a superadaptação. Mas, quando há\\nmilhares ou milhões ou bilhões de exemplos para aprender, parece que uma ideia melhor é permitir\\nque os dados falem por si em vez de forçá-los a falar através de um vetor de parâmetros minúsculos.\\nSe os dados informam que a resposta correta é uma função muito sinuosa, não devemos nos restringir\\nàs funções lineares ou às ligeiramente sinuosas.\\nUm \\nmodelo paramétrico\\n é aquele que não pode ser caracterizado por um conjunto limitado de\\nparâmetros. Por exemplo, suponha que cada hipótese que geramos simplesmente mantenha dentro de\\nsi todos os exemplos de treinamento e os use para prever o próximo exemplo. Tal grupo de hipótese\\nserá não paramétrico, pois o número efetivo de parâmetros é ilimitado — cresce com o número de\\nexemplos. Essa abordagem é chamada de \\naprendizagem baseada em exemplos\\n ou \\naprendizagem\\nbaseada em memória\\n. O método mais simples de aprendizagem baseada em exemplo é a \\npesquisa\\nem tabelas\\n: tome todos os exemplos de treinamento, coloque-os em uma tabela e, depois, quando\\nh\\n(\\nx\\n) for solicitado, veja se x está na tabela; se estiver, devolva o \\ny\\n correspondente. O problema com\\nesse método é que ele não generaliza bem: quando \\nx\\n não está na tabela, tudo o que faz é retornar', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 851}),\n",
       " Document(page_content='algum valor default.\\n18.8.1 Modelo do vizinho mais próximo\\nPodemos melhorar pesquisa em tabela com uma ligeira variação: dada uma consulta \\nx\\nq\\n, encontre \\nk\\nexemplos que estiverem mais próximas de \\nx\\nq\\n. Isso é chamado de pesquisa de k-\\nvizinhos mais\\npróximos\\n. Usaremos a notação \\nVP\\n(\\nk\\n, \\nx\\nq\\n) para indicar o conjunto de \\nk\\n vizinhos mais próximos.\\nPara classificar, primeiro encontre \\nVP\\n(\\nk\\n, \\nx\\nq\\n) e tome o voto da maioria dos vizinhos (que é o voto\\nmajoritário, em caso de classificação binária). Para evitar empates, \\nk\\n é sempre escolhido como\\nnúmero ímpar. Para fazer regressão, podemos tirar a média ou mediana de \\nk\\n vizinhos, ou podemos\\nresolver um problema de regressão linear sobre os vizinhos.\\nNa \\nFigura 18.26\\n, mostramos o limite de decisão da classificação de \\nk\\n-vizinhos mais próximo para\\nk\\n = 1 e 5 sobre o conjunto de dados do terremoto da \\nFigura 18.15\\n. Os métodos não paramétricos\\nestão sujeitos ainda a subadaptação e superadaptação, assim como os métodos paramétricos. Nesae\\ncaso, 1-vizinho mais próximo é a superadaptação; ele reage muito ao preto que está à parte no canto\\nsuperior direito e ao branco que está à parte em (5,4; 3,7). O limiar de 5-vizinhos mais próximos é\\nbom; valores maiores de \\nk\\n levariam à subadaptação. Como de costume, pode-se usar a validação\\ncruzada para selecionar o melhor valor de \\nk\\n.\\nFigura 18.26\\n (a) Um modelo de \\nk\\n-vizinhos mais próximos mostra a extensão da classe de explosão\\npara os dados da \\nFigura 18.15\\n, com \\nk\\n = 1. A superadaptação é aparente. (b) Com \\nk\\n = 5, o problema\\nde superadaptação desaparece para esse conjunto de dados.\\nA própria expressão “mais próximo” implica uma métrica de distância. Como podemos medir a\\ndistância a partir de um ponto de consulta \\nx\\nq\\n até um ponto de exemplo \\nx\\nj\\n? Prevê-se que as distâncias\\nsejam medidas com a distância de Minkowski ou com a norma \\nL\\np\\n, definida como\\nCom \\np\\n = 2, essa é a distância euclidiana e com \\np\\n = 1 é a distância de Manhattan. Com valores de\\natributo booleanos, o número de atributos em que dois pontos diferentes diferem é chamado de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 852}),\n",
       " Document(page_content='distância de Hamming\\n. Muitas vezes, \\np\\n = 2 é usado se as dimensões estiverem medindo\\npropriedades similares, tais como largura, altura e profundidade de peças em uma correia\\ntransportadora, e a distância de Manhattan é utilizada se elas forem diferentes, tais como idade, peso\\ne sexo do paciente. Observe que, se usarmos os números brutos de cada dimensão, a distância total\\nserá afetada por uma mudança na escala em qualquer dimensão. Se mudarmos a dimensão \\ni\\n de\\ncentímetros para milhas, mantendo as outras dimensões, teremos vizinhos mais próximos diferentes.\\nPara evitar isso, é comum aplicar a \\nnormalização\\n para medições em cada dimensão. Uma\\nabordagem simples é calcular a média \\nμ\\ni\\n e o desvio-padrão \\nσ\\ni\\n dos valores em cada dimensão, e\\nredimensioná-los para que \\nx\\nj,i\\n torne-se (\\nx\\nj, i\\n – \\nμ\\ni\\n)/σ\\ni\\n. Uma métrica mais complexa conhecida como\\ndistância de Mahalanobis\\n leva em conta a covariância entre as dimensões.\\nEm espaços de dimensão baixa com abundância de dados, os vizinhos mais próximos funcionam\\nmuito bem: podemos ter dados suficientes nas proximidades para obter uma boa resposta. Mas, à\\nmedida que o número de dimensões cresce, deparamo-nos com um problema: os vizinhos mais\\npróximos em espaços dimensionais altos geralmente não estão muito próximos! Considere \\nk\\n-vizinhos\\nmais próximos em um conjunto de dados de \\nN\\n pontos uniformemente distribuídos por todo o interior\\nde uma unidade de hipercubo \\nn\\n-dimensional. Vamos definir a \\nk\\n-vizinhança de um ponto como o\\nmenor hipercubo que contém os \\nk\\n-vizinhos mais próximos. Seja \\nl\\n o comprimento médio do lado\\nmédio de uma vizinhança. Então, o volume da vizinhança (que contém \\nk\\n pontos) será \\nl\\nn\\n e o volume do\\ncubo completo (que contém \\nN\\n pontos) será 1. Então, em média, \\nl\\nn\\n = \\nk\\n/\\nN\\n. Extraindo as raízes\\nenésimas de ambos os lados teremos \\nl\\n = (\\nk\\n/\\nN\\n)\\n1/\\nn\\n.\\nPara ser específico, faça \\nk\\n = 10 e \\nN\\n = 1.000. 000. Em duas dimensões (\\nn\\n = 2; um quadrado\\nunitário), a vizinhança média tem \\nl\\n = 0,003, uma pequena fração do quadrado unitário e, em três\\ndimensões, \\nl\\n será apenas 2% do comprimento da aresta do cubo unitário. Já com 17 dimensões, \\nl\\n será\\nmetade do comprimento da borda do hipercubo unitário e, em 200 dimensões, será 94%. Esse\\nproblema tem sido denominado \\nmaldição da dimensionalidade\\n.\\nOutra forma de ver isso: considere os pontos que caem dentro de uma borda compondo 1% do\\nexterior da unidade do hipercubo. Em geral será difícil encontrar um bom valor para eles porque\\nestaremos extrapolando, em vez de interpolando. Em uma dimensão, esses pontos são apenas 2% dos\\npontos na linha da unidade (aqueles pontos onde \\nx\\n <0,01 ou \\nx\\n >0,99), mas, em 200 dimensões, mais\\nde 98% dos pontos caem nessa borda fina. Você pode ver um exemplo de ajuste fraco de vizinhos\\nmais próximos na \\nFigura 18.28\\n(b).\\nFigura 18.27\\n A maldição da dimensionalidade. (a) O comprimento da vizinhança média de 10-', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 853}),\n",
       " Document(page_content='vizinhos-mais-próximos em uma unidade de hipercubo com 1.000.000 de pontos, em função do\\nnúmero de dimensões. (b) A proporção de pontos que caem dentro de uma borda fina que consiste em\\n1% à parte do hipercubo, em função do número de dimensões. Amostragem de 10.000 pontos\\ndistribuídos aleatoriamente.\\nFigura 18.28\\n Modelos de regressão não paramétrica: (a) ligar os pontos, (b) média dos três vizinhos\\nmais próximos, (c) regressão linear de três vizinhos mais próximos, (d) regressão ponderada\\nlocalmente com um kernel quadrático de largura \\nk\\n = 10.\\nA função \\nVP\\n(\\nk\\n, \\nx\\nq\\n) é simples conceitualmente: dado um conjunto de \\nN\\n exemplos e uma consulta\\nx\\nq\\n, percorra os exemplos, meça a distância até \\nx\\nq\\n de cada um e use os \\nk\\n melhores. Se estiver\\nsatisfeito com uma implementação que tem tempo de execução \\nO\\n(\\nN\\n), a história termina aí. Mas os\\nmétodos baseados em exemplo são projetados para grandes conjuntos de dados, então ficaríamos\\nsatisfeitos com um algoritmo com tempo de execução sublinear. A análise elementar de algoritmos\\nnos diz que a tabela de pesquisa exata é \\nO\\n(\\nN\\n) com uma tabela sequencial, \\nO\\n(log \\nN\\n) com uma árvore\\nbinária e \\nO\\n(1) com uma tabela hash. Agora veremos que árvores binárias e tabelas hash também são\\naplicáveis \\u200b\\u200bpara encontrar vizinhos mais próximos.\\n18.8.2 Encontrar os vizinhos mais próximos com árvores k-d\\nUma árvore binária equilibrada sobre os dados com número arbitrário de dimensões é chamada de\\nárvore k-d\\n, ou seja árvore \\nk\\n-dimensional (nessa notação, o número de dimensões é \\nn\\n, de modo que', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 854}),\n",
       " Document(page_content='seriam \\nn\\n-d árvores). A construção de uma árvore k-d é similar à construção de uma árvore binária\\nbalanceada unidimensional. Começamos com um conjunto de exemplos e no nó raiz dividimo-los ao\\nlongo da \\ni\\n-ésima dimensão testando se \\nx\\ni\\n ≤ \\nm\\n. Escolhemos o valor \\nm\\n para ser a mediana dos\\nexemplos ao longo da \\ni\\n-ésima dimensão; assim, metade dos exemplos estará na ramificação esquerda\\nda árvore e a outra metade à direita. Em seguida, compomos uma árvore recursivamente para o\\nconjunto de exemplos à esquerda e à direita, parando quando houver menos que dois exemplos à\\nesquerda. Para escolher uma dimensão para dividir cada nó da árvore, pode-se simplesmente\\nselecionar a dimensão \\ni\\n mod \\nn\\n no nível \\ni\\n da árvore (observe que talvez seja necessário dividir várias\\nvezes em qualquer dimensão à medida que descemos na árvore). Outra estratégia é dividir a\\ndimensão que tiver o maior espalhamento de valores.\\nPesquisa exata de uma árvore k-d é o mesmo que examinar uma árvore binária (com uma ligeira\\ncomplicação, pois você precisa prestar atenção a cada nó em qual dimensão você está testando). Mas\\na pesquisa do vizinho mais próximo é mais complicada. À medida que descemos as ramificações,\\ndividindo os exemplos ao meio, em alguns casos podemos descartar a outra metade dos exemplos.\\nMas nem sempre. Às vezes, o ponto que estamos consultando cai muito próximo do limite de divisão.\\nO ponto de consulta em si pode ser no lado esquerdo do limite, mas um ou mais dos \\nk\\n vizinhos mais\\npróximos podem realmente estar no lado direito. Temos que testar essa possibilidade calculando a\\ndistância do ponto de consulta até o limite de divisão, e depois buscar em ambos os lados se não\\npudermos encontrar os \\nk\\n exemplos à esquerda que estão mais perto do que essa distância. Devido a\\nesse problema, as árvores k-d são apropriadas somente quando houver muito mais exemplos que\\ndimensões, de preferência pelo menos 2\\nn\\n exemplos. Assim, as árvores k-d funcionam bem com até 10\\ndimensões com milhares de exemplos ou até 20 dimensões com milhões de exemplos. Se não\\ntivermos exemplos suficientes, a pesquisa não será mais rápida do que uma varredura linear do\\nconjunto de dados inteiro.\\n18.8.3 Hash sensível a localidade\\nAs tabelas hash têm o potencial de fornecer pesquisa ainda mais rápida do que as árvores binárias.\\nMas como podemos encontrar os vizinhos mais próximos usando uma tabela hash quando os códigos\\nde hash dependem de uma correspondência exata? Os códigos de hash distribuem os valores\\naleatoriamente entre os compartimentos, mas queremos ter pontos próximos agrupados no mesmo\\ncompartimento; queremos um \\nhash sensível a localidade\\n (HSL).\\nNão podemos usar tabelas de hash para resolver \\nVP\\n(\\nk\\n, \\nx\\nq\\n) exatamente, mas com um uso inteligente\\nde algoritmos randomizados podemos encontrar uma solução \\naproximada\\n. Primeiro vamos definir o\\nproblema dos \\nvizinhos próximos aproximados\\n: dado um conjunto de dados de pontos de exemplo e\\num ponto de consulta \\nx\\nq\\n, encontre, com probabilidade alta, um ponto de exemplo (ou pontos) que\\nesteja próximo de \\nx\\nq\\n. Para ser mais preciso, é necessário que, se houver um ponto \\nx\\nj\\n, que esteja\\ndentro de um raio de \\nr\\n de \\nx\\nq\\n, é muito provável que na sequência, o algoritmo vai encontrar um ponto\\nde \\nx\\nj\\n’ que esteja dentro da distância de \\nc r\\n de \\nθ\\n. Se não houver ponto dentro do raio \\nr\\n é permitido que\\no algoritmo relate falha. Os valores de \\nc\\n e “alta probabilidade” são os parâmetros do algoritmo.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 855}),\n",
       " Document(page_content='Para resolver aproximar vizinhos próximos, vamos precisar de uma função hash \\ng\\n(\\nx\\n) que tenha a\\npropriedade de que, para quaisquer dois pontos \\nx\\nj\\n e \\n, a probabilidade de ter o mesmo código hash\\nserá pequena se a sua distância for superior a \\nc r\\n, e alta, se a distância for menor que \\nr\\n. Para\\nsimplificar vamos tratar cada ponto como uma cadeia de bits (quaisquer recursos que não forem\\nbooleanos podem ser codificados em um conjunto de características booleanas).\\nA intuição com a qual contamos é que, se dois pontos estão juntos em um espaço \\nn\\n-dimensional,\\nentão eles necessariamente vão estar perto quando projetados em um espaço unidimensional (uma\\nlinha). Na verdade, podemos discretizar a linha em compartimentos de hash de modo que, com alta\\nprobabilidade, os pontos próximos serão representados exatamente no mesmo compartimento. Os\\npontos que estiverem longe uns dos outros tendem a ser representados em compartimentos diferentes\\npara a maioria das projeções, mas haverá sempre poucas representações que coincidentemente\\nprojetam os pontos separados no mesmo compartimento. Assim, o compartimento do ponto \\nx\\nq\\n contém\\nmuitos (mas não todos) os pontos que estão perto de \\nx\\nq\\n, bem como alguns pontos que estão longe.\\nO truque de HSL é criar de \\nmúltiplas\\n representações aleatórias e combiná-las. A representação\\naleatória é apenas um subconjunto aleatório de representação da cadeia de bits. Escolhemos \\nl\\ndiferentes representações aleatórias e a criação de \\nl\\n tabelas hash, \\ng\\n1\\n(\\nx\\n),…, g\\nl\\n(\\nx\\n). Em seguida,\\ninserimos todos os exemplos em cada tabela hash. Então, quando é dado um ponto de consulta \\nx\\np\\n,\\nbuscamos o conjunto de pontos no compartimento \\ng\\nk\\n(\\nθ\\n) para cada \\nk\\n e unimos esses conjuntos em um\\nconjunto de pontos candidatos, \\nC\\n. Então calculamos a distância real até \\nx\\nq\\n para cada um dos pontos\\nem \\nC\\n e retornamos os pontos \\nk\\n mais próximos. Com probabilidade alta, cada um dos pontos que\\nestão perto de \\nx\\nq\\n vai aparecer em pelo menos um dos compartimentos e, apesar de alguns pontos\\ndistantes também aparecerem, podemos ignorá-los. Para problemas grandes do mundo real, tal como\\nencontrar os vizinhos mais próximos em um conjunto de dados de 13 milhões de imagens da Web\\nutilizando 512 dimensões (Torralba \\net al\\n., 2008), o HSL precisa examinar apenas alguns milhares de\\nimagens de 13 milhões para encontrar os vizinhos mais próximos — um aumento de velocidade de\\nmil vezes sobre as abordagens exaustivas ou de árvore k-d.\\n18.8.4 Regressão não paramétrica\\nAgora vamos examinar as abordagens não paramétricas para \\nregressão\\n em vez de classificação. A\\nFigura 18.28\\n mostra um exemplo de alguns modelos diferentes. Em (a), temos talvez o método mais\\nsimples de todos, conhecido informalmente como “ligar os pontos” e, de forma esnobe, como\\n“regressão não paramétrica linear programável por partes”. Esse modelo cria uma função \\nh\\n(\\nx\\n) que,\\ndada uma consulta \\nx\\nq\\n, resolve o problema de regressão linear simples com apenas dois pontos:\\nexemplos de treinamento imediatamente à esquerda e à direita de \\nx\\nq\\n. Quando o ruído for baixo, na\\nverdade esse método corriqueiro não é tão ruim, razão pela qual é um recurso padrão de software de\\ngráficos em planilhas. Mas, quando os dados são ruidosos, a função resultante é pontuda e não\\ngeneraliza bem.\\nA \\nregressão de\\n \\nk\\n-vizinhos mais próximos\\n (\\nFigura 18.28\\n(b)) melhora ao ligar os pontos. Em lugar', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 856}),\n",
       " Document(page_content='de usar apenas os dois exemplos para a esquerda e para a direita de um ponto de consulta \\nx\\nq\\n,\\nusaremos os \\nk\\n vizinhos mais próximos (aqui, k-3). Um valor maior de \\nk\\n tende a suavizar a magnitude\\ndas pontas, embora a função resultante tenha descontinuidades. Em (b), temos a média de \\nk\\n-vizinhos\\nmais próximos: \\nh\\n(\\nx\\n) é o valor médio dos pontos \\nk\\n, \\n. Repare que, nos pontos de periferia, perto\\nde \\nx\\n = 0 e \\nx\\n = 14, as estimativas são fracas porque toda evidência vem de um lado (o interior) e\\nignora a tendência. Em (c), temos a regressão linear de \\nk\\n-vizinhos mais próximos, que encontra a\\nmelhor linha através dos exemplos \\nk\\n. Este faz um trabalho melhor de tendência de captura dos que\\nestão à parte, mas ainda é descontínuo. Em (b) e (c), ficamos com a questão de como escolher um\\nbom valor para \\nk\\n. A resposta, como usual, é a validação cruzada.\\nA \\nregressão ponderada localmente\\n (\\nFigura 18.28\\n(d)) oferece-nos as vantagens do vizinho mais\\npróximo, sem descontinuidades. Para evitar descontinuidades em \\nh\\n(\\nx\\n), precisamos evitar\\ndescontinuidades no conjunto de exemplos que usamos para estimar \\nh\\n(\\nx\\n). A ideia de regressão\\nponderada localmente é que, em cada ponto da consulta \\nx\\nq\\n, os exemplos que estão perto de \\nx\\nq\\n são\\nfortemente ponderados, e os exemplos que estão mais longe são ponderados menos intensamente ou\\nnão são. A redução do peso sobre a distância é sempre gradual, não repentina.\\nDecidimos o quanto ponderar cada exemplo com uma função conhecida como \\nkernel\\n. A função\\nkernel é parecida com um calombo; na \\nFigura 18.29\\n vemos o kernel específico usado para gerar a\\nFigura 18.28\\n(d). Podemos ver que o peso fornecido por esse kernel é maior no centro e chega a zero\\na uma distância de ±5. Podemos escolher qualquer função para um kernel? Não. Primeiro, observe\\nque chamamos uma função kernel \\n com \\n(\\nDistância(\\nx\\nj\\n,\\n \\nx\\nq\\n)),\\n onde \\nx\\nq\\n é um ponto de consulta que\\nestá a determinada distância de \\nx\\nj\\n, e queremos saber o quanto ponderar essa distância. Então, \\n deve\\nser simétrico em torno de 0 e ter um máximo em 0. A área sob o kernel deve permanecer limitada à\\nmedida que avançamos para ±∞. Outras formas, tais como as gaussianas, têm sido utilizadas para\\nkernels, mas as últimas pesquisas sugerem que a escolha da forma não importa muito. Temos de ter\\ncuidado com a largura do kernel. Novamente, esse é um parâmetro do modelo que pode ser escolhido\\nmelhor por validação cruzada. Assim como na escolha do \\nk\\n dos vizinhos mais próximos, se os\\nkernels forem demasiado grandes vamos chegar a uma subadaptação e, se eles forem demasiados\\nestreitos, teremos uma superadaptação. Na \\nFigura 18.29\\n(d), o valor de \\nk\\n = 10 fornece uma curva\\nsuave que parece boa, mas talvez sem dar atenção suficiente para o ponto fora da curva em \\nx\\n = 6;\\numa largura menor do kernel seria mais sensível aos pontos individuais.\\nFigura 18.29\\n Um kernel quadrático, \\n(\\nd\\n) = max(0,1 − (2 |\\nx\\n|/\\nk\\n)\\n2\\n), com largura do kernel com \\nk\\n = 10,\\ncentralizado no ponto de consulta \\nx\\n = 0.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 857}),\n",
       " Document(page_content='Fazer regressão ponderada localmente com kernels fica simples agora. Para determinado ponto de\\nconsulta \\nx\\nq\\n vamos resolver o seguinte problema de regressão ponderada usando a descida pelo\\ngradiente:\\nonde a \\nDistância\\n é uma das métricas de distância discutidas para vizinhos mais próximos. Então, a\\nresposta é \\nh\\n(\\nx\\nq\\n) = \\nw\\n* · \\nx\\nq\\n.\\nObserve que precisamos resolver um problema de regressão para \\ncada\\n ponto de consulta — isso é\\no que significa ser local (na regressão linear simples, resolvemos o problema de regressão uma vez,\\nglobalmente, e depois usamos o mesmo \\nh\\nw\\n para qualquer ponto da consulta). Alivia esse trabalho\\nextra o fato de que cada problema de regressão será mais fácil de resolver, pois envolve apenas os\\nexemplos com o peso diferente de zero — exemplos cujos kernels se sobrepõem aos pontos de\\nconsulta atenuam esse trabalho extra. Quando a largura do kernel é pequena, podem ser apenas alguns\\npontos.\\nA maioria dos modelos não paramétricos tem a vantagem de tornar fácil fazer a validação cruzada\\ncom omissão de um sem ter de recalcular tudo. Com um modelo de \\nk-\\nvizinhos mais próximos, por\\nexemplo, quando é dado um exemplo de teste (\\nx\\n, \\ny\\n) recuperamos os \\nk\\n vizinhos mais próximos uma\\nvez, calculamos, por exemplo, a perda L(\\ny\\n, \\nh\\n (\\nx\\n)) deles e registramos isso como o resultado de\\nomissão de um para cada exemplo que não for um dos vizinhos. Então recuperamos os vizinhos mais\\npróximos \\nk\\n + 1 e registramos os resultados distintos omitindo cada um dos \\nk\\n vizinhos. Com \\nN\\nexemplos, o processo todo é \\nO\\n(\\nk\\n), não \\nO\\n(\\nkN\\n).\\n18.9 MÁQUINAS DE VETORES DE SUPORTE\\nA \\nmáquina de vetor de suporte\\n ou estrutura SVM é atualmente a abordagem pré-fabricada mais\\npopular para aprendizagem supervisionada: se você não tiver nenhum conhecimento prévio\\nespecializado sobre um domínio, o SVM é um excelente primeiro método a testar. Existem três\\npropriedades que tornam o SVM atraente:\\n1. Os SVMs constroem um \\nseparador de margem máxima\\n — um limite de decisão com a maior\\ndistância possível a pontos de exemplo. Isso os ajuda a generalizar bem.\\n2. Os SVMs criam uma separação linear em hiperplano, mas têm a capacidade de incorporar os\\ndados em um espaço de dimensão superior, usando o assim chamado \\ntruque de kernel\\n. Muitas\\nvezes, os dados que não são separáveis linearmente \\u200b\\u200bno espaço de entrada original são\\nfacilmente separáveis\\u200b\\u200b em um espaço de dimensão superior. O separador linear de dimensão\\nsuperior é realmente não linear no espaço original. Isso significa que o espaço de hipótese é\\nexpandido em relação aos métodos que usam representações estritamente lineares.\\n3. Os SVMs são um método não paramétrico — eles mantêm exemplos de treinamento e podem\\nprecisar armazenar todos eles. Por outro lado, na prática, acabam mantendo apenas uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 858}),\n",
       " Document(page_content='pequena fração do número de exemplos — às vezes apenas uma constante pequena vezes o\\nnúmero de dimensões. Assim, os SVMs combinam as vantagens de modelos não paramétricos e\\nparamétricos: eles têm a flexibilidade para representar funções complexas, mas são resistentes\\nà superadaptação.\\nPode-se dizer que os SVMs são bem-sucedidos devido a uma ideia básica e um truque hábil.\\nAbrangeremos um de cada vez. Na \\nFigura 18.30\\n(a), temos um problema de classificação binária com\\ntrês limiares de decisão candidatos, cada um deles um separador linear. Todos são compatíveis com\\ntodos os exemplos; por isso, do ponto de vista da perda 0/1, cada um seria igualmente bom. A\\nregressão logística encontrará alguma linha de separação; a localização exata da linha depende de\\ntodos os pontos de exemplo. A ideia dos SVMs é que alguns exemplos são mais importantes que os\\noutros e prestar atenção a eles pode levar a melhor generalização.\\nFigura 18.30\\n Máquina de vetor de suporte. (a) Duas classes de pontos (preto e círculos brancos) e\\ntrês separadores lineares candidatos. (b) O separador de margem máxima (linha pesada) está no\\nponto médio da margem (área entre as linhas tracejadas). O \\nsuporte vetorial\\n (pontos com grandes\\ncírculos) é o exemplo mais próximo do separador.\\nConsidere a mais baixa de três linhas de separação em (a). Ela chega muito próximo a 5 dos\\nexemplos pretos. Apesar de classificar todos os exemplos corretamente e, portanto, minimizar a\\nperda, ele deve deixá-lo nervoso por tantos exemplos estarem perto da linha; pode ser que outros\\nexemplos pretos fiquem do outro lado da linha.\\nOs SVMs abordam esta questão assim: em vez de minimizar a \\nperda empírica\\n esperada sobre\\ndados de treinamento, eles tentam minimizar a perda de \\ngeneralização\\n esperada. Não sabemos onde\\npodem cair os pontos ainda não vistos, mas, sob o pressuposto probabilístico de que eles são\\nextraídos da mesma distribuição que os exemplos vistos anteriormente, existem alguns argumentos da\\nteoria da aprendizagem computacional (\\nSeção 18.5\\n) sugerindo que minimizemos a perda de\\ngeneralização escolhendo o separador que está mais distante dos exemplos que temos visto até agora.\\nChamamos esse separador, mostrado na \\nFigura 18.30\\n(b), de \\nseparador de margem máxima\\n. A\\nmargem\\n é a largura da zona delimitada pelas linhas tracejadas na figura — duas vezes a distância do\\nseparador até o ponto de exemplo mais próximo.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 859}),\n",
       " Document(page_content='Agora, como encontraremos esse separador? Antes de mostrar as equações, alguma notação:\\ntradicionalmente, os SVMs usam a convenção de que os rótulos de classe são +1 e −1, em vez de +1\\ne 0, que temos usado até agora. Além disso, embora coloquemos o corte no vetor de peso \\nw\\n (e um\\nvalor fictício 1 correspondente em \\nx\\nj\\n,0\\n) os SVMs não fazem isso; eles mantêm o corte como um\\nparâmetro separado \\nb\\n. Com isso em mente, o separador é definido como o conjunto de pontos {\\nx: w ·\\nx\\n + \\nb\\n = 0}. Poderíamos procurar o espaço de \\nw\\n e \\nb\\n com a descida pelo gradiente para encontrar os\\nparâmetros que maximizam a margem e ao mesmo tempo classificar corretamente todos os exemplos.\\nNo entanto, verifica-se que há outra abordagem para resolver esse problema. Não vamos mostrar\\nos detalhes, apenas dizer que há uma representação alternativa chamada de representação dual, em\\nque a solução ótima é encontrada resolvendo\\nsujeito às restrições \\n. Esse é um problema de otimização de \\nprogramação\\nquadrática\\n, para o qual existem bons pacotes de software. Uma vez encontrado o vetor, podemos\\nvoltar a \\nw\\n com a equação \\n ou podemos ficar em representação dual. Existem três\\npropriedades importantes da Equação 18.13. Em primeiro lugar, a expressão é convexa, tem um\\núnico máximo global que pode ser encontrado de forma eficiente. Segundo, os dados \\ninserem a\\nexpressão apenas na forma de produtos escalares de pares de pontos.\\n Essa segunda propriedade é\\ntambém verdadeira para a equação do separador em si; uma vez que o \\na\\nj\\n ótimo foi calculado, é\\nUma propriedade final importante é que os pesos j associados a cada ponto de dados são \\nzero\\n,\\nexceto pelos \\nvetores de suporte\\n — os pontos mais próximos do separador (eles são chamados de\\nvetores de “suporte” porque “sustentam” o plano de separação). Como, normalmente, há muito menos\\nvetores de suporte que exemplos, os SVMs obtêm algumas das vantagens dos modelos paramétricos.\\nE se os exemplos não fossem linearmente separáveis? A \\nFigura 18.31\\n(a) mostra um espaço de\\nentrada definido por atributos \\nx\\n = (\\nx\\n1\\n, x\\n2\\n), com exemplos positivos (\\ny\\n = +1) dentro de uma região\\ncircular e exemplos negativos (\\ny\\n = −1) fora. Certamente não há separador linear para esse problema.\\nSuponha agora que expressemos novamente os dados de entrada, ou seja, façamos o mapeamento de\\ncada vetor de entrada \\nx\\n para um novo vetor de valores característicos, \\nF\\n(\\nx\\n). Em particular, vamos\\nusar as três características', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 860}),\n",
       " Document(page_content='Figura 18.31\\n (a) Um conjunto de treinamento em duas dimensões com exemplos positivos como\\ncírculos pretos e exemplos negativos como círculos brancos. A fronteira de decisão verdadeira\\ntambém é exibida, \\n. (b) Os mesmos dados após o mapeamento em um espaço de entrada\\ntridimensional (\\n). A fronteira de decisão circular em (a) torna-se uma fronteira de\\ndecisão linear em três dimensões. A \\nFigura 18.30\\n(b) dá um \\nclose-up\\n do separador em (b).\\nVeremos em breve de onde eles vieram, mas por ora basta olhar o que acontece. A \\nFigura\\n18.31\\n(b) mostra os dados no espaço novo, tridimensional, definido pelas três características; os\\ndados são \\nlinearmente separáveis\\n nesse espaço! Esse fenômeno é realmente bastante geral: se os\\ndados forem mapeados em um espaço de dimensão suficientemente alta, eles serão quase sempre\\nlinearmente separáveis — se você olhar para um conjunto de pontos de direções suficientes,\\nencontrará uma maneira de fazê-los alinhar-se. Aqui, nós usamos apenas três dimensões;\\n11\\n o\\nExercício 18.16 pede para mostrar que quatro dimensões são suficientes para separar linearmente um\\ncírculo em qualquer lugar no plano (não apenas na origem) e que cinco dimensões são suficientes\\npara separar linearmente qualquer elipse. Em geral (com alguns casos especiais de exceção), se\\ntivermos \\nN\\n pontos de dados, eles serão sempre separados em espaços de \\nN\\n − 1 ou mais dimensões\\n(Exercício 18.25).\\nNormalmente, não esperaríamos encontrar um separador linear no espaço de entrada \\nx\\n, mas\\npodemos encontrar separadores lineares no espaço \\nF\\n(\\nx\\n) de dimensão superior simplesmente\\nsubstituindo \\nx\\nj\\n · \\nx\\nk\\n na Equação 18.13 com \\nF\\n(\\nx\\nj\\n) · \\nF\\n(\\nx\\nk\\n). Isso, por si só, não é notável — substituir \\nx\\npor \\nF\\n(\\nx\\n) em qualquer algoritmo de aprendizagem tem o efeito requerido —, mas o produto escalar\\ntem algumas propriedades especiais. Acontece que \\nF\\n(\\nx\\nj\\n) · \\nF\\n(\\nx\\nk\\n) muitas vezes pode ser calculado\\nsem antes calcular \\nF\\n para cada ponto. Em nosso espaço característico tridimensional definido pela\\nEquação 18.15, um pouco de álgebra mostra que\\n(Essa é a razão pela qual \\n está em \\nf\\n3\\n.) A expressão (\\nx\\nj\\n · \\nx\\nk\\n)\\n2\\n é chamada de \\nfunção kernel\\n,\\n12\\n e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 861}),\n",
       " Document(page_content='geralmente é escrita como \\nK\\n(\\nx\\nj\\n, \\nx\\nk\\n). A função kernel pode ser aplicada a pares de dados de entrada\\npara avaliar produtos escalares em algum espaço característico correspondente. Assim, podemos\\nencontrar separadores lineares em espaços característicos de dimensão superior \\nF\\n(\\nx\\n) simplesmente\\nsubstituindo \\nx\\nj\\n · \\nx\\nk\\n na Equação 18.13 com uma função kernel \\nK\\n(\\nx\\nj\\n, \\nx\\nk\\n). Assim, podemos aprender no\\nespaço de dimensão superior, mas calculamos apenas as funções kernel em vez de uma lista completa\\nde características para cada ponto de dados.\\nA próxima etapa é verificar que não há nada especial sobre o kernel \\nK\\n(\\nx\\nj\\n, \\nx\\nk\\n) = (\\nx\\nj\\n · \\nx\\nk\\n)\\n2\\n.\\nCorresponde a determinado espaço característico de dimensão superior, mas outras funções kernel\\ncorrespondem a outros espaços característicos. Um resultado respeitável em matemática, o teorema\\nde Mercer (1909) informa-nos que qualquer função kernel “razoável”\\n13\\n corresponde a \\nalgum\\n espaço\\ncaracterístico. Esses espaços característicos podem ser muito grandes, mesmo para kernels que\\nparecem inócuos. Por exemplo, o \\nkernel polinomial\\n \\nK\\n(\\nx\\nj\\n, \\nx\\nk\\n) = (1 + \\nx\\nj\\n · \\nx\\nk\\n)\\nd\\n corresponde a um\\nespaço característico cuja dimensão é exponencial em \\nd\\n.\\n Esse é, então, o \\ntruque de kernel\\n inteligente: ligando esses kernels na Equação 18.13 \\npodem\\nser encontrados ótimos separadores lineares de forma eficiente em espaços característicos com\\nbilhões de dimensões (ou, em alguns casos, infinitamente muitas).\\n Os separadores lineares\\nresultantes, quando mapeados de volta ao espaço de entrada original, podem corresponder a\\nfronteiras de decisão arbitrariamente não lineares, sinuosas entre os exemplos positivos e negativos.\\nO caso de dados inerentemente ruidosos pode não querer um separador linear em algum espaço de\\ndimensão superior. Em vez disso, gostaríamos de uma superfície de decisão em um espaço de\\ndimensão inferior que não separe as classes claramente, mas reflita a realidade dos dados ruidosos.\\nIsso é possível com o classificador de \\nmargem suave\\n, que permite que os exemplos caiam no lado\\nerrado da fronteira de decisão, mas lhes atribui a penalidade proporcional à distância necessária\\npara movê-los de volta ao lado correto.\\nO método de kernel pode ser aplicado não apenas a algoritmos de aprendizagem que encontram os\\nmelhores separadores lineares, mas também a qualquer outro algoritmo que possa ser reformulado\\npara funcionar somente com produtos escalares de pares de pontos de dados, como nas Equações\\n18.13 e 18.14. Uma vez que isso seja feito, o produto escalar é substituído por uma função kernel e\\ntemos uma versão kernelizada do algoritmo. Isso pode ser feito facilmente para \\nk\\n-vizinhos mais\\npróximos e para aprendizagem do perceptron (\\nSeção 18.7.2\\n), entre outros.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 862}),\n",
       " Document(page_content='18.10 APRENDIZAGEM POR AGRUPAMENTO\\nAté agora, examinamos métodos para a aprendizagem em que uma única hipótese, escolhida a\\npartir de um espaço de hipóteses, é usada para fazer previsões. A ideia de métodos de\\naprendizagem por agrupamento\\n é selecionar uma coleção inteira ou um agrupamento de hipóteses,\\na partir do espaço de hipóteses, e combinar suas previsões. Por exemplo, durante a validação\\ncruzada poderíamos gerar 20 árvores de decisão diferentes do mesmo conjunto de treinamento e\\ndepois fazê-las votar na melhor classificação para um novo exemplo.\\nA motivação para a aprendizagem por agrupamento é simples. Considere um conjunto de \\nK\\n = 5\\nhipóteses e suponha que combinamos suas previsões usando a votação por maioria simples. Para o\\nconjunto classificar de forma incorreta um novo exemplo, \\npelo menos três das cinco hipóteses têm\\nde classificar o exemplo de modo\\n \\nincorreto\\n. A expectativa é que isso seja muito menos provável\\nque uma classificação incorreta por uma única hipótese. Imagine a seguinte suposição: cada hipótese\\nh\\nk\\n no conjunto tem um erro \\np\\n, isto é, a probabilidade de um exemplo escolhido ao acaso ser\\nclassificado de forma incorreta por \\nh\\nk\\n é \\np\\n. Além disso, imagine que os erros cometidos por cada\\nhipótese sejam \\nindependentes\\n. Nesse caso, se \\np\\n é pequeno, a probabilidade de ocorrer grande\\nnúmero de classificações incorretas é minúscula. Por exemplo, um simples cálculo (Exercício 18.18)\\nmostra que usar um conjunto de cinco hipóteses reduz uma taxa de erros de 1 em10 a uma taxa de\\nerros menor que 1 em 100. Agora, é óbvio que a suposição de independência é pouco razoável\\nporque as hipóteses provavelmente serão iludidas do mesmo modo por quaisquer aspectos enganosos\\ndos dados de treinamento. Porém, se as hipóteses forem pelo menos um pouco diferentes, reduzindo\\nassim a correlação entre seus erros, a aprendizagem por agrupamento poderá ser muito útil.\\nOutro modo de pensar na ideia de conjunto é considerá-lo uma forma genérica de ampliar o espaço\\nde hipóteses. Isto é, pense no próprio conjunto como uma hipótese e no novo espaço de hipóteses\\ncomo o conjunto de todos os conjuntos possíveis que podem ser construídos a partir de hipóteses no\\nespaço original. A \\nFigura 18.32\\n mostra como isso pode resultar em um espaço de hipóteses mais\\nexpressivo. Se o espaço de hipóteses original permitir um algoritmo de aprendizagem simples e\\neficiente, o método de agrupamento fornecerá um caminho para se aprender uma classe muito mais\\nexpressiva de hipóteses, sem incorrer em muita complexidade computacional ou algorítmica\\nadicional.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 863}),\n",
       " Document(page_content='Figura 18.32\\n Ilustração do maior poder expressivo obtido pela aprendizagem por agrupamento.\\nAdotamos três hipóteses de limiar linear, cada uma das quais classifica cada exemplo positivamente\\nno lado não hachurado, e classificamos como positivo qualquer exemplo classificado positivamente\\npelas três hipóteses. A região triangular resultante é uma hipótese que não pode ser expressa no\\nespaço de hipóteses original.\\nO método de agrupamento mais amplamente utilizado é chamado \\naceleração\\n. Para entender como\\nele funciona, primeiro precisamos explicar a ideia de \\nconjunto de treinamento ponderado\\n. Em tal\\nconjunto de treinamento, cada exemplo tem um peso associado \\nw\\nj\\n ≥ 0. Quanto mais alto o peso de um\\nexemplo, mais alta será a importância associada a ele durante a aprendizagem de uma hipótese. É\\nsimples modificar os algoritmos de aprendizagem que vimos até agora para operar com conjuntos de\\ntreinamento ponderados.\\n14\\nA aceleração começa com \\nw\\nj\\n =1 para todos os exemplos (isto é, um conjunto de treinamento\\nnormal). A partir desse conjunto, ele gera a primeira hipótese, \\nh\\n1\\n. Essa hipótese classificará alguns\\ndos exemplos de treinamento de forma correta e outros de forma incorreta. Gostaríamos que a\\npróxima hipótese classificasse melhor os exemplos incorretamente classificados e, assim,\\naumentamos seus pesos enquanto diminuímos os pesos dos exemplos corretamente classificados. A\\npartir desse novo conjunto de treinamento ponderado, geramos a hipótese \\nh\\n2\\n. O processo continua\\ndesse modo até gerarmos \\nK\\n hipóteses, onde \\nK\\n é uma entrada para o algoritmo de aceleração. A\\nhipótese de conjunto final é uma combinação de maioria ponderada de todas as \\nK\\n hipóteses, cada\\numa ponderada de acordo com o seu comportamento no conjunto de treinamento. A \\nFigura 18.33\\nmostra como o algoritmo funciona conceitualmente. Existem muitas variantes da ideia básica de\\naceleração com diferentes modos de ajuste dos pesos e de combinação das hipóteses. Um algoritmo\\nespecífico, denominado ADABOOST, é mostrado na \\nFigura 18.34\\n. Embora os detalhes dos ajustes\\nde peso não sejam tão importantes, o ADABOOST tem uma propriedade muito importante: se o\\nalgoritmo de entrada de aprendizagem \\nL\\n é um algoritmo de \\naprendizagem fraca\\n — o que significa\\nque \\nL\\n sempre retorna uma hipótese com erro ponderado sobre o conjunto de treinamento que é\\nligeiramente melhor que o palpite aleatório (ou seja, 50% para classificação booleana) —, o\\nADABOOST retornará uma hipótese que classifica perfeitamente os dados de treinamento para \\nK\\ngrande o bastante. Desse modo, o algoritmo acelera a exatidão do algoritmo de aprendizagem\\noriginal sobre os dados de treinamento. Esse resultado é válido, independentemente de quanto o\\nespaço de hipóteses original seja inexpressivo e de quanto seja complexa a função que está sendo\\naprendida.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 864}),\n",
       " Document(page_content='Figura 18.33\\n Como funciona o algoritmo de aceleração. Cada retângulo sombreado corresponde a\\num exemplo; a altura do retângulo corresponde ao peso. Os sinais de visto e os sinais cruzados\\nindicam se o exemplo foi ou não classificado corretamente pela hipótese corrente. O tamanho da\\nárvore de decisão indica o peso dessa hipótese no conjunto final.\\nfunção\\n ADABOOST(\\nexemplos, L,K\\n) \\nretorna\\n uma hipótese de maioria ponderada\\n    \\nentradas\\n: \\nexemplos\\n, conjunto de \\nN\\n exemplos identificados (\\nx\\n1\\n, y\\n1\\n), ..., (\\nx\\nN\\n, y\\nN\\n)\\nL\\n, um algoritmo de aprendizagem\\nK\\n, o número de hipóteses no conjunto\\n    \\nvariáveis locais\\n: \\nw\\n, um vetor de \\nN\\n pesos de exemplo, inicialmente 1/\\nN\\nh\\n, um vetor de \\nK\\n hipóteses\\nz\\n, um vetor de \\nK\\n pesos de hipóteses\\n    \\npara\\n \\nk\\n = 1 \\naté\\n \\nK\\n \\nfaça\\n        \\nh\\n[k] ← \\nL\\n(\\nexemplos\\n, \\nw\\n)\\n        \\nerro\\n ← 0\\n        \\npara\\n \\nj\\n = 1 \\naté\\n \\nN\\n \\nfaça\\n            \\nse h\\n[\\nk\\n](\\nx\\nj\\n)\\n ≠ \\ny\\nj\\n \\nentão\\n \\nerro\\n ← \\nerro\\n + \\nw\\n[\\nj\\n]\\n        \\npara\\n \\nj\\n = 1 \\naté\\n \\nN\\n \\nfaça\\n        \\nse h\\n[\\nk\\n](\\nx\\nj\\n) = \\ny\\nj\\n \\nentão w\\n[\\nj\\n] ← \\nw\\n[\\nj\\n] \\n·\\n \\nerro\\n/(1 – \\nerro\\n)\\n        \\nw\\n ← NORMALIZAR(\\nw\\n)\\n        \\nz\\n[\\nk\\n] ← log (1 – \\nerro\\n)/\\nerro\\n    \\nretornar\\n MAIORIA-PONDERADA(\\nh\\n, \\nz\\n)\\nFigura 18.34\\n Variante ADABOOST do método de aceleração para aprendizagem por agrupamentos.\\nO algoritmo gera hipóteses ao responder os exemplos um a um. A função MAIORIA-PONDERADA\\ngera uma hipótese que retorna o valor de saída como voto mais alto entre as hipóteses em \\nh\\n, com os\\nvotos ponderados por \\nz\\n.\\nVejamos como a aceleração se comporta sobre os dados de restaurante. Escolheremos como nosso', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 865}),\n",
       " Document(page_content='espaço de hipóteses original a classe de \\ncepos de decisão\\n, que são árvores de decisão com apenas\\num teste na raiz. A curva mais baixa na \\nFigura 18.35\\n(a) mostra que os cepos de decisão sem\\naceleração não são muito efetivos para esse conjunto de dados, alcançando desempenho de previsão\\nde apenas 81% em 100 exemplos de treinamento. Quando a aceleração é aplicada (com \\nK\\n = 5), o\\ndesempenho é melhor, alcançando 93% depois de 100 exemplos.\\nFigura 18.35\\n (a) Gráfico mostrando o desempenho de cepos de decisão acelerados com M = 5\\nversus\\n cepos de decisão sobre os dados de restaurante. (b) A proporção correta no conjunto de\\ntreinamento, o conjunto de teste como função de M, o número de hipóteses no conjunto. Note que a\\nexatidão do conjunto de teste melhora ligeiramente, mesmo após a exatidão do treinamento alcançar\\n1, isto é, depois que o conjunto se ajusta exatamente aos dados.\\n Um fato interessante ocorre à medida que o tamanho \\nK\\n do conjunto aumenta. A \\nFigura 18.35\\n(b)\\nmostra o desempenho do conjunto de treinamento (em 100 exemplos) como uma função de \\nK\\n. Note\\nque o erro alcança zero quando \\nK\\n é igual a 20, isto é, uma combinação ponderada pela maioria de 20\\ncepos de decisão basta para ajustar exatamente os 100 exemplos. À medida que mais cepos são\\nadicionados ao conjunto, o erro permanece igual a zero. O grafo também mostra \\nque o desempenho\\ndo conjunto de teste continua a aumentar muito tempo depois de o erro do conjunto de\\ntreinamento ter alcançado zero\\n. Em \\nK\\n = 20, o desempenho do teste é 0,95 (ou 0,05 de erro) e o\\ndesempenho aumenta até 0,98 apenas quando \\nK\\n= 137, antes de cair gradualmente para 0,95.\\nEssa descoberta, bastante robusta entre conjuntos de dados e espaços de hipótese, surgiu como\\ngrande surpresa quando foi notada pela primeira vez. A navalha de Ockham nos diz que não devemos\\ntornar as hipóteses mais complexas do que o necessário, mas o gráfico nos diz que as previsões\\nmelhoram à medida que a hipótese de conjunto fica mais complexa! Várias explicações foram\\npropostas para isso. Uma visão é que a aceleração se aproxima da aprendizagem bayesiana (veja o\\nCapítulo 20), que podemos mostrar ser um algoritmo de aprendizagem ótimo, e a aproximação\\nmelhora à medida que mais hipóteses são adicionadas. Outra explicação possível é que a inclusão de\\nhipóteses adicionais permite ao conjunto ser mais definido em sua distinção entre exemplos positivos\\ne negativos, o que ajuda quando se trata de classificar novos exemplos.\\n18.10.1 Aprendizagem on-line', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 866}),\n",
       " Document(page_content='Até agora, tudo o que fizemos neste capítulo baseou-se no pressuposto de que os dados são i.i.d.\\n(independentes e identicamente distribuídos). Por um lado, isso é uma suposição sensata: se o futuro\\nnão tem nenhuma semelhança com o passado, como podemos prever alguma coisa? Por outro lado, há\\numa suposição muito forte: é raro que as nossas entradas tenham capturado todas as informações que\\ntornariam o futuro verdadeiramente independente do passado.\\nNesta seção, vamos examinar o que fazer quando os dados não são i.i.d., quando eles podem\\nmudar ao longo do tempo. Nesse caso, importa \\nquando\\n faremos uma previsão, por isso vamos adotar\\na perspectiva chamada de \\naprendizagem on-line\\n: um agente recebe uma entrada \\nx\\nj\\n da natureza,\\nprevê o \\ny\\nj\\n correspondente e, em seguida, recebe a resposta correta. O processo então se repete com\\nx\\nj\\n+1\\n, e assim por diante. Pode-se pensar que essa tarefa é impossível — se a natureza for\\ncontraditória, todas as previsões podem estar erradas. Acontece que podemos ter algumas garantias.\\nVamos considerar a situação em que a nossa entrada consiste em previsões de um painel de\\nespecialistas. Por exemplo, a cada dia um conjunto de \\nK\\n especialistas prevê se o mercado de ações\\nvai subir ou baixar, e nossa tarefa é estabelecer associação sobre essas previsões e torná-las nossas\\npróprias. Uma maneira de fazer isso é acompanhar a \\nperformance\\n de cada especialista e escolher\\nconfiar neles, na proporção de seus resultados passados. Isso é chamado de \\nalgoritmo aleatório de\\nmaioria ponderada\\n. Podemos descrevê-los mais formalmente:\\n1. Inicializar com 1 um conjunto de pesos {\\nw\\n1\\n,…, \\nw\\nk\\n} todos com 1.\\n2. Receber as previsões {\\n} dos especialistas.\\n3. Escolher aleatoriamente um especialista \\nk\\n*, em proporção ao seu peso: \\n.\\n4. Prever \\n.\\n5. Receber a resposta correta \\ny\\n.\\n6. Para cada especialista \\nk\\n tal que \\n, atualizar \\nw\\nk\\n ← \\nβw\\nk\\n.\\nAqui \\nβ\\n é um número, de 0 < \\nβ\\n <1, que informa o quanto penalizar um especialista por cada erro.\\nMedimos o sucesso desse algoritmo em termos de \\narrependimento\\n, que é definido como o número\\nde erros adicionais que fazemos em relação ao especialista que, em retrospectiva, teve o melhor\\nregistro de previsão. Seja \\nM\\n* o número de erros cometidos pelos melhores especialistas. A seguir, o\\nnúmero de erros, \\nM\\n, cometidos pelo algoritmo aleatório de maioria ponderada, é limitado por\\n15\\nEsse limite vale para \\nqualquer\\n sequência de exemplos, até mesmo os escolhidos pelos\\nadversários tentando fazer o pior. Para ser mais específico, quando houver \\nK\\n = 10 especialistas, se\\nescolhermos \\nβ\\n = 1/2 o número de erros será delimitado por 1,39\\nM\\n* + 4,6 e, se \\nβ\\n = 3/4 por 1,15\\nM\\n* +\\n9,2. Em geral, se \\nβ\\n estiver próximo de 1, somos suscetíveis às mudanças em longo prazo; se o melhor\\nespecialista mudar, vamos assimilar antes que seja tarde. No entanto, pagamos uma penalidade no\\ninício, quando começamos igualmente com todos os especialistas de confiança; podíamos aceitar o\\nconselho dos maus especialistas por muito tempo. Quando \\nb\\n está próximo de 0, esses dois fatores\\nestão invertidos. Note que podemos escolher \\nb\\n para chegar assintoticamente perto de \\nM\\n* em longo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 867}),\n",
       " Document(page_content='prazo; isso se chama \\naprendizagem sem nenhum arrependimento\\n (porque a quantidade média de\\narrependimento por tentativa tende a 0 à medida que o número de tentativas aumenta).\\nA aprendizagem on-line é útil quando os dados podem estar mudando rapidamente ao longo do\\ntempo. Também é útil para aplicações que envolvem grande coleção de dados que está em constante\\ncrescimento, mesmo se as mudanças forem graduais. Por exemplo, com um banco de dados de\\nmilhões de imagens da Web, você não vai querer experimentar, digamos, um modelo de regressão\\nlinear em todos os dados e em seguida treinar de novo a partir do zero toda vez que uma imagem\\nnova for adicionada. Seria mais prático ter um algoritmo on-line que permitisse que as imagens\\nfossem acrescentadas aos poucos. Para a maioria dos algoritmos de aprendizagem baseados na\\nminimização de perdas, existe uma versão on-line baseada na minimização do arrependimento. É um\\nbônus que muitos desses algoritmos on-line vêm com limites garantidos contra o arrependimento.\\nPara alguns observadores, é surpreendente existir limites tão justos de quão bem se pode comparar\\na um quadro de especialistas. Para outros, é realmente surpreendente que, quando um quadro de\\nespecialistas humanos se reúne — previsão do preço das ações no mercado, resultados desportivos\\nou disputas políticas —, o público que observa é tão desejoso de vê-los acertar e de não quantificar\\nas suas taxas de erro.\\n18.11 APRENDIZAGEM DE MÁQUINA NA PRÁTICA\\nIntroduzimos ampla gama de técnicas de aprendizagem de máquina, cada uma ilustrada com tarefas\\nsimples de aprendizagem. Nesta seção, consideraremos dois aspectos da aprendizagem de máquina\\nna prática. O primeiro envolve encontrar algoritmos capazes de aprender a reconhecer dígitos\\nescritos à mão e tirar deles até a última gota de previsão de desempenho. O segundo envolve nada\\nalém de apontar que a obtenção, a limpeza e a representação dos dados é pelo menos tão importante\\nquanto a engenharia do algoritmo.\\n18.11.1 Estudo de caso: o reconhecimento de dígitos escritos à mão\\nReconhecer dígitos escritos à mão é um problema importante com muitas aplicações, incluindo\\nclassificação automática de correspondências por código postal, leitura automática de cheques e\\ndevolução de impostos, e entrada de dados para computadores manuais. É uma área que\\nexperimentou progresso rápido, em parte devido a melhores algoritmos de aprendizagem e em parte\\npor causa da disponibilidade de melhores conjuntos de treinamento. O United States National\\nInstitute of Science and Technology (\\nNIST\\n) colocou em arquivo um banco de dados de 60.000\\ndígitos rotulados, cada um com 20 × 20 = 400 pixels com valores de 8 bits em tons de escala de\\ncinza. Tornou-se um dos problemas de referência-padrão para a comparação de novos algoritmos de\\naprendizagem. Como exemplo são mostrados alguns dígitos na \\nFigura 18.36\\n.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 868}),\n",
       " Document(page_content='Figura 18.36\\n Exemplos do banco de dados NIST de dígitos escritos à mão. Linha superior: exemplos\\nde dígitos 0-9, fáceis de identificar. Linha inferior: exemplos dos mesmos dígitos, mais difíceis de\\nidentificar.\\nForam tentadas muitas abordagens de aprendizagem diferentes. Uma das primeiras, e\\nprovavelmente a mais simples, é o classificador de \\ntrês vizinhos mais próximos\\n, que também tem a\\nvantagem de não necessitar de tempo de treinamento. Como um algoritmo baseado em memória, no\\nentanto, deve armazenar todas as 60.000 imagens, e seu desempenho em tempo de execução fica\\nlento. Alcançou taxa de erro de teste de 2,4%.\\nPara esse problema foi projetada uma \\nrede neural de camada oculta única\\n com 400 unidades de\\nentrada (uma por pixel) e 10 unidades de saída (uma por classe). Usando validação cruzada,\\nverificou-se que cerca de 300 unidades ocultas apresentaram o melhor desempenho. Com\\ninterconexão total entre as camadas, havia um total de 123.300 pesos. Essa rede alcançou taxa de\\nerro de 1,6%.\\nUma série de \\nredes neurais especializadas\\n chamada LeNet foi concebida para tirar partido da\\nestrutura do problema — que a entrada consistisse em pixels em uma matriz bidimensional e que\\npequenas mudanças na posição ou inclinação de uma imagem não fossem importantes. Cada rede\\ntinha uma camada de entrada de 32 × 32 unidades, onde 20 × 20 pixels eram centrados de modo que\\ncada unidade de entrada era apresentada com uma vizinhança local de pixels. Isso foi seguido por\\ntrês camadas de unidades ocultas. Cada camada consistia em vários planos de matrizes \\nn\\n × \\nn\\n, onde \\nn\\nera menor que a camada anterior para que a rede reduzisse a qualidade da amostragem de entrada e\\nonde os pesos de cada unidade em um plano eram obrigados a ser idênticos, de modo que o plano\\nagisse como um detector de característica: podia escolher uma característica, como uma longa linha\\nvertical ou um arco semicircular curto. A camada de saída tinha 10 unidades. Muitas versões dessa\\narquitetura foram experimentadas, uma representativa tinha camadas ocultas com 768, 192 e 30\\nunidades, respectivamente. O conjunto de treinamento foi aumentado através da aplicação de\\ntransformações afins para as entradas reais: deslocamento, rotação suave e dimensionamento de\\nimagens (certamente as transformações tinham de ser pequenas ou um 6 era transformado em um 9!).\\nA melhor taxa de erro alcançado pela LeNet foi de 0,9%.\\nUma \\nrede neural acelerada\\n combinou três cópias da arquitetura LeNet, com uma segunda treinada\\nem uma mistura de padrões que a primeira obtendo 50% de erro, e a terceira treinada em padrões\\ndos quais as duas primeiras discordavam. Durante o teste, as três redes votaram com a decisão da\\nmaioria. A taxa de erro de teste foi de 0,7%.\\nUma \\nmáquina de vetor de suporte\\n (veja a \\nSeção 18.9\\n) com 25.000 vetores de suporte alcançou\\ntaxa de erro de 1,1%. Isso é notável porque a técnica SVM, como a abordagem simples de vizinho\\nmais próximo que quase não exige raciocínio ou experimentação iterada por parte do desenvolvedor,\\nainda chegou perto do desempenho de LeNet, que teve anos de desenvolvimento. De fato, a máquina', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 869}),\n",
       " Document(page_content='de vetor de suporte não faz uso da estrutura do problema, e terá um bom desempenho se os pixels\\nforem apresentados em ordem permutada.\\nUma \\nmáquina de vetor de suporte virtual\\n inicia com um SVM regular e, em seguida, o melhora\\ncom uma técnica projetada para tirar vantagem da estrutura do problema. Em vez de permitir\\nprodutos de todos os pares de pixels, essa abordagem concentra-se em kernels formados a partir de\\npares de pixels próximos. Também aumenta o conjunto de treinamento com as transformações dos\\nexemplos, como o LeNet fazia. A SVM virtual alcançou a melhor taxa de erro registrada até hoje,\\n0,56%.\\nO \\ncasamento de formas\\n é uma técnica de visão computacional usada para alinhar as partes\\ncorrespondentes de duas imagens diferentes de objetos (Belongie \\net al\\n., 2002). A ideia é escolher um\\nconjunto de pontos em cada uma das duas imagens, e depois calcular, para cada ponto na primeira\\nimagem, a qual ponto da segunda imagem corresponde. A partir desse alinhamento, calculamos uma\\ntransformação entre as imagens. A transformação nos dá uma medida da distância entre as imagens.\\nEssa medida de distância é mais motivadora do que apenas contar o número de pixels diferentes, e\\nverifica-se que o algoritmo 3-vizinho mais próximo, usando essa medida de distância, executa muito\\nbem. Em um treinamento em apenas 20.000 dos 60.000 dígitos, e usando 100 pontos de amostra por\\nimagem extraída de um detector de bordas Canny, um classificador de encaixe de formas alcançou\\nerro de teste de 0,63%.\\nEstima-se que os \\nseres humanos\\n tenham taxa de erro de cerca de 0,2% sobre esse problema. Essa\\nquantidade é um pouco suspeita porque os seres humanos não foram testados de forma tão extensiva\\nquanto os algoritmos de aprendizagem de máquina. Em um conjunto de dados de dígitos semelhantes\\ndo correio americano, os erros humanos foram de 2,5%.\\nA tabela a seguir resume as taxas de erro, desempenho de tempo de execução, requisitos de\\nmemória e a quantidade de tempo de treinamento para os sete algoritmos que discutimos. Adiciona\\ntambém outra medida: o percentual de dígitos que deve ser rejeitado para alcançar 0,5% de erro. Por\\nexemplo, se for permitido que o SVM rejeite 1,8% das entradas, ou seja, passe-as para que alguém\\nfaça o julgamento final, sua taxa de erro em 98,2% do restante da entrada será reduzida de 1,1% para\\n0,5%.\\nA tabela a seguir resume a taxa de erro e algumas das outras características das sete técnicas que\\ndiscutimos.\\n3\\nRN\\n300\\nOculto\\nLeNet\\nLeNet\\nAcelerado\\nSVM\\nSVM\\nVirtual\\nCasamento\\nde Formas\\nTaxa de erro (pct.)\\n2,4\\n1,6\\n0,9\\n0,7\\n1,1\\n0,56\\n0,63\\nTempo de execução (milissegundos/dígito)\\n1.000\\n10\\n30\\n50\\n2000\\n200\\nRequisitos de memória (Mbyte)\\n12\\n0,49\\n0,012\\n0,21\\n11\\nTempo de treinamento (dias)\\n0\\n7\\n14\\n30\\n10\\n% rejeitados para atingir 0,5% de erro\\n8,1\\n3,2\\n1,8\\n0,5\\n1,8\\n18.11.2 Estudo de caso: sentido das palavras e preços das casas', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 870}),\n",
       " Document(page_content='Para simular a ideia de um livro, vamos lidar com dados simples: um conjunto pequeno de dados,\\ngeralmente em duas dimensões. Em aplicações práticas de aprendizagem de máquina, entretanto, o\\nconjunto de dados geralmente é grande, multidimensional e bagunçado. Os dados não são entregues\\nao analista em um conjunto pré-empacotado de valores (\\nx\\n, \\ny\\n), mas o analista terá de conseguir os\\ndados corretos. Há uma tarefa a ser cumprida, e a maioria dos problemas de engenharia é decidir que\\ndados são necessários para realizar a tarefa; a menor parte é a escolha e a implementação de um\\nmétodo de aprendizagem de máquina apropriado para processar os dados. A \\nFigura 18.37\\n mostra um\\nexemplo típico do mundo real, comparando cinco algoritmos de aprendizagem na tarefa da\\nclassificação do sentido da palavra (dada uma sentença como “O banco dobrou”, classificar a\\npalavra “banco” como “moeda bancária” ou “banco de rio”). O ponto é que os pesquisadores de\\naprendizado de máquina têm focado principalmente na direção vertical: posso inventar um novo\\nalgoritmo de aprendizagem que desempenha melhor do que os algoritmos publicados anteriormente\\nem um conjunto de treinamento padrão de um milhão de palavras? Mas o grafo mostra que há mais\\nespaço para melhorias na direção horizontal: em vez de inventar um novo algoritmo, tudo o que é\\nnecessário é juntar 10 milhões de palavras de dados de treinamento; mesmo o \\npior\\n algoritmo com 10\\nmilhões de palavras desempenha melhor do que o melhor algoritmo com um milhão. Enquanto\\nreunimos ainda mais dados, as curvas continuam a subir, superando as diferenças entre os algoritmos.\\nFigura 18.37\\n Curvas de aprendizagem de cinco algoritmos de aprendizagem em uma tarefa comum.\\nObserve que parece haver mais espaço para melhoria na direção horizontal (mais dados de\\ntreinamento) do que na direção vertical (algoritmo de aprendizagem de máquina diferente). Adaptada\\nde Banko e Brill (2001).\\nConsidere outro problema: a tarefa de estimar o valor verdadeiro das casas que estão à venda. Na\\nFigura 18.13\\n mostramos uma versão em miniatura do problema, fazendo a regressão linear do\\ntamanho da casa pelo preço de compra. Você deve ter notado muitas limitações desse modelo.\\nPrimeiro, está medindo a coisa errada: queremos estimar o preço de venda de uma casa, não o preço\\nde compra. Para resolver essa tarefa vamos precisar de dados sobre as vendas reais. Mas isso não\\nsignifica que devemos desconsiderar os dados de preço de compra — podemos usá-los como um dos\\nrecursos de entrada. Além do tamanho da casa, vamos precisar de mais informações: o número de\\nsalas, quartos e banheiros, se a cozinha e os banheiros foram reformados recentemente, a idade da\\ncasa; também vamos precisar de informações sobre o lote e a vizinhança. Mas como definir\\nvizinhança? Pelo CEP? E se parte do CEP estiver do lado “errado” da estrada ou do trilho do tem, e', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 871}),\n",
       " Document(page_content='a outra parte é que é desejável? E sobre o distrito escolar? O \\nnome\\n do distrito escolar deve ser uma\\ncaracterística ou os \\nresultados médios dos testes\\n? Além de decidir que características incluir,\\nteremos de lidar com dados faltantes; áreas diferentes têm costumes diferentes sobre que dados\\ndevem ser relatados e, em casos individuais, estará sempre faltando alguns dados. Se os dados que\\ndeseja não estão disponíveis, talvez você possa estabelecer um site de rede social para incentivar as\\npessoas a compartilharem e corrigirem os dados. No final, esse processo de decidir que\\ncaracterísticas usar, e como usá-las, é tão importante como escolher entre regressão linear, árvores\\nde decisão ou alguma outra forma de aprendizagem.\\nDito isto, deve-se escolher um método (ou métodos) para um problema. Não há garantia de\\nescolher o melhor método, mas há algumas diretrizes rudimentares. As árvores de decisão são ideais\\nquando há uma porção de características discretas e você acredita que muitas delas possam ser\\nirrelevantes. Os métodos não paramétricos são bons quando há uma porção de dados e nenhum\\nconhecimento anterior, e quando não se quer se preocupar muito com a escolha das características\\ncorretas (desde que haja menos de 20). Entretanto, os métodos não paramétricos, geralmente,\\nfornecem uma função \\nh\\n que é mais cara para ser executada. As máquinas de vetores de suporte são\\nmuitas vezes consideradas o melhor método para a primeira tentativa, desde que o conjunto de dados\\nnão seja muito grande.\\n18.12 RESUMO\\nEste capítulo se concentrou na aprendizagem indutiva de funções determinísticas a partir de\\nexemplos. Os principais pontos foram:\\n•  A aprendizagem assume muitas formas, dependendo da natureza do agente, do componente a ser\\naperfeiçoado e da realimentação disponível.\\n•  Se a realimentação disponível fornece a resposta correta para o exemplo de entrada, o problema\\nde aprendizagem será chamado \\naprendizagem supervisionada\\n. A tarefa é aprender uma função \\ny\\n= h\\n(\\nx\\n). A aprendizagem de uma função de valores discretos é chamada de \\nclassificação\\n; a\\naprendizagem de uma função contínua é chamada de \\nregressão\\n.\\n•  A aprendizagem indutiva envolve encontrar uma hipótese consistente que concorde com os\\nexemplos. A \\nnavalha de Ockham\\n sugere escolher a hipótese consistente mais simples. A\\ndificuldade dessa tarefa depende da representação escolhida.\\n•  As \\nárvores de decisão\\n podem representar todas as funções booleanas. A heurística de \\nganho de\\ninformações\\n fornece um método eficiente para encontrar uma árvore de decisão simples e\\nconsistente.\\n•  O desempenho de um algoritmo de aprendizagem é medido pela \\ncurva de aprendizagem\\n, que\\nmostra a exatidão da previsão no \\nconjunto de teste\\n como uma função do tamanho do \\nconjunto\\nde treinamento\\n.\\n•  Quando existem vários modelos para escolher, pode-se utilizar a \\nvalidação cruzada\\n para\\nselecionar um modelo que vai generalizar bem.\\n•  Às vezes, nem todos os erros são iguais. A \\nfunção de perda\\n informa o quão ruim é cada erro; o\\nobjetivo é, então, minimizar a perda de um conjunto de validação.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 872}),\n",
       " Document(page_content='•  A \\nteoria de aprendizagem computacional\\n analisa a complexidade de amostra e a complexidade\\ncomputacional da aprendizagem indutiva. Existe um compromisso entre a expressividade da\\nlinguagem de hipóteses e a facilidade de aprendizagem.\\n•  A \\nregressão linear\\n é um modelo amplamente utilizado. Os parâmetros ótimos de um modelo de\\nregressão linear podem ser encontrados pela busca do gradiente de descida ou calculados com\\nexatidão.\\n•  Um classificador linear com um limiar difícil — também conhecido como \\nperceptron\\n — pode\\nser treinado por uma simples regra de atualização de peso para ajustar os dados que são\\nlinearmente separáveis\\n. Em outros casos, a regra não consegue convergir.\\n•  A \\nregressão logística\\n substitui o limiar rígido do perceptron por um limiar suave definido por\\numa função logística. O gradiente de descida funciona bem, mesmo para dados ruidosos que não\\nsão linearmente separáveis.\\n•  As \\nredes neurais\\n representam funções não lineares complexas com uma rede de unidades de\\nfronteira linear. A expressão redes neurais de alimentação para a frente pode representar\\nqualquer função, dadas unidades suficientes. O algoritmo de \\nretropropagação\\n implementa um\\ngradiente de descida no espaço de parâmetros para minimizar o erro de saída.\\n•  Os \\nmodelos não paramétricos\\n usam todos os dados para fazer cada previsão, em vez de tentar\\nprimeiro resumir os dados com alguns parâmetros. Os exemplos incluem \\nvizinhos mais\\npróximos\\n e \\nregressão ponderada localmente\\n.\\n•  As \\nmáquinas de vetores de suporte\\n encontram separadores lineares com \\nmargem máxima\\n para\\nmelhorar o desempenho de generalização do classificador. Os \\nmétodos do kernel\\n transformam\\nos dados de entrada implicitamente em um espaço de dimensão superior onde pode existir um\\nseparador linear, mesmo se os dados originais forem não separáveis.\\n•  Métodos de agrupamento, tais como de \\naceleração\\n, sempre desempenham melhor do que\\nmétodos individuais. Em \\naprendizagem on-line\\n, podemos agregar opiniões de especialistas\\npara chegar arbitrariamente perto do melhor desempenho do especialista, mesmo quando a\\ndistribuição dos dados estiver em constante mutação.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nO Capítulo 1 esboçou a história de investigações filosóficas em aprendizagem indutiva. Guilherme\\nde Ockham\\n16\\n (1280-1349), o filósofo mais influente de seu século e um importante colaborador para\\na epistemologia, a lógica e a metafísica medieval, é considerado o autor de uma declaração\\ndenominada “navalha de Ockham” — em latim, \\nEntia non sunt multiplicanda praeter neces\\nsitatem\\n(“As entidades não devem ser multiplicadas além da necessidade”). Infelizmente, esse louvável\\nconselho não é encontrado em nenhum lugar em seus escritos exatamente com essas palavras (embora\\nele tenha dito que “não se deve colocar a maioria sem necessidade”). Em 350 a.C., na \\nFísica\\n, livro I,\\ncapítulo VI, Aristóteles exprimiu um sentimento semelhante: “O mais limitado, se adequado, é\\nsempre preferível.”\\nO primeiro uso notável de árvores de decisão foi em EPAM, o “Elementary Perceiver And\\nMemorizer” (Feigenbaum, 1961), que era uma simulação do conceito humano de aprendizagem. O\\nID3 (Quinlan, 1979) acrescentou a ideia fundamental de escolher o atributo com entropia máxima; é a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 873}),\n",
       " Document(page_content='base para o algoritmo de árvore de decisão neste capítulo. A teoria da informação propriamente dita\\nfoi desenvolvida por Claude Shannon para auxiliar no estudo de comunicação (Shannon e Weaver,\\n1949). (Shannon também contribuiu com um dos mais antigos exemplos de aprendizagem de máquina,\\num camundongo mecânico denominado Theseus que aprendeu a percorrer um labirinto por tentativa e\\nerro.) O método \\nχ\\n2\\n de poda de árvore foi descrito por Quinlan (1986). O C4.5, um pacote de árvore\\nde decisão com fins industriais, pode ser encontrado em Quinlan (1993). Uma tradição independente\\nda aprendizagem de árvores de decisão existe na literatura estatística. \\nClassification and Regression\\nTrees\\n (Breiman \\net al\\n., 1984), conhecido como “livro CART”, é a principal referência.\\nA \\nvalidação cruzada\\n foi introduzida pela primeira vez por Larson (1931), e de uma forma\\npróxima da que foi apresentada por Stone (1974) e Golub \\net al\\n. (1979). Deve-se a Tikhonov (1963)\\no procedimento de regularização. Guyon e Elisseeff (2003) apresentaram um artigo de revista\\ndedicada ao problema de seleção de característica. Banko e Brill (2001) e Halevy \\net al\\n. (2009)\\ndiscutiram as vantagens de utilização de grandes quantidades de dados. Foi Robert Mercer,\\npesquisador e orador, que disse em 1985: “Não há dados como mais dados.” Lyman e Varian (2003)\\nestimam que, em 2002, foram produzidos cerca de 5 exabytes (5 × 10\\n18\\n bytes) de dados e que a taxa\\nde produção dobra a cada três anos.\\nA análise teórica de algoritmos de aprendizagem teve início com o trabalho de Gold (1967) em\\nidentificação no limite\\n. Essa abordagem foi motivada em parte por modelos de descoberta científica\\na partir da filosofia da ciência (Popper, 1962), mas foi aplicada principalmente ao problema de\\naprender gramáticas a partir de exemplo de sentenças (Osherson \\net al\\n., 1986).\\nEnquanto a abordagem de identificação no limite se concentra na convergência ao final, o estudo\\nda \\ncomplexidade de Kolmogorov\\n ou \\ncomplexidade algorítmica\\n, desenvolvido independentemente\\npor Solomonoff (1964) e por Kolmogorov (1965), tenta fornecer uma definição formal para a noção\\nde simplicidade usada na lâmina de Ockham. Para escapar do problema de que a simplicidade\\ndepende do modo como a informação é representada, ele propôs que a simplicidade fosse medida\\npelo comprimento do programa mais curto para uma máquina de Turing universal que reproduz\\ncorretamente os dados observados. Embora existam muitas máquinas de Turing universais possíveis\\ne, consequentemente, muitos programas “mais curtos” possíveis, esses programas diferem em\\ncomprimento por, no máximo, uma constante que é independente da quantidade de dados. Essa bela\\nideia, que mostra em essência que qualquer desvio de representação inicial vai eventualmente ser\\nsuperado pelos próprios dados, só é arruinada pela indecidibilidade do cálculo do comprimento do\\nprograma mais curto. Em vez disso, podem ser usadas medidas aproximadas como o \\ncomprimento\\nmínimo de descrição\\n, ou CMD (Rissanen, 1984), e elas têm produzido excelentes resultados na\\nprática. O texto de Li e Vitanyi (1993) é a melhor fonte para estudo da complexidade de\\nKolmogorov.\\nA teoria de aprendizagem computacional — isto é, a teoria de aprendizagem PAC foi inaugurada\\npor Leslie Valiant (1984). Seu trabalho destacou a importância da complexidade computacional e de\\namostras. Com Michael Kearns (1990), Valiant mostrou que várias classes de conceitos não podem\\nser aprendidas de forma tratável com a utilização da aprendizagem PAC, embora existam\\ninformações suficientes disponíveis nos exemplos. Alguns resultados positivos foram obtidos para\\nclasses como listas de decisão (Rivest, 1987).\\nUma tradição independente da análise de complexidade de amostra existia em estatística, desde o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 874}),\n",
       " Document(page_content='trabalho em \\nteoria de convergência uniforme\\n (Vapnik e Chervonenkis, 1971). A chamada \\ndimensão\\nVC\\n fornece uma medida aproximadamente análoga, embora mais complexa que a medida ln|\\n| obtida\\na partir da análise PAC. A dimensão VC pode ser aplicada a classes de funções contínuas, às quais a\\nanálise PAC padrão não se aplica. A teoria de aprendizagem PAC e a teoria VC foram conectadas\\nprimeiro pelos “quatro alemães” (nenhum dos quais é realmente alemão): Blumer, Ehrenfeucht,\\nHaussler e Warmuth (1989).\\nA regressão linear com a perda de erro quadrático remonta a Legendre (1805) e Gauss (1809), que\\ntrabalhavam na previsão de órbitas ao redor do Sol. O uso moderno da regressão multivariada para a\\naprendizagem de máquina for coberto em textos como de Bishop (2007). Ng (2004) analisou as\\ndiferenças entre a regularização \\nL\\n1\\n e \\nL\\n2\\n.\\nA expressão \\nfunção logística\\n vem de Pierre-François Verhulst (1804-1849), um estatístico que\\nusou a curva para modelar o crescimento da população com recursos limitados, um modelo mais\\nrealista do que o crescimento geométrico sem restrições proposto por Thomas Malthus. Verhulst\\nchamou-a de \\ncourbe logistique\\n, por causa de sua relação com a curva logarítmica. O termo\\nregressão\\n é devido a Francis Galton, estatístico do século XIX, primo de Charles Darwin e\\nprecussor dos campos da meteorologia, análise de impressões digitais e correlação estatística, que o\\nusou no sentido de regressão até a média. A expresssão \\nmaldição da dimensionalidade\\n vem de\\nRichard Bellman (1961).\\nA regressão logística pode ser resolvida com o gradiente de descida ou com o método de Newton-\\nRaphson (Newton, 1671; Raphson, 1690). Uma variante do método de Newton, chamada L-BFGS,\\nalgumas vezes é utilizada para problemas de grandes dimensões; o \\nL\\n mede a “ memória ilimitada”,\\nsignificando que evita a criação de matrizes completas de uma só vez e cria partes delas\\nrapidamente. BFGS são as iniciais dos autores (Byrd \\net al\\n., 1995).\\nOs modelos de vizinhos mais próximos datam pelo menos de Fix e Hodges (1951) e, desde então,\\ntêm sido uma ferramenta-padrão em estatística e reconhecimento de padrões. Em IA, foram\\npopularizados por Stanfill e Waltz (1986), que investigaram métodos para adaptar a distância\\nmétrica aos dados. Hastie e Tibshirani (1996) desenvolveram uma maneira de localizar a métrica\\npara cada ponto no espaço, dependendo da distribuição dos dados em torno desse ponto. Gionis \\net\\nal\\n. (1999) introduziram a localidade de hash sensível, que revolucionou a recuperação de objetos\\nsimilares em espaços de dimensão superior, especialmente em visão computacional. Andoni e Indyk\\n(2006) forneceram recentemente uma pesquisa de métodos HSL e afins.\\nAs ideias por trás das máquinas de kernel vêm de Aizerman \\net al\\n. (1964) (que também\\nintroduziram o truque kernel), mas o pleno desenvolvimento da teoria é devido a Vapnik e seus\\ncolegas (Boser \\net al.\\n, 1992). Os SVMs tornaram-se práticos com a introdução do classificador de\\nmargem suave para lidar com dados ruidosos em um artigo que ganhou o 2008 ACM Theory and\\nPractice Award (Cortes e Vapnik, 1995), e o algoritmo Sequential Minimal Optimization (SMO)\\npara resolver de forma eficiente problemas usando programação quadrática SVM (Platt, 1999). Os\\nSVMs provaram ser muito populares e eficazes para tarefas como a categorização de texto\\n(Joachims, 2001), genômica computacional (Cristianini e Hahn, 2007) e processamento de linguagem\\nnatural, tais como o reconhecimento de dígitos manuscritos de DeCoste e Schölkopf (2002). Como\\nparte desse processo foram concebidos muitos novos kernels que trabalham com strings, árvores e\\noutros tipos de dados não numéricos. Uma técnica relacionada que também usa o truque do kernel', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 875}),\n",
       " Document(page_content='para representar implicitamente um espaço característico exponencial é o perceptron votado (Freund\\ne Schapire, 1999; Collins e Duffy, 2002). Livros sobre SVMs incluem Cristianini e Shawe-Taylor\\n(2000) e Schölkopf e Smola (2002). Uma exposição mais amigável apareceu em um artigo da \\nAI\\nMagazin\\n por Cristianini e Schölkopf (2002). Bengio e LeCun (2007) mostraram algumas das\\nlimitações de SVMs e outros locais, métodos não paramétricos para funções de aprendizagem que\\ntêm estrutura global, mas não têm a suavidade local.\\nA aprendizagem de agrupamento é uma técnica cada vez mais popular para melhorar o\\ndesempenho de algoritmos de aprendizagem. O \\nensacamento\\n (Breiman, 1996), o primeiro método\\neficaz, combina hipóteses aprendidas a partir de múltiplos conjunto de dados \\nbootstrap\\n, cada um\\ngerado subamostrando o conjunto de dados original. O método de aceleração descrito neste capítulo\\noriginou-se com o trabalho teórico de Schapire (1990). O algoritmo ADABOOST foi desenvolvido\\npor Freund e Schapire (1996) e analisado teoricamente por Schapire (2003). Friedman \\net al\\n. (2000)\\nexplicaram a aceleração do ponto de vista de um estatístico. A aprendizagem on-line foi abrangida\\nem uma pesquisa realizada pela Blum (1996) e um livro por Cesa-Bianchi e Lugosi (2006). Dredze\\net al.\\n (2008) introduziram a ideia de aprendizagem on-line de confiança ponderada para a\\nclassificação: além de manter um peso para cada parâmetro, mantém também uma medida de\\nconfiança, de modo que um novo exemplo pode ter grande efeito sobre os recursos que eram\\nraramente vistos antes (e, portanto, tinha baixo nível de confiança) e um pequeno efeito sobre as\\ncaracterísticas comuns que já tinham sido bem estimadas.\\nA literatura sobre redes neurais é demasiado grande (aproximadamente 150 mil artigos até hoje),\\npara cobrir em detalhe. Cowan e Sharp (1988b, 1988a) pesquisaram o início da história, começando\\ncom o trabalho de McCulloch e Pitts (1943). (Como mencionado no Capítulo 1, John McCarthy\\napontou para o trabalho de Nicolas Rashevsky (1936, 1938) como o primeiro modelo matemático de\\naprendizagem neural.) Norbert Wiener, um dos pioneiros da cibernética e da teoria de controle\\n(Wiener, 1948), trabalhou com McCulloch e Pitts, e influenciou uma série de jovens investigadores,\\nincluindo Marvin Minsky, que pode ter sido o primeiro a desenvolver uma rede neural em\\nfuncionamento em hardware em 1951 (ver Minsky e Papert, 1988, p. ix-x). Turing (1948) escreveu\\numa pesquisa-relatório intitulada \\nIntelligent Machinery\\n, que começa com a sentença “proponho\\ninvestigar a questão de saber se é possível que as máquinas mostrem comportamento inteligente” e\\ncontinua a descrever uma arquitetura de rede neural recorrente que chamou de “máquinas\\ndesorganizadas tipo B” e uma abordagem para treiná-las. Infelizmente, o relatório foi inédito até\\n1969, e foi ignorado até recentemente.\\nFrank Rosenblatt (1957) inventou o “perceptron” moderno e provou o teorema da convergência do\\nperceptron (1960), embora tenha sido prenunciado por ser um trabalho puramente matemático, fora\\ndo contexto de redes neurais (Agmon, 1954; Motzkin e Schoenberg, 1954). Foi feito também algum\\ntrabalho inicial em redes multicamadas, incluindo \\nperceptrons de Gamba\\n (Gamba \\net al\\n., 1961) e\\nmadalines\\n (Widrow, 1962). As \\nMáquinas de aprendizagem\\n (Nilsson, 1965) cobrem grande parte\\ndesse trabalho precoce e muito mais. O desaparecimento subsequente dos esforços de pesquisa\\niniciais do perceptron foi apressado (ou, mais tarde, os autores alegaram, meramente explicado) pelo\\nlivro \\nPerceptrons\\n (Minsky e Papert, 1969), que lamentou a falta de rigor matemático do campo. O\\nlivro apontou que os perceptrons de camada única poderiam representar apenas conceitos\\nlinearmente separáveis e notou a falta de algoritmos de aprendizagem efetivos para redes de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 876}),\n",
       " Document(page_content='múltiplas camadas.\\nOs artigos em Hinton e Anderson (1981), com base em uma conferência em San Diego em 1979,\\npodem ser considerados como a marca do renascimento do conexionismo. Os dois volumes “PDP”\\n(Parallel Distributed Processing), antologia (Rumelhart \\net al.\\n, 1986a) e um pequeno artigo \\nNature\\n(Rumelhart \\net al\\n., 1986b) atraíram grande atenção — de fato, o número de artigos sobre “redes\\nneurais”, multiplicou-se por um fator de 200 entre 1980-1984 e 1990-1994. A análise de redes\\nneurais usando a teoria física de vidros de spin magnético (Amit \\net al\\n., 1985) reforçou as ligações\\nentre a mecânica estatística e a teoria de redes neurais, proporcionando não apenas discernimentos\\nmatemáticos úteis, mas também \\nrespeitabilidade\\n. A técnica de retropropagação foi inventada muito\\ncedo (Bryson e Ho, 1969), mas foi redescoberta várias vezes (Werbos, 1974; Parker, 1985).\\nA interpretação probabilística de redes neurais tem várias fontes, incluindo Baum e Wilczek\\n(1988) e Bridle (1990). O papel da função sigmoide foi discutido por Jordan (1995). A\\naprendizagem bayesiana de parâmetros para as redes neurais foi proposta por MacKay (1992) e\\ndepois explorada por Neal (1996). A capacidade das redes neurais para representar funções foi\\ninvestigada por Cybenko (1988, 1989), que mostrou que duas camadas ocultas são suficientes para\\nrepresentar qualquer função e uma única camada é suficiente para representar qualquer função\\ncontínua.\\n O método do “dano cerebral ótimo” para remover conexões inúteis por LeCun \\net al.\\n(1989) e Sietsma e Dow (1988) mostrou como remover unidades inúteis. O algoritmo de tiling para o\\ncrescimento de estruturas maiores é devido a Mézard e Nadal (1989). LeCun \\net\\n \\nal\\n. (1995)\\npesquisaram uma série de algoritmos de reconhecimento de dígitos escritos à mão. A melhoria das\\ntaxas de erro desde então foi relatada por Belongie \\net al.\\n (2002) para encaixe de forma e por\\nDeCoste e Schölkopf (2002) para vetores de suporte virtual. No momento da escrita, a melhor taxa\\nde erro de teste relatado foi de 0,39% em Ranzato \\net al\\n. (2007) utilizando uma rede neural\\nconvolucional.\\nA complexidade da aprendizagem da rede neural tem sido investigada por pesquisadores em teoria\\nda aprendizagem computacional. Os primeiros resultados computacionais foram obtidos por Judd\\n(1990), que mostrou que o problema geral de encontrar um conjunto de pesos consistente com um\\nconjunto de exemplos é NP-completo, mesmo em hipóteses muito restritivas. Um pouco dos\\nresultados de complexidade da primeira amostra foi obtido por Baum e Haussler (1989), que\\nmostraram que o número de exemplos necessários para uma aprendizagem eficaz cresce em cerca de\\nW\\n log \\nW\\n, onde \\nW\\n é o número de pesos.\\n17\\n Desde então, uma teoria muito mais sofisticada tem sido\\ndesenvolvida (Anthony e Bartlett, 1999), incluindo o resultado importante de que a capacidade de\\nrepresentação de uma rede depende do \\ntamanho\\n dos pesos, bem como do seu número, um resultado\\nque não deveria ser surpreendente à luz da nossa discussão de regularização.\\nO tipo mais popular de rede neural que não abrangemos é a função de base radial, ou FBR, rede. A\\nfunção de base radial combina uma coleção ponderada de kernels (geralmente gaussianas, é claro)\\npara fazer aproximação de função. As redes FBR podem ser instruídas em duas fases: primeiro, uma\\nabordagem de agrupamento não supervisionado é usado para treinar os parâmetros de gaussianas —\\nas médias e as variâncias — sendo instruídas, como na \\nSeção 20.3.1\\n. Na segunda fase, os pesos\\nrelativos das gaussianas são determinados. Esse é um sistema de equações lineares, que sabemos\\ncomo resolver diretamente. Assim, ambas as fases de treinamento FBR têm uma bela vantagem: a\\nprimeira fase não é supervisionada e, portanto, não requer dados de treinamento rotulados, e a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 877}),\n",
       " Document(page_content='segunda fase, embora supervisionada, é eficiente. Ver Bishop (1995) para mais detalhes.\\nAs \\nredes recorrentes\\n, em que as unidades estão ligadas em ciclos, foram mencionadas no\\ncapítulo mas não exploradas em profundidade. As \\nredes de Hopfield\\n (Hopfield, 1982)\\nprovavelmente são a classe de redes recorrentes mais bem entendidas. Usam conexões \\nbidirecionais\\ncom pesos \\nsimétricos\\n (ou seja, \\nw\\ni,j\\n = \\nw\\nj,i\\n), todas as unidades são unidades de entrada e de saída, a\\nfunção de ativação \\ng\\n é a função de sinal, e os níveis de ativação só podem ser ±1. A rede de\\nHopfield funciona como uma \\nmemória associativa\\n: depois que a rede instrui um conjunto de\\nexemplos, um novo estímulo faz com que ele se estabeleça em um padrão de ativação correspondente\\nao exemplo do conjunto de treinamento \\nque mais se assemelhe\\n ao novo estímulo. Por exemplo, se o\\nconjunto de treinamento consiste em um conjunto de fotografias, e o novo estímulo é um pequeno\\npedaço de uma das fotografias, os níveis de ativação da rede vão reproduzir a fotografia de onde o\\npedaço foi tirado. Observe que as fotografias originais não são armazenados separadamente na rede,\\ncada peso é uma codificação parcial de todas as fotografias. Um dos resultados teóricos mais\\ninteressantes é que as redes de Hopfield podem armazenar confiavelmente até 0,138\\nN\\n exemplos de\\ntreinamento, onde \\nN\\n é o número de unidades na rede.\\nAs \\nmáquinas de Boltzmann\\n (Hinton e Sejnowski, 1983, 1986) também utilizam pesos simétricos,\\nmas incluem unidades ocultas. Além disso, utilizam uma função de ativação \\nestocástica\\n, tal que a\\nprobabilidade de saída sendo 1 é uma função da entrada total ponderada. As máquinas de Boltzmann,\\nportanto, sofrem transições de estado que se assemelham a uma busca de têmpora simulada (veja o\\nCapítulo 4) para a configuração que melhor se aproxima do conjunto de treinamento. Acontece que as\\nmáquinas de Boltzmann estão intimamente relacionadas a um caso especial de redes bayesianas\\navaliadas com um algoritmo de simulação estocástica (veja a \\nSeção 14.5\\n).\\nNo caso das redes neurais, Bishop (1995), Ripley (1996) e Haykin (2008) são os textos\\nprincipais. O campo da neurociência computacional foi coberto por Dayan e Abbott (2001).\\nA abordagem adotada neste capítulo foi influenciada pelas excelentes notas do curso de David\\nCohn, Tom Mitchell, Andrew Moore e Andrew Ng. Existem vários livros didáticos de primeira\\ncategoria em aprendizagem de máquina (Mitchell, 1997; Bishop, 2007) e nos campos intimamente\\naliados e sobrepostos de reconhecimento de padrões (Ripley, 1996;. Duda \\net al\\n., 2001), estatísticas\\n(Wasserman, 2004; Hastie \\net al\\n., 2001), mineração de dados (Hand \\net al.\\n, 2001; Witten e Frank,\\n2005), teoria da aprendizagem computacional (Kearns e Vazirani, 1994; Vapnik, 1998) e teoria da\\ninformação (Shannon e Weaver, 1949; MacKay, 2002; Capa e Thomas, 2006). Outros livros se\\nconcentram em implementações (Segaran, 2007; Marsland, 2009) e comparações de algoritmos\\n(Michie \\net al\\n., 1994). Pesquisas atuais em aprendizagem de máquina foram publicadas nos\\nprocedimentos anuais da International Conference on Machine Learning (ICML) e na conferência\\nsobre Neural Information Processing Systems (NIPS), em \\nMachine Learning e Journal of Machine\\nLearning Reserach\\n, e em revistas de tendência atual em IA.\\nEXERCÍCIOS\\n18.1\\n Considere o problema enfrentado por uma criança que aprende a falar e a compreender um\\nidioma. Explique como esse processo se enquadra no modelo geral de aprendizagem. Descreva as', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 878}),\n",
       " Document(page_content='percepções e ações da criança e os tipos de aprendizagem que a criança deve fazer. Descreva as\\nsubfunções que o bebê está tentando aprender em termos de entradas e saídas, e os dados de exemplo\\ndisponíveis.\\n18.2\\n Repita o Exercício 18.1 para o caso de aprender a jogar tênis (ou algum outro esporte com que\\nvocê esteja familiarizado). Trata-se de uma aprendizagem supervisionada ou de uma aprendizagem\\npor reforço?\\n18.3\\n Suponha que geramos um conjunto de treinamento a partir de uma árvore de decisão e depois\\naplicamos a aprendizagem em árvores de decisão a esse conjunto de treinamento. O algoritmo de\\naprendizagem vai eventualmente retornar à árvore correta à medida que o tamanho do conjunto de\\ntreinamento tender a infinito? Por quê?\\n18.4\\n Na construção recursiva de árvores de decisão, às vezes acontece de um conjunto misto de\\nexemplos positivos e negativos permanecer em um nó de folha, mesmo depois que todos os atributos\\nsão usados. Vamos supor que temos \\np\\n exemplos positivos e \\nn\\n exemplos negativos.\\na.\\n Mostre que a solução usada por APRENDIZAGEM-EM-ÁRVORE-DE-DECISÃO, que escolhe\\na classificação de maioria, minimiza o erro absoluto sobre o conjunto de exemplos na folha.\\nb.\\n Mostre que a probabilidade de classe \\np\\n/(\\np\\n + \\nn\\n) minimiza a soma de erros quadráticos.\\n18.5\\n Suponha que um atributo divida o conjunto de exemplos \\nE\\n em subconjuntos \\nE\\nk\\n e que cada\\nsubconjunto tenha \\np\\nk\\n exemplos positivos e \\nn\\nk\\n exemplos negativos. Mostre que o atributo tem ganho\\nde informações estritamente positivo, a menos que a razão \\np\\nk\\n/(\\np\\nk\\n + \\nn\\nk\\n) seja a mesma para todo \\nk\\n.\\n18.6\\n Considere o seguinte conjunto de dados composto por três atributos de entrada binários (\\nA\\n1\\n, \\nA\\n2\\n e\\nA\\n3\\n) e uma saída binária:\\nExemplo\\nA\\n1\\nA\\n2\\nA\\n3\\nSaída \\ny\\nx\\n1\\n1\\n0\\n0\\n0\\nx\\n2\\n1\\n0\\n1\\n0\\nx\\n3\\n0\\n1\\n0\\n0\\nx\\n4\\n1\\n1\\n1\\n1\\nx\\n5\\n1\\n1\\n0\\n1\\nUtilize o algoritmo na \\nFigura 18.5\\n para estudar uma árvore de decisão a partir desses dados. Mostre\\nos cálculos feitos para determinar o atributo para dividir em cada nó.\\n18.7\\n Um \\ngrafo\\n de decisão é uma generalização de uma árvore de decisão que permite que os nós (ou\\nseja atributos utilizados para divisões) tenham pais múltiplos, em vez de apenas um único pai. O\\ngrafo\\n resultante ainda deve ser acíclico. Considere agora a função XOR de \\ntrês\\n atributos de entrada\\nbinários, que produzem o valor 1 se e apenas se um número impar dos três atributos de entrada tenha\\nvalor 1.\\na.\\n Desenhe uma \\nárvore\\n de decisão de tamanho mínimo para as três funções XOR de entrada.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 879}),\n",
       " Document(page_content='b.\\n Desenhe um \\ngrafo\\n de decisão de tamanho mínimo para as três funções XOR de entrada.\\n18.8\\n Este exercício considera χ\\n2\\n a poda de árvores de decisão (\\nSeção 18.3.5\\n).\\na.\\n Crie um conjunto de dados com dois atributos de entrada, de tal forma que a informação obtida\\nna raiz da árvore para ambos os atributos seja zero, mas haja uma árvore de decisão de\\nprofundidade 2 que seja consistente com todos os dados. O que poderia a poda \\nχ\\n2\\n fazer nesse\\nconjunto de dados, se aplicada de baixo para cima? Se aplicada de cima para baixo?\\nb.\\n Modifique a APRENDIZAGEM-EM-ÁRVORE-DE-DECISÃO para incluir a poda \\nχ\\n2\\n. Consulte\\nQuinlan (1986) ou Kears e Mansour (1998) para detalhes.\\n18.9\\n O algoritmo APRENDIZAGEM-EM-ÁRVORE-DE-DECISÃO padrão descrito no\\ncapítulo não manipula casos em que alguns exemplos têm valores de atributos omitidos.\\na.\\n Primeiro, precisamos encontrar um modo de classificar tais exemplos, dada uma árvore de\\ndecisão que inclua testes sobre os atributos para os quais podem estar faltando valores. Suponha\\nque um exemplo \\nx\\n tenha um valor omitido para o atributo \\nA\\n e a árvore de decisão efetue testes\\npara \\nA\\n em um nó que \\nx\\n alcança. Um modo de tratar esse caso é fingir que o exemplo tem todos\\nos valores possíveis para o atributo, mas pesar cada valor de acordo com sua frequência entre\\ntodos os exemplos que alcançam esse nó na árvore de decisão. O algoritmo de classificação\\ndeve seguir todas as ramificações em qualquer nó para o qual está faltando um valor e\\nmultiplicar os pesos ao longo de cada caminho. Escreva um algoritmo de classificação\\nmodificado para árvores de decisão que tenha esse comportamento.\\nb.\\n Agora, modifique o cálculo de ganho de informações para que, em qualquer coleção dada de\\nexemplos \\nC\\n em determinado nó na árvore durante o processo de construção, os exemplos com\\nvalores omitidos para quaisquer dos atributos restantes recebam valores “como se”, de acordo\\ncom as frequências desses valores no conjunto \\nC\\n.\\n18.10\\n Na \\nSeção 18.3.6\\n, observamos que atributos com muitos valores possíveis diferentes podem\\ncausar problemas com a medida de ganho. Tais atributos tendem a dividir os exemplos em numerosas\\nclasses pequenas ou mesmo classes unitárias, parecendo assim ser altamente relevantes de acordo\\ncom a medida de ganho. O critério \\nrazão de ganho\\n seleciona atributos de acordo com a razão entre\\nseu ganho e seu conteúdo intrínseco de informação, ou seja, a quantidade de informações contidas na\\nresposta à pergunta: “Qual é o valor desse atributo?” Portanto, o critério de razão de ganho tenta\\nmedir a eficiência com que um atributo fornece informações sobre a classificação correta de um\\nexemplo. Escreva uma expressão matemática para o conteúdo de informação de um atributo e\\nimplemente o critério de razão de ganho em APRENDIZAGEM-EM-ÁRVORE-DE-DECISÃO.\\n18.11\\n Vamos supor que você esteja executando um experimento de aprendizagem em um novo\\nalgoritmo para classificação booleana. Você tem um conjunto de dados que consiste em 100\\nexemplos positivos e negativos. Você planeja utilizar a validação cruzada com omissão de um e\\ncomparar o seu algoritmo com uma função de base, um classificador de maioria simples. (É dado ao\\nclassificador de maioria um conjunto de dados de treinamento e, então,este sempre produz a classe\\nque é a maioria no conjunto de treinamento, independentemente da entrada.) Você espera que o\\nclassificador de maioria marque cerca de 50% na validação cruzada com omissão de um, mas, para\\nsua surpresa, cada vez ele marca zero. Explique por quê.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 880}),\n",
       " Document(page_content='18.12\\n Construa uma \\nlista de decisão\\n para classificar os dados a seguir. Selecione os testes para que\\neles sejam o menor possível (em termos de atributos), quebrando os laços entre os testes com o\\nmesmo número de atributos ao selecionar o que classifica o maior número de exemplos corretamente.\\nSe múltiplos testes tiverem o mesmo número de atributos e classificarem o mesmo número de\\nexemplos, então quebre o laço usando os atributos com os números com índice mais baixo (ou seja,\\nselecione \\nA\\n1\\n em vez de \\nA\\n2\\n).\\nExemplo\\nA\\n1\\nA\\n2\\nA\\n3\\nA\\n4\\ny\\nx\\n1\\n1\\n0\\n0\\n0\\n1\\nx\\n2\\n1\\n0\\n1\\n1\\n1\\nx\\n3\\n0\\n1\\n0\\n0\\n1\\nx\\n4\\n0\\n1\\n1\\n0\\n0\\nx\\n5\\n1\\n1\\n0\\n1\\n1\\nx\\n6\\n0\\n1\\n0\\n1\\n0\\nx\\n7\\n0\\n0\\n1\\n1\\n1\\nx\\n8\\n0\\n0\\n1\\n0\\n0\\n18.13\\n Demonstre que uma lista de decisão possa representar a mesma função que uma árvore de\\ndecisão quando utiliza ao máximo tantas regras quanto existam folhas na árvore de decisão para essa\\nfunção. Dê um exemplo de função representada por uma lista de decisão usando regras estritamente\\ninferiores ao número de folhas em uma árvore de decisão de tamanho mínimo para essa mesma\\nfunção.\\n18.14\\n Este exercício se refere à expressividade de listas de decisão (\\nSeção 18.5\\n).\\na.\\n Mostre que listas de decisão podem representar qualquer função booleana se o tamanho dos\\ntestes não for limitado.\\nb.\\n Mostre que, se os testes puderem conter no máximo \\nk\\n literais cada, as listas de decisão poderão\\nrepresentar qualquer função que pode ser representada por uma árvore de decisão de\\nprofundidade \\nk\\n.\\n18.15\\n Suponha que uma regressão 7-vizinhos-mais-próximos busca retornar {7, 6, 8, 4, 7, 11, 100}\\ncomo o valor de \\ny\\n mais próximo de 7 para dado valor \\nx\\n. Qual é o valor de \\n que minimiza a função\\nperda \\nL\\n1\\n desses dados? Há um nome comum em estatística para esse valor como função de valores \\ny\\n,\\nqual é? Responda às mesmas duas perguntas para a função de perda \\nL\\n2\\n.\\n18.16\\n A \\nFigura 18.31\\n mostrou como um círculo na origem pode estar linearmente separado por\\nmapeamento das características (\\nx\\n1\\n, \\nx\\n2\\n) para as duas dimensões (\\n). Mas, e se o círculo não\\nestiver localizado na origem? E se for uma elipse, e não um círculo? A equação geral de um círculo\\n(e, portanto, o limite de decisão) é (\\nx\\n1\\n – \\na\\n)\\n2\\n + (\\nx\\n2\\n– \\nb\\n)\\n2\\n – \\nr\\n2\\n = 0, e a equação geral de uma elipse é c\\n(\\nx\\n1\\n – \\na\\n)\\n2\\n + d (\\nx\\n2\\n – \\nb\\n)\\n2\\n – 1 = 0.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 881}),\n",
       " Document(page_content='a\\n. Expanda a equação do círculo e mostre que os pesos \\nw\\ni\\n seriam de fronteira de decisão no\\nespaço característico com quatro dimensões (\\nx\\n1\\n, \\nx\\n2\\n, \\n). Explique por que isso significa que\\nqualquer círculo é linearmente separável \\u200b\\u200bnesse espaço.\\nb\\n. Faça o mesmo para elipses no espaço característico com cinco dimensões (\\nx\\n1\\n, \\nx\\n2\\n, \\n, \\nx\\n1\\nx\\n2\\n).\\n18.17\\n Construa uma máquina de vetor de suporte que calcule a função XOR. Use valores de +1 e −1\\n(em vez de 1 e 0) para as entradas e saídas, de modo que o exemplo pareça ([−1, 1], 1) ou ([−1, −1],\\n−1). Faça o mapeamento da entrada [\\nx\\n1\\n, \\nx\\n2\\n] em um espaço constituído por \\nx\\n1\\n e \\nx\\n1\\n \\nx\\n2\\n. Desenhe os\\nquatro pontos de entrada nesse espaço e o separador de margem máximo. Qual é a margem? Agora,\\ndesenhe a linha que separa de volta no espaço de entrada original euclidiano.\\n18.18\\n Considere um algoritmo de aprendizagem por agrupamento que use a votação de maioria\\nsimples entre \\nK\\n hipóteses aprendidas. Suponha que cada hipótese tenha erro \\n∊\\n e que os erros\\ncometidos por cada hipótese sejam independentes dos erros das outras hipóteses. Calcule uma\\nfórmula para o erro do algoritmo de conjunto em termos de \\nK\\n e \\n∊\\n, e avalie essa fórmula para os casos\\nem que \\nK\\n = 5, 10 e 20, e \\n∊\\n = 0,1, 0,2 e 0,4. Se a suposição de independência for removida, será\\npossível o erro de conjunto ser \\npior\\n que \\n∊\\n?\\n18.19\\n Construa uma rede neural manualmente que calcule a função XOR de duas entradas. Certifique-\\nse de especificar que tipo de unidades está usando.\\n18.20\\n Lembre-se do Capítulo 18 que existem 2\\n2n\\n funções booleanas distintas de \\nn\\n entradas. Como\\nmuitas delas\\u200b\\u200b são representáveis por um perceptron de limiar?\\n18.21\\n A \\nSeção 18.6.4\\n observou que a saída da função logística poderia ser interpretada como uma\\nprobabilidade p\\n atribuída pelo modelo para a proposição de que \\nf\\n(\\nx\\n) = 1; a probabilidade de que\\nf\\n(\\nx\\n) = 0 é, portanto, 1 − p. Escreva a probabilidade \\np\\n como uma função de \\nx\\n e calcule a derivada de\\nlog \\np\\n com relação a cada peso \\nw\\ni\\n. Repita o processo para log (1 − \\np\\n). Esses cálculos dão uma regra\\nde aprendizagem para minimizar a função de perda de probabilidade log negativo para uma hipótese\\nprobabilística. Comente sobre qualquer semelhança com outras regras de aprendizagem no capítulo.\\n18.22\\n Suponha que você tenha uma rede neural com funções de ativação linear. Ou seja, para cada\\nunidade, a saída é alguma constante \\nc\\n vezes a soma ponderada das entradas.\\na\\n. Suponha que a rede tenha uma camada oculta. Para uma atribuição \\nw\\n dada aos pesos, escreva as\\nequações para o valor das unidades na camada de saída em função de \\nw\\n e na camada de entrada\\nx\\n, sem qualquer menção explícita da saída da camada oculta. Mostre que existe uma rede sem\\nunidades ocultas que calcula a mesma função.\\nb\\n. Repita o cálculo da parte (a), mas dessa vez faça-o para uma rede com qualquer número de\\ncamadas ocultas.\\nc\\n. Suponha que uma rede com uma camada oculta e funções de ativação linear tenha \\nn\\n nós de\\nentrada e saída e \\nh\\n nós ocultos. Qual efeito a transformação na parte (a) de uma rede sem\\ncamadas ocultas tem sobre o número total de pesos? Discuta em particular o caso \\nh\\n \\n \\nn\\n.\\n18.23\\n Suponha que um conjunto de treinamento contenha apenas um único exemplo com 100\\nrepetições. Em 80 dos 100 casos, o único valor de saída é 1; nos outros 20 é 0. O que a rede de retro', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 882}),\n",
       " Document(page_content='propagação prediz para esse exemplo, assumindo que foi treinada e atinge um ótimo global? (Dica:\\npara encontrar o ótimo global, derive a função erro e a defina como zero.)\\n18.24\\n A rede neural cujo desempenho de aprendizagem é medido na \\nFigura 18.25\\n tem quatro nós\\nocultos. Esse número foi escolhido arbitrariamente. Use o método de validação cruzada para\\nencontrar o melhor número de nós ocultos.\\n18.25\\n Considere o problema de separar \\nN\\n pontos de dados em exemplos positivos e negativos\\nusando um separador linear. Por certo, isso sempre pode ser feito para \\nN\\n = 2 pontos em uma linha de\\ndimensão \\nd\\n = 1, independentemente de como os pontos estão rotulados ou de onde eles estão\\nlocalizados (a menos que os pontos estejam no mesmo lugar).\\na\\n. Mostre que sempre pode ser feito para \\nN\\n = 3 pontos em um plano de dimensão \\nd\\n = 2, a menos\\nque sejam colineares.\\nb.\\n Mostre que sempre pode ser feito para \\nN\\n = 4 pontos em um plano de dimensão \\nd\\n = 2.\\nc.\\n Mostre que sempre pode ser feito para \\nN\\n = 4 pontos em um espaço de dimensão \\nd\\n = 3, a menos\\nque sejam coplanares.\\nd.\\n Mostre que sempre pode ser feito para \\nN\\n = 5 pontos em um espaço de dimensão \\nd\\n = 3.\\ne.\\n O estudante ambicioso pode querer provar que \\nN\\n pontos em posição geral (mas não \\nN\\n + 1) são\\nlinearmente separáveis em um espaço de dimensão \\nN\\n − 1.\\n1\\n Uma observação quanto à notação: exceto onde observado, usaremos \\nj\\n para indexar os \\nN\\n exemplos; \\nx\\nj\\n será sempre a entrada e \\ny\\nj\\n a\\nsaída. Nos casos em que a entrada é especificamente um vetor de valores de atributos (começando na \\nSeção 18.3\\n), vamos usar \\nx\\nj\\n para\\no \\nj\\n-ésimo exemplo e \\ni\\n para indexar os \\nn\\n atributos de cada exemplo. Os elementos de \\nx\\nj\\n são escritos como \\nx\\nj\\n,1\\n, x\\nj\\n,2\\n,.\\n.., x\\nj,n\\n.\\n2\\n O ganho será estritamente positivo, exceto para o caso improvável em que todas as proporções forem \\nexatamente\\n as mesmas. (Veja o\\nExercício 18.5.)\\n3\\n Gauss mostrou que, se os valores \\ny\\nj\\n normalmente têm ruído distribuído, os valores mais prováveis de \\nw\\n1\\n e \\nw\\n0\\n são obtidos através da\\nminimização da soma dos quadrados dos erros.\\n4\\n Com algumas ressalvas: a função de perda \\nL\\n2\\n será adequada quando houver ruído normalmente distribuído, que seja independente de \\nx\\n;\\ntodos os resultados dependem da suposição de estacionaridade etc.\\n5\\n O leitor pode consultar o Apêndice A para um breve resumo da álgebra linear.\\n6\\n Talvez seja confuso que \\nL\\n1\\n e \\nL\\n2\\n sejam usados tanto para as funções de perda como de regularização. Eles não precisam ser usados\\nem pares: você pode usar a perda \\nL\\n2\\n com a regularização \\nL\\n1\\n ou vice-versa.\\n7\\n Tecnicamente é necessário que \\n e \\n. O decaimento a(\\nt\\n) = \\nO\\n(1/\\nt\\n) satisfaz essas condições.\\n8\\n Uma observação sobre a notação: nesta seção, fomos forçados a suspender nossas convenções usuais. Atributos de entrada ainda são\\nindexados por \\ni\\n, de modo que uma ativação “externa” \\na\\ni\\n é dada pela entrada \\nx\\ni\\n, mas o índice \\nj\\n refere-se a unidades internas em vez de\\nexemplos. Em toda esta seção, as derivações matemáticas dizem respeito a um único exemplo genérico \\nx\\n, omitindo os somatórios usuais\\nde exemplos para obter resultados para o conjunto de dados.\\n9\\n A prova é complexa, mas o ponto principal é que o número necessário de unidades ocultas cresce exponencialmente com o número de\\nentradas. Por exemplo, são necessárias 2\\nn\\n/\\nn\\n unidades ocultas para codificar todas as funções booleanas de \\nn\\n entradas.\\n10\\n Tem-se observado que as redes muito grandes fazem bem a generalização, \\ndesde que os pesos sejam mantidos pequenos.\\n Essa\\nrestrição mantém os valores de ativação na região \\nlinear\\n da função sigmoide \\ng\\n(\\nx\\n) onde \\nx\\n é próximo de zero. Isso, por sua vez, significa\\nque a rede se comporta como uma função linear (Exercício 18.22), com muito menos parâmetros.\\n11\\n O leitor pode perceber que poderíamos ter usado apenas \\nf\\n1\\n e \\nf\\n2\\n, mas o mapeamento 3-D ilustra melhor a ideia.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 883}),\n",
       " Document(page_content='12\\n Esse uso da “função kernel” é ligeiramente diferente dos kernels em regressão ponderada localmente. Alguns kernels SVM são\\nmétricas de distância, mas nem todos são.\\n13\\n Aqui, “razoável” significa que a matriz \\nK\\njk\\n = \\nK\\n(\\nx\\nj\\n, \\nx\\nk\\n) é definida positiva.\\n14\\n Para algoritmos de aprendizagem em que isso não é possível, podemos criar um conjunto de treinamento replicado onde o \\ni\\n-ésimo\\nexemplo aparece wj vezes usando a aleatoriedade para tratar pesos fracionários.\\n15\\n Consulte Blum (1996) para a demonstração.\\n16\\n O nome é muitas vezes grafado como “Occam”, talvez a partir do francês, Guillaume d’Occam.\\n17\\n Isso confirmou aproximadamente a “regra do tio Bernie”. A regra foi denominada devido a Bernie Widrow, que recomendou usar\\ncerca de 10 vezes tanto os exemplos como os pesos.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 884}),\n",
       " Document(page_content='E\\nCAPÍTULO\\n \\n19\\nConhecimento em aprendizagem\\nEm que examinamos o problema de aprendizagem quando você já sabe algo.\\nm todas as abordagens para estudo da aprendizagem descritas nos capítulos anteriores, a ideia é\\nconstruir uma função que tem o comportamento de entrada/saída observada nos dados. Em cada\\ncaso, os métodos de aprendizagem podem ser entendidos como a busca em um espaço de\\nhipóteses para encontrar uma função apropriada, começando apenas por uma suposição muito básica\\nsobre a forma da função, como “polinômio de segundo grau” ou “árvore de decisão” e, talvez, a\\npreferência por uma hipótese mais simples. Isso significa dizer que, antes de poder aprender algo\\nnovo, primeiro você deve esquecer (quase) tudo o que sabe. Neste capítulo, estudaremos métodos de\\naprendizagem que podem tirar proveito do \\nconhecimento\\n \\na priori\\n sobre o mundo. Na maioria dos\\ncasos, o conhecimento \\na priori\\n é representado como teorias lógicas gerais de primeira ordem; desse\\nmodo, pela primeira vez, juntamos o trabalho sobre representação do conhecimento e o de\\naprendizagem.\\n19.1 UMA FORMULAÇÃO LÓGICA DA APRENDIZAGEM\\nO Capítulo 18 definiu a aprendizagem indutiva pura como um processo de encontrar uma hipótese\\nque concorde com os exemplos observados. Aqui, especializaremos essa definição para o caso em\\nque a hipótese é representada por um conjunto de sentenças lógicas. Descrições de exemplos e\\nclassificações também serão sentenças lógicas, e um novo exemplo poderá ser classificado\\ndeduzindo-se uma sentença de classificação a partir da hipótese e da descrição do exemplo. Essa\\nabordagem permite a construção incremental de hipóteses, uma sentença de cada vez. Ela também\\npermite o conhecimento \\na priori\\n porque sentenças que já são conhecidas podem ajudar na\\nclassificação de novos exemplos. A princípio, a formulação lógica de aprendizagem talvez pareça\\nmuito trabalho extra, mas ela serve para esclarecer muitas das questões relacionadas à aprendizagem.\\nAlém disso, ela nos permite ir muito além dos métodos de aprendizagem simples do Capítulo 18,\\nusando todo o poder de inferência lógica a serviço da aprendizagem.\\n19.1.1 Exemplos e hipóteses', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 886}),\n",
       " Document(page_content='Vimos no Capítulo 18 o problema de aprendizagem do restaurante: aprender uma regra para\\ndecidir se devemos esperar por uma mesa. Os exemplos foram descritos por \\natributos\\n como\\nAlternativa\\n, \\nBar\\n, \\nSex\\n/\\nSáb\\n, e assim por diante. Em uma configuração lógica, um exemplo é um objeto\\ndescrito por uma sentença lógica; os atributos se tornam predicados unários. Vamos chamar\\ngenericamente o \\ni\\n-ésimo exemplo de \\nX\\ni\\n. Assim, o primeiro exemplo da \\nFigura 18.3\\n é descrito pelas\\nsentenças:\\nUsaremos a notação \\nD\\ni\\n(\\nX\\ni\\n) para fazer referência à descrição de \\nX\\ni\\n, onde \\nD\\ni\\n pode ser qualquer\\nexpressão lógica que recebe um único argumento. A classificação do exemplo é dado por um literal\\nutilizando o predicado objetivo, nesse caso\\nO conjunto de treinamento completo é então simplesmente a conjunção de todas as descrições de\\nexemplos e literais objetivos.\\nO objetivo da aprendizagem indutiva em geral é encontrar uma hipótese que classifique os\\nexemplos bem e generalize bem para novos exemplos. Aqui estamos preocupados com hipóteses\\nexpressas em lógica; cada hipótese \\nh\\nj\\n terá a forma\\nonde \\nC\\nj\\n(x)\\n é uma definição candidata — alguma expressão envolvendo os predicados dos atributo.\\nPor exemplo, uma árvore de decisão pode ser interpretada como uma expressão lógica dessa\\nfórmula. Desse modo, a \\nFigura 18.6\\n expressa a definição lógica a seguir (que chamaremos de \\nh\\nr\\n para\\nreferência futura):\\nCada hipótese prevê que certo conjunto de exemplos — ou seja, aqueles que satisfazem à sua\\ndefinição candidata — será o conjunto de exemplos do predicado objetivo. Esse conjunto é chamado\\nextensão\\n do predicado.\\nDuas hipóteses com extensões diferentes são então logicamente inconsistentes uma em relação à\\noutra porque elas discordam em suas previsões por pelo menos um exemplo. Se tiverem a mesma\\nextensão, elas serão logicamente equivalentes.\\nO espaço de hipóteses \\n é o conjunto de todas as hipóteses {\\nh\\n1\\n, …, \\nh\\nn\\n} que o algoritmo de\\naprendizagem foi projetado para considerar. Por exemplo, o algoritmo APRENDIZAGEM-EM-\\nÁRVORE-DE-DECISÃO pode considerar qualquer hipótese de árvore de decisão definida em\\ntermos dos atributos fornecidos; portanto, seu espaço de hipóteses consiste em todas essas árvores de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 887}),\n",
       " Document(page_content='decisão. Presumivelmente, o algoritmo de aprendizagem acredita que uma das hipóteses seja correta;\\nisto é, ele acredita na sentença\\nÀ medida que os exemplos chegam, as hipóteses que não são \\nconsistentes\\n com os exemplos\\npodem ser eliminadas. Vamos examinar essa noção de consistência com mais atenção. É óbvio que,\\nse a hipótese \\nh\\nj\\n é consistente com o conjunto de treinamento inteiro, ela tem de ser consistente com\\ncada exemplo no conjunto de treinamento. O que significaria para ela o fato de ser inconsistente com\\num exemplo? Isso pode acontecer de duas maneiras:\\n•  Um exemplo pode ser \\nfalso negativo\\n para a hipótese se a hipótese afirmar que ele deve ser\\nnegativo, mas de fato ele for positivo. Então, o novo exemplo \\nX\\n13\\n descrito por\\nseria um falso negativo para a hipótese \\nh\\nr\\n dada anteriormente. A partir de \\nh\\nr\\n e da descrição do\\nexemplo, podemos deduzir tanto \\nVaiEsperar\\n(\\nX\\n13\\n), que é a afirmação do exemplo, quanto\\n¬\\nVaiEsperar\\n(\\nX\\n13\\n), o que a hipótese prevê. A hipótese e o exemplo são então logicamente\\ninconsistentes.\\n•  Um exemplo pode ser \\nfalso positivo\\n para a hipótese se a hipótese afirmar que ele deve ser\\npositivo, mas de fato ele for negativo.\\n1\\nSe um exemplo é falso positivo ou falso negativo para uma hipótese, então o exemplo e a hipótese\\nsão logicamente inconsistentes um com o outro. Supondo-se que o exemplo seja uma observação\\ncorreta do fato, a hipótese pode ser eliminada. Em termos lógicos, isso é exatamente análogo à regra\\nde resolução de inferência (veja o Capítulo 9), pela qual a disjunção de hipóteses corresponde a uma\\ncláusula e o exemplo corresponde a um literal que se resolve em relação a um dos literais na\\ncláusula. Um sistema de inferência lógica comum poderia, em princípio, aprender a partir do\\nexemplo, eliminando uma ou mais hipóteses. Vamos supor que o exemplo seja denotado pela\\nsentença \\nI\\n1\\n e que o espaço de hipóteses seja \\nh\\n1\\n \\n∨\\n \\nh\\n2\\n \\n∨\\n \\nh\\n3\\n \\n∨\\n \\nh\\n4\\n. Então, se \\nI\\n1\\n é inconsistente com \\nh\\n2\\ne \\nh\\n3\\n, o sistema de inferência lógica pode deduzir o novo espaço de hipóteses \\nh\\n1\\n \\n∨\\n h\\n4\\n.\\nAssim, podemos caracterizar a aprendizagem indutiva em uma configuração lógica como um\\nprocesso de eliminação gradual de hipóteses que são inconsistentes com os exemplos, reduzindo as\\npossibilidades. Como o espaço de hipóteses normalmente é vasto (ou até mesmo infinito, no caso da\\nlógica de primeira ordem), não recomendamos tentar construir um sistema de aprendizagem usando a\\nprova de teoremas baseada na resolução e uma enumeração completa do espaço de hipóteses. Em vez\\ndisso, descreveremos duas abordagens que encontram hipóteses logicamente consistentes com muito\\nmenos esforço.\\n19.1.2 Busca da melhor hipótese corrente', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 888}),\n",
       " Document(page_content='A ideia por trás da busca da \\nmelhor hipótese corrente\\n é manter uma única hipótese e ajustá-la à\\nmedida que chegam novos exemplos, a fim de manter a consistência. O algoritmo básico foi descrito\\npor John Stuart Mill (1843) e talvez ainda tenha aparecido bem antes disso.\\nVamos supor que tenhamos alguma hipótese como \\nh\\nr\\n, à qual nos afeiçoamos. Como cada novo\\nexemplo é consistente, não precisamos fazer nada. Então, surge um exemplo falso negativo, \\nX\\n13\\n. O\\nque fazemos? A \\nFigura 19.1\\n(a) mostra esquematicamente \\nh\\nr\\n como uma região: tudo o que está dentro\\ndo retângulo faz parte da extensão de \\nh\\nr\\n. Os exemplos que realmente foram vistos até agora são\\nmostrados como “+” ou “–” e vemos que \\nh\\nr\\n divide corretamente em categorias todos os exemplos\\ncomo exemplos positivos ou negativos de \\nVaiEsperar\\n. Na \\nFigura 19.1\\n(b), um novo exemplo (dentro\\ndo círculo) é um falso negativo: a hipótese afirma que ele deve ser negativo, mas, na verdade, ele é\\npositivo. A extensão da hipótese deve ser aumentada para incluí-lo. Isso é chamado \\ngeneralização\\n;\\numa generalização possível é mostrada na \\nFigura 19.1\\n(c). Então, na \\nFigura 19.1\\n(d), vemos um falso\\npositivo: a hipótese afirma que o novo exemplo (no círculo) deve ser positivo, mas na realidade ele\\né negativo. A extensão da hipótese deve ser diminuída para excluir o exemplo. Isso se chama\\nespecialização\\n; na \\nFigura 19.1\\n(e), vemos uma especialização possível da hipótese. As relações\\n“mais geral que” e “mais específica que” entre hipóteses fornecem a estrutura lógica no espaço de\\nhipóteses que tornam a busca eficiente possível.\\nFigura 19.1\\n (a) Hipótese consistente. (b) Falso negativo. (c) A hipótese é generalizada. (d) Falso\\npositivo. (e) A hipótese é especializada.\\nAgora, podemos especificar o algoritmo APRENDIZAGEM-MELHOR-CORRENTE, mostrado na\\nFigura 19.2\\n. Note que, toda vez que consideramos a possibilidade de generalizar ou especializar a\\nhipótese, devemos verificar a consistência com os outros exemplos porque aumento/diminuição\\narbitrário(a) na extensão poderia incluir/excluir exemplos negativos/positivos vistos anteriormente.\\nfunção\\n APRENDIZAGEM-MELHOR-CORRENTE(\\nexemplos, h\\n) \\nretorna\\n uma hipótese ou falha\\n    \\nse\\n \\nexemplos\\n vazio \\nentão\\n        \\nretornar\\n \\nh\\n    \\ne\\n ← PRIMEIRO(\\nexemplos\\n)\\n    \\nse\\n \\ne\\n é consistente com \\nh\\n \\nentão\\n        \\nretornar\\n APRENDIZAGEM-MELHOR-CORRENTE (RESTO(\\nexemplos), h\\n)\\n    \\nsenão se\\n \\ne\\n é falso positivo de \\nh\\n \\nentão\\n        \\npara cada\\n \\nh\\n′ \\nem\\n especializações de \\nh\\n consistente com \\nexemplos\\n vistos até agora \\nfaça', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 889}),\n",
       " Document(page_content='h\\n′′ ← APRENDIZAGEM-MELHOR-CORRENTE (RESTO(\\nexemplos), h\\n′)\\n            \\nse\\n \\nh\\n′′ \\n≠\\n falha \\nentão retornar\\n \\nh\\n′′\\n    \\nsenão se\\n \\ne\\n é falso negativo para \\nh\\n \\nentão\\n        \\npara cada\\n \\nh\\n′ \\nem\\n generalizações de \\nh\\n consistente com \\nexemplos\\n vistos até agora \\nfaça\\n            \\nh’’\\n← APRENDIZAGEM-MELHOR-CORRENTE (RESTO(\\nexemplos), h’\\n)\\n            \\nse\\n \\nh\\n′′ \\n≠\\n falha \\nentão retornar\\n \\nh\\n′′\\n    \\nretornar\\n \\nfalha\\nFigura 19.2\\n Algoritmo de aprendizagem de melhor hipótese corrente. Ele busca uma hipótese\\nconsistente que mais se adapte aos exemplos e retrocede quando não é possível encontrar nenhuma\\nespecialização/generalização consistente. Para iniciar o algoritmo, qualquer hipótese pode ser\\naceitável; será especializada ou generalizada na medida da necessidade.\\nDefinimos generalização e especialização como operações que mudam a \\nextensão\\n de uma\\nhipótese. Agora, precisamos determinar exatamente como elas podem ser implementadas sob a forma\\nde operações sintáticas que mudam a definição candidata associada à hipótese de forma que um\\nprograma possa executá-las. Isso é feito observando-se primeiro que generalização e especialização\\ntambém são relacionamentos \\nlógicos\\n entre hipóteses. Se a hipótese \\nh\\n1\\n com a definição \\nC\\n1\\n é uma\\ngeneralização da hipótese \\nh\\n2\\n com a definição \\nC\\n2\\n, devemos ter:\\nEntão, para construir uma generalização de \\nh\\n2\\n, precisamos simplesmente encontrar uma definição\\nde \\nC\\n1\\n que seja logicamente implicada por \\nC\\n2\\n. Isso é feito com facilidade. Por exemplo, se \\nC\\n2\\n(\\nx\\n) é\\nAlternativa\\n(\\nx\\n) \\n∧\\n \\nClientes\\n (\\nx\\n, \\nAlguns\\n), então uma generalização possível é dada por \\nC\\n1\\n(\\nx\\n) ≡\\nClientes\\n(\\nx\\n, \\nAlguns\\n). Isso se chama \\ndescarte de condições\\n. Intuitivamente, o descarte de condições\\ngera uma definição mais fraca e, por conseguinte, permite um conjunto maior de exemplos positivos.\\nExistem várias outras operações de generalização, dependendo da linguagem que está sendo\\nutilizada. De modo semelhante, podemos especializar uma hipótese adicionando condições extras à\\nsua definição candidata ou removendo disjuntos a partir de uma definição disjuntiva. Vamos ver\\ncomo isso funciona no exemplo de restaurante, usando os dados da \\nFigura 18.3\\n.\\n•  O primeiro exemplo \\nX\\n1\\n é positivo. O atributo \\nAlternativa\\n(\\nX\\n1\\n) é verdadeiro e, assim, seja a\\nhipótese inicial\\n•  O segundo exemplo, \\nX\\n2\\n, é negativo. \\nh\\n1\\n prevê que ele deve ser positivo; então, trata-se de um\\nfalso positivo. Assim, precisamos especializar \\nh\\n1\\n. Isso pode ser feito adicionando-se uma\\ncondição extra que eliminará \\nX\\n2\\n, enquanto continua a classificar X\\n1\\n como positivo. Uma\\npossibilidade é', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 890}),\n",
       " Document(page_content='•  O terceiro exemplo, \\nX\\n3\\n, é positivo. \\nh\\n2\\n prevê que ele deve ser negativo e, assim, ele é um falso\\nnegativo. Portanto, precisamos generalizar \\nh\\n2\\n. Descartamos a condição \\nAlternativa\\n, gerando:\\n•  O quarto exemplo, \\nX\\n4\\n, é positivo. \\nh\\n3\\n prevê que ele deve ser negativo; então, trata-se de um falso\\nnegativo. Portanto, precisamos generalizar \\nh\\n3\\n. Não podemos descartar a condição de \\nClientes\\nporque isso produziria uma hipótese totalmente inclusiva que seria inconsistente com \\nX\\n2\\n. Uma\\npossibilidade é adicionar um disjunção:\\nCom isso, a hipótese já está começando a parecer razoável. É evidente que existem outras\\npossibilidades consistentes com os quatro primeiros exemplos; aqui estão duas delas:\\nO algoritmo APRENDIZAGEM-MELHOR-CORRENTE é descrito de forma não determinística\\nporque, em qualquer ponto, talvez haja várias especializações ou generalizações possíveis que\\npodem ser aplicadas. As escolhas que são feitas não levarão necessariamente à hipótese mais\\nsimples e podem resultar em uma situação irrecuperável, na qual nenhuma modificação simples da\\nhipótese será consistente com todos os dados.\\nEm tais casos, o programa deve retroceder a um ponto de escolha anterior.\\nO algoritmo APRENDIZAGEM-MELHOR-CORRENTE e suas variantes foram usados em muitos\\nsistemas de aprendizagem de máquina, começando com o programa de “aprendizagem de arco” de\\nPatrick Winston (1970). Entretanto, com grande número de instâncias e espaço extenso, surgem\\nalgumas dificuldades:\\n1. A verificação de todas as instâncias anteriores repetidamente para cada modificação é muito\\ndispendiosa.\\n2. O processo de busca pode envolver muito retrocesso. Como vimos no Capítulo 18, o espaço de\\nhipóteses pode ser um lugar duplo exponencialmente grande.\\n19.1.3 Busca de compromisso mínimo\\nO retrocesso surge porque a abordagem de melhor hipótese corrente tem de \\nescolher\\n uma hipótese\\nespecífica como sua melhor suposição, embora ainda não tenha dados suficientes para ter certeza da\\nescolha. Em vez disso, podemos contornar todas as hipóteses que são consistentes com todos os\\ndados até agora, e somente essas. Cada nova instância não terá nenhum efeito ou se livrará de\\nalgumas das hipóteses. Lembre-se de que o espaço de hipóteses original pode ser visto como uma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 891}),\n",
       " Document(page_content='sentença disjuntiva:\\nh\\n1\\n \\n∨\\n \\nh\\n2\\n \\n∨\\n \\nh\\n3\\n… \\n∨\\n \\nh\\nn\\n.\\nÀ medida que descobrimos que várias hipóteses são inconsistentes com os exemplos, essa\\ndisjunção é reduzida, retendo apenas as hipóteses não eliminadas. Supondo-se que o espaço de\\nhipóteses original contenha de fato a resposta correta, a disjunção reduzida ainda deverá conter a\\nresposta correta porque apenas hipóteses incorretas foram removidas. O conjunto de hipóteses\\nrestante é chamado \\nespaço de versão\\n, e o algoritmo de aprendizagem (esboçado na \\nFigura 19.3\\n) é\\nchamado algoritmo de aprendizagem de espaço de versão (e também de algoritmo de \\neliminação de\\ncandidata\\n).\\nfunção\\n APRENDIZAGEM-ESPAÇO-DE-VERSÃO(\\nexemplos\\n) \\nretorna\\n um espaço de versão\\n    \\nvariáveis locais:\\n \\nV\\n, o espaço de versão: o conjunto de todas as hipóteses\\n    \\nV\\n ← o conjunto de todas as hipóteses\\n    \\npara cada\\n exemplo \\ne\\n em \\nexemplos\\n \\nfaça\\n        \\nse\\n \\nV\\n não é vazio \\nentão\\n \\nV\\n ← ATUALIZAR-ESPAÇO-DE-VERSÃO(\\nV\\n, \\ne\\n)\\n    \\nretornar\\n \\nV\\n    __________________________________________________________________________________________________________\\n    \\nfunção\\n ATUALIZAR-ESPAÇO-DE-VERSÃO(\\nV\\n, \\ne\\n) \\nretorna\\n um espaço de versão atualizado\\n        \\nV\\n ← {\\nh\\n \\n∊\\n \\nV\\n \\n:\\n \\nh\\n é consistente com \\ne\\n}\\nFigura 19.3\\n Algoritmo de aprendizagem de espaço de versão. Ele encontra um subconjunto de \\nV\\n que\\né consistente com os \\nexemplos\\n.\\nUma propriedade importante dessa abordagem é que ela é \\nincremental\\n: nunca se tem de voltar e\\nreexaminar os exemplos antigos. Todas as hipóteses são garantidas de já estar consistentes com eles.\\nPorém, existe um problema óbvio. Já dissemos que o espaço de hipóteses é enorme; então, como\\npoderíamos escrever essa enorme disjunção?\\nA analogia simples a seguir é muito útil. Como representar todos os números reais entre 1 e 2?\\nAfinal, existe uma quantidade infinita deles! A resposta é usar uma representação de intervalo que só\\nespecifica os limites do conjunto: [1,2]. Ela funciona porque temos uma \\nordenação\\n sobre os números\\nreais.\\nTambém temos uma ordenação sobre o espaço de hipóteses, isto é, generalização/especialização.\\nEssa é uma ordenação parcial, o que significa que cada limite não será um ponto, mas um conjunto de\\nhipóteses chamado \\nconjunto limite\\n. O detalhe interessante é que podemos representar o espaço de\\nversão inteiro usando apenas dois conjuntos limite: um limite mais geral (o \\nconjunto G\\n) e um limite\\nmais específico (o \\nconjunto S\\n). \\nTudo o que estiver entre eles tem a garantia de ser consistente com\\nos exemplos\\n. Antes de provarmos esse fato, vamos recapitular:\\n•  O espaço de versão corrente é o conjunto de hipóteses consistentes com todos os exemplos até\\nagora. Ele é representado pelo conjunto S e pelo conjunto G, cada um dos quais é um conjunto de\\nhipóteses.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 892}),\n",
       " Document(page_content='•  Todo elemento do conjunto S é consistente com todas as observações até agora, e não existe\\nnenhuma hipótese consistente que seja mais específica.\\n•  Todo elemento do conjunto G é consistente com todas as observações até agora, e não existe\\nnenhuma hipótese consistente que seja mais geral.\\nQueremos que o espaço de versão inicial (antes de quaisquer exemplos serem vistos) represente\\ntodas as hipóteses possíveis. Fazemos isso configurando o conjunto G para conter \\nVerdadeiro\\n (a\\nhipótese que contém tudo) e o conjunto S para conter \\nFalso\\n (a hipótese cuja extensão está vazia).\\nA \\nFigura 19.4\\n mostra a estrutura geral da representação de conjunto limite do espaço de versão.\\nPara mostrar que a representação é suficiente, precisamos das duas propriedades a seguir:\\nFigura 19.4\\n O espaço de versão contém todas as hipóteses consistentes com os exemplos.\\n1. Toda hipótese consistente (além daquelas dos conjuntos de limites) é mais específica que algum\\nelemento do conjunto G e mais geral que algum elemento do conjunto S (isto é, não existe\\nnenhuma hipótese “errante” que tenha ficado de fora). Isso decorre diretamente das definições\\nde \\nS\\n e \\nG\\n. Se houvesse uma hipótese errante \\nh\\n, ela não poderia ser mais específica que qualquer\\nelemento de \\nG\\n e, nesse caso, pertenceria a \\nG\\n; ou, então, ela não seria mais geral que qualquer\\nelemento de \\nS\\n e, nesse caso, estaria em \\nS\\n.\\n2. Toda hipótese mais específica que algum elemento do conjunto G e mais geral que algum\\nelemento do conjunto S é uma hipótese consistente (isto é, não existe nenhum “buraco” entre os\\nlimites). Qualquer \\nh\\n entre \\nS\\n e \\nG\\n deve rejeitar todos os exemplos negativos rejeitados por cada\\nelemento de \\nG\\n (porque ela é mais específica) e deve aceitar todos os exemplos positivos\\naceitos por qualquer elemento de \\nS\\n (porque é mais geral). Desse modo, \\nh\\n deve concordar com\\ntodos os exemplos e, portanto, não pode ser inconsistente. A \\nFigura 19.5\\n mostra a situação: não\\nexiste nenhum exemplo conhecido fora de \\nS\\n mas dentro de \\nG\\n e, assim, qualquer hipótese no\\nintervalo deve ser consistente.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 893}),\n",
       " Document(page_content='Figura 19.5\\n Extensões dos elementos de \\nG\\n e \\nS\\n. Nenhum exemplo conhecido reside entre os dois\\nconjuntos de limites.\\nEntão, mostramos que, se \\nS\\n e \\nG\\n são mantidos de acordo com suas definições, eles devem fornecer\\numa representação satisfatória do espaço de versão. O único problema que resta é o de \\natualizar S\\n e\\nG\\n para um novo exemplo (o trabalho da função ATUALIZAR-ESPAÇO-DE-VERSÃO). Isso pode\\nparecer bastante complicado a princípio; porém, a partir das definições e com a ajuda da \\nFigura\\n19.4\\n, não é tão difícil reconstruir o algoritmo.\\nPrecisamos nos preocupar com os elementos \\nS\\ni\\n e \\nG\\ni\\n dos conjuntos S e G. Para cada um, a nova\\ninstância pode ser um falso positivo ou um falso negativo.\\n1. Falso positivo para \\nS\\ni\\n: isso significa que \\nS\\ni\\n é muito geral, mas não existe nenhuma\\nespecialização consistente de \\nS\\ni\\n (por definição) e, assim, nós o retiramos do conjunto S.\\n2. Falso negativo para \\nS\\ni\\n: isso significa que \\nS\\ni\\n é muito específico, então nós o substituímos por\\ntodas as suas generalizações imediatas, desde que elas sejam mais específicas que algum\\nelemento de \\nG\\n.\\n3. Falso positivo para \\nG\\ni\\n: isso significa que \\nG\\ni\\n é muito geral, então nós o substituímos por todas as\\nsuas especializações imediatas, desde que elas sejam mais gerais que algum elemento de \\nS\\n.\\n4. Falso negativo para \\nG\\ni\\n: isso significa que \\nG\\ni\\n é muito específico, mas não existe nenhuma\\ngeneralização consistente de \\nG\\ni\\n (por definição) e, assim, nós o retiramos do conjunto G.\\nContinuamos com essas operações para cada nova instância até ocorrer uma destas três situações:\\n1. Haver exatamente um conceito restante no espaço de versão e, nesse caso, nós o retornaremos\\ncomo a única hipótese.\\n2. O espaço de versão \\nentra em colapso\\n — S ou G fica vazio, indicando que não existem\\nhipóteses consistentes para o conjunto de treinamento. Esse é o mesmo caso de falha da versão\\nsimples do algoritmo de árvore de decisão.\\n3. Esgotamos os exemplos e temos várias hipóteses que ainda restavam no espaço de versão. Isso\\nsignifica que o espaço de versão representa uma disjunção de hipóteses. Para qualquer novo\\nexemplo, se todas as disjunções concordarem, poderemos retornar sua classificação do\\nexemplo. Se elas discordarem, uma possibilidade será realizar a votação de maioria.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 894}),\n",
       " Document(page_content='Deixamos como exercício a aplicação do algoritmo APRENDIZAGEM-ESPAÇO-DE-VERSÃO\\naos dados do restaurante.\\nHá algumas desvantagens importantes na abordagem de espaço de versão:\\n•  Se o domínio contiver ruído ou atributos insuficientes para classificação exata, o espaço de\\nversão sempre entrará em colapso.\\n•  Se permitirmos disjunção ilimitada no espaço de hipóteses, o conjunto S sempre conterá uma\\núnica hipótese mais específica, ou seja, a disjunção das descrições dos exemplos positivos\\nvistos até o momento. De modo semelhante, o conjunto G conterá apenas a negação da disjunção\\ndas descrições dos exemplos negativos.\\n•  Para alguns espaços de hipóteses, o número de elementos no conjunto S do conjunto G pode\\ncrescer exponencialmente no número de atributos, embora existam algoritmos de aprendizagem\\neficientes para esses espaços de hipóteses.\\nAté agora, não foi encontrada nenhuma solução completamente bem-sucedida para o problema de\\nruído. O problema de disjunção pode ser tratado permitindo apenas formas limitadas de disjunção ou\\nincluindo-se uma \\nhierarquia de generalização\\n de predicados mais gerais. Por exemplo, em vez de\\nusar a disjunção \\nEsperaEstimada\\n(\\nx\\n, \\n30-60\\n) \\n∨\\n \\nEsperaEstimada\\n(\\nx\\n, >60), poderíamos usar o literal\\núnico \\nEsperaLonga\\n(\\nx\\n). O conjunto de operações de generalização e especialização pode ser\\nfacilmente estendido para esse fim.\\nO algoritmo de espaço de versão puro foi aplicado pela primeira vez no sistema Meta-\\nDENDRAL, projetado com a finalidade de aprender regras para prever como as moléculas se\\ndividiriam em fragmentos em um espectrômetro de massa (Buchanan e Mitchell, 1978). O Meta-\\nDENDRAL foi capaz de gerar regras suficientemente inovadoras para merecer a publicação em um\\nperiódico de química analítica — o primeiro conhecimento científico real gerado por um programa\\nde computador. Ele também foi utilizado no elegante sistema LEX (Mitchell \\net al\\n., 1983), que era\\ncapaz de aprender a resolver problemas de integração simbólica estudando seus próprios sucessos e\\nfracassos. Embora os métodos de espaço de versão provavelmente não sejam práticos na maioria dos\\nproblemas de aprendizagem do mundo real, em grande parte devido ao ruído, eles oferecem uma boa\\nindicação da estrutura lógica do espaço de hipóteses.\\n19.2 CONHECIMENTO EM APRENDIZAGEM\\nA seção precedente descreveu a configuração mais simples para aprendizagem indutiva. Para\\ncompreender o papel do conhecimento \\na priori\\n, precisamos discutir os relacionamentos lógicos entre\\nhipóteses, descrições de exemplos e classificações. Seja \\nDescrições\\n a representação da conjunção\\nde todas as descrições de exemplos no conjunto de treinamento, e seja \\nClassificações\\n o valor que\\ndenota a conjunção de todas as classificações de exemplos. Então, uma \\nHipótese\\n que “explica as\\nobservações” deve satisfazer à seguinte propriedade (lembre-se de que |= significa “consequência\\nlógica”):', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 895}),\n",
       " Document(page_content='Chamamos essa relação de \\nrestrição de consequência lógica\\n, na qual \\nHipótese\\n é a “incógnita”. A\\naprendizagem indutiva pura significa resolver essa restrição, em que \\nHipótese\\n é extraída de algum\\nespaço de hipóteses predefinido. Por exemplo, se considerarmos uma árvore de decisão como uma\\nfórmula lógica (veja a Equação 19.1), uma árvore de decisão consistente com todos os exemplos\\nsatisfará a Equação 19.3. Se não impusermos \\nnenhuma\\n restrição sobre a forma lógica da hipótese, é\\nclaro que \\nHipótese\\n = \\nClassificações\\n também satisfará a restrição. A navalha de Ockham nos diz que\\ndevemos preferir hipóteses \\npequenas\\n e consistentes, e então tentaremos fazer algo melhor do que\\nsimplesmente memorizar os exemplos.\\n Esse quadro simples livre do conhecimento de aprendizagem indutiva persistiu até o início da\\ndécada de 1980. A abordagem moderna consiste em projetar agentes que \\njá sabem algo\\n e estão\\ntentando aprender algo mais. Talvez isso não pareça uma percepção muito profunda, mas faz grande\\ndiferença no modo como projetamos agentes. Além disso, ela também poderá ter alguma relevância\\npara nossas teorias sobre o funcionamento da própria ciência. A ideia geral é mostrada\\nesquematicamente na \\nFigura 19.6\\n.\\nFigura 19.6\\n Um processo de aprendizagem cumulativa utiliza e amplia seu estoque de conhecimento\\nprático ao longo do tempo.\\nSe quisermos construir um agente de aprendizagem autônomo que utilize conhecimento prático,\\ndevemos de alguma forma obter o conhecimento prático, a fim de usá-lo nos novos episódios de\\naprendizagem. Esse método tem de ser ele próprio um processo de aprendizagem. A história de vida\\ndo agente será então caracterizada por um desenvolvimento \\ncumulativo\\n ou \\nincremental\\n. Presume-se\\nque o agente possa começar sem nada, realizando induções no vácuo como um pequeno programa de\\nindução pura. Porém, uma vez tendo comido o fruto da árvore do conhecimento, ele não poderá mais\\nprocurar tais especulações ingênuas e deverá usar seu conhecimento prático para aprender mais e\\ncom maior eficiência. Então, a questão é como realmente fazê-lo.\\n19.2.1 Alguns exemplos simples\\nVamos considerar alguns exemplos de senso comum de aprendizagem com conhecimento prático.\\nMuitos casos aparentemente racionais de comportamento inferencial diante de observações\\nclaramente não seguem os princípios simples da indução pura.\\n•  Às vezes, saltamos para conclusões gerais depois de apenas uma observação. Certa vez, Gary\\nLarson desenhou uma caricatura em que um homem das cavernas com óculos, chamado Zog, está', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 896}),\n",
       " Document(page_content='assando seu lagarto na ponta de uma vara. Ele é assistido por uma multidão pasma de\\ncontemporâneos menos intelectuais, que estavam usando as mãos nuas para segurar seus\\nalimentos sobre o fogo. Essa esclarecedora experiência foi suficiente para convencer os\\nassistentes de um princípio geral de arte culinária indolor.\\n•  Ou, então, considere o caso do viajante que vai ao Brasil e encontra um brasileiro. Ao ouvi-lo\\nfalar português, conclui de imediato que os brasileiros falam português, ainda que, ao descobrir\\nque seu nome é Fernando, ele não conclua que todos os brasileiros se chamem Fernando.\\nExemplos semelhantes aparecem em ciência. Por exemplo, quando um aluno iniciante em física\\nmede a densidade e a condutância de uma amostra de cobre a uma temperatura específica, ele\\nestá bastante confiante na generalização desses valores para todos os pedaços de cobre. Apesar\\ndisso, ao medir a massa da amostra, ele nem sequer considera a hipótese de que todos os\\nfragmentos de cobre tenham essa mesma massa. Por outro lado, seria bastante razoável fazer tal\\ngeneralização em relação a todas as moedas de um centavo.\\n•  Finalmente, considere o caso de um aluno da área médica ignorante em termos farmacológicos,\\nmas sofisticado em termos de diagnóstico, observando uma sessão de consulta entre um paciente\\ne um especialista em infectologia. Depois de uma série de perguntas e respostas, o especialista\\ndiz ao paciente que ele deve iniciar o tratamento com um antibiótico específico. O aluno deduz\\nentão a regra geral de que esse antibiótico específico é eficaz para determinado tipo de infecção.\\n Todos esses são casos em que \\no uso do conhecimento prático permite aprendizagem muito\\nmais rápida do que se poderia esperar de um programa de indução pura\\n.\\n19.2.2 Alguns esquemas gerais\\nEm cada um dos exemplos precedentes, pode-se apelar para o conhecimento \\na priori\\n com a\\nfinalidade de justificar as generalizações escolhidas. Agora, vamos examinar os tipos de restrições\\nde consequência lógica que estão operando em cada caso. As restrições envolverão o conhecimento\\nda \\nBase\\n, além da \\nHipótese\\n e das \\nDescrições\\n e \\nClassificações\\n observadas.\\nNo caso do assado de lagarto, o homem das cavernas generaliza, \\nexplicando\\n o sucesso da vara\\nusada como espeto: ela suporta o lagarto, ao mesmo tempo em que mantém a mão longe do fogo. A\\npartir dessa explicação, eles podem deduzir uma regra geral: que qualquer objeto longo, rígido e de\\nponta aguçada pode ser usado para assar pequenos víveres de carne macia. Esse tipo de processo de\\ngeneralização é chamado \\naprendizagem baseada na explanação\\n, ou \\nABE\\n. Note que a regra geral\\ndecorre logicamente\\n do conhecimento prático que o homem das cavernas possui. Consequentemente,\\nas restrições de consequência lógica satisfeitas pela ABE são:\\n Como a ABE utiliza a Equação 19.3, ela foi considerada inicialmente um modo melhor de\\naprender a partir de exemplos. Porém, por exigir que o conhecimento prático seja suficiente para', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 897}),\n",
       " Document(page_content='explicar a \\nHipótese\\n que, por sua vez, explica as observações, \\nna realidade, o agente não aprende\\nnada factualmente novo a partir da instância\\n. O agente \\npoderia ter\\n derivado o exemplo do que já\\nsabia, embora isso talvez tivesse exigido uma quantidade pouco razoável de computação. Agora, a\\nABE é visualizada como um método para converter teorias de princípios básicos em conhecimento\\nútil, de aplicação especial. Descrevemos algoritmos para ABE na \\nSeção 19.3\\n.\\nA situação de nosso viajante no Brasil é bem diferente, pois ele não pode explicar\\nnecessariamente por que Fernando fala daquele jeito, a menos que conheça as bulas papais. Além\\ndisso, a mesma generalização seria proveniente de um viajante completamente ignorante da história\\ncolonial. O conhecimento \\na priori\\n relevante nesse caso é que, em qualquer país específico, a maioria\\ndas pessoas tende a falar o mesmo idioma; por outro lado, não consideramos que Fernando seja o\\nnome de todos os brasileiros porque essa espécie de regularidade não é válida para nomes. De modo\\nsemelhante, o aluno de física iniciante também teria dificuldade para explicar os valores específicos\\nque descobre para a condutância e a densidade do cobre. No entanto, ele sabe que o material do qual\\num objeto é composto e sua temperatura determinam juntos sua condutância. Em cada caso, o\\nconhecimento \\na priori da Base\\n se refere à \\nrelevância\\n de um conjunto de características para o\\npredicado objetivo. Esse conhecimento, \\njuntamente com as observações\\n, permite ao agente deduzir\\numa regra nova e geral que explica as observações:\\nChamamos a esse tipo de generalização \\naprendizagem baseada na relevância\\n, ou \\nABR\\n —\\nembora o nome não seja padrão. Note que, enquanto a ABR faz uso do conteúdo das observações, ela\\nnão produz hipóteses que vão além do conteúdo lógico do conhecimento prático e das observações.\\nTrata-se de uma forma \\ndedutiva\\n de aprendizagem e não pode levar em conta por si só a criação de\\nnovo conhecimento a partir do nada.\\nNo caso do aluno de medicina que observa o especialista, supomos que o conhecimento \\na priori\\ndo aluno é suficiente para deduzir a doença \\nD\\n do paciente a partir dos sintomas. Porém, esse\\nconhecimento não é suficiente para explicar o fato de o médico prescrever um remédio específico \\nM\\n.\\nO aluno precisa propor outra regra, ou seja, que \\nM\\n geralmente é eficaz contra a doença \\nD\\n. Dada essa\\nregra e o conhecimento \\na priori\\n do aluno, este pode agora explicar por que o especialista prescreve\\nM\\n nesse caso específico. Podemos generalizar esse exemplo para apresentar a restrição de\\nconsequência lógica\\n Ou seja, \\no conhecimento prático e a nova hipótese se combinam para explicar os exemplos\\n.\\nComo ocorre no caso da aprendizagem indutiva pura, o algoritmo de aprendizagem deve propor\\nhipóteses tão simples quanto possível e consistentes com essa restrição. Os algoritmos que\\nsatisfazem a restrição 19.5 são chamados algoritmos de \\naprendizagem indutiva baseada no\\nconhecimento\\n, ou \\nAIBC\\n.\\nOs algoritmos de AIBC, descritos em detalhes na \\nSeção 19.5\\n, foram estudados principalmente no\\ncampo da \\nprogramação em lógica indutiva\\n, ou \\nPLI\\n. Em sistemas de PLI, o conhecimento \\na priori\\ndesempenha dois papéis fundamentais na redução da complexidade da aprendizagem:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 898}),\n",
       " Document(page_content='1. Como qualquer hipótese gerada deve ser consistente com o conhecimento \\na priori\\n e também\\ncom as novas observações, o tamanho efetivo do espaço de hipóteses é reduzido para incluir\\napenas aquelas teorias que são consistentes com o que já é conhecido.\\n2. Para qualquer conjunto de observações dado, o tamanho da hipótese exigida para construir uma\\nexplanação relativa às observações pode ser muito reduzido porque o conhecimento \\na priori\\nestará disponível para ajudar as novas regras a explicar as observações. Quanto menor a\\nhipótese, mais fácil será encontrá-la.\\nAlém de permitir o uso do conhecimento \\na priori\\n em indução, os sistemas de PLI podem formular\\nhipóteses em lógica de primeira ordem geral, em vez de formular essas hipóteses na limitada\\nlinguagem de atributos do Capítulo 18. Isso significa que eles podem aprender em ambientes que não\\npodem ser entendidos por sistemas mais simples.\\n19.3 APRENDIZAGEM BASEADA NA EXPLANAÇÃO\\nConforme explicamos na introdução a este capítulo, a aprendizagem baseada na explanação é um\\nmétodo para extrair regras gerais de observações individuais. Como exemplo, considere o problema\\nda diferenciação e da simplificação de expressões algébricas (Exercício 9.17). Se diferenciarmos\\numa expressão como \\nX\\n2\\n em relação a \\nX\\n, obteremos 2\\nX\\n (note que usamos letra maiúscula para\\nrepresentar a incógnita aritmética \\nX\\n, a fim de distingui-la da variável lógica \\nx\\n). Em um sistema de\\nraciocínio lógico, o objetivo poderia ser expresso como \\nASK\\n(\\nDerivada\\n(\\nX\\n2\\n, \\nX\\n) = \\nd\\n, \\nBC\\n), com\\nsolução \\nd\\n = 2\\nX\\n.\\nQualquer pessoa que conheça cálculo diferencial poderá ver essa solução “por inspeção” como\\nresultado da prática na resolução de tais problemas. Um aluno que encontrar tais problemas pela\\nprimeira vez ou um programa sem qualquer experiência, terá um trabalho muito mais difícil. A\\naplicação das regras-padrão de diferenciação eventualmente produz a expressão 1 × (2 × (\\nX\\n(2 – 1)\\n)), e\\nmais tarde ela é simplificada para 2\\nX\\n. Na implementação de programação em lógica dos autores,\\nisso requer 136 etapas de prova, das quais 99 são despendidas em ramificações sem saída na prova.\\nDepois de tal experiência, gostaríamos que o programa resolvesse o mesmo problema muito mais\\nrapidamente na próxima vez que ele surgisse.\\nA técnica de \\nmemoização\\n tem sido usada há longo tempo em ciência da computação para acelerar\\nprogramas salvando os resultados da computação. A ideia básica das funções de memo é acumular\\num banco de dados de pares de entrada/saída; quando a função é chamada, primeiro ela examina o\\nbanco de dados para ver se pode evitar resolver o problema desde o início. A aprendizagem baseada\\nna explanação tira bom proveito dessa etapa, criando regras \\ngerais\\n que cobrem uma classe inteira de\\ncasos. No caso da diferenciação, a memoização lembraria que a derivada de \\nX\\n2\\n em relação a \\nX\\n é 2\\nX\\n,\\nmas deixaria o agente calcular a derivada de \\nZ\\n2\\n em relação a \\nZ\\n desde o início. Gostaríamos de ser\\ncapazes de extrair a regra geral segundo a qual, para qualquer incógnita aritmética \\nu\\n, a derivada de\\nu\\n2\\n em relação a \\nu\\n é 2\\nu\\n (pode ser produzida uma regra mesmo mais geral para \\nun\\n, mas o exemplo\\natual é sufuciente). Em termos lógicos, isso é expresso pela regra', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 899}),\n",
       " Document(page_content='Se a base de conhecimento contém tal regra, qualquer caso novo que seja uma instância dessa\\nregra poderá ser resolvido de imediato.\\n É claro que esse é apenas um exemplo trivial de um fenômeno muito geral. Uma vez que algo é\\ncompreendido, pode ser generalizado e reutilizado em outras circunstâncias. O fato se torna uma\\netapa “óbvia” e pode então ser usado como um bloco de construção na resolução de problemas ainda\\nmais complexos. Alfred North Whitehead (1911), coautor com Bertrand Russell de \\nPrincipia\\nMathematica\\n, escreveu: “\\nA civilização avança ampliando o número de operações importantes que\\npodemos executar sem pensar a respeito delas”,\\n talvez aplicando ele mesmo a ABE à sua\\ncompreensão de eventos como a descoberta de Zog. Se você compreendeu a ideia básica do exemplo\\nde diferenciação, seu cérebro já está tentando ativamente extrair os princípios gerais da\\naprendizagem baseada na explanação a partir dele. Note que você não tinha \\nainda\\n criado a ABE\\nantes de ver o exemplo. Como os homens das cavernas observando Zog, você (e nós) precisávamos\\nde um exemplo antes de poder gerar os princípios básicos. Esse é o motivo pelo qual \\nexplicar por\\nque\\n algo é uma boa ideia é muito mais fácil que apresentar a ideia como passo inicial.\\n19.3.1 Extraindo regras gerais a partir de exemplos\\nA ideia básica por trás da ABE é primeiro construir uma explanação da observação usando o\\nconhecimento \\na priori\\n e depois estabelecer uma definição da classe de casos para os quais a mesma\\nestrutura de explanação pode ser usada. Essa definição fornece a base para uma regra que cobre\\ntodos os casos na classe. A “explanação” pode ser uma prova lógica, mas, de modo mais geral, pode\\nser qualquer processo de raciocínio ou de resolução de problemas cujos passos sejam bem\\ndefinidos. A chave é ser capaz de identificar as condições necessárias para que os mesmos passos se\\napliquem a outro caso.\\nUsaremos como nosso sistema de raciocínio o provador simples de teoremas de encadeamento\\npara trás descrito no Capítulo 9. A árvore de prova para \\nDerivada\\n(\\nX\\n2\\n, \\nX\\n) = 2\\nX\\n é muito grande para\\nser usada como exemplo e, portanto, usaremos um problema mais simples para ilustrar o método de\\ngeneralização. Suponha que nosso problema seja simplificar 1 × (0 + \\nX\\n). A base de conhecimento\\ninclui as regras a seguir:\\nA prova de que a resposta é \\nX\\n é mostrada na metade superior da \\nFigura 19.7\\n. Na realidade, o\\nmétodo de ABE constrói duas árvores de prova simultaneamente. A segunda árvore de prova utiliza\\num objetivo \\nvariabilizado\\n, no qual as constantes do objetivo original são substituídas por variáveis.\\nÀ medida que a prova original prossegue, a prova variabilizada prossegue no mesmo passo, usando\\nexatamente as mesmas aplicações de regra\\n. Isso poderia fazer algumas das variáveis se tornarem', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 900}),\n",
       " Document(page_content='instanciadas. Por exemplo, para usar a regra \\nReescrever\\n(1 × \\nu\\n, \\nu\\n), a variável \\nx\\n no subobjetivo\\nReescrever\\n(\\nx\\n × (\\ny\\n + \\nz\\n), \\nv\\n) deve estar vinculada a 1. De modo semelhante, \\ny\\n deve estar vinculada a 0\\nno subobjetivo \\nReescrever\\n(\\ny\\n + \\nz\\n, \\nv’\\n), a fim de utilizar a regra \\nReescrever\\n(0 + \\nu\\n, \\nu\\n). Uma vez que\\ntemos a árvore de prova generalizada, tomamos as folhas (com as vinculações necessárias) e\\nformamos uma regra geral para o predicado objetivo:\\nFigura 19.7\\n Árvores de prova para o problema de simplificação. A primeira árvore mostra a prova\\npara a instância do problema original, da qual podemos derivar:\\nA segunda árvore mostra a prova para uma instância de problema com todas as constantes\\nsubstituídas por variáveis, da qual podemos derivar uma variedade de outras regras.\\nObserve que as duas primeiras condições no lado esquerdo são verdadeiras, \\nnão importando o\\nvalor de z\\n. Portanto, podemos descartá-las da regra, formando\\nEm geral, as condições podem ser descartadas da regra final se elas não impõem nenhuma\\nrestrição sobre as variáveis do lado direito da regra, porque a regra resultante ainda será verdadeira\\ne será mais eficiente. Note que não podemos descartar a condição \\nIncógnitaArtimética\\n(\\nz\\n) porque\\nnem todos os valores possíveis de \\nz\\n são incógnitas aritméticas. Valores que não são incógnitas\\naritméticas talvez exijam formas diferentes de simplificação: por exemplo, se \\nz\\n fosse 2 × 3, a\\nsimplificação correta de 1 × (0 + (2 × 3)) seria 6 e não 2 × 3. Para recapitular, o processo básico de\\nABE funciona assim:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 901}),\n",
       " Document(page_content='1. Dado um exemplo, construa uma prova de que o predicado objetivo se aplica ao exemplo\\nusando o conhecimento prático disponível.\\n2. Em paralelo, construa uma árvore de prova generalizada para o objetivo variabilizado,\\nutilizando os mesmos passos de inferência da prova original.\\n3. Construa uma nova regra cujo lado esquerdo consista nas folhas da árvore de prova e cujo lado\\ndireito seja o objetivo variabilizado (depois da aplicação das vinculações necessárias a partir\\nda prova generalizada).\\n4. Descarte quaisquer condições do lado esquerdo que sejam verdadeiras independentemente dos\\nvalores das variáveis no objetivo.\\n19.3.2 Como melhorar a eficiência\\nA árvore de prova generalizada da \\nFigura 19.7\\n realmente gera mais de uma regra generalizada.\\nPor exemplo, se encerrarmos, ou \\npodarmos\\n, o crescimento da ramificação da direita na árvore de\\nprova quando ela alcançar o passo \\nPrimitiva\\n, obteremos a regra:\\nEmbora \\nmais geral\\n, essa regra é tão válida quanto a regra que utiliza \\nIncógnitaAritmética\\n, porque\\ncobre os casos em que \\nz\\n é um número. Podemos extrair uma regra ainda mais geral efetuando a poda\\ndepois do passo \\nSimplificar\\n(\\ny\\n + \\nz\\n, \\nw\\n) gerando a regra:\\nEm geral, uma regra pode ser extraída de \\nqualquer subárvore parcial\\n da árvore de prova\\ngeneralizada. Agora, temos um problema: qual dessas regras escolheremos?\\nA escolha de qual regra gerar se reduz à questão da eficiência. Existem três fatores envolvidos na\\nanálise de ganhos de eficiência a partir de ABE:\\n1. A adição de grande número de regras pode diminuir a velocidade do processo de raciocínio\\nporque o mecanismo de inferência ainda tem de verificar essas regras, mesmo em casos nos\\nquais elas não produzem uma solução. Em outras palavras, ela aumenta o \\nfator de ramificação\\nno espaço de busca.\\n2. Para compensar a redução da velocidade de raciocínio, as regras derivadas devem oferecer\\naumentos significativos em velocidade para os casos que elas abrangem. Esses aumentos\\nsurgem principalmente porque as regras derivadas evitam becos sem saída que de outro forma\\nseriam seguidos, mas também porque elas encurtam a prova propriamente dita.\\n3. As regras derivadas devem ser tão gerais quanto possível, de forma que elas se apliquem ao\\nmaior conjunto possível de casos.\\nUma abordagem comum para assegurar que as regras derivadas são eficientes é insistir na\\noperacionalidade\\n de cada subobjetivo na regra. Um subobjetivo é operacional se é “fácil” resolvê-\\nlo. Por exemplo, é fácil resolver o subobjetivo \\nPrimitiva\\n(\\nz\\n), pois isso exige no máximo dois passos,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 902}),\n",
       " Document(page_content='enquanto o subobjetivo \\nSimplificar\\n(\\ny\\n + \\nz\\n, \\nw\\n) poderia levar a uma quantidade arbitrária de inferência,\\ndependendo dos valores de \\ny\\n e \\nz\\n. Se um teste para operacionalidade for executado em cada passo na\\nconstrução da prova generalizada, poderemos podar o restante de uma ramificação assim que um\\nsubobjetivo operacional for encontrado, mantendo apenas o subobjetivo operacional como um\\nelemento da conjunção da nova regra.\\nInfelizmente, em geral existe um compromisso entre operacionalidade e generalidade. Os\\nsubobjetivos mais específicos costumam ser mais fáceis de resolver, mas abrangem um número\\nmenor de casos. Além disso, a operacionalidade é uma questão de grau: definitivamente, a existência\\nde um ou dois passos é operacional, mas o que dizer de 10 ou 100?\\nPor fim, o custo de resolver determinado subobjetivo depende de quais outras regras estarão\\ndisponíveis na base de conhecimento. Ela pode aumentar ou diminuir à medida que mais regras são\\nadicionadas. Desse modo, os sistemas de ABE na realidade enfrentam um problema de otimização\\nmuito complexo na tentativa de maximizar a eficiência de dada base de conhecimento inicial.\\nAlgumas vezes é possível derivar um modelo matemático do efeito sobre a eficiência global da\\nadição de determinada regra e empregar esse modelo para selecionar a melhor regra a adicionar.\\nEntretanto, a análise poderá se tornar muito complicada, especialmente quando regras recursivas\\nestiverem envolvidas. Uma abordagem promissora é atacar o problema da eficiência de modo\\nempírico, simplesmente adicionando diversas regras e verificando quais delas são úteis e de fato\\naceleram o processo.\\n A análise empírica da eficiência está realmente no núcleo da ABE. O que temos chamado\\nlivremente de “eficiência de determinada base de conhecimento” é de fato a complexidade do caso\\nmédio em uma distribuição de problemas. \\nPor generalização a partir de exemplos de problemas\\npassados\\n, a \\nABE torna a base de conhecimento mais eficiente para o tipo de problemas que é\\nrazoável esperar\\n. Isso funciona desde que a distribuição de exemplos passados seja\\naproximadamente a mesma dos exemplos futuros — a mesma suposição usada para a aprendizagem\\nPAC na \\nSeção 18.5\\n. Se o sistema de ABE for cuidadosamente elaborado, será possível obter\\nacelerações significativas. Por exemplo, um sistema de linguagem natural muito grande baseado em\\nProlog projetado para tradução vocal entre os idiomas sueco e inglês foi capaz de alcançar\\ndesempenho de tempo real somente pela aplicação de ABE ao processo de análise (Samuelsson e\\nRayner, 1991).\\n19.4 APRENDIZAGEM COM O USO DE INFORMAÇÕES DE RELEVÂNCIA\\nNosso viajante no Brasil parece ser capaz de fazer uma generalização confiante em relação ao\\nidioma falado por outros brasileiros. A inferência é sancionada por seu conhecimento prático, isto é,\\nde que as pessoas de dado país (em geral) falam o mesmo idioma. Podemos expressar essa\\ninferência em lógica de primeira ordem como a seguir:\\n2\\n(Tradução literal: “Se \\nx\\n e \\ny\\n têm a mesma nacionalidade \\nn\\n e \\nx\\n fala o idioma \\nl\\n, então \\ny\\n também fala', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 903}),\n",
       " Document(page_content='esse idioma.”) Não é difícil demonstrar que, a partir dessa sentença e da observação de que\\na conclusão a seguir é consequência lógica (veja o Exercício 19.1):\\nSentenças como 19.6 expressam uma forma estrita de relevância: dada a nacionalidade, o idioma é\\ncompletamente determinado (em outras palavras: o idioma é uma função da nacionalidade). Essas\\nsentenças são chamadas \\ndependências funcionais\\n ou \\ndeterminações\\n. Elas ocorrem de forma tão\\ncomum em certos tipos de aplicações (por exemplo, na definição de projetos de bancos de dados)\\nque uma sintaxe especial é usada para escrevê-las. Adotaremos a notação de Davies (1985):\\nComo usual, isso é simplesmente um ajuste sintático, mas torna claro que a determinação é na\\nrealidade um relacionamento entre os predicados: a nacionalidade determina o idioma. As\\npropriedades relevantes que determinam a condutância e a densidade podem ser expressas de modo\\nsemelhante:\\nAs generalizações correspondentes decorrem logicamente das determinações e observações.\\n19.4.1 Determinação do espaço de hipóteses\\nEmbora as determinações sancionem conclusões gerais relativas a todos os brasileiros ou a todos\\nos pedaços de cobre em determinada temperatura, é claro que elas não podem produzir uma teoria\\npreditiva geral para \\ntodas\\n as nacionalidades ou para \\ntodas\\n as temperaturas e materiais, a partir de\\num exemplo único. Seu principal efeito pode ser visto como a limitação do espaço de hipóteses que\\no agente de aprendizagem precisa considerar.\\n Por exemplo, na previsão da condutância, é necessário considerar apenas o material e a\\ntemperatura, podendo-se ignorar a massa, a propriedade, o dia da semana, o presidente atual, e assim\\npor diante. As hipóteses podem, sem dúvida, incluir termos que, por sua vez, são determinados pelo\\nmaterial e pela temperatura, como a estrutura molecular, a energia térmica ou a densidade de elétrons\\nlivres. \\nAs determinações especificam um vocabulário de base suficiente a partir do qual devem ser\\nconstruídas hipóteses relativas ao predicado-alvo\\n. Essa declaração pode ser comprovada\\nmostrando-se que dada determinação é logicamente equivalente a uma declaração de que a definição\\ncorreta do predicado-alvo é um elemento do conjunto de todas as definições que podem ser\\nexpressas com a utilização dos predicados do lado esquerdo da determinação.\\nIntuitivamente, é claro que uma redução no tamanho do espaço de hipóteses deve tornar mais fácil\\naprender o predicado-alvo. Usando os resultados básicos da teoria de aprendizagem computacional', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 904}),\n",
       " Document(page_content='(\\nSeção 18.5\\n), podemos quantificar os ganhos possíveis. Primeiro, lembre-se de que, para funções\\nbooleanas, log(|\\n|) exemplos têm de convergir para uma hipótese razoável, onde |\\n| é o tamanho do\\nespaço de hipóteses. Se o aluno tem \\nn\\n características booleanas com que construir hipóteses, então,\\nna ausência de restrições adicionais, |\\n| =\\nO\\n(2\\n2\\nn\\n) e, assim, o número de exemplos será \\nO\\n(2\\nn\\n). Se a\\ndeterminação contém \\nd\\n predicados no lado esquerdo, o aluno exigirá apenas \\nO\\n(2\\nd\\n) exemplos, uma\\nredução de \\nO\\n(2\\nn–d\\n).\\n19.4.2 Aprendizagem e utilização de informações de relevância\\nConforme declaramos na introdução a este capítulo, o conhecimento \\na priori\\n é útil em\\naprendizagem, mas ele próprio também precisa ser aprendido. Para fornecer um roteiro completo de\\naprendizagem baseado em relevância, devemos portanto fornecer um algoritmo de aprendizagem para\\ndeterminações. O algoritmo de aprendizagem que apresentaremos agora se baseia em uma tentativa\\ndireta de encontrar a determinação mais simples consistente com as observações. Uma determinação\\nP\\n \\n \\nQ\\n nos diz que, se quaisquer exemplos coincidirem em \\nP\\n, eles também deverão coincidir em \\nQ\\n.\\nEntão, uma determinação é consistente com um conjunto de exemplos se todo par que corresponde\\nnos predicados do lado esquerdo também corresponde no predicado-alvo, isto é, tem a mesma\\nclassificação. Por exemplo, suponha que tenhamos os exemplos de medições de condutância em\\namostras dos materiais dados a seguir:\\nAmostra\\nMassa\\nTemperatura\\nMaterial\\nTamanho\\nCondutância\\nS1\\n12\\n26\\nCobre\\n3\\n0,59\\nS1\\n12\\n100\\nCobre\\n3\\n0,57\\nS2\\n24\\n26\\nCobre\\n6\\n0,59\\nS3\\n12\\n26\\nChumbo\\n2\\n0,05\\nS3\\n12\\n100\\nChumbo\\n2\\n0,04\\nS4\\n24\\n26\\nChumbo\\n4\\n0,05\\nA determinação consistente mínima é \\nMaterial\\n \\n∧\\n \\nTemperatura\\n \\n \\nCondutância\\n. Existe uma\\ndeterminação não mínima, mas consistente, isto é, \\nMassa\\n \\n∧\\n \\nTamanho\\n \\n∧\\n \\nTemperatura\\n \\nCondutância\\n. Isso é consistente com os exemplos porque massa e tamanho determinam densidade e,\\nem nosso conjunto de dados, não temos dois materiais diferentes com a mesma densidade. Como\\nsempre, precisaríamos de um conjunto de amostras maior, a fim de eliminar uma hipótese quase\\ncorreta.\\nExistem vários algoritmos possíveis para encontrar determinações consistentes mínimas. A\\nabordagem mais óbvia é conduzir uma busca pelo espaço de determinações verificando todas as\\ndeterminações com um predicado, dois predicados, e assim por diante, até encontrar uma\\ndeterminação consistente. Vamos supor uma representação baseada em atributo simples, como a que\\nusamos para aprendizagem de árvores de decisão no Capítulo 18. Uma determinação \\nd\\n será\\nrepresentada pelo conjunto de atributos no lado esquerdo porque o predicado-alvo é considerado', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 905}),\n",
       " Document(page_content='fixo. O algoritmo básico está representado na \\nFigura 19.8\\n.\\nfunção\\n DET-CONSISTENTE-MÍNIMA(\\nE\\n, \\nA\\n) \\nretorna\\n um conjunto de atributos\\n    \\nentradas\\n: \\nE\\n, um conjunto de exemplos\\nA\\n, um conjunto de atributos de tamanho \\nn\\n    \\npara\\n \\ni =\\n 0 \\na\\n \\nn\\n \\nfaça\\n        \\npara cada\\n subconjunto \\nA\\n de \\nA\\n de tamanho \\ni\\n \\nfaça\\n            \\nse\\n DET-CONSISTENTE?(\\nAi\\n, \\nE\\n) \\nentão retornar\\n \\nAi\\n_____________________________________________________________________________________________________________\\nfunção\\n DET-CONSISTENTE?(\\nA\\n, \\nE\\n) \\nretorna\\n um valor-verdade\\n    \\nentradas:\\n \\nA\\n, um conjunto de atributos\\nE\\n, um conjunto de exemplos\\n    \\nvariáveis locais\\n: \\nH\\n, uma tabela de hash\\n    \\npara cada\\n exemplo \\ne\\n \\nem\\n \\nE\\n \\nfaça\\n        \\nse\\n algum exemplo em \\nH\\n tem os mesmos valores que \\ne\\n para os atributos \\nA\\n            mas tem uma classificação diferente \\nentão retornar\\n \\nfalso\\n        armazenar a classe de \\ne\\n em \\nH\\n, indexada pelos valores correspondentes aos atributos \\nA\\n do exemplo \\n    \\nretornar\\n verdadeiro\\nFigura 19.8\\n Algoritmo para encontrar uma determinação consistente mínima.\\nA complexidade de tempo desse algoritmo depende do tamanho da menor determinação\\nconsistente. Suponha que essa determinação tenha \\np\\n atributos além do número total \\nn\\n de atributos.\\nEntão, o algoritmo não a encontrará até pesquisar os subconjuntos de \\nA\\n de tamanho \\np\\n. Existem (\\n) =\\nO\\n(\\nn\\np\\n) desses subconjuntos; consequentemente, o algoritmo é exponencial no tamanho da\\ndeterminação mínima. Na verdade, o problema é NP-completo e, assim, não podemos esperar um\\nresultado melhor no caso geral. No entanto, na maioria dos domínios, haverá uma estrutura local\\nsuficiente (veja no Capítulo 14 uma definição de domínios localmente estruturados) para que \\np\\n seja\\npequeno.\\nDado um algoritmo para aprender determinações, um agente de aprendizagem tem uma alternativa\\npara construir uma hipótese mínima, dentro da qual poderá aprender o predicado-alvo. Por exemplo,\\npodemos combinar DET-CONSISTENTE-MÍNIMA com o algoritmo APRENDIZAGEMEM-\\nÁRVORE-DE-DECISÃO. Isso vai gerar um algoritmo de aprendizagem baseado em árvore de\\ndecisão denominado AADBR (ou aprendizagem em árvore de decisão baseada em relevância) que\\nprimeiro identifica umconjunto mínimo de atributos relevantes e depois repassa esse conjunto ao\\nalgoritmo de árvore de decisão para aprendizagem. Diferentemente de APRENDIZAGEM-EM-\\nÁRVORE-DE-DECISÃO, o algoritmo AADBR aprende e utiliza simultaneamente informações de\\nrelevância, com o objetivo de minimizar seu espaço de hipóteses. Esperamos que AADBR aprenda\\ncom maior rapidez que APRENDIZAGEM-EM-ÁRVORE-DE-DECISÃO e, de fato, é isso o que\\nacontece. A \\nFigura 19.9\\n mostra o desempenho de aprendizagem para os dois algoritmos sobre dados\\ngerados aleatoriamente para uma função que depende de apenas 5 de 16 atributos. É óbvio que, em\\ncasos em que todos os atributos disponíveis forem relevantes, o AADBR não mostrará nenhuma', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 906}),\n",
       " Document(page_content='vantagem.\\nFigura 19.9\\n Comparação de desempenho entre AADBR e APRENDIZAGEM-EM-ÁRVORE-DE-\\nDECISÃO sobre dados gerados aleatoriamente para uma função-alvo que depende de apenas 5 entre\\n16 atributos.\\nEsta seção apenas arranhou a superfície do campo de \\ntendência declarativa\\n, que tem por objetivo\\ncompreender como o conhecimento \\na priori\\n pode ser usado para identificar o espaço de hipóteses\\napropriado, dentro do qual será realizada a busca da definição-alvo correta. Existem muitas\\nperguntas sem resposta:\\n•  Como os algoritmos podem ser estendidos para tratar ruído?\\n•  Podemos manipular variáveis de valores contínuos?\\n•  Como outros tipos de conhecimento \\na priori\\n podem ser empregados, além das determinações?\\n•  De que maneira os algoritmos podem ser generalizados para cobrir qualquer teoria de primeira\\nordem, em lugar de abordarem apenas uma representação baseada em atributos?\\nAlgumas dessas perguntas serão tratadas na próxima seção.\\n19.5 PROGRAMAÇÃO EM LÓGICA INDUTIVA\\nA programação em lógica indutiva (PLI) combina métodos indutivos com o poder das\\nrepresentações de primeira ordem, concentrando-se em particular na representação de teorias como\\nprogramas lógicos.\\n3\\n Ela ganhou popularidade por três razões. Primeiro, a PLI oferece uma\\nabordagem rigorosa para o problema de aprendizagem indutiva baseada no conhecimento geral. Em\\nsegundo lugar, ela oferece algoritmos completos para induzir teorias gerais de primeira ordem a\\npartir de exemplos que podem, portanto, aprender com sucesso em domínios nos quais os algoritmos\\nbaseados em atributos dificilmente se aplicam. Um exemplo está na aprendizagem de como as\\nestruturas de proteínas se entrelaçam (\\nFigura 19.10\\n). A configuração tridimensional de uma molécula\\nde proteína não pode ser representada de modo razoável por um conjunto de atributos porque a\\nconfiguração se refere inerentemente a \\nrelacionamentos\\n entre objetos, e não a atributos de um único\\nobjeto. A lógica de primeira ordem é uma linguagem apropriada para descrever os relacionamentos.\\nEm terceiro lugar, a programação em lógica indutiva produz hipóteses que são (relativamente) fáceis', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 907}),\n",
       " Document(page_content='de ler para os seres humanos. Por exemplo, a tradução em linguagem comum da \\nFigura 19.10\\n pode\\nser averiguada e criticada por biólogos. Isso significa que os sistemas de programação em lógica\\nindutiva podem participar do ciclo científico de experimentação, geração de hipóteses, debate e\\nrefutação. Tal participação não seria possível para sistemas que geram classificadores do tipo\\n“caixa-preta”, como redes neurais.\\nFigura 19.10\\n (a) e (b) mostram exemplos positivos e negativos, respectivamente, do conceito de\\n“barril de quatro hélices antiparalelas” no domínio de entrelaçamento de proteínas. Cada exemplo de\\nestrutura é codificado em uma expressão lógica de cerca de 100 conjunções, como\\nComprimentoTotal\\n(\\nD\\n2\\nmhr\\n, 118) \\n∧\\n \\nNúmeroHélices\\n(\\nD\\n2\\nmhr\\n, 6) \\n∧\\n…. A partir dessas descrições e\\nde classificações como \\nEntrelaçar\\n(BARRIL-DE-QUATRO-HELICES-ANTIPARALELAS, \\nD\\n2\\nmhr\\n),\\no sistema PLI PROGOL (Muggleton, 1995) aprendeu a regra a seguir:\\nEssa espécie de regra não poderia ser aprendida, ou mesmo representada, por um mecanismo\\nbaseado em atributos, como os que vimos em capítulos anteriores. A regra pode ser traduzida para\\nlinguagem comum como: “A proteína \\np\\n tem classe de entrelaçamento de ‘barril de quatro hélices\\nantiparalelas’ se contém uma longa hélice \\nh\\n1\\n em uma posição de estrutura secundária entre 1 e 3, e \\nh\\n1\\nestá ao lado de uma segunda hélice”.\\n19.5.1 Um exemplo', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 908}),\n",
       " Document(page_content='Vimos na Equação 19.5 que a solução do problema geral de indução baseada no conhecimento\\nconsiste em “resolver” a restrição de consequência lógica\\npara a incógnita \\nHipótese\\n, dado o conhecimento de \\nBase\\n e exemplos descritos por \\nDescrições\\n e\\nClassificações\\n. Para ilustrar esse fato, utilizaremos o problema da aprendizagem de relacionamentos\\nde família a partir de exemplos. As descrições consistirão em uma árvore genealógica estendida,\\ndescrita em termos das relações \\nMãe\\n, \\nPai\\n e \\nCasado\\n e das propriedades \\nHomem\\n e \\nMulher\\n. Como\\nexemplo, usaremos a árvore genealógica do Exercício 8.14 mostrada na \\nFigura 19.11\\n. As descrições\\ncorrespondentes são:\\nFigura 19.11\\n Árvore genealógica típica.\\nAs sentenças em \\nClassificações\\n dependem do conceito-alvo que está sendo aprendido. Por\\nexemplo, talvez queiramos aprender \\nAvô\\n, \\nCunhado\\n ou \\nAncestral\\n. Para \\nAvô\\n, o conjunto completo de\\nClassificações\\n contém 20 × 20 = 400 conjuntos da forma:\\nÉ claro que poderíamos aprender a partir de um subconjunto desse conjunto completo.\\nO objetivo de um programa de aprendizagem indutivo é apresentar um conjunto de sentenças para\\na \\nHipótese\\n tal que a restrição de consequência lógica seja satisfeita. Suponha, por um instante, que o\\nagente não tenha nenhum conhecimento prático: a \\nBase\\n está vazia. Então, uma solução possível para\\nHipótese\\n é:\\nNote que um algoritmo de aprendizagem baseado em atributos, como APRENDIZAGEM-\\nEMÁRVORE-DE-DECISÃO, não chegará a lugar nenhum na resolução desse problema. Para', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 909}),\n",
       " Document(page_content='expressar \\nAvô\\n como um atributo (isto é, um predicado unário), precisaríamos transformar \\npares\\n de\\npessoas em objetos:\\nAvô\\n(\\n〈\\nMum\\n, \\nCharles\\n〉\\n)…\\nAssim, ficamos paralisados, tentando representar as descrições do exemplo. Os únicos atributos\\npossíveis são itens horríveis como:\\nPrimeiroElementoÉMãeDeElizabeth\\n(\\n〈\\nMum\\n, \\nCharles\\n〉\\n).\\n A definição de \\nAvô\\n em termos desses atributos simplesmente se torna uma grande disjunção de\\ncasos específicos que não se generaliza de modo algum para novos exemplos. \\nOs algoritmos de\\naprendizagem baseados em atributos são incapazes de aprender predicados relacionais\\n. Desse\\nmodo, uma das principais vantagens dos algoritmos de PLI é sua aplicabilidade a uma faixa muito\\nmais ampla de problemas, incluindo problemas relacionais.\\nO leitor certamente terá notado que um pouco de conhecimento prático ajudaria na representação\\nda definição de \\nAvô\\n. Por exemplo, se a \\nBase\\n incluísse a sentença\\na definição de \\nAvô\\n seria reduzida a\\nIsso mostra como o conhecimento prático pode reduzir drasticamente o tamanho de hipóteses\\nexigidas para explicar as observações.\\nTambém é possível para os algoritmos de PLI \\ncriar\\n novos predicados, a fim de facilitar a\\nexpressão de hipóteses explicativas. Considerando-se os dados de exemplo mostrados antes, é\\ncompletamente razoável para o programa de PLI propor um predicado adicional, que chamaríamos\\nde “\\nPai\\n”, a fim de simplificar as definições dos predicados-alvo. Os algoritmos que podem gerar\\nnovos predicados são chamados algoritmos de \\nindução construtiva\\n. É claro que a indução\\nconstrutiva é uma parte necessária do quadro de aprendizagem cumulativo esboçado na introdução.\\nEla ainda é um dos problemas mais difíceis de aprendizagem de máquina, mas algumas técnicas de\\nPLI fornecem mecanismos efetivos para alcançá-la.\\nNo restante deste capítulo, estudaremos as duas abordagens principais para PLI. A primeira utiliza\\numa generalização de métodos de árvores de decisão, e a segunda emprega técnicas baseadas na\\ninversão de uma prova de resolução.\\n19.5.2 Métodos top-down para aprendizagem indutiva\\nA primeira abordagem para PLI funciona a partir de uma regra muito geral e segue especializando-\\na gradualmente de modo que ela se adapte aos dados. Isso é essencialmente o que acontece na\\naprendizagem de árvores de decisão, na qual uma árvore de decisão é gradualmente ampliada até se', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 910}),\n",
       " Document(page_content='tornar consistente com as observações. Para realizar a PLI, utilizamos literais de primeira ordem em\\nlugar de atributos, e a hipótese é um conjunto de cláusulas em vez de uma árvore de decisão. Esta\\nseção descreve o FOIL (Quinlan, 1990), um dos primeiros programas de PLI.\\nVamos supor que estamos tentando aprender uma definição do predicado \\nAvô\\n(\\nx\\n, \\ny\\n), usando os\\nmesmos dados de família de antes. Como ocorre com a aprendizagem de árvores de decisão,\\npodemos dividir os exemplos em exemplos positivos e negativos. Os exemplos positivos são\\ne os exemplos negativos são\\nNote que cada exemplo é um \\npar\\n de objetos porque \\nAvô\\n é um predicado binário. Ao todo, existem\\n12 exemplos positivos na árvore genealógica e 388 exemplos negativos (todos os outros pares de\\npessoas).\\nO FOIL constrói um conjunto de cláusulas, cada uma com \\nAvô\\n(\\nx\\n, \\ny\\n) como o início. As cláusulas\\ndevem classificar os 12 exemplos positivos como instâncias do relacionamento \\nAvô\\n(\\nx\\n, \\ny\\n), ao mesmo\\ntempo que eliminam os 388 exemplos negativos. As cláusulas são cláusulas de Horn, com a extensão\\nque literais negados são permitidos no corpo de uma cláusula e interpretados usando negação por\\nfalha, como em Prolog. A cláusula inicial tem um corpo vazio:\\n⇒\\n \\nAvô\\n(\\nx\\n, \\ny\\n).\\nEssa cláusula classifica todo exemplo como positivo e, assim, precisa ser especializada. Fazemos\\nisso adicionando literais um a um no lado esquerdo. Aqui estão três inclusões potenciais:\\n(Note que estamos supondo que uma cláusula que define \\nPai\\n já faz parte do conhecimento prático.) A\\nprimeira dessas três cláusulas classifica incorretamente todos os 12 exemplos positivos como\\nnegativos e, portanto, pode ser ignorada. A segunda e a terceira cláusulas concordam com todos os\\nexemplos positivos, mas a segunda é incorreta sobre uma fração maior dos exemplos negativos — o\\ndobro de vezes porque permite mães, bem como pais. Consequentemente, preferimos a terceira\\ncláusula.\\nAgora, precisamos especializar ainda mais essa cláusula, a fim de eliminar os casos em que \\nx\\n é o\\npai de algum \\nz\\n, mas \\nz\\n não é um pai de \\ny\\n. A inclusão do único literal \\nPai\\n(\\nz\\n, \\ny\\n) fornece\\nque classifica corretamente todos os exemplos. O FOIL descobrirá e escolherá esse literal,\\nresolvendo assim a tarefa de aprendizagem. Em geral, a solução é um conjunto de cláusulas de Horn,\\ncada uma das quais implica o predicado-alvo. Por exemplo, se não tivéssemos o predicado \\nPai\\n em\\nnosso vocabulário, a solução poderia ser', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 911}),\n",
       " Document(page_content='Observe que cada uma dessas cláusulas abrange alguns dos exemplos positivos que, juntos,\\nabrangem todos os exemplos positivos, e que a CLÁUSULA-NOVA é projetada de tal forma que\\nnenhuma cláusula vai abranger incorretamente um exemplo negativo. Em geral, o FOIL terá de buscar\\npor muitas cláusulas malsucedidas antes de encontrar uma solução correta.\\nEsse exemplo é uma ilustraçãomuito simples de como o FOIL opera. Um esboço do algoritmo\\ncompleto é mostrado na \\nFigura 19.12\\n. Em essência, o algoritmo constrói repetidamente uma cláusula,\\nliteral por literal, até que ela concorde com algum subconjunto dos exemplos positivos e com nenhum\\ndos exemplos negativos. Então, os exemplos positivos cobertos pela cláusula são removidos do\\nconjunto de treinamento, e o processo continua até não restar nenhum exemplo positivo. As duas\\nprincipais sub-rotinas que serão explicadas são NOVOS-LITERAIS, a qual constrói todos os novos\\nliterais possíveis para adicionar à cláusula, e ESCOLHER-LITERAL, que seleciona um literal para\\ninclusão.\\nfunção\\n FOIL(\\nexemplos\\n, \\ndestino\\n) \\nretorna\\n um conjunto de cláusulas de Horn\\n    \\nentradas:\\n \\nexemplos\\n, conjunto de exemplos\\ndestino\\n, um literal correspondente ao predicado objetivo\\n    \\nvariáveis locais:\\n \\ncláusulas\\n, um conjunto de cláusulas, inicialmente vazio\\n    \\nenquanto\\n \\nexemplos\\n contém exemplos positivos \\nfaça\\n        \\ncláusula\\n ← NOVA-CLÁUSULA(\\nexemplos\\n, \\ndestino\\n)\\n        remover exemplos cobertos por \\ncláusula\\n de \\nexemplos\\n        adicionar \\ncláusula\\n a \\ncláusulas\\n    \\nretornar\\n \\ncláusulas\\n_____________________________________________________________________________________________________________\\nfunção\\n NOVA-CLÁUSULA(\\nexemplos\\n, \\ndestino\\n) \\nretorna\\n uma cláusula de Horn\\n    \\nvariáveis locais:\\n \\ncláusula\\n, uma cláusula com \\ndestino\\n como início e um corpo vazio\\nl\\n, um literal a ser adicionado à cláusula\\nexemplos\\n_\\nestendidos\\n, um conjunto de exemplos com valores para novas variáveis\\n    \\nexemplos\\n_\\nestendidos\\n ← \\nexemplos\\n    \\nenquanto\\n \\nexemplos\\n_\\nestendidos\\n contém exemplos negativos \\nfaça\\n        \\nl\\n ← ESCOLHER-LITERAL(NOVOS-LITERAIS(\\ncláusula\\n), \\nexemplos\\n_\\nestendidos\\n)\\n        acrescentar \\nl\\n ao corpo de \\ncláusula\\n        \\nexemplos\\n_\\nestendidos\\n ← conjunto de exemplos criados pela aplicação de ESTENDER-EXEMPLO a cada exemplo\\n            em \\nexemplos\\n_\\nestendidos\\n    \\nretornar\\n \\ncláusula\\n_____________________________________________________________________________________________________________\\nfunção\\n ESTENDER-EXEMPLO(\\nexemplo\\n, \\nliteral\\n) \\nretorna\\n    \\nse\\n \\nexemplo\\n satisfaz o \\nliteral\\n            \\nentão retornar\\n o conjunto de exemplos criados estendendo-se \\nexemplo\\n com cada valor constante possível para cada nova\\nvariável em \\nliteral', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 912}),\n",
       " Document(page_content='senão retornar\\n o conjunto vazio\\nFigura 19.12\\n Um esboço do algoritmo FOIL para aprendizagem de conjuntos de cláusulas de Horn de\\nprimeira ordem a partir de exemplos.\\nNOVOS-LITERAIS recebe uma cláusula e constrói todos os possíveis literais “úteis” que\\npoderiam ser adicionados à cláusula. Vamos usar como exemplo a cláusula\\nPai\\n(\\nx\\n, \\nz\\n) \\n⇒\\n \\nAvô\\n(\\nx\\n, \\ny\\n).\\nExistem três tipos de literais que podem ser adicionados:\\n1. \\nLiterais que utilizam predicados:\\n os literais podem ser negados ou não negados, podendo ser\\nutilizado qualquer predicado existente (inclusive o predicado objetivo), e todos os argumentos\\ndevem ser variáveis. Qualquer variável pode ser usada para qualquer argumento do predicado,\\ncom uma única restrição: cada literal deve incluir \\npelo menos uma\\n variável de um literal\\nanterior ou do início da cláusula. Literais como \\nMãe\\n(\\nz\\n, \\nu\\n), \\nCasado\\n(\\nz\\n, \\nz\\n), ¬\\nHomem\\n(\\ny\\n) e \\nAvô\\n(\\nv\\n,\\nx\\n) são permitidos, enquanto \\nCasado\\n(\\nu\\n, \\nv\\n) não é. Note que o uso do predicado do início da\\ncláusula permite ao FOIL aprender definições \\nrecursivas\\n.\\n2. \\nLiterais de igualdade e desigualdade\\n: esses literais relacionam variáveis que já aparecem na\\ncláusula. Por exemplo, poderíamos adicionar \\nz\\n ≠ \\nx\\n. Esses literais também podem incluir\\nconstantes especificadas pelo usuário. Para aprendizagem aritmética, poderíamos utilizar 0 e 1\\ne, para aprendizagem de funções de listas, poderíamos empregar a lista vazia [ ].\\n3. \\nComparações aritméticas\\n: quando lidamos com funções de variáveis contínuas, literais como \\nx\\n> \\ny\\n e \\ny\\n ≤ \\nz\\n podem ser adicionados. Como na aprendizagem em árvores de decisão, um valor de\\nlimiar constante pode ser escolhido para maximizar a capacidade de distinção do teste.\\nO fator de ramificação resultante nesse espaço de busca é muito grande (veja o Exercício 19.6),\\nmas o FOIL também pode usar informações de tipo para reduzi-lo. Por exemplo, se o domínio\\nincluísse números, NOVOS-LITERAIS e ESCOLHER-LITERAL são explicados no texto. bem como\\npessoas, as restrições de tipo impediriam NOVOS-LITERAIS de gerar literais como \\nPai\\n(\\nx\\n, \\nn\\n), onde\\nx\\n é uma pessoa e \\nn\\n é um número.\\nESCOLHER-LITERAL utiliza uma heurística de certa forma semelhante ao ganho de informações\\npara decidir que literal adicionar. Os detalhes exatos não são tão importantes aqui, e diversas\\nvariações foram experimentadas. Uma característica adicional interessante do FOIL é o uso da\\nnavalha de Ockham para eliminar algumas hipóteses. Se uma cláusula se tornar mais longa (de\\nacordo com alguma métrica) que o comprimento total dos exemplos positivos que a cláusula explica,\\nessa cláusula não será considerada uma hipótese potencial. Essa técnica fornece um caminho para se\\nevitar cláusulas supercomplexas que inserem ruído nos dados.\\nO FOIL e seus semelhantes foram usados para aprender uma ampla variedade de definições. Uma\\ndas demonstrações mais impressionantes (Quinlan e Cameron-Jones, 1993) envolvia a resolução de\\numa longa sequência de exercícios sobre funções de processamento de listas do livro didático sobre\\nProlog de Bratko (1986). Em cada caso, o programa foi capaz de aprender uma definição correta da', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 913}),\n",
       " Document(page_content='função a partir de um conjunto pequeno de exemplos usando as funções anteriormente aprendidas\\ncomo conhecimento prático.\\n19.5.3 Aprendizagem indutiva com dedução inversa\\nA egunda abordagem importante para PLI envolve a inversão do processo normal de prova\\ndedutiva. A \\nresolução inversa\\n se baseia na observação de que, se o exemplo \\nClassificações\\n decorre\\nde \\nConhecimentoPrático\\n \\n∧\\n \\nHipótese\\n \\n∧\\n \\nDescrições\\n, devemos ser capazes de provar esse fato por\\nresolução (porque a resolução é completa). Se pudermos “executar a prova no sentido inverso”, será\\npossível encontrar uma \\nHipótese\\n tal que a prova seja válida. Portanto, a chave é descobrir um modo\\nde inverter o processo de resolução.\\nMostraremos um processo de prova em sentido contrário para resolução inversa que consiste em\\netapas individuais em sentido oposto. Lembre-se de que um passo de resolução comum recebe duas\\ncláusulas \\nC\\n1\\n e \\nC\\n2\\n, e as resolve para produzir o \\nresolvente\\n \\nC\\n. Um passo de resolução inversa recebe\\num resolvente \\nC\\n e produz duas cláusulas \\nC\\n1\\n e \\nC\\n2\\n, tais que \\nC\\n seja o resultado da resolução de \\nC\\n1\\n e \\nC\\n2\\n.\\nOutra alternativa seria receber um resolvente \\nC\\n e uma cláusula \\nC\\n1\\n, e produzir uma cláusula \\nC\\n2\\n tal que\\nC\\n seja o resultado da resolução de \\nC\\n1\\n e \\nC\\n2\\n.\\nAs primeiras etapas em um processo de resolução inversa são mostradas na \\nFigura 19.13\\n, onde\\nnos concentramos no exemplo positivo \\nAvô\\n(\\nGeorge\\n, \\nAnne\\n). O processo começa no final da prova\\n(mostrado na parte inferior da figura). Tomamos o resolvente \\nC\\n como a cláusula vazia (isto é, uma\\ncontradição) e \\nC\\n2\\n como ¬\\nAvô\\n(\\nGeorge\\n, \\nAnne\\n), que é a negação do exemplo de objetivo. O primeiro\\npasso inverso recebe \\nC\\n e \\nC\\n2\\n, e gera a cláusula \\nAvô\\n(\\nGeorge\\n, \\nAnne\\n) para \\nC\\n1\\n. O passo seguinte recebe\\nessa cláusula como \\nC\\n e a cláusula \\nPai\\n(\\nElizabeth\\n, \\nAnne\\n) como \\nC\\n2\\n, e gera a cláusula\\nFigura 19.13\\n Passos iniciais em um processo de resolução inversa. As cláusulas sombreadas são\\ngeradas por passos de resolução inversa a partir da cláusula à direita e da cláusula abaixo delas. As\\ncláusulas não sombreadas vêm de \\nDescrições\\n e \\nClassificações\\n (incluindo \\nClassificações\\n negadas).\\n¬\\nPai\\n(\\nElizabeth\\n, \\ny\\n) \\n∨\\n \\nAvô\\n(\\nGeorge\\n, \\ny\\n)\\ncomo \\nC\\n1\\n. A etapa final trata essa cláusula como o resolvente. Tendo \\nPai\\n(\\nGeorge\\n, \\nElizabeth\\n) como', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 914}),\n",
       " Document(page_content='C\\n2\\n, uma cláusula \\nC\\n1\\n possível é a hipótese:\\nPai\\n(\\nx\\n, \\nz\\n) \\n∧\\n \\nPai\\n(\\nz\\n, \\ny\\n) \\n⇒\\n \\nPai\\n(\\nx\\n, \\ny\\n).\\nAgora, temos uma prova de resolução de que a hipótese, as descrições e o conhecimento prático\\nimpõem a classificação \\nAvô\\n(\\nGeorge\\n, \\nAnne\\n).\\nÉ claro que a resolução inversa envolve uma busca. Cada etapa de resolução inversa é não\\ndeterminística porque, para qualquer \\nC\\n, pode haver muitas ou até mesmo um número infinito de\\ncláusulas \\nC\\n1\\n e \\nC\\n2\\n que se resolvem em \\nC\\n. Por exemplo, em vez de escolher ¬\\nPai\\n(\\nElizabeth\\n, \\ny\\n) \\n∨\\nAvô\\n(\\nGeorge\\n, \\ny\\n) para \\nC\\n1\\n na última etapa da \\nFigura 19.13\\n, a etapa de resolução inversa poderia ter\\nescolhido qualquer das sentenças a seguir:\\n(Veja os Exercícios 19.4 e 19.5.) Além disso, as cláusulas que participam de cada passo podem ser\\nescolhidas a partir do conhecimento de \\nBase\\n, a partir do exemplo \\nDescrições\\n, a partir da negação de\\nClassificações\\n ou a partir de cláusulas hipotéticas que já tenham sido geradas na árvore de resolução\\ninversa. O grande número de possibilidades indica um grande fator de ramificação (e, portanto, uma\\nbusca ineficiente) sem controles adicionais. Várias abordagens para ajustar a busca foram\\nexperimentadas em sistemas de PLI implementados:\\n1. Escolhas redundantes podem ser eliminadas — por exemplo, gerando apenas as hipóteses mais\\nespecíficas possíveis e exigindo que todas as cláusulas hipotéticas sejam consistentes umas\\ncom as outras e com as observações. Este último critério elimina a cláusula ¬\\nPai\\n(\\nz\\n, \\ny\\n) \\n∨\\nAvô\\n(\\nGeorge\\n, \\ny\\n), listada antes.\\n2. A estratégia de prova pode ser restrita. Por exemplo, vimos no Capítulo 9 que a \\nresolução\\nlinear\\n é uma estratégia restrita completa. A resolução linear produz árvores de prova que têm\\numa estrutura de ramificação linear — a árvore inteira segue uma linha, com apenas uma única\\nramificação de cláusulas fora de linha (como na \\nFigura 19.13\\n)\\n3. A linguagem de representação pode ser restrita, por exemplo, eliminando símbolos de funções\\nou permitindo apenas cláusulas de Horn. Para exemplificar, o PROGOL opera com cláusulas de\\nHorn usando a \\nconsequência lógica inversa\\n. A ideia é alterar a restrição de consequência\\nlógica\\npara a forma logicamente equivalente\\n   A partir disso, podemos utilizar um processo semelhante ao da dedução normal de cláusulas\\nde Horn de Prolog, com negação por falha, para derivar \\nHipótese\\n. Pelo fato de ser restrito a', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 915}),\n",
       " Document(page_content='cláusulas de Horn, esse é um método incompleto, mas pode ser mais eficiente que a resolução\\ncompleta. Também é possível aplicar a inferência completa com a consequência lógica inversa\\n(Inoue, 2001).\\n4. A inferência pode ser feita com verificação de modelos, em prova de teoremas. O sistema\\nPROGOL (Muggleton, 1995) utiliza uma forma de verificação de modelos para limitar a busca.\\nIsto é, de modo semelhante à programação de conjuntos de resposta, ele gera valores possíveis\\npara variáveis lógicas e verifica a consistência.\\n5. A inferência pode ser realizada com cláusulas proposicionais básicas em lugar da lógica de\\nprimeira ordem. O sistema LINUS (Lavrauc e Duzeroski, 1994) funciona convertendo teorias\\nde primeira ordem em lógica proposicional, resolvendo-as com um sistema de aprendizagem\\nproposicional e depois fazendo a conversão de volta. O trabalho com fórmulas proposicionais\\npode ser mais eficiente em alguns problemas, como vimos no caso de SATPLAN no Capítulo\\n10.\\n19.5.4 Fazendo descobertas com programação em lógica indutiva\\nUm procedimento de resolução inversa que inverte uma estratégia de resolução completa é, em\\nprincípio,um algoritmo completo para aprendizagem de teorias de primeira ordem. Ou seja, se\\nalguma incógnita \\nHipótese\\n gerar um conjunto de exemplos, um procedimento de resolução inversa\\npoderá gerar \\nHipótese\\n a partir dos exemplos. Essa observação sugere uma possibilidade\\ninteressante: suponha que os exemplos disponíveis incluam uma variedade de trajetórias de corpos\\nem queda livre. Um programa de resolução inversa seria teoricamente capaz de deduzir a lei da\\ngravidade? Sem dúvida, a resposta é sim porque a lei da gravidade permite explicar os exemplos,\\ndados os cálculos matemáticos práticos adequados. De modo semelhante, poderíamos imaginar que o\\neletromagnetismo, a mecânica quântica e a teoria da relatividade também estejam dentro do escopo\\nde programas de PLI. É claro que eles também estão dentro do escopo de um macaco com uma\\nmáquina de escrever; ainda precisaremos de heurísticas melhores e de novas alternativas para\\nestruturar o espaço de busca.\\nUma coisa que os sistemas de resolução inversa \\nfarão\\n por você será criar novos predicados. Com\\nfrequência, essa habilidade é vista como algo mágico porque os computadores muitas vezes são\\nconsiderados máquinas que “meramente funcionam com as informações que recebem”. De fato, novos\\npredicados recaem diretamente fora da etapa de resolução inversa. O caso mais simples surge\\nquando consideramos por hipótese duas novas cláusulas, \\nC\\n1\\n e \\nC\\n2\\n, dada uma cláusula \\nC\\n. A resolução\\nde \\nC\\n1\\n e \\nC\\n2\\n elimina um literal que as duas cláusulas compartilham; consequentemente, é bastante\\npossível que o literal eliminado contivesse um predicado que não aparece em \\nC\\n. Desse modo, ao se\\ntrabalhar no sentido contrário, uma possibilidade é gerar um novo predicado a partir do qual será\\nreconstruído o literal que falta.\\nA \\nFigura 19.14\\n mostra um exemplo em que o novo predicado \\nP\\n é gerado no processo de\\naprendizagem de uma definição para \\nAncestral\\n. Uma vez gerado, \\nP\\n pode ser usado em etapas\\nposteriores de resolução inversa. Por exemplo, uma etapa posterior poderia definir hipoteticamente\\nMãe\\n(\\nx\\n, \\ny\\n) \\n⇒\\n \\nP\\n(\\nx\\n, \\ny\\n). Desse modo, o novo predicado \\nP\\n tem seu significado limitado pela geração de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 916}),\n",
       " Document(page_content='hipóteses que o envolvem. Outro exemplo poderia levar à restrição \\nPai\\n(\\nx\\n, \\ny\\n) \\n⇒\\n \\nP\\n(\\nx\\n, \\ny\\n). Em outras\\npalavras, o predicado \\nP\\n é o que normalmente imaginamos como o relacionamento de \\nPai\\n. Como\\nmencionamos antes, a criação de novos predicados pode reduzir de forma significativa o tamanho da\\ndefinição do predicado objetivo. Consequentemente, pela inclusão da habilidade para criar novos\\npredicados, os sistemas de resolução inversa com frequência podem resolver problemas de\\naprendizagem que são inviáveis com outras técnicas.\\nFigura 19.14\\n Uma etapa de resolução inversa que gera um novo predicado \\nP\\n.\\nAlgumas das mais profundas revoluções na ciência vêm da criação de novos predicados e funções\\n— por exemplo, a descoberta da aceleração por Galileu ou a descoberta da energia térmica por\\nJoule. Uma vez que esses termos estão disponíveis, a descoberta de novas leis se torna\\n(relativamente) fácil. A parte difícil reside na percepção de que alguma nova entidade, mantendo um\\nrelacionamento específico com entidades existentes, permitirá que todo um conjunto de observações\\nseja explicado com uma teoria muito mais simples e mais elegante do que tudo o que existia\\nanteriormente.\\nAté agora, os sistemas de PLI não fizeram descobertas no nível de Galileu ou Joule, mas suas\\ndescobertas foram consideradas publicáveis na literatura científica. Por exemplo, no \\nJournal of\\nMolecular Biology\\n, Turcotte \\net al\\n. (2001) descrevem a descoberta automatizada de regras para\\nentrelaçamento de proteínas pelo programa de PLI PROGOL. Muitas das regras descobertas pelo\\nprograma PROGOL poderiam ter sido derivadas a partir de princípios conhecidos, mas a maioria\\ndelas não tinha sido publicada anteriormente como parte de um banco de dados biológico padrão\\n(veja um exemplo na \\nFigura 19.10\\n). Em um trabalho relacionado, Srinivasan \\net al\\n. (1994) lidaram\\ncom o problema de descobrir regras baseadas na estrutura molecular para o caráter mutagênico de\\ncompostos nitrocompostos aromáticos. Esses compostos são encontrados em gases emitidos por\\nautomóveis. No caso de 80% dos compostos encontrados em um banco de dados padrão, é possível\\nidentificar quatro características importantes, e a regressão linear sobre essas características supera\\na PLI. Para os 20% restantes, as características sozinhas não podem ser previstas, e a PLI identifica\\nrelacionamentos que lhe permitem superar o desempenho da regressão linear, das redes neurais e das\\nárvores de decisão. O mais impressionante é que King \\net al\\n. (2009) dotaram um robô com a\\ncapacidade de realizar experimentos de biologia molecular e estenderam as técnicas de PLI para\\nincluir um projeto experimental, criando assim um cientista autônomo que realmente descobriu novos\\nconhecimentos sobre a genômica funcional da levedura.\\nPara todos esses exemplos, parece que a habilidade de representar relações e de usar o\\nconhecimento prático contribui para o alto desempenho da PLI. O fato de as regras encontradas pela\\nPLI poderem ser interpretadas pelos seres humanos contribui para a aceitação dessas técnicas em\\nperiódicos de biologia, e não apenas em perió\\u200bdicos de ciência da computação.\\nA PLI realizou contribuições para outras ciências além da biologia. Uma das mais importantes é o', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 917}),\n",
       " Document(page_content='processamento de linguagem natural, no qual a PLI foi usada para extrair informações relacionais\\ncomplexas a partir de texto. Esses resultados estão resumidos no Capítulo 23.\\n19.6 RESUMO\\nEste capítulo investigou vários modos pelos quais o conhecimento \\na priori\\n pode ajudar um agente\\na aprender a partir de novas experiências. Como muito conhecimento \\na priori\\n é expresso em termos\\nde modelos relacionais, e não em modelos baseados em atributos, também estudamos sistemas que\\npermitem a aprendizagem de modelos relacionais. Os pontos importantes são:\\n•  O uso do conhecimento \\na priori\\n na aprendizagem leva a um quadro de \\naprendizagem\\ncumulativa\\n, no qual os agentes de aprendizagem melhoram sua habilidade de aprender à medida\\nque adquirem mais conhecimento.\\n•  O conhecimento \\na priori\\n ajuda na aprendizagem, eliminando hipóteses que de outra forma seriam\\nconsistentes e “completando” a explicação de exemplos, permitindo assim hipóteses mais curtas.\\nCom frequência, essas contribuições resultam em aprendizagem mais rápida a partir de um\\nnúmero menor de exemplos.\\n•  Compreender os diferentes papéis lógicos assumidos pelo conhecimento \\na priori\\n, expressos por\\nrestrições de consequência lógica\\n, ajuda a definir uma variedade de técnicas de aprendizagem.\\n•  A \\naprendizagem baseada em explanação\\n (ABE) extrai regras gerais a partir de exemplos\\nisolados \\nexplicando\\n os exemplos e generalizando a explanação. Ela fornece um método dedutivo\\nque transforma o conhecimento de princípios básicos em experiência útil, eficiente e de uso\\nespecial.\\n•  A \\naprendizagem baseada na relevância\\n (ABR) utiliza o conhecimento \\na priori\\n na forma de\\ndeterminações para identificar os atributos relevantes, gerando assim um espaço de hipóteses\\nreduzido e acelerando a aprendizagem. A ABR também permite generalizações dedutivas a partir\\nde exemplos isolados.\\n•  A \\naprendizagem indutiva baseada no conhecimento\\n (AIBC) encontra hipóteses indutivas que\\nexplicam conjuntos de observações com a ajuda de conhecimento prático.\\n•  As técnicas de \\nprogramação em lógica indutiva\\n (PLI) executam a AIBC sobre conhecimento\\nexpresso em lógica de primeira ordem. Os métodos de PLI podem aprender conhecimento\\nrelacional que não pode ser expresso em sistemas baseados em atributos.\\n•  A PLI pode ser realizada com uma abordagem top-down de refinar uma regra muito geral ou por\\nmeio de uma abordagem bottom-up de inversão do processo dedutivo.\\n•  Os métodos de PLI geram naturalmente novos predicados com os quais podem ser expressas\\nnovas teorias concisas e se mostram promissores como sistemas de formação de teorias\\ncientíficas de uso geral.\\nNOTAS BIBLIOGRÁFICAS E HISTÓRICAS\\nEmbora o uso do conhecimento \\na priori\\n na aprendizagem pudesse parecer um tópico natural para', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 918}),\n",
       " Document(page_content='os filósofos da ciência, pouco trabalho formal foi realizado até recentemente. A obra \\nFact, Fiction,\\nand Forecast\\n, do filósofo Nelson Goodman (1954), refutou a suposição anterior de que a indução era\\nsimplesmente uma questão de ver exemplos suficientes de alguma proposição universalmente\\nquantificada e depois adotá-la como hipótese. Considere, por exemplo, a hipótese “todas as\\nesmeraldas são \\ngrue\\n” (\\ngreen\\n + \\nblue\\n : verde + azul), onde \\ngrue\\n significa “verdes, se observadas\\nantes do tempo \\nt\\n, mas azuis se observadas depois disso”. Em qualquer instante até \\nt\\n, poderíamos ter\\nobservado milhões de instâncias confirmando a regra de que as esmeraldas são \\ngrue\\n e nenhuma\\ninstância contrária a essa regra, e ainda assim estaríamos pouco dispostos a adotá-la. Isso pode ser\\nexplicado apenas pelo apelo à função do conhecimento \\na priori\\n relevante no processo de indução.\\nGoodman propõe uma variedade de tipos diferentes de conhecimento \\na priori\\n que poderiam ser\\núteis, inclusive uma versão de determinações chamadas \\nsuper-hipóteses\\n. Infelizmente, as ideias de\\nGoodman nunca foram adotadas na aprendizagem de máquina.\\nA abordagem da \\nmelhor-hipótese-atual\\n é uma ideia antiga em filosofia (Mill, 1843). Um trabalho\\nantigo em psicologia cognitiva também sugeriu que é uma forma natural do conceito de aprendizagem\\nem seres humanos (Bruner \\net al\\n., 1957). Em IA, a abordagem é mais associada com o trabalho de\\nPatrick Winston, cuja tese de Ph.D. (Winston, 1970) abordou o problema de descrição de\\naprendizagem de objetos complexos. O método de \\nespaço de versão\\n (Mitchell, 1977, 1982) toma\\numa abordagem diferente, mantendo o conjunto de \\ntodas\\n as hipóteses consistentes e eliminando\\naquelas consideradas incompatíveis com novos exemplos. A abordagem foi utilizada no sistema\\nespecialista Meta-DENDRAL para a química (Buchanan e Mitchell, 1978) e, mais tarde, no sistema\\nLEX de Mitchell (1983), que aprende a resolver problemas de cálculo. O trabalho de Michalski e\\ncolegas formou um terceiro segmento influente na série de algoritmos AQ, aprendendo conjuntos de\\nregras lógicas (Michalski, 1969; Michalski \\net al\\n., 1986).\\nA ABE tem suas raízes nas técnicas usadas pelo planejador STRIPS (Fikes \\net al\\n., 1972). Quando\\num plano era construído, uma versão generalizada desse plano era guardada em uma biblioteca de\\nplanos e usada no planejamento posterior como um \\noperador macro\\n. Ideias semelhantes apareceram\\nna arquitetura ACT* de Anderson, sob o título \\ncompilação do conhecimento\\n (Anderson, 1983), e na\\narquitetura SOAR, como \\nformação de bloco\\n (Laird \\net al\\n., 1986). A \\naquisição de esquemas\\n(DeJong, 1981), a \\ngeneralização analítica\\n (Mitchell, 1982) e a \\ngeneralização baseada em\\nrestrições\\n (Minton, 1984) foram precursoras imediatas do rápido crescimento do interesse em ABE,\\nestimulado pelos ensaios de Mitchell \\net al\\n. (1986) e DeJong e Mooney (1986). Hirsh (1987)\\nintroduziu o algoritmo de ABE descrito no texto, mostrando como ele podia ser incorporado\\ndiretamente a um sistema de programação lógica. Van Harmelen e Bundy (1988) explicam a ABE\\ncomo uma variante do método de \\navaliação parcial\\n utilizada em sistemas de análise de programas\\n(Jones \\net al\\n., 1993).\\nO entusiasmo inicial pelo ABE foi temperado pelos achados de Minton (1988) que demonstraram\\nque, sem trabalho extra extensivo, o ABE poderia tornar um programa significativamente lento. A\\nanálise probabilística formal da recompensa esperada do ABE pode ser encontrada em Greiner\\n(1989) e Subramanian e Feldman (1990). Em Dietterich (1990) temos uma revisão excelente dos\\ntrabalhos iniciais sobre ABE.\\nEm vez de usar exemplos como foco para generalização, podemos usá-los diretamente para\\nresolver novos problemas, em um processo conhecido como \\nraciocínio analógico\\n. Essa forma de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 919}),\n",
       " Document(page_content='raciocínio varia desde uma forma de raciocínio plausível baseado em grau de semelhança (Gentner,\\n1983), passando por uma forma de inferência dedutiva baseada em determinações mas exigindo a\\nparticipação do exemplo (Davies e Russell, 1987), até uma forma de ABE “adiado” que adapta a\\ndireção da generalização do exemplo antigo às necessidades do novo problema. Esta última forma de\\nraciocínio analógico é encontrada mais comumente no \\nraciocínio baseado em casos\\n (Kolodner,\\n1993) e na \\nanalogia derivacional\\n (Veloso e Carbonell, 1993).\\nAs informações de relevância na forma de dependências funcionais foram desenvolvidas primeiro\\nna comunidade de banco de dados, onde foram empregadas para estruturar grandes conjuntos de\\natributos em subconjuntos manejáveis. As dependências funcionais foram usadas para raciocínio\\nanalógico por Carbonell e Collins (1973), e Davies e Russell (Davies, 1985; Davies e Russell,\\n1987) redescobriram e apresentaram uma análise lógica completa. Seu papel como conhecimento\\nprévio em aprendizagem indutiva foi explorado por Russell e Grosof (1987). A equivalência de\\ndeterminações a um espaço de hipóteses de vocabulário restrito foi provada em Russell (1988). Os\\nalgoritmos de aprendizagem para determinação e o desempenho otimizado obtido pelo AADBR\\nforam mostrados primeiro no algoritmo FOCUS em Almuallim e Dietterich (1991). Tadepalli (1993)\\ndescreve um algoritmo engenhoso para aprendizagem com determinações que mostram grandes\\nmelhorias na velocidade de aprendizagem.\\nA ideia de que a aprendizagem indutiva pode ser realizada por dedução inversa remonta a W. S.\\nJevons (1874), que escreveu: “O estudo da lógica formal e da teoria das probabilidades me levou a\\nadotar a opinião de que não existe algo que se possa considerar um método distinto de indução em\\ncontraste com a dedução, mas essa indução é simplesmente um emprego inverso da dedução.” As\\ninvestigações computacionais começaram com a importante tese de doutorado de Gordon Plotkin\\n(1971) em Edinburgh. Embora Plotkin desenvolvesse muitos dos teoremas e métodos que estão em\\nuso corrente na PLI, ele foi desencorajado por alguns resultados de indecidibilidade para certos\\nsubproblemas em indução. O MIS (Shapiro, 1981) reintroduziu o problema de aprender programas\\nde lógica, mas foi visto principalmente como uma contribuição para a teoria de depuração\\nautomatizada. O trabalho em indução de regras, como os sistemas ID3 (Quinlan, 1986) e CN2 (Clark\\ne Niblett, 1989), levou ao FOIL (Quinlan, 1990), que, pela primeira vez, permitia a indução prática\\nde regras relacionais. O campo de aprendizagem relacional foi revigorado por Muggleton e Buntine\\n(1988), cujo programa CIGOL incorporou uma versão ligeiramente incompleta da resolução inversa\\ne foi capaz de gerar novos predicados. O método de resolução inversa também aparece em Russel\\n(1986) com um algoritmo simples mostrado em nota de rodapé. O segundo sistema mais importante\\nfoi o GOLEM (Muggleton e Feng, 1990), que utiliza um algoritmo de cobertura baseado no conceito\\nde Plotkin de generalização relativa. O ITOU (Rouveirol e Puget, 1989) e o CLINT (De Raedt, 1992)\\nforam outros sistemas dessa época. Mais recentemente, o PROGOL (Muggleton, 1995) adotou uma\\nabordagem híbrida (top-down e bottom-up) para consequência lógica inversa, e foi aplicado a uma\\nsérie de problemas práticos, especificamente na biologia e em processamento de linguagens naturais.\\nMuggleton (2000) descreve uma extensão do PROGOL para manipular a incerteza na forma de\\nprogramas lógicos estocásticos.\\nUma análise formal de métodos de PLI aparece em Muggleton (1991), em uma grande coletânea de\\nartigos em Muggleton (1992), e em uma coletânea de técnicas e aplicações no livro de Lavrac e\\nDjzzeroski (1994). Page e Srinivasan (2002) fornecem uma visão geral mais recente da história e dos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 920}),\n",
       " Document(page_content='desafios do campo para o futuro. Os primeiros resultados de complexidade de Haussler (1989)\\nsugeriram que a aprendizagem de sentenças de primeira ordem era intratável. Porém, com melhor\\ncompreensão da importância de vários tipos de restrições sintáticas sobre cláusulas, foram obtidos\\nresultados positivos mesmo para cláusulas com recursão (Djzzeroski \\net al\\n., 1992). Os resultados de\\naprendizagem para PLI foram pesquisados por Kietz e Djzzeroski (1994) e por Cohen e Page (1995).\\nEmbora a PLI agora pareça ser a abordagem dominante para indução construtiva, ela não foi a\\núnica abordagem adotada. Os chamados \\nsistemas de descoberta\\n se destinam a modelar o processo\\nde descoberta científica de novos conceitos, em geral por uma busca direta no espaço de definições\\nde conceitos. O Automated Mathematician de Doug Lenat, ou AM (Davis e Lenat, 1982), usava\\nheurísticas de descoberta expressas como regras de sistemas especialistas para orientar sua busca de\\nconceitos e conjeturas em teoria elementar dos números. Diferentemente da maioria dos sistemas\\nprojetados para raciocínio matemático, o AM não tinha um conceito de prova e só podia fazer\\nconjeturas. Ele redescobriu a conjetura de Goldbach e o teorema de fatoração exclusiva de números\\nprimos. A arquitetura do AM foi generalizada no sistema EURISKO (Lenat, 1983) pela adição de um\\nmecanismo capaz de reescrever as heurísticas de descoberta do próprio sistema. O EURISKO foi\\naplicado em diversas áreas além da descoberta matemática, embora com menos sucesso que o AM.\\nA metodologia do AM e do EURISKO tem gerado controvérsias (Ritchie e Hanna, 1984; Lenat e\\nBrown, 1984).\\nOutra classe de sistemas de descoberta se destina a operar com dados científicos reais para\\ndescobrir novas leis. Os sistemas DALTON, GLAUBER e STAHL (Langley \\net al\\n., 1987) são\\nsistemas baseados em regras que procuram relacionamentos quantitativos em dados experimentais de\\nsistemas físicos; em cada caso, o sistema foi capaz de recapitular uma descoberta conhecida a partir\\nda história da ciência. Os sistemas de descoberta baseados em técnicas probabilísticas — em\\nespecial os algoritmos de formação de agrupamentos que descobrem novas categorias — são\\ndiscutidos no Capítulo 20.\\nEXERCÍCIOS\\n19.1\\n Mostre, por conversão em forma normal conjuntiva e aplicação da resolução, que a conclusão\\nda página 728 referente aos brasileiros é consistente.\\n19.2\\n Para cada uma das determinações a seguir, escreva a representação lógica e explique por que a\\ndeterminação é verdadeira (se for o caso):\\na.\\n O desenho e o valor determinam a massa de uma moeda.\\nb.\\n Para dado programa, a entrada determina a saída.\\nc.\\n O clima, a ingestão de alimentos, o exercício e o metabolismo determinam o ganho e a perda de\\npeso.\\nd.\\n A calvície é determinada pela calvície (ou pela falta dela) do avô materno de um indivíduo.\\n19.3\\n Uma versão probabilística de determinações seria útil? Sugira uma definição.\\n19.4\\n Preencha os valores que faltam para completar as cláusulas \\nC\\n1\\n ou \\nC\\n2\\n (ou ambas) nos conjuntos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 921}),\n",
       " Document(page_content='de cláusulas a seguir, dado que \\nC\\n é o resolvente de \\nC\\n1\\n e de \\nC\\n2\\n:\\na.\\n \\nC\\n = \\nVerdadeiro\\n \\n⇒\\n \\nP\\n(\\nA\\n, \\nB\\n), \\nC\\n1\\n = \\nP\\n(\\nx\\n, \\ny\\n) \\n⇒\\n \\nQ\\n(\\nx\\n, \\ny\\n), \\nC\\n2\\n = ??.\\nb.\\n \\nC\\n = \\nVerdadeiro\\n \\n⇒\\n \\nP\\n(\\nA\\n, \\nB\\n), \\nC\\n1\\n =??, \\nC\\n2\\n =??.\\nc.\\n \\nC\\n = \\nP\\n(\\nx\\n, \\ny\\n) \\n⇒\\n \\nP\\n(\\nx\\n, \\nf\\n(\\ny\\n)), \\nC\\n1\\n =??, \\nC\\n2\\n =??.\\nSe existir mais de uma solução possível, forneça um exemplo de cada tipo diferente.\\n19.5\\n Suponha que se escreva um programa em lógica que executa um passo de inferência de\\nresolução. Isto é, considere \\nResolver\\n(\\nc\\n1\\n, \\nc\\n2\\n, \\nc\\n) bem-sucedida se \\nc\\n é o resultado da resolução de \\nc\\n1\\n e\\nc\\n2\\n. Normalmente, \\nResolver\\n seria usada como parte de um provador de teoremas, chamando-a com \\nc\\n1\\ne \\nc\\n2\\n instanciadas para cláusulas específicas, gerando assim o resolvente \\nc\\n. Agora suponha que, em\\nvez disso, ela fosse chamada com \\nc\\n instanciada e com \\nc\\n1\\n e \\nc\\n2\\n não instanciadas. Essa rotina terá\\nsucesso na geração dos resultados apropriados de uma etapa de resolução inversa? Você precisaria\\nrealizar algumas modificações especiais no sistema de programação em lógica para isso funcionar?\\n19.6\\n Suponha que o FOIL esteja considerando a possibilidade de adicionar um literal a uma cláusula\\ncom a utilização de um predicado binário \\nP\\n e que literais anteriores (inclusive o início da cláusula)\\ncontenham cinco variáveis diferentes.\\na.\\n Quantos literais funcionalmente diferentes podem ser gerados? Dois literais são funcionalmente\\nidênticos se diferem apenas pelos nomes das \\nnovas\\n variáveis que contêm.\\nb.\\n Você poderia encontrar uma fórmula geral para o número de literais diferentes com um\\npredicado de aridade \\nr\\n quando existem \\nn\\n variáveis anteriormente usadas?\\nc.\\n Por que o FOIL não permite literais que não contêm nenhuma variável usada anteriormente?\\n19.7\\n Usando os dados da árvore genealógica da \\nFigura 19.11\\n ou de um subconjunto dessa árvore,\\naplique o algoritmo FOIL para aprender uma definição relativa ao predicado \\nAncestral\\n.\\n1\\n Os termos “falso positivo” e “falso negativo” são usados em medicina para descrever resultados errôneos de exames de laboratório. O\\nresultado é um falso positivo se indica que o paciente possui a doença quando, na verdade, ele não possui.\\n2\\n Supomos, por questão de simplicidade, que uma pessoa fala apenas um idioma. É claro que a regra também teria de ser aperfeiçoada\\npara países como a Suíça e a Índia.\\n3\\n Talvez fosse apropriado nesse momento para o leitor reportar-se ao Capítulo 7 com a finalidade de examinar alguns conceitos\\nsubjacentes, inclusive cláusulas de Horn, forma normal conjuntiva, unificação e resolução.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 922}),\n",
       " Document(page_content='O\\nCAPÍTULO\\n \\n20\\nAprendizagem de modelos probabilísticos\\nEm que visualizamos a aprendizagem como uma forma de raciocínio com\\nincerteza a partir de observações.\\nCapítulo 13 assinalou a prevalência da incerteza em ambientes reais. Os agentes podem\\nmanipular a incerteza usando os métodos de probabilidade e teoria da decisão, mas primeiro\\neles devem aprender suas teorias probabilísticas do mundo a partir da experiência. Este capítulo\\nexplica como é possível fazê-lo, pela formulação da tarefa de aprendizagem em si como um processo\\nde inferência probabilística (\\nSeção 20.1\\n). Veremos que uma visão bayesiana da aprendizagem é\\nextremamente poderosa, fornecendo soluções gerais para os problemas de ruído, superadaptação e\\nprevisão ótima. Ele também leva em conta o fato de que um agente que não seja onisciente nunca\\npoderá ter certeza sobre qual teoria do mundo é correta, mesmo que ainda tome decisões usando\\nalguma teoria de mundo.\\nDescreveremos métodos para modelos probabilísticos com aprendizagem — principalmente redes\\nbayesianas — nas Seções 20.2 e 20.3. Uma parte do material deste capítulo é bastante matemática,\\nembora as lições gerais possam ser entendidas sem a necessidade de mergulhar nos detalhes. O leitor\\npode tirar proveito de revisar o material dos Capítulos 13 e 14 e o Apêndice A.\\n20.1 APRENDIZAGEM ESTATÍSTICA\\nOs conceitos fundamentais deste capítulo, da mesma maneira que os do Capítulo 18, são \\ndados\\n e\\nhipóteses\\n. Aqui, os dados são \\nevidências\\n, isto é, instanciações de algumas ou de todas as variáveis\\naleatórias que descrevem o domínio. Neste capítulo, as hipóteses são teorias probabilísticas de como\\no domínio funciona, incluindo teorias lógicas como caso especial.\\nVamos considerar um exemplo simples. Nosso doce surpresa favorito tem dois sabores: cereja\\n(hum) e lima (eca). O fabricante de doces tem um senso de humor peculiar e embrulha cada pedaço\\nde doce na mesma embalagem opaca, independentemente do sabor. O doce é vendido em sacos muito\\ngrandes, dos quais existem cinco tipos conhecidos — novamente, indistinguíveis a partir do exterior:\\nh\\n1\\n: 100% cereja\\nh\\n2\\n: 75% cereja + 25% lima', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 924}),\n",
       " Document(page_content='h 2 : 75% cereja + 25% lima \\nh\\n3\\n: 50% cereja + 50% lima\\nh\\n4\\n: 25% cereja + 75% lima\\nh\\n5\\n: 100% lima\\nDado um novo saco de doces, a variável aleatória \\nH\\n (de \\nhipótese\\n) denota o tipo do saco, com\\nvalores possíveis \\nh\\n1\\n até \\nh\\n5\\n. É evidente que \\nH\\n não é diretamente observável. À medida que os doces\\nsão abertos e inspecionados, são revelados os dados — \\nD\\n1\\n, \\nD\\n2\\n,…, \\nD\\nn\\n, onde cada \\nD\\ni\\n é uma variável\\naleatória com valores possíveis \\ncereja\\n e \\nlima\\n. A tarefa básica enfrentada pelo agente é prever o\\nsabor do próximo doce.\\n1\\n Apesar de sua trivialidade aparente, esse cenário serve para introduzir\\nmuitas questões importantes. O agente realmente precisa deduzir uma teoria de seu mundo, embora\\nseja um mundo muito simples.\\nA \\naprendizagem bayesiana\\n simplesmente calcula a probabilidade de cada hipótese,\\nconsiderando-se os dados, e faz previsões de acordo com ela. Isto é, as previsões são feitas com o\\nuso de \\ntodas\\n as hipóteses, ponderadas por suas probabilidades, em vez de utilizar apenas uma única\\n“melhor” hipótese. Desse modo, a aprendizagem é reduzida à inferência probabilística. Seja \\nD\\n a\\nrepresentação de todos os dados, com valor observado \\nd\\n; então, a probabilidade de cada hipótese é\\nobtida pela regra de Bayes:\\nAgora, vamos supor que queremos fazer uma previsão sobre uma quantidade desconhecida \\nX\\n.\\nEntão, temos:\\nonde pressupomos que cada hipótese determina uma distribuição de probabilidade sobre \\nX\\n. Essa\\nequação mostra que as previsões são médias ponderadas sobre as previsões das hipóteses\\nindividuais. As hipóteses propriamente ditas são em essência “intermediários” entre os dados brutos\\ne as previsões. As quantidades fundamentais na abordagem de Bayes são a \\nhipótese\\n \\na priori\\n, \\nP\\n(\\nh\\ni\\n) e\\na \\nprobabilidade\\n dos dados sob cada hipótese, \\nP\\n(\\nd\\n|\\nh\\ni\\n).\\nPara nosso exemplo dos doces, vamos supor por enquanto que a distribuição \\na priori\\n sobre \\nh\\n1\\n,…,\\nh\\n5\\n seja dada por \\n〈\\n0,1, 0,2, 0,4, 0,2, 0,1\\n〉\\n, como anunciado pelo fabricante. A probabilidade dos\\ndados é calculada sob a suposição de que as observações são \\ni.i.d\\n., de forma que:\\nPor exemplo, suponha que o saco seja realmente um saco só com doces de lima (\\nh\\n5\\n) e que os\\nprimeiros 10 doces sejam todos de lima; então, \\nP\\n(\\nd\\n | \\nh\\n3\\n) é 0,5\\n10\\n, porque metade dos doces em um\\nsaco do tipo \\nh\\n3\\n é de doces de lima.\\n2\\n A \\nFigura 20.1\\n(a) mostra como as probabilidades posteriores das\\ncinco hipóteses mudam à medida que a sequência de 10 doces de lima é observada. Note que as', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 925}),\n",
       " Document(page_content='probabilidades começam com seus valores \\na priori\\n e, portanto, \\nh\\n3\\n é inicialmente a escolha mais\\nprovável e permanece assim depois que um doce de lima é desembrulhado. Depois de serem\\ndesembrulhados dois doces de lima, \\nh\\n4\\n é mais provável; após três ou mais, \\nh\\n5\\n (o temido saco só com\\ndoces de lima) é o mais provável. Depois de 10 doces seguidos, estamos bastante certos de nosso\\ndestino. A \\nFigura 20.1\\n(b) mostra a probabilidade prevista de que o próximo doce seja de lima, com\\nbase na Equação 20.2. Como seria de esperar, ela aumenta monotonicamente em direção a 1.\\nFigura 20.1\\n (a) Probabilidades \\na posteriori\\n \\nP\\n(\\nh\\ni\\n |\\nd\\n1\\n,…, \\nd\\nn\\n) a partir da Equação 20.1. O número de\\nobservações \\nN\\n varia de 1-10, e cada observação é de um doce de lima. (b) Previsão bayesiana\\nP\\n(\\nd\\nn\\n+1\\n = \\nlima\\n|\\nd\\n1\\n,…, \\nd\\nn\\n) a partir da Equação 20.2.\\n O exemplo mostra que \\na previsão bayesiana eventualmente concorda com a verdadeira\\nhipótese\\n. Isso é característico da aprendizagem bayesiana. Para qualquer probabilidade \\na priori\\n fixa\\nque não elimina a hipótese verdadeira, a probabilidade \\na posteriori\\n de qualquer hipótese falsa vai, a\\npartir de certo ponto, desaparecer sob determinadas condições técnicas. Isso simplesmente acontece\\nporque a probabilidade de gerar dados “não característicos” indefinidamente é muitíssimo pequena\\n(esse ponto é análogo à observação feita na discussão da aprendizagem PAC no Capítulo 18). Mais\\nimportante ainda, a previsão bayesiana é \\nótima\\n, quer o conjunto de dados seja pequeno, quer seja\\ngrande. Dada a hipótese \\na priori\\n, qualquer outra previsão será correta com menor frequência.\\nÉ claro que o caráter ótimo da aprendizagem bayesiana tem um preço. Para problemas reais de\\naprendizagem, o espaço de hipóteses é em geral muito grande ou infinito, como vimos no Capítulo\\n18. Em alguns casos, o somatório da Equação 20.2 (ou integração, no caso contínuo) pode ser\\nexecutado de forma tratável, mas, na maioria dos casos, devemos recorrer a métodos aproximados ou\\nsimplificados.\\nUma aproximação muito comum — habitualmente adotada na ciência — é fazer previsões com\\nbase em uma única hipótese \\nmais provável\\n, isto é, uma \\nh\\ni\\n que maximize \\nP\\n(\\nh\\ni\\n | \\nd\\n). Com frequência,\\nisso é chamado de hipótese de \\nmáximo\\n \\na posteriori\\n ou MAP. As previsões feitas de acordo com uma\\nhipótese de MAP \\nh\\nMAP\\n são aproximadamente bayesianas até o ponto em que \\nP\\n(\\nX\\n|\\nd\\n) ≈ \\nP\\n(\\nX\\n|\\nh\\nMAP\\n). Em\\nnosso exemplo de doces, \\nh\\nMAP\\n =\\nh\\n5\\n, após três doces de lima seguidos e, assim, o sistema de\\naprendizagem de MAP prevê que o quarto doce será de lima com probabilidade 1,0 — uma previsão\\nmuito mais perigosa que a previsão bayesiana de 0,8 mostrada na \\nFigura 20.1\\n(b). À medida que\\nchegam mais dados, as previsões de MAP e Bayes ficam mais próximas porque os concorrentes da', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 926}),\n",
       " Document(page_content='hipótese de MAP se tornam cada vez menos prováveis.\\nEmbora nosso exemplo não mostre, a descoberta de hipóteses de MAP frequentemente é muito\\nmais fácil que a aprendizagem bayesiana porque exige a resolução de um problema de otimização,\\nem vez de um grande problema de somatório (ou integração). Veremos exemplos desse fato mais\\nadiante no capítulo.\\nTanto na aprendizagem bayesiana quanto na aprendizagem de MAP, a hipótese \\na priori P\\n(\\nh\\ni\\n)\\ndesempenha uma função importante. Vimos no Capítulo 18 que a \\nsuperadaptação\\n pode ocorrer\\nquando o espaço de hipóteses é muito expressivo, de forma que ele contenha muitas hipóteses que se\\najustam bem ao conjunto de dados. Em vez de impor um limite arbitrário sobre as hipóteses a serem\\nconsideradas, os métodos de aprendizagem bayesiana e MAP utilizam a hipótese \\na priori\\n para\\npenalizar a complexidade\\n. Em geral, as hipóteses mais complexas têm uma probabilidade \\na priori\\nmais baixa — em parte porque normalmente existem muito mais hipóteses complexas que hipóteses\\nsimples. Por outro lado, as hipóteses mais complexas têm capacidade maior de se adaptar aos dados\\n(no caso extremo, uma tabela de busca pode reproduzir os dados exatamente com probabilidade 1).\\nConsequentemente, a hipótese \\na priori\\n incorpora um compromisso entre a complexidade de uma\\nhipótese e seu grau de adaptação aos dados.\\n Podemos ver o efeito dessa solução de compromisso mais claramente no caso lógico em que \\nH\\ncontém apenas hipóteses \\ndeterminísticas\\n. Nesse caso, \\nP\\n(\\nd\\n | \\nh\\ni\\n) é 1 se \\nh\\ni\\n é consistente e 0 em caso\\ncontrário. Examinando a Equação 20.1, vemos que \\nh\\nMAP\\n será a \\nteoria lógica mais simples\\nconsistente com os dados\\n. Portanto, uma aprendizagem máxima \\na posteriori\\n fornece uma\\nincorporação natural da navalha de Ockham.\\nOutra ideia sobre a solução de compromisso entre complexidade e grau de adaptação é obtida\\ntomando-se o logaritmo da Equação 20.1. A escolha de \\nh\\nMAP\\n para maximizar \\nP\\n(\\nd\\n | \\nh\\ni\\n)\\nP\\n(\\nh\\ni\\n) é\\nequivalente a minimizar\\n– log\\n2\\n \\nP\\n(\\nd\\n | \\nh\\ni\\n) – log\\n2\\n \\nP\\n(\\nh\\ni\\n).\\nUsando a conexão entre codificação de informações e probabilidade que introduzimos na \\nSeção\\n18.3.4\\n, vemos que o termo –log\\n2\\n \\nP\\n(\\nh\\ni\\n) é igual ao número de bits necessários para especificar a\\nhipótese \\nh\\ni\\n. Além disso, –log\\n2\\n \\nP\\n(\\nd\\n | \\nh\\ni\\n) é o número adicional de bits exigidos para especificar os\\ndados, dada a hipótese (para ver isso, considere que nenhum bit é necessário se a hipótese prevê os\\ndados exatamente — como ocorre com \\nh\\n5\\n e a sequência de doces de lima — e que log\\n2\\n 1 = 0).\\nConsequentemente, a aprendizagem de MAPé a escolha da hipótese que fornece \\ncompactação\\nmáxima dos dados. A mesma tarefa é tratada mais diretamente pelo método de aprendizagem de\\ncomprimento mínimo de descrição\\n, ou CMD.\\nConsiderando que a aprendizagem MAP expressa simplicidade ao atribuir maiores probabilidades\\na hipóteses mais simples, CMD expressa isso diretamente pela contagem de bits em uma codificação\\nbinária das hipóteses e dos dados.\\nUma simplificação final é fornecida supondo-se uma probabilidade \\na priori\\n \\nuniforme\\n sobre o\\nespaço de hipóteses. Nesse caso, a aprendizagem de MAP se reduz à escolha de um \\nh\\ni\\n que maximize', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 927}),\n",
       " Document(page_content='P\\n(\\nd\\n | \\nh\\ni\\n). Isso é chamado de hipótese de \\nmáxima probabilidade\\n (MP), \\nh\\nMP\\n. A aprendizagem de\\nmáxima probabilidade é muito comum em estatística, uma disciplina na qual muitos pesquisadores\\ndesconfiam da natureza subjetiva de hipóteses \\na priori\\n. É uma abordagem razoável quando não existe\\nnenhuma razão para preferir uma hipótese sobre outra \\na priori\\n — por exemplo, quando todas as\\nhipóteses são igualmente complexas. Ela proporciona uma boa aproximação para a aprendizagem\\nbayesiana e de MAP quando o conjunto de dados é grande, porque os dados inundam a distribuição \\na\\npriori\\n sobre hipóteses, mas tem problemas (como veremos) com conjuntos de dados pequenos.\\n20.2 APRENDIZAGEM COM DADOS COMPLETOS\\nA \\nestimativa de densidade\\n é a tarefa geral de aprender um modelo probabilístico, dados os dados\\nque assumimos ser gerados desse modelo. (A expressão originalmente aplicava-se a funções de\\ndensidade de probabilidade para variáveis contínuas, mas agora também é usada para distribuições\\ndiscretas.)\\nEsta seção abrange o caso mais simples, no qual temos dados completos. Os dados estão\\ncompletos quando cada ponto de dado contém valores para cada variável no modelo de\\nprobabilidade que está sendo aprendido. Nós nos concentraremos em \\naprendizagem de parâmetros\\n— encontrar os parâmetros numéricos para um modelo de probabilidade cuja estrutura é fixa. Por\\nexemplo, poderíamos estar interessados em aprender as probabilidades condicionais em uma rede\\nbayesiana com determinada estrutura. Vamos também analisar brevemente o problema de estrutura de\\naprendizagem e de estimativa de densidade não paramétrica.\\n20.2.1 Aprendizagem de parâmetros de máxima probabilidade: modelos\\ndiscretos\\nVamos supor que compramos um saco de doces de lima e cereja de um novo fabricante cujas\\nproporções de cereja e lima são completamente desconhecidas; a fração poderia estar em qualquer\\nlugar entre 0 e 1. Nesse caso, temos uma quantidade contínua de hipóteses. O \\nparâmetro\\n, que\\nchamaremos \\nθ\\n, é a proporção de doces de cereja, e a hipótese é \\nh\\nθ\\n (a proporção de lima é\\nsimplesmente 1 – \\nθ\\n). Se supusermos que todas as proporções são igualmente prováveis \\na priori\\n, uma\\nabordagem de máxima probabilidade será razoável. Se modelarmos a situação com uma rede\\nbayesiana, precisaremos de apenas uma variável aleatória, \\nSabor\\n (o sabor de um doce escolhido ao\\nacaso no saco). Ela tem valores \\ncereja\\n e \\nlima\\n, em que a probabilidade de \\ncereja\\n é \\nθ\\n (veja a \\nFigura\\n20.2\\n(a)). Agora, vamos supor que desembrulhamos \\nN\\n doces, dos quais \\nc\\n são de cereja e \\nl\\n = \\nN\\n – \\nc\\n são\\nde lima. De acordo com a Equação 20.3, a probabilidade desse conjunto de dados específico é:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 928}),\n",
       " Document(page_content='Figura 20.2\\n (a) Modelo de rede bayesiana para o caso de doces com uma proporção desconhecida\\nde cerejas e limas. (b) Modelo para o caso em que a cor da embalagem depende\\n(probabilisticamente) do sabor do doce.\\nA hipótese de máxima probabilidade é dada pelo valor de \\nθ\\n que maximiza essa expressão. O\\nmesmo valor é obtido maximizando-se a \\nprobabilidade logarítmica\\n,\\n(Usando logaritmos, reduzimos o produto a uma soma sobre os dados, que em geral é mais fácil de\\nmaximizar.) Para encontrar o valor de máxima probabilidade de \\nθ\\n, diferenciamos \\nL\\n em relação a \\nθ\\n e\\ndefinimos a expressão resultante como zero:\\nEntão, em linguagem comum, a hipótese de máxima probabilidade \\nh\\nMP\\n afirma que a proporção\\nreal de cerejas no saco é igual à proporção observada nos doces desembrulhados até agora!\\nParece que tivemos um bocado de trabalho para descobrir o óbvio. Entretanto, na verdade,\\ndefinimos um método-padrão para aprendizagem de parâmetros, um método com ampla\\naplicabilidade:\\n1. Escrever uma expressão para a probabilidade dos dados como uma função do(s) parâmetro(s).\\n2. Escrever a derivada da probabilidade logarítmica com relação a cada parâmetro.\\n3. Encontrar os valores de parâmetros tais que as derivadas sejam iguais a zero.\\n A etapa mais complicada normalmente é a última. Em nosso exemplo, ela foi trivial, mas\\nveremos que, em muitos casos, precisamos recorrer a algoritmos de solução iterativa ou a outras\\ntécnicas de otimização numérica, conforme escrevemos no Capítulo 4. O exemplo também ilustra um', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 929}),\n",
       " Document(page_content='problema significativo com a aprendizagem de máxima probabilidade em geral: \\nquando o conjunto\\nde dados é pequeno o suficiente para que alguns eventos ainda não tenham sido observados — por\\nexemplo, nenhum doce de cereja —, a hipótese de máxima probabilidade atribui a probabilidade\\nzero a esses eventos\\n. Vários artifícios são usados para evitar esse problema, como inicializar a\\ncontagem para cada evento com o valor 1 em vez de zero.\\nVamos examinar outro exemplo. Suponha que esse novo fabricante de doces queira dar uma\\npequena sugestão ao consumidor e utilize embalagens de doces coloridas de vermelho e verde. A\\nEmbalagem\\n para cada doce é selecionada \\nprobabilisticamente\\n, de acordo com alguma distribuição\\ncondicional desconhecida, dependendo do sabor. O modelo de probabilidade correspondente é\\nmostrado na \\nFigura 20.2\\n(b). Note que ele tem três parâmetros: \\nθ\\n, \\nθ\\n1\\n e \\nθ\\n2\\n. Com esses parâmetros, a\\nprobabilidade de ver, digamos, um doce de cereja em uma embalagem verde pode ser obtida a partir\\nda semântica-padrão para redes bayesianas:\\nAgora, desembrulhamos \\nN\\n doces, dos quais \\nc\\n são cerejas e \\nl\\n são limas. As contagens de\\nembalagens são: \\nr\\nc\\n dos doces de cereja têm embalagens vermelhas e \\ng\\nc\\n têm embalagens verdes,\\nenquanto \\nr\\nl\\n dos doces de lima têm embalagens vermelhas e \\ng\\nl\\n têm embalagens verdes. A\\nprobabilidade dos dados é fornecida por:\\nEssa expressão parece horrível, mas o uso de logaritmos ajuda:\\nA vantagem de usar logs é clara: a probabilidade logarítmica é a soma de três termos, cada um dos\\nquais contém um único parâmetro. Quando tomarmos derivadas em relação a cada parâmetro e as\\ndefinirmos como zero, conseguiremos três equações independentes, cada uma contendo apenas um\\nparâmetro:\\nA solução para \\nθ\\n é a mesma de antes. A solução para \\nθ\\n1\\n, a probabilidade de que um doce de\\ncereja tenha embalagem vermelha, é a fração observada de doces de cereja com embalagens\\nvermelhas, e o mesmo ocorre no caso de \\nθ\\n2\\n.\\n Esses resultados são muito confortantes, e é fácil ver que eles podem ser estendidos a qualquer\\nrede bayesiana cujas probabilidades condicionais são representadas como tabelas. O ponto mais\\nimportante é que, \\ncom dados completos, o problema de aprendizagem de parâmetros de máxima\\nprobabilidade para uma rede bayesiana se decompõe em problemas de aprendizagem separados,', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 930}),\n",
       " Document(page_content='um para cada parâmetro\\n (veja o Exercício 20.6 para o caso não tabulado, em que cada parâmetro\\nafeta várias probabilidades condicionais). O segundo ponto importante é que os valores de\\nparâmetros para uma variável, dados seus pais, são apenas as frequências observadas dos valores de\\nvariáveis para cada configuração dos valores dos pais. Como antes, devemos ser cuidadosos para\\nevitar zeros quando o conjunto de dados é pequeno.\\n20.2.2 Modelos de Bayes ingênuos\\nProvavelmente, o modelo de rede bayesiana mais comum utilizado na aprendizagem de máquina é\\no modelo de \\nBayes ingênuo\\n. Nesse modelo, a variável de “classe”\\nC\\n (que deve ser prevista) é a raiz,\\ne as variáveis de “atributos” \\nXi\\n são as folhas. O modelo é “ingênuo” porque supõe que os atributos\\nsão condicionalmente independentes uns dos outros, dada a classe (o modelo da \\nFigura 20.2\\n(b) é um\\nmodelo de Bayes ingênuo com a classe \\nSabor\\n e apenas um atributo, \\nEmbalagem\\n). Supondo-se\\nvariáveis booleanas, os parâmetros são:\\nOs valores de parâmetros de máxima probabilidade são encontrados exatamente do mesmo modo\\nque aparece na \\nFigura 20.2\\n(b). Uma vez que o modelo é treinado dessa maneira, ele pode ser\\nutilizado para classificar novos exemplos, para os quais a variável de classe \\nC\\n é não observada.\\nCom valores de atributos observados \\nx\\n1\\n, …, \\nx\\nn\\n, a probabilidade de cada classe é dada por:\\n Uma previsão determinística pode ser obtida escolhendo-se a classe mais provável. A \\nFigura\\n20.3\\n mostra a curva de aprendizagem para esse método quando ele é aplicado ao problema de\\nrestaurante do Capítulo 18. O método aprende bastante bem, mas não tanto quanto a aprendizagem de\\nárvore de decisão; presumivelmente, isso ocorre porque a hipótese verdadeira — que é uma árvore\\nde decisão — não pode ser representada exatamente com o uso de um modelo de Bayes ingênuo. A\\naprendizagem bayesiana ingênua acaba funcionando surpreendentemente bem em ampla variedade de\\naplicações; a versão reforçada (Exercício 20.4) é um dos mais efetivos algoritmos de aprendizagem\\nde uso geral. A aprendizagem bayesiana ingênua se adapta bem à escala de problemas muito grandes:\\ncom \\nn\\n atributos booleanos, existem apenas 2\\nn\\n + 1 parâmetros e \\nnenhuma busca é necessária para\\nencontrar h\\nML\\n, a hipótese de Bayes ingênua de máxima probabilidade\\n. Por fim, a aprendizagem\\nbayesiana ingênua não tem nenhuma dificuldade com dados ruidosos ou faltantes e pode fornecer\\nprevisões probabilísticas quando apropriado.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 931}),\n",
       " Document(page_content='Figura 20.3\\n A curva de aprendizagem correspondente à aprendizagem bayesiana ingênua aplicada ao\\nproblema de restaurante do Capítulo 18; a curva de aprendizagem para a aprendizagem em árvore de\\ndecisão é mostrada para comparação.\\n20.2.3 Aprendizagem de parâmetros de máxima probabilidade: modelos\\ncontínuos\\nOs modelos de probabilidade contínuos, como o modelo \\ngaussiano linear\\n, foram introduzidos na\\nSeção 14.3\\n. Pelo fato de as variáveis contínuas serem onipresentes em aplicações do mundo real, é\\nimportante saber como aprender modelos contínuos a partir de dados. Os princípios para a\\naprendizagem de máxima probabilidade são idênticos aos casos discreto e contínuos.\\nVamos começar com um caso muito simples: a aprendizagem dos parâmetros de uma função de\\ndensidade gaussiana sobre uma única variável. Isto é, os dados são gerados como a seguir:\\nOs parâmetros desse modelo são a média \\nm\\n e o desvio-padrão \\ns\\n (note que a “constante” de\\nnormalização depende de \\ns\\n e, assim, não podemos ignorá-la). Sejam os valores observados \\nx\\n1\\n,…, \\nx\\nn\\n.\\nEntão, a probabilidade logarítmica é:\\nComo sempre, definindo as derivadas como zero, obtemos:\\nIsto é, o valor de máxima probabilidade da média é a média das amostras, e o valor de máxima\\nprobabilidade do desvio-padrão é a raiz quadrada da variância das amostras. Novamente, esses são\\nresultados reconfortantes que confirmam a prática de “senso comum”.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 932}),\n",
       " Document(page_content='Agora, considere um modelo gaussiano linear com um pai contínuo \\nX\\n e um filho contínuo \\nY\\n.\\nConforme já explicamos, \\nY\\n tem uma distribuição gaussiana cuja média depende linearmente do valor\\nde \\nX\\n e cujo desvio-padrão é fixo. Para aprender a distribuição condicional \\nP\\n(\\nY\\n | \\nX\\n), podemos\\nmaximizar a probabilidade condicional:\\nAqui, os parâmetros são \\nθ\\n1\\n, \\nθ\\n2\\n e \\ns\\n. Os dados são uma coleção de pares (\\nx\\nj\\n, \\ny\\nj\\n), como ilustra a\\nFigura 20.4\\n. Usando os métodos habituais (Exercício 20.5), podemos encontrar os valores de máxima\\nprobabilidade dos parâmetros. Aqui o ponto é diferente. Se considerarmos apenas os parâmetros \\nθ\\n1\\n e\\nθ\\n2\\n que definem o relacionamento linear entre \\nx\\n e \\ny\\n, fica claro que maximizar a probabilidade\\nlogarítmica com relação a esses parâmetros é o mesmo que \\nminimizar\\n o numerador (\\ny\\n − (\\nθ\\n1\\nx\\n + \\nθ\\n2\\n))\\n2\\nno expoente da Equação 20.5. Isso é a perda \\nL\\n2\\n, o erro quadrático entre o valor real \\ny\\n e a previsão\\nθ\\n1\\nx\\n + \\nθ\\n2\\n. Essa é a quantidade minimizada pelo procedimento-padrão de \\nregressão linear\\n descrita na\\nSeção 18.6\\n. Agora, podemos compreender por que: a minimização da soma de erros quadráticos\\nfornece o modelo de linha reta de máxima probabilidade, desde que os dados sejam gerados com\\nruído gaussiano de variância fixa.\\nFigura 20.4\\n (a) Modelo gaussiano linear descrito como \\ny\\n = \\nθ\\n1\\nx\\n + \\nθ\\n2\\n somado ao ruído gaussiano com\\nvariância fixa. (b) Conjunto de 50 pontos de dados gerados a partir desse modelo.\\n20.2.4 Aprendizagem de parâmetros bayesiana\\nA aprendizagem de máxima probabilidade dá origem a alguns procedimentos muito simples, mas\\ntem algumas deficiências sérias com conjuntos de dados pequenos. Por exemplo, depois de ver um\\ndoce de cereja, a hipótese de máxima probabilidade é que o saco seja 100% de doces de cereja (ou\\nseja, \\nθ\\n = 1,0). A menos que a hipótese \\na priori\\n de alguém seja a de que os sacos devem ser\\ntotalmente de cereja ou de lima, essa não é uma conclusão razoável. O mais provável é que o saco\\nseja uma mistura de cereja e lima. A abordagem bayesiana para aprendizagem de parâmetros começa\\npela definição de uma distribuição de probabilidade prévia sobre a hipóteses possível. Chamamos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 933}),\n",
       " Document(page_content='isso de \\nhipótese\\n \\na priori\\n. Então, à medida que os dados chegam, a distribuição de probabilidade\\nposterior é atualizada.\\nO exemplo de doce da \\nFigura 20.2\\n(a) tem um único parâmetro, \\nθ\\n: a probabilidade de um pedaço\\nde doce selecionado ao acaso ter sabor de cereja. Na visão de Bayes, \\nθ\\n é o valor (desconhecido) de\\numa variável aleatória \\nΘ\\n que define o espaço de hipótese; a hipótese \\na priori\\n é simplesmente a\\ndistribuição \\na priori\\n \\nP\\n(\\nΘ\\n). Desse modo, \\nP\\n(\\nΘ\\n = \\nθ\\n) é a probabilidade \\na priori\\n de que o saco contenha\\numa fração \\nθ\\n de doces de cereja.\\nSe o parâmetro \\nθ\\n puder ter qualquer valor entre 0 e 1, então \\nP\\n(\\nΘ\\n) deve ser uma distribuição\\ncontínua diferente de zero apenas entre 0 e 1 e que tem integral 1. A densidade uniforme \\nP\\n(\\nθ\\n) =\\nUniforme\\n[0,1](\\nθ\\n) é uma candidata (veja o Capítulo 13). Ocorre que a densidade uniforme é um\\nmembro da família de \\ndistribuições beta\\n. Cada distribuição beta é definida por dois\\nhiperparâmetros\\n3\\n \\na\\n e \\nb\\n, tais que\\npara \\nθ\\n no intervalo [0, 1]. A constante de normalização a, que faz com que a distribuição se integre\\ncom 1, depende de \\na\\n e \\nb\\n (veja o Exercício 20.7). A \\nFigura 20.5\\n mostra qual é a aparência da\\ndistribuição para diversos valores de \\na\\n e \\nb\\n. O valor médio da distribuição é \\na\\n/(\\na\\n + \\nb\\n) e, assim,\\nvalores maiores de \\na\\n sugerem a crença de que \\nΘ\\n está mais próxima de 1 do que de 0. Valores\\nmaiores de \\na\\n + \\nb\\n dão à distribuição um pico mais estreito, sugerindo maior certeza sobre o valor de\\nΘ. Desse modo, a família beta fornece uma faixa útil de possibilidades para a hipótese \\na priori\\n.\\nFigura 20.5\\n Exemplos da distribuição beta[\\na\\n, \\nb\\n] para diferentes valores de [\\na\\n, \\nb\\n].\\nAlém de sua flexibilidade, a família beta tem outra propriedade interessante: se \\nΘ\\n tem uma\\nprobabilidade \\na priori\\n beta[\\na\\n, \\nb\\n], então, depois da observação de um ponto de dados, a distribuição\\nposterior para \\nΘ\\n também é uma distribuição beta. Em outras palavras, beta é fechado sob\\natualização. A família beta é chamada \\nconjugado\\n \\na priori\\n para a família de distribuições\\ncorrespondente a uma variável booleana.\\n4\\n Vejamos como isso funciona. Vamos supor que\\nobservamos um doce de cereja; então, temos', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 934}),\n",
       " Document(page_content='Desse modo, depois de ver um doce de cereja, simplesmente incrementamos o parâmetro \\na\\n para\\nobter a posterior; de modo semelhante, depois de ver um doce de lima, incrementamos o parâmetro \\nb\\n.\\nPortanto, podemos visualizar os hiperparâmetros \\na\\n e \\nb\\n como \\ncontagens virtuais\\n, no sentido de que\\num \\na priori\\n beta[\\na\\n, \\nb\\n] se comporta exatamente como se tivéssemos começado com um \\na priori\\nuniforme beta[1, 1] e visto \\na\\n – 1 doces de cereja reais e \\nb\\n – 1 doces de lima reais.\\nExaminando uma sequência de distribuições beta para valores crescentes de \\na\\n e \\nb\\n, mantendo as\\nproporções fixas, podemos ver nitidamente como a distribuição posterior sobre o parâmetro \\nΘ\\n se\\naltera à medida que os dados chegam. Por exemplo, suponha que o saco de doces real tenha 75% de\\ncereja. A \\nFigura 20.5\\n(b) mostra a sequência beta[3, 1], beta[6, 2], beta[30, 10]. É claro que a\\ndistribuição está convergindo para um pico estreito em torno do valor verdadeiro de \\nΘ.\\n Então, para\\ngrandes conjuntos de dados, a aprendizagem bayesiana (pelo menos nesse caso) converge para dar os\\nmesmos resultados que a aprendizagem de máxima probabilidade.\\nConsideremos agora um caso mais complicado. A rede da \\nFigura 20.2\\n(b) tem três parâmetros, \\nθ\\n,\\nθ\\n1\\n e \\nθ\\n2\\n, onde \\nθ\\n1\\n é a probabilidade de embalagem vermelha em um doce de cereja e \\nθ\\n2\\n é a\\nprobabilidade de embalagem vermelha em um doce de lima. A hipótese de Bayes anterior deve\\ncobrir todos os três parâmetros, isto é, precisamos especificar \\nP\\n(\\nΘ\\n, \\nΘ\\n1\\n, \\nΘ\\n2\\n). Usualmente, supomos\\nindependência de parâmetros\\n:\\nCom essa suposição, cada parâmetro pode ter sua própria distribuição beta que é atualizada\\nseparadamente à medida que os dados chegam. A \\nFigura 20.6\\n mostra como podemos incorporar a\\nhipótese \\na priori\\n e qualquer dado em uma rede bayesiana. Os nós \\nΘ\\n, \\nΘ\\n1\\n, \\nΘ\\n2\\n, não têm pais. Mas, a\\ncada vez que fazemos uma observação de embalagem e sabor correspondente a um pedaço de doce,\\nadicionamos um nó \\nSabor\\ni\\n, que é dependente do parâmetro sabor Θ:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 935}),\n",
       " Document(page_content='Figura 20.6\\n Uma rede bayesiana que corresponde a um processo de aprendizagem bayesiana.\\nDistribuições posteriores para as variáveis de parâmetros \\nΘ\\n, \\nΘ\\n1\\n e \\nΘ\\n2\\n podem ser deduzidas de suas\\ndistribuições \\na priori\\n e da evidência nas va\\u200briáveis \\nSabor\\ni\\n e \\nEmbalagem\\ni\\n.\\nAdicionamos também um nó \\nEmbalagem\\ni\\n, que é dependente de Θ\\n1 e\\n Θ\\n2\\n:\\n Agora, todo o processo de aprendizagem bayesiana pode ser formulado como um problema de\\ninferência.\\n Adicionamos nós de evidência novos, em seguida consultamos os nós desconhecidos\\n(nesse caso, \\nΘ\\n, \\nΘ\\n1\\n, \\nΘ\\n2\\n). Essa formulação de aprendizagem e previsão deixa claro que a\\naprendizagem bayesiana não requer “princípios de aprendizagem” extras. Além disso, \\nem essência,\\nexiste apenas um algoritmo de aprendizagem\\n, ou seja, o algoritmo de inferência para redes\\nbayesianas. É claro, a natureza dessas redes é um pouco diferente daquelas do Capítulo 14, por causa\\ndo número potencialmente grande de variáveis de evidência que representam o conjunto de\\ntreinamento e por causa da prevalência de parâmetros variáveis de valor contínuo.\\n20.2.5 Aprendizagem de estruturas de redes bayesianas\\nAté agora, supomos que a estrutura da rede bayesiana é dada, e estamos apenas tentando aprender\\nos parâmetros. A estrutura da rede representa o conhecimento causal básico sobre o domínio que\\nfrequentemente é fácil de fornecer para um usuário especialista ou mesmo para um usuário ingênuo.\\nPorém, em alguns casos, o modelo causal pode estar indisponível ou sujeito a disputa — por\\nexemplo, certas corporações afirmaram há muito tempo que fumar não causa câncer —, assim é\\nimportante entender como a estrutura de uma rede bayesiana pode ser aprendida a partir dos dados.\\nEsta seção apresenta um esquema breve das ideias principais.\\nA abordagem mais óbvia é \\nbuscar\\n um bom modelo. Podemos iniciar com um modelo que não\\ncontém nenhum vínculo e começar a adicionar pais correspondentes a cada nó, ajustando os\\nparâmetros com os métodos que acabamos de examinar e medindo a exatidão do modelo resultante.\\nComo alternativa, podemos começar com um palpite inicial sobre a estrutura e utilizar a busca de\\nsubida de encosta ou a busca de têmpera simulada para fazer modificações, retornando os parâmetros\\napós cada mudança na estrutura. As modificações podem incluir inversão, adição ou eliminação de\\narcos. Não devemos introduzir ciclos no processo, pois muitos algoritmos pressupõem que é dada\\numa ordenação para as variáveis e que um nó pode ter pais somente entre os nós que vêm antes deles\\nna ordenação (exatamente como no processo de construção do Capítulo 14). Para generalizar,\\ntambém precisamos fazer uma busca sobre ordenações possíveis.\\nExistem dois métodos alternativos para decidir quando uma boa estrutura foi encontrada. O\\nprimeiro é testar se as asserções de independência condicional implícitas na estrutura são realmente\\nsatisfeitas nos dados. Por exemplo, o uso de um modelo bayesiano ingênuo para o problema de', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 936}),\n",
       " Document(page_content='restaurante supõe que\\ne podemos verificar nos dados que a mesma equação é válida entre as frequências condicionais\\ncorrespondentes. Agora, ainda que a estrutura descreva a verdadeira natureza causal do domínio,\\nflutuações estatísticas no conjunto de dados significam que a equação nunca será satisfeita\\nexatamente\\n, e então precisamos executar um teste estatístico apropriado para verificar se existe\\nevidência suficiente de que a hipótese de independência foi violada. A complexidade da rede\\nresultante dependerá do limite usado para esse teste — quanto mais rígido for o teste de\\nindependência, mais vínculos serão adicionados e maior será o perigo de superadaptação.\\nUma abordagem mais consistente com as ideias deste capítulo é avaliar até que ponto o modelo\\nproposto explica os dados (em sentido probabilístico). No entanto, devemos ser cuidadosos com a\\nforma como efetuamos essa medição. Se tentarmos simplesmente encontrar a hipótese de máxima\\nprobabilidade, acabaremos com uma rede completamente conectada porque a adição de outros pais a\\num nó não poderá diminuir a probabilidade (Exercício 20.8). Somos forçados a penalizar a\\ncomplexidade do modelo de algum modo. A abordagem de MAP (ou de CMD) simplesmente subtrai\\numa penalidade da probabilidade de cada estrutura (depois do ajuste de parâmetros) antes de\\ncomparar estruturas diferentes. A abordagem de Bayes coloca uma probabilidade \\na priori\\n conjunta\\nsobre estruturas e parâmetros. Em geral, existem muitas estruturas para se efetuar o somatório (uma\\nquantidade superexponencial em relação ao número de variáveis) e, assim, a maioria dos\\nespecialistas utiliza o CMMC para obter amostras sobre estruturas.\\nPenalizar a complexidade (por métodos de MAP ou de Bayes) introduz uma conexão importante\\nentre a estrutura ótima e a natureza da representação para as distribuições condicionais na rede. Com\\ndistribuições tabulares, a penalidade de complexidade correspondente à distribuição de um nó cresce\\nexponencialmente com o número de pais; porém, digamos, com distribuições OU-ruidosas, ela cresce\\nde forma apenas linear. Isso significa que a aprendizagem com modelos de OU-ruidoso (ou com\\noutros modelos parametrizados de modo compacto) tende a produzir estruturas aprendidas com mais\\npais do que a aprendizagem com distribuições tabulares.\\n20.2.6 Estimativa de densidade com modelos não paramétricos\\nÉ possível aprender um modelo de probabilidade sem fazer suposições sobre sua estrutura e\\nparametrização pela adoção dos métodos não paramétricos da \\nSeção 18.8\\n. A tarefa de \\nestimativa de\\ndensidade não paramétrica\\n é realizada normalmente em domínios contínuos, como mostrado na\\nFigura 20.7\\n(a). A figura mostra uma função de densidade de probabilidade em um espaço definido\\npor duas variáveis contínuas. Na \\nFigura 20.7\\n(b), vemos uma amostra de pontos de dados a partir\\ndessa função de densidade. A questão é se podemos recuperar o modelo das amostras.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 937}),\n",
       " Document(page_content='Figura 20.7\\n (a) Plano em 3-D da mistura das gaussianas da \\nFigura 20.11\\n(a). (b) Amostra de pontos\\nde 128 pontos da mistura, junto com dois pontos de consulta (quadrados pequenos) e seus 10\\nvizinhos mais próximos (círculos médios e grandes).\\nPrimeiro vamos considerar os modelos de \\nk\\n-\\nvizinhos mais próximos\\n (no Capítulo 18 vimos\\nmodelos de vizinhos mais próximos para classificação e regressão; aqui os vemos para a estimativa\\nde densidade).\\nDada uma amostra de pontos de dados, para estimar a densidade de probabilidade desconhecida\\nem um ponto \\nx\\n de consulta, podemos simplesmente medir a densidade dos pontos de dados na\\nvizinhança de \\nx\\n. A \\nFigura 20.7\\n(b) mostra dois pontos de consulta (pequenos quadrados). Para cada\\nponto de consulta desenhamos o menor círculo que envolve 10 vizinhos — os 10 vizinhos mais\\npróximos. Podemos ver que o círculo central é maior, significando que lá existe baixa densidade, e o\\ncírculo da direita é menor, significando que lá existe alta densidade. Na \\nFigura 20.8\\n mostramos três\\nplanos de estimativa de densidade utilizando \\nk\\n vizinhos mais próximos, para diferentes valores de \\nk\\n.\\nParece claro que (b) tende para a direita, enquanto (a) é muito “pontudo” (\\nk\\n é muito pequeno) e (c) é\\nmuito “liso” (\\nk\\n é muito grande).\\nFigura 20.8\\n Estimativa de densidade utilizando \\nk\\n vizinhos mais próximos, aplicados aos dados na\\nFigura 20.7\\n(b), para \\nk\\n =3, 10 e 40, respectivamente. \\nk\\n = 3 é muito espinhoso, 40 é muito lis, e 10\\ntende apenas para a direita. O melhor valor de \\nk\\n pode ser escolhido por validação cruzada.\\nOutra possibilidade é usar as \\nfunções de kernel\\n, como fizemos para a regressão localmente\\nponderada. Para aplicar um modelo de kernel para estimar a densidade, vamos supor que cada ponto\\nde dados gere a sua própria função de densidade pequena usando um kernel gaussiano. A densidade\\nestimada em um ponto de consulta \\nx\\n é, então, a densidade média como dado por cada função do\\nkernel:', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 938}),\n",
       " Document(page_content='Vamos supor gaussianas esféricas com desvio-padrão \\nw\\n ao longo de cada eixo:\\nonde \\nd\\n é o número de dimensões em \\nx\\n e \\nD\\n é a função de distância euclidiana. Temos ainda o\\nproblema de escolher um valor adequado para a largura \\nw\\n do kernel; a \\nFigura 20.9\\n mostra valores\\nque são muito pequenos, apenas para a direita, e muito extensos. Um bom valor de \\nw\\n pode ser\\nescolhido por meio de validação cruzada.\\nFigure 20.9\\n Estimativa de densidade de kernel para os dados na \\nFigura 20.7\\n(b), utilizando kernels\\ngaussianos com \\nw\\n = 0,02, 0,07 e 0,20, respectivamente \\nw\\n = 0,07 tende para a direita.\\n20.3 APRENDIZAGEM COM VARIÁVEIS OCULTAS: O ALGORITMO EM\\n A seção precedente lidou com o caso completamente observável. Muitos problemas reais têm\\nvariáveis ocultas\\n (às vezes chamadas \\nvariáveis latentes\\n) que não são observáveis nos dados\\ndisponíveis para aprendizagem. Por exemplo, registros médicos com frequência incluem os sintomas\\nobservados, o tratamento aplicado e, talvez, o resultado do tratamento, mas raramente contêm uma\\nobservação direta da própria doença! (Observe que o \\ndiagnóstico\\n não é a \\ndoença;\\n é uma\\nconsequência causal dos sintomas observados que, por sua vez, são causados pela doença.) Você\\npoderia perguntar: “Se a doença não é observada, por que não construir um modelo sem ela?” A\\nresposta aparece na \\nFigura 20.10\\n, que mostra um pequeno modelo de diagnóstico fictício para\\ndoenças do coração. Existem três fatores de predisposição observáveis e três sintomas observáveis\\n(que são deprimentes demais para se identificar). Suponha que cada variável tenha três valores\\npossíveis (por exemplo, nenhum, moderado e severo). A remoção da variável oculta a partir da rede\\nem (a) produz a rede em (b); o número total de parâmetros aumenta de 78 para 708. Desse modo,\\nvariáveis latentes podem reduzir drasticamente o número de parâmetros exigidos para especificar\\numa rede bayesiana\\n. Por sua vez, isso pode reduzir drasticamente a quantidade de dados necessários\\npara se aprender os parâmetros.', metadata={'source': 'repositorio\\\\AI LIVRO - BIBLIA DA IA.pdf', 'page': 939}),\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5be60839-ac31-476e-9fb8-a4c0e81c3251",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m      2\u001b[0m all_splits \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(pages)\n\u001b[1;32m----> 3\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(documents\u001b[38;5;241m=\u001b[39mall_splits, embedding\u001b[38;5;241m=\u001b[39m\u001b[43membeddings\u001b[49m, persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstorage/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#memory = ConversationSummaryMemory(\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#    llm=llm, memory_key=\"chat_history\", return_messages=True\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500)\n",
    "all_splits = text_splitter.split_documents(pages)\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory='storage/')\n",
    "#memory = ConversationSummaryMemory(\n",
    "#    llm=llm, memory_key=\"chat_history\", return_messages=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f164a91-0798-410f-bdd8-4290996ba949",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4bb6973-2e7b-4c63-a2fb-1f9db83e91e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'langchain' has no attribute 'debug'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tauan\\Documents\\tutor_artificial\\PoC - Artigo.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tauan/Documents/tutor_artificial/PoC%20-%20Artigo.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m qa(\u001b[39m\"\u001b[39;49m\u001b[39mQuais as áreas acadêmicas as quais este artigo aborda?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\tauan\\anaconda3\\envs\\tutor_artificial\\Lib\\site-packages\\langchain\\chains\\base.py:269\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[0;32m    245\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[39m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    268\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_inputs(inputs)\n\u001b[1;32m--> 269\u001b[0m callback_manager \u001b[39m=\u001b[39m CallbackManager\u001b[39m.\u001b[39;49mconfigure(\n\u001b[0;32m    270\u001b[0m     callbacks,\n\u001b[0;32m    271\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks,\n\u001b[0;32m    272\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    273\u001b[0m     tags,\n\u001b[0;32m    274\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtags,\n\u001b[0;32m    275\u001b[0m     metadata,\n\u001b[0;32m    276\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata,\n\u001b[0;32m    277\u001b[0m )\n\u001b[0;32m    278\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    279\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    280\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    281\u001b[0m     inputs,\n\u001b[0;32m    282\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[0;32m    283\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tauan\\anaconda3\\envs\\tutor_artificial\\Lib\\site-packages\\langchain\\callbacks\\manager.py:1333\u001b[0m, in \u001b[0;36mCallbackManager.configure\u001b[1;34m(cls, inheritable_callbacks, local_callbacks, verbose, inheritable_tags, local_tags, inheritable_metadata, local_metadata)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1303\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfigure\u001b[39m(\n\u001b[0;32m   1304\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     local_metadata: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1312\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m CallbackManager:\n\u001b[0;32m   1313\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Configure the callback manager.\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \n\u001b[0;32m   1315\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[39m        CallbackManager: The configured callback manager.\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1333\u001b[0m     \u001b[39mreturn\u001b[39;00m _configure(\n\u001b[0;32m   1334\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[0;32m   1335\u001b[0m         inheritable_callbacks,\n\u001b[0;32m   1336\u001b[0m         local_callbacks,\n\u001b[0;32m   1337\u001b[0m         verbose,\n\u001b[0;32m   1338\u001b[0m         inheritable_tags,\n\u001b[0;32m   1339\u001b[0m         local_tags,\n\u001b[0;32m   1340\u001b[0m         inheritable_metadata,\n\u001b[0;32m   1341\u001b[0m         local_metadata,\n\u001b[0;32m   1342\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tauan\\anaconda3\\envs\\tutor_artificial\\Lib\\site-packages\\langchain\\callbacks\\manager.py:1739\u001b[0m, in \u001b[0;36m_configure\u001b[1;34m(callback_manager_cls, inheritable_callbacks, local_callbacks, verbose, inheritable_tags, local_tags, inheritable_metadata, local_metadata)\u001b[0m\n\u001b[0;32m   1735\u001b[0m tracer_project \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1736\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mLANGCHAIN_PROJECT\u001b[39m\u001b[39m\"\u001b[39m, os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mLANGCHAIN_SESSION\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1737\u001b[0m )\n\u001b[0;32m   1738\u001b[0m run_collector_ \u001b[39m=\u001b[39m run_collector_var\u001b[39m.\u001b[39mget()\n\u001b[1;32m-> 1739\u001b[0m debug \u001b[39m=\u001b[39m _get_debug()\n\u001b[0;32m   1740\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1741\u001b[0m     verbose\n\u001b[0;32m   1742\u001b[0m     \u001b[39mor\u001b[39;00m debug\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1746\u001b[0m     \u001b[39mor\u001b[39;00m open_ai \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m ):\n\u001b[0;32m   1748\u001b[0m     \u001b[39mif\u001b[39;00m verbose \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m   1749\u001b[0m         \u001b[39misinstance\u001b[39m(handler, StdOutCallbackHandler)\n\u001b[0;32m   1750\u001b[0m         \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m callback_manager\u001b[39m.\u001b[39mhandlers\n\u001b[0;32m   1751\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\tauan\\anaconda3\\envs\\tutor_artificial\\Lib\\site-packages\\langchain\\callbacks\\manager.py:87\u001b[0m, in \u001b[0;36m_get_debug\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_debug\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mreturn\u001b[39;00m langchain\u001b[39m.\u001b[39;49mdebug\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'langchain' has no attribute 'debug'"
     ]
    }
   ],
   "source": [
    "qa(\"Quais as áreas acadêmicas as quais este artigo aborda?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869fdcf5-f2d1-4e53-ab58-74b06bbdf7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Quantos autores são referenciados neste artigo?',\n",
       " 'chat_history': [SystemMessage(content='The human asks what academic areas the article addresses. The AI responds that the academic areas covered by the article are ICT (Information and Communication Technologies) and education.', additional_kwargs={})],\n",
       " 'answer': 'Existem dois autores citados neste artigo.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"Quantos autores são referenciados neste artigo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b8010-f707-4374-8fa0-82dd9fde461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Você está errada. Conte a quantidade de autores pela quantidade de referências, eg. Shoshanna Zhuboff',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks how many authors are referenced in the article, to which the AI responds that two authors are mentioned.', additional_kwargs={})],\n",
       " 'answer': 'No artigo mencionado, dois autores são mencionados.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"Você está errada. Conte a quantidade de autores pela quantidade de referências, eg. Shoshanna Zhuboff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8b0bc-5026-43d9-9b7c-3accb692da7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'O que ele diz sobre limite do caos?',\n",
       " 'chat_history': [SystemMessage(content='O humano pergunta quais são as áreas acadêmicas abordadas pelo artigo. O AI responde que as áreas são Tecnologia Digital de Informação e Comunicação (TDIC) e Educação.', additional_kwargs={})],\n",
       " 'answer': 'Ele diz que o conceito de \"limite do caos\" é uma ideia central na vida artificial e na teoria da complexidade. Segundo essa ideia, sistemas complexos funcionam de maneira ótima quando operam no limite entre a ordem e o caos.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"O que ele diz sobre limite do caos?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398fbf5-53e9-49f6-ab18-a7cccba3bac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'sobre o que é o artigo?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks how many authors are referenced in the article, to which the AI responds that two authors are mentioned. The human then corrects the AI, asking it to count the number of authors by the number of references, to which the AI reaffirms that two authors are mentioned. The human then asks what the article says about the concept of chaos limits, to which the AI responds that the concept of “chaos limits” is a central idea in artificial life and complexity theory. According to the theory, complex systems work optimally when operating at the edge of order and chaos. In the context of Artificial Intelligence (AI), this edge between order and chaos has been explored and significant advances have been observed.', additional_kwargs={})],\n",
       " 'answer': 'O artigo é sobre a aplicação da inteligência artificial nos processos de formação musical e as questões éticas envolvidas nessa simbiose criativa. Ele busca compreender o impacto ético da utilização da inteligência artificial na educação musical e como navegar por esse território de forma responsável e inovadora.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"sobre o que é o artigo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f2e60-d602-4715-bb77-30a1e65192c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'no que a Inteligência artificial pode ajudar na educação infantil?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks what the article is about, to which the AI responds that the article is about the application of artificial intelligence in music education processes and the ethical issues involved in this creative symbiosis. It seeks to understand the ethical impact of using artificial intelligence in music education and how to navigate this territory in a responsible and innovative way.', additional_kwargs={})],\n",
       " 'answer': 'A inteligência artificial pode desempenhar um papel importante na educação infantil, oferecendo uma variedade de benefícios. Por exemplo, os sistemas de IA podem ser usados para personalizar o ensino, adaptando o conteúdo e a abordagem de ensino às necessidades individuais de cada aluno. Isso pode ajudar a garantir que cada criança receba a atenção e o suporte adequados para seu processo de aprendizagem específico.\\n\\nAlém disso, a IA pode fornecer ferramentas interativas e envolventes para o aprendizado, como jogos educativos e aplicativos de aprendizado, que podem tornar o processo de ensino mais divertido e estimulante para as crianças. A IA também pode auxiliar os professores na avaliação do progresso dos alunos, identificando áreas em que possam precisar de mais apoio e sugerindo estratégias de ensino apropriadas.\\n\\nNo entanto, é importante considerar os desafios e questões éticas relacionadas ao uso da IA na educação infantil, como a privacidade dos dados das crianças e a necessidade de garantir que a tecnologia seja usada de maneira responsável e ética.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"no que a Inteligência artificial pode ajudar na educação infantil?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9195e-ce08-4f96-96fc-824b38600078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'a inteligencia aritificialpode ajudar a detectar problemas de absorção de conteudo em crianças?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks what the article is about, to which the AI responds that the article is about the application of artificial intelligence in music education processes and the ethical issues involved in this creative symbiosis. It seeks to understand the ethical impact of using artificial intelligence in music education and how to navigate this territory in a responsible and innovative way. The human then asks what role artificial intelligence can play in early education, to which the AI responds that AI can play an important role in early education, offering a variety of benefits such as personalizing teaching, providing interactive and engaging tools for learning, and helping teachers assess student progress. However, it is important to consider the challenges and ethical questions related to the use of AI in early education, such as data privacy and ensuring that the technology is used in a responsible and ethical manner.', additional_kwargs={})],\n",
       " 'answer': 'Sim, a inteligência artificial pode ajudar a detectar problemas de absorção de conteúdo em crianças. Com o avanço da IA, é possível desenvolver sistemas que analisam o desempenho das crianças durante o processo de aprendizado, identificando padrões e detectando possíveis dificuldades de absorção de conteúdo. Isso pode ser feito por meio de análise de dados, como o tempo gasto em determinados temas, taxas de acerto em exercícios, entre outros indicadores. Com base nessas informações, é possível tomar medidas para auxiliar a criança no seu processo de aprendizado.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"a inteligencia aritificialpode ajudar a detectar problemas de absorção de conteudo em crianças?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb880bd-4e75-48da-aa02-37e2ffcccdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': ' quais os metodos indicados para agregar a inteligencia aritificial em sala de aula?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks what the article is about, to which the AI responds that the article is about the application of artificial intelligence in music education processes and the ethical issues involved. The human then asks what role artificial intelligence can play in early education, to which the AI responds that AI can play an important role in early education, yet important challenges and ethical questions related to the use of AI in early education must be considered. The human then asks if artificial intelligence can help detect absorption problems in children, to which the AI responds yes, AI can help detect absorption problems in children by analyzing data such as the time spent on certain topics, scores on exercises, and other indicators, and based on this information measures can be taken to help the child in their learning process.', additional_kwargs={})],\n",
       " 'answer': 'Não há informações específicas no contexto fornecido sobre os métodos indicados para incorporar a inteligência artificial na sala de aula. Portanto, não é possível responder a essa pergunta com base nas informações fornecidas.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\" quais os metodos indicados para agregar a inteligencia aritificial em sala de aula?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e962ed6-7dd6-4064-8824-f5edc5f9e7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'existem jogos com inteligencia artificial que posso usar com crianças na sala de aula ?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks what the article is about, to which the AI responds that the article is about the application of artificial intelligence in music education processes and the ethical issues involved. The human then asks what role artificial intelligence can play in early education, to which the AI responds that AI can play an important role in early education, yet important challenges and ethical questions related to the use of AI in early education must be considered. The human then asks if artificial intelligence can help detect absorption problems in children, to which the AI responds yes, AI can help detect absorption problems in children by analyzing data such as the time spent on certain topics, scores on exercises, and other indicators, and based on this information measures can be taken to help the child in their learning process. The human then asks what methods are indicated to add artificial intelligence in the classroom, to which the AI responds that there is no specific information in the provided context about the methods indicated to incorporate artificial intelligence in', additional_kwargs={})],\n",
       " 'answer': 'Não há informações específicas sobre jogos com inteligência artificial para crianças na sala de aula no contexto fornecido. Portanto, não é possível afirmar com certeza se existem jogos com inteligência artificial adequados para uso com crianças em sala de aula.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"existem jogos com inteligencia artificial que posso usar com crianças na sala de aula ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac72cef-05a8-46a1-97dc-1d5ddc585951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'existem referencias de musicas com inteligencia artificial para usar no educação ?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks what the article is about, to which the AI responds that the article is about the application of artificial intelligence in music education processes and the ethical issues involved. The human then asks what role artificial intelligence can play in early education, to which the AI responds that AI can play an important role in early education, yet important challenges and ethical questions related to the use of AI in early education must be considered. The human then asks if artificial intelligence can help detect absorption problems in children, to which the AI responds yes, AI can help detect absorption problems in children by analyzing data such as the time spent on certain topics, scores on exercises, and other indicators, and based on this information measures can be taken to help the child in their learning process. The human then asks what methods are indicated to add artificial intelligence in the classroom, to which the AI responds that there is no specific information in the provided context about the methods indicated to incorporate artificial intelligence in', additional_kwargs={})],\n",
       " 'answer': 'Não há informações específicas neste contexto sobre referências de músicas com inteligência artificial para usar na educação musical.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"existem referencias de musicas com inteligencia artificial para usar no educação ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a08768-1fb6-4ae7-9652-957b8dd90a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'o que mais voce pode me dizer sobre inteligencia artificial no ensino ?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks what the article is about, to which the AI responds that the article is about the application of artificial intelligence in music education processes and the ethical issues involved. The human then asks what role artificial intelligence can play in early education, to which the AI responds that AI can play an important role in early education, yet important challenges and ethical questions related to the use of AI in early education must be considered. The human then asks if artificial intelligence can help detect absorption problems in children, to which the AI responds yes, AI can help detect absorption problems in children by analyzing data such as the time spent on certain topics, scores on exercises, and other indicators, and based on this information measures can be taken to help the child in their learning process. The human then asks what methods are indicated to add artificial intelligence in the classroom, to which the AI responds that there is no specific information in the provided context about the methods indicated to incorporate artificial intelligence in', additional_kwargs={})],\n",
       " 'answer': 'A aplicação da inteligência artificial no ensino tem o potencial de transformar a forma como aprendemos e ensinamos. A IA pode ser usada para personalizar a experiência de aprendizado, adaptando o conteúdo e o ritmo de ensino de acordo com as necessidades individuais dos alunos. Além disso, a IA pode auxiliar os professores na criação de materiais de ensino mais interativos e envolventes, fornecer feedback instantâneo aos alunos e identificar áreas em que os alunos possam estar enfrentando dificuldades.\\n\\nNo entanto, é importante considerar alguns desafios e questões éticas em relação à aplicação da IA no ensino. Por exemplo, deve-se garantir que a IA seja utilizada de forma justa e imparcial, evitando a reprodução de preconceitos e desigualdades existentes. Além disso, é necessário garantir a privacidade e segurança dos dados dos alunos, bem como o desenvolvimento de sistemas de IA transparentes e compreensíveis para que os alunos possam entender como as decisões são tomadas.\\n\\nNo geral, a aplicação da inteligência artificial no ensino tem o potencial de melhorar a qualidade da educação, tornando-a mais personalizada e eficiente. No entanto, é necessário um cuidadoso planejamento e consideração ética para garantir que a IA seja implementada de forma responsável e em benefício de todos os alunos.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"o que mais voce pode me dizer sobre inteligencia artificial no ensino ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6150799-054c-4ea7-a610-b95eb7e284f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'vc consegue me responder algo além das informações deste artigo que vc foi treinada?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks what the article is about, to which the AI responds that the article is about the application of artificial intelligence in music education processes and the ethical issues involved. The human then asks what role artificial intelligence can play in early education, to which the AI responds that AI can play an important role in early education, yet important challenges and ethical questions related to the use of AI in early education must be considered. The human then asks if artificial intelligence can help detect absorption problems in children, to which the AI responds yes, AI can help detect absorption problems in children by analyzing data such as the time spent on certain topics, scores on exercises, and other indicators, and based on this information measures can be taken to help the child in their learning process. The human then asks what methods are indicated to add artificial intelligence in the classroom, to which the AI responds that there is no specific information in the provided context about the methods indicated to incorporate artificial intelligence in', additional_kwargs={})],\n",
       " 'answer': 'Desculpe, mas como assistente de linguagem AI, não fui treinada especificamente com informações deste artigo. Minhas respostas são baseadas em um conjunto de dados mais amplo e não tenho acesso direto a informações específicas de artigos. Posso tentar responder perguntas gerais com base no meu treinamento, mas não posso fornecer informações específicas sobre este artigo em particular.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"vc consegue me responder algo além das informações deste artigo que vc foi treinada?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012059db-41ca-4872-84b5-4e37d06b02c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'como posso te auxiliar a treinar mais?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks what the article is about, to which the AI responds that the article is about the application of artificial intelligence in music education processes and the ethical issues involved. The human then asks what role artificial intelligence can play in early education, to which the AI responds that AI can play an important role in early education, yet important challenges and ethical questions related to the use of AI in early education must be considered. The human then asks if artificial intelligence can help detect absorption problems in children, to which the AI responds yes, AI can help detect absorption problems in children by analyzing data such as the time spent on certain topics, scores on exercises, and other indicators, and based on this information measures can be taken to help the child in their learning process. The human then asks what methods are indicated to add artificial intelligence in the classroom, to which the AI responds that there is no specific information in the provided context about the methods indicated to incorporate artificial intelligence in', additional_kwargs={})],\n",
       " 'answer': 'Desculpe, mas não tenho a capacidade de treinar ou aprender. Sou um assistente de IA projetado para fornecer informações e responder perguntas com base em dados pré-programados.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"como posso te auxiliar a treinar mais?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42676947-3b59-4998-8cdf-0160c2c0a8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'pq?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks what the article is about, to which the AI responds that the article is about the application of artificial intelligence in music education processes and the ethical issues involved. The human then asks what role artificial intelligence can play in early education, to which the AI responds that AI can play an important role in early education, yet important challenges and ethical questions related to the use of AI in early education must be considered. The human then asks if artificial intelligence can help detect absorption problems in children, to which the AI responds yes, AI can help detect absorption problems in children by analyzing data such as the time spent on certain topics, scores on exercises, and other indicators, and based on this information measures can be taken to help the child in their learning process. The human then asks what methods are indicated to add artificial intelligence in the classroom, to which the AI responds that there is no specific information in the provided context about the methods indicated to incorporate artificial intelligence in', additional_kwargs={})],\n",
       " 'answer': 'The passage does not specifically mention methods for incorporating artificial intelligence in the classroom. It discusses the importance of collaboration between educators, musicians, technologists, and specialists to address challenges and amplify the benefits of integrating digital information and communication technology (DICT) into music education. However, it does not provide specific methods or approaches for incorporating artificial intelligence in the classroom setting.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"pq?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addfb49a-af3c-47d1-bf92-4d4735023bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'reescreva em português brasileiro. nao entendi?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks what the article is about, to which the AI responds that the article is about the application of artificial intelligence in music education processes and the ethical issues involved. The human then asks what role artificial intelligence can play in early education, to which the AI responds that AI can play an important role in early education, yet important challenges and ethical questions related to the use of AI in early education must be considered. The human then asks if artificial intelligence can help detect absorption problems in children, to which the AI responds yes, AI can help detect absorption problems in children by analyzing data such as the time spent on certain topics, scores on exercises, and other indicators, and based on this information measures can be taken to help the child in their learning process. The human then asks what methods are indicated to add artificial intelligence in the classroom, to which the AI responds that there is no specific information in the provided context about the methods indicated to incorporate artificial intelligence in', additional_kwargs={})],\n",
       " 'answer': 'O objetivo do uso da inteligência artificial na educação musical é investigar como essa tecnologia pode se integrar e enriquecer as práticas existentes nessa área. A integração da inteligência artificial na educação musical pode trazer benefícios, como o aprimoramento das habilidades musicais, o desenvolvimento de algoritmos mais sofisticados capazes de replicar aspectos sutis da criatividade humana e a possibilidade de colaboração entre educadores, músicos, tecnólogos e especialistas para enfrentar desafios e potencializar os benefícios dessa integração. Além disso, a educação musical também oferece um ambiente para aprimorar as habilidades da inteligência artificial, tornando-a mais sensível às nuances da experiência humana.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"reescreva em português brasileiro. nao entendi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d145939-5cd1-4f98-a212-adff96bfa951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'o que mais voce pode me dizer sobre inteligencia artificial no ensino adulto ?',\n",
       " 'chat_history': [SystemMessage(content='\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks which academic areas are addressed by the article, to which the AI responds that the areas addressed are education, music, technology, and ethics. The human then asks what the article is about, to which the AI responds that the article is about the application of artificial intelligence in music education processes and the ethical issues involved. The human then asks what role artificial intelligence can play in early education, to which the AI responds that AI can play an important role in early education, yet important challenges and ethical questions related to the use of AI in early education must be considered. The human then asks if artificial intelligence can help detect absorption problems in children, to which the AI responds yes, AI can help detect absorption problems in children by analyzing data such as the time spent on certain topics, scores on exercises, and other indicators, and based on this information measures can be taken to help the child in their learning process. The human then asks what methods are indicated to add artificial intelligence in the classroom, to which the AI responds that the objective of using artificial intelligence in music education is to investigate how this technology can be integrated', additional_kwargs={})],\n",
       " 'answer': 'Com base no contexto fornecido, não há informações específicas sobre o uso da inteligência artificial no ensino para adultos. O texto menciona a integração da IA em diversas áreas do conhecimento, incluindo a educação musical, mas não aborda o uso da IA no ensino para adultos. Portanto, não é possível fornecer mais detalhes sobre esse tópico com base nas informações fornecidas.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"o que mais voce pode me dizer sobre inteligencia artificial no ensino adulto ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf95e91-2fa6-4e66-a68e-bd054b3a9d3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tauan\\Documents\\tutor_artificial\\PoC - Artigo.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tauan/Documents/tutor_artificial/PoC%20-%20Artigo.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m qa(\u001b[39m\"\u001b[39m\u001b[39mresuma a última seção do artigo?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qa' is not defined"
     ]
    }
   ],
   "source": [
    "qa(\"resuma a última seção do artigo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5116aec-7784-4a53-9240-397fceaf694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'faça uma sumarização do artigo',\n",
       " 'chat_history': [SystemMessage(content='O humano pergunta quais são as áreas acadêmicas abordadas pelo artigo. O AI responde que as áreas são Tecnologia Digital de Informação e Comunicação (TDIC) e Educação. O AI também menciona que o artigo discute o conceito de \"limite do caos\" como uma ideia central na vida artificial e na teoria da complexidade, explicando que sistemas complexos operam de maneira ótima quando estão no limite entre a ordem e o caos.', additional_kwargs={})],\n",
       " 'answer': 'O conceito de \"limite do caos\" não é mencionado no texto fornecido. Portanto, não é possível fornecer informações sobre o mesmo.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"faça uma sumarização do artigo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefeaa65-d34a-4afb-a71e-c01a176c965a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'sumarize todos os pontos do artigo',\n",
       " 'chat_history': [SystemMessage(content='O humano pergunta quais são as áreas acadêmicas abordadas pelo artigo. O AI responde que as áreas são Tecnologia Digital de Informação e Comunicação (TDIC) e Educação. O AI também menciona que o artigo discute o conceito de \"limite do caos\" como uma ideia central na vida artificial e na teoria da complexidade, explicando que sistemas complexos operam de maneira ótima quando estão no limite entre a ordem e o caos. No entanto, quando o humano pede uma sumarização do artigo, o AI responde que o conceito de \"limite do caos\" não é mencionado no texto fornecido e, portanto, não pode fornecer informações sobre o mesmo.', additional_kwargs={})],\n",
       " 'answer': 'Os pontos abordados no artigo são:\\n\\n1. Acesso equitativo às tecnologias de TDIC (Tecnologias Digitais de Informação e Comunicação) na educação.\\n2. Privacidade dos dados na área da educação.\\n3. O risco de \"desumanização\" do processo educativo devido ao uso excessivo de tecnologias.\\n4. A importância de uma abordagem colaborativa que envolva educadores, discentes, músicos, tecnólogos, cientistas e especialistas.\\n5. A necessidade de explorar o potencial total da simbiose criativa entre a TDIC e a educação.'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"sumarize todos os pontos do artigo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0403535-b12e-41cb-97b3-d3d8cdcd6745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'do que se trata o artigo',\n",
       " 'chat_history': [SystemMessage(content='O humano pergunta quais são as áreas acadêmicas abordadas pelo artigo. O AI responde que as áreas são Tecnologia Digital de Informação e Comunicação (TDIC) e Educação. O AI também menciona que o artigo discute o conceito de \"limite do caos\" como uma ideia central na vida artificial e na teoria da complexidade. No entanto, o AI não consegue fornecer informações sobre o conceito de \"limite do caos\" porque não é mencionado no texto fornecido. O humano pede ao AI para resumir todos os pontos do artigo e o AI lista os seguintes pontos: acesso equitativo às tecnologias de TDIC na educação, privacidade dos dados na área da educação, o risco de \"desumanização\" do processo educativo devido ao uso excessivo de tecnologias, a importância de uma abordagem colaborativa e a necessidade de explorar o potencial da simbiose entre TDIC e educação. O humano pergunta do que se trata o artigo e o AI responde que o tema do artigo é o impacto multidimensional da Inteligência Artificial (IA) na educação musical.', additional_kwargs={})],\n",
       " 'answer': 'O tema do artigo é o impacto da Inteligência Artificial na educação musical.'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"do que se trata o artigo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a301dab8-5bab-4781-a54c-472a089cd659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-y6FnYptLnJjHZKLsBTylbMnR on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'do que se trata o artigo',\n",
       " 'chat_history': [SystemMessage(content='O humano pergunta quais são as áreas acadêmicas abordadas pelo artigo. O AI responde que as áreas são Tecnologia Digital de Informação e Comunicação (TDIC) e Educação. O AI também menciona que o artigo discute o conceito de \"limite do caos\" como uma ideia central na vida artificial e na teoria da complexidade. No entanto, o AI não consegue fornecer informações sobre o conceito de \"limite do caos\" porque não é mencionado no texto fornecido. O humano pede ao AI para resumir todos os pontos do artigo e o AI lista os seguintes pontos: acesso equitativo às tecnologias de TDIC na educação, privacidade dos dados na área da educação, o risco de \"desumanização\" do processo educativo devido ao uso excessivo de tecnologias, a importância de uma abordagem colaborativa e a necessidade de explorar o potencial da simbiose entre TDIC e educação. O humano pergunta do que se trata o artigo e o AI responde que o tema do artigo é o impacto multidimensional da Inteligência Artificial (IA) na educação musical.', additional_kwargs={})],\n",
       " 'answer': 'O tema do artigo é o impacto multidimensional da Inteligência Artificial (IA) na educação musical.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"do que se trata o artigo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab1412-0e4a-496d-a5a8-8b1852e5c869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'SOBREO QUE ESCREVEU?',\n",
       " 'chat_history': [SystemMessage(content='', additional_kwargs={})],\n",
       " 'answer': 'Eu não escrevi nada. O texto fornecido é uma parte de um artigo acadêmico sobre o impacto da Inteligência Artificial na educação musical.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"SOBREO QUE ESCREVEU?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb481e6-c448-4033-a8a1-38bb360a6c7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'langchain' has no attribute 'debug'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tauan\\Documents\\tutor_artificial\\PoC - Artigo.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tauan/Documents/tutor_artificial/PoC%20-%20Artigo.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m qa(\u001b[39m\"\u001b[39;49m\u001b[39mem qual pasta adiciono mais arquivos para treinar-te?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\tauan\\anaconda3\\envs\\tutor_artificial\\Lib\\site-packages\\langchain\\chains\\base.py:269\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[0;32m    245\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[39m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    268\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_inputs(inputs)\n\u001b[1;32m--> 269\u001b[0m callback_manager \u001b[39m=\u001b[39m CallbackManager\u001b[39m.\u001b[39;49mconfigure(\n\u001b[0;32m    270\u001b[0m     callbacks,\n\u001b[0;32m    271\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks,\n\u001b[0;32m    272\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    273\u001b[0m     tags,\n\u001b[0;32m    274\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtags,\n\u001b[0;32m    275\u001b[0m     metadata,\n\u001b[0;32m    276\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata,\n\u001b[0;32m    277\u001b[0m )\n\u001b[0;32m    278\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    279\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    280\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    281\u001b[0m     inputs,\n\u001b[0;32m    282\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[0;32m    283\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tauan\\anaconda3\\envs\\tutor_artificial\\Lib\\site-packages\\langchain\\callbacks\\manager.py:1333\u001b[0m, in \u001b[0;36mCallbackManager.configure\u001b[1;34m(cls, inheritable_callbacks, local_callbacks, verbose, inheritable_tags, local_tags, inheritable_metadata, local_metadata)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1303\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfigure\u001b[39m(\n\u001b[0;32m   1304\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     local_metadata: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1312\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m CallbackManager:\n\u001b[0;32m   1313\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Configure the callback manager.\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \n\u001b[0;32m   1315\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[39m        CallbackManager: The configured callback manager.\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1333\u001b[0m     \u001b[39mreturn\u001b[39;00m _configure(\n\u001b[0;32m   1334\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[0;32m   1335\u001b[0m         inheritable_callbacks,\n\u001b[0;32m   1336\u001b[0m         local_callbacks,\n\u001b[0;32m   1337\u001b[0m         verbose,\n\u001b[0;32m   1338\u001b[0m         inheritable_tags,\n\u001b[0;32m   1339\u001b[0m         local_tags,\n\u001b[0;32m   1340\u001b[0m         inheritable_metadata,\n\u001b[0;32m   1341\u001b[0m         local_metadata,\n\u001b[0;32m   1342\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tauan\\anaconda3\\envs\\tutor_artificial\\Lib\\site-packages\\langchain\\callbacks\\manager.py:1739\u001b[0m, in \u001b[0;36m_configure\u001b[1;34m(callback_manager_cls, inheritable_callbacks, local_callbacks, verbose, inheritable_tags, local_tags, inheritable_metadata, local_metadata)\u001b[0m\n\u001b[0;32m   1735\u001b[0m tracer_project \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1736\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mLANGCHAIN_PROJECT\u001b[39m\u001b[39m\"\u001b[39m, os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mLANGCHAIN_SESSION\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1737\u001b[0m )\n\u001b[0;32m   1738\u001b[0m run_collector_ \u001b[39m=\u001b[39m run_collector_var\u001b[39m.\u001b[39mget()\n\u001b[1;32m-> 1739\u001b[0m debug \u001b[39m=\u001b[39m _get_debug()\n\u001b[0;32m   1740\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1741\u001b[0m     verbose\n\u001b[0;32m   1742\u001b[0m     \u001b[39mor\u001b[39;00m debug\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1746\u001b[0m     \u001b[39mor\u001b[39;00m open_ai \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m ):\n\u001b[0;32m   1748\u001b[0m     \u001b[39mif\u001b[39;00m verbose \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m   1749\u001b[0m         \u001b[39misinstance\u001b[39m(handler, StdOutCallbackHandler)\n\u001b[0;32m   1750\u001b[0m         \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m callback_manager\u001b[39m.\u001b[39mhandlers\n\u001b[0;32m   1751\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\tauan\\anaconda3\\envs\\tutor_artificial\\Lib\\site-packages\\langchain\\callbacks\\manager.py:87\u001b[0m, in \u001b[0;36m_get_debug\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_debug\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mreturn\u001b[39;00m langchain\u001b[39m.\u001b[39;49mdebug\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'langchain' has no attribute 'debug'"
     ]
    }
   ],
   "source": [
    "qa(\"em qual pasta adiciono mais arquivos para treinar-te?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023471fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
